{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3OTY3NzYz", "number": 1641, "title": "Add NaN counter to Metrics and implement in Parquet writers", "bodyText": "This change adds NaN counter in Metrics model, and update it during Parquet writing. I believe it only touches internal models and will not write the new attribute to output files. This change is the first step towards implementing spec change defined in #348 .\nQuestions:\n\nAs mentioned in a comment I highlighted,  SparkTableUtil (essentially importSparkTable()) (link) reads metrics from Parquet footer directly, and thus won't populate NaN counts. If we don't want to accept this as a fact, we may need to switch ParquetFileReader.readFooter() to use internal parquet reader, and enable metric collection during reading, but this could be much more expensive than the current approach. Do people have better suggestions?\n\nOne thing that may worth noting is that ParquetFileReader.readFooter is on deprecation path (https://www.javadoc.io/doc/org.apache.parquet/parquet-hadoop/1.10.0/deprecated-list.html)\nfileMetrics() in ParquetUtil also has the same problem\n\n\nThe current change doesn't help with removing NaN from lower/upper bound, since parquet library doesn't treat NaN for its min/max stats specially. I'm thinking to use the same approach to populate upper and lower bounds, and wondering if people have better suggestions.\n\nWanted to submit a draft to gather comments on the approach in general. Will add more tests later.", "createdAt": "2020-10-22T02:20:51Z", "url": "https://github.com/apache/iceberg/pull/1641", "merged": true, "mergeCommit": {"oid": "944a437f1057b8be60292426aebdb0b8059d90e0"}, "closed": true, "closedAt": "2020-11-12T19:36:33Z", "author": {"login": "yyanyy"}, "timelineItems": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdU4lItAFqTUxNDMxNDgxMw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdboCrTgBqjM5ODYzMTA4ODg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0MzE0ODEz", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-514314813", "createdAt": "2020-10-22T02:23:48Z", "commit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwMjoyMzo0OFrOHmOOTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwMjozMDo0NVrOHmOVwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MDk3NA==", "bodyText": "We may potentially use ColumnDescriptor desc for determine id, but felt that explicitly passing id could provide better guarantee. Suggestions are welcomed.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r509840974", "createdAt": "2020-10-22T02:23:48Z", "author": {"login": "yyanyy"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -137,11 +141,20 @@ public void write(int repetitionLevel, T value) {\n     public void setColumnStore(ColumnWriteStore columnStore) {\n       this.column.setColumnStore(columnStore);\n     }\n+\n+    @Override\n+    public Stream<FieldMetrics> metrics() {\n+      if (id != null) {\n+        return Stream.of(new FieldMetrics(id.intValue(), 0L, 0L, 0L, null, null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MTU1NA==", "bodyText": "We could potentially use the schema from the footer itself in ParquetUtil instead of explicitly pass it here; currently have it this way since it's guaranteed that the schema will match.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r509841554", "createdAt": "2020-10-22T02:25:57Z", "author": {"login": "yyanyy"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetWriter.java", "diffHunk": "@@ -121,7 +123,7 @@ public void add(T value) {\n \n   @Override\n   public Metrics metrics() {\n-    return ParquetUtil.footerMetrics(writer.getFooter(), metricsConfig);\n+    return ParquetUtil.footerMetrics(writer.getFooter(), model.metrics(), inputSchema, metricsConfig);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MjEyMQ==", "bodyText": "I later noticed that there's a TestParquetMetrics as well, will see if I can merge this to that (and eventually toTestMetrics).\nUpdate: I plan to leave this class separately from TestParquetMetrics since it currently test metrics in a different angle than TestParquetMetrics and has more coverage for NaN use case. Will try merging it back to TestMetrics once I finished implementing NaN across all three writers. In the meanwhile I will develop the same test using flink/spark appender factory to ensure coverage. Let me know if you have better suggestions on this!", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r509842121", "createdAt": "2020-10-22T02:27:55Z", "author": {"login": "yyanyy"}, "path": "data/src/test/java/org/apache/iceberg/parquet/TestParquetMergingMetrics.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.parquet;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericAppenderFactory;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.RandomGenericData;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestParquetMergingMetrics {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0Mjg4Mg==", "bodyText": "This has the similar problem I mentioned in pr description for importing spark table; if the file itself is directly passed in there's not much chance to get the additional metrics tracked by value writers. Currently fileMetrics are only used by tests. Do people have suggestions on this?", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r509842882", "createdAt": "2020-10-22T02:30:45Z", "author": {"login": "yyanyy"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java", "diffHunk": "@@ -65,28 +68,25 @@\n   private ParquetUtil() {\n   }\n \n-  // Access modifier is package-private, to only allow use from existing tests\n-  static Metrics fileMetrics(InputFile file) {\n-    return fileMetrics(file, MetricsConfig.getDefault());\n-  }\n-\n   public static Metrics fileMetrics(InputFile file, MetricsConfig metricsConfig) {\n     return fileMetrics(file, metricsConfig, null);\n   }\n \n   public static Metrics fileMetrics(InputFile file, MetricsConfig metricsConfig, NameMapping nameMapping) {\n     try (ParquetFileReader reader = ParquetFileReader.open(ParquetIO.file(file))) {\n-      return footerMetrics(reader.getFooter(), metricsConfig, nameMapping);\n+      return footerMetrics(reader.getFooter(), Stream.empty(), null, metricsConfig, nameMapping);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1MDE3MjYw", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-515017260", "createdAt": "2020-10-22T18:42:14Z", "commit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxODo0MjoxNFrOHmvEXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxODo0NzoxOVrOHmvPgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM3OTEwMA==", "bodyText": "Please add Java doc.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r510379100", "createdAt": "2020-10-22T18:42:14Z", "author": {"login": "giovannifumarola"}, "path": "api/src/main/java/org/apache/iceberg/FieldMetrics.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+\n+import java.nio.ByteBuffer;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM4MTk1Mw==", "bodyText": "It is not clear the use of ID here.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r510381953", "createdAt": "2020-10-22T18:47:19Z", "author": {"login": "giovannifumarola"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetWriters.java", "diffHunk": "@@ -126,38 +126,39 @@ private SparkParquetWriters() {\n     @Override\n     public ParquetValueWriter<?> primitive(DataType sType, PrimitiveType primitive) {\n       ColumnDescriptor desc = type.getColumnDescription(currentPath());\n+      Type.ID id = primitive.getId();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bbfa6af9d5bb48aaeccaa4b8fcb5570b056cfce9", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/bbfa6af9d5bb48aaeccaa4b8fcb5570b056cfce9", "committedDate": "2020-10-23T01:34:06Z", "message": "update tests"}, "afterCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/a128ae00949320577a279bb44d1245db5538db51", "committedDate": "2020-10-28T23:18:17Z", "message": "add flink and spark tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE5MTgxMDgy", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-519181082", "createdAt": "2020-10-29T00:03:16Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQwMDowMzoxN1rOHqB1oA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQwMDowMzoxN1rOHqB1oA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzgzMjM1Mg==", "bodyText": "The change to this class was mostly trying to use it in TestSparkParquetMergingMetrics. Currently this class is only being used for reading rows for metadata tables (in RowDataReader, and I think only the metadata table will produce DataTask).\nIn the tests I wanted to convert Record to InternalRow for testing Spark appender. I was debating if I should expand this class beyond its current usage, or to write a new converter. Here are the two things I need to change to (partially) implement the former:\n\nnull handling which results to the change in get(): RowDataReader doesn't call get() directly (it uses Dyn reflections for reading individual attributes and skip nulls) for converting into other Spark internal row representation (UnsafeRow in this case), thus we didn't see issue. However, when spark parquet writer uses get(), without this change NPE will occur. Note that even after this change, other use cases of this class (e.g. getUTF8String() are still not null safe, and I wonder if people have opinion on if we want a full null-safe support update to all methods in this class.\nfor getBinary() change, currently we convert Fixed type to binary for Spark (link), and the method I used for creating random records generate fixed type with byte[] (link), and before this change getBinary() doesn't work for byte[] implementation of fixed type. Alternatively we could wrap fixed type in random record generator the same way we do for binary type. I decide to do the former to allow binary related types to be more flexible when wrapping them in this class, but I guess this comes back to the question to if we want to evolve this class or to create a separate converter.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r513832352", "createdAt": "2020-10-29T00:03:17Z", "author": {"login": "yyanyy"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/StructInternalRow.java", "diffHunk": "@@ -146,8 +146,13 @@ public UTF8String getUTF8String(int ordinal) {\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE5MTg3OTQx", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-519187941", "createdAt": "2020-10-29T00:08:39Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQwMDowODozOVrOHqB77g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQwMDowODozOVrOHqB77g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzgzMzk2Ng==", "bodyText": "I currently put it this way so that file types other than parquet could use it, however I've noticed that ORC reports metrics differently than parquet. I think ORC currently doesn't report anything for elements in list/map type, but report metrics for the list/map type themselves (i.e. root node), which is completely opposite to what parquet does today.\nTo me what parquet does seems more useful, and I wonder if people have opinion on if we want to record element metrics for ORC along with the new NaN counter. This is not a blocker for this specific pr, but the ORC implementation is on its way and I'd like to gather feedback sooner the better.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r513833966", "createdAt": "2020-10-29T00:08:39Z", "author": {"login": "yyanyy"}, "path": "data/src/test/java/org/apache/iceberg/TestMergingMetrics.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.RandomGenericData;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class TestMergingMetrics<T> {\n+\n+  // all supported fields, except for UUID which is on deprecation path: see https://github.com/apache/iceberg/pull/1611\n+  // as well as Types.TimeType and Types.TimestampType.withoutZone as both are not supported by Spark\n+  protected static final Types.NestedField ID_FIELD = required(1, \"id\", Types.IntegerType.get());\n+  protected static final Types.NestedField DATA_FIELD = optional(2, \"data\", Types.StringType.get());\n+  protected static final Types.NestedField FLOAT_FIELD = required(3, \"float\", Types.FloatType.get());\n+  protected static final Types.NestedField DOUBLE_FIELD = optional(4, \"double\", Types.DoubleType.get());\n+  protected static final Types.NestedField DECIMAL_FIELD = optional(5, \"decimal\", Types.DecimalType.of(5, 3));\n+  protected static final Types.NestedField FIXED_FIELD = optional(7, \"fixed\", Types.FixedType.ofLength(4));\n+  protected static final Types.NestedField BINARY_FIELD = optional(8, \"binary\", Types.BinaryType.get());\n+  protected static final Types.NestedField FLOAT_LIST = optional(9, \"floatlist\",\n+      Types.ListType.ofRequired(10, Types.FloatType.get()));\n+  protected static final Types.NestedField LONG_FIELD = optional(11, \"long\", Types.LongType.get());\n+\n+  protected static final Types.NestedField MAP_FIELD_1 = optional(17, \"map1\",\n+      Types.MapType.ofOptional(18, 19, Types.FloatType.get(), Types.StringType.get())\n+  );\n+  protected static final Types.NestedField MAP_FIELD_2 = optional(20, \"map2\",\n+      Types.MapType.ofOptional(21, 22, Types.IntegerType.get(), Types.DoubleType.get())\n+  );\n+  protected static final Types.NestedField STRUCT_FIELD = optional(23, \"structField\", Types.StructType.of(\n+      required(24, \"booleanField\", Types.BooleanType.get()),\n+      optional(25, \"date\", Types.DateType.get()),\n+      optional(27, \"timestamp\", Types.TimestampType.withZone())\n+  ));\n+\n+  private static final Set<Integer> IDS_WITH_ZERO_NAN_COUNT = ImmutableSet.of(1, 2, 5, 7, 8, 11, 24, 25, 27);\n+\n+  private static final Map<Types.NestedField, Integer> FIELDS_WITH_NAN_COUNT_TO_ID = ImmutableMap.of(\n+      FLOAT_FIELD, 3, DOUBLE_FIELD, 4, FLOAT_LIST, 10, MAP_FIELD_1, 18, MAP_FIELD_2, 22\n+  );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIwNDI5MzEy", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-520429312", "createdAt": "2020-10-30T07:34:59Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNzozNDo1OVrOHrD8hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNzo1NjoyMVrOHrEcPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkxNTQ2Mg==", "bodyText": "Based on the behavior of footer metrics, it is not clear to me if we should have this metrics for Counts mode.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r514915462", "createdAt": "2020-10-30T07:34:59Z", "author": {"login": "jackye1995"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java", "diffHunk": "@@ -149,9 +149,25 @@ public static Metrics footerMetrics(ParquetMetadata metadata, MetricsConfig metr\n     }\n \n     return new Metrics(rowCount, columnSizes, valueCounts, nullValueCounts,\n+        getNanValueCounts(fieldMetrics, metricsConfig, inputSchema),\n         toBufferMap(fileSchema, lowerBounds), toBufferMap(fileSchema, upperBounds));\n   }\n \n+  private static Map<Integer, Long> getNanValueCounts(\n+      Stream<FieldMetrics> fieldMetrics, MetricsConfig metricsConfig, Schema inputSchema) {\n+    if (fieldMetrics == null || inputSchema == null) {\n+      return Maps.newHashMap();\n+    }\n+\n+    return fieldMetrics\n+        .filter(metrics -> {\n+          String alias = inputSchema.idToAlias(metrics.getId());\n+          MetricsMode metricsMode = metricsConfig.columnMode(alias);\n+          return metricsMode != MetricsModes.None.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkxNjg5MQ==", "bodyText": "Why we want to change the interface to include inputSchema? Line 99-100 below already creates the fieldSchema, are they different?", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r514916891", "createdAt": "2020-10-30T07:38:54Z", "author": {"login": "jackye1995"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java", "diffHunk": "@@ -65,28 +68,25 @@\n   private ParquetUtil() {\n   }\n \n-  // Access modifier is package-private, to only allow use from existing tests\n-  static Metrics fileMetrics(InputFile file) {\n-    return fileMetrics(file, MetricsConfig.getDefault());\n-  }\n-\n   public static Metrics fileMetrics(InputFile file, MetricsConfig metricsConfig) {\n     return fileMetrics(file, metricsConfig, null);\n   }\n \n   public static Metrics fileMetrics(InputFile file, MetricsConfig metricsConfig, NameMapping nameMapping) {\n     try (ParquetFileReader reader = ParquetFileReader.open(ParquetIO.file(file))) {\n-      return footerMetrics(reader.getFooter(), metricsConfig, nameMapping);\n+      return footerMetrics(reader.getFooter(), Stream.empty(), null, metricsConfig, nameMapping);\n     } catch (IOException e) {\n       throw new RuntimeIOException(e, \"Failed to read footer of file: %s\", file);\n     }\n   }\n \n-  public static Metrics footerMetrics(ParquetMetadata metadata, MetricsConfig metricsConfig) {\n-    return footerMetrics(metadata, metricsConfig, null);\n+  public static Metrics footerMetrics(ParquetMetadata metadata, Stream<FieldMetrics> fieldMetrics,\n+                                      Schema inputSchema, MetricsConfig metricsConfig) {\n+    return footerMetrics(metadata, fieldMetrics, inputSchema, metricsConfig, null);\n   }\n \n-  public static Metrics footerMetrics(ParquetMetadata metadata, MetricsConfig metricsConfig, NameMapping nameMapping) {\n+  public static Metrics footerMetrics(ParquetMetadata metadata, Stream<FieldMetrics> fieldMetrics,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkyMTU4Mg==", "bodyText": "Yeah it's a messy change, it would be great if we can somehow not pass in the id", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r514921582", "createdAt": "2020-10-30T07:51:33Z", "author": {"login": "jackye1995"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -137,11 +141,20 @@ public void write(int repetitionLevel, T value) {\n     public void setColumnStore(ColumnWriteStore columnStore) {\n       this.column.setColumnStore(columnStore);\n     }\n+\n+    @Override\n+    public Stream<FieldMetrics> metrics() {\n+      if (id != null) {\n+        return Stream.of(new FieldMetrics(id.intValue(), 0L, 0L, 0L, null, null));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MDk3NA=="}, "originalCommit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkyMTkxMw==", "bodyText": "Yeah, as my comment in the ParquetUtil class, we should investigate if they are actually the same schema.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r514921913", "createdAt": "2020-10-30T07:52:18Z", "author": {"login": "jackye1995"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetWriter.java", "diffHunk": "@@ -121,7 +123,7 @@ public void add(T value) {\n \n   @Override\n   public Metrics metrics() {\n-    return ParquetUtil.footerMetrics(writer.getFooter(), metricsConfig);\n+    return ParquetUtil.footerMetrics(writer.getFooter(), model.metrics(), inputSchema, metricsConfig);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MTU1NA=="}, "originalCommit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkyMjYwMA==", "bodyText": "Documentation needed. And is the name a bit too generic?", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r514922600", "createdAt": "2020-10-30T07:54:03Z", "author": {"login": "jackye1995"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriter.java", "diffHunk": "@@ -28,4 +30,7 @@\n   List<TripleWriter<?>> columns();\n \n   void setColumnStore(ColumnWriteStore columnStore);\n+\n+  Stream<FieldMetrics> metrics();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkyMzA5OQ==", "bodyText": "I think it would be more clear with more documentation for the FieldMetrics class and the Stream<FieldMetrics> metrics() method.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r514923099", "createdAt": "2020-10-30T07:55:12Z", "author": {"login": "jackye1995"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetWriters.java", "diffHunk": "@@ -126,38 +126,39 @@ private SparkParquetWriters() {\n     @Override\n     public ParquetValueWriter<?> primitive(DataType sType, PrimitiveType primitive) {\n       ColumnDescriptor desc = type.getColumnDescription(currentPath());\n+      Type.ID id = primitive.getId();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM4MTk1Mw=="}, "originalCommit": {"oid": "a47cf2cfd8091ea98452c06ab77a9a69f09c2ec6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkyMzU4MA==", "bodyText": "Do we need all these metrics that can be obtained from the footer? To me it feels more reasonable for this class to only contain metrics that is not covered by the footer metrics.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r514923580", "createdAt": "2020-10-30T07:56:21Z", "author": {"login": "jackye1995"}, "path": "api/src/main/java/org/apache/iceberg/FieldMetrics.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+\n+import java.nio.ByteBuffer;\n+\n+/**\n+ * Iceberg internally tracked field level metrics.\n+ */\n+public class FieldMetrics {\n+  private final int id;\n+  private final long valueCount;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjU3NzEw", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521257710", "createdAt": "2020-11-01T20:23:19Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDoyMzoxOVrOHrx10Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDoyMzoxOVrOHrx10Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY2NzQwOQ==", "bodyText": "Style: We avoid using get in method names because it adds no value. For a simple getter, the method should be named for the field: valueCount().", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515667409", "createdAt": "2020-11-01T20:23:19Z", "author": {"login": "rdblue"}, "path": "api/src/main/java/org/apache/iceberg/FieldMetrics.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+\n+import java.nio.ByteBuffer;\n+\n+/**\n+ * Iceberg internally tracked field level metrics.\n+ */\n+public class FieldMetrics {\n+  private final int id;\n+  private final long valueCount;\n+  private final long nullValueCount;\n+  private final long nanValueCount;\n+  private final ByteBuffer lowerBound;\n+  private final ByteBuffer upperBound;\n+\n+  public FieldMetrics(int id,\n+                      long valueCount,\n+                      long nullValueCount,\n+                      long nanValueCount,\n+                      ByteBuffer lowerBound,\n+                      ByteBuffer upperBound) {\n+    this.id = id;\n+    this.valueCount = valueCount;\n+    this.nullValueCount = nullValueCount;\n+    this.nanValueCount = nanValueCount;\n+    this.lowerBound = lowerBound;\n+    this.upperBound = upperBound;\n+  }\n+\n+  public int getId() {\n+    return id;\n+  }\n+\n+  public long getValueCount() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjU3ODMz", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521257833", "createdAt": "2020-11-01T20:24:44Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDoyNDo0NVrOHrx2fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDoyNDo0NVrOHrx2fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY2NzU4Mg==", "bodyText": "If we intend to remove it, then we should add @Deprecated and Javadoc @deprecated will be removed in 0.12.0; use ... instead.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515667582", "createdAt": "2020-11-01T20:24:45Z", "author": {"login": "rdblue"}, "path": "api/src/main/java/org/apache/iceberg/Metrics.java", "diffHunk": "@@ -37,12 +37,14 @@\n   private Map<Integer, Long> columnSizes = null;\n   private Map<Integer, Long> valueCounts = null;\n   private Map<Integer, Long> nullValueCounts = null;\n+  private Map<Integer, Long> nanValueCounts = null;\n   private Map<Integer, ByteBuffer> lowerBounds = null;\n   private Map<Integer, ByteBuffer> upperBounds = null;\n \n   public Metrics() {\n   }\n \n+  // for temporary backward compatibility, will be removed when all writers support nanValueCounts", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjU3ODYw", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521257860", "createdAt": "2020-11-01T20:25:15Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDoyNToxNVrOHrx2xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDoyNToxNVrOHrx2xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY2NzY1NA==", "bodyText": "For all float and double fields. Other entries should be omitted because they are 0.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515667654", "createdAt": "2020-11-01T20:25:15Z", "author": {"login": "rdblue"}, "path": "api/src/main/java/org/apache/iceberg/Metrics.java", "diffHunk": "@@ -103,6 +134,15 @@ public Long recordCount() {\n     return nullValueCounts;\n   }\n \n+  /**\n+   * Get the number of NaN values for all fields in a file.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjU4MDI1", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521258025", "createdAt": "2020-11-01T20:27:20Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDoyNzoyMFrOHrx3pA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDoyNzoyMFrOHrx3pA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY2Nzg3Ng==", "bodyText": "Rather than changing so many rows that call assertCounts, you may want to consider adding a second variant of the method that accepts the count. Then you'd only need to change the double and float cases.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515667876", "createdAt": "2020-11-01T20:27:20Z", "author": {"login": "rdblue"}, "path": "core/src/test/java/org/apache/iceberg/TestMetrics.java", "diffHunk": "@@ -257,31 +238,27 @@ public void testMetricsForDecimals() throws IOException {\n     record.setField(\"decimalAsInt64\", new BigDecimal(\"4.75\"));\n     record.setField(\"decimalAsFixed\", new BigDecimal(\"5.80\"));\n \n-    InputFile recordsFile = writeRecords(schema, record);\n-\n-    Metrics metrics = getMetrics(recordsFile);\n+    Metrics metrics = getMetrics(schema, record);\n     Assert.assertEquals(1L, (long) metrics.recordCount());\n-    assertCounts(1, 1L, 0L, metrics);\n+    assertCounts(1, 1L, 0L, 0L, metrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 178}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjU4OTk3", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521258997", "createdAt": "2020-11-01T20:38:59Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDozODo1OVrOHrx8mA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDozODo1OVrOHrx8mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY2OTE0NA==", "bodyText": "There are a few cases to consider with NaN values because comparison with NaN is always false.\nHere are a couple of implementations that have issues because they use comparison without checking for NaN:\n// max is NaN for values [NaN, 1.0, 1.1]\nFloat max = null;\nfor (value : values) {\n  if (max == null || max < value) {\n    max = value;\n  }\n}\n\n// max is NaN if any value is NaN\nFloat max = null;\nfor (value : values) {\n  max = (max != null && max >= value) ? max : value;\n}\nBecause the failure cases are different, I think we should test a few different cases:\n\nA column starts with NaN\nA column contains NaN in the middle\nA column ends with NaN", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515669144", "createdAt": "2020-11-01T20:38:59Z", "author": {"login": "rdblue"}, "path": "core/src/test/java/org/apache/iceberg/TestMetrics.java", "diffHunk": "@@ -352,14 +327,34 @@ public void testMetricsForNullColumns() throws IOException {\n     Record secondRecord = GenericRecord.create(schema);\n     secondRecord.setField(\"intCol\", null);\n \n-    InputFile recordsFile = writeRecords(schema, firstRecord, secondRecord);\n-\n-    Metrics metrics = getMetrics(recordsFile);\n+    Metrics metrics = getMetrics(schema, firstRecord, secondRecord);\n     Assert.assertEquals(2L, (long) metrics.recordCount());\n-    assertCounts(1, 2L, 2L, metrics);\n+    assertCounts(1, 2L, 2L, 0L, metrics);\n     assertBounds(1, IntegerType.get(), null, null, metrics);\n   }\n \n+  @Test\n+  public void testMetricsForNaNColumns() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 254}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjU5NDc5", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521259479", "createdAt": "2020-11-01T20:45:32Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDo0NTozMlrOHrx_Ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDo0NTozMlrOHrx_Ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY2OTgxOQ==", "bodyText": "Instead of passing the id, you can get it from the column descriptor:\nint id = desc.getPrimitiveType().getId().intValue();\nThat will remove a lot of changes from this file.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515669819", "createdAt": "2020-11-01T20:45:32Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/data/FlinkParquetWriters.java", "diffHunk": "@@ -167,70 +168,70 @@ private FlinkParquetWriters() {\n       switch (primitive.getPrimitiveTypeName()) {\n         case FIXED_LEN_BYTE_ARRAY:\n         case BINARY:\n-          return byteArrays(desc);\n+          return byteArrays(desc, id);\n         case BOOLEAN:\n-          return ParquetValueWriters.booleans(desc);\n+          return ParquetValueWriters.booleans(desc, id);\n         case INT32:\n-          return ints(fType, desc);\n+          return ints(fType, desc, id);\n         case INT64:\n-          return ParquetValueWriters.longs(desc);\n+          return ParquetValueWriters.longs(desc, id);\n         case FLOAT:\n-          return ParquetValueWriters.floats(desc);\n+          return ParquetValueWriters.floats(desc, id);\n         case DOUBLE:\n-          return ParquetValueWriters.doubles(desc);\n+          return ParquetValueWriters.doubles(desc, id);\n         default:\n           throw new UnsupportedOperationException(\"Unsupported type: \" + primitive);\n       }\n     }\n   }\n \n-  private static ParquetValueWriters.PrimitiveWriter<?> ints(LogicalType type, ColumnDescriptor desc) {\n+  private static ParquetValueWriters.PrimitiveWriter<?> ints(LogicalType type, ColumnDescriptor desc, Type.ID id) {\n     if (type instanceof TinyIntType) {\n-      return ParquetValueWriters.tinyints(desc);\n+      return ParquetValueWriters.tinyints(desc, id);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 82}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjYwMTM4", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521260138", "createdAt": "2020-11-01T20:54:05Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDo1NDowNVrOHryChg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDo1NDowNVrOHryChg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY3MDY2Mg==", "bodyText": "Alias isn't what you want to use here. An alias is the file schema's name when an Iceberg schema is converted from a file schema. Parquet and Avro don't allow special characters in field names, or a column's name may have changed after a file is written. In both cases, a file schema's names won't match the schema. The alias map exposes the original file field names for when we need to use them (e.g., get a page reader for a column from the file).\nIn this case, we want to use the table schema's name, not a file schema's name. That's why we use findColumnName above. That should work here as well.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515670662", "createdAt": "2020-11-01T20:54:05Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java", "diffHunk": "@@ -149,9 +149,25 @@ public static Metrics footerMetrics(ParquetMetadata metadata, MetricsConfig metr\n     }\n \n     return new Metrics(rowCount, columnSizes, valueCounts, nullValueCounts,\n+        getNanValueCounts(fieldMetrics, metricsConfig, inputSchema),\n         toBufferMap(fileSchema, lowerBounds), toBufferMap(fileSchema, upperBounds));\n   }\n \n+  private static Map<Integer, Long> getNanValueCounts(\n+      Stream<FieldMetrics> fieldMetrics, MetricsConfig metricsConfig, Schema inputSchema) {\n+    if (fieldMetrics == null || inputSchema == null) {\n+      return Maps.newHashMap();\n+    }\n+\n+    return fieldMetrics\n+        .filter(metrics -> {\n+          String alias = inputSchema.idToAlias(metrics.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjYwNTI3", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521260527", "createdAt": "2020-11-01T20:59:33Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDo1OTozM1rOHryE0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMDo1OTozM1rOHryE0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY3MTI1MA==", "bodyText": "Rather than passing incorrect metrics, I think it would be better to create a ParquetFieldMetrics class that throws exceptions when the other metrics are accessed. That will ensure that the other metrics values aren't used.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515671250", "createdAt": "2020-11-01T20:59:33Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -165,9 +178,65 @@ public void writeDouble(int repetitionLevel, double value) {\n     }\n   }\n \n+  private static class FloatWriter extends UnboxedWriter<Float> {\n+    private final ColumnDescriptor desc;\n+    private long nanCount;\n+\n+    private FloatWriter(ColumnDescriptor desc, Type.ID id) {\n+      super(desc, id);\n+      this.desc = desc;\n+      this.nanCount = 0;\n+    }\n+\n+    @Override\n+    public void write(int repetitionLevel, Float value) {\n+      super.write(repetitionLevel, value);\n+      if (Float.compare(Float.NaN, value) == 0) {\n+        nanCount++;\n+      }\n+    }\n+\n+    @Override\n+    public Stream<FieldMetrics> metrics() {\n+      if (id != null) {\n+        return Stream.of(new FieldMetrics(id.intValue(), 0L, 0L, nanCount, null, null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 157}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjYwNjUz", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521260653", "createdAt": "2020-11-01T21:00:41Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowMDo0MVrOHryFaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowMDo0MVrOHryFaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY3MTQwMQ==", "bodyText": "I think this should always produce the metric. Field IDs are required to write, so we are guaranteed that they are always present (or should fail if one is not). And as long as this is always gathering the metric, we may as well return it.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515671401", "createdAt": "2020-11-01T21:00:41Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -165,9 +178,65 @@ public void writeDouble(int repetitionLevel, double value) {\n     }\n   }\n \n+  private static class FloatWriter extends UnboxedWriter<Float> {\n+    private final ColumnDescriptor desc;\n+    private long nanCount;\n+\n+    private FloatWriter(ColumnDescriptor desc, Type.ID id) {\n+      super(desc, id);\n+      this.desc = desc;\n+      this.nanCount = 0;\n+    }\n+\n+    @Override\n+    public void write(int repetitionLevel, Float value) {\n+      super.write(repetitionLevel, value);\n+      if (Float.compare(Float.NaN, value) == 0) {\n+        nanCount++;\n+      }\n+    }\n+\n+    @Override\n+    public Stream<FieldMetrics> metrics() {\n+      if (id != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 156}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjYwNzA1", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521260705", "createdAt": "2020-11-01T21:01:15Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowMToxNVrOHryFqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowMToxNVrOHryFqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY3MTQ2Nw==", "bodyText": "The descriptor isn't used, so I don't think it is needed. This class should keep the int id only, I think.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515671467", "createdAt": "2020-11-01T21:01:15Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -165,9 +178,65 @@ public void writeDouble(int repetitionLevel, double value) {\n     }\n   }\n \n+  private static class FloatWriter extends UnboxedWriter<Float> {\n+    private final ColumnDescriptor desc;\n+    private long nanCount;\n+\n+    private FloatWriter(ColumnDescriptor desc, Type.ID id) {\n+      super(desc, id);\n+      this.desc = desc;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 142}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjYwOTA3", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521260907", "createdAt": "2020-11-01T21:03:51Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowMzo1MVrOHryGgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowMzo1MVrOHryGgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY3MTY4MA==", "bodyText": "This can call writeFloat directly instead of super.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515671680", "createdAt": "2020-11-01T21:03:51Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -165,9 +178,65 @@ public void writeDouble(int repetitionLevel, double value) {\n     }\n   }\n \n+  private static class FloatWriter extends UnboxedWriter<Float> {\n+    private final ColumnDescriptor desc;\n+    private long nanCount;\n+\n+    private FloatWriter(ColumnDescriptor desc, Type.ID id) {\n+      super(desc, id);\n+      this.desc = desc;\n+      this.nanCount = 0;\n+    }\n+\n+    @Override\n+    public void write(int repetitionLevel, Float value) {\n+      super.write(repetitionLevel, value);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 148}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjYxMzEx", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521261311", "createdAt": "2020-11-01T21:08:12Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowODoxMlrOHryIvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowODoxMlrOHryIvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY3MjI1NA==", "bodyText": "I would prefer to use float.isNaN() instead because it is more direct. The implementation of compare does a few comparisons because it needs to work for normal values, but Float.isNaN just returns value != value.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515672254", "createdAt": "2020-11-01T21:08:12Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -165,9 +178,65 @@ public void writeDouble(int repetitionLevel, double value) {\n     }\n   }\n \n+  private static class FloatWriter extends UnboxedWriter<Float> {\n+    private final ColumnDescriptor desc;\n+    private long nanCount;\n+\n+    private FloatWriter(ColumnDescriptor desc, Type.ID id) {\n+      super(desc, id);\n+      this.desc = desc;\n+      this.nanCount = 0;\n+    }\n+\n+    @Override\n+    public void write(int repetitionLevel, Float value) {\n+      super.write(repetitionLevel, value);\n+      if (Float.compare(Float.NaN, value) == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 149}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjYxMzQ0", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521261344", "createdAt": "2020-11-01T21:08:30Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowODozMFrOHryI5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowODozMFrOHryI5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY3MjI5Mg==", "bodyText": "Same comments from the float case above.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515672292", "createdAt": "2020-11-01T21:08:30Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -165,9 +178,65 @@ public void writeDouble(int repetitionLevel, double value) {\n     }\n   }\n \n+  private static class FloatWriter extends UnboxedWriter<Float> {\n+    private final ColumnDescriptor desc;\n+    private long nanCount;\n+\n+    private FloatWriter(ColumnDescriptor desc, Type.ID id) {\n+      super(desc, id);\n+      this.desc = desc;\n+      this.nanCount = 0;\n+    }\n+\n+    @Override\n+    public void write(int repetitionLevel, Float value) {\n+      super.write(repetitionLevel, value);\n+      if (Float.compare(Float.NaN, value) == 0) {\n+        nanCount++;\n+      }\n+    }\n+\n+    @Override\n+    public Stream<FieldMetrics> metrics() {\n+      if (id != null) {\n+        return Stream.of(new FieldMetrics(id.intValue(), 0L, 0L, nanCount, null, null));\n+      } else {\n+        return Stream.empty();\n+      }\n+    }\n+  }\n+\n+  private static class DoubleWriter extends UnboxedWriter<Double> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 164}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjYxNDMz", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521261433", "createdAt": "2020-11-01T21:09:41Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowOTo0MVrOHryJYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMTowOTo0MVrOHryJYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY3MjQxOQ==", "bodyText": "Why not Stream.of(keyWriter.metrics(), valueWriter.metrics())? That seems easier than creating a stream only to create another stream.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515672419", "createdAt": "2020-11-01T21:09:41Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -435,6 +514,11 @@ public void setColumnStore(ColumnWriteStore columnStore) {\n     }\n \n     protected abstract Iterator<Map.Entry<K, V>> pairs(M value);\n+\n+    @Override\n+    public Stream<FieldMetrics> metrics() {\n+      return Stream.of(keyWriter, valueWriter).flatMap(ParquetValueWriter::metrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 297}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMjYxNDY0", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-521261464", "createdAt": "2020-11-01T21:10:11Z", "commit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMToxMDoxMVrOHryJog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMVQyMToxMDoxMVrOHryJog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY3MjQ4Mg==", "bodyText": "+1", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r515672482", "createdAt": "2020-11-01T21:10:11Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetWriteAdapter.java", "diffHunk": "@@ -29,6 +30,12 @@\n import org.apache.parquet.hadoop.ParquetWriter;\n import org.apache.parquet.hadoop.metadata.ParquetMetadata;\n \n+/**\n+ * Parquet writer that wraps around hadoop's {@link ParquetWriter}.\n+ * It shouldn't be used in production; {@link org.apache.iceberg.parquet.ParquetWriter} is a better alternative.\n+ * @deprecated use {@link org.apache.iceberg.parquet.ParquetWriter}\n+ */\n+@Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a128ae00949320577a279bb44d1245db5538db51"}, "originalPosition": 17}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8d6c014e38efca97ef038c02564db826c8ce88ee", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/8d6c014e38efca97ef038c02564db826c8ce88ee", "committedDate": "2020-11-03T01:33:28Z", "message": "update based on comments"}, "afterCommit": {"oid": "472c16dea561b5b42c17286d80697ef4c1afd3f5", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/472c16dea561b5b42c17286d80697ef4c1afd3f5", "committedDate": "2020-11-03T01:54:35Z", "message": "update based on comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIzNjI1Mzk2", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-523625396", "createdAt": "2020-11-04T18:25:00Z", "commit": {"oid": "7c4853dd8a4138a0a5c9cde3732ff1ce714f5c95"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxODoyNTowMFrOHtkdKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxODoyNTowMFrOHtkdKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzU0NTI1OQ==", "bodyText": "nit: start a sentence on a new line", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r517545259", "createdAt": "2020-11-04T18:25:00Z", "author": {"login": "jackye1995"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetFieldMetrics.java", "diffHunk": "@@ -23,32 +23,44 @@\n import org.apache.iceberg.FieldMetrics;\n \n /**\n- * TODO comments\n+ * Iceberg internally tracked field level metrics, used by Parquet writer only.\n+ * Parquet keeps track of most metrics in its footer, and only NaN counter is actually tracked by writers. This", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c4853dd8a4138a0a5c9cde3732ff1ce714f5c95"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIzNjU0Mzc3", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-523654377", "createdAt": "2020-11-04T19:04:29Z", "commit": {"oid": "7ca9dee78b71436e77d92db0bf91de558edc05ad"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxOTowNDoyOVrOHtl09g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxOTowNDoyOVrOHtl09g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzU2NzczNA==", "bodyText": "why is this suppressed?", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r517567734", "createdAt": "2020-11-04T19:04:29Z", "author": {"login": "jackye1995"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriters.java", "diffHunk": "@@ -113,8 +115,8 @@ private ParquetValueWriters() {\n     return new MapWriter<>(dl, rl, keyWriter, valueWriter);\n   }\n \n+  @SuppressWarnings(\"checkstyle:VisibilityModifier\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ca9dee78b71436e77d92db0bf91de558edc05ad"}, "originalPosition": 28}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIzNzU5Njc0", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-523759674", "createdAt": "2020-11-04T21:48:17Z", "commit": {"oid": "7ca9dee78b71436e77d92db0bf91de558edc05ad"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQyMTo0ODoxOFrOHtq4Zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQyMTo0ODoxOFrOHtq4Zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzY1MDUzNA==", "bodyText": "Javadoc needs a <p> on the empty line above if you want to start a new paragraph.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r517650534", "createdAt": "2020-11-04T21:48:18Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -305,6 +306,9 @@ private SparkTableUtil() {\n    * For Parquet and ORC partitions, this will read metrics from the file footer. For Avro partitions,\n    * metrics are set to null.\n    *\n+   * Note: certain metrics, like NaN counts, that are only supported by iceberg file writers but not file footers, will", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ca9dee78b71436e77d92db0bf91de558edc05ad"}, "originalPosition": 12}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "75efe71b804150cd15342b29381e6d0c5e1cb442", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/75efe71b804150cd15342b29381e6d0c5e1cb442", "committedDate": "2020-11-05T00:31:24Z", "message": "make StructInternalRow null safe"}, "afterCommit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/b0e3e45395e0f995e66fa3915ebd7c57f889f78d", "committedDate": "2020-11-05T01:13:01Z", "message": "make StructInternalRow null safe"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NTQxNTk3", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-528541597", "createdAt": "2020-11-11T21:18:23Z", "commit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToxODoyM1rOHxepDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToxODoyM1rOHxepDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0NDMwMA==", "bodyText": "You can also make these records static variables. That might reduce the size of these test cases.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r521644300", "createdAt": "2020-11-11T21:18:23Z", "author": {"login": "rdblue"}, "path": "core/src/test/java/org/apache/iceberg/TestMetrics.java", "diffHunk": "@@ -347,14 +327,120 @@ public void testMetricsForNullColumns() throws IOException {\n     Record secondRecord = GenericRecord.create(schema);\n     secondRecord.setField(\"intCol\", null);\n \n-    InputFile recordsFile = writeRecords(schema, firstRecord, secondRecord);\n-\n-    Metrics metrics = getMetrics(recordsFile);\n+    Metrics metrics = getMetrics(schema, firstRecord, secondRecord);\n     Assert.assertEquals(2L, (long) metrics.recordCount());\n     assertCounts(1, 2L, 2L, metrics);\n     assertBounds(1, IntegerType.get(), null, null, metrics);\n   }\n \n+  @Test\n+  public void testMetricsForNaNColumns() throws IOException {\n+    Record firstRecord = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    firstRecord.setField(\"floatCol\", Float.NaN);\n+    firstRecord.setField(\"doubleCol\", Double.NaN);\n+    Record secondRecord = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    secondRecord.setField(\"floatCol\", Float.NaN);\n+    secondRecord.setField(\"doubleCol\", Double.NaN);\n+\n+    Metrics metrics = getMetrics(FLOAT_DOUBLE_ONLY_SCHEMA, firstRecord, secondRecord);\n+    Assert.assertEquals(2L, (long) metrics.recordCount());\n+    assertCounts(1, 2L, 0L, 2L, metrics);\n+    assertCounts(2, 2L, 0L, 2L, metrics);\n+    // below: current behavior; will be null once NaN is excluded from upper/lower bound\n+    assertBounds(1, FloatType.get(), Float.NaN, Float.NaN, metrics);\n+    assertBounds(2, DoubleType.get(), Double.NaN, Double.NaN, metrics);\n+  }\n+\n+  @Test\n+  public void testColumnBoundsWithNaNValueAtFront() throws IOException {\n+    Record nonNaNRecord1 = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nonNaNRecord1.setField(\"floatCol\", 1.2F);\n+    nonNaNRecord1.setField(\"doubleCol\", 3.4D);\n+\n+    Record nonNaNRecord2 = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nonNaNRecord2.setField(\"floatCol\", 5.6F);\n+    nonNaNRecord2.setField(\"doubleCol\", 7.8D);\n+\n+    Record nanRecord = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nanRecord.setField(\"floatCol\", Float.NaN);\n+    nanRecord.setField(\"doubleCol\", Double.NaN);\n+\n+    Metrics metrics = getMetrics(FLOAT_DOUBLE_ONLY_SCHEMA, nanRecord, nonNaNRecord1, nonNaNRecord2);\n+    Assert.assertEquals(3L, (long) metrics.recordCount());\n+    assertCounts(1, 3L, 0L, 1L, metrics);\n+    assertCounts(2, 3L, 0L, 1L, metrics);\n+\n+    // below: current behavior; will be non-NaN values once NaN is excluded from upper/lower bound. ORC and Parquet's\n+    // behaviors differ due to their implementation of comparison being different.\n+    if (fileFormat() == FileFormat.ORC) {\n+      assertBounds(1, FloatType.get(), Float.NaN, Float.NaN, metrics);\n+      assertBounds(2, DoubleType.get(), Double.NaN, Double.NaN, metrics);\n+    } else {\n+      assertBounds(1, FloatType.get(), 1.2F, Float.NaN, metrics);\n+      assertBounds(2, DoubleType.get(), 3.4D, Double.NaN, metrics);\n+    }\n+  }\n+\n+  @Test\n+  public void testColumnBoundsWithNaNValueInMiddle() throws IOException {\n+    Record nonNaNRecord1 = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nonNaNRecord1.setField(\"floatCol\", 1.2F);\n+    nonNaNRecord1.setField(\"doubleCol\", 3.4D);\n+\n+    Record nonNaNRecord2 = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nonNaNRecord2.setField(\"floatCol\", 5.6F);\n+    nonNaNRecord2.setField(\"doubleCol\", 7.8D);\n+\n+    Record nanRecord = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nanRecord.setField(\"floatCol\", Float.NaN);\n+    nanRecord.setField(\"doubleCol\", Double.NaN);\n+\n+    Metrics metrics = getMetrics(FLOAT_DOUBLE_ONLY_SCHEMA, nonNaNRecord1, nanRecord, nonNaNRecord2);\n+    Assert.assertEquals(3L, (long) metrics.recordCount());\n+    assertCounts(1, 3L, 0L, 1L, metrics);\n+    assertCounts(2, 3L, 0L, 1L, metrics);\n+\n+    // below: current behavior; will be non-NaN values once NaN is excluded from upper/lower bound. ORC and Parquet's\n+    // behaviors differ due to their implementation of comparison being different.\n+    if (fileFormat() == FileFormat.ORC) {\n+      assertBounds(1, FloatType.get(), 1.2F, 5.6F, metrics);\n+      assertBounds(2, DoubleType.get(), 3.4D, 7.8D, metrics);\n+    } else {\n+      assertBounds(1, FloatType.get(), 1.2F, Float.NaN, metrics);\n+      assertBounds(2, DoubleType.get(), 3.4D, Double.NaN, metrics);\n+    }\n+  }\n+\n+  @Test\n+  public void testColumnBoundsWithNaNValueAtEnd() throws IOException {\n+    Record nonNaNRecord1 = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nonNaNRecord1.setField(\"floatCol\", 1.2F);\n+    nonNaNRecord1.setField(\"doubleCol\", 3.4D);\n+\n+    Record nonNaNRecord2 = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nonNaNRecord2.setField(\"floatCol\", 5.6F);\n+    nonNaNRecord2.setField(\"doubleCol\", 7.8D);\n+\n+    Record nanRecord = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nanRecord.setField(\"floatCol\", Float.NaN);\n+    nanRecord.setField(\"doubleCol\", Double.NaN);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "originalPosition": 264}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NTQyMzY0", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-528542364", "createdAt": "2020-11-11T21:19:38Z", "commit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToxOTozOFrOHxerXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToxOTozOFrOHxerXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0NDg5Mw==", "bodyText": "This refactor seems to have introduced a lot of changes. Is it needed? Seems like it may just introduce conflicts.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r521644893", "createdAt": "2020-11-11T21:19:38Z", "author": {"login": "rdblue"}, "path": "core/src/test/java/org/apache/iceberg/TestMetrics.java", "diffHunk": "@@ -96,67 +97,54 @@\n       required(13, \"timestampColBelowEpoch\", TimestampType.withoutZone())\n   );\n \n+  private static final Schema FLOAT_DOUBLE_ONLY_SCHEMA = new Schema(\n+      optional(1, \"floatCol\", FloatType.get()),\n+      optional(2, \"doubleCol\", DoubleType.get())\n+  );\n+\n   private final byte[] fixed = \"abcd\".getBytes(StandardCharsets.UTF_8);\n \n   public abstract FileFormat fileFormat();\n \n-  public Metrics getMetrics(InputFile file) {\n-    return getMetrics(file, MetricsConfig.getDefault());\n-  }\n-\n-  public abstract Metrics getMetrics(InputFile file, MetricsConfig metricsConfig);\n+  public abstract Metrics getMetrics(Schema schema, MetricsConfig metricsConfig, Record... records) throws IOException;\n \n-  public abstract InputFile writeRecords(Schema schema, Record... records) throws IOException;\n+  public abstract Metrics getMetrics(Schema schema, Record... records) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NTQyNDk2", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-528542496", "createdAt": "2020-11-11T21:19:51Z", "commit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToxOTo1MVrOHxeryg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToxOTo1MVrOHxeryg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0NTAwMg==", "bodyText": "What about createOutputFile?", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r521645002", "createdAt": "2020-11-11T21:19:51Z", "author": {"login": "rdblue"}, "path": "core/src/test/java/org/apache/iceberg/TestMetrics.java", "diffHunk": "@@ -96,67 +97,54 @@\n       required(13, \"timestampColBelowEpoch\", TimestampType.withoutZone())\n   );\n \n+  private static final Schema FLOAT_DOUBLE_ONLY_SCHEMA = new Schema(\n+      optional(1, \"floatCol\", FloatType.get()),\n+      optional(2, \"doubleCol\", DoubleType.get())\n+  );\n+\n   private final byte[] fixed = \"abcd\".getBytes(StandardCharsets.UTF_8);\n \n   public abstract FileFormat fileFormat();\n \n-  public Metrics getMetrics(InputFile file) {\n-    return getMetrics(file, MetricsConfig.getDefault());\n-  }\n-\n-  public abstract Metrics getMetrics(InputFile file, MetricsConfig metricsConfig);\n+  public abstract Metrics getMetrics(Schema schema, MetricsConfig metricsConfig, Record... records) throws IOException;\n \n-  public abstract InputFile writeRecords(Schema schema, Record... records) throws IOException;\n+  public abstract Metrics getMetrics(Schema schema, Record... records) throws IOException;\n \n-  public abstract InputFile writeRecordsWithSmallRowGroups(Schema schema, Record... records)\n-      throws IOException;\n+  protected abstract Metrics getMetricsForRecordsWithSmallRowGroups(Schema schema, OutputFile outputFile,\n+                                                                    Record... records) throws IOException;\n \n   public abstract int splitCount(InputFile inputFile) throws IOException;\n \n   public boolean supportsSmallRowGroups() {\n     return false;\n   }\n \n+  protected abstract OutputFile createFileToWriteTo() throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NTQ0OTc4", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-528544978", "createdAt": "2020-11-11T21:23:57Z", "commit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToyMzo1N1rOHxezKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToyMzo1N1rOHxezKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0Njg5MA==", "bodyText": "Could you avoid using equals? Primitive NaN is not equal to itself, so it's strange to see this here. What about casting and using Double.isNaN?", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r521646890", "createdAt": "2020-11-11T21:23:57Z", "author": {"login": "rdblue"}, "path": "data/src/test/java/org/apache/iceberg/TestMergingMetrics.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.RandomGenericData;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class TestMergingMetrics<T> {\n+\n+  // all supported fields, except for UUID which is on deprecation path: see https://github.com/apache/iceberg/pull/1611\n+  // as well as Types.TimeType and Types.TimestampType.withoutZone as both are not supported by Spark\n+  protected static final Types.NestedField ID_FIELD = required(1, \"id\", Types.IntegerType.get());\n+  protected static final Types.NestedField DATA_FIELD = optional(2, \"data\", Types.StringType.get());\n+  protected static final Types.NestedField FLOAT_FIELD = required(3, \"float\", Types.FloatType.get());\n+  protected static final Types.NestedField DOUBLE_FIELD = optional(4, \"double\", Types.DoubleType.get());\n+  protected static final Types.NestedField DECIMAL_FIELD = optional(5, \"decimal\", Types.DecimalType.of(5, 3));\n+  protected static final Types.NestedField FIXED_FIELD = optional(7, \"fixed\", Types.FixedType.ofLength(4));\n+  protected static final Types.NestedField BINARY_FIELD = optional(8, \"binary\", Types.BinaryType.get());\n+  protected static final Types.NestedField FLOAT_LIST = optional(9, \"floatlist\",\n+      Types.ListType.ofRequired(10, Types.FloatType.get()));\n+  protected static final Types.NestedField LONG_FIELD = optional(11, \"long\", Types.LongType.get());\n+\n+  protected static final Types.NestedField MAP_FIELD_1 = optional(17, \"map1\",\n+      Types.MapType.ofOptional(18, 19, Types.FloatType.get(), Types.StringType.get())\n+  );\n+  protected static final Types.NestedField MAP_FIELD_2 = optional(20, \"map2\",\n+      Types.MapType.ofOptional(21, 22, Types.IntegerType.get(), Types.DoubleType.get())\n+  );\n+  protected static final Types.NestedField STRUCT_FIELD = optional(23, \"structField\", Types.StructType.of(\n+      required(24, \"booleanField\", Types.BooleanType.get()),\n+      optional(25, \"date\", Types.DateType.get()),\n+      optional(27, \"timestamp\", Types.TimestampType.withZone())\n+  ));\n+\n+  private static final Map<Types.NestedField, Integer> FIELDS_WITH_NAN_COUNT_TO_ID = ImmutableMap.of(\n+      FLOAT_FIELD, 3, DOUBLE_FIELD, 4, FLOAT_LIST, 10, MAP_FIELD_1, 18, MAP_FIELD_2, 22\n+  );\n+\n+  // create a schema with all supported fields\n+  protected static final Schema SCHEMA = new Schema(\n+      ID_FIELD,\n+      DATA_FIELD,\n+      FLOAT_FIELD,\n+      DOUBLE_FIELD,\n+      DECIMAL_FIELD,\n+      FIXED_FIELD,\n+      BINARY_FIELD,\n+      FLOAT_LIST,\n+      LONG_FIELD,\n+      MAP_FIELD_1,\n+      MAP_FIELD_2,\n+      STRUCT_FIELD\n+  );\n+\n+  protected abstract FileAppender<T> writeAndGetAppender(List<Record> records) throws Exception;\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  @Test\n+  public void verifySingleRecordMetric() throws Exception {\n+    Record record = GenericRecord.create(SCHEMA);\n+    record.setField(\"id\", 3);\n+    record.setField(\"float\", Float.NaN); // FLOAT_FIELD - 1\n+    record.setField(\"double\", Double.NaN); // DOUBLE_FIELD - 1\n+    record.setField(\"floatlist\", ImmutableList.of(3.3F, 2.8F, Float.NaN, -25.1F, Float.NaN)); // FLOAT_LIST - 2\n+    record.setField(\"map1\", ImmutableMap.of(Float.NaN, \"a\", 0F, \"b\")); // MAP_FIELD_1 - 1\n+    record.setField(\"map2\", ImmutableMap.of(\n+        0, 0D, 1, Double.NaN, 2, 2D, 3, Double.NaN, 4, Double.NaN)); // MAP_FIELD_2 - 3\n+\n+    FileAppender<T> appender = writeAndGetAppender(ImmutableList.of(record));\n+    Map<Integer, Long> nanValueCount = appender.metrics().nanValueCounts();\n+\n+    assertNaNCountMatch(1L, nanValueCount, FLOAT_FIELD);\n+    assertNaNCountMatch(1L, nanValueCount, DOUBLE_FIELD);\n+    assertNaNCountMatch(2L, nanValueCount, FLOAT_LIST);\n+    assertNaNCountMatch(1L, nanValueCount, MAP_FIELD_1);\n+    assertNaNCountMatch(3L, nanValueCount, MAP_FIELD_2);\n+  }\n+\n+  private void assertNaNCountMatch(Long expected, Map<Integer, Long> nanValueCount, Types.NestedField field) {\n+    Assert.assertEquals(\n+        String.format(\"NaN count for field %s does not match expected\", field.name()),\n+        expected, nanValueCount.get(FIELDS_WITH_NAN_COUNT_TO_ID.get(field)));\n+  }\n+\n+  @Test\n+  public void verifyRandomlyGeneratedRecordsMetric() throws Exception {\n+    List<Record> recordList = RandomGenericData.generate(SCHEMA, 50, 250L);\n+\n+    FileAppender<T> appender = writeAndGetAppender(recordList);\n+    Map<Integer, Long> nanValueCount = appender.metrics().nanValueCounts();\n+\n+    FIELDS_WITH_NAN_COUNT_TO_ID.forEach((key, value) -> Assert.assertEquals(\n+        String.format(\"NaN count for field %s does not match expected\", key.name()),\n+        getExpectedNaNCount(recordList, key),\n+        nanValueCount.get(value)));\n+\n+    SCHEMA.columns().stream()\n+        .filter(column -> !FIELDS_WITH_NAN_COUNT_TO_ID.containsKey(column))\n+        .map(Types.NestedField::fieldId)\n+        .forEach(id -> Assert.assertNull(\"NaN count for field %s should be null\", nanValueCount.get(id)));\n+  }\n+\n+  private Long getExpectedNaNCount(List<Record> expectedRecords, Types.NestedField field) {\n+    return expectedRecords.stream()\n+        .mapToLong(e -> {\n+          Object value = e.getField(field.name());\n+          if (value == null) {\n+            return 0;\n+          }\n+          if (FLOAT_FIELD.equals(field)) {\n+            return value.equals(Float.NaN) ? 1 : 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "originalPosition": 144}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NTQ3Mzk3", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-528547397", "createdAt": "2020-11-11T21:28:03Z", "commit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToyODowM1rOHxe6-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToyODowM1rOHxe6-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0ODg5MQ==", "bodyText": "Javadoc paragraphs need to be separated by <p> to display correctly.", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r521648891", "createdAt": "2020-11-11T21:28:03Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueWriter.java", "diffHunk": "@@ -28,4 +30,16 @@\n   List<TripleWriter<?>> columns();\n \n   void setColumnStore(ColumnWriteStore columnStore);\n+\n+  /**\n+   * Returns a stream of {@link FieldMetrics} that this ParquetValueWriter keeps track of.\n+   *", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NTYxMzE5", "url": "https://github.com/apache/iceberg/pull/1641#pullrequestreview-528561319", "createdAt": "2020-11-11T21:51:39Z", "commit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMTo1MTozOVrOHxfnew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMTo1MTozOVrOHxfnew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY2MDI4Mw==", "bodyText": "NaN as an upper bound should be safe, but NaN as a lower bound may not be. Does this mean we need to fix our evaluators to check for NaN?", "url": "https://github.com/apache/iceberg/pull/1641#discussion_r521660283", "createdAt": "2020-11-11T21:51:39Z", "author": {"login": "rdblue"}, "path": "core/src/test/java/org/apache/iceberg/TestMetrics.java", "diffHunk": "@@ -347,14 +327,120 @@ public void testMetricsForNullColumns() throws IOException {\n     Record secondRecord = GenericRecord.create(schema);\n     secondRecord.setField(\"intCol\", null);\n \n-    InputFile recordsFile = writeRecords(schema, firstRecord, secondRecord);\n-\n-    Metrics metrics = getMetrics(recordsFile);\n+    Metrics metrics = getMetrics(schema, firstRecord, secondRecord);\n     Assert.assertEquals(2L, (long) metrics.recordCount());\n     assertCounts(1, 2L, 2L, metrics);\n     assertBounds(1, IntegerType.get(), null, null, metrics);\n   }\n \n+  @Test\n+  public void testMetricsForNaNColumns() throws IOException {\n+    Record firstRecord = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    firstRecord.setField(\"floatCol\", Float.NaN);\n+    firstRecord.setField(\"doubleCol\", Double.NaN);\n+    Record secondRecord = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    secondRecord.setField(\"floatCol\", Float.NaN);\n+    secondRecord.setField(\"doubleCol\", Double.NaN);\n+\n+    Metrics metrics = getMetrics(FLOAT_DOUBLE_ONLY_SCHEMA, firstRecord, secondRecord);\n+    Assert.assertEquals(2L, (long) metrics.recordCount());\n+    assertCounts(1, 2L, 0L, 2L, metrics);\n+    assertCounts(2, 2L, 0L, 2L, metrics);\n+    // below: current behavior; will be null once NaN is excluded from upper/lower bound\n+    assertBounds(1, FloatType.get(), Float.NaN, Float.NaN, metrics);\n+    assertBounds(2, DoubleType.get(), Double.NaN, Double.NaN, metrics);\n+  }\n+\n+  @Test\n+  public void testColumnBoundsWithNaNValueAtFront() throws IOException {\n+    Record nonNaNRecord1 = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nonNaNRecord1.setField(\"floatCol\", 1.2F);\n+    nonNaNRecord1.setField(\"doubleCol\", 3.4D);\n+\n+    Record nonNaNRecord2 = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nonNaNRecord2.setField(\"floatCol\", 5.6F);\n+    nonNaNRecord2.setField(\"doubleCol\", 7.8D);\n+\n+    Record nanRecord = GenericRecord.create(FLOAT_DOUBLE_ONLY_SCHEMA);\n+    nanRecord.setField(\"floatCol\", Float.NaN);\n+    nanRecord.setField(\"doubleCol\", Double.NaN);\n+\n+    Metrics metrics = getMetrics(FLOAT_DOUBLE_ONLY_SCHEMA, nanRecord, nonNaNRecord1, nonNaNRecord2);\n+    Assert.assertEquals(3L, (long) metrics.recordCount());\n+    assertCounts(1, 3L, 0L, 1L, metrics);\n+    assertCounts(2, 3L, 0L, 1L, metrics);\n+\n+    // below: current behavior; will be non-NaN values once NaN is excluded from upper/lower bound. ORC and Parquet's\n+    // behaviors differ due to their implementation of comparison being different.\n+    if (fileFormat() == FileFormat.ORC) {\n+      assertBounds(1, FloatType.get(), Float.NaN, Float.NaN, metrics);\n+      assertBounds(2, DoubleType.get(), Double.NaN, Double.NaN, metrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d"}, "originalPosition": 215}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0aebbcd708832149b5b7b66b3481c7a8c267ff98", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/0aebbcd708832149b5b7b66b3481c7a8c267ff98", "committedDate": "2020-11-12T00:37:57Z", "message": "Add NaN counter to Metrics and implement in Parquet writers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1db924c1e080b192be084730758c844af3bdfc4", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/a1db924c1e080b192be084730758c844af3bdfc4", "committedDate": "2020-11-12T00:37:57Z", "message": "update tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f7e4c7a568ab63bcf22d01470af84c232eed397", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/1f7e4c7a568ab63bcf22d01470af84c232eed397", "committedDate": "2020-11-12T00:37:57Z", "message": "add flink and spark tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ddd25d6b83c47004bed3552bb091150b0af86af", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/8ddd25d6b83c47004bed3552bb091150b0af86af", "committedDate": "2020-11-12T00:37:57Z", "message": "update based on comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "10220065611ca4486ff7aa7a38c3ccc10e8298e9", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/10220065611ca4486ff7aa7a38c3ccc10e8298e9", "committedDate": "2020-11-12T00:37:57Z", "message": "update some comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45474d75452aa48bf519bb8545337e3c81a925f7", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/45474d75452aa48bf519bb8545337e3c81a925f7", "committedDate": "2020-11-12T00:37:57Z", "message": "clean up tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a16a59d0ff427e99e0bc77c1c70e97f0ea1ca0f", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/2a16a59d0ff427e99e0bc77c1c70e97f0ea1ca0f", "committedDate": "2020-11-12T00:37:57Z", "message": "fix style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "654021300393b5b3587aa127a92611b3812df0f0", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/654021300393b5b3587aa127a92611b3812df0f0", "committedDate": "2020-11-12T00:37:57Z", "message": "make StructInternalRow null safe"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8b0b3206d085c1b4f1adfb0ba9ae220c22be52c", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/e8b0b3206d085c1b4f1adfb0ba9ae220c22be52c", "committedDate": "2020-11-12T01:11:54Z", "message": "update based on comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b0e3e45395e0f995e66fa3915ebd7c57f889f78d", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/b0e3e45395e0f995e66fa3915ebd7c57f889f78d", "committedDate": "2020-11-05T01:13:01Z", "message": "make StructInternalRow null safe"}, "afterCommit": {"oid": "e8b0b3206d085c1b4f1adfb0ba9ae220c22be52c", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/e8b0b3206d085c1b4f1adfb0ba9ae220c22be52c", "committedDate": "2020-11-12T01:11:54Z", "message": "update based on comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4010, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}