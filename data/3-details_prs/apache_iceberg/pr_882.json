{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk1Nzk4MTcw", "number": 882, "title": "fix: Failed to get status issue because of s3 eventual consistency", "bodyText": "fix for: #881\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file.", "createdAt": "2020-03-30T17:39:40Z", "url": "https://github.com/apache/iceberg/pull/882", "merged": true, "mergeCommit": {"oid": "d106fcfe5d71a724f71a0845cefe0a08fd3bba7f"}, "closed": true, "closedAt": "2020-04-02T23:56:38Z", "author": {"login": "sudssf"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcS5nZCABqjMxODEyNDY2NDU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcTguq_gBqjMxOTAwODI3NDM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a1ffcdbb9c8770dc1586c9a95ad7c46ed1e250c2", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/a1ffcdbb9c8770dc1586c9a95ad7c46ed1e250c2", "committedDate": "2020-03-30T17:36:06Z", "message": "fix: Failed to get status issue because of s3 eventual consistency\n\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\n\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file."}, "afterCommit": {"oid": "20b1ab45ce803f814be23667625b9414b0b7209d", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/20b1ab45ce803f814be23667625b9414b0b7209d", "committedDate": "2020-03-31T02:24:04Z", "message": "fix: Failed to get status issue because of s3 eventual consistency\n\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\n\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "20b1ab45ce803f814be23667625b9414b0b7209d", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/20b1ab45ce803f814be23667625b9414b0b7209d", "committedDate": "2020-03-31T02:24:04Z", "message": "fix: Failed to get status issue because of s3 eventual consistency\n\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\n\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file."}, "afterCommit": {"oid": "7916d8fb9b9a421f597a6b95526ad1642ac542ab", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/7916d8fb9b9a421f597a6b95526ad1642ac542ab", "committedDate": "2020-03-31T17:47:09Z", "message": "fix: Failed to get status issue because of s3 eventual consistency\n\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\n\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file when configured.\n\nadded new datasource option \"use-writer-length-as-file-size\" to control behaviour."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1ODAyMTMz", "url": "https://github.com/apache/iceberg/pull/882#pullrequestreview-385802133", "createdAt": "2020-04-01T17:32:39Z", "commit": {"oid": "7916d8fb9b9a421f597a6b95526ad1642ac542ab"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxNzozMjozOVrOF_LQdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxNzozMjozOVrOF_LQdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc4OTA0NQ==", "bodyText": "@rdblue additional 103 in writer length, can this be bug in writer factory which returns buffer size after flush?\n( no rush of merging this PR , I am trying to make sure changes are ok)", "url": "https://github.com/apache/iceberg/pull/882#discussion_r401789045", "createdAt": "2020-04-01T17:32:39Z", "author": {"login": "sudssf"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestDataSourceOptions.java", "diffHunk": "@@ -201,6 +201,36 @@ public void testSplitOptionsOverridesTableProperties() throws IOException {\n     Assert.assertEquals(\"Spark partitions should match\", 2, resultDf.javaRDD().getNumPartitions());\n   }\n \n+  @Test\n+  public void testSplitOptionsOverridesTablePropertiesWithWriterLength() throws IOException {\n+    String tableLocation = temp.newFolder(\"iceberg-table\").toString();\n+\n+    HadoopTables tables = new HadoopTables(CONF);\n+    PartitionSpec spec = PartitionSpec.unpartitioned();\n+    Map<String, String> options = Maps.newHashMap();\n+    options.put(TableProperties.SPLIT_SIZE, String.valueOf(128L * 1024 * 1024)); // 128Mb\n+    tables.create(SCHEMA, spec, options, tableLocation);\n+\n+    List<SimpleRecord> expectedRecords = Lists.newArrayList(\n+        new SimpleRecord(1, \"a\"),\n+        new SimpleRecord(2, \"b\")\n+    );\n+    Dataset<Row> originalDf = spark.createDataFrame(expectedRecords, SimpleRecord.class);\n+    originalDf.select(\"id\", \"data\").write()\n+        .format(\"iceberg\")\n+        .mode(\"append\")\n+        .option(\"use-writer-length-as-file-size\", true)\n+        .save(tableLocation);\n+\n+    Dataset<Row> resultDf = spark.read()\n+        .format(\"iceberg\")\n+        .option(\"split-size\", String.valueOf(611 + 103)) // 611 bytes is the size of SimpleRecord(1,\"a\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7916d8fb9b9a421f597a6b95526ad1642ac542ab"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1ODQwNTA0", "url": "https://github.com/apache/iceberg/pull/882#pullrequestreview-385840504", "createdAt": "2020-04-01T18:25:28Z", "commit": {"oid": "7916d8fb9b9a421f597a6b95526ad1642ac542ab"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxODoyNToyOVrOF_NK6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxODoyNToyOVrOF_NK6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgyMDM5NA==", "bodyText": "This shouldn't be a new option. Let's remove it.", "url": "https://github.com/apache/iceberg/pull/882#discussion_r401820394", "createdAt": "2020-04-01T18:25:29Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/Writer.java", "diffHunk": "@@ -114,6 +115,7 @@\n     long tableTargetFileSize = PropertyUtil.propertyAsLong(\n         table.properties(), WRITE_TARGET_FILE_SIZE_BYTES, WRITE_TARGET_FILE_SIZE_BYTES_DEFAULT);\n     this.targetFileSize = options.getLong(\"target-file-size-bytes\", tableTargetFileSize);\n+    this.useWriterLengthAsFileSize = options.getBoolean(\"use-writer-length-as-file-size\", false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7916d8fb9b9a421f597a6b95526ad1642ac542ab"}, "originalPosition": 12}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7916d8fb9b9a421f597a6b95526ad1642ac542ab", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/7916d8fb9b9a421f597a6b95526ad1642ac542ab", "committedDate": "2020-03-31T17:47:09Z", "message": "fix: Failed to get status issue because of s3 eventual consistency\n\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\n\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file when configured.\n\nadded new datasource option \"use-writer-length-as-file-size\" to control behaviour."}, "afterCommit": {"oid": "3c5e52e53cd4a87a5c7b637e4a7ab2e9a58df466", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/3c5e52e53cd4a87a5c7b637e4a7ab2e9a58df466", "committedDate": "2020-04-01T23:56:30Z", "message": "fix: Failed to get status issue because of s3 eventual consistency\n\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\n\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "69de3f2fe3e5b871e42d13a5fece4e713f3b2e06", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/69de3f2fe3e5b871e42d13a5fece4e713f3b2e06", "committedDate": "2020-04-01T23:58:26Z", "message": "fix: Failed to get status issue because of s3 eventual consistency\n\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\n\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3c5e52e53cd4a87a5c7b637e4a7ab2e9a58df466", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/3c5e52e53cd4a87a5c7b637e4a7ab2e9a58df466", "committedDate": "2020-04-01T23:56:30Z", "message": "fix: Failed to get status issue because of s3 eventual consistency\n\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\n\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file."}, "afterCommit": {"oid": "69de3f2fe3e5b871e42d13a5fece4e713f3b2e06", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/69de3f2fe3e5b871e42d13a5fece4e713f3b2e06", "committedDate": "2020-04-01T23:58:26Z", "message": "fix: Failed to get status issue because of s3 eventual consistency\n\ns3a file will invoke HadoopInputFile.getStat when getting length of file.\nthis call might fail because of s3 eventual consistency.\n\ninstead use appender.length to get file size and call respective setter methods\nwhile creating instance of data file."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4747, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}