{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ5MTc4NDI2", "number": 1205, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMDozMjo0NVrOEOeuKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMToyNDozNlrOEOfS6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNjE4ODU5OnYy", "diffSide": "RIGHT", "path": "site/docs/spark.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMDozMjo0NVrOGxp_RQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMToyMzoxN1rOGxq03A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcyMTM0OQ==", "bodyText": "@dongjoon-hyun, this is the warning I've added to make people aware of the issues with the DataFrameReader. Please take a look if you have time. There is also one below for the v1 DataFrameWriter API.", "url": "https://github.com/apache/iceberg/pull/1205#discussion_r454721349", "createdAt": "2020-07-15T00:32:45Z", "author": {"login": "rdblue"}, "path": "site/docs/spark.md", "diffHunk": "@@ -286,6 +286,11 @@ val df = spark.read\n     .table(\"prod.db.table\")\n ```\n \n+!!! Warning\n+    When reading with DataFrames in Spark 3, use `table` to load a table by name from a catalog.\n+    Using `format(\"iceberg\")` loads an isolated table reference that is not refreshed when other queries update the table.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "369c32dc4137d16437c0b71326a0fbafe306ccc4"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDczNTA2OA==", "bodyText": "Thank you, @rdblue . It looks good to me.", "url": "https://github.com/apache/iceberg/pull/1205#discussion_r454735068", "createdAt": "2020-07-15T01:23:17Z", "author": {"login": "dongjoon-hyun"}, "path": "site/docs/spark.md", "diffHunk": "@@ -286,6 +286,11 @@ val df = spark.read\n     .table(\"prod.db.table\")\n ```\n \n+!!! Warning\n+    When reading with DataFrames in Spark 3, use `table` to load a table by name from a catalog.\n+    Using `format(\"iceberg\")` loads an isolated table reference that is not refreshed when other queries update the table.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcyMTM0OQ=="}, "originalCommit": {"oid": "369c32dc4137d16437c0b71326a0fbafe306ccc4"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNjI4MjE1OnYy", "diffSide": "RIGHT", "path": "site/docs/spark.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMToyNDoxOFrOGxq17A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMToyNDoxOFrOGxq17A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDczNTM0MA==", "bodyText": "Ya. We should release Apache Spark 3.0.1 soon for the users.", "url": "https://github.com/apache/iceberg/pull/1205#discussion_r454735340", "createdAt": "2020-07-15T01:24:18Z", "author": {"login": "dongjoon-hyun"}, "path": "site/docs/spark.md", "diffHunk": "@@ -353,6 +358,13 @@ To replace data in the table with the result of a query, use `INSERT OVERWRITE`.\n \n The partitions that will be replaced by `INSERT OVERWRITE` depends on Spark's partition overwrite mode and the partitioning of a table.\n \n+!!! Warning\n+    Spark 3.0.0 has a correctness bug that affects dynamic `INSERT OVERWRITE` with hidden partitioning, [SPARK-32168][spark-32168].\n+    For tables with [hidden partitions](../partitioning), wait for Spark 3.0.1.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b40723c134f7701b73916e4c3162b015c0f3f40"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNjI4MjY2OnYy", "diffSide": "RIGHT", "path": "site/docs/spark.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMToyNDozNlrOGxq2Og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMToyNDozNlrOGxq2Og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDczNTQxOA==", "bodyText": "Thanks, @rdblue !", "url": "https://github.com/apache/iceberg/pull/1205#discussion_r454735418", "createdAt": "2020-07-15T01:24:36Z", "author": {"login": "dongjoon-hyun"}, "path": "site/docs/spark.md", "diffHunk": "@@ -432,6 +444,13 @@ Spark 3 introduced the new `DataFrameWriterV2` API for writing to tables using d\n     - `df.writeTo(t).append()` is equivalent to `INSERT INTO`\n     - `df.writeTo(t).overwritePartitions()` is equivalent to dynamic `INSERT OVERWRITE`\n \n+The v1 DataFrame `write` API is still supported, but is not recommended.\n+\n+!!! Warning\n+    When writing with the v1 DataFrame API in Spark 3, use `saveAsTable` or `insertInto` to load tables with a catalog.\n+    Using `format(\"iceberg\")` loads an isolated table reference that will not automatically refresh tables used by queries.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b40723c134f7701b73916e4c3162b015c0f3f40"}, "originalPosition": 52}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3768, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}