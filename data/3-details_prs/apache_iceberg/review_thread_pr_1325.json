{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY2NTczODI4", "number": 1325, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxODoxOToxMFrOEXvjSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxODoxOToxMFrOEXvjSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMzMxNzg2OnYy", "diffSide": "RIGHT", "path": "spark3/src/main/java/org/apache/iceberg/spark/Spark3Util.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxODoxOToxMFrOG_tG0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMDo1ODoxN1rOHAjy7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1MjQ5Nw==", "bodyText": "I'm not sure that this should call allowIncompatibleChanges() because adding a required column when there are no existing values will break reading the new column in any table with data in it. The only time it is safe to add a required column is if there is no data in the table.\nWhat about throwing an exception here instead? I agree that the column should not be optional if NOT NULL was specified.\nAnother alternative is to check whether the table has data and allow the incompatible change if it doesn't have any rows.", "url": "https://github.com/apache/iceberg/pull/1325#discussion_r469452497", "createdAt": "2020-08-12T18:19:10Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/Spark3Util.java", "diffHunk": "@@ -178,8 +178,12 @@ private static void apply(UpdateSchema pendingUpdate, TableChange.UpdateColumnPo\n \n   private static void apply(UpdateSchema pendingUpdate, TableChange.AddColumn add) {\n     Type type = SparkSchemaUtil.convert(add.dataType());\n-    pendingUpdate.addColumn(parentName(add.fieldNames()), leafName(add.fieldNames()), type, add.comment());\n-\n+    if (add.isNullable()) {\n+      pendingUpdate.addColumn(parentName(add.fieldNames()), leafName(add.fieldNames()), type, add.comment());\n+    } else {\n+      pendingUpdate.allowIncompatibleChanges()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d27ccab4d18defe38de4dd276d306c261fa36223"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM0ODUyNg==", "bodyText": "Thanks for the review, @rdblue.  Sure, that makes sense.\nI will update it to throw an error and will use the same error message as SchemaUpdate.addRequiredColumn would have returned without the allowIncompatibleChanges().\nie  Incompatible change: cannot add required column: %s", "url": "https://github.com/apache/iceberg/pull/1325#discussion_r470348526", "createdAt": "2020-08-14T00:58:17Z", "author": {"login": "skambha"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/Spark3Util.java", "diffHunk": "@@ -178,8 +178,12 @@ private static void apply(UpdateSchema pendingUpdate, TableChange.UpdateColumnPo\n \n   private static void apply(UpdateSchema pendingUpdate, TableChange.AddColumn add) {\n     Type type = SparkSchemaUtil.convert(add.dataType());\n-    pendingUpdate.addColumn(parentName(add.fieldNames()), leafName(add.fieldNames()), type, add.comment());\n-\n+    if (add.isNullable()) {\n+      pendingUpdate.addColumn(parentName(add.fieldNames()), leafName(add.fieldNames()), type, add.comment());\n+    } else {\n+      pendingUpdate.allowIncompatibleChanges()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1MjQ5Nw=="}, "originalCommit": {"oid": "d27ccab4d18defe38de4dd276d306c261fa36223"}, "originalPosition": 9}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3632, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}