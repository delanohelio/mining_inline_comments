{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY3MjQ5NjE3", "number": 1332, "title": "Flink: Introduce CatalogLoader and TableLoader", "bodyText": "Fixes #1303\nUnlike Spark catalog table (Table is only required on the client/driver side), Flink needs obtain Table object in Job Manager or Task.\n\nFor writer (#1185): Flink needs obtain Table in committer task for appending files.\nFor reader (#1293): Flink needs obtain Table in Job Manager for planing tasks.\n\nSo we can introduce a CatalogLoader for reader and writer, users can define a custom catalog loader in FlinkCatalogFactory.\npublic interface CatalogLoader extends Serializable {\n  Catalog loadCatalog(Configuration hadoopConf);\n}\n\nFor support hadoop table based on location. Introduce TableLoader for both catalog table and hadoop location table.\nQ: Can/Should we introduce CatalogLoader and TableLoader to an Iceberg common module.", "createdAt": "2020-08-13T08:59:44Z", "url": "https://github.com/apache/iceberg/pull/1332", "merged": true, "mergeCommit": {"oid": "e2d0d73715ff97b4a401874b5889f844d78f1508"}, "closed": true, "closedAt": "2020-08-20T17:59:34Z", "author": {"login": "JingsongLi"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc_tbI-gH2gAyNDY3MjQ5NjE3OjFjNzU3MjEyNGU4ZmQ3OWFmMGNhOGU3OWQzYjViNGUxMTAyNTE2MjQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdAMECDAFqTQ2OTc1MDU3Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "1c7572124e8fd79af0ca8e79d3b5b4e110251624", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/1c7572124e8fd79af0ca8e79d3b5b4e110251624", "committedDate": "2020-08-17T07:38:41Z", "message": "Flink: Introduce CatalogLoader and TableLoader"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "17adea8b2efac6f217657ddf618bc43db4833ffb", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/17adea8b2efac6f217657ddf618bc43db4833ffb", "committedDate": "2020-08-14T05:49:17Z", "message": "Fix checkstyle"}, "afterCommit": {"oid": "1c7572124e8fd79af0ca8e79d3b5b4e110251624", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/1c7572124e8fd79af0ca8e79d3b5b4e110251624", "committedDate": "2020-08-17T07:38:41Z", "message": "Flink: Introduce CatalogLoader and TableLoader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de62dac2cae6c391f4efa44023cc3f4120105dc4", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/de62dac2cae6c391f4efa44023cc3f4120105dc4", "committedDate": "2020-08-17T08:18:35Z", "message": "Add util clusterHadoopConf"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4OTc2NDIy", "url": "https://github.com/apache/iceberg/pull/1332#pullrequestreview-468976422", "createdAt": "2020-08-18T04:05:51Z", "commit": {"oid": "de62dac2cae6c391f4efa44023cc3f4120105dc4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwNDowNTo1MVrOHCCjzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwNDowNTo1MVrOHCCjzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTkwMTEzNQ==", "bodyText": "Those two seems don't have to be private members because I did not see anywhere accessing them except the constructor.", "url": "https://github.com/apache/iceberg/pull/1332#discussion_r471901135", "createdAt": "2020-08-18T04:05:51Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -71,6 +72,8 @@\n  */\n public class FlinkCatalog extends AbstractCatalog {\n \n+  private final CatalogLoader catalogLoader;\n+  private final Configuration hadoopConf;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de62dac2cae6c391f4efa44023cc3f4120105dc4"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4OTc4ODUz", "url": "https://github.com/apache/iceberg/pull/1332#pullrequestreview-468978853", "createdAt": "2020-08-18T04:15:09Z", "commit": {"oid": "de62dac2cae6c391f4efa44023cc3f4120105dc4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwNDoxNTowOVrOHCCsHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwNDoxNTowOVrOHCCsHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTkwMzI2Mw==", "bodyText": "Is possible to track only on Catalog in this FlinkCatalog class ? For example,  we only keep the icebergCatalog as the member of this class, that will be much easier to follow the code ( Introducing two member here confused me sometime).   When close the catalog we could make the CachingCatalog to implement Closeable inteface.", "url": "https://github.com/apache/iceberg/pull/1332#discussion_r471903263", "createdAt": "2020-08-18T04:15:09Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -80,14 +83,17 @@ public FlinkCatalog(\n       String catalogName,\n       String defaultDatabase,\n       String[] baseNamespace,\n-      Catalog icebergCatalog,\n+      CatalogLoader catalogLoader,\n+      Configuration hadoopConf,\n       boolean cacheEnabled) {\n     super(catalogName, defaultDatabase);\n-    this.originalCatalog = icebergCatalog;\n-    this.icebergCatalog = cacheEnabled ? CachingCatalog.wrap(icebergCatalog) : icebergCatalog;\n+    this.hadoopConf = hadoopConf;\n+    this.originalCatalog = catalogLoader.loadCatalog(hadoopConf);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de62dac2cae6c391f4efa44023cc3f4120105dc4"}, "originalPosition": 29}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "103997e68910e767173f86edaf5ebb6c9edafc45", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/103997e68910e767173f86edaf5ebb6c9edafc45", "committedDate": "2020-08-18T05:27:57Z", "message": "Address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5NzUwNTc2", "url": "https://github.com/apache/iceberg/pull/1332#pullrequestreview-469750576", "createdAt": "2020-08-18T19:16:38Z", "commit": {"oid": "103997e68910e767173f86edaf5ebb6c9edafc45"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxOToxNjozOVrOHCibpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxOToxNjozOVrOHCibpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQyMzMzNA==", "bodyText": "Do you really need this? isn't this covered by the CatalogTableLoader using hadoop?", "url": "https://github.com/apache/iceberg/pull/1332#discussion_r472423334", "createdAt": "2020-08-18T19:16:39Z", "author": {"login": "edgarRd"}, "path": "flink/src/main/java/org/apache/iceberg/flink/TableLoader.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+\n+/**\n+ * Serializable loader to load an Iceberg {@link Table}.\n+ * Flink needs to get {@link Table} objects in the cluster (for example, to get splits), not just on the client side.\n+ * So we need an Iceberg table loader to get the {@link Table} object.\n+ */\n+public interface TableLoader extends Closeable, Serializable {\n+\n+  void open(Configuration configuration);\n+\n+  Table loadTable();\n+\n+  static TableLoader fromCatalog(CatalogLoader catalogLoader, TableIdentifier identifier) {\n+    return new CatalogTableLoader(catalogLoader, identifier);\n+  }\n+\n+  static TableLoader fromHadoopTable(String location) {\n+    return new HadoopTableLoader(location);\n+  }\n+\n+  class HadoopTableLoader implements TableLoader {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "103997e68910e767173f86edaf5ebb6c9edafc45"}, "originalPosition": 50}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4025, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}