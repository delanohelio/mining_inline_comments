{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY0ODYyMDE5", "number": 1310, "title": "Spark: Use SessionState to load Hadoop config", "bodyText": "We have to use SessionState to get a complete Hadoop conf. It is legal to set Hadoop properties directly without the spark.hadoop prefix. If we use SparkContext directly, we will miss such properties.", "createdAt": "2020-08-07T22:44:59Z", "url": "https://github.com/apache/iceberg/pull/1310", "merged": true, "mergeCommit": {"oid": "4bb2b0893a5de0b0452cb9db32401729c098ca8b"}, "closed": true, "closedAt": "2020-08-10T15:31:10Z", "author": {"login": "aokolnychyi"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc8sS4VgH2gAyNDY0ODYyMDE5OjdmNGRkNDY3NGRmOTlhYmQwMmYxZGRiMGY0MTM5N2MxM2I0ZmM1ZjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc9S_hOAH2gAyNDY0ODYyMDE5Ojc3YzQxMjcwOTgzMzRhY2UyNzhiZTE3NGUyOTQ3NDg4YzE5NDhmZjY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "7f4dd4674df99abd02f1ddb0f41397c13b4fc5f1", "author": {"user": {"login": "aokolnychyi", "name": "Anton Okolnychyi"}}, "url": "https://github.com/apache/iceberg/commit/7f4dd4674df99abd02f1ddb0f41397c13b4fc5f1", "committedDate": "2020-08-07T22:37:59Z", "message": "Spark: Use SessionState to load Hadoop config"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYzNjc2NDIw", "url": "https://github.com/apache/iceberg/pull/1310#pullrequestreview-463676420", "createdAt": "2020-08-07T22:46:50Z", "commit": {"oid": "7f4dd4674df99abd02f1ddb0f41397c13b4fc5f1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QyMjo0Njo1MFrOG9qxKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QyMjo0Njo1MFrOG9qxKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMxNzAzMg==", "bodyText": "I kept the current implementation as sessionState().newHadoopConf() is more expensive. I think the correct fix here would be to broadcast the Hadoop conf. We already do that while broadcasting FileIO, though.", "url": "https://github.com/apache/iceberg/pull/1310#discussion_r467317032", "createdAt": "2020-08-07T22:46:50Z", "author": {"login": "aokolnychyi"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -443,6 +443,7 @@ private Schema lazyExpectedSchema() {\n       return expectedSchema;\n     }\n \n+    @SuppressWarnings(\"checkstyle:RegexpSingleline\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f4dd4674df99abd02f1ddb0f41397c13b4fc5f1"}, "originalPosition": 13}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d664ff6ed88f637cbd40c780ba56773e65fcf7e8", "author": {"user": {"login": "aokolnychyi", "name": "Anton Okolnychyi"}}, "url": "https://github.com/apache/iceberg/commit/d664ff6ed88f637cbd40c780ba56773e65fcf7e8", "committedDate": "2020-08-09T06:14:44Z", "message": "Fix usages in tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77c4127098334ace278be174e2947488c1948ff6", "author": {"user": {"login": "aokolnychyi", "name": "Anton Okolnychyi"}}, "url": "https://github.com/apache/iceberg/commit/77c4127098334ace278be174e2947488c1948ff6", "committedDate": "2020-08-09T19:43:08Z", "message": "Fix one more usage"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4410, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}