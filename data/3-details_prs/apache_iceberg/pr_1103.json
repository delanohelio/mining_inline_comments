{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxMjU4NDQ0", "number": 1103, "title": "Add IcebergSerDe", "bodyText": "Hello! This is part 1 of our series of PR's to add in the mapred InputFormat to support reading tables from Hive. This was initially meant to only include the IcebergSerDe but we had to add a few more classes to get it working properly.\n@rdblue @massdosage @teabot", "createdAt": "2020-06-08T16:30:37Z", "url": "https://github.com/apache/iceberg/pull/1103", "merged": true, "mergeCommit": {"oid": "ea3d4d3a97027343c7c51fbb5485b93ebbbbfb8b"}, "closed": true, "closedAt": "2020-07-01T16:24:17Z", "author": {"login": "cmathiesen"}, "timelineItems": {"totalCount": 62, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcpSFRzAH2gAyNDMxMjU4NDQ0OmE5NmY5NTBhOTgwMGY3ZWZlNjcxN2UwMmQ0MzdjOGMxNTU3NThhYzc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcwtQOlAFqTQ0MTA0NTMzOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a96f950a9800f7efe6717e02d437c8c155758ac7", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/a96f950a9800f7efe6717e02d437c8c155758ac7", "committedDate": "2020-06-08T15:21:02Z", "message": "Adding serde classes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ec7a4bf44fea63dd17a95e31f283b2541ee6dfd", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/8ec7a4bf44fea63dd17a95e31f283b2541ee6dfd", "committedDate": "2020-06-08T15:50:10Z", "message": "added some required classes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90311cc8ba9d11ace4e8c4237f5c908d95d91ce6", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/90311cc8ba9d11ace4e8c4237f5c908d95d91ce6", "committedDate": "2020-06-08T16:24:21Z", "message": "Add tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NDI0Mzc0", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-426424374", "createdAt": "2020-06-08T16:45:29Z", "commit": {"oid": "90311cc8ba9d11ace4e8c4237f5c908d95d91ce6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNjo0NToyOVrOGgnCTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNjo0NToyOVrOGgnCTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg0NzE4MA==", "bodyText": "Can you add the log message you want now? Or just remove the try/catch as it's not adding anything right now.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r436847180", "createdAt": "2020-06-08T16:45:29Z", "author": {"login": "massdosage"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+/**\n+ * Class to convert Iceberg types to Hive TypeInfo\n+ */\n+final class IcebergSchemaToTypeInfo {\n+\n+  private IcebergSchemaToTypeInfo() {\n+\n+  }\n+\n+  private static final ImmutableMap<Object, Object> primitiveTypeToTypeInfo = ImmutableMap.builder()\n+      .put(Types.BooleanType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BOOLEAN_TYPE_NAME))\n+      .put(Types.IntegerType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.INT_TYPE_NAME))\n+      .put(Types.LongType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.FloatType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.FLOAT_TYPE_NAME))\n+      .put(Types.DoubleType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DOUBLE_TYPE_NAME))\n+      .put(Types.BinaryType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME))\n+      .put(Types.StringType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME))\n+      .put(Types.DateType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DATE_TYPE_NAME))\n+      .put(Types.TimestampType.withoutZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.TimestampType.withZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .build();\n+\n+  public static List<TypeInfo> getColumnTypes(Schema schema) throws Exception {\n+    List<Types.NestedField> fields = schema.columns();\n+    List<TypeInfo> types = new ArrayList<>(fields.size());\n+    for (Types.NestedField field : fields) {\n+      types.add(generateTypeInfo(field.type()));\n+    }\n+    return types;\n+  }\n+\n+  private static TypeInfo generateTypeInfo(Type type) throws Exception {\n+    if (primitiveTypeToTypeInfo.containsKey(type)) {\n+      return (TypeInfo) primitiveTypeToTypeInfo.get(type);\n+    }\n+    switch (type.typeId()) {\n+      case UUID:\n+        return TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME);\n+      case FIXED:\n+        return TypeInfoFactory.getPrimitiveTypeInfo(\"binary\");\n+      case TIME:\n+        return TypeInfoFactory.getPrimitiveTypeInfo(\"long\");\n+      case DECIMAL:\n+        Types.DecimalType dec = (Types.DecimalType) type;\n+        int scale = dec.scale();\n+        int precision = dec.precision();\n+        try {\n+          HiveDecimalUtils.validateParameter(precision, scale);\n+        } catch (Exception e) {\n+          //TODO Log that precision / scale isn't valid", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90311cc8ba9d11ace4e8c4237f5c908d95d91ce6"}, "originalPosition": 83}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/c0cec1786f33ae4dafe46e0aa8be61e5acebea4e", "committedDate": "2020-06-09T08:45:12Z", "message": "Remove try/catch"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MjcwNTM2", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428270536", "createdAt": "2020-06-10T17:18:59Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoxODo1OVrOGh-43g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoxODo1OVrOGh-43g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4NjU1OA==", "bodyText": "Nit: no need for a blank line here.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438286558", "createdAt": "2020-06-10T17:18:59Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+/**\n+ * Class to convert Iceberg types to Hive TypeInfo\n+ */\n+final class IcebergSchemaToTypeInfo {\n+\n+  private IcebergSchemaToTypeInfo() {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MjcxNTg3", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428271587", "createdAt": "2020-06-10T17:20:19Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMDoyMFrOGh-79A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMDoyMFrOGh-79A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4NzM0OA==", "bodyText": "Why not use serdeConstants here and for the fixed case?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438287348", "createdAt": "2020-06-10T17:20:20Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+/**\n+ * Class to convert Iceberg types to Hive TypeInfo\n+ */\n+final class IcebergSchemaToTypeInfo {\n+\n+  private IcebergSchemaToTypeInfo() {\n+\n+  }\n+\n+  private static final ImmutableMap<Object, Object> primitiveTypeToTypeInfo = ImmutableMap.builder()\n+      .put(Types.BooleanType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BOOLEAN_TYPE_NAME))\n+      .put(Types.IntegerType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.INT_TYPE_NAME))\n+      .put(Types.LongType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.FloatType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.FLOAT_TYPE_NAME))\n+      .put(Types.DoubleType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DOUBLE_TYPE_NAME))\n+      .put(Types.BinaryType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME))\n+      .put(Types.StringType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME))\n+      .put(Types.DateType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DATE_TYPE_NAME))\n+      .put(Types.TimestampType.withoutZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.TimestampType.withZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .build();\n+\n+  public static List<TypeInfo> getColumnTypes(Schema schema) throws Exception {\n+    List<Types.NestedField> fields = schema.columns();\n+    List<TypeInfo> types = new ArrayList<>(fields.size());\n+    for (Types.NestedField field : fields) {\n+      types.add(generateTypeInfo(field.type()));\n+    }\n+    return types;\n+  }\n+\n+  private static TypeInfo generateTypeInfo(Type type) throws Exception {\n+    if (primitiveTypeToTypeInfo.containsKey(type)) {\n+      return (TypeInfo) primitiveTypeToTypeInfo.get(type);\n+    }\n+    switch (type.typeId()) {\n+      case UUID:\n+        return TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME);\n+      case FIXED:\n+        return TypeInfoFactory.getPrimitiveTypeInfo(\"binary\");\n+      case TIME:\n+        return TypeInfoFactory.getPrimitiveTypeInfo(\"long\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MjczMTYy", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428273162", "createdAt": "2020-06-10T17:22:27Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMjoyOFrOGh_Aug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMjoyOFrOGh_Aug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4ODU3MA==", "bodyText": "Since this is public, can you add Javadoc describing its purpose?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438288570", "createdAt": "2020-06-10T17:22:28Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergWritable.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.Record;\n+\n+public class IcebergWritable implements Writable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MjczMjc2", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428273276", "createdAt": "2020-06-10T17:22:36Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMjozNlrOGh_BEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMjozNlrOGh_BEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4ODY1Ng==", "bodyText": "No need to include empty public constructors.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438288656", "createdAt": "2020-06-10T17:22:36Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergWritable.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.Record;\n+\n+public class IcebergWritable implements Writable {\n+\n+  private Record record;\n+  private Schema schema;\n+\n+  public IcebergWritable() {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MjczNjg1", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428273685", "createdAt": "2020-06-10T17:23:11Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMzoxMVrOGh_CUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMzoxMVrOGh_CUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4ODk3Nw==", "bodyText": "We typically use the verb wrap for this pattern.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438288977", "createdAt": "2020-06-10T17:23:11Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergWritable.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.Record;\n+\n+public class IcebergWritable implements Writable {\n+\n+  private Record record;\n+  private Schema schema;\n+\n+  public IcebergWritable() {}\n+\n+  public void setRecord(Record record) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MjczOTU4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428273958", "createdAt": "2020-06-10T17:23:33Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMzozM1rOGh_DGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyMzozM1rOGh_DGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4OTE3Nw==", "bodyText": "For getters, we omit get because it doesn't add any value.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438289177", "createdAt": "2020-06-10T17:23:33Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergWritable.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.Record;\n+\n+public class IcebergWritable implements Writable {\n+\n+  private Record record;\n+  private Schema schema;\n+\n+  public IcebergWritable() {}\n+\n+  public void setRecord(Record record) {\n+    this.record = record;\n+  }\n+\n+  public Record getRecord() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjc0MzM5", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428274339", "createdAt": "2020-06-10T17:24:03Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyNDowNFrOGh_EPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyNDowNFrOGh_EPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4OTQ3MA==", "bodyText": "If this writable isn't actually writable, then I think this should throw UnsupportedOperationException here and in readFields.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438289470", "createdAt": "2020-06-10T17:24:04Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergWritable.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.Record;\n+\n+public class IcebergWritable implements Writable {\n+\n+  private Record record;\n+  private Schema schema;\n+\n+  public IcebergWritable() {}\n+\n+  public void setRecord(Record record) {\n+    this.record = record;\n+  }\n+\n+  public Record getRecord() {\n+    return record;\n+  }\n+\n+  public Schema getSchema() {\n+    return schema;\n+  }\n+\n+  public void setSchema(Schema schema) {\n+    this.schema = schema;\n+  }\n+\n+  @Override\n+  public void write(DataOutput dataOutput) throws IOException {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjc3MTQ0", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428277144", "createdAt": "2020-06-10T17:27:34Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyNzozNVrOGh_M2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyNzozNVrOGh_M2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI5MTY3Mg==", "bodyText": "If this is configurable, then why use the double underscore name? Couldn't this use snapshot_id instead?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438291672", "createdAt": "2020-06-10T17:27:35Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/SystemTableUtil.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.types.Types;\n+\n+public class SystemTableUtil {\n+\n+  static final String VIRTUAL_COLUMN_NAME = \"iceberg.hive.snapshot.virtual.column.name\";\n+\n+  private static final String DEFAULT_SNAPSHOT_ID_COLUMN_NAME = \"snapshot__id\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 35}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjc3Nzc4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428277778", "createdAt": "2020-06-10T17:28:25Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyODoyNVrOGh_O0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyODoyNVrOGh_O0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI5MjE3OA==", "bodyText": "We generally like to use Lists.newArrayList() to avoid depending on a specific implementation class.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438292178", "createdAt": "2020-06-10T17:28:25Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/SystemTableUtil.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.types.Types;\n+\n+public class SystemTableUtil {\n+\n+  static final String VIRTUAL_COLUMN_NAME = \"iceberg.hive.snapshot.virtual.column.name\";\n+\n+  private static final String DEFAULT_SNAPSHOT_ID_COLUMN_NAME = \"snapshot__id\";\n+\n+  private SystemTableUtil() {}\n+\n+  protected static Schema schemaWithVirtualColumn(Schema schema, String columnName) {\n+    List<Types.NestedField> columns = new ArrayList<>(schema.columns());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjc4OTE3", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428278917", "createdAt": "2020-06-10T17:29:50Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyOTo1MFrOGh_SPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzoyOTo1MFrOGh_SPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI5MzA1Mw==", "bodyText": "The field positions match, right? If so, then this could just iterate through positions in the original record instead of names. That would avoid a hashmap lookup of the position for both get and set.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438293053", "createdAt": "2020-06-10T17:29:50Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/SystemTableUtil.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.types.Types;\n+\n+public class SystemTableUtil {\n+\n+  static final String VIRTUAL_COLUMN_NAME = \"iceberg.hive.snapshot.virtual.column.name\";\n+\n+  private static final String DEFAULT_SNAPSHOT_ID_COLUMN_NAME = \"snapshot__id\";\n+\n+  private SystemTableUtil() {}\n+\n+  protected static Schema schemaWithVirtualColumn(Schema schema, String columnName) {\n+    List<Types.NestedField> columns = new ArrayList<>(schema.columns());\n+    columns.add(Types.NestedField.optional(Integer.MAX_VALUE, columnName, Types.LongType.get()));\n+    return new Schema(columns);\n+  }\n+\n+  protected static Record recordWithVirtualColumn(Record record, long snapshotId, Schema oldSchema,\n+                                                   String columnName) {\n+    Schema newSchema = schemaWithVirtualColumn(oldSchema, columnName);\n+    Record newRecord = GenericRecord.create(newSchema);\n+    for (Types.NestedField field : oldSchema.columns()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjc5NDgx", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428279481", "createdAt": "2020-06-10T17:30:33Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzozMDozM1rOGh_UAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzozMDozM1rOGh_UAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI5MzUwNQ==", "bodyText": "When are properties used and when is configuration used? I'm surprised that we need both.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438293505", "createdAt": "2020-06-10T17:30:33Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/SystemTableUtil.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.types.Types;\n+\n+public class SystemTableUtil {\n+\n+  static final String VIRTUAL_COLUMN_NAME = \"iceberg.hive.snapshot.virtual.column.name\";\n+\n+  private static final String DEFAULT_SNAPSHOT_ID_COLUMN_NAME = \"snapshot__id\";\n+\n+  private SystemTableUtil() {}\n+\n+  protected static Schema schemaWithVirtualColumn(Schema schema, String columnName) {\n+    List<Types.NestedField> columns = new ArrayList<>(schema.columns());\n+    columns.add(Types.NestedField.optional(Integer.MAX_VALUE, columnName, Types.LongType.get()));\n+    return new Schema(columns);\n+  }\n+\n+  protected static Record recordWithVirtualColumn(Record record, long snapshotId, Schema oldSchema,\n+                                                   String columnName) {\n+    Schema newSchema = schemaWithVirtualColumn(oldSchema, columnName);\n+    Record newRecord = GenericRecord.create(newSchema);\n+    for (Types.NestedField field : oldSchema.columns()) {\n+      newRecord.setField(field.name(), record.getField(field.name()));\n+    }\n+    newRecord.setField(columnName, snapshotId);\n+    return newRecord;\n+  }\n+\n+  protected static String getVirtualColumnName(Configuration conf) {\n+    String virtualColumnName = conf.get(VIRTUAL_COLUMN_NAME);\n+    if (virtualColumnName == null) {\n+      return DEFAULT_SNAPSHOT_ID_COLUMN_NAME;\n+    } else {\n+      return virtualColumnName;\n+    }\n+  }\n+\n+  protected static String getVirtualColumnName(Properties properties) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjg3ODU4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428287858", "createdAt": "2020-06-10T17:42:09Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo0MjoxMFrOGh_u4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo0MjoxMFrOGh_u4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwMDM4NQ==", "bodyText": "It looks like this would be easier to implement using the type visitors, which already have the logic to traverse a schema. A good example is converting a Type to Spark's DataType.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438300385", "createdAt": "2020-06-10T17:42:10Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+/**\n+ * Class to convert Iceberg types to Hive TypeInfo\n+ */\n+final class IcebergSchemaToTypeInfo {\n+\n+  private IcebergSchemaToTypeInfo() {\n+\n+  }\n+\n+  private static final ImmutableMap<Object, Object> primitiveTypeToTypeInfo = ImmutableMap.builder()\n+      .put(Types.BooleanType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BOOLEAN_TYPE_NAME))\n+      .put(Types.IntegerType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.INT_TYPE_NAME))\n+      .put(Types.LongType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.FloatType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.FLOAT_TYPE_NAME))\n+      .put(Types.DoubleType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DOUBLE_TYPE_NAME))\n+      .put(Types.BinaryType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME))\n+      .put(Types.StringType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME))\n+      .put(Types.DateType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DATE_TYPE_NAME))\n+      .put(Types.TimestampType.withoutZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.TimestampType.withZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .build();\n+\n+  public static List<TypeInfo> getColumnTypes(Schema schema) throws Exception {\n+    List<Types.NestedField> fields = schema.columns();\n+    List<TypeInfo> types = new ArrayList<>(fields.size());\n+    for (Types.NestedField field : fields) {\n+      types.add(generateTypeInfo(field.type()));\n+    }\n+    return types;\n+  }\n+\n+  private static TypeInfo generateTypeInfo(Type type) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjg4MTg4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428288188", "createdAt": "2020-06-10T17:42:37Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo0MjozOFrOGh_v9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo0MjozOFrOGh_v9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwMDY2MQ==", "bodyText": "Doesn't Hive have timestamp types?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438300661", "createdAt": "2020-06-10T17:42:38Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+/**\n+ * Class to convert Iceberg types to Hive TypeInfo\n+ */\n+final class IcebergSchemaToTypeInfo {\n+\n+  private IcebergSchemaToTypeInfo() {\n+\n+  }\n+\n+  private static final ImmutableMap<Object, Object> primitiveTypeToTypeInfo = ImmutableMap.builder()\n+      .put(Types.BooleanType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BOOLEAN_TYPE_NAME))\n+      .put(Types.IntegerType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.INT_TYPE_NAME))\n+      .put(Types.LongType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.FloatType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.FLOAT_TYPE_NAME))\n+      .put(Types.DoubleType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DOUBLE_TYPE_NAME))\n+      .put(Types.BinaryType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME))\n+      .put(Types.StringType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME))\n+      .put(Types.DateType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DATE_TYPE_NAME))\n+      .put(Types.TimestampType.withoutZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.TimestampType.withZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjg5NzM1", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428289735", "createdAt": "2020-06-10T17:44:39Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo0NDozOVrOGh_0jg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo0NDozOVrOGh_0jg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwMTgzOA==", "bodyText": "I think getVritualColumnName should have a better method name. Here, it isn't clear what's happening because which virtual column is getting added is not obvious. If this were snapshotIdColumnName then I think it would be better.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438301838", "createdAt": "2020-06-10T17:44:39Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSerDe.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import javax.annotation.Nullable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde2.AbstractSerDe;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.SerDeStats;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SnapshotsTable;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.types.Types;\n+\n+public class IcebergSerDe extends AbstractSerDe {\n+\n+  private Schema schema;\n+  private ObjectInspector inspector;\n+\n+  @Override\n+  public void initialize(@Nullable Configuration configuration, Properties serDeProperties) throws SerDeException {\n+    Table table = null;\n+    try {\n+      table = TableResolver.resolveTableFromConfiguration(configuration, serDeProperties);\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(\"Unable to resolve table from configuration: \", e);\n+    }\n+    this.schema = table.schema();\n+    if (table instanceof SnapshotsTable) {\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(schema);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    } else {\n+      List<Types.NestedField> columns = new ArrayList<>(schema.columns());\n+      columns.add(Types.NestedField.optional(Integer.MAX_VALUE, SystemTableUtil.getVirtualColumnName(serDeProperties),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 62}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MjkzNzQ2", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428293746", "createdAt": "2020-06-10T17:49:55Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo0OTo1NVrOGiAAtg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo0OTo1NVrOGiAAtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwNDk1MA==", "bodyText": "Does this need to allocate a new ArrayList every time or can it reuse one?\nWe try to make the code called for every row in a tight loop (like this method) as small as possible for performance reasons. Ideally, we would be able to reuse this storage, have the list of columns already prepared, and access field values by column position instead of by name. Something like this:\npublic Object deserialize(Writable writable) {\n  Record record = ((IcebergWritable) writable).record();\n  for (int i = 0; i < recordSize; i += 1) {\n    reusedArray[i] = record.get(i, Object.class);\n  }\n  return reusedArrayAsList;\n}", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438304950", "createdAt": "2020-06-10T17:49:55Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSerDe.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import javax.annotation.Nullable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde2.AbstractSerDe;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.SerDeStats;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SnapshotsTable;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.types.Types;\n+\n+public class IcebergSerDe extends AbstractSerDe {\n+\n+  private Schema schema;\n+  private ObjectInspector inspector;\n+\n+  @Override\n+  public void initialize(@Nullable Configuration configuration, Properties serDeProperties) throws SerDeException {\n+    Table table = null;\n+    try {\n+      table = TableResolver.resolveTableFromConfiguration(configuration, serDeProperties);\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(\"Unable to resolve table from configuration: \", e);\n+    }\n+    this.schema = table.schema();\n+    if (table instanceof SnapshotsTable) {\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(schema);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    } else {\n+      List<Types.NestedField> columns = new ArrayList<>(schema.columns());\n+      columns.add(Types.NestedField.optional(Integer.MAX_VALUE, SystemTableUtil.getVirtualColumnName(serDeProperties),\n+              Types.LongType.get()));\n+      Schema withVirtualColumn = new Schema(columns);\n+\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(withVirtualColumn);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public Class<? extends Writable> getSerializedClass() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Writable serialize(Object o, ObjectInspector objectInspector) {\n+    return null;\n+  }\n+\n+  @Override\n+  public SerDeStats getSerDeStats() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Object deserialize(Writable writable) {\n+    IcebergWritable icebergWritable = (IcebergWritable) writable;\n+    List<Types.NestedField> fields = icebergWritable.getSchema().columns();\n+    List<Object> row = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjk2MjM1", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428296235", "createdAt": "2020-06-10T17:53:04Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo1MzowNFrOGiAILg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo1MzowNFrOGiAILg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwNjg2Mg==", "bodyText": "This should assert that the types are correct, not just that there is the correct number of types.\nAlso, please use context where possible to make it clear what the assertion expects, like \"Converted TypeInfo should have the same number of columns\". That makes it easier to understand when tests start to fail.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438306862", "createdAt": "2020-06-10T17:53:04Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/TestIcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestIcebergSchemaToTypeInfo {\n+\n+  @Test\n+  public void testGeneratePrimitiveTypeInfo() throws Exception {\n+    Schema schema = new Schema(\n+        required(1, \"id\", Types.IntegerType.get()),\n+        optional(2, \"data\", Types.StringType.get()),\n+        required(8, \"feature1\", Types.BooleanType.get()),\n+        required(12, \"lat\", Types.FloatType.get()),\n+        required(15, \"x\", Types.LongType.get()),\n+        required(16, \"date\", Types.DateType.get()),\n+        required(17, \"double\", Types.DoubleType.get()),\n+        required(18, \"binary\", Types.BinaryType.get()));\n+    List<TypeInfo> types = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    assertEquals(8, types.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 51}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjk3ODI4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428297828", "createdAt": "2020-06-10T17:55:06Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo1NTowNlrOGiANBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo1NTowNlrOGiANBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwODEwMg==", "bodyText": "No need for new ArrayList<>(...) here. Arrays.asList(...) should return a list.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438308102", "createdAt": "2020-06-10T17:55:06Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/TestIcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestIcebergSchemaToTypeInfo {\n+\n+  @Test\n+  public void testGeneratePrimitiveTypeInfo() throws Exception {\n+    Schema schema = new Schema(\n+        required(1, \"id\", Types.IntegerType.get()),\n+        optional(2, \"data\", Types.StringType.get()),\n+        required(8, \"feature1\", Types.BooleanType.get()),\n+        required(12, \"lat\", Types.FloatType.get()),\n+        required(15, \"x\", Types.LongType.get()),\n+        required(16, \"date\", Types.DateType.get()),\n+        required(17, \"double\", Types.DoubleType.get()),\n+        required(18, \"binary\", Types.BinaryType.get()));\n+    List<TypeInfo> types = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    assertEquals(8, types.size());\n+  }\n+\n+  @Test\n+  public void testGenerateMapTypeInfo() throws Exception {\n+    TypeInfo expected = TypeInfoFactory.getMapTypeInfo(\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME),\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME));\n+\n+    Schema schema = new Schema(\n+        optional(7, \"properties\", Types.MapType.ofOptional(18, 19,\n+            Types.StringType.get(),\n+            Types.StringType.get()\n+        ), \"string map of properties\"));\n+\n+    List<TypeInfo> types = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    assertEquals(1, types.size());\n+    assertEquals(expected, types.get(0));\n+  }\n+\n+  @Test\n+  public void testGenerateListTypeInfo() throws Exception {\n+    TypeInfo expected = TypeInfoFactory\n+        .getListTypeInfo(TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DOUBLE_TYPE_NAME));\n+    Schema schema = new Schema(\n+        required(6, \"doubles\", Types.ListType.ofRequired(17,\n+            Types.DoubleType.get()\n+        )));\n+    List<TypeInfo> types = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    assertEquals(1, types.size());\n+    assertEquals(expected, types.get(0));\n+  }\n+\n+  @Test\n+  public void testGenerateMapAndStructTypeInfo() throws Exception {\n+    List<String> names1 = new ArrayList<>(Arrays.asList(\"address\", \"city\", \"state\", \"zip\"));\n+    List<TypeInfo> typeInfo1 = new ArrayList<>(Arrays.asList(\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME),\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME),\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME),\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.INT_TYPE_NAME)\n+    ));\n+    TypeInfo mapKeyStructExpected = TypeInfoFactory.getStructTypeInfo(names1, typeInfo1);\n+\n+    List<String> names2 = new ArrayList<>(Arrays.asList(\"lat\", \"long\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 97}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzAwMjMy", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428300232", "createdAt": "2020-06-10T17:58:06Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo1ODowNlrOGiAUXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo1ODowNlrOGiAUXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwOTk4Mg==", "bodyText": "Minor: these names could be better to make it clear what's happening. These are the types for the value struct, so you could name the variable valueTypes, and the names valueNames.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438309982", "createdAt": "2020-06-10T17:58:06Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/TestIcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestIcebergSchemaToTypeInfo {\n+\n+  @Test\n+  public void testGeneratePrimitiveTypeInfo() throws Exception {\n+    Schema schema = new Schema(\n+        required(1, \"id\", Types.IntegerType.get()),\n+        optional(2, \"data\", Types.StringType.get()),\n+        required(8, \"feature1\", Types.BooleanType.get()),\n+        required(12, \"lat\", Types.FloatType.get()),\n+        required(15, \"x\", Types.LongType.get()),\n+        required(16, \"date\", Types.DateType.get()),\n+        required(17, \"double\", Types.DoubleType.get()),\n+        required(18, \"binary\", Types.BinaryType.get()));\n+    List<TypeInfo> types = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    assertEquals(8, types.size());\n+  }\n+\n+  @Test\n+  public void testGenerateMapTypeInfo() throws Exception {\n+    TypeInfo expected = TypeInfoFactory.getMapTypeInfo(\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME),\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME));\n+\n+    Schema schema = new Schema(\n+        optional(7, \"properties\", Types.MapType.ofOptional(18, 19,\n+            Types.StringType.get(),\n+            Types.StringType.get()\n+        ), \"string map of properties\"));\n+\n+    List<TypeInfo> types = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    assertEquals(1, types.size());\n+    assertEquals(expected, types.get(0));\n+  }\n+\n+  @Test\n+  public void testGenerateListTypeInfo() throws Exception {\n+    TypeInfo expected = TypeInfoFactory\n+        .getListTypeInfo(TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DOUBLE_TYPE_NAME));\n+    Schema schema = new Schema(\n+        required(6, \"doubles\", Types.ListType.ofRequired(17,\n+            Types.DoubleType.get()\n+        )));\n+    List<TypeInfo> types = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    assertEquals(1, types.size());\n+    assertEquals(expected, types.get(0));\n+  }\n+\n+  @Test\n+  public void testGenerateMapAndStructTypeInfo() throws Exception {\n+    List<String> names1 = new ArrayList<>(Arrays.asList(\"address\", \"city\", \"state\", \"zip\"));\n+    List<TypeInfo> typeInfo1 = new ArrayList<>(Arrays.asList(\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME),\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME),\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME),\n+        TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.INT_TYPE_NAME)\n+    ));\n+    TypeInfo mapKeyStructExpected = TypeInfoFactory.getStructTypeInfo(names1, typeInfo1);\n+\n+    List<String> names2 = new ArrayList<>(Arrays.asList(\"lat\", \"long\"));\n+    List<TypeInfo> typeInfo2 = new ArrayList<>(Arrays.asList(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzAxNDgy", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428301482", "createdAt": "2020-06-10T17:59:44Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo1OTo0NFrOGiAYMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo1OTo0NFrOGiAYMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxMDk2MA==", "bodyText": "Minor: you might consider changing the signature of createCustomRecord to Schema, Object... and wrap the object array as a list internally. Then these would be shorter: createCustomRecord(schema, \"Michael\", 3000L).", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438310960", "createdAt": "2020-06-10T17:59:44Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/TestIcebergSerDe.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TestIcebergSerDe {\n+\n+  private File tableLocation;\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  @Before\n+  public void before() throws IOException {\n+    tableLocation = temp.newFolder();\n+    Schema schema = new Schema(optional(1, \"name\", Types.StringType.get()),\n+        optional(2, \"salary\", Types.LongType.get()));\n+    PartitionSpec spec = PartitionSpec.unpartitioned();\n+\n+    Configuration conf = new Configuration();\n+    HadoopCatalog catalog = new HadoopCatalog(conf, tableLocation.getAbsolutePath());\n+    TableIdentifier id = TableIdentifier.parse(\"source_db.table_a\");\n+    Table table = catalog.createTable(id, schema, spec);\n+\n+    List<Record> data = new ArrayList<>();\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Michael\", 3000L)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 69}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzAyMzQ1", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428302345", "createdAt": "2020-06-10T18:00:53Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowMDo1M1rOGiAa7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowMDo1M1rOGiAa7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxMTY2MA==", "bodyText": "Does Hive support non-string map keys? It looks like all of the test cases are string maps.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438311660", "createdAt": "2020-06-10T18:00:53Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/TestIcebergSerDe.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TestIcebergSerDe {\n+\n+  private File tableLocation;\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  @Before\n+  public void before() throws IOException {\n+    tableLocation = temp.newFolder();\n+    Schema schema = new Schema(optional(1, \"name\", Types.StringType.get()),\n+        optional(2, \"salary\", Types.LongType.get()));\n+    PartitionSpec spec = PartitionSpec.unpartitioned();\n+\n+    Configuration conf = new Configuration();\n+    HadoopCatalog catalog = new HadoopCatalog(conf, tableLocation.getAbsolutePath());\n+    TableIdentifier id = TableIdentifier.parse(\"source_db.table_a\");\n+    Table table = catalog.createTable(id, schema, spec);\n+\n+    List<Record> data = new ArrayList<>();\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Michael\", 3000L)));\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Andy\", 3000L)));\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Berta\", 4000L)));\n+\n+    DataFile fileA = TestHelpers.writeFile(temp.newFile(), table, null, FileFormat.PARQUET, data);\n+\n+    table.newAppend().appendFile(fileA).commit();\n+  }\n+\n+  @Test\n+  public void testDeserializeMap() {\n+    Schema schema = new Schema(required(1, \"map_type\", Types.MapType\n+        .ofRequired(18, 19, Types.StringType.get(), Types.StringType.get())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 81}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzAzNTYx", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428303561", "createdAt": "2020-06-10T18:02:29Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowMjoyOVrOGiAeWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowMjoyOVrOGiAeWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxMjUzOQ==", "bodyText": "I think the assertEquals is sufficient since it checks deep equality.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438312539", "createdAt": "2020-06-10T18:02:29Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/TestIcebergSerDe.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TestIcebergSerDe {\n+\n+  private File tableLocation;\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  @Before\n+  public void before() throws IOException {\n+    tableLocation = temp.newFolder();\n+    Schema schema = new Schema(optional(1, \"name\", Types.StringType.get()),\n+        optional(2, \"salary\", Types.LongType.get()));\n+    PartitionSpec spec = PartitionSpec.unpartitioned();\n+\n+    Configuration conf = new Configuration();\n+    HadoopCatalog catalog = new HadoopCatalog(conf, tableLocation.getAbsolutePath());\n+    TableIdentifier id = TableIdentifier.parse(\"source_db.table_a\");\n+    Table table = catalog.createTable(id, schema, spec);\n+\n+    List<Record> data = new ArrayList<>();\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Michael\", 3000L)));\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Andy\", 3000L)));\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Berta\", 4000L)));\n+\n+    DataFile fileA = TestHelpers.writeFile(temp.newFile(), table, null, FileFormat.PARQUET, data);\n+\n+    table.newAppend().appendFile(fileA).commit();\n+  }\n+\n+  @Test\n+  public void testDeserializeMap() {\n+    Schema schema = new Schema(required(1, \"map_type\", Types.MapType\n+        .ofRequired(18, 19, Types.StringType.get(), Types.StringType.get())));\n+    Map<String, String> expected = ImmutableMap.of(\"foo\", \"bar\");\n+    List<Map> data = new ArrayList<>();\n+    data.add(expected);\n+\n+    Record record = TestHelpers.createCustomRecord(schema, data);\n+    IcebergWritable writable = new IcebergWritable();\n+    writable.setRecord(record);\n+    writable.setSchema(schema);\n+\n+    IcebergSerDe serDe = new IcebergSerDe();\n+    List<Object> deserialized = (List<Object>) serDe.deserialize(writable);\n+    Map result = (Map) deserialized.get(0);\n+\n+    assertEquals(expected, result);\n+    assertTrue(result.containsKey(\"foo\"));\n+    assertTrue(result.containsValue(\"bar\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 97}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzAzNjg4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428303688", "createdAt": "2020-06-10T18:02:39Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowMjozOVrOGiAevw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowMjozOVrOGiAevw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxMjYzOQ==", "bodyText": "Should this use the object inspectors?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438312639", "createdAt": "2020-06-10T18:02:39Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/TestIcebergSerDe.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TestIcebergSerDe {\n+\n+  private File tableLocation;\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  @Before\n+  public void before() throws IOException {\n+    tableLocation = temp.newFolder();\n+    Schema schema = new Schema(optional(1, \"name\", Types.StringType.get()),\n+        optional(2, \"salary\", Types.LongType.get()));\n+    PartitionSpec spec = PartitionSpec.unpartitioned();\n+\n+    Configuration conf = new Configuration();\n+    HadoopCatalog catalog = new HadoopCatalog(conf, tableLocation.getAbsolutePath());\n+    TableIdentifier id = TableIdentifier.parse(\"source_db.table_a\");\n+    Table table = catalog.createTable(id, schema, spec);\n+\n+    List<Record> data = new ArrayList<>();\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Michael\", 3000L)));\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Andy\", 3000L)));\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Berta\", 4000L)));\n+\n+    DataFile fileA = TestHelpers.writeFile(temp.newFile(), table, null, FileFormat.PARQUET, data);\n+\n+    table.newAppend().appendFile(fileA).commit();\n+  }\n+\n+  @Test\n+  public void testDeserializeMap() {\n+    Schema schema = new Schema(required(1, \"map_type\", Types.MapType\n+        .ofRequired(18, 19, Types.StringType.get(), Types.StringType.get())));\n+    Map<String, String> expected = ImmutableMap.of(\"foo\", \"bar\");\n+    List<Map> data = new ArrayList<>();\n+    data.add(expected);\n+\n+    Record record = TestHelpers.createCustomRecord(schema, data);\n+    IcebergWritable writable = new IcebergWritable();\n+    writable.setRecord(record);\n+    writable.setSchema(schema);\n+\n+    IcebergSerDe serDe = new IcebergSerDe();\n+    List<Object> deserialized = (List<Object>) serDe.deserialize(writable);\n+    Map result = (Map) deserialized.get(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzA0MzE2", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428304316", "createdAt": "2020-06-10T18:03:28Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowMzoyOFrOGiAgmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowMzoyOFrOGiAgmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxMzExMg==", "bodyText": "I'm not sure so many test cases are necessary since this is really just testing that a record is converted to a collection with the same field order. That's all deserialize is doing.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438313112", "createdAt": "2020-06-10T18:03:28Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/TestIcebergSerDe.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TestIcebergSerDe {\n+\n+  private File tableLocation;\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  @Before\n+  public void before() throws IOException {\n+    tableLocation = temp.newFolder();\n+    Schema schema = new Schema(optional(1, \"name\", Types.StringType.get()),\n+        optional(2, \"salary\", Types.LongType.get()));\n+    PartitionSpec spec = PartitionSpec.unpartitioned();\n+\n+    Configuration conf = new Configuration();\n+    HadoopCatalog catalog = new HadoopCatalog(conf, tableLocation.getAbsolutePath());\n+    TableIdentifier id = TableIdentifier.parse(\"source_db.table_a\");\n+    Table table = catalog.createTable(id, schema, spec);\n+\n+    List<Record> data = new ArrayList<>();\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Michael\", 3000L)));\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Andy\", 3000L)));\n+    data.add(TestHelpers.createCustomRecord(schema, Arrays.asList(\"Berta\", 4000L)));\n+\n+    DataFile fileA = TestHelpers.writeFile(temp.newFile(), table, null, FileFormat.PARQUET, data);\n+\n+    table.newAppend().appendFile(fileA).commit();\n+  }\n+\n+  @Test\n+  public void testDeserializeMap() {\n+    Schema schema = new Schema(required(1, \"map_type\", Types.MapType\n+        .ofRequired(18, 19, Types.StringType.get(), Types.StringType.get())));\n+    Map<String, String> expected = ImmutableMap.of(\"foo\", \"bar\");\n+    List<Map> data = new ArrayList<>();\n+    data.add(expected);\n+\n+    Record record = TestHelpers.createCustomRecord(schema, data);\n+    IcebergWritable writable = new IcebergWritable();\n+    writable.setRecord(record);\n+    writable.setSchema(schema);\n+\n+    IcebergSerDe serDe = new IcebergSerDe();\n+    List<Object> deserialized = (List<Object>) serDe.deserialize(writable);\n+    Map result = (Map) deserialized.get(0);\n+\n+    assertEquals(expected, result);\n+    assertTrue(result.containsKey(\"foo\"));\n+    assertTrue(result.containsValue(\"bar\"));\n+  }\n+\n+  @Test\n+  public void testDeserializeList() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 101}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzA1NDcy", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428305472", "createdAt": "2020-06-10T18:05:03Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowNTowM1rOGiAj-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowNTowM1rOGiAj-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxMzk3OA==", "bodyText": "Does Hive use LocalDate as its internal representation for date? That's what Iceberg generics are going to return. I think the object inspector needs to convert that correctly to the representation that Hive expects.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438313978", "createdAt": "2020-06-10T18:05:03Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergObjectInspectorGenerator.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+\n+class IcebergObjectInspectorGenerator {\n+\n+  protected ObjectInspector createObjectInspector(Schema schema) throws Exception {\n+    List<String> columnNames = setColumnNames(schema);\n+    List<TypeInfo> columnTypes = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    List<ObjectInspector> columnOIs = new ArrayList<>(columnTypes.size());\n+    for (int i = 0; i < columnTypes.size(); i++) {\n+      columnOIs.add(createObjectInspectorWorker(columnTypes.get(i)));\n+    }\n+    return ObjectInspectorFactory.getStandardStructObjectInspector(columnNames, columnOIs, null);\n+  }\n+\n+  protected ObjectInspector createObjectInspectorWorker(TypeInfo typeInfo) throws Exception {\n+    ObjectInspector.Category typeCategory = typeInfo.getCategory();\n+\n+    switch (typeCategory) {\n+      case PRIMITIVE:\n+        PrimitiveTypeInfo pti = (PrimitiveTypeInfo) typeInfo;\n+        return PrimitiveObjectInspectorFactory.getPrimitiveJavaObjectInspector(pti);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 55}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzA1OTY1", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428305965", "createdAt": "2020-06-10T18:05:45Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowNTo0NlrOGiAllg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODowNTo0NlrOGiAllg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxNDM5MA==", "bodyText": "Does this need to be removed from the InputFormat class?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438314390", "createdAt": "2020-06-10T18:05:46Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/InputFormatConfig.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr;\n+\n+import java.util.function.Function;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SchemaParser;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.expressions.Expression;\n+\n+public class InputFormatConfig {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzA5MzEw", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428309310", "createdAt": "2020-06-10T18:10:22Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODoxMDoyMlrOGiAvyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODoxMDoyMlrOGiAvyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxNzAwMA==", "bodyText": "Why does this coerce to a URI and get the path? The full path should be used so I don't see a reason to modify it.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438317000", "createdAt": "2020-06-10T18:10:22Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/TableResolver.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.Properties;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+import org.apache.iceberg.mr.InputFormatConfig;\n+\n+final class TableResolver {\n+\n+  private TableResolver() {\n+  }\n+\n+  static Table resolveTableFromJob(JobConf conf) throws IOException {\n+    Properties properties = new Properties();\n+    properties.setProperty(InputFormatConfig.CATALOG_NAME, extractProperty(conf, InputFormatConfig.CATALOG_NAME));\n+    if (conf.get(InputFormatConfig.CATALOG_NAME).equals(InputFormatConfig.HADOOP_CATALOG)) {\n+      properties.setProperty(InputFormatConfig.SNAPSHOT_TABLE, conf.get(InputFormatConfig.SNAPSHOT_TABLE, \"true\"));\n+    }\n+    properties.setProperty(InputFormatConfig.TABLE_LOCATION, extractProperty(conf, InputFormatConfig.TABLE_LOCATION));\n+    properties.setProperty(InputFormatConfig.TABLE_NAME, extractProperty(conf, InputFormatConfig.TABLE_NAME));\n+    return resolveTableFromConfiguration(conf, properties);\n+  }\n+\n+  static Table resolveTableFromConfiguration(Configuration conf, Properties properties) throws IOException {\n+    String catalogName = properties.getProperty(InputFormatConfig.CATALOG_NAME);\n+    URI tableLocation = pathAsURI(properties.getProperty(InputFormatConfig.TABLE_LOCATION));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzEwMjY1", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428310265", "createdAt": "2020-06-10T18:11:43Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODoxMTo0NFrOGiAyyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODoxMTo0NFrOGiAyyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxNzc3MQ==", "bodyText": "I think the warehouse path should be passed separately, possibly as table properties but maybe just defaulting to the Hive warehouse path. It doesn't make sense to me to pass a full URI and then use HadoopCatalog instead of HadoopTables, which handles tables at a specific path. There is no benefit to HadoopCatalog if you have the full table location.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438317771", "createdAt": "2020-06-10T18:11:44Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/TableResolver.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.Properties;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+import org.apache.iceberg.mr.InputFormatConfig;\n+\n+final class TableResolver {\n+\n+  private TableResolver() {\n+  }\n+\n+  static Table resolveTableFromJob(JobConf conf) throws IOException {\n+    Properties properties = new Properties();\n+    properties.setProperty(InputFormatConfig.CATALOG_NAME, extractProperty(conf, InputFormatConfig.CATALOG_NAME));\n+    if (conf.get(InputFormatConfig.CATALOG_NAME).equals(InputFormatConfig.HADOOP_CATALOG)) {\n+      properties.setProperty(InputFormatConfig.SNAPSHOT_TABLE, conf.get(InputFormatConfig.SNAPSHOT_TABLE, \"true\"));\n+    }\n+    properties.setProperty(InputFormatConfig.TABLE_LOCATION, extractProperty(conf, InputFormatConfig.TABLE_LOCATION));\n+    properties.setProperty(InputFormatConfig.TABLE_NAME, extractProperty(conf, InputFormatConfig.TABLE_NAME));\n+    return resolveTableFromConfiguration(conf, properties);\n+  }\n+\n+  static Table resolveTableFromConfiguration(Configuration conf, Properties properties) throws IOException {\n+    String catalogName = properties.getProperty(InputFormatConfig.CATALOG_NAME);\n+    URI tableLocation = pathAsURI(properties.getProperty(InputFormatConfig.TABLE_LOCATION));\n+    if (catalogName == null) {\n+      throw new IllegalArgumentException(\"Catalog property: 'iceberg.catalog' not set in JobConf\");\n+    }\n+    switch (catalogName) {\n+      case InputFormatConfig.HADOOP_TABLES:\n+        HadoopTables tables = new HadoopTables(conf);\n+        return tables.load(tableLocation.getPath());\n+      case InputFormatConfig.HADOOP_CATALOG:\n+        String tableName = properties.getProperty(InputFormatConfig.TABLE_NAME);\n+        TableIdentifier id = TableIdentifier.parse(tableName);\n+        if (tableName.endsWith(InputFormatConfig.SNAPSHOT_TABLE_SUFFIX)) {\n+          if (!Boolean.parseBoolean(properties.getProperty(InputFormatConfig.SNAPSHOT_TABLE,\n+                  Boolean.TRUE.toString()))) {\n+            String tablePath = id.toString().replaceAll(\"\\\\.\", \"/\");\n+            URI warehouseLocation = pathAsURI(tableLocation.getPath().replaceAll(tablePath, \"\"));\n+            HadoopCatalog catalog = new HadoopCatalog(conf, warehouseLocation.getPath());\n+            return catalog.loadTable(id);\n+          } else {\n+            return resolveMetadataTable(conf, tableLocation.getPath(), tableName);\n+          }\n+        } else {\n+          URI warehouseLocation = pathAsURI(extractWarehousePath(tableLocation.getPath(), tableName));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzEwNjIx", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-428310621", "createdAt": "2020-06-10T18:12:13Z", "commit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODoxMjoxM1rOGiAz9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxODoxMjoxM1rOGiAz9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxODA2OQ==", "bodyText": "How are the db and table name passed?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r438318069", "createdAt": "2020-06-10T18:12:13Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/TableResolver.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.Properties;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+import org.apache.iceberg.mr.InputFormatConfig;\n+\n+final class TableResolver {\n+\n+  private TableResolver() {\n+  }\n+\n+  static Table resolveTableFromJob(JobConf conf) throws IOException {\n+    Properties properties = new Properties();\n+    properties.setProperty(InputFormatConfig.CATALOG_NAME, extractProperty(conf, InputFormatConfig.CATALOG_NAME));\n+    if (conf.get(InputFormatConfig.CATALOG_NAME).equals(InputFormatConfig.HADOOP_CATALOG)) {\n+      properties.setProperty(InputFormatConfig.SNAPSHOT_TABLE, conf.get(InputFormatConfig.SNAPSHOT_TABLE, \"true\"));\n+    }\n+    properties.setProperty(InputFormatConfig.TABLE_LOCATION, extractProperty(conf, InputFormatConfig.TABLE_LOCATION));\n+    properties.setProperty(InputFormatConfig.TABLE_NAME, extractProperty(conf, InputFormatConfig.TABLE_NAME));\n+    return resolveTableFromConfiguration(conf, properties);\n+  }\n+\n+  static Table resolveTableFromConfiguration(Configuration conf, Properties properties) throws IOException {\n+    String catalogName = properties.getProperty(InputFormatConfig.CATALOG_NAME);\n+    URI tableLocation = pathAsURI(properties.getProperty(InputFormatConfig.TABLE_LOCATION));\n+    if (catalogName == null) {\n+      throw new IllegalArgumentException(\"Catalog property: 'iceberg.catalog' not set in JobConf\");\n+    }\n+    switch (catalogName) {\n+      case InputFormatConfig.HADOOP_TABLES:\n+        HadoopTables tables = new HadoopTables(conf);\n+        return tables.load(tableLocation.getPath());\n+      case InputFormatConfig.HADOOP_CATALOG:\n+        String tableName = properties.getProperty(InputFormatConfig.TABLE_NAME);\n+        TableIdentifier id = TableIdentifier.parse(tableName);\n+        if (tableName.endsWith(InputFormatConfig.SNAPSHOT_TABLE_SUFFIX)) {\n+          if (!Boolean.parseBoolean(properties.getProperty(InputFormatConfig.SNAPSHOT_TABLE,\n+                  Boolean.TRUE.toString()))) {\n+            String tablePath = id.toString().replaceAll(\"\\\\.\", \"/\");\n+            URI warehouseLocation = pathAsURI(tableLocation.getPath().replaceAll(tablePath, \"\"));\n+            HadoopCatalog catalog = new HadoopCatalog(conf, warehouseLocation.getPath());\n+            return catalog.loadTable(id);\n+          } else {\n+            return resolveMetadataTable(conf, tableLocation.getPath(), tableName);\n+          }\n+        } else {\n+          URI warehouseLocation = pathAsURI(extractWarehousePath(tableLocation.getPath(), tableName));\n+          HadoopCatalog catalog = new HadoopCatalog(conf, warehouseLocation.getPath());\n+          return catalog.loadTable(id);\n+        }\n+      case InputFormatConfig.HIVE_CATALOG:\n+        //TODO Implement HiveCatalog", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 80}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4ccfd7b996c68fb4ad82d7351c244baa43b4856", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/e4ccfd7b996c68fb4ad82d7351c244baa43b4856", "committedDate": "2020-06-11T16:52:08Z", "message": "Fix date/time types, address format comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI5MTk4MDY3", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-429198067", "createdAt": "2020-06-11T18:55:02Z", "commit": {"oid": "e4ccfd7b996c68fb4ad82d7351c244baa43b4856"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQxODo1NTowM1rOGiqlzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQxOTowMDoxMlrOGiqwTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTAwMjU3NA==", "bodyText": "There's actually no need to return anything other the Record object. Hive relies on the ObjectInspector class to retrieve values from arbitrary data structures and convert those values to the classes Hive expects.\nYou may want to take a look at https://cwiki.apache.org/confluence/display/Hive/DeveloperGuide#DeveloperGuide-ObjectInspector and then read the implementation of a few object inspectors in the Hive codebase.\nSo all we have to do here is return the Record object and ensure we have the right object inspectors for the Record class and other data types that are not represented in the same fashion in Iceberg vs. Hive.\nAs a matter of fact, I started working on an object inspector for the Record class last year. Why don't I submit a PR on top off this one to get you started?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r439002574", "createdAt": "2020-06-11T18:55:03Z", "author": {"login": "guilload"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSerDe.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import javax.annotation.Nullable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde2.AbstractSerDe;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.SerDeStats;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SnapshotsTable;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class IcebergSerDe extends AbstractSerDe {\n+\n+  private Schema schema;\n+  private ObjectInspector inspector;\n+  private List<Object> row;\n+\n+  @Override\n+  public void initialize(@Nullable Configuration configuration, Properties serDeProperties) throws SerDeException {\n+    Table table = null;\n+    try {\n+      table = TableResolver.resolveTableFromConfiguration(configuration, serDeProperties);\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(\"Unable to resolve table from configuration: \", e);\n+    }\n+    this.schema = table.schema();\n+    if (table instanceof SnapshotsTable) {\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(schema);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    } else {\n+      List<Types.NestedField> columns = new ArrayList<>(schema.columns());\n+      columns.add(Types.NestedField.optional(Integer.MAX_VALUE,\n+          SystemTableUtil.snapshotIdVirtualColumnName(serDeProperties), Types.LongType.get()));\n+      Schema withVirtualColumn = new Schema(columns);\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(withVirtualColumn);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public Class<? extends Writable> getSerializedClass() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Writable serialize(Object o, ObjectInspector objectInspector) {\n+    return null;\n+  }\n+\n+  @Override\n+  public SerDeStats getSerDeStats() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Object deserialize(Writable writable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ccfd7b996c68fb4ad82d7351c244baa43b4856"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTAwMzk0OA==", "bodyText": "See this is where object inspectors come in handy, they'll take care of the conversion for us. Plus, you can clearly see that this current approach won't work for nested data structures.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r439003948", "createdAt": "2020-06-11T18:57:37Z", "author": {"login": "guilload"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSerDe.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import javax.annotation.Nullable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde2.AbstractSerDe;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.SerDeStats;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SnapshotsTable;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class IcebergSerDe extends AbstractSerDe {\n+\n+  private Schema schema;\n+  private ObjectInspector inspector;\n+  private List<Object> row;\n+\n+  @Override\n+  public void initialize(@Nullable Configuration configuration, Properties serDeProperties) throws SerDeException {\n+    Table table = null;\n+    try {\n+      table = TableResolver.resolveTableFromConfiguration(configuration, serDeProperties);\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(\"Unable to resolve table from configuration: \", e);\n+    }\n+    this.schema = table.schema();\n+    if (table instanceof SnapshotsTable) {\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(schema);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    } else {\n+      List<Types.NestedField> columns = new ArrayList<>(schema.columns());\n+      columns.add(Types.NestedField.optional(Integer.MAX_VALUE,\n+          SystemTableUtil.snapshotIdVirtualColumnName(serDeProperties), Types.LongType.get()));\n+      Schema withVirtualColumn = new Schema(columns);\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(withVirtualColumn);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public Class<? extends Writable> getSerializedClass() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Writable serialize(Object o, ObjectInspector objectInspector) {\n+    return null;\n+  }\n+\n+  @Override\n+  public SerDeStats getSerDeStats() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Object deserialize(Writable writable) {\n+    IcebergWritable icebergWritable = (IcebergWritable) writable;\n+    List<Types.NestedField> fields = icebergWritable.schema().columns();\n+\n+    if (row == null || row.size() != fields.size()) {\n+      row = new ArrayList<Object>(fields.size());\n+    } else {\n+      row.clear();\n+    }\n+    for (int i = 0; i < fields.size(); i++) {\n+      Object obj = ((IcebergWritable) writable).record().get(i);\n+      Type fieldType = fields.get(i).type();\n+      if (fieldType.equals(Types.DateType.get())) {\n+        row.add(Date.valueOf((LocalDate) obj));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ccfd7b996c68fb4ad82d7351c244baa43b4856"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTAwNTI2MA==", "bodyText": "I already have a type visitor somewhere from Schema to ObjectInspector. I can also submit that one on my PR so you can focus on the remaining things to do.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r439005260", "createdAt": "2020-06-11T19:00:12Z", "author": {"login": "guilload"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+/**\n+ * Class to convert Iceberg types to Hive TypeInfo\n+ */\n+final class IcebergSchemaToTypeInfo {\n+\n+  private IcebergSchemaToTypeInfo() {\n+\n+  }\n+\n+  private static final ImmutableMap<Object, Object> primitiveTypeToTypeInfo = ImmutableMap.builder()\n+      .put(Types.BooleanType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BOOLEAN_TYPE_NAME))\n+      .put(Types.IntegerType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.INT_TYPE_NAME))\n+      .put(Types.LongType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.FloatType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.FLOAT_TYPE_NAME))\n+      .put(Types.DoubleType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DOUBLE_TYPE_NAME))\n+      .put(Types.BinaryType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME))\n+      .put(Types.StringType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME))\n+      .put(Types.DateType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DATE_TYPE_NAME))\n+      .put(Types.TimestampType.withoutZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.TimestampType.withZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .build();\n+\n+  public static List<TypeInfo> getColumnTypes(Schema schema) throws Exception {\n+    List<Types.NestedField> fields = schema.columns();\n+    List<TypeInfo> types = new ArrayList<>(fields.size());\n+    for (Types.NestedField field : fields) {\n+      types.add(generateTypeInfo(field.type()));\n+    }\n+    return types;\n+  }\n+\n+  private static TypeInfo generateTypeInfo(Type type) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwMDM4NQ=="}, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI5NDQxMTgy", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-429441182", "createdAt": "2020-06-12T03:40:49Z", "commit": {"oid": "e4ccfd7b996c68fb4ad82d7351c244baa43b4856"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzo0MDo0OVrOGi2CJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzo1MToyMlrOGi2LnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE5MDA1NA==", "bodyText": "Maybe this can be a visitor?  We recently built a visitor the other way round Hive -> Iceberg. https://github.com/linkedin/iceberg/blob/master/hive/src/main/java/org/apache/iceberg/hive/legacy/HiveTypeToIcebergType.java", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r439190054", "createdAt": "2020-06-12T03:40:49Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergObjectInspectorGenerator.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+\n+class IcebergObjectInspectorGenerator {\n+\n+  protected ObjectInspector createObjectInspector(Schema schema) throws Exception {\n+    List<String> columnNames = setColumnNames(schema);\n+    List<TypeInfo> columnTypes = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    List<ObjectInspector> columnOIs = new ArrayList<>(columnTypes.size());\n+    for (int i = 0; i < columnTypes.size(); i++) {\n+      columnOIs.add(createObjectInspectorWorker(columnTypes.get(i)));\n+    }\n+    return ObjectInspectorFactory.getStandardStructObjectInspector(columnNames, columnOIs, null);\n+  }\n+\n+  protected ObjectInspector createObjectInspectorWorker(TypeInfo typeInfo) throws Exception {\n+    ObjectInspector.Category typeCategory = typeInfo.getCategory();\n+\n+    switch (typeCategory) {\n+      case PRIMITIVE:\n+        PrimitiveTypeInfo pti = (PrimitiveTypeInfo) typeInfo;\n+        return PrimitiveObjectInspectorFactory.getPrimitiveJavaObjectInspector(pti);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxMzk3OA=="}, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE5MDM1MQ==", "bodyText": "Yea +1 for a visitor. We have TypeInfo to Iceberg Type visitor for inspiration https://github.com/linkedin/iceberg/blob/master/hive/src/main/java/org/apache/iceberg/hive/legacy/HiveTypeToIcebergType.java", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r439190351", "createdAt": "2020-06-12T03:42:12Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSchemaToTypeInfo.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+/**\n+ * Class to convert Iceberg types to Hive TypeInfo\n+ */\n+final class IcebergSchemaToTypeInfo {\n+\n+  private IcebergSchemaToTypeInfo() {\n+\n+  }\n+\n+  private static final ImmutableMap<Object, Object> primitiveTypeToTypeInfo = ImmutableMap.builder()\n+      .put(Types.BooleanType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BOOLEAN_TYPE_NAME))\n+      .put(Types.IntegerType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.INT_TYPE_NAME))\n+      .put(Types.LongType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.FloatType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.FLOAT_TYPE_NAME))\n+      .put(Types.DoubleType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DOUBLE_TYPE_NAME))\n+      .put(Types.BinaryType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BINARY_TYPE_NAME))\n+      .put(Types.StringType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.STRING_TYPE_NAME))\n+      .put(Types.DateType.get(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.DATE_TYPE_NAME))\n+      .put(Types.TimestampType.withoutZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .put(Types.TimestampType.withZone(), TypeInfoFactory.getPrimitiveTypeInfo(serdeConstants.BIGINT_TYPE_NAME))\n+      .build();\n+\n+  public static List<TypeInfo> getColumnTypes(Schema schema) throws Exception {\n+    List<Types.NestedField> fields = schema.columns();\n+    List<TypeInfo> types = new ArrayList<>(fields.size());\n+    for (Types.NestedField field : fields) {\n+      types.add(generateTypeInfo(field.type()));\n+    }\n+    return types;\n+  }\n+\n+  private static TypeInfo generateTypeInfo(Type type) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwMDM4NQ=="}, "originalCommit": {"oid": "c0cec1786f33ae4dafe46e0aa8be61e5acebea4e"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE5MDc3OA==", "bodyText": "throw Unsupported?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r439190778", "createdAt": "2020-06-12T03:43:47Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSerDe.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import javax.annotation.Nullable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde2.AbstractSerDe;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.SerDeStats;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SnapshotsTable;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class IcebergSerDe extends AbstractSerDe {\n+\n+  private Schema schema;\n+  private ObjectInspector inspector;\n+  private List<Object> row;\n+\n+  @Override\n+  public void initialize(@Nullable Configuration configuration, Properties serDeProperties) throws SerDeException {\n+    Table table = null;\n+    try {\n+      table = TableResolver.resolveTableFromConfiguration(configuration, serDeProperties);\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(\"Unable to resolve table from configuration: \", e);\n+    }\n+    this.schema = table.schema();\n+    if (table instanceof SnapshotsTable) {\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(schema);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    } else {\n+      List<Types.NestedField> columns = new ArrayList<>(schema.columns());\n+      columns.add(Types.NestedField.optional(Integer.MAX_VALUE,\n+          SystemTableUtil.snapshotIdVirtualColumnName(serDeProperties), Types.LongType.get()));\n+      Schema withVirtualColumn = new Schema(columns);\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(withVirtualColumn);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public Class<? extends Writable> getSerializedClass() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Writable serialize(Object o, ObjectInspector objectInspector) {\n+    return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ccfd7b996c68fb4ad82d7351c244baa43b4856"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE5MTI4NQ==", "bodyText": "+1. We should build this similar to reader Funcs. Please see examples of this in Spark module org.apache.iceberg.spark.data.SparkValueReaders [for Avro] and org.apache.iceberg.spark.data.SparkOrcValueReaders", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r439191285", "createdAt": "2020-06-12T03:45:55Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSerDe.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import javax.annotation.Nullable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde2.AbstractSerDe;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.SerDeStats;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SnapshotsTable;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class IcebergSerDe extends AbstractSerDe {\n+\n+  private Schema schema;\n+  private ObjectInspector inspector;\n+  private List<Object> row;\n+\n+  @Override\n+  public void initialize(@Nullable Configuration configuration, Properties serDeProperties) throws SerDeException {\n+    Table table = null;\n+    try {\n+      table = TableResolver.resolveTableFromConfiguration(configuration, serDeProperties);\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(\"Unable to resolve table from configuration: \", e);\n+    }\n+    this.schema = table.schema();\n+    if (table instanceof SnapshotsTable) {\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(schema);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    } else {\n+      List<Types.NestedField> columns = new ArrayList<>(schema.columns());\n+      columns.add(Types.NestedField.optional(Integer.MAX_VALUE,\n+          SystemTableUtil.snapshotIdVirtualColumnName(serDeProperties), Types.LongType.get()));\n+      Schema withVirtualColumn = new Schema(columns);\n+      try {\n+        this.inspector = new IcebergObjectInspectorGenerator().createObjectInspector(withVirtualColumn);\n+      } catch (Exception e) {\n+        throw new SerDeException(e);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public Class<? extends Writable> getSerializedClass() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Writable serialize(Object o, ObjectInspector objectInspector) {\n+    return null;\n+  }\n+\n+  @Override\n+  public SerDeStats getSerDeStats() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Object deserialize(Writable writable) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTAwMjU3NA=="}, "originalCommit": {"oid": "e4ccfd7b996c68fb4ad82d7351c244baa43b4856"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE5MjQ3Nw==", "bodyText": "@cmathiesen @rdblue . Do u folks see value in having Hive classes in a separate hive  module instead of MR?  Similar to Iceberg Pig ? I think we need to provide a reader func implementation for Hive to be used with the MR module", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r439192477", "createdAt": "2020-06-12T03:51:22Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSerDe.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import javax.annotation.Nullable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde2.AbstractSerDe;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.SerDeStats;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SnapshotsTable;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class IcebergSerDe extends AbstractSerDe {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ccfd7b996c68fb4ad82d7351c244baa43b4856"}, "originalPosition": 47}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eecb8336d66c3922e2b37552be35418abce5dd0b", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/eecb8336d66c3922e2b37552be35418abce5dd0b", "committedDate": "2020-06-12T13:47:55Z", "message": "Remove HadoopCatalog, clean up SerDe and tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwMDU3Njgy", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-430057682", "createdAt": "2020-06-12T21:56:15Z", "commit": {"oid": "eecb8336d66c3922e2b37552be35418abce5dd0b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQyMTo1NjoxNlrOGjSmUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQyMTo1NjoxNlrOGjSmUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTY1ODA2NQ==", "bodyText": "According to https://github.com/ExpediaGroup/hiveberg/blob/master/README.md#time-travel-and-system-tables it seems like to access a snapshot metadata table, we need to create a new table which ends in __snapshots. Instead of that, can we rather let the user create a table with any name but put the metadata table name as part of the location instead.\nCREATE TABLE source_db.table_a_snapshot_metadata_table\n  STORED BY 'com.expediagroup.hiveberg.IcebergStorageHandler'\n  LOCATION 'path_to_original_data_table#snapshots'\n    TBLPROPERTIES ('iceberg.catalog'='hadoop.catalog')\n\nThat way,\n\nYou don't need to reserve a table suffix\nYou don't need flags like iceberg.snapshots.table=false\nTableResolver code is also simplified as it does not need to understand the syntax for metadata tables in different catalogs. e.g. HadoopTables uses #snapshots, HiveCatalog uses .snapshots. It simply has to pass the location as-is to the catalog.\nIt will also be able to handle other metadata tables, like partitions, manifest, entries, etc. without any additional handling.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r439658065", "createdAt": "2020-06-12T21:56:16Z", "author": {"login": "shardulm94"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/TableResolver.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+import org.apache.iceberg.mr.InputFormatConfig;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+\n+final class TableResolver {\n+\n+  private TableResolver() {\n+  }\n+\n+  static Table resolveTableFromJob(JobConf conf) throws IOException {\n+    Properties properties = new Properties();\n+    properties.setProperty(InputFormatConfig.CATALOG_NAME,\n+        conf.get(InputFormatConfig.CATALOG_NAME, InputFormatConfig.HADOOP_TABLES)); //Default to HadoopTables\n+    properties.setProperty(InputFormatConfig.SNAPSHOT_TABLE,\n+        conf.get(InputFormatConfig.SNAPSHOT_TABLE, \"true\"));\n+    properties.setProperty(InputFormatConfig.TABLE_LOCATION, extractProperty(conf, InputFormatConfig.TABLE_LOCATION));\n+    properties.setProperty(InputFormatConfig.TABLE_NAME, extractProperty(conf, InputFormatConfig.TABLE_NAME));\n+    return resolveTableFromConfiguration(conf, properties);\n+  }\n+\n+  static Table resolveTableFromConfiguration(Configuration conf, Properties properties) throws IOException {\n+    String catalogName = properties.getProperty(InputFormatConfig.CATALOG_NAME, InputFormatConfig.HADOOP_TABLES);\n+    String tableLocation = properties.getProperty(InputFormatConfig.TABLE_LOCATION);\n+    String tableName = properties.getProperty(InputFormatConfig.TABLE_NAME);\n+    Preconditions.checkNotNull(tableLocation, \"Table location is not set.\");\n+    Preconditions.checkNotNull(tableName, \"Table name is not set.\");\n+    switch (catalogName) {\n+      case InputFormatConfig.HADOOP_TABLES:\n+        HadoopTables tables = new HadoopTables(conf);\n+        if (tableName.endsWith(InputFormatConfig.SNAPSHOT_TABLE_SUFFIX)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eecb8336d66c3922e2b37552be35418abce5dd0b"}, "originalPosition": 57}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2350025f11bf3ce6df226d21a87d5c403ab50b53", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/2350025f11bf3ce6df226d21a87d5c403ab50b53", "committedDate": "2020-06-15T12:36:50Z", "message": "refactored code from IcebergInputFormat into InputFormatConfig"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwODM4MjQ0", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-430838244", "createdAt": "2020-06-15T17:12:20Z", "commit": {"oid": "2350025f11bf3ce6df226d21a87d5c403ab50b53"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxNzoxMjoyMFrOGj7R8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxNzoxMjoyMFrOGj7R8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDMyNDU5NQ==", "bodyText": "Seems like this class is shared by both mrv2 and mrv1 apis, similar to InputFormatConfig. We should have a consistent package name there..", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r440324595", "createdAt": "2020-06-15T17:12:20Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/TableResolver.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2350025f11bf3ce6df226d21a87d5c403ab50b53"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNTc2Njky", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-431576692", "createdAt": "2020-06-16T14:40:19Z", "commit": {"oid": "2350025f11bf3ce6df226d21a87d5c403ab50b53"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNDo0MDoxOVrOGkepyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNDo0MDoxOVrOGkepyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkwNDEzOQ==", "bodyText": "nit: maybe just rename this to columnNames.  Also why is this protected , seems like it can static like its counterpart in IcebergSchemaToTypeInfo", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r440904139", "createdAt": "2020-06-16T14:40:19Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergObjectInspectorGenerator.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+\n+class IcebergObjectInspectorGenerator {\n+\n+  protected ObjectInspector createObjectInspector(Schema schema) throws Exception {\n+    List<String> columnNames = setColumnNames(schema);\n+    List<TypeInfo> columnTypes = IcebergSchemaToTypeInfo.getColumnTypes(schema);\n+\n+    List<ObjectInspector> columnOIs = new ArrayList<>(columnTypes.size());\n+    for (int i = 0; i < columnTypes.size(); i++) {\n+      columnOIs.add(createObjectInspectorWorker(columnTypes.get(i)));\n+    }\n+    return ObjectInspectorFactory.getStandardStructObjectInspector(columnNames, columnOIs, null);\n+  }\n+\n+  protected ObjectInspector createObjectInspectorWorker(TypeInfo typeInfo) throws Exception {\n+    ObjectInspector.Category typeCategory = typeInfo.getCategory();\n+\n+    switch (typeCategory) {\n+      case PRIMITIVE:\n+        PrimitiveTypeInfo pti = (PrimitiveTypeInfo) typeInfo;\n+        return PrimitiveObjectInspectorFactory.getPrimitiveJavaObjectInspector(pti);\n+      case LIST:\n+        ListTypeInfo ati = (ListTypeInfo) typeInfo;\n+        return ObjectInspectorFactory\n+            .getStandardListObjectInspector(createObjectInspectorWorker(ati.getListElementTypeInfo()));\n+      case MAP:\n+        MapTypeInfo mti = (MapTypeInfo) typeInfo;\n+        return ObjectInspectorFactory.getStandardMapObjectInspector(\n+            createObjectInspectorWorker(mti.getMapKeyTypeInfo()),\n+            createObjectInspectorWorker(mti.getMapValueTypeInfo()));\n+      case STRUCT:\n+        StructTypeInfo sti = (StructTypeInfo) typeInfo;\n+        List<ObjectInspector> ois = new ArrayList<>(sti.getAllStructFieldTypeInfos().size());\n+        for (TypeInfo structTypeInfos : sti.getAllStructFieldTypeInfos()) {\n+          ois.add(createObjectInspectorWorker(structTypeInfos));\n+        }\n+        return ObjectInspectorFactory.getStandardStructObjectInspector(sti.getAllStructFieldNames(), ois);\n+      default:\n+        throw new SerDeException(\"Couldn't create Object Inspector for category: '\" + typeCategory + \"'\");\n+    }\n+  }\n+\n+  protected List<String> setColumnNames(Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2350025f11bf3ce6df226d21a87d5c403ab50b53"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxOTc2MzA5", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-431976309", "createdAt": "2020-06-17T00:20:03Z", "commit": {"oid": "2350025f11bf3ce6df226d21a87d5c403ab50b53"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMDoyMDowNFrOGkxbNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMDoyMDowNFrOGkxbNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIxMTcwMg==", "bodyText": "I think the indentation was correct before. Can you revert this?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r441211702", "createdAt": "2020-06-17T00:20:04Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapreduce/IcebergInputFormat.java", "diffHunk": "@@ -265,9 +158,9 @@ private static void checkResiduals(CombinedScanTask task) {\n       Expression residual = fileScanTask.residual();\n       if (residual != null && !residual.equals(Expressions.alwaysTrue())) {\n         throw new UnsupportedOperationException(\n-            String.format(\n-                \"Filter expression %s is not completely satisfied. Additional rows \" +\n-                    \"can be returned not satisfied by the filter expression\", residual));\n+                String.format(\n+                        \"Filter expression %s is not completely satisfied. Additional rows \" +\n+                                \"can be returned not satisfied by the filter expression\", residual));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2350025f11bf3ce6df226d21a87d5c403ab50b53"}, "originalPosition": 202}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxOTc2NTE4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-431976518", "createdAt": "2020-06-17T00:20:46Z", "commit": {"oid": "2350025f11bf3ce6df226d21a87d5c403ab50b53"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMDoyMDo0NlrOGkxb9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMDoyMDo0NlrOGkxb9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIxMTg5Mg==", "bodyText": "Can you revert the whitespace-only changes in this file? Otherwise this is going to have more conflicts than necessary.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r441211892", "createdAt": "2020-06-17T00:20:46Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapreduce/IcebergInputFormat.java", "diffHunk": "@@ -517,20 +411,20 @@ private Record withIdentityPartitionColumns(\n   }\n \n   private static Table findTable(Configuration conf) {\n-    String path = conf.get(TABLE_PATH);\n+    String path = conf.get(InputFormatConfig.TABLE_PATH);\n     Preconditions.checkArgument(path != null, \"Table path should not be null\");\n     if (path.contains(\"/\")) {\n       HadoopTables tables = new HadoopTables(conf);\n       return tables.load(path);\n     }\n \n-    String catalogFuncClass = conf.get(CATALOG);\n+    String catalogFuncClass = conf.get(InputFormatConfig.CATALOG);\n     if (catalogFuncClass != null) {\n       Function<Configuration, Catalog> catalogFunc = (Function<Configuration, Catalog>)\n-          DynConstructors.builder(Function.class)\n-                         .impl(catalogFuncClass)\n-                         .build()\n-                         .newInstance();\n+              DynConstructors.builder(Function.class)\n+                      .impl(catalogFuncClass)\n+                      .build()\n+                      .newInstance();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2350025f11bf3ce6df226d21a87d5c403ab50b53"}, "originalPosition": 361}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abaafb501982052d6849923ccde51b4d7351c377", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/abaafb501982052d6849923ccde51b4d7351c377", "committedDate": "2020-06-17T13:09:32Z", "message": "Remove system tables"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c5b6cd8171aa1d73df7da3cf14ce256c21c57a61", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/c5b6cd8171aa1d73df7da3cf14ce256c21c57a61", "committedDate": "2020-06-17T16:10:50Z", "message": "revert whitespace changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7c5c39387b13c27a44d17e4c5534578763c788a", "author": {"user": {"login": "guilload", "name": "Adrien Guillo"}}, "url": "https://github.com/apache/iceberg/commit/f7c5c39387b13c27a44d17e4c5534578763c788a", "committedDate": "2020-06-26T11:16:03Z", "message": "Refactor IcebergObjectInspector and implement custom object inspectors (#12)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6421ed6b47d5e6d3cbdcf56fe48798c8c815e6a0", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/6421ed6b47d5e6d3cbdcf56fe48798c8c815e6a0", "committedDate": "2020-06-26T12:00:07Z", "message": "Merge branch 'master' into iceberg-serde"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "38e43396763cd7f3d2ba402579555119b5289daa", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/38e43396763cd7f3d2ba402579555119b5289daa", "committedDate": "2020-06-26T12:52:24Z", "message": "fix compiler errors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d", "committedDate": "2020-06-29T14:10:05Z", "message": "tidied up and fleshed out tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NTk3ODY4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-439597868", "createdAt": "2020-06-30T00:58:20Z", "commit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMDo1ODoyMVrOGqnxJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMDo1ODoyMVrOGqnxJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0NDkzNA==", "bodyText": "I didn't realize Java added an UncheckedIOException in 8. We have one that is RuntimeIOException. We should probably convert Iceberg over to using the standard Java one.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r447344934", "createdAt": "2020-06-30T00:58:21Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSerDe.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Properties;\n+import javax.annotation.Nullable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde2.AbstractSerDe;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.SerDeStats;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.io.Writable;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.mr.mapred.serde.objectinspector.IcebergObjectInspector;\n+\n+public class IcebergSerDe extends AbstractSerDe {\n+\n+  private ObjectInspector inspector;\n+\n+  @Override\n+  public void initialize(@Nullable Configuration configuration, Properties serDeProperties) throws SerDeException {\n+    final Table table;\n+\n+    try {\n+      table = TableResolver.resolveTableFromConfiguration(configuration, serDeProperties);\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(\"Unable to resolve table from configuration: \", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NTk5NjM0", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-439599634", "createdAt": "2020-06-30T01:04:25Z", "commit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMTowNDoyNVrOGqn35Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMTowNDoyNVrOGqn35Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0NjY2MQ==", "bodyText": "This isn't correct because it doesn't follow the contract of ByteBuffer. Avro will reuse byte buffers, so there is no guarantee that this array is the correct length. In addition, we want to generally follow the ByteBuffer contract so that we don't need to worry about whether an optimization later (buffer reuse) will break certain sections of code.\nAn easy fix is to use ByteBuffers.toByteArray here.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r447346661", "createdAt": "2020-06-30T01:04:25Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/serde/objectinspector/IcebergBinaryObjectInspector.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred.serde.objectinspector;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Arrays;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.BinaryObjectInspector;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.hadoop.io.BytesWritable;\n+\n+public final class IcebergBinaryObjectInspector extends IcebergPrimitiveObjectInspector\n+                                                implements BinaryObjectInspector {\n+\n+  private static final IcebergBinaryObjectInspector INSTANCE = new IcebergBinaryObjectInspector();\n+\n+  public static IcebergBinaryObjectInspector get() {\n+    return INSTANCE;\n+  }\n+\n+  private IcebergBinaryObjectInspector() {\n+    super(TypeInfoFactory.binaryTypeInfo);\n+  }\n+\n+  @Override\n+  public byte[] getPrimitiveJavaObject(Object o) {\n+    return o == null ? null : ((ByteBuffer) o).array();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NjAxMDM2", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-439601036", "createdAt": "2020-06-30T01:08:52Z", "commit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMTowODo1MlrOGqn9jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMTowODo1MlrOGqn9jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0ODExMQ==", "bodyText": "Couldn't fixed by read as binary? And UUID as string? And doesn't Hive support time?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r447348111", "createdAt": "2020-06-30T01:08:52Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/serde/objectinspector/IcebergObjectInspector.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred.serde.objectinspector;\n+\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.TypeUtil;\n+import org.apache.iceberg.types.Types;\n+\n+public final class IcebergObjectInspector extends TypeUtil.SchemaVisitor<ObjectInspector> {\n+\n+  public static ObjectInspector create(@Nullable Schema schema) {\n+    if (schema == null) {\n+      return IcebergRecordObjectInspector.empty();\n+    }\n+\n+    return TypeUtil.visit(schema, new IcebergObjectInspector());\n+  }\n+\n+  public static ObjectInspector create(Types.NestedField... fields) {\n+    return create(new Schema(fields));\n+  }\n+\n+  @Override\n+  public ObjectInspector field(Types.NestedField field, ObjectInspector fieldObjectInspector) {\n+    return fieldObjectInspector;\n+  }\n+\n+  @Override\n+  public ObjectInspector list(Types.ListType listTypeInfo, ObjectInspector listObjectInspector) {\n+    return ObjectInspectorFactory.getStandardListObjectInspector(listObjectInspector);\n+  }\n+\n+  @Override\n+  public ObjectInspector map(Types.MapType mapType,\n+                             ObjectInspector keyObjectInspector, ObjectInspector valueObjectInspector) {\n+    return ObjectInspectorFactory.getStandardMapObjectInspector(keyObjectInspector, valueObjectInspector);\n+  }\n+\n+  @Override\n+  public ObjectInspector primitive(Type.PrimitiveType primitiveType) {\n+    final PrimitiveTypeInfo primitiveTypeInfo;\n+\n+    switch (primitiveType.typeId()) {\n+      case BINARY:\n+        return IcebergBinaryObjectInspector.get();\n+      case BOOLEAN:\n+        primitiveTypeInfo = TypeInfoFactory.booleanTypeInfo;\n+        break;\n+      case DATE:\n+        return IcebergDateObjectInspector.get();\n+      case DECIMAL:\n+        Types.DecimalType type = (Types.DecimalType) primitiveType;\n+        return IcebergDecimalObjectInspector.get(type.precision(), type.scale());\n+      case DOUBLE:\n+        primitiveTypeInfo = TypeInfoFactory.doubleTypeInfo;\n+        break;\n+      case FLOAT:\n+        primitiveTypeInfo = TypeInfoFactory.floatTypeInfo;\n+        break;\n+      case INTEGER:\n+        primitiveTypeInfo = TypeInfoFactory.intTypeInfo;\n+        break;\n+      case LONG:\n+        primitiveTypeInfo = TypeInfoFactory.longTypeInfo;\n+        break;\n+      case STRING:\n+        primitiveTypeInfo = TypeInfoFactory.stringTypeInfo;\n+        break;\n+      case TIMESTAMP:\n+        boolean adjustToUTC = ((Types.TimestampType) primitiveType).shouldAdjustToUTC();\n+        return IcebergTimestampObjectInspector.get(adjustToUTC);\n+\n+      case FIXED:\n+      case TIME:\n+      case UUID:\n+      default:\n+        throw new IllegalArgumentException(primitiveType.typeId() + \" type is not supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "originalPosition": 102}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NjAyOTY1", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-439602965", "createdAt": "2020-06-30T01:14:58Z", "commit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMToxNDo1OVrOGqoEbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMToxNDo1OVrOGqoEbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0OTg2OA==", "bodyText": "@omalley, is the Iceberg field ID suitable to return as a Hive field ID here?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r447349868", "createdAt": "2020-06-30T01:14:59Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/serde/objectinspector/IcebergRecordObjectInspector.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred.serde.objectinspector;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Types;\n+\n+public final class IcebergRecordObjectInspector extends StructObjectInspector {\n+\n+  private static final IcebergRecordObjectInspector EMPTY =\n+          new IcebergRecordObjectInspector(Types.StructType.of(), Collections.emptyList());\n+\n+  private final List<IcebergRecordStructField> structFields;\n+\n+  public IcebergRecordObjectInspector(Types.StructType structType, List<ObjectInspector> objectInspectors) {\n+    Preconditions.checkArgument(structType.fields().size() == objectInspectors.size());\n+\n+    this.structFields = Lists.newArrayListWithExpectedSize(structType.fields().size());\n+\n+    int position = 0;\n+\n+    for (Types.NestedField field : structType.fields()) {\n+      ObjectInspector oi = objectInspectors.get(position);\n+      IcebergRecordStructField structField = new IcebergRecordStructField(field, oi, position);\n+      structFields.add(structField);\n+      position++;\n+    }\n+  }\n+\n+  public static IcebergRecordObjectInspector empty() {\n+    return EMPTY;\n+  }\n+\n+  @Override\n+  public List<? extends StructField> getAllStructFieldRefs() {\n+    return structFields;\n+  }\n+\n+  @Override\n+  public StructField getStructFieldRef(String name) {\n+    return ObjectInspectorUtils.getStandardStructFieldRef(name, structFields);\n+  }\n+\n+  @Override\n+  public Object getStructFieldData(Object o, StructField structField) {\n+    return ((Record) o).get(((IcebergRecordStructField) structField).position());\n+  }\n+\n+  @Override\n+  public List<Object> getStructFieldsDataAsList(Object o) {\n+    Record record = (Record) o;\n+    return structFields\n+            .stream()\n+            .map(f -> record.get(f.position()))\n+            .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public String getTypeName() {\n+    return ObjectInspectorUtils.getStandardStructTypeName(this);\n+  }\n+\n+  @Override\n+  public Category getCategory() {\n+    return Category.STRUCT;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o) {\n+    if (this == o) {\n+      return true;\n+    }\n+\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+\n+    IcebergRecordObjectInspector that = (IcebergRecordObjectInspector) o;\n+    return structFields.equals(that.structFields);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return structFields.hashCode();\n+  }\n+\n+  private static class IcebergRecordStructField implements StructField {\n+\n+    private final Types.NestedField field;\n+    private final ObjectInspector oi;\n+    private final int position;\n+\n+    IcebergRecordStructField(Types.NestedField field, ObjectInspector oi, int position) {\n+      this.field = field;\n+      this.oi = oi;\n+      this.position = position; // position in the record\n+    }\n+\n+    @Override\n+    public String getFieldName() {\n+      return field.name();\n+    }\n+\n+    @Override\n+    public ObjectInspector getFieldObjectInspector() {\n+      return oi;\n+    }\n+\n+    @Override\n+    public int getFieldID() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "originalPosition": 136}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NjAzMjA0", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-439603204", "createdAt": "2020-06-30T01:15:43Z", "commit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMToxNTo0M1rOGqoFUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMToxNTo0M1rOGqoFUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM1MDA5Ng==", "bodyText": "We typically prefer Objects.hash to this older pattern.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r447350096", "createdAt": "2020-06-30T01:15:43Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/serde/objectinspector/IcebergRecordObjectInspector.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred.serde.objectinspector;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Types;\n+\n+public final class IcebergRecordObjectInspector extends StructObjectInspector {\n+\n+  private static final IcebergRecordObjectInspector EMPTY =\n+          new IcebergRecordObjectInspector(Types.StructType.of(), Collections.emptyList());\n+\n+  private final List<IcebergRecordStructField> structFields;\n+\n+  public IcebergRecordObjectInspector(Types.StructType structType, List<ObjectInspector> objectInspectors) {\n+    Preconditions.checkArgument(structType.fields().size() == objectInspectors.size());\n+\n+    this.structFields = Lists.newArrayListWithExpectedSize(structType.fields().size());\n+\n+    int position = 0;\n+\n+    for (Types.NestedField field : structType.fields()) {\n+      ObjectInspector oi = objectInspectors.get(position);\n+      IcebergRecordStructField structField = new IcebergRecordStructField(field, oi, position);\n+      structFields.add(structField);\n+      position++;\n+    }\n+  }\n+\n+  public static IcebergRecordObjectInspector empty() {\n+    return EMPTY;\n+  }\n+\n+  @Override\n+  public List<? extends StructField> getAllStructFieldRefs() {\n+    return structFields;\n+  }\n+\n+  @Override\n+  public StructField getStructFieldRef(String name) {\n+    return ObjectInspectorUtils.getStandardStructFieldRef(name, structFields);\n+  }\n+\n+  @Override\n+  public Object getStructFieldData(Object o, StructField structField) {\n+    return ((Record) o).get(((IcebergRecordStructField) structField).position());\n+  }\n+\n+  @Override\n+  public List<Object> getStructFieldsDataAsList(Object o) {\n+    Record record = (Record) o;\n+    return structFields\n+            .stream()\n+            .map(f -> record.get(f.position()))\n+            .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public String getTypeName() {\n+    return ObjectInspectorUtils.getStandardStructTypeName(this);\n+  }\n+\n+  @Override\n+  public Category getCategory() {\n+    return Category.STRUCT;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o) {\n+    if (this == o) {\n+      return true;\n+    }\n+\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+\n+    IcebergRecordObjectInspector that = (IcebergRecordObjectInspector) o;\n+    return structFields.equals(that.structFields);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return structFields.hashCode();\n+  }\n+\n+  private static class IcebergRecordStructField implements StructField {\n+\n+    private final Types.NestedField field;\n+    private final ObjectInspector oi;\n+    private final int position;\n+\n+    IcebergRecordStructField(Types.NestedField field, ObjectInspector oi, int position) {\n+      this.field = field;\n+      this.oi = oi;\n+      this.position = position; // position in the record\n+    }\n+\n+    @Override\n+    public String getFieldName() {\n+      return field.name();\n+    }\n+\n+    @Override\n+    public ObjectInspector getFieldObjectInspector() {\n+      return oi;\n+    }\n+\n+    @Override\n+    public int getFieldID() {\n+      return field.fieldId();\n+    }\n+\n+    @Override\n+    public String getFieldComment() {\n+      return field.doc();\n+    }\n+\n+    int position() {\n+      return position;\n+    }\n+\n+    @Override\n+    public boolean equals(Object o) {\n+      if (this == o) {\n+        return true;\n+      }\n+\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+\n+      IcebergRecordStructField that = (IcebergRecordStructField) o;\n+      return field.equals(that.field) && oi.equals(that.oi);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+      return 31 * field.hashCode() + oi.hashCode();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "originalPosition": 165}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NjA0MjQ5", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-439604249", "createdAt": "2020-06-30T01:19:09Z", "commit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMToxOTowOVrOGqoI1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMToxOTowOVrOGqoI1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM1MDk5Nw==", "bodyText": "Minor: It seems like this would be a bit cleaner if the outer class was abstract and these were anonymous classes with an implementation for LocalDateTime convert(Object o) or something similar. Using Function is okay, but seems like it uses functions to avoid normal inheritance.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r447350997", "createdAt": "2020-06-30T01:19:09Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/serde/objectinspector/IcebergTimestampObjectInspector.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred.serde.objectinspector;\n+\n+import java.sql.Timestamp;\n+import java.time.LocalDateTime;\n+import java.time.OffsetDateTime;\n+import java.util.function.Function;\n+import org.apache.hadoop.hive.serde2.io.TimestampWritable;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.TimestampObjectInspector;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+\n+public final class IcebergTimestampObjectInspector extends IcebergPrimitiveObjectInspector\n+        implements TimestampObjectInspector {\n+\n+  private static final IcebergTimestampObjectInspector INSTANCE_WITH_ZONE =\n+          new IcebergTimestampObjectInspector(o -> ((OffsetDateTime) o).toLocalDateTime());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NjE4Mzkx", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-439618391", "createdAt": "2020-06-30T02:04:38Z", "commit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMjowNDozOFrOGqo73A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMjowNDozOFrOGqo73A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM2NDA2MA==", "bodyText": "It would be nice to have more cases in this test suite:\n\nWhen the buffer's limit is less than array().length\nWhen the buffer's arrayOffset is non-zero\nWhen the buffer's position is non-zero", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r447364060", "createdAt": "2020-06-30T02:04:38Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/serde/objectinspector/TestIcebergBinaryObjectInspector.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred.serde.objectinspector;\n+\n+import java.nio.ByteBuffer;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.BinaryObjectInspector;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestIcebergBinaryObjectInspector {\n+\n+  @Test\n+  public void testIcebergBinaryObjectInspector() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NjE5MzI4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-439619328", "createdAt": "2020-06-30T02:07:45Z", "commit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMjowNzo0NVrOGqo_WA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMjowNzo0NVrOGqo_WA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM2NDk1Mg==", "bodyText": "Instead of converting to Date and then wrapping with DateWritable, could we use the DateWritable constructor that accepts an integer? That would be more direct and we could convert using DateTimeUtil.daysFromDate(localDate) that we use elsewhere.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r447364952", "createdAt": "2020-06-30T02:07:45Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/serde/objectinspector/IcebergDateObjectInspector.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred.serde.objectinspector;\n+\n+import java.sql.Date;\n+import java.time.LocalDate;\n+import org.apache.hadoop.hive.serde2.io.DateWritable;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.DateObjectInspector;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n+\n+public final class IcebergDateObjectInspector extends IcebergPrimitiveObjectInspector implements DateObjectInspector {\n+\n+  private static final IcebergDateObjectInspector INSTANCE = new IcebergDateObjectInspector();\n+\n+  public static IcebergDateObjectInspector get() {\n+    return INSTANCE;\n+  }\n+\n+  private IcebergDateObjectInspector() {\n+    super(TypeInfoFactory.dateTypeInfo);\n+  }\n+\n+  @Override\n+  public Date getPrimitiveJavaObject(Object o) {\n+    return o == null ? null : Date.valueOf((LocalDate) o);\n+  }\n+\n+  @Override\n+  public DateWritable getPrimitiveWritableObject(Object o) {\n+    Date date = getPrimitiveJavaObject(o);\n+    return date == null ? null : new DateWritable(date);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3a0cfe243b58719ab5b3b26f0dbd108b3f35c6d"}, "originalPosition": 48}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0d8a1ba24f664fc4c07dd43988b06bb5a886e27", "author": {"user": {"login": "guilload", "name": "Adrien Guillo"}}, "url": "https://github.com/apache/iceberg/commit/f0d8a1ba24f664fc4c07dd43988b06bb5a886e27", "committedDate": "2020-07-01T12:42:27Z", "message": "Fix binary object inspector and handle fixed and UUID types (#13)\n\n* Refactor TestIcebergObjectInspector\r\n* Inherit from AbstractPrimitiveJavaObjectInspector rather than IcebergPrimitiveObjectInspector\r\n* Avoid creating an intermediate Date object\r\n* Fix IcebergRecordStructField.equals\r\n* Use inheritance to implement static Timestamp object inspectors\r\n* Handle UUID type as String\r\n* Handle fixed type as binary (byte array)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de445c4aa7416a21b978b7f448b9d7fde27c7ced", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/de445c4aa7416a21b978b7f448b9d7fde27c7ced", "committedDate": "2020-07-01T13:19:09Z", "message": "throw UnsupportedOperationException instead of returning null"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxMDE5NTQ4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-441019548", "createdAt": "2020-07-01T16:21:23Z", "commit": {"oid": "f0d8a1ba24f664fc4c07dd43988b06bb5a886e27"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoyMToyM1rOGrs1Vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoyMToyM1rOGrs1Vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ3NjUwMg==", "bodyText": "Why was this introduced? It seems like relying on the same execution order between the schema creation and the test methods is brittle.\nI'd prefer to move back to fixed IDs since that's easier to test and more clear in assertions.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r448476502", "createdAt": "2020-07-01T16:21:23Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/serde/objectinspector/TestIcebergObjectInspector.java", "diffHunk": "@@ -38,31 +38,37 @@\n \n public class TestIcebergObjectInspector {\n \n+  private int id = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f0d8a1ba24f664fc4c07dd43988b06bb5a886e27"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxMDIwNjc1", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-441020675", "createdAt": "2020-07-01T16:23:01Z", "commit": {"oid": "de445c4aa7416a21b978b7f448b9d7fde27c7ced"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoyMzowMVrOGrs5Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoyMzowMVrOGrs5Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ3NzQ2Mw==", "bodyText": "We usually prefer using AssertHelpers.assertThrows here, but this is minor since you don't need to check that other state has not been modified after the failure.", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r448477463", "createdAt": "2020-07-01T16:23:01Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/mapred/TestTableResolver.java", "diffHunk": "@@ -111,4 +111,21 @@ public void resolveTableFromPropertiesDefault() throws IOException {\n     Assert.assertEquals(tableLocation.getAbsolutePath(), table.location());\n   }\n \n+  @Test(expected = UnsupportedOperationException.class)\n+  public void resolveTableFromConfigurationHiveCatalog() throws IOException {\n+    Configuration conf = new Configuration();\n+    conf.set(InputFormatConfig.CATALOG_NAME, InputFormatConfig.HIVE_CATALOG);\n+    conf.set(InputFormatConfig.TABLE_NAME, \"table_a\");\n+\n+    TableResolver.resolveTableFromConfiguration(conf);\n+  }\n+\n+  @Test(expected = NullPointerException.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de445c4aa7416a21b978b7f448b9d7fde27c7ced"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxMDQ1MzM4", "url": "https://github.com/apache/iceberg/pull/1103#pullrequestreview-441045338", "createdAt": "2020-07-01T16:57:54Z", "commit": {"oid": "de445c4aa7416a21b978b7f448b9d7fde27c7ced"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjo1Nzo1NFrOGruFDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjo1Nzo1NFrOGruFDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ5NjkwOA==", "bodyText": "can we put the hive classes in org.apache.iceberg.hive ? This is committed, but are you guys ok for this refactor?", "url": "https://github.com/apache/iceberg/pull/1103#discussion_r448496908", "createdAt": "2020-07-01T16:57:54Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/mapred/IcebergSerDe.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.mapred;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de445c4aa7416a21b978b7f448b9d7fde27c7ced"}, "originalPosition": 20}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4508, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}