{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI4NjAwNTUz", "number": 1843, "title": "Support for file paths in SparkCatalogs via HadoopTables", "bodyText": "", "createdAt": "2020-11-27T13:00:27Z", "url": "https://github.com/apache/iceberg/pull/1843", "merged": true, "mergeCommit": {"oid": "f3dc93faece50e174287fbf4d00ffd115a54e179"}, "closed": true, "closedAt": "2020-12-08T22:20:26Z", "author": {"login": "rymurr"}, "timelineItems": {"totalCount": 40, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdhozMDgBqjQwNTMxMTQ3MDg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdrMXaqgFqTU1OTk4MjI2Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "55fc2c6e63c5ac2099b494928b0cdc977ba4b55e", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/55fc2c6e63c5ac2099b494928b0cdc977ba4b55e", "committedDate": "2020-11-27T12:58:00Z", "message": "wip: create and drop support for file paths\n\ncloses #1306"}, "afterCommit": {"oid": "2acf7ffa7fb64dfcd7692f9fd24fa92c4d7ca6aa", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/2acf7ffa7fb64dfcd7692f9fd24fa92c4d7ca6aa", "committedDate": "2020-11-30T17:28:41Z", "message": "fix visibility"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3ee5ce22beeb3eda25f56b5748cde5be2ed42eab", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/3ee5ce22beeb3eda25f56b5748cde5be2ed42eab", "committedDate": "2020-12-01T14:24:11Z", "message": "fix build"}, "afterCommit": {"oid": "d915653ebce5a6cb1c0fe1ff37d735c8dda6868b", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/d915653ebce5a6cb1c0fe1ff37d735c8dda6868b", "committedDate": "2020-12-01T14:24:36Z", "message": "fix build"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMjAyMTA0", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-542202104", "createdAt": "2020-12-01T18:55:45Z", "commit": {"oid": "14fa86f36df62588c98a9fbc9a4a29f797d4f07b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODo1NTo0NVrOH87Pkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODo1NTo0NVrOH87Pkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY0NzI1MQ==", "bodyText": "I think this is okay, but if staging isn't supported then a path identifier should fail instead of going ahead without using the path. Otherwise, this will attempt to create a table in the Iceberg catalog with a crazy name, which would probably fail.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r533647251", "createdAt": "2020-12-01T18:55:45Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -165,6 +179,7 @@ public StagedTable stageCreate(Identifier ident, StructType schema, Transform[]\n                                  Map<String, String> properties) throws TableAlreadyExistsException {\n     Schema icebergSchema = SparkSchemaUtil.convert(schema);\n     try {\n+      // can't stage a hadoop table", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14fa86f36df62588c98a9fbc9a4a29f797d4f07b"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1Mjg4ODc1", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-545288875", "createdAt": "2020-12-04T20:53:26Z", "commit": {"oid": "57685ba7ace1053d6189fa032ee3c9b68984dd50"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMDo1MzoyN1rOH_hoHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMDo1MzoyN1rOH_hoHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjM3MzI3OQ==", "bodyText": "How about isValidLocation?", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536373279", "createdAt": "2020-12-04T20:53:27Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -209,4 +278,35 @@ public void setConf(Configuration conf) {\n   public Configuration getConf() {\n     return conf;\n   }\n+\n+\n+  /**\n+   * Check to see if the location is a potential Hadoop table by checking if its an absolute path on some filesystem.\n+   */\n+  public static boolean isHadoopTable(String location) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57685ba7ace1053d6189fa032ee3c9b68984dd50"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1Mjg5ODgz", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-545289883", "createdAt": "2020-12-04T20:55:13Z", "commit": {"oid": "57685ba7ace1053d6189fa032ee3c9b68984dd50"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMDo1NToxM1rOH_hrew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMDo1NToxM1rOH_hrew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjM3NDEzOQ==", "bodyText": "If this uses a session, then it should be identified when the catalog is created and stored as an instance field. Catalogs are specific to a SQL session, so they should not use the active session except for in initialization. After that, the same session should always be used.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536374139", "createdAt": "2020-12-04T20:55:13Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -132,10 +134,17 @@ protected TableIdentifier buildIdentifier(Identifier identifier) {\n     return TableIdentifier.of(Namespace.of(identifier.namespace()), identifier.name());\n   }\n \n+  private String[] currentNamespace() {\n+    return SparkSession.active().sessionState().catalogManager().currentNamespace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57685ba7ace1053d6189fa032ee3c9b68984dd50"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NjYyNDY5", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-545662469", "createdAt": "2020-12-06T01:31:15Z", "commit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTozMToxNVrOIADk6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTozMToxNVrOIADk6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTUxMw==", "bodyText": "This should throw an exception if it can't rename, right?", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536929513", "createdAt": "2020-12-06T01:31:15Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -257,6 +317,7 @@ public boolean dropTable(Identifier ident) {\n   @Override\n   public void renameTable(Identifier from, Identifier to) throws NoSuchTableException, TableAlreadyExistsException {\n     try {\n+      // can't rename hadoop tables", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "originalPosition": 191}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NjYyNTA3", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-545662507", "createdAt": "2020-12-06T01:31:52Z", "commit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTozMTo1MlrOIADlYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTozMTo1MlrOIADlYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTYzNA==", "bodyText": "There should also be no way to pass a path as a namespace.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536929634", "createdAt": "2020-12-06T01:31:52Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -268,14 +329,19 @@ public void renameTable(Identifier from, Identifier to) throws NoSuchTableExcept\n   @Override\n   public void invalidateTable(Identifier ident) {\n     try {\n-      icebergCatalog.loadTable(buildIdentifier(ident)).refresh();\n+      TableIdentifier tableIdentifier = buildIdentifier(ident);\n+      Table table = isPathIdentifier(ident) ?\n+          tables.load(tableIdentifier.name()) :\n+          icebergCatalog.loadTable(tableIdentifier);\n+      table.refresh();\n     } catch (org.apache.iceberg.exceptions.NoSuchTableException ignored) {\n       // ignore if the table doesn't exist, it is not cached\n     }\n   }\n \n   @Override\n   public Identifier[] listTables(String[] namespace) {\n+    // no way to identify if this is a path and we should use tables instead of catalog.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "originalPosition": 212}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NjYyNTIw", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-545662520", "createdAt": "2020-12-06T01:32:02Z", "commit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTozMjowM1rOIADlhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTozMjowM1rOIADlhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTY2OQ==", "bodyText": "Nit: unnecessary newline.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536929669", "createdAt": "2020-12-06T01:32:03Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -453,4 +520,5 @@ private static void commitChanges(Table table, SetProperty setLocation, SetPrope\n \n     transaction.commitTransaction();\n   }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "originalPosition": 228}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NjYyOTI0", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-545662924", "createdAt": "2020-12-06T01:40:29Z", "commit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTo0MDozMFrOIADqGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTo0MDozMFrOIADqGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMDg0MA==", "bodyText": "Can this use TableBuilder instead? That would make the SparkCatalog implementation a lot cleaner because the code to configure the builder could be shared.\nI opened #1879 because tests would fail unless the builder is also supported in CachingCatalog.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536930840", "createdAt": "2020-12-06T01:40:30Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -200,6 +197,76 @@ TableOperations newTableOps(String location) {\n     }\n   }\n \n+  private TableMetadata tableMetadata(Schema schema, PartitionSpec spec, SortOrder order,\n+                                      Map<String, String> properties, String location) {\n+    Preconditions.checkNotNull(schema, \"A table schema is required\");\n+\n+    Map<String, String> tableProps = properties == null ? ImmutableMap.of() : properties;\n+    PartitionSpec partitionSpec = spec == null ? PartitionSpec.unpartitioned() : spec;\n+    SortOrder sortOrder = order == null ? SortOrder.unsorted() : order;\n+    return TableMetadata.newTableMetadata(schema, partitionSpec, sortOrder, location, tableProps);\n+  }\n+\n+  /**\n+   * Start a transaction to create a table.\n+   *\n+   * @param identifier a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @return a {@link Transaction} to create the table\n+   * @throws AlreadyExistsException if the table already exists\n+   */\n+  public Transaction newCreateTableTransaction(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NjYzMTM1", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-545663135", "createdAt": "2020-12-06T01:45:13Z", "commit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTo0NToxM1rOIADsvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTo0NToxM1rOIADsvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTUxNg==", "bodyText": "I think that the namespace should be the location, not an array of path parts. This would create really weird namespaces, like [\"s3:\", \"\", \"bucket\", \"path\", \"to\"].", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536931516", "createdAt": "2020-12-06T01:45:13Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/PathIdentifier.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.util.List;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+\n+public class PathIdentifier implements Identifier {\n+  private final String[] namespace;\n+  private final String location;\n+  private final String name;\n+\n+  public PathIdentifier(String location) {\n+    this.location = location;\n+    List<String> pathParts = Splitter.on(\"/\").splitToList(location);\n+    name = Iterables.getLast(pathParts);\n+    namespace = pathParts.size() > 1 ? pathParts.subList(0, pathParts.size() - 1).toArray(new String[0]) :\n+        new String[0];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NjYzMTkw", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-545663190", "createdAt": "2020-12-06T01:46:38Z", "commit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTo0NjozOFrOIADtdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMTo0NjozOFrOIADtdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTcwMQ==", "bodyText": "This should be tableIdentifier.location() right?", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536931701", "createdAt": "2020-12-06T01:46:38Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -164,13 +183,24 @@ public SparkTable createTable(Identifier ident, StructType schema,\n   public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws TableAlreadyExistsException {\n     Schema icebergSchema = SparkSchemaUtil.convert(schema);\n+    TableIdentifier tableIdentifier = buildIdentifier(ident);\n     try {\n-      return new StagedSparkTable(icebergCatalog.newCreateTableTransaction(\n-          buildIdentifier(ident),\n-          icebergSchema,\n-          Spark3Util.toPartitionSpec(icebergSchema, transforms),\n-          properties.get(\"location\"),\n-          Spark3Util.rebuildCreateProperties(properties)));\n+      Transaction transaction;\n+      if (isPathIdentifier(ident)) {\n+        transaction = tables.newCreateTableTransaction(\n+            tableIdentifier.name(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd39f71606de90a165aa4d1696017a5c77bfc628"}, "originalPosition": 80}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c9589f8645950dc8d9723f8ca251f6d887fd5bf7", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/c9589f8645950dc8d9723f8ca251f6d887fd5bf7", "committedDate": "2020-12-07T18:36:43Z", "message": "wip: create and drop support for file paths\n\ncloses #1306"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "36b31ef063675c2848fddfe27ec039613f2ef67c", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/36b31ef063675c2848fddfe27ec039613f2ef67c", "committedDate": "2020-12-07T18:36:44Z", "message": "fix visibility"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "78bfda94b0d6b5aba71798f101e3354cefd91298", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/78bfda94b0d6b5aba71798f101e3354cefd91298", "committedDate": "2020-12-07T18:36:45Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71c69de631a89752e76091cd5f6e5f4c82f8880e", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/71c69de631a89752e76091cd5f6e5f4c82f8880e", "committedDate": "2020-12-07T18:36:46Z", "message": "skip `DROP` if session catalog and add ALTER"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a1d19aa07a890767925198b3c4e20cdf8027c3a", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/2a1d19aa07a890767925198b3c4e20cdf8027c3a", "committedDate": "2020-12-07T18:36:47Z", "message": "remove HadoopDelegatedCatalog.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d725841b68e31b7ba57293aa2ae1120b086c6133", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/d725841b68e31b7ba57293aa2ae1120b086c6133", "committedDate": "2020-12-07T18:36:48Z", "message": "revert change in visibility"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a5530cead241efae4d8a6f0652d84b3ef15b574e", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/a5530cead241efae4d8a6f0652d84b3ef15b574e", "committedDate": "2020-12-07T18:36:49Z", "message": "fix build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a5c6f95fb4a0a4d9a390ea0c8ba148b475728810", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/a5c6f95fb4a0a4d9a390ea0c8ba148b475728810", "committedDate": "2020-12-07T18:36:50Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94e6b63b1aeaf8abe0bb31b5057f70ee6e133e54", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/94e6b63b1aeaf8abe0bb31b5057f70ee6e133e54", "committedDate": "2020-12-07T18:36:51Z", "message": "use hadoop tables to validate"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b392767e5540920914894995819839e954f7925", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/8b392767e5540920914894995819839e954f7925", "committedDate": "2020-12-07T18:36:52Z", "message": "add transactions to hadoop tables"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "068a4f9587ad0991f9e368a4f96633c83767cd96", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/068a4f9587ad0991f9e368a4f96633c83767cd96", "committedDate": "2020-12-07T18:36:53Z", "message": "move check to hadoop tables and ensure path is absolute"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8710c1508f4344b84a427701176d82e89fd668e5", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/8710c1508f4344b84a427701176d82e89fd668e5", "committedDate": "2020-12-07T18:36:53Z", "message": "clean up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dfb9e2c35ab31d40b5b425a8a15cd8ae9c246581", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/dfb9e2c35ab31d40b5b425a8a15cd8ae9c246581", "committedDate": "2020-12-07T18:36:54Z", "message": "respect default catalog if added"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbba2c15fe186cbf7f7694af52f2883361161d09", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/fbba2c15fe186cbf7f7694af52f2883361161d09", "committedDate": "2020-12-07T18:36:55Z", "message": "address code review commends and reduce scope of change"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/46d5fb7360c32ff7d1b25555786440f7f3d61885", "committedDate": "2020-12-07T18:36:56Z", "message": "address code review and simplify"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "97ef11ebfa499fb621fcfd3fd55a512051ce6b7e", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/97ef11ebfa499fb621fcfd3fd55a512051ce6b7e", "committedDate": "2020-12-07T12:38:15Z", "message": "address code review and simplify"}, "afterCommit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/46d5fb7360c32ff7d1b25555786440f7f3d61885", "committedDate": "2020-12-07T18:36:56Z", "message": "address code review and simplify"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2NDI5NDY4", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-546429468", "createdAt": "2020-12-07T18:40:20Z", "commit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxODo0MDoyMFrOIA09Lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxODo0MDoyMFrOIA09Lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzczODU0Mg==", "bodyText": "I think this should validate that the location matches the one passed to create the builder. If this is a different location, it can't just be ignored.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537738542", "createdAt": "2020-12-07T18:40:20Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -200,6 +193,162 @@ TableOperations newTableOps(String location) {\n     }\n   }\n \n+  private TableMetadata tableMetadata(Schema schema, PartitionSpec spec, SortOrder order,\n+                                      Map<String, String> properties, String location) {\n+    Preconditions.checkNotNull(schema, \"A table schema is required\");\n+\n+    Map<String, String> tableProps = properties == null ? ImmutableMap.of() : properties;\n+    PartitionSpec partitionSpec = spec == null ? PartitionSpec.unpartitioned() : spec;\n+    SortOrder sortOrder = order == null ? SortOrder.unsorted() : order;\n+    return TableMetadata.newTableMetadata(schema, partitionSpec, sortOrder, location, tableProps);\n+  }\n+\n+  /**\n+   * Start a transaction to create a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @return a {@link Transaction} to create the table\n+   * @throws AlreadyExistsException if the table already exists\n+   */\n+  public Transaction newCreateTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties) {\n+    return buildTable(location, schema).withPartitionSpec(spec).withProperties(properties).createTransaction();\n+  }\n+\n+  /**\n+   * Start a transaction to replace a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @param orCreate whether to create the table if not exists\n+   * @return a {@link Transaction} to replace the table\n+   * @throws NoSuchTableException if the table doesn't exist and orCreate is false\n+   */\n+  public Transaction newReplaceTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties,\n+      boolean orCreate) {\n+\n+\n+    Catalog.TableBuilder builder = buildTable(location, schema).withPartitionSpec(spec).withProperties(properties);\n+    return orCreate ? builder.createOrReplaceTransaction() : builder.replaceTransaction();\n+  }\n+\n+  public Catalog.TableBuilder buildTable(String location, Schema schema) {\n+    return new HadoopTableBuilder(location, schema);\n+  }\n+\n+  private class HadoopTableBuilder implements Catalog.TableBuilder {\n+    private final String location;\n+    private final Schema schema;\n+    private final ImmutableMap.Builder<String, String> propertiesBuilder = ImmutableMap.builder();\n+    private PartitionSpec spec = PartitionSpec.unpartitioned();\n+    private SortOrder sortOrder = SortOrder.unsorted();\n+\n+\n+    HadoopTableBuilder(String location, Schema schema) {\n+      this.location = location;\n+      this.schema = schema;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withPartitionSpec(PartitionSpec newSpec) {\n+      this.spec = newSpec != null ? newSpec : PartitionSpec.unpartitioned();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withSortOrder(SortOrder newSortOrder) {\n+      this.sortOrder = newSortOrder != null ? newSortOrder : SortOrder.unsorted();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withLocation(String newLocation) {\n+      return this;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885"}, "originalPosition": 121}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e5be0da20ff2b87a9be8b6a2689e360136a9e5af", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/e5be0da20ff2b87a9be8b6a2689e360136a9e5af", "committedDate": "2020-12-07T18:53:10Z", "message": "add table location check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2NDU0MDY1", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-546454065", "createdAt": "2020-12-07T19:12:24Z", "commit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxOToxMjoyNVrOIA2Q8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxOToxMjoyNVrOIA2Q8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc1OTk4NQ==", "bodyText": "There should be no need to call toArray here because the joiner accepts Iterable<?>.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537759985", "createdAt": "2020-12-07T19:12:25Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/PathIdentifier.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.util.List;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+\n+public class PathIdentifier implements Identifier {\n+  private final String[] namespace;\n+  private final String location;\n+  private final String name;\n+\n+  public PathIdentifier(String location) {\n+    this.location = location;\n+    List<String> pathParts = Splitter.on(\"/\").splitToList(location);\n+    name = Iterables.getLast(pathParts);\n+    namespace = pathParts.size() > 1 ?\n+        new String[]{Joiner.on(\"/\").join(pathParts.subList(0, pathParts.size() - 1).toArray(new String[0]))} :", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2NDU0Njc1", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-546454675", "createdAt": "2020-12-07T19:13:12Z", "commit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxOToxMzoxM1rOIA2S6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxOToxMzoxM1rOIA2S6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2MDQ4OQ==", "bodyText": "We usually make Splitter and Joiner instances static fields.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537760489", "createdAt": "2020-12-07T19:13:13Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/PathIdentifier.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.util.List;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+\n+public class PathIdentifier implements Identifier {\n+  private final String[] namespace;\n+  private final String location;\n+  private final String name;\n+\n+  public PathIdentifier(String location) {\n+    this.location = location;\n+    List<String> pathParts = Splitter.on(\"/\").splitToList(location);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885"}, "originalPosition": 35}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7eb6b951b1e38f3aa7e7e07371e3ad9e7bf5c2a", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/f7eb6b951b1e38f3aa7e7e07371e3ad9e7bf5c2a", "committedDate": "2020-12-07T19:18:10Z", "message": "clean up PathIdentifier"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "78071f355a639cafdc8a0ee3487303081999907e", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/78071f355a639cafdc8a0ee3487303081999907e", "committedDate": "2020-12-07T19:20:26Z", "message": "remove pointless comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2NDYxNjk0", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-546461694", "createdAt": "2020-12-07T19:22:55Z", "commit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxOToyMjo1NVrOIA2rIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxOToyMjo1NVrOIA2rIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2NjY5MQ==", "bodyText": "Looks like there are 3 ways this is called:\n\nTo load a table\nTo create a builder\nTo drop a table\n\nI think it would be a bit cleaner to make the first 2 into private methods (load and newBuilder) rather than using pathOrTable with the same functions in lots of places.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537766691", "createdAt": "2020-12-07T19:22:55Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -453,4 +467,21 @@ private static void commitChanges(Table table, SetProperty setLocation, SetPrope\n \n     transaction.commitTransaction();\n   }\n+\n+  private static boolean isPathIdentifier(Identifier ident) {\n+    return ident instanceof PathIdentifier;\n+  }\n+\n+  private static void checkNotPathIdentifier(Identifier identifier, String method) {\n+    if (identifier instanceof PathIdentifier) {\n+      throw new IllegalArgumentException(String.format(\"Cannot pass path based identifier to %s method. %s is a path.\",\n+          method, identifier));\n+    }\n+  }\n+\n+  private <T> T pathOrTable(Identifier ident, Function<String, T> path, Function<TableIdentifier, T> table) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885"}, "originalPosition": 188}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "211b070f40eb1c0444e60d9fc2fe2b89196df176", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/211b070f40eb1c0444e60d9fc2fe2b89196df176", "committedDate": "2020-12-07T20:07:28Z", "message": "clearer path vs catalog checks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "793a117e05794833ec9e083cc12c020ac3207d14", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/793a117e05794833ec9e083cc12c020ac3207d14", "committedDate": "2020-12-08T14:45:13Z", "message": "add unit test for PathIdentifier"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9ea7450f02149a6c2643cca1c616faa8c690d4c9", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/9ea7450f02149a6c2643cca1c616faa8c690d4c9", "committedDate": "2020-12-08T14:03:45Z", "message": "add unit test for PathIdentifier"}, "afterCommit": {"oid": "793a117e05794833ec9e083cc12c020ac3207d14", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/793a117e05794833ec9e083cc12c020ac3207d14", "committedDate": "2020-12-08T14:45:13Z", "message": "add unit test for PathIdentifier"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3Njc4Mzk4", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-547678398", "createdAt": "2020-12-08T22:16:01Z", "commit": {"oid": "793a117e05794833ec9e083cc12c020ac3207d14"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMjoxNjowMlrOIB4stA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMjoxNjowMlrOIB4stA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0ODQzNg==", "bodyText": "Nit: preconditions already support argument formatting, so String.format is redundant.", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r538848436", "createdAt": "2020-12-08T22:16:02Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -200,6 +193,165 @@ TableOperations newTableOps(String location) {\n     }\n   }\n \n+  private TableMetadata tableMetadata(Schema schema, PartitionSpec spec, SortOrder order,\n+                                      Map<String, String> properties, String location) {\n+    Preconditions.checkNotNull(schema, \"A table schema is required\");\n+\n+    Map<String, String> tableProps = properties == null ? ImmutableMap.of() : properties;\n+    PartitionSpec partitionSpec = spec == null ? PartitionSpec.unpartitioned() : spec;\n+    SortOrder sortOrder = order == null ? SortOrder.unsorted() : order;\n+    return TableMetadata.newTableMetadata(schema, partitionSpec, sortOrder, location, tableProps);\n+  }\n+\n+  /**\n+   * Start a transaction to create a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @return a {@link Transaction} to create the table\n+   * @throws AlreadyExistsException if the table already exists\n+   */\n+  public Transaction newCreateTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties) {\n+    return buildTable(location, schema).withPartitionSpec(spec).withProperties(properties).createTransaction();\n+  }\n+\n+  /**\n+   * Start a transaction to replace a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @param orCreate whether to create the table if not exists\n+   * @return a {@link Transaction} to replace the table\n+   * @throws NoSuchTableException if the table doesn't exist and orCreate is false\n+   */\n+  public Transaction newReplaceTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties,\n+      boolean orCreate) {\n+\n+\n+    Catalog.TableBuilder builder = buildTable(location, schema).withPartitionSpec(spec).withProperties(properties);\n+    return orCreate ? builder.createOrReplaceTransaction() : builder.replaceTransaction();\n+  }\n+\n+  public Catalog.TableBuilder buildTable(String location, Schema schema) {\n+    return new HadoopTableBuilder(location, schema);\n+  }\n+\n+  private class HadoopTableBuilder implements Catalog.TableBuilder {\n+    private final String location;\n+    private final Schema schema;\n+    private final ImmutableMap.Builder<String, String> propertiesBuilder = ImmutableMap.builder();\n+    private PartitionSpec spec = PartitionSpec.unpartitioned();\n+    private SortOrder sortOrder = SortOrder.unsorted();\n+\n+\n+    HadoopTableBuilder(String location, Schema schema) {\n+      this.location = location;\n+      this.schema = schema;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withPartitionSpec(PartitionSpec newSpec) {\n+      this.spec = newSpec != null ? newSpec : PartitionSpec.unpartitioned();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withSortOrder(SortOrder newSortOrder) {\n+      this.sortOrder = newSortOrder != null ? newSortOrder : SortOrder.unsorted();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withLocation(String newLocation) {\n+      Preconditions.checkArgument(newLocation == null || location.equals(newLocation),\n+          String.format(\"Table location %s differs from the table location (%s) from the PathIdentifier\",\n+              newLocation, location));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "793a117e05794833ec9e083cc12c020ac3207d14"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NjgwNTgz", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-547680583", "createdAt": "2020-12-08T22:19:05Z", "commit": {"oid": "793a117e05794833ec9e083cc12c020ac3207d14"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5OTgyMjY2", "url": "https://github.com/apache/iceberg/pull/1843#pullrequestreview-559982266", "createdAt": "2020-12-30T10:00:24Z", "commit": {"oid": "793a117e05794833ec9e083cc12c020ac3207d14"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMDowMDoyNVrOIMnirA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMDowMDoyNVrOIMnirA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDEwMTY3Ng==", "bodyText": "@rymurr  Here we use the SortOrder.unsorted or null to set the sort order rather than the sortOrder set from here ?  Is it correct ?  IMO,  we've ignored the user-provied sort order ?", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r550101676", "createdAt": "2020-12-30T10:00:25Z", "author": {"login": "openinx"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -200,6 +193,165 @@ TableOperations newTableOps(String location) {\n     }\n   }\n \n+  private TableMetadata tableMetadata(Schema schema, PartitionSpec spec, SortOrder order,\n+                                      Map<String, String> properties, String location) {\n+    Preconditions.checkNotNull(schema, \"A table schema is required\");\n+\n+    Map<String, String> tableProps = properties == null ? ImmutableMap.of() : properties;\n+    PartitionSpec partitionSpec = spec == null ? PartitionSpec.unpartitioned() : spec;\n+    SortOrder sortOrder = order == null ? SortOrder.unsorted() : order;\n+    return TableMetadata.newTableMetadata(schema, partitionSpec, sortOrder, location, tableProps);\n+  }\n+\n+  /**\n+   * Start a transaction to create a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @return a {@link Transaction} to create the table\n+   * @throws AlreadyExistsException if the table already exists\n+   */\n+  public Transaction newCreateTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties) {\n+    return buildTable(location, schema).withPartitionSpec(spec).withProperties(properties).createTransaction();\n+  }\n+\n+  /**\n+   * Start a transaction to replace a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @param orCreate whether to create the table if not exists\n+   * @return a {@link Transaction} to replace the table\n+   * @throws NoSuchTableException if the table doesn't exist and orCreate is false\n+   */\n+  public Transaction newReplaceTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties,\n+      boolean orCreate) {\n+\n+\n+    Catalog.TableBuilder builder = buildTable(location, schema).withPartitionSpec(spec).withProperties(properties);\n+    return orCreate ? builder.createOrReplaceTransaction() : builder.replaceTransaction();\n+  }\n+\n+  public Catalog.TableBuilder buildTable(String location, Schema schema) {\n+    return new HadoopTableBuilder(location, schema);\n+  }\n+\n+  private class HadoopTableBuilder implements Catalog.TableBuilder {\n+    private final String location;\n+    private final Schema schema;\n+    private final ImmutableMap.Builder<String, String> propertiesBuilder = ImmutableMap.builder();\n+    private PartitionSpec spec = PartitionSpec.unpartitioned();\n+    private SortOrder sortOrder = SortOrder.unsorted();\n+\n+\n+    HadoopTableBuilder(String location, Schema schema) {\n+      this.location = location;\n+      this.schema = schema;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withPartitionSpec(PartitionSpec newSpec) {\n+      this.spec = newSpec != null ? newSpec : PartitionSpec.unpartitioned();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withSortOrder(SortOrder newSortOrder) {\n+      this.sortOrder = newSortOrder != null ? newSortOrder : SortOrder.unsorted();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withLocation(String newLocation) {\n+      Preconditions.checkArgument(newLocation == null || location.equals(newLocation),\n+          String.format(\"Table location %s differs from the table location (%s) from the PathIdentifier\",\n+              newLocation, location));\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withProperties(Map<String, String> properties) {\n+      if (properties != null) {\n+        propertiesBuilder.putAll(properties);\n+      }\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withProperty(String key, String value) {\n+      propertiesBuilder.put(key, value);\n+      return this;\n+    }\n+\n+    @Override\n+    public Table create() {\n+      TableOperations ops = newTableOps(location);\n+      if (ops.current() != null) {\n+        throw new AlreadyExistsException(\"Table already exists at location: %s\", location);\n+      }\n+\n+      Map<String, String> properties = propertiesBuilder.build();\n+      TableMetadata metadata = tableMetadata(schema, spec, sortOrder, properties, location);\n+      ops.commit(null, metadata);\n+      return new BaseTable(ops, location);\n+    }\n+\n+    @Override\n+    public Transaction createTransaction() {\n+      TableOperations ops = newTableOps(location);\n+      if (ops.current() != null) {\n+        throw new AlreadyExistsException(\"Table already exists: %s\", location);\n+      }\n+\n+      Map<String, String> properties = propertiesBuilder.build();\n+      TableMetadata metadata = tableMetadata(schema, spec, null, properties, location);\n+      return Transactions.createTableTransaction(location, ops, metadata);\n+    }\n+\n+    @Override\n+    public Transaction replaceTransaction() {\n+      return newReplaceTableTransaction(false);\n+    }\n+\n+    @Override\n+    public Transaction createOrReplaceTransaction() {\n+      return newReplaceTableTransaction(true);\n+    }\n+\n+    private Transaction newReplaceTableTransaction(boolean orCreate) {\n+      TableOperations ops = newTableOps(location);\n+      if (!orCreate && ops.current() == null) {\n+        throw new NoSuchTableException(\"No such table: %s\", location);\n+      }\n+\n+      Map<String, String> properties = propertiesBuilder.build();\n+      TableMetadata metadata;\n+      if (ops.current() != null) {\n+        metadata = ops.current().buildReplacement(schema, spec, SortOrder.unsorted(), location, properties);\n+      } else {\n+        metadata = tableMetadata(schema, spec, null, properties, location);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "793a117e05794833ec9e083cc12c020ac3207d14"}, "originalPosition": 187}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3449, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}