{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI4MjA3OTU4", "number": 1096, "title": "Add flink data type convertor to convert data types between iceberg data type and flink data type.", "bodyText": "@waterlx have did the netflix Poc before. Had a discussion with him before, we're planning to divide the flink connector module into serveral patches, and push it into the offical apache repo.\nThis is the first pull requset, which would align the data types between flink & iceberg (also introduced the iceberg-flink module with necessary flink dependencies). The following pull requests would be:\n\nflink reader & writer to access the parquet/avro/orc file formats etc.  ( background:  the flink table will depends on the flink Row data type, which is similar to the iceberg GenericRecord. although the flink reader/writer and iceberg generic reader/writer would share most of code, we need still need to flink row reader/writer, so it will be an abstract pull request).\nsink to iceberg by flink data stream API. we have the mature solution to maintain the exactly-once semantics in the poc code and the generic data lake repo, will try to make it to a small pull request.\nsink to iceberg by flink SQL. we also did the work in the generic-datalake/iceberg-pro repo,  will try to pr this.\n\nFor the part-2, we may better to have a doc describe the design behind it because it seems need some flink background to understand the flink operator state and it's design.", "createdAt": "2020-06-05T04:04:51Z", "url": "https://github.com/apache/iceberg/pull/1096", "merged": true, "mergeCommit": {"oid": "20651b1c1a3ba8bddf16ef5d91b3775b803d801e"}, "closed": true, "closedAt": "2020-06-17T17:45:16Z", "author": {"login": "openinx"}, "timelineItems": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcoKmQCgH2gAyNDI4MjA3OTU4OjlhOWZhZmU5Mjk5MjhmYzExMDRmMjE0ODgxODhmMGRlMjY3OWM3NTc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcsW12mgFqTQzMjkyNTA3NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/9a9fafe929928fc1104f21488188f0de2679c757", "committedDate": "2020-06-05T04:03:53Z", "message": "Add flink data type convertor to convert data types between iceberg data type and flink data type."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDQ0Njgy", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425444682", "createdAt": "2020-06-05T16:21:30Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyMTozMFrOGf1BwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyMTozMFrOGf1BwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyNzg0MQ==", "bodyText": "Is Arrow used in this module?", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436027841", "createdAt": "2020-06-05T16:21:30Z", "author": {"login": "rdblue"}, "path": "build.gradle", "diffHunk": "@@ -235,6 +235,38 @@ project(':iceberg-data') {\n   }\n }\n \n+project(':iceberg-flink') {\n+  apply plugin: 'scala'\n+\n+  dependencies {\n+    compile project(':iceberg-api')\n+    compile project(':iceberg-common')\n+    compile project(':iceberg-core')\n+    compile project(':iceberg-data')\n+    compile project(':iceberg-orc')\n+    compile project(':iceberg-parquet')\n+    compile project(':iceberg-arrow')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDQ1Mzcy", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425445372", "createdAt": "2020-06-05T16:22:25Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyMjoyNVrOGf1Dzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyMjoyNVrOGf1Dzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyODM2Nw==", "bodyText": "Does Flink have a Scala 2.12 version? Will it cause a problem to rely on 2.11?", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436028367", "createdAt": "2020-06-05T16:22:25Z", "author": {"login": "rdblue"}, "path": "build.gradle", "diffHunk": "@@ -235,6 +235,38 @@ project(':iceberg-data') {\n   }\n }\n \n+project(':iceberg-flink') {\n+  apply plugin: 'scala'\n+\n+  dependencies {\n+    compile project(':iceberg-api')\n+    compile project(':iceberg-common')\n+    compile project(':iceberg-core')\n+    compile project(':iceberg-data')\n+    compile project(':iceberg-orc')\n+    compile project(':iceberg-parquet')\n+    compile project(':iceberg-arrow')\n+    compile \"org.apache.flink:flink-streaming-java_2.11::tests\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDQ1OTEw", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425445910", "createdAt": "2020-06-05T16:23:09Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyMzowOVrOGf1FYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyMzowOVrOGf1FYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyODc2OQ==", "bodyText": "Is it necessary to have Scala in the Iceberg build? We plan to remove it from the Spark build since it is only used for a couple of helpers. It doesn't look like there is any Scala code in this PR.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436028769", "createdAt": "2020-06-05T16:23:09Z", "author": {"login": "rdblue"}, "path": "build.gradle", "diffHunk": "@@ -235,6 +235,38 @@ project(':iceberg-data') {\n   }\n }\n \n+project(':iceberg-flink') {\n+  apply plugin: 'scala'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDQ2NzU5", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425446759", "createdAt": "2020-06-05T16:24:23Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyNDoyM1rOGf1Hxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyNDoyM1rOGf1Hxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyOTM4Mg==", "bodyText": "Style: we like to have an empty line after control flow statements like the one above. Looks like we missed this in the original copy of this code.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436029382", "createdAt": "2020-06-05T16:24:23Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.CheckCompatibility;\n+import org.apache.iceberg.types.Type;\n+\n+public class FlinkSchemaUtil {\n+\n+  private FlinkSchemaUtil() {\n+  }\n+\n+  public static Schema convert(TableSchema flinkSchema) {\n+    FieldsDataType root = (FieldsDataType) flinkSchema.toRowDataType();\n+    Type converted = FlinkTypeVisitor.visit(root, new FlinkTypeToType(root));\n+    return new Schema(converted.asNestedType().asStructType().fields());\n+  }\n+\n+  static void validate(Schema readSchema, Schema writeSchema, boolean checkNullability, boolean checkOrdering) {\n+    List<String> errors;\n+    if (checkNullability) {\n+      errors = CheckCompatibility.writeCompatibilityErrors(readSchema, writeSchema, checkOrdering);\n+    } else {\n+      errors = CheckCompatibility.typeCompatibilityErrors(readSchema, writeSchema, checkOrdering);\n+    }\n+    if (!errors.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDQ4MzIx", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425448321", "createdAt": "2020-06-05T16:26:39Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyNjozOVrOGf1MdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyNjozOVrOGf1MdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMDU4MQ==", "bodyText": "This looks identical to the one in Spark. Can we move this into a helper class so we don't duplicate the code?", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436030581", "createdAt": "2020-06-05T16:26:39Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.CheckCompatibility;\n+import org.apache.iceberg.types.Type;\n+\n+public class FlinkSchemaUtil {\n+\n+  private FlinkSchemaUtil() {\n+  }\n+\n+  public static Schema convert(TableSchema flinkSchema) {\n+    FieldsDataType root = (FieldsDataType) flinkSchema.toRowDataType();\n+    Type converted = FlinkTypeVisitor.visit(root, new FlinkTypeToType(root));\n+    return new Schema(converted.asNestedType().asStructType().fields());\n+  }\n+\n+  static void validate(Schema readSchema, Schema writeSchema, boolean checkNullability, boolean checkOrdering) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDQ5MzA0", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425449304", "createdAt": "2020-06-05T16:28:09Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyODowOVrOGf1PYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyODowOVrOGf1PYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTMzMA==", "bodyText": "Is BinaryType a fixed-length binary? If so, it should be FixedType instead.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436031330", "createdAt": "2020-06-05T16:28:09Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType dataType, Map<String, Tuple2<String, Type>> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == dataType;\n+\n+    Map<String, DataType> fieldsMap = dataType.getFieldDataTypes();\n+    int index = 0;\n+    for (String name : types.keySet()) {\n+      assert fieldsMap.containsKey(name);\n+      DataType field = fieldsMap.get(name);\n+      Tuple2<String, Type> tuple2 = types.get(name);\n+\n+      int id = isRoot ? index : getNextId();\n+      if (field.getLogicalType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, tuple2.f1, tuple2.f0));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, tuple2.f1, tuple2.f0));\n+      }\n+      index++;\n+    }\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {\n+    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+      return Types.ListType.ofOptional(getNextId(), elementType);\n+    } else {\n+      return Types.ListType.ofRequired(getNextId(), elementType);\n+    }\n+  }\n+\n+  @Override\n+  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+    if (map.getValueDataType().getLogicalType().isNullable()) {\n+      return Types.MapType.ofOptional(getNextId(), getNextId(), keyType, valueType);\n+    } else {\n+      return Types.MapType.ofRequired(getNextId(), getNextId(), keyType, valueType);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:CyclomaticComplexity\")\n+  @Override\n+  public Type atomic(AtomicDataType type) {\n+    LogicalType inner = type.getLogicalType();\n+    if (inner instanceof VarCharType ||\n+        inner instanceof CharType) {\n+      return Types.StringType.get();\n+    } else if (inner instanceof BooleanType) {\n+      return Types.BooleanType.get();\n+    } else if (inner instanceof IntType ||\n+        inner instanceof SmallIntType ||\n+        inner instanceof TinyIntType) {\n+      return Types.IntegerType.get();\n+    } else if (inner instanceof BigIntType) {\n+      return Types.LongType.get();\n+    } else if (inner instanceof VarBinaryType ||\n+        inner instanceof BinaryType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDQ5NTQ1", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425449545", "createdAt": "2020-06-05T16:28:28Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyODoyOFrOGf1QDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoyODoyOFrOGf1QDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTUwMQ==", "bodyText": "Flink doesn't support TIMESTAMP WITHOUT TIME ZONE?", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436031501", "createdAt": "2020-06-05T16:28:28Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType dataType, Map<String, Tuple2<String, Type>> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == dataType;\n+\n+    Map<String, DataType> fieldsMap = dataType.getFieldDataTypes();\n+    int index = 0;\n+    for (String name : types.keySet()) {\n+      assert fieldsMap.containsKey(name);\n+      DataType field = fieldsMap.get(name);\n+      Tuple2<String, Type> tuple2 = types.get(name);\n+\n+      int id = isRoot ? index : getNextId();\n+      if (field.getLogicalType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, tuple2.f1, tuple2.f0));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, tuple2.f1, tuple2.f0));\n+      }\n+      index++;\n+    }\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {\n+    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+      return Types.ListType.ofOptional(getNextId(), elementType);\n+    } else {\n+      return Types.ListType.ofRequired(getNextId(), elementType);\n+    }\n+  }\n+\n+  @Override\n+  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+    if (map.getValueDataType().getLogicalType().isNullable()) {\n+      return Types.MapType.ofOptional(getNextId(), getNextId(), keyType, valueType);\n+    } else {\n+      return Types.MapType.ofRequired(getNextId(), getNextId(), keyType, valueType);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:CyclomaticComplexity\")\n+  @Override\n+  public Type atomic(AtomicDataType type) {\n+    LogicalType inner = type.getLogicalType();\n+    if (inner instanceof VarCharType ||\n+        inner instanceof CharType) {\n+      return Types.StringType.get();\n+    } else if (inner instanceof BooleanType) {\n+      return Types.BooleanType.get();\n+    } else if (inner instanceof IntType ||\n+        inner instanceof SmallIntType ||\n+        inner instanceof TinyIntType) {\n+      return Types.IntegerType.get();\n+    } else if (inner instanceof BigIntType) {\n+      return Types.LongType.get();\n+    } else if (inner instanceof VarBinaryType ||\n+        inner instanceof BinaryType) {\n+      return Types.BinaryType.get();\n+    } else if (inner instanceof FloatType) {\n+      return Types.FloatType.get();\n+    } else if (inner instanceof DoubleType) {\n+      return Types.DoubleType.get();\n+    } else if (inner instanceof DateType) {\n+      return Types.DateType.get();\n+    } else if (inner instanceof TimeType) {\n+      return Types.TimeType.get();\n+    } else if (inner instanceof TimestampType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 133}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDUwODc2", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425450876", "createdAt": "2020-06-05T16:30:25Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozMDoyNVrOGf1T2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozMDoyNVrOGf1T2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMjQ3NQ==", "bodyText": "Minor: We generally prefer Maps.newLinkedHashMap() instead of using a specific implementation.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436032475", "createdAt": "2020-06-05T16:30:25Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDUxODAx", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425451801", "createdAt": "2020-06-05T16:31:47Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozMTo0N1rOGf1Wng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozMTo0N1rOGf1Wng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMzE4Mg==", "bodyText": "How do we know that the logical type is RowType? Is that the only one? We may want to add a Precondition to validate this.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436033182", "createdAt": "2020-06-05T16:31:47Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDUzMzYw", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425453360", "createdAt": "2020-06-05T16:34:12Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozNDoxMlrOGf1bRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozNDoxMlrOGf1bRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNDM3NQ==", "bodyText": "What is returned by rowType.getFields()? Why is that used to get the comment, but fields.get(name) is used for the type? I would expect this to use one or the other.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436034375", "createdAt": "2020-06-05T16:34:12Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();\n+      for (int i = 0; i < fields.size(); i++) {\n+        String name = rowType.getFieldNames().get(i);\n+        String comment = rowType.getFields().get(i).getDescription().orElse(null);\n+        fieldResults.put(name, Tuple2.of(comment, visit(fields.get(name), visitor)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDU1MTE4", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425455118", "createdAt": "2020-06-05T16:36:46Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozNjo0NlrOGf1gtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozNjo0NlrOGf1gtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNTc2NQ==", "bodyText": "If fields is always a row, it seems to me that row might be a better name because it is more clear that it is a record/struct/tuple type. It wasn't clear to me that fields was the record type, since most other formats make a distinction between a record and its field list.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436035765", "createdAt": "2020-06-05T16:36:46Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();\n+      for (int i = 0; i < fields.size(); i++) {\n+        String name = rowType.getFieldNames().get(i);\n+        String comment = rowType.getFields().get(i).getDescription().orElse(null);\n+        fieldResults.put(name, Tuple2.of(comment, visit(fields.get(name), visitor)));\n+      }\n+      return visitor.fields(fieldsType, fieldResults);\n+    } else if (dataType instanceof CollectionDataType) {\n+      CollectionDataType collectionType = (CollectionDataType) dataType;\n+      return visitor.collection(collectionType,\n+          visit(collectionType.getElementDataType(), visitor));\n+    } else if (dataType instanceof KeyValueDataType) {\n+      KeyValueDataType mapType = (KeyValueDataType) dataType;\n+      return visitor.map(mapType,\n+          visit(mapType.getKeyDataType(), visitor),\n+          visit(mapType.getValueDataType(), visitor));\n+    } else if (dataType instanceof AtomicDataType) {\n+      AtomicDataType atomic = (AtomicDataType) dataType;\n+      return visitor.atomic(atomic);\n+    } else {\n+      throw new UnsupportedOperationException(\"Unsupported data type: \" + dataType);\n+    }\n+  }\n+\n+  public T fields(FieldsDataType dataType, Map<String, Tuple2<String, T>> fieldResults) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 64}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDU2MjYw", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425456260", "createdAt": "2020-06-05T16:38:29Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozODoyOVrOGf1j_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozODoyOVrOGf1j_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNjYwNg==", "bodyText": "In other visitors, we avoid the need for a Tuple2 or equivalent by adding a visitor method for a field. That also gives us an opportunity to add before and after callbacks to do things like keep track of the original schema's names. We can always add this later, but you might consider adding it.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436036606", "createdAt": "2020-06-05T16:38:29Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();\n+      for (int i = 0; i < fields.size(); i++) {\n+        String name = rowType.getFieldNames().get(i);\n+        String comment = rowType.getFields().get(i).getDescription().orElse(null);\n+        fieldResults.put(name, Tuple2.of(comment, visit(fields.get(name), visitor)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDU2Njkw", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425456690", "createdAt": "2020-06-05T16:39:07Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozOTowN1rOGf1lIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjozOTowN1rOGf1lIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNjg5Ng==", "bodyText": "We typically use a Pair in Iceberg code for consistency.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436036896", "createdAt": "2020-06-05T16:39:07Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDU3NzA1", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425457705", "createdAt": "2020-06-05T16:40:41Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0MDo0MVrOGf1oDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0MDo0MVrOGf1oDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNzY0Nw==", "bodyText": "Using a name like commentAndType would help make it clear what's happening when the values are used.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436037647", "createdAt": "2020-06-05T16:40:41Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType dataType, Map<String, Tuple2<String, Type>> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == dataType;\n+\n+    Map<String, DataType> fieldsMap = dataType.getFieldDataTypes();\n+    int index = 0;\n+    for (String name : types.keySet()) {\n+      assert fieldsMap.containsKey(name);\n+      DataType field = fieldsMap.get(name);\n+      Tuple2<String, Type> tuple2 = types.get(name);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 76}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDU5NTQ1", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425459545", "createdAt": "2020-06-05T16:43:25Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0MzoyNVrOGf1tjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0MzoyNVrOGf1tjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzOTA1NA==", "bodyText": "It would be good to use a different precision and scale so that this validates that they are passed correctly, since both are ints.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436039054", "createdAt": "2020-06-05T16:43:25Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkSchemaUtil {\n+\n+  @Test\n+  public void testConvertFlinkSchemaToIcebergSchema() {\n+    TableSchema flinkSchema = TableSchema.builder()\n+        .field(\"id\", DataTypes.INT().notNull())\n+        .field(\"name\", DataTypes.STRING()) /* optional by default */\n+        .field(\"salary\", DataTypes.DOUBLE().notNull())\n+        .field(\"locations\", DataTypes.MAP(DataTypes.STRING(),\n+            DataTypes.ROW(DataTypes.FIELD(\"posX\", DataTypes.DOUBLE().notNull(), \"X field\"),\n+                DataTypes.FIELD(\"posY\", DataTypes.DOUBLE().notNull(), \"Y field\"))))\n+        .field(\"strArray\", DataTypes.ARRAY(DataTypes.STRING()).nullable())\n+        .field(\"intArray\", DataTypes.ARRAY(DataTypes.INT()).nullable())\n+        .field(\"char\", DataTypes.CHAR(10).notNull())\n+        .field(\"varchar\", DataTypes.VARCHAR(10).notNull())\n+        .field(\"boolean\", DataTypes.BOOLEAN().nullable())\n+        .field(\"tinyint\", DataTypes.TINYINT())\n+        .field(\"smallint\", DataTypes.SMALLINT())\n+        .field(\"bigint\", DataTypes.BIGINT())\n+        .field(\"varbinary\", DataTypes.VARBINARY(10))\n+        .field(\"binary\", DataTypes.BINARY(10))\n+        .field(\"time\", DataTypes.TIME())\n+        .field(\"timestamp\", DataTypes.TIMESTAMP())\n+        .field(\"date\", DataTypes.DATE())\n+        .field(\"decimal\", DataTypes.DECIMAL(2, 2))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDYwMTc3", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425460177", "createdAt": "2020-06-05T16:44:22Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0NDoyMlrOGf1vkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0NDoyMlrOGf1vkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzOTU3MQ==", "bodyText": "Instead of using toString, use asStruct. Struct implements equals so you can use it in tests.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436039571", "createdAt": "2020-06-05T16:44:22Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkSchemaUtil {\n+\n+  @Test\n+  public void testConvertFlinkSchemaToIcebergSchema() {\n+    TableSchema flinkSchema = TableSchema.builder()\n+        .field(\"id\", DataTypes.INT().notNull())\n+        .field(\"name\", DataTypes.STRING()) /* optional by default */\n+        .field(\"salary\", DataTypes.DOUBLE().notNull())\n+        .field(\"locations\", DataTypes.MAP(DataTypes.STRING(),\n+            DataTypes.ROW(DataTypes.FIELD(\"posX\", DataTypes.DOUBLE().notNull(), \"X field\"),\n+                DataTypes.FIELD(\"posY\", DataTypes.DOUBLE().notNull(), \"Y field\"))))\n+        .field(\"strArray\", DataTypes.ARRAY(DataTypes.STRING()).nullable())\n+        .field(\"intArray\", DataTypes.ARRAY(DataTypes.INT()).nullable())\n+        .field(\"char\", DataTypes.CHAR(10).notNull())\n+        .field(\"varchar\", DataTypes.VARCHAR(10).notNull())\n+        .field(\"boolean\", DataTypes.BOOLEAN().nullable())\n+        .field(\"tinyint\", DataTypes.TINYINT())\n+        .field(\"smallint\", DataTypes.SMALLINT())\n+        .field(\"bigint\", DataTypes.BIGINT())\n+        .field(\"varbinary\", DataTypes.VARBINARY(10))\n+        .field(\"binary\", DataTypes.BINARY(10))\n+        .field(\"time\", DataTypes.TIME())\n+        .field(\"timestamp\", DataTypes.TIMESTAMP())\n+        .field(\"date\", DataTypes.DATE())\n+        .field(\"decimal\", DataTypes.DECIMAL(2, 2))\n+        .build();\n+\n+    Schema actualSchema = FlinkSchemaUtil.convert(flinkSchema);\n+    Schema expectedSchema = new Schema(\n+        Types.NestedField.required(0, \"id\", Types.IntegerType.get(), null),\n+        Types.NestedField.optional(1, \"name\", Types.StringType.get(), null),\n+        Types.NestedField.required(2, \"salary\", Types.DoubleType.get(), null),\n+        Types.NestedField.optional(3, \"locations\", Types.MapType.ofOptional(20, 21,\n+            Types.StringType.get(),\n+            Types.StructType.of(\n+                Types.NestedField.required(18, \"posX\", Types.DoubleType.get(), \"X field\"),\n+                Types.NestedField.required(19, \"posY\", Types.DoubleType.get(), \"Y field\")\n+            ))),\n+        Types.NestedField.optional(4, \"strArray\", Types.ListType.ofOptional(22, Types.StringType.get())),\n+        Types.NestedField.optional(5, \"intArray\", Types.ListType.ofOptional(23, Types.IntegerType.get())),\n+        Types.NestedField.required(6, \"char\", Types.StringType.get()),\n+        Types.NestedField.required(7, \"varchar\", Types.StringType.get()),\n+        Types.NestedField.optional(8, \"boolean\", Types.BooleanType.get()),\n+        Types.NestedField.optional(9, \"tinyint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(10, \"smallint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(11, \"bigint\", Types.LongType.get()),\n+        Types.NestedField.optional(12, \"varbinary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(13, \"binary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(14, \"time\", Types.TimeType.get()),\n+        Types.NestedField.optional(15, \"timestamp\", Types.TimestampType.withZone()),\n+        Types.NestedField.optional(16, \"date\", Types.DateType.get()),\n+        Types.NestedField.optional(17, \"decimal\", Types.DecimalType.of(2, 2))\n+    );\n+\n+    Assert.assertEquals(expectedSchema.toString(), actualSchema.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 83}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDYxMDE1", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425461015", "createdAt": "2020-06-05T16:45:41Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0NTo0MVrOGf1yNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0NTo0MVrOGf1yNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDI0Nw==", "bodyText": "Looks like this doesn't test:\n\nField comments\nStruct types\nMaps or lists that contain structs\nMaps with non-string keys\n\nAre all of those supported? If so, can you add tests?", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436040247", "createdAt": "2020-06-05T16:45:41Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkSchemaUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDYxMjcz", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425461273", "createdAt": "2020-06-05T16:46:04Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0NjowNFrOGf1zAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjo0NjowNFrOGf1zAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDQ1MQ==", "bodyText": "I think validation should be tested separately.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436040451", "createdAt": "2020-06-05T16:46:04Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkSchemaUtil {\n+\n+  @Test\n+  public void testConvertFlinkSchemaToIcebergSchema() {\n+    TableSchema flinkSchema = TableSchema.builder()\n+        .field(\"id\", DataTypes.INT().notNull())\n+        .field(\"name\", DataTypes.STRING()) /* optional by default */\n+        .field(\"salary\", DataTypes.DOUBLE().notNull())\n+        .field(\"locations\", DataTypes.MAP(DataTypes.STRING(),\n+            DataTypes.ROW(DataTypes.FIELD(\"posX\", DataTypes.DOUBLE().notNull(), \"X field\"),\n+                DataTypes.FIELD(\"posY\", DataTypes.DOUBLE().notNull(), \"Y field\"))))\n+        .field(\"strArray\", DataTypes.ARRAY(DataTypes.STRING()).nullable())\n+        .field(\"intArray\", DataTypes.ARRAY(DataTypes.INT()).nullable())\n+        .field(\"char\", DataTypes.CHAR(10).notNull())\n+        .field(\"varchar\", DataTypes.VARCHAR(10).notNull())\n+        .field(\"boolean\", DataTypes.BOOLEAN().nullable())\n+        .field(\"tinyint\", DataTypes.TINYINT())\n+        .field(\"smallint\", DataTypes.SMALLINT())\n+        .field(\"bigint\", DataTypes.BIGINT())\n+        .field(\"varbinary\", DataTypes.VARBINARY(10))\n+        .field(\"binary\", DataTypes.BINARY(10))\n+        .field(\"time\", DataTypes.TIME())\n+        .field(\"timestamp\", DataTypes.TIMESTAMP())\n+        .field(\"date\", DataTypes.DATE())\n+        .field(\"decimal\", DataTypes.DECIMAL(2, 2))\n+        .build();\n+\n+    Schema actualSchema = FlinkSchemaUtil.convert(flinkSchema);\n+    Schema expectedSchema = new Schema(\n+        Types.NestedField.required(0, \"id\", Types.IntegerType.get(), null),\n+        Types.NestedField.optional(1, \"name\", Types.StringType.get(), null),\n+        Types.NestedField.required(2, \"salary\", Types.DoubleType.get(), null),\n+        Types.NestedField.optional(3, \"locations\", Types.MapType.ofOptional(20, 21,\n+            Types.StringType.get(),\n+            Types.StructType.of(\n+                Types.NestedField.required(18, \"posX\", Types.DoubleType.get(), \"X field\"),\n+                Types.NestedField.required(19, \"posY\", Types.DoubleType.get(), \"Y field\")\n+            ))),\n+        Types.NestedField.optional(4, \"strArray\", Types.ListType.ofOptional(22, Types.StringType.get())),\n+        Types.NestedField.optional(5, \"intArray\", Types.ListType.ofOptional(23, Types.IntegerType.get())),\n+        Types.NestedField.required(6, \"char\", Types.StringType.get()),\n+        Types.NestedField.required(7, \"varchar\", Types.StringType.get()),\n+        Types.NestedField.optional(8, \"boolean\", Types.BooleanType.get()),\n+        Types.NestedField.optional(9, \"tinyint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(10, \"smallint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(11, \"bigint\", Types.LongType.get()),\n+        Types.NestedField.optional(12, \"varbinary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(13, \"binary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(14, \"time\", Types.TimeType.get()),\n+        Types.NestedField.optional(15, \"timestamp\", Types.TimestampType.withZone()),\n+        Types.NestedField.optional(16, \"date\", Types.DateType.get()),\n+        Types.NestedField.optional(17, \"decimal\", Types.DecimalType.of(2, 2))\n+    );\n+\n+    Assert.assertEquals(expectedSchema.toString(), actualSchema.toString());\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, true, true);\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, false, true);\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, true, false);\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, false, false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 87}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1ODgwMDgz", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-425880083", "createdAt": "2020-06-08T02:03:18Z", "commit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "state": "COMMENTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwMjowMzoxOFrOGgNcQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwNDowODowMVrOGgOrJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQyNzg0Mw==", "bodyText": "OK, although we are depending few scala jar from flink modules, we don't need the scala plugin when building the iceberg-flink module because we won't have any scala code.\nWill remove this,  thanks.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436427843", "createdAt": "2020-06-08T02:03:18Z", "author": {"login": "openinx"}, "path": "build.gradle", "diffHunk": "@@ -235,6 +235,38 @@ project(':iceberg-data') {\n   }\n }\n \n+project(':iceberg-flink') {\n+  apply plugin: 'scala'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyODc2OQ=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQyODM3Mg==", "bodyText": "Seems it was introduced by mistake, will remove this.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436428372", "createdAt": "2020-06-08T02:07:18Z", "author": {"login": "openinx"}, "path": "build.gradle", "diffHunk": "@@ -235,6 +235,38 @@ project(':iceberg-data') {\n   }\n }\n \n+project(':iceberg-flink') {\n+  apply plugin: 'scala'\n+\n+  dependencies {\n+    compile project(':iceberg-api')\n+    compile project(':iceberg-common')\n+    compile project(':iceberg-core')\n+    compile project(':iceberg-data')\n+    compile project(':iceberg-orc')\n+    compile project(':iceberg-parquet')\n+    compile project(':iceberg-arrow')", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyNzg0MQ=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQyODg4OA==", "bodyText": "Yes we have scala 2.12 version. I'm not sure what's the specific problem you mean in 2.11, You have more information ? thanks.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436428888", "createdAt": "2020-06-08T02:10:54Z", "author": {"login": "openinx"}, "path": "build.gradle", "diffHunk": "@@ -235,6 +235,38 @@ project(':iceberg-data') {\n   }\n }\n \n+project(':iceberg-flink') {\n+  apply plugin: 'scala'\n+\n+  dependencies {\n+    compile project(':iceberg-api')\n+    compile project(':iceberg-common')\n+    compile project(':iceberg-core')\n+    compile project(':iceberg-data')\n+    compile project(':iceberg-orc')\n+    compile project(':iceberg-parquet')\n+    compile project(':iceberg-arrow')\n+    compile \"org.apache.flink:flink-streaming-java_2.11::tests\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyODM2Nw=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzNzIxMw==", "bodyText": "Sounds good.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436437213", "createdAt": "2020-06-08T03:03:05Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType dataType, Map<String, Tuple2<String, Type>> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == dataType;\n+\n+    Map<String, DataType> fieldsMap = dataType.getFieldDataTypes();\n+    int index = 0;\n+    for (String name : types.keySet()) {\n+      assert fieldsMap.containsKey(name);\n+      DataType field = fieldsMap.get(name);\n+      Tuple2<String, Type> tuple2 = types.get(name);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNzY0Nw=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzNzU0NA==", "bodyText": "Thanks for the reminding, will fix this and provide a unit test to address it. Thanks.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436437544", "createdAt": "2020-06-08T03:05:20Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType dataType, Map<String, Tuple2<String, Type>> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == dataType;\n+\n+    Map<String, DataType> fieldsMap = dataType.getFieldDataTypes();\n+    int index = 0;\n+    for (String name : types.keySet()) {\n+      assert fieldsMap.containsKey(name);\n+      DataType field = fieldsMap.get(name);\n+      Tuple2<String, Type> tuple2 = types.get(name);\n+\n+      int id = isRoot ? index : getNextId();\n+      if (field.getLogicalType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, tuple2.f1, tuple2.f0));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, tuple2.f1, tuple2.f0));\n+      }\n+      index++;\n+    }\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {\n+    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+      return Types.ListType.ofOptional(getNextId(), elementType);\n+    } else {\n+      return Types.ListType.ofRequired(getNextId(), elementType);\n+    }\n+  }\n+\n+  @Override\n+  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+    if (map.getValueDataType().getLogicalType().isNullable()) {\n+      return Types.MapType.ofOptional(getNextId(), getNextId(), keyType, valueType);\n+    } else {\n+      return Types.MapType.ofRequired(getNextId(), getNextId(), keyType, valueType);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:CyclomaticComplexity\")\n+  @Override\n+  public Type atomic(AtomicDataType type) {\n+    LogicalType inner = type.getLogicalType();\n+    if (inner instanceof VarCharType ||\n+        inner instanceof CharType) {\n+      return Types.StringType.get();\n+    } else if (inner instanceof BooleanType) {\n+      return Types.BooleanType.get();\n+    } else if (inner instanceof IntType ||\n+        inner instanceof SmallIntType ||\n+        inner instanceof TinyIntType) {\n+      return Types.IntegerType.get();\n+    } else if (inner instanceof BigIntType) {\n+      return Types.LongType.get();\n+    } else if (inner instanceof VarBinaryType ||\n+        inner instanceof BinaryType) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTMzMA=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzODI4Mg==", "bodyText": "It's a bug here which I forget to fix before. we have an issue to address this: https://github.com/generic-datalake/iceberg-pro/issues/30.\nLet me address it in this pull request.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436438282", "createdAt": "2020-06-08T03:10:32Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType dataType, Map<String, Tuple2<String, Type>> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == dataType;\n+\n+    Map<String, DataType> fieldsMap = dataType.getFieldDataTypes();\n+    int index = 0;\n+    for (String name : types.keySet()) {\n+      assert fieldsMap.containsKey(name);\n+      DataType field = fieldsMap.get(name);\n+      Tuple2<String, Type> tuple2 = types.get(name);\n+\n+      int id = isRoot ? index : getNextId();\n+      if (field.getLogicalType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, tuple2.f1, tuple2.f0));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, tuple2.f1, tuple2.f0));\n+      }\n+      index++;\n+    }\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {\n+    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+      return Types.ListType.ofOptional(getNextId(), elementType);\n+    } else {\n+      return Types.ListType.ofRequired(getNextId(), elementType);\n+    }\n+  }\n+\n+  @Override\n+  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+    if (map.getValueDataType().getLogicalType().isNullable()) {\n+      return Types.MapType.ofOptional(getNextId(), getNextId(), keyType, valueType);\n+    } else {\n+      return Types.MapType.ofRequired(getNextId(), getNextId(), keyType, valueType);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:CyclomaticComplexity\")\n+  @Override\n+  public Type atomic(AtomicDataType type) {\n+    LogicalType inner = type.getLogicalType();\n+    if (inner instanceof VarCharType ||\n+        inner instanceof CharType) {\n+      return Types.StringType.get();\n+    } else if (inner instanceof BooleanType) {\n+      return Types.BooleanType.get();\n+    } else if (inner instanceof IntType ||\n+        inner instanceof SmallIntType ||\n+        inner instanceof TinyIntType) {\n+      return Types.IntegerType.get();\n+    } else if (inner instanceof BigIntType) {\n+      return Types.LongType.get();\n+    } else if (inner instanceof VarBinaryType ||\n+        inner instanceof BinaryType) {\n+      return Types.BinaryType.get();\n+    } else if (inner instanceof FloatType) {\n+      return Types.FloatType.get();\n+    } else if (inner instanceof DoubleType) {\n+      return Types.DoubleType.get();\n+    } else if (inner instanceof DateType) {\n+      return Types.DateType.get();\n+    } else if (inner instanceof TimeType) {\n+      return Types.TimeType.get();\n+    } else if (inner instanceof TimestampType) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTUwMQ=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0MzMxMw==", "bodyText": "Yes, it's the only one.  Providing a Precondition seems good.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436443313", "createdAt": "2020-06-08T03:41:08Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMzE4Mg=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0NjQzMQ==", "bodyText": "There are two different datatype class in flink type:  DataType and LogicalType. The DataType have the following types:\n\nAtomicDataType;\nCollectionDataType;\nFieldsDataType;\nKeyValueDataType;\n\nand the logicalType the following kinds: ArrayType/CharType/LongType/MapType etc , it describe more details about the type.\nThe RowType is a LogicalType, while we defined the visit by accepting DataType, that's why I need two types here:  the logical type to get the name & comment, while the DataType to passing the argument.\nI think I can write this code more clear, please see the next patch.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436446431", "createdAt": "2020-06-08T03:59:41Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();\n+      for (int i = 0; i < fields.size(); i++) {\n+        String name = rowType.getFieldNames().get(i);\n+        String comment = rowType.getFields().get(i).getDescription().orElse(null);\n+        fieldResults.put(name, Tuple2.of(comment, visit(fields.get(name), visitor)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNDM3NQ=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0Njk2Nw==", "bodyText": "The name fields is matching the FieldsDataType ,  like the collection is matching the CollectionDataType, map is matching the KeyValueDataType.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436446967", "createdAt": "2020-06-08T04:02:51Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();\n+      for (int i = 0; i < fields.size(); i++) {\n+        String name = rowType.getFieldNames().get(i);\n+        String comment = rowType.getFields().get(i).getDescription().orElse(null);\n+        fieldResults.put(name, Tuple2.of(comment, visit(fields.get(name), visitor)));\n+      }\n+      return visitor.fields(fieldsType, fieldResults);\n+    } else if (dataType instanceof CollectionDataType) {\n+      CollectionDataType collectionType = (CollectionDataType) dataType;\n+      return visitor.collection(collectionType,\n+          visit(collectionType.getElementDataType(), visitor));\n+    } else if (dataType instanceof KeyValueDataType) {\n+      KeyValueDataType mapType = (KeyValueDataType) dataType;\n+      return visitor.map(mapType,\n+          visit(mapType.getKeyDataType(), visitor),\n+          visit(mapType.getValueDataType(), visitor));\n+    } else if (dataType instanceof AtomicDataType) {\n+      AtomicDataType atomic = (AtomicDataType) dataType;\n+      return visitor.atomic(atomic);\n+    } else {\n+      throw new UnsupportedOperationException(\"Unsupported data type: \" + dataType);\n+    }\n+  }\n+\n+  public T fields(FieldsDataType dataType, Map<String, Tuple2<String, T>> fieldResults) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNTc2NQ=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0NzIyOA==", "bodyText": "As we discussed above, we will move this validate method into the common TypeUtil.  Let me add unit test in TestTypeUtil. Thanks.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436447228", "createdAt": "2020-06-08T04:04:08Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkSchemaUtil {\n+\n+  @Test\n+  public void testConvertFlinkSchemaToIcebergSchema() {\n+    TableSchema flinkSchema = TableSchema.builder()\n+        .field(\"id\", DataTypes.INT().notNull())\n+        .field(\"name\", DataTypes.STRING()) /* optional by default */\n+        .field(\"salary\", DataTypes.DOUBLE().notNull())\n+        .field(\"locations\", DataTypes.MAP(DataTypes.STRING(),\n+            DataTypes.ROW(DataTypes.FIELD(\"posX\", DataTypes.DOUBLE().notNull(), \"X field\"),\n+                DataTypes.FIELD(\"posY\", DataTypes.DOUBLE().notNull(), \"Y field\"))))\n+        .field(\"strArray\", DataTypes.ARRAY(DataTypes.STRING()).nullable())\n+        .field(\"intArray\", DataTypes.ARRAY(DataTypes.INT()).nullable())\n+        .field(\"char\", DataTypes.CHAR(10).notNull())\n+        .field(\"varchar\", DataTypes.VARCHAR(10).notNull())\n+        .field(\"boolean\", DataTypes.BOOLEAN().nullable())\n+        .field(\"tinyint\", DataTypes.TINYINT())\n+        .field(\"smallint\", DataTypes.SMALLINT())\n+        .field(\"bigint\", DataTypes.BIGINT())\n+        .field(\"varbinary\", DataTypes.VARBINARY(10))\n+        .field(\"binary\", DataTypes.BINARY(10))\n+        .field(\"time\", DataTypes.TIME())\n+        .field(\"timestamp\", DataTypes.TIMESTAMP())\n+        .field(\"date\", DataTypes.DATE())\n+        .field(\"decimal\", DataTypes.DECIMAL(2, 2))\n+        .build();\n+\n+    Schema actualSchema = FlinkSchemaUtil.convert(flinkSchema);\n+    Schema expectedSchema = new Schema(\n+        Types.NestedField.required(0, \"id\", Types.IntegerType.get(), null),\n+        Types.NestedField.optional(1, \"name\", Types.StringType.get(), null),\n+        Types.NestedField.required(2, \"salary\", Types.DoubleType.get(), null),\n+        Types.NestedField.optional(3, \"locations\", Types.MapType.ofOptional(20, 21,\n+            Types.StringType.get(),\n+            Types.StructType.of(\n+                Types.NestedField.required(18, \"posX\", Types.DoubleType.get(), \"X field\"),\n+                Types.NestedField.required(19, \"posY\", Types.DoubleType.get(), \"Y field\")\n+            ))),\n+        Types.NestedField.optional(4, \"strArray\", Types.ListType.ofOptional(22, Types.StringType.get())),\n+        Types.NestedField.optional(5, \"intArray\", Types.ListType.ofOptional(23, Types.IntegerType.get())),\n+        Types.NestedField.required(6, \"char\", Types.StringType.get()),\n+        Types.NestedField.required(7, \"varchar\", Types.StringType.get()),\n+        Types.NestedField.optional(8, \"boolean\", Types.BooleanType.get()),\n+        Types.NestedField.optional(9, \"tinyint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(10, \"smallint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(11, \"bigint\", Types.LongType.get()),\n+        Types.NestedField.optional(12, \"varbinary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(13, \"binary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(14, \"time\", Types.TimeType.get()),\n+        Types.NestedField.optional(15, \"timestamp\", Types.TimestampType.withZone()),\n+        Types.NestedField.optional(16, \"date\", Types.DateType.get()),\n+        Types.NestedField.optional(17, \"decimal\", Types.DecimalType.of(2, 2))\n+    );\n+\n+    Assert.assertEquals(expectedSchema.toString(), actualSchema.toString());\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, true, true);\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, false, true);\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, true, false);\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, false, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDQ1MQ=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0NzI2Nw==", "bodyText": "The flink version can be upgraded to 1.10.1 now.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436447267", "createdAt": "2020-06-08T04:04:25Z", "author": {"login": "openinx"}, "path": "versions.props", "diffHunk": "@@ -1,5 +1,6 @@\n org.slf4j:* = 1.7.25\n org.apache.avro:avro = 1.9.2\n+org.apache.flink:* = 1.10.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0ODAzNg==", "bodyText": "The reason why I add  a Tuple2/Pair here because the flink Type did not expose the interface to access the comment, so I have to maintain it by myself. I got your points about before or after hooks. In the worst case, the hooks may also accept the Map<String, Pair<String, Type>> as an argument. we may could do better ..", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436448036", "createdAt": "2020-06-08T04:08:01Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();\n+      for (int i = 0; i < fields.size(); i++) {\n+        String name = rowType.getFieldNames().get(i);\n+        String comment = rowType.getFields().get(i).getDescription().orElse(null);\n+        fieldResults.put(name, Tuple2.of(comment, visit(fields.get(name), visitor)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNjYwNg=="}, "originalCommit": {"oid": "9a9fafe929928fc1104f21488188f0de2679c757"}, "originalPosition": 44}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a7c88003ff2206f83dcf8509b868b60cb2d7c4d", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/1a7c88003ff2206f83dcf8509b868b60cb2d7c4d", "committedDate": "2020-06-08T05:34:09Z", "message": "Addressing the comments from Ryan blue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "98648e5fc0912b365a6b768435565f969fff4962", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/98648e5fc0912b365a6b768435565f969fff4962", "committedDate": "2020-06-08T09:41:03Z", "message": "Minor updates and more unit tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NDQ2MjYy", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-426446262", "createdAt": "2020-06-08T17:11:05Z", "commit": {"oid": "98648e5fc0912b365a6b768435565f969fff4962"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxMTowNVrOGgn_DA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxMTowNVrOGgn_DA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2MjczMg==", "bodyText": "Schema doesn't implement equals because it isn't clear what schema equality means. Because we track fields by ID, two schemas are equal only if their fields have the same IDs, but most people don't think about schema equality that way and think of a SQL schema, like id bigint, data string. To avoid confusion, we don't provide an equals method that may have confusing results. Instead, we implement equals for structs so you can use schema.asStruct() in test assertions.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436862732", "createdAt": "2020-06-08T17:11:05Z", "author": {"login": "rdblue"}, "path": "api/src/main/java/org/apache/iceberg/Schema.java", "diffHunk": "@@ -314,4 +315,31 @@ public String toString() {\n             .map(f -> \"  \" + f)\n             .collect(Collectors.toList())));\n   }\n+\n+  @Override\n+  public boolean equals(Object o) {\n+    if (!(o instanceof Schema)) {\n+      return false;\n+    }\n+\n+    Schema that = (Schema) o;\n+    if (!Objects.equals(struct.fields(), that.struct.fields())) {\n+      return false;\n+    }\n+\n+    if (aliasToId == that.aliasToId) {\n+      return true;\n+    }\n+\n+    if (aliasToId == null || that.aliasToId == null) {\n+      return false;\n+    }\n+\n+    return aliasToId.equals(that.aliasToId);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return Objects.hash(struct.fields(), aliasToId == null ? 0 : aliasToId.hashCode());\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "98648e5fc0912b365a6b768435565f969fff4962"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NDQ3NjUy", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-426447652", "createdAt": "2020-06-08T17:12:39Z", "commit": {"oid": "98648e5fc0912b365a6b768435565f969fff4962"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxMjo0MFrOGgoDMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxMjo0MFrOGgoDMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2Mzc5NA==", "bodyText": "asNestedType is no longer necessary. Now asStructType is defined on Type, not just NestedType.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436863794", "createdAt": "2020-06-08T17:12:40Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.types.Type;\n+\n+public class FlinkSchemaUtil {\n+\n+  private FlinkSchemaUtil() {\n+  }\n+\n+  /**\n+   * Convert the flink table schema to apache iceberg schema.\n+   */\n+  public static Schema convert(TableSchema schema) {\n+    Preconditions.checkArgument(schema.toRowDataType() instanceof FieldsDataType, \"Should be FieldsDataType\");\n+\n+    FieldsDataType root = (FieldsDataType) schema.toRowDataType();\n+    Type converted = FlinkTypeVisitor.visit(root, new FlinkTypeToType(root));\n+\n+    return new Schema(converted.asNestedType().asStructType().fields());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "98648e5fc0912b365a6b768435565f969fff4962"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NDQ5NDE0", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-426449414", "createdAt": "2020-06-08T17:14:44Z", "commit": {"oid": "98648e5fc0912b365a6b768435565f969fff4962"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxNDo0NFrOGgoIiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxNDo0NFrOGgoIiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2NTE2MA==", "bodyText": "Why have variable index  when its value is always equal to i?", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436865160", "createdAt": "2020-06-08T17:14:44Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.flink.table.types.logical.ZonedTimestampType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType fields, List<Type> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == fields;\n+\n+    List<RowType.RowField> rowFields = ((RowType) fields.getLogicalType()).getFields();\n+    Preconditions.checkArgument(rowFields.size() == types.size(), \"fields list and types list should have same size.\");\n+\n+    int index = 0;\n+    for (int i = 0; i < rowFields.size(); i++) {\n+      int id = isRoot ? index : getNextId();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "98648e5fc0912b365a6b768435565f969fff4962"}, "originalPosition": 76}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ea48aa2439be6b77fc4bc7aad39e9bcb0a1843f", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/7ea48aa2439be6b77fc4bc7aad39e9bcb0a1843f", "committedDate": "2020-06-09T03:59:51Z", "message": "Addressing the comments round#2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6820f9e03108dcf272168b2d04113d5296a10a37", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/6820f9e03108dcf272168b2d04113d5296a10a37", "committedDate": "2020-06-10T04:05:59Z", "message": "Add flink_2.12 module for scala 2.12"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MjUyMTg3", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-428252187", "createdAt": "2020-06-10T16:55:12Z", "commit": {"oid": "6820f9e03108dcf272168b2d04113d5296a10a37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNjo1NToxMlrOGh-CGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNjo1NToxMlrOGh-CGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI3MjUzOQ==", "bodyText": "There is no source code in flink_2.12, so this module is actually empty. Like I said in the other comment, let's have one 2.12 module for now to get this PR in. Then we can figure out how to test compatibility with 2.11 later.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r438272539", "createdAt": "2020-06-10T16:55:12Z", "author": {"login": "rdblue"}, "path": "build.gradle", "diffHunk": "@@ -235,6 +235,65 @@ project(':iceberg-data') {\n   }\n }\n \n+project(':iceberg-flink') {\n+  dependencies {\n+    compile project(':iceberg-api')\n+    compile project(':iceberg-common')\n+    compile project(':iceberg-core')\n+    compile project(':iceberg-data')\n+    compile project(':iceberg-orc')\n+    compile project(':iceberg-parquet')\n+\n+    compileOnly \"org.apache.flink:flink-streaming-java_2.11\"\n+    compileOnly \"org.apache.flink:flink-streaming-java_2.11::tests\"\n+    compileOnly \"org.apache.flink:flink-table-api-java-bridge_2.11\"\n+    compileOnly \"org.apache.flink:flink-table-planner-blink_2.11\"\n+    compileOnly \"org.apache.flink:flink-table-planner_2.11\"\n+    compileOnly \"org.apache.hadoop:hadoop-hdfs\"\n+    compileOnly \"org.apache.hadoop:hadoop-common\"\n+    compileOnly(\"org.apache.hadoop:hadoop-minicluster\") {\n+      exclude group: 'org.apache.avro', module: 'avro'\n+    }\n+\n+    testCompile \"org.apache.flink:flink-core\"\n+    testCompile \"org.apache.flink:flink-runtime_2.11\"\n+    testCompile \"org.apache.flink:flink-test-utils-junit\"\n+    testCompile(\"org.apache.flink:flink-test-utils_2.11\") {\n+      exclude group: \"org.apache.curator\", module: 'curator-test'\n+    }\n+  }\n+}\n+\n+project(':iceberg-flink_2.12') {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6820f9e03108dcf272168b2d04113d5296a10a37"}, "originalPosition": 33}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e3624f05d29b7d98b9e9602aa529c89e0acbf08", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/2e3624f05d29b7d98b9e9602aa529c89e0acbf08", "committedDate": "2020-06-11T02:46:50Z", "message": "Revert the change that the nubllbility of ListType is depending on DataTypes.ARRAY (it should depend on the nullbility of elementType.)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8891cd5438306f0b4b226706058beff7c3cd4080", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/8891cd5438306f0b4b226706058beff7c3cd4080", "committedDate": "2020-06-12T02:10:02Z", "message": "Remove flink module with scala 2.11 binary"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyOTI1MDc0", "url": "https://github.com/apache/iceberg/pull/1096#pullrequestreview-432925074", "createdAt": "2020-06-18T04:02:22Z", "commit": {"oid": "8891cd5438306f0b4b226706058beff7c3cd4080"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwNDowMjoyMlrOGle1TA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwNDoxODoyMVrOGlfDhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1NTY2MA==", "bodyText": "Flink has LogicalTypeVisitor and DataTypeVisitor, they are very useful for visiting types and you don't need have this static <T> T visit method, it is not so elegant.\nAnd for FieldsDataType, it not has a good design in 1.9 and 1.10, so in Flink 1.11, it has been refactored to be removed getFieldDataTypes.\nAnd I think maybe a LogicalTypeVisitor is enough, since we never touch the physical information in the DataTypes.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r441955660", "createdAt": "2020-06-18T04:02:22Z", "author": {"login": "JingsongLi"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+\n+public class FlinkTypeVisitor<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8891cd5438306f0b4b226706058beff7c3cd4080"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1NzQ4NA==", "bodyText": "A better name is generateNextId or just nextId. Looks like it is not only \"get\".", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r441957484", "createdAt": "2020-06-18T04:09:45Z", "author": {"login": "JingsongLi"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8891cd5438306f0b4b226706058beff7c3cd4080"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1ODc2OQ==", "bodyText": "A CollectionDataType may be MultisetType too. Maybe iceberg not support it now? Or we can map it to Map<T, Integer>.", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r441958769", "createdAt": "2020-06-18T04:15:50Z", "author": {"login": "JingsongLi"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType fields, List<Type> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == fields;\n+\n+    List<RowType.RowField> rowFields = ((RowType) fields.getLogicalType()).getFields();\n+    Preconditions.checkArgument(rowFields.size() == types.size(), \"fields list and types list should have same size.\");\n+\n+    for (int i = 0; i < rowFields.size(); i++) {\n+      int id = isRoot ? i : getNextId();\n+\n+      RowType.RowField field = rowFields.get(i);\n+      String name = field.getName();\n+      String comment = field.getDescription().orElse(null);\n+\n+      if (field.getType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, types.get(i), comment));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, types.get(i), comment));\n+      }\n+    }\n+\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8891cd5438306f0b4b226706058beff7c3cd4080"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1OTMwMA==", "bodyText": "But flink can be, so should we throw unsupported exception here?", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r441959300", "createdAt": "2020-06-18T04:18:21Z", "author": {"login": "JingsongLi"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType fields, List<Type> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == fields;\n+\n+    List<RowType.RowField> rowFields = ((RowType) fields.getLogicalType()).getFields();\n+    Preconditions.checkArgument(rowFields.size() == types.size(), \"fields list and types list should have same size.\");\n+\n+    for (int i = 0; i < rowFields.size(); i++) {\n+      int id = isRoot ? i : getNextId();\n+\n+      RowType.RowField field = rowFields.get(i);\n+      String name = field.getName();\n+      String comment = field.getDescription().orElse(null);\n+\n+      if (field.getType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, types.get(i), comment));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, types.get(i), comment));\n+      }\n+    }\n+\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {\n+    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+      return Types.ListType.ofOptional(getNextId(), elementType);\n+    } else {\n+      return Types.ListType.ofRequired(getNextId(), elementType);\n+    }\n+  }\n+\n+  @Override\n+  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+    // keys in map are not allowed to be null.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8891cd5438306f0b4b226706058beff7c3cd4080"}, "originalPosition": 102}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4484, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}