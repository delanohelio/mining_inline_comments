{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY0ODYyMDE5", "number": 1310, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QyMjo0Njo1MFrOEWYeDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QyMjo0Njo1MFrOEWYeDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxOTA1MDM2OnYy", "diffSide": "RIGHT", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QyMjo0Njo1MFrOG9qxKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QyMzoxNTozMlrOG9rLGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMxNzAzMg==", "bodyText": "I kept the current implementation as sessionState().newHadoopConf() is more expensive. I think the correct fix here would be to broadcast the Hadoop conf. We already do that while broadcasting FileIO, though.", "url": "https://github.com/apache/iceberg/pull/1310#discussion_r467317032", "createdAt": "2020-08-07T22:46:50Z", "author": {"login": "aokolnychyi"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -443,6 +443,7 @@ private Schema lazyExpectedSchema() {\n       return expectedSchema;\n     }\n \n+    @SuppressWarnings(\"checkstyle:RegexpSingleline\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f4dd4674df99abd02f1ddb0f41397c13b4fc5f1"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMxNzc2MA==", "bodyText": "I think we can address that in a follow-up.", "url": "https://github.com/apache/iceberg/pull/1310#discussion_r467317760", "createdAt": "2020-08-07T22:49:51Z", "author": {"login": "aokolnychyi"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -443,6 +443,7 @@ private Schema lazyExpectedSchema() {\n       return expectedSchema;\n     }\n \n+    @SuppressWarnings(\"checkstyle:RegexpSingleline\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMxNzAzMg=="}, "originalCommit": {"oid": "7f4dd4674df99abd02f1ddb0f41397c13b4fc5f1"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMyMzI5MA==", "bodyText": "I think this is fixed in the Spark 3 path, where we use FileIO instead of creating a file system directly.", "url": "https://github.com/apache/iceberg/pull/1310#discussion_r467323290", "createdAt": "2020-08-07T23:13:52Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -443,6 +443,7 @@ private Schema lazyExpectedSchema() {\n       return expectedSchema;\n     }\n \n+    @SuppressWarnings(\"checkstyle:RegexpSingleline\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMxNzAzMg=="}, "originalCommit": {"oid": "7f4dd4674df99abd02f1ddb0f41397c13b4fc5f1"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMyMzY3Mg==", "bodyText": "Let's leave it as is then.", "url": "https://github.com/apache/iceberg/pull/1310#discussion_r467323672", "createdAt": "2020-08-07T23:15:32Z", "author": {"login": "aokolnychyi"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -443,6 +443,7 @@ private Schema lazyExpectedSchema() {\n       return expectedSchema;\n     }\n \n+    @SuppressWarnings(\"checkstyle:RegexpSingleline\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMxNzAzMg=="}, "originalCommit": {"oid": "7f4dd4674df99abd02f1ddb0f41397c13b4fc5f1"}, "originalPosition": 13}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3841, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}