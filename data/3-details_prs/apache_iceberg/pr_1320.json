{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY1ODM0NDMy", "number": 1320, "title": "Flink: Replace Row with RowData in flink write path.", "bodyText": "This patch addressing the third point in issue #1305\n\n\nWe will need an extra patch doing the refactor to replace all the Row type with RowData (I have implemented one in my own branch 2af37c5), and make sure all the unit tests could pass. From this point in time, all flink development and unit tests will use RowData.\n\n\nAfter this patch,  only FlinkParquetReaders, FlinkParquetWriters, RandomData, TestFlinkParquetReaderWriter will reference Row data type.\n\nOnce we merged the pull requests about RowData parquet readers (#1266)  and parquet writers (#1272),  there should be no other core classes that will use Row data type.", "createdAt": "2020-08-11T03:05:20Z", "url": "https://github.com/apache/iceberg/pull/1320", "merged": true, "mergeCommit": {"oid": "a6a511a98a6c679a7ac27c33832960ef8a4e88f1"}, "closed": true, "closedAt": "2020-08-12T20:16:24Z", "author": {"login": "openinx"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc9uOg-gH2gAyNDY1ODM0NDMyOmEyYmFhMTQyZDczM2Q4NjlkYjUwMTgzYjBiYzFjNGZmZjY3ODQxYTM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc-RMakAFqTQ2NjIzNzIzNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a2baa142d733d869db50183b0bc1c4fff67841a3", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/a2baa142d733d869db50183b0bc1c4fff67841a3", "committedDate": "2020-08-11T03:26:57Z", "message": "Flink: Replace Row with RowData in flink write path."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "846e9ce5964fd07ee2696e742859bea84cd0683d", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/846e9ce5964fd07ee2696e742859bea84cd0683d", "committedDate": "2020-08-11T02:54:48Z", "message": "Flink: Replace Row with RowData in flink write path."}, "afterCommit": {"oid": "a2baa142d733d869db50183b0bc1c4fff67841a3", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/a2baa142d733d869db50183b0bc1c4fff67841a3", "committedDate": "2020-08-11T03:26:57Z", "message": "Flink: Replace Row with RowData in flink write path."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1MzU3NzI5", "url": "https://github.com/apache/iceberg/pull/1320#pullrequestreview-465357729", "createdAt": "2020-08-11T19:17:14Z", "commit": {"oid": "a2baa142d733d869db50183b0bc1c4fff67841a3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxOToxNzoxNFrOG_F1BQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxOToxNzoxNFrOG_F1BQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgwODk2NQ==", "bodyText": "In Spark, we had a bug where Spark may produce a row with a short, which is stored as an int in Iceberg. In a CTAS query, data would actually get passed to Iceberg with the short and we would end up with a ClassCastException. That's why we now pass the dataset schema when creating writers. You might want to watch out for a similar bug.", "url": "https://github.com/apache/iceberg/pull/1320#discussion_r468808965", "createdAt": "2020-08-11T19:17:14Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/RowDataTaskWriterFactory.java", "diffHunk": "@@ -38,37 +40,38 @@\n import org.apache.iceberg.io.OutputFileFactory;\n import org.apache.iceberg.io.TaskWriter;\n import org.apache.iceberg.io.UnpartitionedWriter;\n-import org.apache.iceberg.parquet.Parquet;\n import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n \n-class RowTaskWriterFactory implements TaskWriterFactory<Row> {\n+class RowDataTaskWriterFactory implements TaskWriterFactory<RowData> {\n   private final Schema schema;\n   private final PartitionSpec spec;\n   private final LocationProvider locations;\n   private final FileIO io;\n   private final EncryptionManager encryptionManager;\n   private final long targetFileSizeBytes;\n   private final FileFormat format;\n-  private final FileAppenderFactory<Row> appenderFactory;\n+  private final RowType flinkSchema;\n+  private final FileAppenderFactory<RowData> appenderFactory;\n \n   private OutputFileFactory outputFileFactory;\n \n-  RowTaskWriterFactory(Schema schema,\n-                       PartitionSpec spec,\n-                       LocationProvider locations,\n-                       FileIO io,\n-                       EncryptionManager encryptionManager,\n-                       long targetFileSizeBytes,\n-                       FileFormat format,\n-                       Map<String, String> tableProperties) {\n+  RowDataTaskWriterFactory(Schema schema,\n+                           PartitionSpec spec,\n+                           LocationProvider locations,\n+                           FileIO io,\n+                           EncryptionManager encryptionManager,\n+                           long targetFileSizeBytes,\n+                           FileFormat format,\n+                           Map<String, String> tableProperties) {\n     this.schema = schema;\n     this.spec = spec;\n     this.locations = locations;\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.targetFileSizeBytes = targetFileSizeBytes;\n     this.format = format;\n-    this.appenderFactory = new FlinkFileAppenderFactory(schema, tableProperties);\n+    this.flinkSchema = FlinkSchemaUtil.convert(schema);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2baa142d733d869db50183b0bc1c4fff67841a3"}, "originalPosition": 65}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f43ec6118f1af861f29a37f56605edc751868ead", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/f43ec6118f1af861f29a37f56605edc751868ead", "committedDate": "2020-08-12T03:34:57Z", "message": "Address the schema issue from ryan"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "44da7c33f883d472801b1195d25b54405846d4c5", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/44da7c33f883d472801b1195d25b54405846d4c5", "committedDate": "2020-08-12T06:35:20Z", "message": "Add unit tests."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NjM1MDY3", "url": "https://github.com/apache/iceberg/pull/1320#pullrequestreview-465635067", "createdAt": "2020-08-12T06:52:37Z", "commit": {"oid": "44da7c33f883d472801b1195d25b54405846d4c5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo1MjozOFrOG_UF8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo1MjozOFrOG_UF8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTA0MjY3Mw==", "bodyText": "I changed the type from iceberg type to flink's logical type here, because the value of tinyint & smallint is a byte  & short,  when cast to the byte or short to Integer here, it will throw a cast failure exception.  Using logical type here so that we could cast it to integer right way.", "url": "https://github.com/apache/iceberg/pull/1320#discussion_r469042673", "createdAt": "2020-08-12T06:52:38Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/RowDataWrapper.java", "diffHunk": "@@ -85,52 +85,51 @@ public int size() {\n   }\n \n   private static PositionalGetter<?> buildGetter(LogicalType logicalType, Type type) {\n-    switch (type.typeId()) {\n-      case STRING:\n+    switch (logicalType.getTypeRoot()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44da7c33f883d472801b1195d25b54405846d4c5"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "018d16d5fa0273ee442135fe23ee65c4285931b1", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/018d16d5fa0273ee442135fe23ee65c4285931b1", "committedDate": "2020-08-12T07:01:58Z", "message": "Minor changes."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MjM0MTM1", "url": "https://github.com/apache/iceberg/pull/1320#pullrequestreview-466234135", "createdAt": "2020-08-12T20:06:16Z", "commit": {"oid": "018d16d5fa0273ee442135fe23ee65c4285931b1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMDowNjoxNlrOG_wmMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMDowNjoxNlrOG_wmMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTUwOTY4Mg==", "bodyText": "I think an identity check would be okay since this is an enum symbol, but either way is fine.", "url": "https://github.com/apache/iceberg/pull/1320#discussion_r469509682", "createdAt": "2020-08-12T20:06:16Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/RowDataWrapper.java", "diffHunk": "@@ -85,52 +85,51 @@ public int size() {\n   }\n \n   private static PositionalGetter<?> buildGetter(LogicalType logicalType, Type type) {\n-    switch (type.typeId()) {\n-      case STRING:\n+    switch (logicalType.getTypeRoot()) {\n+      case TINYINT:\n+        return (row, pos) -> (int) row.getByte(pos);\n+      case SMALLINT:\n+        return (row, pos) -> (int) row.getShort(pos);\n+      case CHAR:\n+      case VARCHAR:\n         return (row, pos) -> row.getString(pos).toString();\n \n-      case FIXED:\n       case BINARY:\n-        return (row, pos) -> ByteBuffer.wrap(row.getBinary(pos));\n-\n-      case UUID:\n-        return (row, pos) -> {\n-          ByteBuffer bb = ByteBuffer.wrap(row.getBinary(pos));\n-          long mostSigBits = bb.getLong();\n-          long leastSigBits = bb.getLong();\n-          return new UUID(mostSigBits, leastSigBits);\n-        };\n+      case VARBINARY:\n+        if (Type.TypeID.UUID.equals(type.typeId())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "018d16d5fa0273ee442135fe23ee65c4285931b1"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MjM0NTAz", "url": "https://github.com/apache/iceberg/pull/1320#pullrequestreview-466234503", "createdAt": "2020-08-12T20:06:52Z", "commit": {"oid": "018d16d5fa0273ee442135fe23ee65c4285931b1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMDowNjo1M1rOG_wnTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMDowNjo1M1rOG_wnTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTUwOTk2Nw==", "bodyText": "Looks like another area where we should have a util method to convert (though it shouldn't block this commit).", "url": "https://github.com/apache/iceberg/pull/1320#discussion_r469509967", "createdAt": "2020-08-12T20:06:53Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/RowDataWrapper.java", "diffHunk": "@@ -85,52 +85,51 @@ public int size() {\n   }\n \n   private static PositionalGetter<?> buildGetter(LogicalType logicalType, Type type) {\n-    switch (type.typeId()) {\n-      case STRING:\n+    switch (logicalType.getTypeRoot()) {\n+      case TINYINT:\n+        return (row, pos) -> (int) row.getByte(pos);\n+      case SMALLINT:\n+        return (row, pos) -> (int) row.getShort(pos);\n+      case CHAR:\n+      case VARCHAR:\n         return (row, pos) -> row.getString(pos).toString();\n \n-      case FIXED:\n       case BINARY:\n-        return (row, pos) -> ByteBuffer.wrap(row.getBinary(pos));\n-\n-      case UUID:\n-        return (row, pos) -> {\n-          ByteBuffer bb = ByteBuffer.wrap(row.getBinary(pos));\n-          long mostSigBits = bb.getLong();\n-          long leastSigBits = bb.getLong();\n-          return new UUID(mostSigBits, leastSigBits);\n-        };\n+      case VARBINARY:\n+        if (Type.TypeID.UUID.equals(type.typeId())) {\n+          return (row, pos) -> {\n+            ByteBuffer bb = ByteBuffer.wrap(row.getBinary(pos));\n+            long mostSigBits = bb.getLong();\n+            long leastSigBits = bb.getLong();\n+            return new UUID(mostSigBits, leastSigBits);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "018d16d5fa0273ee442135fe23ee65c4285931b1"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MjM1NTQy", "url": "https://github.com/apache/iceberg/pull/1320#pullrequestreview-466235542", "createdAt": "2020-08-12T20:08:33Z", "commit": {"oid": "018d16d5fa0273ee442135fe23ee65c4285931b1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMDowODozM1rOG_wqeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMDowODozM1rOG_wqeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTUxMDc3Nw==", "bodyText": "Why not use the same logic here that is used in the other timestamp type? Both of the values are TimestampData that is returned by getTimestamp. It seems like converting directly to a microsecond value is better than going through LocalDateTime here.", "url": "https://github.com/apache/iceberg/pull/1320#discussion_r469510777", "createdAt": "2020-08-12T20:08:33Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/RowDataWrapper.java", "diffHunk": "@@ -85,52 +85,51 @@ public int size() {\n   }\n \n   private static PositionalGetter<?> buildGetter(LogicalType logicalType, Type type) {\n-    switch (type.typeId()) {\n-      case STRING:\n+    switch (logicalType.getTypeRoot()) {\n+      case TINYINT:\n+        return (row, pos) -> (int) row.getByte(pos);\n+      case SMALLINT:\n+        return (row, pos) -> (int) row.getShort(pos);\n+      case CHAR:\n+      case VARCHAR:\n         return (row, pos) -> row.getString(pos).toString();\n \n-      case FIXED:\n       case BINARY:\n-        return (row, pos) -> ByteBuffer.wrap(row.getBinary(pos));\n-\n-      case UUID:\n-        return (row, pos) -> {\n-          ByteBuffer bb = ByteBuffer.wrap(row.getBinary(pos));\n-          long mostSigBits = bb.getLong();\n-          long leastSigBits = bb.getLong();\n-          return new UUID(mostSigBits, leastSigBits);\n-        };\n+      case VARBINARY:\n+        if (Type.TypeID.UUID.equals(type.typeId())) {\n+          return (row, pos) -> {\n+            ByteBuffer bb = ByteBuffer.wrap(row.getBinary(pos));\n+            long mostSigBits = bb.getLong();\n+            long leastSigBits = bb.getLong();\n+            return new UUID(mostSigBits, leastSigBits);\n+          };\n+        } else {\n+          return (row, pos) -> ByteBuffer.wrap(row.getBinary(pos));\n+        }\n \n       case DECIMAL:\n         DecimalType decimalType = (DecimalType) logicalType;\n         return (row, pos) -> row.getDecimal(pos, decimalType.getPrecision(), decimalType.getScale()).toBigDecimal();\n \n-      case TIME:\n+      case TIME_WITHOUT_TIME_ZONE:\n         // Time in RowData is in milliseconds (Integer), while iceberg's time is microseconds (Long).\n         return (row, pos) -> ((long) row.getInt(pos)) * 1_000;\n \n-      case TIMESTAMP:\n-        switch (logicalType.getTypeRoot()) {\n-          case TIMESTAMP_WITHOUT_TIME_ZONE:\n-            TimestampType timestampType = (TimestampType) logicalType;\n-            return (row, pos) -> {\n-              LocalDateTime localDateTime = row.getTimestamp(pos, timestampType.getPrecision()).toLocalDateTime();\n-              return DateTimeUtil.microsFromTimestamp(localDateTime);\n-            };\n-\n-          case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n-            LocalZonedTimestampType lzTs = (LocalZonedTimestampType) logicalType;\n-            return (row, pos) -> {\n-              TimestampData timestampData = row.getTimestamp(pos, lzTs.getPrecision());\n-              return timestampData.getMillisecond() * 1000 + timestampData.getNanoOfMillisecond() / 1000;\n-            };\n-\n-          default:\n-            throw new IllegalArgumentException(\"Unhandled iceberg type: \" + type + \" corresponding flink type: \" +\n-                logicalType);\n-        }\n+      case TIMESTAMP_WITHOUT_TIME_ZONE:\n+        TimestampType timestampType = (TimestampType) logicalType;\n+        return (row, pos) -> {\n+          LocalDateTime localDateTime = row.getTimestamp(pos, timestampType.getPrecision()).toLocalDateTime();\n+          return DateTimeUtil.microsFromTimestamp(localDateTime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "018d16d5fa0273ee442135fe23ee65c4285931b1"}, "originalPosition": 71}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MjM3MjM0", "url": "https://github.com/apache/iceberg/pull/1320#pullrequestreview-466237234", "createdAt": "2020-08-12T20:11:19Z", "commit": {"oid": "018d16d5fa0273ee442135fe23ee65c4285931b1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMDoxMToxOVrOG_wvrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMDoxMToxOVrOG_wvrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTUxMjEwOQ==", "bodyText": "This could also use the assertEquals implementation that @chenjunjiedada has added in #1266. That would be better than converting a specific record type.", "url": "https://github.com/apache/iceberg/pull/1320#discussion_r469512109", "createdAt": "2020-08-12T20:11:19Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/SimpleDataUtil.java", "diffHunk": "@@ -74,10 +76,16 @@ static Record createRecord(Integer id, String data) {\n     return record;\n   }\n \n-  static void assertTableRows(String tablePath, List<Row> rows) throws IOException {\n+  static RowData createRowData(Integer id, String data) {\n+    return GenericRowData.of(id, StringData.fromString(data));\n+  }\n+\n+  static void assertTableRows(String tablePath, List<RowData> rows) throws IOException {\n     List<Record> records = Lists.newArrayList();\n-    for (Row row : rows) {\n-      records.add(createRecord((Integer) row.getField(0), (String) row.getField(1)));\n+    for (RowData row : rows) {\n+      Integer id = row.isNullAt(0) ? null : row.getInt(0);\n+      String data = row.isNullAt(1) ? null : row.getString(1).toString();\n+      records.add(createRecord(id, data));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "018d16d5fa0273ee442135fe23ee65c4285931b1"}, "originalPosition": 27}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4425, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}