{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1MjQ3NzMy", "number": 830, "title": "Support name mapping resolution for parquet", "bodyText": "This fixes #715.", "createdAt": "2020-03-08T09:55:11Z", "url": "https://github.com/apache/iceberg/pull/830", "merged": true, "mergeCommit": {"oid": "5a3cd22e775dfa8bf79deab675390aad48ba79a5"}, "closed": true, "closedAt": "2020-06-17T16:57:09Z", "author": {"login": "chenjunjiedada"}, "timelineItems": {"totalCount": 91, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcLme1JgBqjMxMDgzMDk4MjY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcsCuGlgH2gAyMzg1MjQ3NzMyOjNjYTE0YzdkZTE5ZmI2YjUxZTlhNjkxMzA2ZjRkZTY0ZTY3Yzg2Yjg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b00fbb4b8acb58dcec8fcf88e6a1947bf28d3f13", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/b00fbb4b8acb58dcec8fcf88e6a1947bf28d3f13", "committedDate": "2020-03-08T09:42:51Z", "message": "Support namemapping resolution for parquet"}, "afterCommit": {"oid": "dd7fb25a8be9ec665628faaef2563bf5eee5ad59", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/dd7fb25a8be9ec665628faaef2563bf5eee5ad59", "committedDate": "2020-03-08T10:08:17Z", "message": "Support namemapping resolution for parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dd7fb25a8be9ec665628faaef2563bf5eee5ad59", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/dd7fb25a8be9ec665628faaef2563bf5eee5ad59", "committedDate": "2020-03-08T10:08:17Z", "message": "Support namemapping resolution for parquet"}, "afterCommit": {"oid": "b3d2f4e17d66ce5a0a55cac7e1918fd6fc29ef44", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/b3d2f4e17d66ce5a0a55cac7e1918fd6fc29ef44", "committedDate": "2020-03-08T12:49:48Z", "message": "Support namemapping resolution for parquet"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwODUyMzQ2", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-370852346", "createdAt": "2020-03-08T19:30:13Z", "commit": {"oid": "b3d2f4e17d66ce5a0a55cac7e1918fd6fc29ef44"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOFQxOTozMDoxM1rOFzW-cQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOFQxOTozMjozOVrOFzW_KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTM5ODEyOQ==", "bodyText": "I think the nameMapping should be taken as a parameter in Parquet as part of the builder and passed in from there", "url": "https://github.com/apache/iceberg/pull/830#discussion_r389398129", "createdAt": "2020-03-08T19:30:13Z", "author": {"login": "rdsr"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -72,29 +74,31 @@\n     this.options = options;\n     this.reader = newReader(file, options);\n     MessageType fileSchema = reader.getFileMetaData().getSchema();\n-\n     boolean hasIds = ParquetSchemaUtil.hasIds(fileSchema);\n-    MessageType typeWithIds = hasIds ? fileSchema : ParquetSchemaUtil.addFallbackIds(fileSchema);\n \n     this.projection = hasIds ?\n-        ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema) :\n-        ParquetSchemaUtil.pruneColumnsFallback(fileSchema, expectedSchema);\n+            ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema) :\n+            ParquetSchemaUtil.pruneColumnsByName(fileSchema, expectedSchema);\n+\n     this.rowGroups = reader.getRowGroups();\n     this.shouldSkip = new boolean[rowGroups.size()];\n \n     ParquetMetricsRowGroupFilter statsFilter = null;\n     ParquetDictionaryRowGroupFilter dictFilter = null;\n     if (filter != null) {\n-      statsFilter = new ParquetMetricsRowGroupFilter(expectedSchema, filter, caseSensitive);\n-      dictFilter = new ParquetDictionaryRowGroupFilter(expectedSchema, filter, caseSensitive);\n+      NameMapping nameMapping = MappingUtil.create(ParquetSchemaUtil.convert(fileSchema));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3d2f4e17d66ce5a0a55cac7e1918fd6fc29ef44"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTM5ODMxMw==", "bodyText": "For Avro  we assigned ids to fileSchema based on the name mapping  and projected ids, which we derived from expected schema. [Set<Integer> projectedIds = TypeUtil.getProjectedIds(expectedSchema)] . This was piggy backed on column pruning code for Avro see - AvroSchemaUtil.pruneColumns\nI'm unsure whether the same general approach can be applied here as well. @rdblue Thoughts?", "url": "https://github.com/apache/iceberg/pull/830#discussion_r389398313", "createdAt": "2020-03-08T19:32:39Z", "author": {"login": "rdsr"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -72,29 +74,31 @@\n     this.options = options;\n     this.reader = newReader(file, options);\n     MessageType fileSchema = reader.getFileMetaData().getSchema();\n-\n     boolean hasIds = ParquetSchemaUtil.hasIds(fileSchema);\n-    MessageType typeWithIds = hasIds ? fileSchema : ParquetSchemaUtil.addFallbackIds(fileSchema);\n \n     this.projection = hasIds ?\n-        ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema) :\n-        ParquetSchemaUtil.pruneColumnsFallback(fileSchema, expectedSchema);\n+            ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema) :\n+            ParquetSchemaUtil.pruneColumnsByName(fileSchema, expectedSchema);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3d2f4e17d66ce5a0a55cac7e1918fd6fc29ef44"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyOTE4MzE2", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-372918316", "createdAt": "2020-03-11T16:21:13Z", "commit": {"oid": "eeb8455304d64ac93db55b14e23fcb0be54c6574"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNjoyMToxNlrOF0-kwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNjoyMToxNlrOF0-kwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTA5NTQ5MA==", "bodyText": "This is only used to pass the build, will fix in another pr.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r391095490", "createdAt": "2020-03-11T16:21:16Z", "author": {"login": "chenjunjiedada"}, "path": "api/src/main/java/org/apache/iceberg/types/TypeUtil.java", "diffHunk": "@@ -190,7 +191,7 @@ public static boolean isPromotionAllowed(Type from, Type.PrimitiveType to) {\n   }\n \n   public static class SchemaVisitor<T> {\n-    private final Deque<Integer> fieldIds = Lists.newLinkedList();\n+    private final Deque<Integer> fieldIds = new ConcurrentLinkedDeque<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eeb8455304d64ac93db55b14e23fcb0be54c6574"}, "originalPosition": 13}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "71189cdc08221ec601c5e230b47343d8a983bdfa", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/71189cdc08221ec601c5e230b47343d8a983bdfa", "committedDate": "2020-03-13T13:27:54Z", "message": "fix code style and doc"}, "afterCommit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/e7a0ecbf699e23a39c26d5658a256391883fa403", "committedDate": "2020-03-19T07:48:30Z", "message": "create name mapping from expected schema"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4Njk0NTQz", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-388694543", "createdAt": "2020-04-06T23:48:38Z", "commit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo0ODozOFrOGBt-Zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo0ODozOFrOGBt-Zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NTAxNA==", "bodyText": "This is called nameMapping in the Avro API. I think I prefer this name, but we should be consistent and either change that one or use the same name here.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r404455014", "createdAt": "2020-04-06T23:48:38Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/Parquet.java", "diffHunk": "@@ -393,6 +395,11 @@ public ReadBuilder recordsPerBatch(int numRowsPerBatch) {\n       return this;\n     }\n \n+    public ReadBuilder withNameMapping(NameMapping newNameMapping) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4Njk4NjE3", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-388698617", "createdAt": "2020-04-07T00:00:20Z", "commit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMDoyMFrOGBuNaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMDoyMFrOGBuNaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1ODg1OQ==", "bodyText": "This class doesn't need to know about the name mapping. The mapping should be used to add IDs to the file schema so that most classes don't need to add specific support.\nLook at how the other fallback happens using ParquetSchemaUtil.addFallbackIds. I think this should mimic that fallback in all cases.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r404458859", "createdAt": "2020-04-07T00:00:20Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java", "diffHunk": "@@ -75,6 +86,16 @@ public ParquetDictionaryRowGroupFilter(Schema schema, Expression unbound, boolea\n    */\n   public boolean shouldRead(MessageType fileSchema, BlockMetaData rowGroup,\n                             DictionaryPageReadStore dictionaries) {\n+    StructType struct;\n+\n+    if (nameMapping != null) {\n+      MessageType project = ParquetSchemaUtil.pruneColumnsByName(fileSchema, schema, nameMapping);\n+      struct = ParquetSchemaUtil.convert(project).asStruct();\n+    } else {\n+      struct = schema.asStruct();\n+    }\n+\n+    this.expr = Binder.bind(struct, Expressions.rewriteNot(expr), caseSensitive);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4Njk4Njkw", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-388698690", "createdAt": "2020-04-07T00:00:31Z", "commit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMDozMlrOGBuNqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMDozMlrOGBuNqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1ODkyMw==", "bodyText": "This file also should not be modified.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r404458923", "createdAt": "2020-04-07T00:00:32Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java", "diffHunk": "@@ -64,8 +68,14 @@ public ParquetMetricsRowGroupFilter(Schema schema, Expression unbound) {\n \n   public ParquetMetricsRowGroupFilter(Schema schema, Expression unbound, boolean caseSensitive) {\n     this.schema = schema;\n-    StructType struct = schema.asStruct();\n-    this.expr = Binder.bind(struct, Expressions.rewriteNot(unbound), caseSensitive);\n+    this.expr = unbound;\n+    this.caseSensitive = caseSensitive;\n+  }\n+\n+\n+  public ParquetMetricsRowGroupFilter withNameMapping(NameMapping newNameMapping) {\n+    this.nameMapping = newNameMapping;\n+    return this;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4Njk4OTUz", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-388698953", "createdAt": "2020-04-07T00:01:23Z", "commit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMToyM1rOGBuOhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMToyM1rOGBuOhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1OTE0MA==", "bodyText": "This should not replace the existing fallback strategy. If the mapping is present, it should be used. Otherwise, the existing position-based fallback strategy should be used.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r404459140", "createdAt": "2020-04-07T00:01:23Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetReadSupport.java", "diffHunk": "@@ -57,7 +58,7 @@ public ReadContext init(Configuration configuration, Map<String, String> keyValu\n \n     MessageType projection = ParquetSchemaUtil.hasIds(fileSchema) ?\n         ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema) :\n-        ParquetSchemaUtil.pruneColumnsFallback(fileSchema, expectedSchema);\n+        ParquetSchemaUtil.pruneColumnsByName(fileSchema, expectedSchema, MappingUtil.create(expectedSchema));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4Njk5MjI3", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-388699227", "createdAt": "2020-04-07T00:02:12Z", "commit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMjoxMlrOGBuPbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMjoxMlrOGBuPbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1OTM3NQ==", "bodyText": "No need for this annotation. Looks like we should have removed it in the other PR as well.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r404459375", "createdAt": "2020-04-07T00:02:12Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -59,42 +61,46 @@\n   private final boolean reuseContainers;\n   @Nullable\n   private final Integer batchSize;\n+  @Nullable", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4Njk5Nzc5", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-388699779", "createdAt": "2020-04-07T00:03:48Z", "commit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMzo0OFrOGBuRRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowMzo0OFrOGBuRRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1OTg0NA==", "bodyText": "This is not the right place to infer a name mapping. This class should apply the name mapping if it exists, and use a position-based fallback otherwise.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r404459844", "createdAt": "2020-04-07T00:03:48Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -59,42 +61,46 @@\n   private final boolean reuseContainers;\n   @Nullable\n   private final Integer batchSize;\n+  @Nullable\n+  private final NameMapping nameMapping;\n \n   // List of column chunk metadata for each row group\n   private final List<Map<ColumnPath, ColumnChunkMetaData>> columnChunkMetaDataForRowGroups;\n \n   @SuppressWarnings(\"unchecked\")\n   ReadConf(InputFile file, ParquetReadOptions options, Schema expectedSchema, Expression filter,\n            Function<MessageType, ParquetValueReader<?>> readerFunc, Function<MessageType,\n-           VectorizedReader<?>> batchedReaderFunc, boolean reuseContainers,\n+           VectorizedReader<?>> batchedReaderFunc, NameMapping nameMapping, boolean reuseContainers,\n            boolean caseSensitive, Integer bSize) {\n     this.file = file;\n     this.options = options;\n     this.reader = newReader(file, options);\n     MessageType fileSchema = reader.getFileMetaData().getSchema();\n-\n     boolean hasIds = ParquetSchemaUtil.hasIds(fileSchema);\n-    MessageType typeWithIds = hasIds ? fileSchema : ParquetSchemaUtil.addFallbackIds(fileSchema);\n+    this.nameMapping = nameMapping == null ? MappingUtil.create(expectedSchema) : nameMapping;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4NzAwMTg1", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-388700185", "createdAt": "2020-04-07T00:05:01Z", "commit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowNTowMVrOGBuSxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwMDowNTowMVrOGBuSxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ2MDIyOA==", "bodyText": "What was the purpose of this change?", "url": "https://github.com/apache/iceberg/pull/830#discussion_r404460228", "createdAt": "2020-04-07T00:05:01Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -59,42 +61,46 @@\n   private final boolean reuseContainers;\n   @Nullable\n   private final Integer batchSize;\n+  @Nullable\n+  private final NameMapping nameMapping;\n \n   // List of column chunk metadata for each row group\n   private final List<Map<ColumnPath, ColumnChunkMetaData>> columnChunkMetaDataForRowGroups;\n \n   @SuppressWarnings(\"unchecked\")\n   ReadConf(InputFile file, ParquetReadOptions options, Schema expectedSchema, Expression filter,\n            Function<MessageType, ParquetValueReader<?>> readerFunc, Function<MessageType,\n-           VectorizedReader<?>> batchedReaderFunc, boolean reuseContainers,\n+           VectorizedReader<?>> batchedReaderFunc, NameMapping nameMapping, boolean reuseContainers,\n            boolean caseSensitive, Integer bSize) {\n     this.file = file;\n     this.options = options;\n     this.reader = newReader(file, options);\n     MessageType fileSchema = reader.getFileMetaData().getSchema();\n-\n     boolean hasIds = ParquetSchemaUtil.hasIds(fileSchema);\n-    MessageType typeWithIds = hasIds ? fileSchema : ParquetSchemaUtil.addFallbackIds(fileSchema);\n+    this.nameMapping = nameMapping == null ? MappingUtil.create(expectedSchema) : nameMapping;\n \n     this.projection = hasIds ?\n-        ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema) :\n-        ParquetSchemaUtil.pruneColumnsFallback(fileSchema, expectedSchema);\n+            ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema) :\n+            ParquetSchemaUtil.pruneColumnsByName(fileSchema, expectedSchema, this.nameMapping);\n+\n     this.rowGroups = reader.getRowGroups();\n     this.shouldSkip = new boolean[rowGroups.size()];\n \n     ParquetMetricsRowGroupFilter statsFilter = null;\n     ParquetDictionaryRowGroupFilter dictFilter = null;\n     if (filter != null) {\n-      statsFilter = new ParquetMetricsRowGroupFilter(expectedSchema, filter, caseSensitive);\n-      dictFilter = new ParquetDictionaryRowGroupFilter(expectedSchema, filter, caseSensitive);\n+      statsFilter = new ParquetMetricsRowGroupFilter(expectedSchema, filter, caseSensitive)\n+              .withNameMapping(this.nameMapping);\n+      dictFilter = new ParquetDictionaryRowGroupFilter(expectedSchema, filter, caseSensitive)\n+              .withNameMapping(this.nameMapping);\n     }\n \n     long computedTotalValues = 0L;\n     for (int i = 0; i < shouldSkip.length; i += 1) {\n       BlockMetaData rowGroup = rowGroups.get(i);\n       boolean shouldRead = filter == null || (\n-          statsFilter.shouldRead(typeWithIds, rowGroup) &&\n-              dictFilter.shouldRead(typeWithIds, rowGroup, reader.getDictionaryReader(rowGroup)));\n+          statsFilter.shouldRead(fileSchema, rowGroup) &&\n+              dictFilter.shouldRead(fileSchema, rowGroup, reader.getDictionaryReader(rowGroup)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7a0ecbf699e23a39c26d5658a256391883fa403"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MzU1MTgz", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-389355183", "createdAt": "2020-04-07T17:52:40Z", "commit": {"oid": "88637dc34b90dbb11ac94bf1f19059909ec4f533"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo1Mjo0MFrOGCPU1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo1Mjo0MFrOGCPU1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwMTQyOQ==", "bodyText": "Why was this changed?", "url": "https://github.com/apache/iceberg/pull/830#discussion_r405001429", "createdAt": "2020-04-07T17:52:40Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java", "diffHunk": "@@ -200,7 +200,7 @@ protected int nextId() {\n     return current;\n   }\n \n-  private int getId(org.apache.parquet.schema.Type type) {\n+  protected int getId(org.apache.parquet.schema.Type type) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88637dc34b90dbb11ac94bf1f19059909ec4f533"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MzU2MjM2", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-389356236", "createdAt": "2020-04-07T17:54:04Z", "commit": {"oid": "88637dc34b90dbb11ac94bf1f19059909ec4f533"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo1NDowNFrOGCPYQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo1NDowNFrOGCPYQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwMjMwNQ==", "bodyText": "It is fine if not everything has an ID. Columns without IDs will be ignored and should not cause a read to fail.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r405002305", "createdAt": "2020-04-07T17:54:04Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -87,29 +82,21 @@ public static boolean hasIds(MessageType fileSchema) {\n       // Try to convert the type to Iceberg. If an ID assignment is needed, return false.\n       ParquetTypeVisitor.visit(fileSchema, new MessageTypeToType(fileSchema) {\n         @Override\n-        protected int nextId() {\n-          throw new IllegalStateException(\"Needed to assign ID\");\n+        protected int getId(org.apache.parquet.schema.Type type) {\n+          org.apache.parquet.schema.Type.ID id = type.getId();\n+          if (id != null) {\n+            throw new IllegalStateException(\"at least one ID exists\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88637dc34b90dbb11ac94bf1f19059909ec4f533"}, "originalPosition": 54}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "05461ee742334cb7ae7880f5f25a765da6ffb538", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/05461ee742334cb7ae7880f5f25a765da6ffb538", "committedDate": "2020-04-08T15:55:23Z", "message": "add ID fallback way back"}, "afterCommit": {"oid": "a92c51ccd4ac1f973e3fb53cee814463805c87a7", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/a92c51ccd4ac1f973e3fb53cee814463805c87a7", "committedDate": "2020-04-08T16:24:09Z", "message": "add ID fallback way back"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a92c51ccd4ac1f973e3fb53cee814463805c87a7", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/a92c51ccd4ac1f973e3fb53cee814463805c87a7", "committedDate": "2020-04-08T16:24:09Z", "message": "add ID fallback way back"}, "afterCommit": {"oid": "7af5eda82dac80ac07a8a86015134c071cc7660f", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/7af5eda82dac80ac07a8a86015134c071cc7660f", "committedDate": "2020-04-08T16:31:02Z", "message": "add ID fallback way back"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7af5eda82dac80ac07a8a86015134c071cc7660f", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/7af5eda82dac80ac07a8a86015134c071cc7660f", "committedDate": "2020-04-08T16:31:02Z", "message": "add ID fallback way back"}, "afterCommit": {"oid": "619087779d0c3d1a1ad84169cb09d12cc94ffcd8", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/619087779d0c3d1a1ad84169cb09d12cc94ffcd8", "committedDate": "2020-04-08T16:51:11Z", "message": "add ID fallback way back"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwOTc5MTU0", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-390979154", "createdAt": "2020-04-09T17:11:14Z", "commit": {"oid": "35e22ff55ac1a743d006c206fa719b311075e1c4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNzoxMToxNFrOGDhwwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNzoxMToxNFrOGDhwwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjM1MjA2NA==", "bodyText": "@rdsr, just want to confirm that you're okay with this change? If it is going to cause you problems because you've already deployed it, we can go with the original.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406352064", "createdAt": "2020-04-09T17:11:14Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/avro/Avro.java", "diffHunk": "@@ -235,7 +235,7 @@ public ReadBuilder rename(String fullName, String newName) {\n       return this;\n     }\n \n-    public ReadBuilder nameMapping(NameMapping newNameMapping) {\n+    public ReadBuilder withNameMapping(NameMapping newNameMapping) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "35e22ff55ac1a743d006c206fa719b311075e1c4"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTQ4ODkw", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391548890", "createdAt": "2020-04-10T16:58:59Z", "commit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNjo1ODo1OVrOGEAANA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNjo1ODo1OVrOGEAANA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg0NzU0MA==", "bodyText": "Do you have a test case where this is thrown?", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406847540", "createdAt": "2020-04-10T16:58:59Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java", "diffHunk": "@@ -108,11 +118,15 @@ private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n       }\n \n       for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n-        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n-        if (colType.getId() != null) {\n-          int id = colType.getId().intValue();\n-          isFallback.put(id, ParquetUtil.hasNonDictionaryPages(meta));\n-          mayContainNulls.put(id, mayContainNull(meta));\n+        try {\n+          PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n+          if (colType.getId() != null) {\n+            int id = colType.getId().intValue();\n+            isFallback.put(id, ParquetUtil.hasNonDictionaryPages(meta));\n+            mayContainNulls.put(id, mayContainNull(meta));\n+          }\n+        } catch (org.apache.parquet.io.InvalidRecordException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "originalPosition": 56}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTQ5Mjkx", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391549291", "createdAt": "2020-04-10T16:59:43Z", "commit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNjo1OTo0M1rOGEABew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNjo1OTo0M1rOGEABew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg0Nzg2Nw==", "bodyText": "Please revert unnecessary changes and move expression binding back into the constructor.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406847867", "createdAt": "2020-04-10T16:59:43Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java", "diffHunk": "@@ -76,6 +81,9 @@ public ParquetMetricsRowGroupFilter(Schema schema, Expression unbound, boolean c\n    * @return false if the file cannot contain rows that match the expression, true otherwise.\n    */\n   public boolean shouldRead(MessageType fileSchema, BlockMetaData rowGroup) {\n+    StructType struct = schema.asStruct();\n+    this.expr = Binder.bind(struct, Expressions.rewriteNot(expr), caseSensitive);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTUzMDM5", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391553039", "createdAt": "2020-04-10T17:07:34Z", "commit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzowNzozNFrOGEAN7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzowNzozNFrOGEAN7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1MTA1Mg==", "bodyText": "Let's pass nameMapping to addFallbackIds and have that choose whether to assign using the mapping or by position.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406851052", "createdAt": "2020-04-10T17:07:34Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -66,19 +63,27 @@\n   @SuppressWarnings(\"unchecked\")\n   ReadConf(InputFile file, ParquetReadOptions options, Schema expectedSchema, Expression filter,\n            Function<MessageType, ParquetValueReader<?>> readerFunc, Function<MessageType,\n-           VectorizedReader<?>> batchedReaderFunc, boolean reuseContainers,\n+           VectorizedReader<?>> batchedReaderFunc, NameMapping nameMapping, boolean reuseContainers,\n            boolean caseSensitive, Integer bSize) {\n     this.file = file;\n     this.options = options;\n     this.reader = newReader(file, options);\n     MessageType fileSchema = reader.getFileMetaData().getSchema();\n-\n     boolean hasIds = ParquetSchemaUtil.hasIds(fileSchema);\n-    MessageType typeWithIds = hasIds ? fileSchema : ParquetSchemaUtil.addFallbackIds(fileSchema);\n+    MessageType typeWithIds;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTUzNTIz", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391553523", "createdAt": "2020-04-10T17:08:37Z", "commit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzowODozN1rOGEAPew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzowODozN1rOGEAPew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1MTQ1MQ==", "bodyText": "This is should recursively assign IDs using a visitor, not just assign to the top-level.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406851451", "createdAt": "2020-04-10T17:08:37Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -112,4 +127,56 @@ public static MessageType addFallbackIds(MessageType fileSchema) {\n \n     return builder.named(fileSchema.getName());\n   }\n+\n+  public static MessageType addFallbackIds(MessageType fileSchema, NameMapping nameMapping) {\n+    MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "originalPosition": 71}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTUzODM5", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391553839", "createdAt": "2020-04-10T17:09:17Z", "commit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzowOToxN1rOGEAQrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzowOToxN1rOGEAQrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1MTc1OA==", "bodyText": "This looks good.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406851758", "createdAt": "2020-04-10T17:09:17Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -112,4 +127,56 @@ public static MessageType addFallbackIds(MessageType fileSchema) {\n \n     return builder.named(fileSchema.getName());\n   }\n+\n+  public static MessageType addFallbackIds(MessageType fileSchema, NameMapping nameMapping) {\n+    MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+\n+    for (Type type : fileSchema.getFields()) {\n+      if (nameMapping.find(type.getName()) != null) {\n+        builder.addField(type.withId(nameMapping.find(type.getName()).id()));\n+      }\n+    }\n+\n+    return builder.named(fileSchema.getName());\n+  }\n+\n+  public static class HasIds extends ParquetTypeVisitor<Boolean> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "originalPosition": 82}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTU1Mjg4", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391555288", "createdAt": "2020-04-10T17:12:10Z", "commit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoxMjoxMVrOGEAVIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoxMjoxMVrOGEAVIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1Mjg5Ng==", "bodyText": "When a name mapping is used, column pruning should happen using the normal pruneColumns. The reason why the other fallback path uses pruneColumnsFallback is because ordinal IDs can only be assigned to the top-level columns and so projection must only use top-level column IDs. That's not a limitation of name mapping, so we can use normal pruning once the IDs are filled in.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406852896", "createdAt": "2020-04-10T17:12:11Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetReadSupport.java", "diffHunk": "@@ -55,9 +58,16 @@ public ReadContext init(Configuration configuration, Map<String, String> keyValu\n     // matching to the file's columns by full path, so this must select columns by using the path\n     // in the file's schema.\n \n-    MessageType projection = ParquetSchemaUtil.hasIds(fileSchema) ?\n-        ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema) :\n-        ParquetSchemaUtil.pruneColumnsFallback(fileSchema, expectedSchema);\n+    MessageType projection;\n+    if (ParquetSchemaUtil.hasIds(fileSchema)) {\n+      projection = ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema);\n+    } else {\n+      if (nameMapping != null) {\n+        projection = ParquetSchemaUtil.pruneColumnsByName(fileSchema, expectedSchema, nameMapping);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "originalPosition": 35}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTU1NzUz", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391555753", "createdAt": "2020-04-10T17:12:59Z", "commit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoxMjo1OVrOGEAWsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoxMjo1OVrOGEAWsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1MzI5OA==", "bodyText": "We don't need this method. Instead, let's add the IDs and then use normal schema pruning.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406853298", "createdAt": "2020-04-10T17:12:59Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -82,23 +86,34 @@ public static MessageType pruneColumnsFallback(MessageType fileSchema, Schema ex\n     return builder.named(fileSchema.getName());\n   }\n \n-  public static boolean hasIds(MessageType fileSchema) {\n-    try {\n-      // Try to convert the type to Iceberg. If an ID assignment is needed, return false.\n-      ParquetTypeVisitor.visit(fileSchema, new MessageTypeToType(fileSchema) {\n-        @Override\n-        protected int nextId() {\n-          throw new IllegalStateException(\"Needed to assign ID\");\n-        }\n-      });\n+  /**\n+   * Prunes columns from a Parquet file schema that was written without field ids.\n+   * The order of columns in the resulting Parquet schema matches the Parquet file.\n+   *\n+   * @param fileSchema schema from a Parquet file that does not have field ids.\n+   * @param expectedSchema expected schema\n+   * @return a parquet schema pruned using the expected schema\n+   */\n+  public static MessageType pruneColumnsByName(MessageType fileSchema, Schema expectedSchema, NameMapping nameMapping) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTU4MTgz", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391558183", "createdAt": "2020-04-10T17:18:00Z", "commit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoxODowMFrOGEAe4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoxODowMFrOGEAe4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1NTM5Mw==", "bodyText": "I don't think a name-based reader is necessary. Instead, the file schema passed to the builder should have IDs assigned.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406855393", "createdAt": "2020-04-10T17:18:00Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetReaders.java", "diffHunk": "@@ -111,6 +124,49 @@ private SparkParquetReaders() {\n     }\n   }\n \n+  private static class NameBasedReadBuilder extends ReadBuilder {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTU4NDY4", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391558468", "createdAt": "2020-04-10T17:18:32Z", "commit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoxODozMlrOGEAf2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoxODozMlrOGEAf2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1NTY0MQ==", "bodyText": "The fileSchema passed here should by the type with IDs filled in.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r406855641", "createdAt": "2020-04-10T17:18:32Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java", "diffHunk": "@@ -171,10 +173,12 @@\n       InputFile location,\n       FileScanTask task,\n       Schema readSchema) {\n+    NameMapping nameMapping = MappingUtil.create(readSchema);\n     return Parquet.read(location)\n         .project(readSchema)\n+        .withNameMapping(nameMapping)\n         .split(task.start(), task.length())\n-        .createReaderFunc(fileSchema -> SparkParquetReaders.buildReader(readSchema, fileSchema))\n+        .createReaderFunc(fileSchema -> SparkParquetReaders.buildReader(readSchema, fileSchema, nameMapping))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07ef73d3390826231d4f8d9f1908af23c9cb872e"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzY4MjYw", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-391768260", "createdAt": "2020-04-11T13:53:16Z", "commit": {"oid": "e3a211f324bf2595071044dfff9522938762e8fa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMzo1MzoxNlrOGENYBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMzo1MzoxNlrOGENYBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA2NjYyOQ==", "bodyText": "I add an extra parameter here because the field names built from the original ParquetTypeVisitor are different in name mapping. For example, if we have a field consists of a list of the map type like below:\noptional(1, \"list_of_maps\",Types.ListType.ofOptional(2, Types.MapType.ofOptional(3, 4,\n    Types.StringType.get(),Types.StringType.get());\n\nthe field names of the map key and value are list_of_map.list.element.map.key and list_of_map.list.element.map.value. While the names in name mapping are list_of_map.element.key and list_of_map.element.value.\nSince the NameMapping is used by Avro already, so I update ParquetTypeVisitor a bit to handle this.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r407066629", "createdAt": "2020-04-11T13:53:16Z", "author": {"login": "chenjunjiedada"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetTypeVisitor.java", "diffHunk": "@@ -34,9 +34,13 @@\n   protected Deque<String> fieldNames = Lists.newLinkedList();\n \n   public static <T> T visit(Type type, ParquetTypeVisitor<T> visitor) {\n+    return visit(type, visitor, false);\n+  }\n+\n+  public static <T> T visit(Type type, ParquetTypeVisitor<T> visitor, Boolean ignoreRepeated) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3a211f324bf2595071044dfff9522938762e8fa"}, "originalPosition": 7}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e3a211f324bf2595071044dfff9522938762e8fa", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/e3a211f324bf2595071044dfff9522938762e8fa", "committedDate": "2020-04-11T13:37:44Z", "message": "Use ParquetTypeVisitor to assign IDs, also add a unit test"}, "afterCommit": {"oid": "a8a7007fffe5795a0c6077a134a40fe7735f4320", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/a8a7007fffe5795a0c6077a134a40fe7735f4320", "committedDate": "2020-04-11T13:57:00Z", "message": "Use ParquetTypeVisitor to assign IDs, also add a unit test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a8a7007fffe5795a0c6077a134a40fe7735f4320", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/a8a7007fffe5795a0c6077a134a40fe7735f4320", "committedDate": "2020-04-11T13:57:00Z", "message": "Use ParquetTypeVisitor to assign IDs, also add a unit test"}, "afterCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9", "committedDate": "2020-04-13T08:10:17Z", "message": "Merge branch 'master' into namemapping"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NDI3OTgx", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-405427981", "createdAt": "2020-05-05T00:09:13Z", "commit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDowOToxNFrOGQWf7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDowOToxNFrOGQWf7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTc5OTAyMw==", "bodyText": "Minor: this could be simplified to return hasId || array.getId() != null.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r419799023", "createdAt": "2020-05-05T00:09:14Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -83,33 +92,144 @@ public static MessageType pruneColumnsFallback(MessageType fileSchema, Schema ex\n   }\n \n   public static boolean hasIds(MessageType fileSchema) {\n-    try {\n-      // Try to convert the type to Iceberg. If an ID assignment is needed, return false.\n-      ParquetTypeVisitor.visit(fileSchema, new MessageTypeToType(fileSchema) {\n-        @Override\n-        protected int nextId() {\n-          throw new IllegalStateException(\"Needed to assign ID\");\n+    return ParquetTypeVisitor.visit(fileSchema, new HasIds(), true);\n+  }\n+\n+  public static MessageType addFallbackIds(MessageType fileSchema, NameMapping nameMapping) {\n+    if (nameMapping == null) {\n+      MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+\n+      int ordinal = 1; // ids are assigned starting at 1\n+      for (Type type : fileSchema.getFields()) {\n+        builder.addField(type.withId(ordinal));\n+        ordinal += 1;\n+      }\n+\n+      return builder.named(fileSchema.getName());\n+    } else {\n+      return (MessageType) ParquetTypeVisitor.visit(fileSchema, new AssignIdsByNameMapping(nameMapping), true);\n+    }\n+  }\n+\n+  public static class HasIds extends ParquetTypeVisitor<Boolean> {\n+    @Override\n+    public Boolean message(MessageType message, List<Boolean> fields) {\n+      return struct(message, fields);\n+    }\n+\n+    @Override\n+    public Boolean struct(GroupType struct, List<Boolean> hasIds) {\n+      for (Boolean hasId : hasIds) {\n+        if (hasId) {\n+          return true;\n         }\n-      });\n+      }\n+      return struct.getId() != null;\n+    }\n+\n+    @Override\n+    public Boolean list(GroupType array, Boolean hasId) {\n+      if (hasId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "originalPosition": 69}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NDI4MTAy", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-405428102", "createdAt": "2020-05-05T00:09:37Z", "commit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDowOTozN1rOGQWgWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDowOTozN1rOGQWgWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTc5OTEyOA==", "bodyText": "This could also be simplified to return keyHasId || valueHasId || map.getId() != null", "url": "https://github.com/apache/iceberg/pull/830#discussion_r419799128", "createdAt": "2020-05-05T00:09:37Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -83,33 +92,144 @@ public static MessageType pruneColumnsFallback(MessageType fileSchema, Schema ex\n   }\n \n   public static boolean hasIds(MessageType fileSchema) {\n-    try {\n-      // Try to convert the type to Iceberg. If an ID assignment is needed, return false.\n-      ParquetTypeVisitor.visit(fileSchema, new MessageTypeToType(fileSchema) {\n-        @Override\n-        protected int nextId() {\n-          throw new IllegalStateException(\"Needed to assign ID\");\n+    return ParquetTypeVisitor.visit(fileSchema, new HasIds(), true);\n+  }\n+\n+  public static MessageType addFallbackIds(MessageType fileSchema, NameMapping nameMapping) {\n+    if (nameMapping == null) {\n+      MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+\n+      int ordinal = 1; // ids are assigned starting at 1\n+      for (Type type : fileSchema.getFields()) {\n+        builder.addField(type.withId(ordinal));\n+        ordinal += 1;\n+      }\n+\n+      return builder.named(fileSchema.getName());\n+    } else {\n+      return (MessageType) ParquetTypeVisitor.visit(fileSchema, new AssignIdsByNameMapping(nameMapping), true);\n+    }\n+  }\n+\n+  public static class HasIds extends ParquetTypeVisitor<Boolean> {\n+    @Override\n+    public Boolean message(MessageType message, List<Boolean> fields) {\n+      return struct(message, fields);\n+    }\n+\n+    @Override\n+    public Boolean struct(GroupType struct, List<Boolean> hasIds) {\n+      for (Boolean hasId : hasIds) {\n+        if (hasId) {\n+          return true;\n         }\n-      });\n+      }\n+      return struct.getId() != null;\n+    }\n+\n+    @Override\n+    public Boolean list(GroupType array, Boolean hasId) {\n+      if (hasId) {\n+        return true;\n+      } else {\n+        return array.getId() != null;\n+      }\n+    }\n \n-      // no assignment was needed\n-      return true;\n+    @Override\n+    public Boolean map(GroupType map, Boolean keyHasId, Boolean valueHasId) {\n+      if (keyHasId || valueHasId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "originalPosition": 80}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NDI4MzYy", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-405428362", "createdAt": "2020-05-05T00:10:28Z", "commit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoxMDoyOFrOGQWhWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoxMDoyOFrOGQWhWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTc5OTM4NA==", "bodyText": "This overwrites any existing IDs, so let's call it applyNameMapping instead.\nAlso, this is quite a large class. Can you move it into its own file? It should be package-private.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r419799384", "createdAt": "2020-05-05T00:10:28Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -83,33 +92,144 @@ public static MessageType pruneColumnsFallback(MessageType fileSchema, Schema ex\n   }\n \n   public static boolean hasIds(MessageType fileSchema) {\n-    try {\n-      // Try to convert the type to Iceberg. If an ID assignment is needed, return false.\n-      ParquetTypeVisitor.visit(fileSchema, new MessageTypeToType(fileSchema) {\n-        @Override\n-        protected int nextId() {\n-          throw new IllegalStateException(\"Needed to assign ID\");\n+    return ParquetTypeVisitor.visit(fileSchema, new HasIds(), true);\n+  }\n+\n+  public static MessageType addFallbackIds(MessageType fileSchema, NameMapping nameMapping) {\n+    if (nameMapping == null) {\n+      MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+\n+      int ordinal = 1; // ids are assigned starting at 1\n+      for (Type type : fileSchema.getFields()) {\n+        builder.addField(type.withId(ordinal));\n+        ordinal += 1;\n+      }\n+\n+      return builder.named(fileSchema.getName());\n+    } else {\n+      return (MessageType) ParquetTypeVisitor.visit(fileSchema, new AssignIdsByNameMapping(nameMapping), true);\n+    }\n+  }\n+\n+  public static class HasIds extends ParquetTypeVisitor<Boolean> {\n+    @Override\n+    public Boolean message(MessageType message, List<Boolean> fields) {\n+      return struct(message, fields);\n+    }\n+\n+    @Override\n+    public Boolean struct(GroupType struct, List<Boolean> hasIds) {\n+      for (Boolean hasId : hasIds) {\n+        if (hasId) {\n+          return true;\n         }\n-      });\n+      }\n+      return struct.getId() != null;\n+    }\n+\n+    @Override\n+    public Boolean list(GroupType array, Boolean hasId) {\n+      if (hasId) {\n+        return true;\n+      } else {\n+        return array.getId() != null;\n+      }\n+    }\n \n-      // no assignment was needed\n-      return true;\n+    @Override\n+    public Boolean map(GroupType map, Boolean keyHasId, Boolean valueHasId) {\n+      if (keyHasId || valueHasId) {\n+        return true;\n+      } else {\n+        return map.getId() != null;\n+      }\n+    }\n \n-    } catch (IllegalStateException e) {\n-      // at least one field was missing an id.\n-      return false;\n+    @Override\n+    public Boolean primitive(PrimitiveType primitive) {\n+      return primitive.getId() != null;\n     }\n   }\n \n-  public static MessageType addFallbackIds(MessageType fileSchema) {\n-    MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+  public static class AssignIdsByNameMapping extends ParquetTypeVisitor<Type> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NDI4NjE5", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-405428619", "createdAt": "2020-05-05T00:11:19Z", "commit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoxMToxOVrOGQWiQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoxMToxOVrOGQWiQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTc5OTYxOA==", "bodyText": "Please rebase on master. #950 moved these methods into the ParquetTypeVisitor so you don't have to copy them.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r419799618", "createdAt": "2020-05-05T00:11:19Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -83,33 +92,144 @@ public static MessageType pruneColumnsFallback(MessageType fileSchema, Schema ex\n   }\n \n   public static boolean hasIds(MessageType fileSchema) {\n-    try {\n-      // Try to convert the type to Iceberg. If an ID assignment is needed, return false.\n-      ParquetTypeVisitor.visit(fileSchema, new MessageTypeToType(fileSchema) {\n-        @Override\n-        protected int nextId() {\n-          throw new IllegalStateException(\"Needed to assign ID\");\n+    return ParquetTypeVisitor.visit(fileSchema, new HasIds(), true);\n+  }\n+\n+  public static MessageType addFallbackIds(MessageType fileSchema, NameMapping nameMapping) {\n+    if (nameMapping == null) {\n+      MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+\n+      int ordinal = 1; // ids are assigned starting at 1\n+      for (Type type : fileSchema.getFields()) {\n+        builder.addField(type.withId(ordinal));\n+        ordinal += 1;\n+      }\n+\n+      return builder.named(fileSchema.getName());\n+    } else {\n+      return (MessageType) ParquetTypeVisitor.visit(fileSchema, new AssignIdsByNameMapping(nameMapping), true);\n+    }\n+  }\n+\n+  public static class HasIds extends ParquetTypeVisitor<Boolean> {\n+    @Override\n+    public Boolean message(MessageType message, List<Boolean> fields) {\n+      return struct(message, fields);\n+    }\n+\n+    @Override\n+    public Boolean struct(GroupType struct, List<Boolean> hasIds) {\n+      for (Boolean hasId : hasIds) {\n+        if (hasId) {\n+          return true;\n         }\n-      });\n+      }\n+      return struct.getId() != null;\n+    }\n+\n+    @Override\n+    public Boolean list(GroupType array, Boolean hasId) {\n+      if (hasId) {\n+        return true;\n+      } else {\n+        return array.getId() != null;\n+      }\n+    }\n \n-      // no assignment was needed\n-      return true;\n+    @Override\n+    public Boolean map(GroupType map, Boolean keyHasId, Boolean valueHasId) {\n+      if (keyHasId || valueHasId) {\n+        return true;\n+      } else {\n+        return map.getId() != null;\n+      }\n+    }\n \n-    } catch (IllegalStateException e) {\n-      // at least one field was missing an id.\n-      return false;\n+    @Override\n+    public Boolean primitive(PrimitiveType primitive) {\n+      return primitive.getId() != null;\n     }\n   }\n \n-  public static MessageType addFallbackIds(MessageType fileSchema) {\n-    MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+  public static class AssignIdsByNameMapping extends ParquetTypeVisitor<Type> {\n+    private final NameMapping nameMapping;\n \n-    int ordinal = 1; // ids are assigned starting at 1\n-    for (Type type : fileSchema.getFields()) {\n-      builder.addField(type.withId(ordinal));\n-      ordinal += 1;\n+    public AssignIdsByNameMapping(NameMapping nameMapping) {\n+      this.nameMapping = nameMapping;\n     }\n \n-    return builder.named(fileSchema.getName());\n+    private String[] currentPath() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "originalPosition": 110}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NDI4Njk3", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-405428697", "createdAt": "2020-05-05T00:11:37Z", "commit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoxMTozN1rOGQWihA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoxMTozN1rOGQWihA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTc5OTY4NA==", "bodyText": "Overall, the implementations in this class look correct to me.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r419799684", "createdAt": "2020-05-05T00:11:37Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -83,33 +92,144 @@ public static MessageType pruneColumnsFallback(MessageType fileSchema, Schema ex\n   }\n \n   public static boolean hasIds(MessageType fileSchema) {\n-    try {\n-      // Try to convert the type to Iceberg. If an ID assignment is needed, return false.\n-      ParquetTypeVisitor.visit(fileSchema, new MessageTypeToType(fileSchema) {\n-        @Override\n-        protected int nextId() {\n-          throw new IllegalStateException(\"Needed to assign ID\");\n+    return ParquetTypeVisitor.visit(fileSchema, new HasIds(), true);\n+  }\n+\n+  public static MessageType addFallbackIds(MessageType fileSchema, NameMapping nameMapping) {\n+    if (nameMapping == null) {\n+      MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+\n+      int ordinal = 1; // ids are assigned starting at 1\n+      for (Type type : fileSchema.getFields()) {\n+        builder.addField(type.withId(ordinal));\n+        ordinal += 1;\n+      }\n+\n+      return builder.named(fileSchema.getName());\n+    } else {\n+      return (MessageType) ParquetTypeVisitor.visit(fileSchema, new AssignIdsByNameMapping(nameMapping), true);\n+    }\n+  }\n+\n+  public static class HasIds extends ParquetTypeVisitor<Boolean> {\n+    @Override\n+    public Boolean message(MessageType message, List<Boolean> fields) {\n+      return struct(message, fields);\n+    }\n+\n+    @Override\n+    public Boolean struct(GroupType struct, List<Boolean> hasIds) {\n+      for (Boolean hasId : hasIds) {\n+        if (hasId) {\n+          return true;\n         }\n-      });\n+      }\n+      return struct.getId() != null;\n+    }\n+\n+    @Override\n+    public Boolean list(GroupType array, Boolean hasId) {\n+      if (hasId) {\n+        return true;\n+      } else {\n+        return array.getId() != null;\n+      }\n+    }\n \n-      // no assignment was needed\n-      return true;\n+    @Override\n+    public Boolean map(GroupType map, Boolean keyHasId, Boolean valueHasId) {\n+      if (keyHasId || valueHasId) {\n+        return true;\n+      } else {\n+        return map.getId() != null;\n+      }\n+    }\n \n-    } catch (IllegalStateException e) {\n-      // at least one field was missing an id.\n-      return false;\n+    @Override\n+    public Boolean primitive(PrimitiveType primitive) {\n+      return primitive.getId() != null;\n     }\n   }\n \n-  public static MessageType addFallbackIds(MessageType fileSchema) {\n-    MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+  public static class AssignIdsByNameMapping extends ParquetTypeVisitor<Type> {\n+    private final NameMapping nameMapping;\n \n-    int ordinal = 1; // ids are assigned starting at 1\n-    for (Type type : fileSchema.getFields()) {\n-      builder.addField(type.withId(ordinal));\n-      ordinal += 1;\n+    public AssignIdsByNameMapping(NameMapping nameMapping) {\n+      this.nameMapping = nameMapping;\n     }\n \n-    return builder.named(fileSchema.getName());\n+    private String[] currentPath() {\n+      String[] path = new String[fieldNames.size()];\n+      if (!fieldNames.isEmpty()) {\n+        Iterator<String> iter = fieldNames.descendingIterator();\n+        for (int i = 0; iter.hasNext(); i += 1) {\n+          path[i] = iter.next();\n+        }\n+      }\n+\n+      return path;\n+    }\n+\n+    @Override\n+    public Type message(MessageType message, List<Type> fields) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NDMwMjg2", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-405430286", "createdAt": "2020-05-05T00:16:19Z", "commit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoxNjoxOVrOGQWoYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoxNjoxOVrOGQWoYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgwMTE4NA==", "bodyText": "Let's leave this line to avoid git conflicts.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r419801184", "createdAt": "2020-05-05T00:16:19Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -66,19 +63,21 @@\n   @SuppressWarnings(\"unchecked\")\n   ReadConf(InputFile file, ParquetReadOptions options, Schema expectedSchema, Expression filter,\n            Function<MessageType, ParquetValueReader<?>> readerFunc, Function<MessageType,\n-           VectorizedReader<?>> batchedReaderFunc, boolean reuseContainers,\n+           VectorizedReader<?>> batchedReaderFunc, NameMapping nameMapping, boolean reuseContainers,\n            boolean caseSensitive, Integer bSize) {\n     this.file = file;\n     this.options = options;\n     this.reader = newReader(file, options);\n     MessageType fileSchema = reader.getFileMetaData().getSchema();\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NDMyMjAx", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-405432201", "createdAt": "2020-05-05T00:22:56Z", "commit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoyMjo1N1rOGQWviw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDoyMjo1N1rOGQWviw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgwMzAxOQ==", "bodyText": "This should use asStruct() instead of toString.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r419803019", "createdAt": "2020-05-05T00:22:57Z", "author": {"login": "rdblue"}, "path": "parquet/src/test/java/org/apache/iceberg/parquet/TestParquetSchemaUtil.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.parquet;\n+\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.mapping.MappingUtil;\n+import org.apache.iceberg.mapping.NameMapping;\n+import org.apache.iceberg.types.TypeUtil;\n+import org.apache.iceberg.types.Types;\n+import org.apache.parquet.schema.MessageType;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestParquetSchemaUtil {\n+  private static final Types.StructType SUPPORTED_PRIMITIVES = Types.StructType.of(\n+      required(100, \"id\", Types.LongType.get()),\n+      optional(101, \"data\", Types.StringType.get()),\n+      required(102, \"b\", Types.BooleanType.get()),\n+      optional(103, \"i\", Types.IntegerType.get()),\n+      required(104, \"l\", Types.LongType.get()),\n+      optional(105, \"f\", Types.FloatType.get()),\n+      required(106, \"d\", Types.DoubleType.get()),\n+      optional(107, \"date\", Types.DateType.get()),\n+      required(108, \"ts\", Types.TimestampType.withZone()),\n+      required(110, \"s\", Types.StringType.get()),\n+      required(112, \"fixed\", Types.FixedType.ofLength(7)),\n+      optional(113, \"bytes\", Types.BinaryType.get()),\n+      required(114, \"dec_9_0\", Types.DecimalType.of(9, 0)),\n+      required(115, \"dec_11_2\", Types.DecimalType.of(11, 2)),\n+      required(116, \"dec_38_10\", Types.DecimalType.of(38, 10)) // spark's maximum precision\n+  );\n+\n+  @Test\n+  public void testAssignIdsByNameMapping() {\n+    Types.StructType structType = Types.StructType.of(\n+        required(0, \"id\", Types.LongType.get()),\n+        optional(1, \"list_of_maps\",\n+            Types.ListType.ofOptional(2, Types.MapType.ofOptional(3, 4,\n+                Types.StringType.get(),\n+                SUPPORTED_PRIMITIVES))),\n+        optional(5, \"map_of_lists\",\n+            Types.MapType.ofOptional(6, 7,\n+                Types.StringType.get(),\n+                Types.ListType.ofOptional(8, SUPPORTED_PRIMITIVES))),\n+        required(9, \"list_of_lists\",\n+            Types.ListType.ofOptional(10, Types.ListType.ofOptional(11, SUPPORTED_PRIMITIVES))),\n+        required(12, \"map_of_maps\",\n+            Types.MapType.ofOptional(13, 14,\n+                Types.StringType.get(),\n+                Types.MapType.ofOptional(15, 16,\n+                    Types.StringType.get(),\n+                    SUPPORTED_PRIMITIVES))),\n+        required(17, \"list_of_struct_of_nested_types\", Types.ListType.ofOptional(19, Types.StructType.of(\n+            Types.NestedField.required(20, \"m1\", Types.MapType.ofOptional(21, 22,\n+                Types.StringType.get(),\n+                SUPPORTED_PRIMITIVES)),\n+            Types.NestedField.optional(23, \"l1\", Types.ListType.ofRequired(24, SUPPORTED_PRIMITIVES)),\n+            Types.NestedField.required(25, \"l2\", Types.ListType.ofRequired(26, SUPPORTED_PRIMITIVES)),\n+            Types.NestedField.optional(27, \"m2\", Types.MapType.ofOptional(28, 29,\n+                Types.StringType.get(),\n+                SUPPORTED_PRIMITIVES))\n+        )))\n+    );\n+\n+    Schema schema = new Schema(TypeUtil.assignFreshIds(structType, new AtomicInteger(0)::incrementAndGet)\n+        .asStructType().fields());\n+    NameMapping nameMapping = MappingUtil.create(schema);\n+    MessageType messageType = ParquetSchemaUtil.convert(schema, \"complex_schema\");\n+    MessageType typeWithIdsFromNameMapping = ParquetSchemaUtil.addFallbackIds(messageType, nameMapping);\n+    Schema newSchema = ParquetSchemaUtil.convert(typeWithIdsFromNameMapping);\n+\n+    Assert.assertEquals(schema.toString(), newSchema.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NDM4MDc3", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-405438077", "createdAt": "2020-05-05T00:43:49Z", "commit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDo0Mzo0OVrOGQXFpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMDo0Mzo0OVrOGQXFpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgwODY3Nw==", "bodyText": "This logic assumes what addFallbackIds is going to do. I think I'd rather structure this a bit differently:\nMessageType typeWithIds;\nif (ParquetSchemaUtil.hasIds(fileSchema)) {\n  typeWithIds = fileSchema;\n  this.projection = ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema);\n} else if (nameMapping != null) {\n  typeWithIds = ParquetSchemaUtil.applyNameMapping(fileSchema, nameMapping);\n  this.projection = ParquetSchemaUtil.pruneColumns(typeWithIds, expectedSchema);\n} else {\n  typeWithIds = ParquetSchemaUtil.addFallbackIds(fileSchema);\n  this.projection = ParquetSchemaUtil.pruneColumnsFallback(fileSchema, expectedSchema);\n}", "url": "https://github.com/apache/iceberg/pull/830#discussion_r419808677", "createdAt": "2020-05-05T00:43:49Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -66,19 +63,21 @@\n   @SuppressWarnings(\"unchecked\")\n   ReadConf(InputFile file, ParquetReadOptions options, Schema expectedSchema, Expression filter,\n            Function<MessageType, ParquetValueReader<?>> readerFunc, Function<MessageType,\n-           VectorizedReader<?>> batchedReaderFunc, boolean reuseContainers,\n+           VectorizedReader<?>> batchedReaderFunc, NameMapping nameMapping, boolean reuseContainers,\n            boolean caseSensitive, Integer bSize) {\n     this.file = file;\n     this.options = options;\n     this.reader = newReader(file, options);\n     MessageType fileSchema = reader.getFileMetaData().getSchema();\n-\n     boolean hasIds = ParquetSchemaUtil.hasIds(fileSchema);\n-    MessageType typeWithIds = hasIds ? fileSchema : ParquetSchemaUtil.addFallbackIds(fileSchema);\n+    MessageType typeWithIds = hasIds ? fileSchema : ParquetSchemaUtil.addFallbackIds(fileSchema, nameMapping);\n+\n+    if (nameMapping == null && !hasIds) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9"}, "originalPosition": 45}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/f1115034c0db5ded6a7feab0a3cf7e8bbd1e24d9", "committedDate": "2020-04-13T08:10:17Z", "message": "Merge branch 'master' into namemapping"}, "afterCommit": {"oid": "9114d4fe020b74baa689f655fff3ce5152af3585", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/9114d4fe020b74baa689f655fff3ce5152af3585", "committedDate": "2020-05-05T13:58:13Z", "message": "rebase to master"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9114d4fe020b74baa689f655fff3ce5152af3585", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/9114d4fe020b74baa689f655fff3ce5152af3585", "committedDate": "2020-05-05T13:58:13Z", "message": "rebase to master"}, "afterCommit": {"oid": "8860208ec4a011743117e421b3c90140f71293e3", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/8860208ec4a011743117e421b3c90140f71293e3", "committedDate": "2020-05-05T14:21:44Z", "message": "rebase to master"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8860208ec4a011743117e421b3c90140f71293e3", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/8860208ec4a011743117e421b3c90140f71293e3", "committedDate": "2020-05-05T14:21:44Z", "message": "rebase to master"}, "afterCommit": {"oid": "d9c01c257aa704adc0aaf470731a23f6cf8be413", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/d9c01c257aa704adc0aaf470731a23f6cf8be413", "committedDate": "2020-05-05T14:24:32Z", "message": "rebase to master"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d9c01c257aa704adc0aaf470731a23f6cf8be413", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/d9c01c257aa704adc0aaf470731a23f6cf8be413", "committedDate": "2020-05-05T14:24:32Z", "message": "rebase to master"}, "afterCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/8554c33ff2cc4090d864ef38139d36d9734e64fe", "committedDate": "2020-05-05T14:37:47Z", "message": "Address comments and rebase to master"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzM3NzUy", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-407737752", "createdAt": "2020-05-07T18:40:03Z", "commit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0MDowM1rOGSLaJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0MDowM1rOGSLaJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTcxNDQ2OA==", "bodyText": "This shouldn't create a name mapping. It should use one from the table, if it exists.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r421714468", "createdAt": "2020-05-07T18:40:03Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java", "diffHunk": "@@ -192,8 +194,10 @@\n       FileScanTask task,\n       Schema readSchema,\n       Map<Integer, ?> idToConstant) {\n+    NameMapping nameMapping = MappingUtil.create(readSchema);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzM5MTM4", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-407739138", "createdAt": "2020-05-07T18:42:02Z", "commit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0MjowMlrOGSLejQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0MjowMlrOGSLejQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTcxNTU5Nw==", "bodyText": "No need for a newline here.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r421715597", "createdAt": "2020-05-07T18:42:02Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetReadSupport.java", "diffHunk": "@@ -55,9 +58,16 @@ public ReadContext init(Configuration configuration, Map<String, String> keyValu\n     // matching to the file's columns by full path, so this must select columns by using the path\n     // in the file's schema.\n \n-    MessageType projection = ParquetSchemaUtil.hasIds(fileSchema) ?\n-        ParquetSchemaUtil.pruneColumns(fileSchema, expectedSchema) :\n-        ParquetSchemaUtil.pruneColumnsFallback(fileSchema, expectedSchema);\n+    MessageType projection;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "originalPosition": 31}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzQwNDQ5", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-407740449", "createdAt": "2020-05-07T18:43:52Z", "commit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0Mzo1MlrOGSLitA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0Mzo1MlrOGSLitA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTcxNjY2MA==", "bodyText": "Let's rename this to mach the method, ApplyNameMapping.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r421716660", "createdAt": "2020-05-07T18:43:52Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/AssignIdsByNameMapping.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.parquet;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import org.apache.iceberg.mapping.MappedField;\n+import org.apache.iceberg.mapping.NameMapping;\n+import org.apache.parquet.Preconditions;\n+import org.apache.parquet.schema.GroupType;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.PrimitiveType;\n+import org.apache.parquet.schema.Type;\n+import org.apache.parquet.schema.Types;\n+\n+class AssignIdsByNameMapping extends ParquetTypeVisitor<Type> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzQxMjIy", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-407741222", "createdAt": "2020-05-07T18:44:56Z", "commit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0NDo1NlrOGSLlZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0NDo1NlrOGSLlZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTcxNzM0OA==", "bodyText": "Nit: Indentation is incorrect here.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r421717348", "createdAt": "2020-05-07T18:44:56Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkTableUtil.java", "diffHunk": "@@ -199,4 +204,41 @@ public void testImportAsHiveTable() throws Exception {\n     long count2 = spark.read().format(\"iceberg\").load(DB_NAME + \".test_partitioned_table\").count();\n     Assert.assertEquals(\"three values \", 3, count2);\n   }\n+\n+  @Test\n+  public void testImportWithIncompatibleSchema() throws Exception {\n+    spark.table(qualifiedTableName).write().mode(\"overwrite\").format(\"parquet\")\n+        .saveAsTable(\"original_table\");\n+\n+    // The field is different so that it will project with name mapping\n+    Schema filteredSchema = new Schema(\n+            optional(1, \"data\", Types.StringType.get())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzQxMzk2", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-407741396", "createdAt": "2020-05-07T18:45:12Z", "commit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0NToxMlrOGSLmDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0NToxMlrOGSLmDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTcxNzUxNg==", "bodyText": "Why isn't TableIdentifier imported?", "url": "https://github.com/apache/iceberg/pull/830#discussion_r421717516", "createdAt": "2020-05-07T18:45:12Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkTableUtil.java", "diffHunk": "@@ -199,4 +204,41 @@ public void testImportAsHiveTable() throws Exception {\n     long count2 = spark.read().format(\"iceberg\").load(DB_NAME + \".test_partitioned_table\").count();\n     Assert.assertEquals(\"three values \", 3, count2);\n   }\n+\n+  @Test\n+  public void testImportWithIncompatibleSchema() throws Exception {\n+    spark.table(qualifiedTableName).write().mode(\"overwrite\").format(\"parquet\")\n+        .saveAsTable(\"original_table\");\n+\n+    // The field is different so that it will project with name mapping\n+    Schema filteredSchema = new Schema(\n+            optional(1, \"data\", Types.StringType.get())\n+    );\n+\n+    TableIdentifier source = new TableIdentifier(\"original_table\");\n+    Table table = catalog.createTable(\n+        org.apache.iceberg.catalog.TableIdentifier.of(DB_NAME, \"target_table\"),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzQ0ODMw", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-407744830", "createdAt": "2020-05-07T18:49:53Z", "commit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0OTo1M1rOGSLwWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo0OTo1M1rOGSLwWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTcyMDE1Mg==", "bodyText": "Name mapping should only be used if it is set on the table.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r421720152", "createdAt": "2020-05-07T18:49:53Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkTableUtil.java", "diffHunk": "@@ -199,4 +204,41 @@ public void testImportAsHiveTable() throws Exception {\n     long count2 = spark.read().format(\"iceberg\").load(DB_NAME + \".test_partitioned_table\").count();\n     Assert.assertEquals(\"three values \", 3, count2);\n   }\n+\n+  @Test\n+  public void testImportWithIncompatibleSchema() throws Exception {\n+    spark.table(qualifiedTableName).write().mode(\"overwrite\").format(\"parquet\")\n+        .saveAsTable(\"original_table\");\n+\n+    // The field is different so that it will project with name mapping", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzQ2NzUy", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-407746752", "createdAt": "2020-05-07T18:52:25Z", "commit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo1MjoyNVrOGSL2FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo1MjoyNVrOGSL2FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTcyMTYyMA==", "bodyText": "This should be named testImportWithNameMapping instead. The schema isn't incompatible, it just uses a different strategy (name mapping, instead of position mapping) to assign IDs for fields.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r421721620", "createdAt": "2020-05-07T18:52:25Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkTableUtil.java", "diffHunk": "@@ -199,4 +204,41 @@ public void testImportAsHiveTable() throws Exception {\n     long count2 = spark.read().format(\"iceberg\").load(DB_NAME + \".test_partitioned_table\").count();\n     Assert.assertEquals(\"three values \", 3, count2);\n   }\n+\n+  @Test\n+  public void testImportWithIncompatibleSchema() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzUwMzM5", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-407750339", "createdAt": "2020-05-07T18:57:26Z", "commit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo1NzoyNlrOGSMBWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxODo1NzoyNlrOGSMBWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTcyNDUwNw==", "bodyText": "This should return the list with IDs assigned to sub-types.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r421724507", "createdAt": "2020-05-07T18:57:26Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/AssignIdsByNameMapping.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.parquet;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import org.apache.iceberg.mapping.MappedField;\n+import org.apache.iceberg.mapping.NameMapping;\n+import org.apache.parquet.Preconditions;\n+import org.apache.parquet.schema.GroupType;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.PrimitiveType;\n+import org.apache.parquet.schema.Type;\n+import org.apache.parquet.schema.Types;\n+\n+class AssignIdsByNameMapping extends ParquetTypeVisitor<Type> {\n+  private final NameMapping nameMapping;\n+\n+  AssignIdsByNameMapping(NameMapping nameMapping) {\n+    this.nameMapping = nameMapping;\n+  }\n+\n+  @Override\n+  public Type message(MessageType message, List<Type> fields) {\n+    Types.MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+    fields.stream().filter(Objects::nonNull).forEach(builder::addField);\n+\n+    return builder.named(message.getName());\n+  }\n+\n+  @Override\n+  public Type struct(GroupType struct, List<Type> types) {\n+    MappedField field = nameMapping.find(currentPath());\n+    if (field == null) {\n+      return null;\n+    }\n+    List<Type> actualTypes = types.stream().filter(Objects::nonNull).collect(Collectors.toList());\n+\n+    return struct.withNewFields(actualTypes).withId(field.id());\n+  }\n+\n+  @Override\n+  public Type list(GroupType list, Type elementType) {\n+    MappedField field = nameMapping.find(currentPath());\n+    if (field == null) {\n+      return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "originalPosition": 64}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzY0Mjc2", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-407764276", "createdAt": "2020-05-07T19:17:28Z", "commit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxOToxNzoyOVrOGSMsvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxOToxNzoyOVrOGSMsvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTczNTYxNA==", "bodyText": "When a Parquet file is imported, its schema is converted to Iceberg using MessageTypeToType, which assigns IDs to fields using the position-based strategy. Stats from those files are generated and stored in Iceberg metadata using the position-based IDs, not name-based. That means for this imported table, the stats in Iceberg metadata are incorrect.\nTo fix this, you also need to support name mapping in the conversion from Parquet to an Iceberg schema, and make sure that is called here. Alternatively, you could detect that the table has a name mapping and skip metrics when importing data files.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r421735614", "createdAt": "2020-05-07T19:17:29Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkTableUtil.java", "diffHunk": "@@ -199,4 +204,41 @@ public void testImportAsHiveTable() throws Exception {\n     long count2 = spark.read().format(\"iceberg\").load(DB_NAME + \".test_partitioned_table\").count();\n     Assert.assertEquals(\"three values \", 3, count2);\n   }\n+\n+  @Test\n+  public void testImportWithIncompatibleSchema() throws Exception {\n+    spark.table(qualifiedTableName).write().mode(\"overwrite\").format(\"parquet\")\n+        .saveAsTable(\"original_table\");\n+\n+    // The field is different so that it will project with name mapping\n+    Schema filteredSchema = new Schema(\n+            optional(1, \"data\", Types.StringType.get())\n+    );\n+\n+    TableIdentifier source = new TableIdentifier(\"original_table\");\n+    Table table = catalog.createTable(\n+        org.apache.iceberg.catalog.TableIdentifier.of(DB_NAME, \"target_table\"),\n+        filteredSchema,\n+        SparkSchemaUtil.specForTable(spark, \"original_table\"));\n+    File stagingDir = temp.newFolder(\"staging-dir\");\n+    SparkTableUtil.importSparkTable(spark, source, table, stagingDir.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8554c33ff2cc4090d864ef38139d36d9734e64fe"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe05997129abb8813b462f78ace9096de9a3f2a5", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/fe05997129abb8813b462f78ace9096de9a3f2a5", "committedDate": "2020-05-14T01:56:34Z", "message": "Support namemapping resolution for parquet"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2f6b96409421d19e1e800ce7e71a641ccb9a412", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/b2f6b96409421d19e1e800ce7e71a641ccb9a412", "committedDate": "2020-05-14T01:56:34Z", "message": "create name mapping from expected schema"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "502b1b935a902a9fa208d5e2443fe011fb51eff5", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/502b1b935a902a9fa208d5e2443fe011fb51eff5", "committedDate": "2020-05-14T01:56:34Z", "message": "Address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1fd7d605b54a637d76a2d0bd86cf67914f68e93f", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/1fd7d605b54a637d76a2d0bd86cf67914f68e93f", "committedDate": "2020-05-14T01:56:34Z", "message": "add ID fallback way back"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d851ad520a3358b1156b057dfb41f9d3f39b2bb8", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/d851ad520a3358b1156b057dfb41f9d3f39b2bb8", "committedDate": "2020-05-14T01:56:34Z", "message": "Add HasIds visitor to detect schema ID"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "19809366c8913658675df8dfca7314bf6b9d3456", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/19809366c8913658675df8dfca7314bf6b9d3456", "committedDate": "2020-05-14T01:56:34Z", "message": "fix coding style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7db31f5eeb6f304b669841814cd4b507bd72f1d6", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/7db31f5eeb6f304b669841814cd4b507bd72f1d6", "committedDate": "2020-05-14T01:56:34Z", "message": "use typeWithIds"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3145244890a4984cff80a98ba7e6ad823091df1", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/c3145244890a4984cff80a98ba7e6ad823091df1", "committedDate": "2020-05-14T01:56:55Z", "message": "Use ParquetTypeVisitor to assign IDs, also add a unit test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd4c7d0444040510aad01aecd04364f8b0829f69", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/fd4c7d0444040510aad01aecd04364f8b0829f69", "committedDate": "2020-05-14T01:56:55Z", "message": "Address comments and rebase to master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3323ae016246fa2353732b8340c44dca445ec97b", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/3323ae016246fa2353732b8340c44dca445ec97b", "committedDate": "2020-05-14T01:56:55Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d718765d849f91a5910f16ba7cfb72d454026eda", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/d718765d849f91a5910f16ba7cfb72d454026eda", "committedDate": "2020-05-14T01:56:55Z", "message": "update ApplyNameMapping implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a12f430b02bda993c19c3b9f20cdd4d8a6ff0d37", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/a12f430b02bda993c19c3b9f20cdd4d8a6ff0d37", "committedDate": "2020-05-14T02:16:42Z", "message": "update ApplyNameMapping to use latest ParquetTypeVisito"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "69777b79d0bf134cf5ae4f279c5e2d722745d8fc", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/69777b79d0bf134cf5ae4f279c5e2d722745d8fc", "committedDate": "2020-05-08T09:06:35Z", "message": "update ApplyNameMapping implementation"}, "afterCommit": {"oid": "a12f430b02bda993c19c3b9f20cdd4d8a6ff0d37", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/a12f430b02bda993c19c3b9f20cdd4d8a6ff0d37", "committedDate": "2020-05-14T02:16:42Z", "message": "update ApplyNameMapping to use latest ParquetTypeVisito"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2NDc1Mjg2", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-416475286", "createdAt": "2020-05-21T20:39:50Z", "commit": {"oid": "a12f430b02bda993c19c3b9f20cdd4d8a6ff0d37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQyMDozOTo1MFrOGZCEfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQyMDozOTo1MFrOGZCEfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODkwMTUwMQ==", "bodyText": "Parquet should never automatically add a mapping. When reading, a name mapping should be parsed and added if one is present in table properties.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r428901501", "createdAt": "2020-05-21T20:39:50Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/Parquet.java", "diffHunk": "@@ -419,17 +433,18 @@ public ReadBuilder recordsPerBatch(int numRowsPerBatch) {\n         ParquetReadOptions options = optionsBuilder.build();\n \n         if (batchedReaderFunc != null) {\n-          return new VectorizedParquetReader(file, schema, options, batchedReaderFunc, filter, reuseContainers,\n-              caseSensitive, maxRecordsPerBatch);\n+          return new VectorizedParquetReader(file, schema, options, batchedReaderFunc, nameMapping,\n+              applyNameMapping, filter, reuseContainers, caseSensitive, maxRecordsPerBatch);\n         } else {\n           return new org.apache.iceberg.parquet.ParquetReader<>(\n-              file, schema, options, readerFunc, filter, reuseContainers, caseSensitive);\n+              file, schema, options, readerFunc, nameMapping, applyNameMapping, filter, reuseContainers,\n+              caseSensitive);\n         }\n       }\n \n       ParquetReadBuilder<D> builder = new ParquetReadBuilder<>(ParquetIO.file(file));\n \n-      builder.project(schema);\n+      builder.project(schema).withNameMapping(MappingUtil.create(schema));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a12f430b02bda993c19c3b9f20cdd4d8a6ff0d37"}, "originalPosition": 54}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e1e393cc545d601ba1967ee3b9904ab14a42eb67", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/e1e393cc545d601ba1967ee3b9904ab14a42eb67", "committedDate": "2020-05-22T05:04:38Z", "message": "address comments"}, "afterCommit": {"oid": "07961ed1fd2a153fda5ef3e58c1310121453c816", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/07961ed1fd2a153fda5ef3e58c1310121453c816", "committedDate": "2020-05-22T05:06:54Z", "message": "address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "07961ed1fd2a153fda5ef3e58c1310121453c816", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/07961ed1fd2a153fda5ef3e58c1310121453c816", "committedDate": "2020-05-22T05:06:54Z", "message": "address comments"}, "afterCommit": {"oid": "2895df4f6ecfe53e9fd04a3418065d7986f2dd1b", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/2895df4f6ecfe53e9fd04a3418065d7986f2dd1b", "committedDate": "2020-05-22T05:22:57Z", "message": "revert ApplyNameMapping to ignore field without IDs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d2a1ddbaafe7e82dac8d355c6cb90e446f2e8bb", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/7d2a1ddbaafe7e82dac8d355c6cb90e446f2e8bb", "committedDate": "2020-05-22T06:00:10Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0c8b3da646578e9ccd5a2da33fa0d88f8b141d14", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/0c8b3da646578e9ccd5a2da33fa0d88f8b141d14", "committedDate": "2020-05-22T06:00:33Z", "message": "revert ApplyNameMapping to ignore field without ID"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2895df4f6ecfe53e9fd04a3418065d7986f2dd1b", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/2895df4f6ecfe53e9fd04a3418065d7986f2dd1b", "committedDate": "2020-05-22T05:22:57Z", "message": "revert ApplyNameMapping to ignore field without IDs"}, "afterCommit": {"oid": "0c8b3da646578e9ccd5a2da33fa0d88f8b141d14", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/0c8b3da646578e9ccd5a2da33fa0d88f8b141d14", "committedDate": "2020-05-22T06:00:33Z", "message": "revert ApplyNameMapping to ignore field without ID"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MTUxMDUz", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-417151053", "createdAt": "2020-05-22T19:45:07Z", "commit": {"oid": "0c8b3da646578e9ccd5a2da33fa0d88f8b141d14"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxOTo0NTowN1rOGZiHtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxOTo0NTowN1rOGZiHtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjYxNQ==", "bodyText": "What is the purpose of this? Why not always apply a mapping if it was supplied?\nI think it is confusing to only apply a mapping if this is called, even when the mapping is set.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r429426615", "createdAt": "2020-05-22T19:45:07Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/Parquet.java", "diffHunk": "@@ -393,6 +396,16 @@ public ReadBuilder recordsPerBatch(int numRowsPerBatch) {\n       return this;\n     }\n \n+    public ReadBuilder withNameMapping(NameMapping newNameMapping) {\n+      this.nameMapping = newNameMapping;\n+      return this;\n+    }\n+\n+    public ReadBuilder applyNameMapping() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0c8b3da646578e9ccd5a2da33fa0d88f8b141d14"}, "originalPosition": 26}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4baa9003ad428ee33e83e7b607018cdc044ff306", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/4baa9003ad428ee33e83e7b607018cdc044ff306", "committedDate": "2020-05-23T05:53:08Z", "message": "get name mapping from table property"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d62854570c4cdc92f85fd01e7b1dcc6bd8f90fa2", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/d62854570c4cdc92f85fd01e7b1dcc6bd8f90fa2", "committedDate": "2020-05-29T02:22:02Z", "message": "Merge branch 'master' into namemapping"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9529f0df1be9970c6dc4c14c0637d0ed2395634e", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/9529f0df1be9970c6dc4c14c0637d0ed2395634e", "committedDate": "2020-05-29T03:28:11Z", "message": "allow types without IDs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "526e79becfe9fe83d6065f9be1569957f8d49cc7", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/526e79becfe9fe83d6065f9be1569957f8d49cc7", "committedDate": "2020-05-29T06:37:19Z", "message": "remove unrelated changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a128fa7dc37b0f0d8484de4c9f3bae28519d65c2", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/a128fa7dc37b0f0d8484de4c9f3bae28519d65c2", "committedDate": "2020-06-16T02:24:51Z", "message": "Merge branch 'master' into namemapping"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/18a803f9bd033e4c5fada44394ee7ebfb4468216", "committedDate": "2020-06-16T07:54:26Z", "message": "resolve merge conflicts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzE5ODk0", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431719894", "createdAt": "2020-06-16T17:09:36Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzowOTozNlrOGklITw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzowOTozNlrOGklITw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAxMDI1NQ==", "bodyText": "Looks like this is a non-functional change to an unrelated file. Could you revert it? Same with ParquetDictionaryRowGroupFilter.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441010255", "createdAt": "2020-06-16T17:09:36Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java", "diffHunk": "@@ -47,6 +47,7 @@\n import org.apache.parquet.schema.PrimitiveType;\n \n public class ParquetMetricsRowGroupFilter {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzIyNjgx", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431722681", "createdAt": "2020-06-16T17:13:22Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzoxMzoyMlrOGklQrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzoxMzoyMlrOGklQrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAxMjM5OA==", "bodyText": "Please don't split types across lines. I think moving Function<MessageType to the previous line should be reverted.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441012398", "createdAt": "2020-06-16T17:13:22Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/VectorizedParquetReader.java", "diffHunk": "@@ -48,11 +49,12 @@\n   private boolean reuseContainers;\n   private final boolean caseSensitive;\n   private final int batchSize;\n+  private final NameMapping nameMapping;\n \n   public VectorizedParquetReader(\n-      InputFile input, Schema expectedSchema, ParquetReadOptions options,\n-      Function<MessageType, VectorizedReader<?>> readerFunc,\n-      Expression filter, boolean reuseContainers, boolean caseSensitive, int maxRecordsPerBatch) {\n+      InputFile input, Schema expectedSchema, ParquetReadOptions options, Function<MessageType,\n+      VectorizedReader<?>> readerFunc, NameMapping nameMapping, Expression filter, boolean reuseContainers,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzI1OTM4", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431725938", "createdAt": "2020-06-16T17:17:37Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzoxNzozN1rOGklaVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzoxNzozN1rOGklaVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAxNDg2OQ==", "bodyText": "There's a problem here: applyNameMapping could be a noop and this would still work because the conversion to Parquet and back preserves IDs. For Avro, there is a test utility to remove IDs from the schema so that we can test adding them back with the name mapping. I think it would make sense to take the Avro name mapping tests and adapt them for Parquet as well. That can be done in a follow-up, but this test does need to be fixed before committing.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441014869", "createdAt": "2020-06-16T17:17:37Z", "author": {"login": "rdblue"}, "path": "parquet/src/test/java/org/apache/iceberg/parquet/TestParquetSchemaUtil.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.parquet;\n+\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.mapping.MappingUtil;\n+import org.apache.iceberg.mapping.NameMapping;\n+import org.apache.iceberg.types.TypeUtil;\n+import org.apache.iceberg.types.Types;\n+import org.apache.parquet.schema.MessageType;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestParquetSchemaUtil {\n+  private static final Types.StructType SUPPORTED_PRIMITIVES = Types.StructType.of(\n+      required(100, \"id\", Types.LongType.get()),\n+      optional(101, \"data\", Types.StringType.get()),\n+      required(102, \"b\", Types.BooleanType.get()),\n+      optional(103, \"i\", Types.IntegerType.get()),\n+      required(104, \"l\", Types.LongType.get()),\n+      optional(105, \"f\", Types.FloatType.get()),\n+      required(106, \"d\", Types.DoubleType.get()),\n+      optional(107, \"date\", Types.DateType.get()),\n+      required(108, \"ts\", Types.TimestampType.withZone()),\n+      required(110, \"s\", Types.StringType.get()),\n+      required(112, \"fixed\", Types.FixedType.ofLength(7)),\n+      optional(113, \"bytes\", Types.BinaryType.get()),\n+      required(114, \"dec_9_0\", Types.DecimalType.of(9, 0)),\n+      required(115, \"dec_11_2\", Types.DecimalType.of(11, 2)),\n+      required(116, \"dec_38_10\", Types.DecimalType.of(38, 10)) // spark's maximum precision\n+  );\n+\n+  @Test\n+  public void testAssignIdsByNameMapping() {\n+    Types.StructType structType = Types.StructType.of(\n+        required(0, \"id\", Types.LongType.get()),\n+        optional(1, \"list_of_maps\",\n+            Types.ListType.ofOptional(2, Types.MapType.ofOptional(3, 4,\n+                Types.StringType.get(),\n+                SUPPORTED_PRIMITIVES))),\n+        optional(5, \"map_of_lists\",\n+            Types.MapType.ofOptional(6, 7,\n+                Types.StringType.get(),\n+                Types.ListType.ofOptional(8, SUPPORTED_PRIMITIVES))),\n+        required(9, \"list_of_lists\",\n+            Types.ListType.ofOptional(10, Types.ListType.ofOptional(11, SUPPORTED_PRIMITIVES))),\n+        required(12, \"map_of_maps\",\n+            Types.MapType.ofOptional(13, 14,\n+                Types.StringType.get(),\n+                Types.MapType.ofOptional(15, 16,\n+                    Types.StringType.get(),\n+                    SUPPORTED_PRIMITIVES))),\n+        required(17, \"list_of_struct_of_nested_types\", Types.ListType.ofOptional(19, Types.StructType.of(\n+            Types.NestedField.required(20, \"m1\", Types.MapType.ofOptional(21, 22,\n+                Types.StringType.get(),\n+                SUPPORTED_PRIMITIVES)),\n+            Types.NestedField.optional(23, \"l1\", Types.ListType.ofRequired(24, SUPPORTED_PRIMITIVES)),\n+            Types.NestedField.required(25, \"l2\", Types.ListType.ofRequired(26, SUPPORTED_PRIMITIVES)),\n+            Types.NestedField.optional(27, \"m2\", Types.MapType.ofOptional(28, 29,\n+                Types.StringType.get(),\n+                SUPPORTED_PRIMITIVES))\n+        )))\n+    );\n+\n+    Schema schema = new Schema(TypeUtil.assignFreshIds(structType, new AtomicInteger(0)::incrementAndGet)\n+        .asStructType().fields());\n+    NameMapping nameMapping = MappingUtil.create(schema);\n+    MessageType messageType = ParquetSchemaUtil.convert(schema, \"complex_schema\");\n+    MessageType typeWithIdsFromNameMapping = ParquetSchemaUtil.applyNameMapping(messageType, nameMapping);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 90}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzM2MjQ0", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431736244", "createdAt": "2020-06-16T17:31:02Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozMTowMlrOGkl59w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozMTowMlrOGkl59w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyMjk2Nw==", "bodyText": "Why is this not if (fieldId != null && selectedIds.contains(fieldId))?\nThe else case is used when a sub-field is projected by ID. So the question is whether a sub-field can be projected if its parents aren't mapped. I think we should allow it because it would be confusing to have a value mapped, but still get nulls because a parent is not.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441022967", "createdAt": "2020-06-16T17:31:02Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/PruneColumns.java", "diffHunk": "@@ -45,13 +44,16 @@ public Type message(MessageType message, List<Type> fields) {\n     for (int i = 0; i < fields.size(); i += 1) {\n       Type originalField = message.getType(i);\n       Type field = fields.get(i);\n-      if (selectedIds.contains(getId(originalField))) {\n-        builder.addField(originalField);\n-        fieldCount += 1;\n-      } else if (field != null) {\n-        builder.addField(field);\n-        fieldCount += 1;\n-        hasChange = true;\n+      Integer fieldId = getId(originalField);\n+      if (fieldId != null) {\n+        if (selectedIds.contains(fieldId)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzM2NDY3", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431736467", "createdAt": "2020-06-16T17:31:17Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozMToxN1rOGkl6iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozMToxN1rOGkl6iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyMzExMg==", "bodyText": "Same logic as above applies here.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441023112", "createdAt": "2020-06-16T17:31:17Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/PruneColumns.java", "diffHunk": "@@ -71,11 +73,14 @@ public Type struct(GroupType struct, List<Type> fields) {\n     for (int i = 0; i < fields.size(); i += 1) {\n       Type originalField = struct.getType(i);\n       Type field = fields.get(i);\n-      if (selectedIds.contains(getId(originalField))) {\n-        filteredFields.add(originalField);\n-      } else if (field != null) {\n-        filteredFields.add(originalField);\n-        hasChange = true;\n+      Integer fieldId = getId(originalField);\n+      if (fieldId != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzM3MzE5", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431737319", "createdAt": "2020-06-16T17:32:21Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozMjoyMVrOGkl9Fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozMjoyMVrOGkl9Fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyMzc2Ng==", "bodyText": "Looks correct to me.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441023766", "createdAt": "2020-06-16T17:32:21Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetReaders.java", "diffHunk": "@@ -142,9 +142,11 @@ private SparkParquetReaders() {\n       for (int i = 0; i < fields.size(); i += 1) {\n         Type fieldType = fields.get(i);\n         int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n-        int id = fieldType.getId().intValue();\n-        readersById.put(id, ParquetValueReaders.option(fieldType, fieldD, fieldReaders.get(i)));\n-        typesById.put(id, fieldType);\n+        if (fieldType.getId() != null) {\n+          int id = fieldType.getId().intValue();\n+          readersById.put(id, ParquetValueReaders.option(fieldType, fieldD, fieldReaders.get(i)));\n+          typesById.put(id, fieldType);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzM4Mzc3", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431738377", "createdAt": "2020-06-16T17:33:44Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozMzo0NFrOGkmAJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozMzo0NFrOGkmAJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyNDU0OQ==", "bodyText": "I'd prefer to keep the name mapping and building separate. There's no need to mix these together.\nif (nameMapping != null) {\n  builder.withNameMapping(NameMappingParser.fromJson(nameMapping));\n}\n\niter = builder.build();", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441024549", "createdAt": "2020-06-16T17:33:44Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/BatchDataReader.java", "diffHunk": "@@ -65,8 +68,10 @@\n           // Spark eagerly consumes the batches. So the underlying memory allocated could be reused\n           // without worrying about subsequent reads clobbering over each other. This improves\n           // read performance as every batch read doesn't have to pay the cost of allocating memory.\n-          .reuseContainers()\n-          .build();\n+          .reuseContainers();\n+\n+      iter = nameMapping != null ?\n+          builder.withNameMapping(NameMappingParser.fromJson(nameMapping)).build() : builder.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzM5ODQ2", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431739846", "createdAt": "2020-06-16T17:35:46Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozNTo0NlrOGkmEow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozNTo0NlrOGkmEow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyNTY5OQ==", "bodyText": "Can you add a test for name mapping with the vectorized read path? Just set the property on the table when you add the mapping and it should take that path.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441025699", "createdAt": "2020-06-16T17:35:46Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkTableUtil.java", "diffHunk": "@@ -200,4 +209,48 @@ public void testImportAsHiveTable() throws Exception {\n     long count2 = spark.read().format(\"iceberg\").load(DB_NAME + \".test_partitioned_table\").count();\n     Assert.assertEquals(\"three values \", 3, count2);\n   }\n+\n+  @Test\n+  public void testImportWithNameMapping() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzQwMjEy", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431740212", "createdAt": "2020-06-16T17:36:15Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozNjoxNVrOGkmF6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozNjoxNVrOGkmF6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyNjAyNQ==", "bodyText": "Nit: extra newline.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441026025", "createdAt": "2020-06-16T17:36:15Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkTableUtil.java", "diffHunk": "@@ -200,4 +209,48 @@ public void testImportAsHiveTable() throws Exception {\n     long count2 = spark.read().format(\"iceberg\").load(DB_NAME + \".test_partitioned_table\").count();\n     Assert.assertEquals(\"three values \", 3, count2);\n   }\n+\n+  @Test\n+  public void testImportWithNameMapping() throws Exception {\n+    spark.table(qualifiedTableName).write().mode(\"overwrite\").format(\"parquet\")\n+        .saveAsTable(\"original_table\");\n+\n+    // The field is different so that it will project with name mapping\n+    Schema filteredSchema = new Schema(\n+        optional(1, \"data\", Types.StringType.get())\n+    );\n+\n+    NameMapping nameMapping = MappingUtil.create(filteredSchema);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzQwNzU2", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431740756", "createdAt": "2020-06-16T17:36:58Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozNjo1OFrOGkmHeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozNjo1OFrOGkmHeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyNjQyNA==", "bodyText": "Same here, let's separate the name mapping from build.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441026424", "createdAt": "2020-06-16T17:36:58Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java", "diffHunk": "@@ -151,13 +154,15 @@\n       FileScanTask task,\n       Schema readSchema,\n       Map<Integer, ?> idToConstant) {\n-    return Parquet.read(location)\n-        .project(readSchema)\n+    Parquet.ReadBuilder builder = Parquet.read(location)\n         .split(task.start(), task.length())\n+        .project(readSchema)\n         .createReaderFunc(fileSchema -> SparkParquetReaders.buildReader(readSchema, fileSchema, idToConstant))\n         .filter(task.residual())\n-        .caseSensitive(caseSensitive)\n-        .build();\n+        .caseSensitive(caseSensitive);\n+\n+    return nameMapping != null ?\n+        builder.withNameMapping(NameMappingParser.fromJson(nameMapping)).build() : builder.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzQxNzMz", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431741733", "createdAt": "2020-06-16T17:38:16Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozODoxNlrOGkmKNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozODoxNlrOGkmKNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyNzEyNg==", "bodyText": "I'd also prefer to revert this change. There may not be a use of it as a protected method any more, but we don't need to change this file and risk git conflicts.", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441027126", "createdAt": "2020-06-16T17:38:16Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java", "diffHunk": "@@ -229,7 +229,7 @@ private void addAlias(String name, int fieldId) {\n     aliasToId.put(DOT.join(path(name)), fieldId);\n   }\n \n-  protected int nextId() {\n+  private int nextId() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNzQxOTIz", "url": "https://github.com/apache/iceberg/pull/830#pullrequestreview-431741923", "createdAt": "2020-06-16T17:38:31Z", "commit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozODozMVrOGkmKrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNzozODozMVrOGkmKrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyNzI0Nw==", "bodyText": "Can you add comments to these methods to explain why they are here?", "url": "https://github.com/apache/iceberg/pull/830#discussion_r441027247", "createdAt": "2020-06-16T17:38:31Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ApplyNameMapping.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.parquet;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import org.apache.iceberg.mapping.MappedField;\n+import org.apache.iceberg.mapping.NameMapping;\n+import org.apache.parquet.Preconditions;\n+import org.apache.parquet.schema.GroupType;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.PrimitiveType;\n+import org.apache.parquet.schema.Type;\n+import org.apache.parquet.schema.Types;\n+\n+class ApplyNameMapping extends ParquetTypeVisitor<Type> {\n+  private final NameMapping nameMapping;\n+\n+  ApplyNameMapping(NameMapping nameMapping) {\n+    this.nameMapping = nameMapping;\n+  }\n+\n+  @Override\n+  public Type message(MessageType message, List<Type> fields) {\n+    Types.MessageTypeBuilder builder = org.apache.parquet.schema.Types.buildMessage();\n+    fields.stream().filter(Objects::nonNull).forEach(builder::addField);\n+\n+    return builder.named(message.getName());\n+  }\n+\n+  @Override\n+  public Type struct(GroupType struct, List<Type> types) {\n+    MappedField field = nameMapping.find(currentPath());\n+    List<Type> actualTypes = types.stream().filter(Objects::nonNull).collect(Collectors.toList());\n+    Type structType = struct.withNewFields(actualTypes);\n+\n+    return field == null ? structType : structType.withId(field.id());\n+  }\n+\n+  @Override\n+  public Type list(GroupType list, Type elementType) {\n+    Preconditions.checkArgument(elementType != null,\n+        \"List type must have element field\");\n+\n+    MappedField field = nameMapping.find(currentPath());\n+    Type listType = org.apache.parquet.schema.Types.list(list.getRepetition())\n+        .element(elementType)\n+        .named(list.getName());\n+\n+    return field == null ? listType : listType.withId(field.id());\n+  }\n+\n+  @Override\n+  public Type map(GroupType map, Type keyType, Type valueType) {\n+    Preconditions.checkArgument(keyType != null && valueType != null,\n+        \"Map type must have both key field and value field\");\n+\n+    MappedField field = nameMapping.find(currentPath());\n+    Type mapType = org.apache.parquet.schema.Types.map(map.getRepetition())\n+        .key(keyType)\n+        .value(valueType)\n+        .named(map.getName());\n+\n+    return field == null ? mapType : mapType.withId(field.id());\n+  }\n+\n+  @Override\n+  public Type primitive(PrimitiveType primitive) {\n+    MappedField field = nameMapping.find(currentPath());\n+    return field == null ? primitive : primitive.withId(field.id());\n+  }\n+\n+  @Override\n+  public void beforeRepeatedElement(Type element) {\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a803f9bd033e4c5fada44394ee7ebfb4468216"}, "originalPosition": 93}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2f47631f65b54c0c798ae8c0d3af7ceee003b9f5", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/2f47631f65b54c0c798ae8c0d3af7ceee003b9f5", "committedDate": "2020-06-17T03:18:05Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3ca14c7de19fb6b51e9a691306f4de64e67c86b8", "author": {"user": {"login": "chenjunjiedada", "name": "Chen, Junjie"}}, "url": "https://github.com/apache/iceberg/commit/3ca14c7de19fb6b51e9a691306f4de64e67c86b8", "committedDate": "2020-06-17T05:08:55Z", "message": "fix style"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4709, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}