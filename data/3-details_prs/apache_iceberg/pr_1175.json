{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ1MjI4ODI1", "number": 1175, "title": "Flink: Add wrapper to adapt Row to StructLike", "bodyText": "This patch abstract the common codes of PartitionKey to the newly introduced class BasePartitionKey, and both spark PartitionKey and flink PartitionKey will extend this base class.  I also provide the unit tests for flink PartitionKey.", "createdAt": "2020-07-07T07:56:28Z", "url": "https://github.com/apache/iceberg/pull/1175", "merged": true, "mergeCommit": {"oid": "d1b6d16dc6b996043f0911bad8a7930e081edb1c"}, "closed": true, "closedAt": "2020-07-15T20:22:06Z", "author": {"login": "openinx"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcylCdQAFqTQ0Mzg0MjgzNw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc1HtLYgH2gAyNDQ1MjI4ODI1OjZiYzQ1MmM3MTk1YTg2ZWU3MzcwOWE2YTIxMWUwM2M2MDhlMDlhMTU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzODQyODM3", "url": "https://github.com/apache/iceberg/pull/1175#pullrequestreview-443842837", "createdAt": "2020-07-07T12:31:27Z", "commit": {"oid": "37dc2f3cad2f3b9ab7e1feb5bd911192b9f612cf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMjozMToyN1rOGt8Vxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMjozMToyN1rOGt8Vxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgyNzcxOQ==", "bodyText": "It's quite confuse for me to see that the above else-if use accessor.getClass() == PositionAccessor.class while this line use accessor instanceof Position2Accessor.  I see that there's only one Position2Accessor implementation, so changing it from instanceof  to = should be OK here.", "url": "https://github.com/apache/iceberg/pull/1175#discussion_r450827719", "createdAt": "2020-07-07T12:31:27Z", "author": {"login": "openinx"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/PartitionKey.java", "diffHunk": "@@ -176,61 +70,22 @@ public int hashCode() {\n     }\n   }\n \n-  private static Accessor<InternalRow> newAccessor(int position, boolean isOptional, Types.StructType type,\n-                                                   Accessor<InternalRow> accessor) {\n+  @Override\n+  protected Accessor<InternalRow> newAccessor(int position, boolean isOptional, Types.StructType type,\n+                                              Accessor<InternalRow> accessor) {\n     int size = type.fields().size();\n     if (isOptional) {\n       // the wrapped position handles null layers\n       return new WrappedPositionAccessor(position, size, accessor);\n     } else if (accessor.getClass() == PositionAccessor.class) {\n       return new Position2Accessor(position, size, (PositionAccessor) accessor);\n-    } else if (accessor instanceof Position2Accessor) {\n+    } else if (accessor.getClass() == Position2Accessor.class) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37dc2f3cad2f3b9ab7e1feb5bd911192b9f612cf"}, "originalPosition": 174}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72730aedf7cc645afbe18ed1a0ce1d1bbc101c26", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/72730aedf7cc645afbe18ed1a0ce1d1bbc101c26", "committedDate": "2020-07-14T07:52:42Z", "message": "Flink: add flink row PartitionKey."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "37dc2f3cad2f3b9ab7e1feb5bd911192b9f612cf", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/37dc2f3cad2f3b9ab7e1feb5bd911192b9f612cf", "committedDate": "2020-07-07T09:43:48Z", "message": "Refactor the newStructAccessor to newAccessor"}, "afterCommit": {"oid": "72730aedf7cc645afbe18ed1a0ce1d1bbc101c26", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/72730aedf7cc645afbe18ed1a0ce1d1bbc101c26", "committedDate": "2020-07-14T07:52:42Z", "message": "Flink: add flink row PartitionKey."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4bc4b84d01ab72ad8aca46cf5b566bbe6070b115", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/4bc4b84d01ab72ad8aca46cf5b566bbe6070b115", "committedDate": "2020-07-14T08:05:05Z", "message": "Fix the checkstyle."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ4Mjk5ODM0", "url": "https://github.com/apache/iceberg/pull/1175#pullrequestreview-448299834", "createdAt": "2020-07-14T17:06:47Z", "commit": {"oid": "4bc4b84d01ab72ad8aca46cf5b566bbe6070b115"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNzowNjo0N1rOGxdCCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNzowNjo0N1rOGxdCCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwOTA2NA==", "bodyText": "The objects returned by this wrapper need to be Iceberg's internal representation:\n\nint for DateType: number of days from epoch\nlong for TimeType: number of microseconds from midnight\nlong for both TimestampType: number of microseconds from epoch\nByteBuffer for both fixed(L) and binary types\nBigDecimal for decimal(P, S)\n\nBecause we Flink uses the same in-memory representation as Iceberg generics, this should use the same conversions that we use for Record.", "url": "https://github.com/apache/iceberg/pull/1175#discussion_r454509064", "createdAt": "2020-07-14T17:06:47Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/RowWrapper.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.lang.reflect.Array;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.StructLike;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class RowWrapper implements StructLike {\n+\n+  private final Type[] types;\n+  private final PositionalGetter[] getters;\n+  private Row row = null;\n+\n+  public RowWrapper(Types.StructType type) {\n+    int size = type.fields().size();\n+\n+    types = (Type[]) Array.newInstance(Type.class, size);\n+    for (int i = 0; i < size; i++) {\n+      types[i] = type.fields().get(i).type();\n+    }\n+\n+    getters = (PositionalGetter[]) Array.newInstance(PositionalGetter.class, size);\n+    for (int i = 0; i < size; i++) {\n+      getters[i] = buildGetter(types[i]);\n+    }\n+  }\n+\n+  RowWrapper wrap(Row data) {\n+    this.row = data;\n+    return this;\n+  }\n+\n+  @Override\n+  public int size() {\n+    return types.length;\n+  }\n+\n+  @Override\n+  public <T> T get(int pos, Class<T> javaClass) {\n+    if (row.getField(pos) == null) {\n+      return null;\n+    } else if (getters[pos] != null) {\n+      return javaClass.cast(getters[pos].get(row, pos));\n+    }\n+\n+    return javaClass.cast(row.getField(pos));\n+  }\n+\n+  @Override\n+  public <T> void set(int pos, T value) {\n+    row.setField(pos, value);\n+  }\n+\n+  private interface PositionalGetter<T> {\n+    T get(Row row, int pos);\n+  }\n+\n+  private static PositionalGetter buildGetter(Type type) {\n+    if (type instanceof Types.StructType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4bc4b84d01ab72ad8aca46cf5b566bbe6070b115"}, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ4MzAzMTAx", "url": "https://github.com/apache/iceberg/pull/1175#pullrequestreview-448303101", "createdAt": "2020-07-14T17:11:15Z", "commit": {"oid": "4bc4b84d01ab72ad8aca46cf5b566bbe6070b115"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNzoxMToxNVrOGxdMcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNzoxMToxNVrOGxdMcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUxMTczMA==", "bodyText": "Can you add a test based on Spark's TestPartitionValues? That tests every supported type, null values, and different column orders.", "url": "https://github.com/apache/iceberg/pull/1175#discussion_r454511730", "createdAt": "2020-07-14T17:11:15Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestPartitionKey.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.PartitionKey;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.exceptions.ValidationException;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestPartitionKey {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4bc4b84d01ab72ad8aca46cf5b566bbe6070b115"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ4MzA0MDE1", "url": "https://github.com/apache/iceberg/pull/1175#pullrequestreview-448304015", "createdAt": "2020-07-14T17:12:34Z", "commit": {"oid": "4bc4b84d01ab72ad8aca46cf5b566bbe6070b115"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNzoxMjozNFrOGxdPiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNzoxMjozNFrOGxdPiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUxMjUyMw==", "bodyText": "Can you split each of these blocks into a separate test case? There are lots of different cases mixed together in this method. Mixing cases together makes it harder to see what is broken when tests fail because you don't get a picture of what is common across failed cases since many of them don't run.", "url": "https://github.com/apache/iceberg/pull/1175#discussion_r454512523", "createdAt": "2020-07-14T17:12:34Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestPartitionKey.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.PartitionKey;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.exceptions.ValidationException;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestPartitionKey {\n+\n+  @Test\n+  public void testSimplePartition() {\n+    Schema schema = new Schema(\n+        Types.NestedField.optional(1, \"id\", Types.IntegerType.get()),\n+        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n+        Types.NestedField.optional(3, \"address\", Types.StringType.get())\n+    );\n+\n+    PartitionSpec spec = PartitionSpec.builderFor(schema)\n+        .identity(\"address\")\n+        .build();\n+    RowWrapper rowWrapper = new RowWrapper(schema.asStruct());\n+\n+    Row row1 = Row.of(101, \"hello\", \"addr-1\");\n+    PartitionKey partitionKey = new PartitionKey(spec, schema);\n+    partitionKey.partition(rowWrapper.wrap(row1));\n+    Assert.assertEquals(partitionKey.size(), 1);\n+    Assert.assertEquals(partitionKey.get(0, String.class), \"addr-1\");\n+\n+    Row row2 = Row.of(102, \"world\", \"addr-2\");\n+    partitionKey.partition(rowWrapper.wrap(row2));\n+    Assert.assertEquals(partitionKey.size(), 1);\n+    Assert.assertEquals(partitionKey.get(0, String.class), \"addr-2\");\n+  }\n+\n+  @Test\n+  public void testPartitionWithNestedType() {\n+    Schema schema = new Schema(\n+        Types.NestedField.optional(1, \"id\", Types.IntegerType.get()),\n+        Types.NestedField.optional(2, \"structType\", Types.StructType.of(\n+            Types.NestedField.optional(3, \"innerStringType\", Types.StringType.get()),\n+            Types.NestedField.optional(4, \"innerIntegerType\", Types.IntegerType.get())\n+        )),\n+        Types.NestedField.optional(5, \"listType\", Types.ListType.ofOptional(6, Types.LongType.get())),\n+        Types.NestedField.optional(7, \"mapType\",\n+            Types.MapType.ofRequired(8, 9, Types.IntegerType.get(), Types.StringType.get())),\n+        Types.NestedField.required(10, \"ts\", Types.TimestampType.withZone())\n+    );\n+    RowWrapper rowWrapper = new RowWrapper(schema.asStruct());\n+\n+    Row row = Row.of(\n+        1001,\n+        Row.of(\"addr-1\", 200),\n+        new Long[] {101L, 102L},\n+        ImmutableMap.of(1001, \"1001-value\"),\n+        DateTimeUtil.microsFromTimestamp(DateTimeUtil.timestampFromMicros(0L))\n+    );\n+\n+    PartitionSpec spec = PartitionSpec.builderFor(schema)\n+        .identity(\"structType.innerStringType\")\n+        .build();\n+    PartitionKey partitionKey = new PartitionKey(spec, schema);\n+    partitionKey.partition(rowWrapper.wrap(row));\n+    Assert.assertEquals(partitionKey.size(), 1);\n+    Assert.assertEquals(partitionKey.get(0, String.class), \"addr-1\");\n+    Assert.assertEquals(partitionKey.toPath(), \"structType.innerStringType=addr-1\");\n+\n+    PartitionSpec spec2 = PartitionSpec.builderFor(schema)\n+        .identity(\"structType.innerIntegerType\")\n+        .build();\n+    PartitionKey partitionKey2 = new PartitionKey(spec2, schema);\n+    partitionKey2.partition(rowWrapper.wrap(row));\n+    Assert.assertEquals(1, partitionKey2.size());\n+    Assert.assertEquals(200, (int) partitionKey2.get(0, Integer.class));\n+    Assert.assertEquals(partitionKey2.toPath(), \"structType.innerIntegerType=200\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4bc4b84d01ab72ad8aca46cf5b566bbe6070b115"}, "originalPosition": 100}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "397acce20e488cbe70d49e007e34b4a1da7d600e", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/397acce20e488cbe70d49e007e34b4a1da7d600e", "committedDate": "2020-07-15T09:51:48Z", "message": "More unit tests & Add conversion for DATE, TIME, TIMESTAMP, FIXED, STRUCT"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6bc452c7195a86ee73709a6a211e03c608e09a15", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/6bc452c7195a86ee73709a6a211e03c608e09a15", "committedDate": "2020-07-15T10:02:45Z", "message": "Remove the public modifier"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4620, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}