{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY2NzY0MTE2", "number": 1326, "title": "Hive: Filter pushdown", "bodyText": "Hello! This is a follow-up PR to the Hive IF PR's that got merged recently that adds filter pushdown to the HiveIcebergInputFormat. I've added a filter factory to convert the Hive filter to an Iceberg Expression and then use the InputFormatConfig to set the filter expression for IcebergInputFormat to apply to the table scan.\ncc: @rdblue @guilload @massdosage @pvary @rdsr @shardulm94\nThanks :D", "createdAt": "2020-08-12T13:14:56Z", "url": "https://github.com/apache/iceberg/pull/1326", "merged": true, "mergeCommit": {"oid": "c801a2c15715f6d33c3b26eca1c2f495c3cb73b5"}, "closed": true, "closedAt": "2020-09-01T01:27:31Z", "author": {"login": "cmathiesen"}, "timelineItems": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc5EXBgAH2gAyNDY2NzY0MTE2OmUyMDA3YzFkMzU0ZjQ2ZmIyNjE4NmU3MWE4MWRmOTg5ZGU2ZDRjNGQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdEUU37AH2gAyNDY2NzY0MTE2OmVmNWIwNTBkZmI5MDI5NTA1ODViMjZjZDAxYTBlMmU4MTYyZGQ5YWY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "e2007c1d354f46fb26186e71a81df989de6d4c4d", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/e2007c1d354f46fb26186e71a81df989de6d4c4d", "committedDate": "2020-07-27T16:24:32Z", "message": "Add filter factory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f97e408c1645285fc8f06c565d06a9d69c2e703e", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/f97e408c1645285fc8f06c565d06a9d69c2e703e", "committedDate": "2020-08-12T12:42:09Z", "message": "Fix type conversions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/03729f414d48373cfa23c24e91861afea1f838db", "committedDate": "2020-08-12T13:00:17Z", "message": "Add tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1OTY3MzY2", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-465967366", "createdAt": "2020-08-12T14:23:57Z", "commit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNDoyMzo1N1rOG_jsfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNDoyMzo1N1rOG_jsfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTI5ODMwMw==", "bodyText": "This comment seems to be at odds with the exception being thrown? It looks like in the hive code it just does nothing? Maybe I'm reading it wrong.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469298303", "createdAt": "2020-08-12T14:23:57Z", "author": {"login": "RussellSpitzer"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        //We are unsure of how the CONSTANT case works, so using the approach of:\n+        //https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/\n+        // ParquetFilterPredicateConverter.java#L116", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "originalPosition": 80}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1OTcxMjY0", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-465971264", "createdAt": "2020-08-12T14:27:42Z", "commit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNDoyNzo0MlrOG_j3wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNDoyNzo0MlrOG_j3wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMwMTE4Ng==", "bodyText": "I'm new to this code, so I wonder when reading this why we was to get the literal as a list if getLiteral is null? Does having getLiteral() returning null mean that there is a collection type?", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469301186", "createdAt": "2020-08-12T14:27:42Z", "author": {"login": "RussellSpitzer"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        //We are unsure of how the CONSTANT case works, so using the approach of:\n+        //https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/\n+        // ParquetFilterPredicateConverter.java#L116\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToIcebergType(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToIcebergType(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToIcebergType(leaf));\n+      case IN:\n+        return in(column, (List) leafToIcebergType(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leaf.getLiteralList();\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToIcebergType(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+        return leaf.getLiteral() != null ? leaf.getLiteral() : leaf.getLiteralList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1OTczODM3", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-465973837", "createdAt": "2020-08-12T14:30:09Z", "commit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNDozMDowOVrOG_j-yA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNDozMDowOVrOG_j-yA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMwMjk4NA==", "bodyText": "Not a big deal but I tend to make constants for numbers that can be misread like this, MILLION or MICROS_PER_SECOND", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469302984", "createdAt": "2020-08-12T14:30:09Z", "author": {"login": "RussellSpitzer"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        //We are unsure of how the CONSTANT case works, so using the approach of:\n+        //https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/\n+        // ParquetFilterPredicateConverter.java#L116\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToIcebergType(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToIcebergType(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToIcebergType(leaf));\n+      case IN:\n+        return in(column, (List) leafToIcebergType(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leaf.getLiteralList();\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToIcebergType(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+        return leaf.getLiteral() != null ? leaf.getLiteral() : leaf.getLiteralList();\n+      case FLOAT:\n+        return leaf.getLiteral() != null ? leaf.getLiteral() : leaf.getLiteralList();\n+      case STRING:\n+        return leaf.getLiteral() != null ? leaf.getLiteral() : leaf.getLiteralList();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        if (leaf.getLiteral() != null) {\n+          return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+        } else {\n+          //But not when retrieving the literalList\n+          List<Object> icebergValues = leaf.getLiteralList();\n+          icebergValues.replaceAll(value -> ((Date) value).toLocalDate().toEpochDay());\n+          return icebergValues;\n+        }\n+      case DECIMAL:\n+        if (leaf.getLiteral() != null) {\n+          return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+        } else {\n+          List<Object> icebergValues = leaf.getLiteralList();\n+          icebergValues.replaceAll(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()));\n+          return icebergValues;\n+        }\n+      case TIMESTAMP:\n+        if (leaf.getLiteral() != null) {\n+          Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+          return timestamp.toInstant().getEpochSecond() * 1000000 + timestamp.getNanos() / 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "originalPosition": 143}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1OTg1Mzk4", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-465985398", "createdAt": "2020-08-12T14:41:54Z", "commit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNDo0MTo1NFrOG_kgLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNDo0MTo1NFrOG_kgLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMxMTUzNQ==", "bodyText": "I think we should probably have tests for all the filter literal types here, It seems like we are only checking Longs?  Especially given the special code around other specific types.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469311535", "createdAt": "2020-08-12T14:41:54Z", "author": {"login": "RussellSpitzer"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MDkxNDU1", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-466091455", "createdAt": "2020-08-12T16:42:22Z", "commit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjo0MjoyMlrOG_pp0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjo0MjoyMlrOG_pp0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM5NTkyMQ==", "bodyText": "Should this be childNodes.get(0)?", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469395921", "createdAt": "2020-08-12T16:42:22Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MDk5NzU4", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-466099758", "createdAt": "2020-08-12T16:53:23Z", "commit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjo1MzoyM1rOG_qDZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjo1MzoyM1rOG_qDZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQwMjQ2OA==", "bodyText": "I think it would be better to split this into two methods: one for a single literal and one for a list of literals. Returning either one as Object doesn't allow us to make sure we're calling getLiteralList for the correct predicates.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469402468", "createdAt": "2020-08-12T16:53:23Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        //We are unsure of how the CONSTANT case works, so using the approach of:\n+        //https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/\n+        // ParquetFilterPredicateConverter.java#L116\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToIcebergType(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToIcebergType(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToIcebergType(leaf));\n+      case IN:\n+        return in(column, (List) leafToIcebergType(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leaf.getLiteralList();\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToIcebergType(PredicateLeaf leaf) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "03729f414d48373cfa23c24e91861afea1f838db"}, "originalPosition": 114}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/b34300aea4e768240a1b39f35b01c58a0fe7ca22", "committedDate": "2020-08-13T17:21:19Z", "message": "Add more tests and change literalList method"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5ODE0NDA4", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-469814408", "createdAt": "2020-08-18T20:40:22Z", "commit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMDo0MDoyMlrOHCl4Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMjo0MDoxN1rOHCpHWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQ3OTc3NQ==", "bodyText": "nit: empty line", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472479775", "createdAt": "2020-08-18T20:40:22Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwODkxMw==", "bodyText": "nit: to b consistent with MICROS_PER_SECOND maybe we can rename NANOSECS_PER_MICROSEC to NANOS_PER_MICROSEC", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472508913", "createdAt": "2020-08-18T21:40:12Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMDg1MQ==", "bodyText": "seems like leafToLiteral can be called only once and its result used in the switch branches", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472510851", "createdAt": "2020-08-18T21:44:38Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMTg0NA==", "bodyText": "nit: seems like UnuspportedOperationExp is more suitable here", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472511844", "createdAt": "2020-08-18T21:46:47Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMDE4NA==", "bodyText": "I'm unsure if this is correct. I think here, the scale of the BigDecimal will always be 0. Irrespective of the underlying data", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472530184", "createdAt": "2020-08-18T22:32:41Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMTY1Mg==", "bodyText": "nit: I think it is clearer to not modify the returned list but to use standard idioms like leaf.getLiteralList().stream().map ... or Lists.transform(..)", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472531652", "createdAt": "2020-08-18T22:36:57Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+      case TIMESTAMP:\n+        Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+        return timestamp.toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                timestamp.getNanos() / NANOSECS_PER_MICROSEC;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        List<Object> dateValues = leaf.getLiteralList();\n+        dateValues.replaceAll(value -> ((Date) value).toLocalDate().toEpochDay());\n+        return dateValues;\n+      case DECIMAL:\n+        List<Object> decimalValues = leaf.getLiteralList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMTcyOA==", "bodyText": "same.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472531728", "createdAt": "2020-08-18T22:37:10Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+      case TIMESTAMP:\n+        Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+        return timestamp.toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                timestamp.getNanos() / NANOSECS_PER_MICROSEC;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        List<Object> dateValues = leaf.getLiteralList();\n+        dateValues.replaceAll(value -> ((Date) value).toLocalDate().toEpochDay());\n+        return dateValues;\n+      case DECIMAL:\n+        List<Object> decimalValues = leaf.getLiteralList();\n+        decimalValues.replaceAll(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()));\n+        return decimalValues;\n+      case TIMESTAMP:\n+        List<Object> timestampValues = leaf.getLiteralList();\n+        timestampValues.replaceAll(value -> ((Timestamp) value).toInstant().getEpochSecond() * MICROS_PER_SECOND +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMTc5Nw==", "bodyText": "nit: better to throw unsupportedexception", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472531797", "createdAt": "2020-08-18T22:37:24Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+      case TIMESTAMP:\n+        Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+        return timestamp.toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                timestamp.getNanos() / NANOSECS_PER_MICROSEC;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        List<Object> dateValues = leaf.getLiteralList();\n+        dateValues.replaceAll(value -> ((Date) value).toLocalDate().toEpochDay());\n+        return dateValues;\n+      case DECIMAL:\n+        List<Object> decimalValues = leaf.getLiteralList();\n+        decimalValues.replaceAll(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()));\n+        return decimalValues;\n+      case TIMESTAMP:\n+        List<Object> timestampValues = leaf.getLiteralList();\n+        timestampValues.replaceAll(value -> ((Timestamp) value).toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                ((Timestamp) value).getNanos() / NANOSECS_PER_MICROSEC);\n+        return timestampValues;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ==", "bodyText": "I don't think getSplits is the right method to set the translated Iceberg expr in jobconf. I think this should go in IcebergStorageHandler . @guilload what do you think?", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472532591", "createdAt": "2020-08-18T22:39:42Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergInputFormat.java", "diffHunk": "@@ -51,6 +58,17 @@\n \n     forwardConfigSettings(job);\n \n+    //Convert Hive filter to Iceberg filter\n+    String hiveFilter = job.get(TableScanDesc.FILTER_EXPR_CONF_STR);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjgyNQ==", "bodyText": "@cmathiesen the latest HiveIcebergInputFormat has changed substantially. Can you please rebase?", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472532825", "createdAt": "2020-08-18T22:40:17Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergInputFormat.java", "diffHunk": "@@ -51,6 +58,17 @@\n \n     forwardConfigSettings(job);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 25}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45197f058034c61f9fe6da6a96ecb0775fec9422", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/45197f058034c61f9fe6da6a96ecb0775fec9422", "committedDate": "2020-08-19T09:54:38Z", "message": "Add filter factory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1f67acf16fd7700027fcd1466bb86a1c5b4da16", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/a1f67acf16fd7700027fcd1466bb86a1c5b4da16", "committedDate": "2020-08-19T09:54:38Z", "message": "Fix type conversions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6c908763037bb04ef78a266e5636b1f67e0eb1d7", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/6c908763037bb04ef78a266e5636b1f67e0eb1d7", "committedDate": "2020-08-19T09:54:38Z", "message": "Add tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e53592d1d51a31e88153a33f2b550b0fd3901c61", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/e53592d1d51a31e88153a33f2b550b0fd3901c61", "committedDate": "2020-08-19T09:54:38Z", "message": "Add more tests and change literalList method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f3d5984bb27881e638283e7a71963f60e557625", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/9f3d5984bb27881e638283e7a71963f60e557625", "committedDate": "2020-08-19T09:54:38Z", "message": "Use stream.map() and nit cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf7551d0039490a7c1d24b3219fcfcea0cc824a5", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/cf7551d0039490a7c1d24b3219fcfcea0cc824a5", "committedDate": "2020-08-19T10:12:11Z", "message": "Fix merge conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5", "committedDate": "2020-08-19T10:28:04Z", "message": "PR review changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwMzMwNTgy", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-470330582", "createdAt": "2020-08-19T10:34:01Z", "commit": {"oid": "4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxMDozNDowMVrOHDBWcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxMDozNDowMVrOHDBWcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkyOTkwNw==", "bodyText": "@cmathiesen I think something went wrong with your rebase/merge from master, there's a lot of stuff in here now which shouldn't be.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472929907", "createdAt": "2020-08-19T10:34:01Z", "author": {"login": "massdosage"}, "path": "api/src/main/java/org/apache/iceberg/ContentFile.java", "diffHunk": "@@ -102,6 +102,18 @@\n    */\n   List<Long> splitOffsets();\n \n+  /**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0b9c04612690c543146fea2c8c40e76daa35a579", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/0b9c04612690c543146fea2c8c40e76daa35a579", "committedDate": "2020-08-19T11:30:36Z", "message": "Merge conflicts"}, "afterCommit": {"oid": "4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5", "committedDate": "2020-08-19T10:28:04Z", "message": "PR review changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43", "committedDate": "2020-08-19T12:23:42Z", "message": "Merge branch 'master' into hive-filter-pushdown"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwNDI0NDE1", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-470424415", "createdAt": "2020-08-19T12:52:16Z", "commit": {"oid": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxMjo1MjoxNlrOHDF6BQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxMjo1MjoxNlrOHDF6BQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzAwNDU0OQ==", "bodyText": "@rdblue @rdsr I added tests for the Date and Timestamp types but when these are run I get errors like:\njava.lang.IllegalArgumentException: Cannot create expression literal from java.time.LocalDate: 2015-11-12\n\tat org.apache.iceberg.expressions.Literals.from(Literals.java:83)\n\tat org.apache.iceberg.expressions.UnboundPredicate.<init>(UnboundPredicate.java:39)\n\tat org.apache.iceberg.expressions.Expressions.equal(Expressions.java:159)\n        at org.apache.iceberg.mr.hive.TestHiveIcebergFilterFactory.testDateType(TestHiveIcebergFilterFactory.java:211)\n\nI noticed here in another test that Date's etc.  are actually passed as Strings - is that the correct option to be using in this case?", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473004549", "createdAt": "2020-08-19T12:52:16Z", "author": {"login": "cmathiesen"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgumentFactory;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestHiveIcebergFilterFactory {\n+\n+  @Test\n+  public void testEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testNotEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startNot().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    Not expected = (Not) Expressions.not(Expressions.equal(\"salary\", 3000L));\n+    Not actual = (Not) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    UnboundPredicate childExpressionActual = (UnboundPredicate) actual.child();\n+    UnboundPredicate childExpressionExpected = Expressions.equal(\"salary\", 3000L);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.child().op(), expected.child().op());\n+    assertEquals(childExpressionActual.ref().name(), childExpressionExpected.ref().name());\n+    assertEquals(childExpressionActual.literal(), childExpressionExpected.literal());\n+  }\n+\n+  @Test\n+  public void testLessThanOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThan(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThan(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literal(), expected.literal());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testLessThanEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThanEquals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThanOrEqual(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testInOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().in(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.in(\"salary\", 3000L, 4000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literals(), expected.literals());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testBetweenOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .between(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    And expected = (And) Expressions.and(Expressions.greaterThanOrEqual(\"salary\", 3000L),\n+        Expressions.lessThanOrEqual(\"salary\", 3000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testIsNullOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().isNull(\"salary\", PredicateLeaf.Type.LONG).end().build();\n+\n+    UnboundPredicate expected = Expressions.isNull(\"salary\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testAndOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 3000L)\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 4000L)\n+        .end().build();\n+\n+    And expected = (And) Expressions\n+        .and(Expressions.equal(\"salary\", 3000L), Expressions.equal(\"salary\", 4000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testOrOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startOr()\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 3000L)\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 4000L)\n+        .end().build();\n+\n+    Or expected = (Or) Expressions\n+        .or(Expressions.equal(\"salary\", 3000L), Expressions.equal(\"salary\", 4000L));\n+    Or actual = (Or) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testStringType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"string\", PredicateLeaf.Type.STRING, \"Joe\").end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"string\", \"Joe\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testFloatType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"float\", PredicateLeaf.Type.FLOAT, 1200D).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"float\", 1200D);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testBooleanType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"boolean\", PredicateLeaf.Type.BOOLEAN, true).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"boolean\", true);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  /*@Test\n+  public void testDateType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"date\", PredicateLeaf.Type.DATE,\n+            Date.valueOf(\"2015-11-12\")).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"date\", LocalDate.of(2015,11,12));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43"}, "originalPosition": 206}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwNzA2NTQ4", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-470706548", "createdAt": "2020-08-19T17:52:56Z", "commit": {"oid": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNzo1Mjo1NlrOHDS7FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNzo1Mjo1NlrOHDS7FQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzIxNzgxMw==", "bodyText": "Do we need to validate that there are only two literals here, or is this reliable?", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473217813", "createdAt": "2020-08-19T17:52:56Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43"}, "originalPosition": 104}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwNzEzODc3", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-470713877", "createdAt": "2020-08-19T18:03:04Z", "commit": {"oid": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxODowMzowNFrOHDTSEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxODowMzowNFrOHDTSEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzIyMzY5OQ==", "bodyText": "Could these cases share the conversion logic between leafToLiteral and leafToLiteralList? That way if we need to fix something it is always applied to both cases.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473223699", "createdAt": "2020-08-19T18:03:04Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+      case TIMESTAMP:\n+        Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+        return timestamp.toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                timestamp.getNanos() / NANOS_PER_MICROSEC;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        return leaf.getLiteralList().stream().map(value -> ((Date) value).toLocalDate().toEpochDay())\n+                .collect(Collectors.toList());\n+      case DECIMAL:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()))\n+                .collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43"}, "originalPosition": 148}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/81fb5cbac1071261797d864ee2b444e65c434a11", "committedDate": "2020-08-21T11:22:41Z", "message": "Conversion methods and fix date/timestamp tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyNDE0OTEz", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-472414913", "createdAt": "2020-08-21T11:30:39Z", "commit": {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMTozMDozOVrOHEptOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxMTozMDozOVrOHEptOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYzOTY3Mw==", "bodyText": "I found a small quirk with the Hive Date type where if you call getLiteral you get a Timestamp back and if you call getLiteralList you get Date objects, which is why there are 2 separate methods for DATE", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r474639673", "createdAt": "2020-08-21T11:30:39Z", "author": {"login": "cmathiesen"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return timestampToDateString((Timestamp) leaf.getLiteral());\n+      case DECIMAL:\n+        return hiveDecimalToBigDecimal((HiveDecimalWritable) leaf.getLiteral());\n+      case TIMESTAMP:\n+        return timestampToTimestampString((Timestamp) leaf.getLiteral());\n+\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11"}, "originalPosition": 140}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyNjMxNTc4", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-472631578", "createdAt": "2020-08-21T16:32:47Z", "commit": {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNjozMjo0N1rOHEzxPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNjozMjo0N1rOHEzxPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgwNDU0Mg==", "bodyText": "This shouldn't convert to a string. Instead, it should convert the Timestamp value directly to microseconds from the unix epoch. String conversion in expressions is only for convenience in tests and for people using the API directly with generics. If an engine passes a predicate, we don't want to needlessly convert to string and back because it is much, much more likely to corrupt the value.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r474804542", "createdAt": "2020-08-21T16:32:47Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -140,18 +137,34 @@ private static Object leafToLiteral(PredicateLeaf leaf) {\n       case STRING:\n         return leaf.getLiteralList();\n       case DATE:\n-        return leaf.getLiteralList().stream().map(value -> ((Date) value).toLocalDate().toEpochDay())\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))\n                 .collect(Collectors.toList());\n       case DECIMAL:\n         return leaf.getLiteralList().stream()\n-                .map(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()))\n+                .map(value -> hiveDecimalToBigDecimal((HiveDecimalWritable) value))\n                 .collect(Collectors.toList());\n       case TIMESTAMP:\n         return leaf.getLiteralList().stream()\n-                .map(value -> ((Timestamp) value).toInstant().getEpochSecond() * MICROS_PER_SECOND +\n-                        ((Timestamp) value).getNanos() / NANOS_PER_MICROSEC).collect(Collectors.toList());\n+                .map(value -> timestampToTimestampString((Timestamp) value))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyNjMxOTc0", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-472631974", "createdAt": "2020-08-21T16:33:23Z", "commit": {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNjozMzoyNFrOHEzyUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNjozMzoyNFrOHEzyUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgwNDgxOQ==", "bodyText": "I don't think we want to convert to String here, either. Can you use the same logic from ORC?", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r474804819", "createdAt": "2020-08-21T16:33:24Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -140,18 +137,34 @@ private static Object leafToLiteral(PredicateLeaf leaf) {\n       case STRING:\n         return leaf.getLiteralList();\n       case DATE:\n-        return leaf.getLiteralList().stream().map(value -> ((Date) value).toLocalDate().toEpochDay())\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))\n                 .collect(Collectors.toList());\n       case DECIMAL:\n         return leaf.getLiteralList().stream()\n-                .map(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()))\n+                .map(value -> hiveDecimalToBigDecimal((HiveDecimalWritable) value))\n                 .collect(Collectors.toList());\n       case TIMESTAMP:\n         return leaf.getLiteralList().stream()\n-                .map(value -> ((Timestamp) value).toInstant().getEpochSecond() * MICROS_PER_SECOND +\n-                        ((Timestamp) value).getNanos() / NANOS_PER_MICROSEC).collect(Collectors.toList());\n+                .map(value -> timestampToTimestampString((Timestamp) value))\n+                .collect(Collectors.toList());\n       default:\n-        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n     }\n   }\n+\n+  private static String timestampToDateString(Timestamp timestamp) {\n+    return timestamp.toLocalDateTime().toLocalDate().toString();\n+  }\n+\n+  private static String dateToString(Date date) {\n+    return date.toLocalDate().toString();\n+  }\n+\n+  private static BigDecimal hiveDecimalToBigDecimal(HiveDecimalWritable hiveDecimalWritable) {\n+    return new BigDecimal(hiveDecimalWritable.toString()).setScale(hiveDecimalWritable.scale());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11"}, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyOTk1Njgy", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-472995682", "createdAt": "2020-08-23T09:30:44Z", "commit": {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOTozMDo0NFrOHFLrQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOTozMDo0NFrOHFLrQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NjIyNg==", "bodyText": "HiveIcebergFilterFactory.generateFilterExpression might throw UnsupportedOperationException.\nMaybe it would be good to catch the exception and continue without filters in case if there is an error.\nHive runs the filters later anyway, so it will not cause issue.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r475196226", "createdAt": "2020-08-23T09:30:44Z", "author": {"login": "pvary"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergInputFormat.java", "diffHunk": "@@ -36,6 +43,16 @@\n \n   @Override\n   public InputSplit[] getSplits(JobConf job, int numSplits) throws IOException {\n+    //Convert Hive filter to Iceberg filter\n+    String hiveFilter = job.get(TableScanDesc.FILTER_EXPR_CONF_STR);\n+    if (hiveFilter != null) {\n+      ExprNodeGenericFuncDesc exprNodeDesc = SerializationUtilities\n+              .deserializeObject(hiveFilter, ExprNodeGenericFuncDesc.class);\n+      SearchArgument sarg = ConvertAstToSearchArg.create(job, exprNodeDesc);\n+      Expression filter = HiveIcebergFilterFactory.generateFilterExpression(sarg);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11"}, "originalPosition": 29}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4396672bf858e5e5edbf0cda24930fda3d96501e", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/4396672bf858e5e5edbf0cda24930fda3d96501e", "committedDate": "2020-08-24T10:33:33Z", "message": "Correct timestamp and decimal conversion"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/848a3aba235f6e91017f7d4590efeadc7626ec24", "committedDate": "2020-08-24T18:40:41Z", "message": "Change log message to warn"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczNzcyMDQ1", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-473772045", "createdAt": "2020-08-24T18:54:49Z", "commit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo1NDo0OVrOHFyLFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo1NDo0OVrOHFyLFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyNjk2Ng==", "bodyText": "This seems odd to me. Why not call TimeUnit.SECONDS.toMicros(timestamp.toInstant().getEpochSecond())? Using the toMicros function to get the conversion factor, but not actually using it for conversion is strange.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r475826966", "createdAt": "2020-08-24T18:54:49Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return timestampToDateString((Timestamp) leaf.getLiteral());\n+      case DECIMAL:\n+        return hiveDecimalToBigDecimal((HiveDecimalWritable) leaf.getLiteral());\n+      case TIMESTAMP:\n+        return timestampToUnixEpoch((Timestamp) leaf.getLiteral());\n+\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))\n+                .collect(Collectors.toList());\n+      case DECIMAL:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> hiveDecimalToBigDecimal((HiveDecimalWritable) value))\n+                .collect(Collectors.toList());\n+      case TIMESTAMP:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> timestampToUnixEpoch((Timestamp) value))\n+                .collect(Collectors.toList());\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static String timestampToDateString(Timestamp timestamp) {\n+    return timestamp.toLocalDateTime().toLocalDate().toString();\n+  }\n+\n+  private static String dateToString(Date date) {\n+    return date.toLocalDate().toString();\n+  }\n+\n+  private static BigDecimal hiveDecimalToBigDecimal(HiveDecimalWritable hiveDecimalWritable) {\n+    return hiveDecimalWritable.getHiveDecimal().bigDecimalValue().setScale(hiveDecimalWritable.scale());\n+  }\n+\n+  private static long timestampToUnixEpoch(Timestamp timestamp) {\n+    return timestamp.toInstant().getEpochSecond() * TimeUnit.SECONDS.toMicros(1) +\n+            timestamp.getNanos() / TimeUnit.MICROSECONDS.toNanos(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24"}, "originalPosition": 170}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczNzcyMzkz", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-473772393", "createdAt": "2020-08-24T18:55:18Z", "commit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo1NToxOFrOHFyMRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo1NToxOFrOHFyMRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyNzI2OA==", "bodyText": "Dates need to be converted directly to a value and not a string also. You can use DateTimeUtil if you need.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r475827268", "createdAt": "2020-08-24T18:55:18Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return timestampToDateString((Timestamp) leaf.getLiteral());\n+      case DECIMAL:\n+        return hiveDecimalToBigDecimal((HiveDecimalWritable) leaf.getLiteral());\n+      case TIMESTAMP:\n+        return timestampToUnixEpoch((Timestamp) leaf.getLiteral());\n+\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))\n+                .collect(Collectors.toList());\n+      case DECIMAL:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> hiveDecimalToBigDecimal((HiveDecimalWritable) value))\n+                .collect(Collectors.toList());\n+      case TIMESTAMP:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> timestampToUnixEpoch((Timestamp) value))\n+                .collect(Collectors.toList());\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static String timestampToDateString(Timestamp timestamp) {\n+    return timestamp.toLocalDateTime().toLocalDate().toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24"}, "originalPosition": 157}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczNzczNTU0", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-473773554", "createdAt": "2020-08-24T18:56:55Z", "commit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo1Njo1NlrOHFyPxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo1Njo1NlrOHFyPxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyODE2NA==", "bodyText": "I think this expression should use an integer value instead of a String.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r475828164", "createdAt": "2020-08-24T18:56:56Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,243 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgumentFactory;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestHiveIcebergFilterFactory {\n+\n+  @Test\n+  public void testEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testNotEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startNot().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    Not expected = (Not) Expressions.not(Expressions.equal(\"salary\", 3000L));\n+    Not actual = (Not) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    UnboundPredicate childExpressionActual = (UnboundPredicate) actual.child();\n+    UnboundPredicate childExpressionExpected = Expressions.equal(\"salary\", 3000L);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.child().op(), expected.child().op());\n+    assertEquals(childExpressionActual.ref().name(), childExpressionExpected.ref().name());\n+    assertEquals(childExpressionActual.literal(), childExpressionExpected.literal());\n+  }\n+\n+  @Test\n+  public void testLessThanOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThan(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThan(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literal(), expected.literal());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testLessThanEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThanEquals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThanOrEqual(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testInOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().in(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.in(\"salary\", 3000L, 4000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literals(), expected.literals());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testBetweenOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .between(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    And expected = (And) Expressions.and(Expressions.greaterThanOrEqual(\"salary\", 3000L),\n+        Expressions.lessThanOrEqual(\"salary\", 3000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testIsNullOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().isNull(\"salary\", PredicateLeaf.Type.LONG).end().build();\n+\n+    UnboundPredicate expected = Expressions.isNull(\"salary\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testAndOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 3000L)\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 4000L)\n+        .end().build();\n+\n+    And expected = (And) Expressions\n+        .and(Expressions.equal(\"salary\", 3000L), Expressions.equal(\"salary\", 4000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testOrOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startOr()\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 3000L)\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 4000L)\n+        .end().build();\n+\n+    Or expected = (Or) Expressions\n+        .or(Expressions.equal(\"salary\", 3000L), Expressions.equal(\"salary\", 4000L));\n+    Or actual = (Or) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testStringType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"string\", PredicateLeaf.Type.STRING, \"Joe\").end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"string\", \"Joe\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testFloatType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"float\", PredicateLeaf.Type.FLOAT, 1200D).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"float\", 1200D);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testBooleanType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"boolean\", PredicateLeaf.Type.BOOLEAN, true).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"boolean\", true);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testDateType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"date\", PredicateLeaf.Type.DATE,\n+            Date.valueOf(\"2015-11-12\")).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"date\", \"2015-11-12\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24"}, "originalPosition": 208}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0MjQ5MDgy", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-474249082", "createdAt": "2020-08-25T08:24:15Z", "commit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQwODoyNDoxNVrOHGNI3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQwODozNDo0M1rOHGNikw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI2ODc2Ng==", "bodyText": "+1, similarly for timestamp.getNanos() / TimeUnit.MICROSECONDS.toNanos(1) -TimeUnit.NANOSECONDS.toMicros(timestamp.getNanos())", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r476268766", "createdAt": "2020-08-25T08:24:15Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return timestampToDateString((Timestamp) leaf.getLiteral());\n+      case DECIMAL:\n+        return hiveDecimalToBigDecimal((HiveDecimalWritable) leaf.getLiteral());\n+      case TIMESTAMP:\n+        return timestampToUnixEpoch((Timestamp) leaf.getLiteral());\n+\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))\n+                .collect(Collectors.toList());\n+      case DECIMAL:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> hiveDecimalToBigDecimal((HiveDecimalWritable) value))\n+                .collect(Collectors.toList());\n+      case TIMESTAMP:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> timestampToUnixEpoch((Timestamp) value))\n+                .collect(Collectors.toList());\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static String timestampToDateString(Timestamp timestamp) {\n+    return timestamp.toLocalDateTime().toLocalDate().toString();\n+  }\n+\n+  private static String dateToString(Date date) {\n+    return date.toLocalDate().toString();\n+  }\n+\n+  private static BigDecimal hiveDecimalToBigDecimal(HiveDecimalWritable hiveDecimalWritable) {\n+    return hiveDecimalWritable.getHiveDecimal().bigDecimalValue().setScale(hiveDecimalWritable.scale());\n+  }\n+\n+  private static long timestampToUnixEpoch(Timestamp timestamp) {\n+    return timestamp.toInstant().getEpochSecond() * TimeUnit.SECONDS.toMicros(1) +\n+            timestamp.getNanos() / TimeUnit.MICROSECONDS.toNanos(1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyNjk2Ng=="}, "originalCommit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI2OTQzNw==", "bodyText": "That makes sense. Seems like we cannot do this for predicate and projection pushdown in StorageHandler itself.", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r476269437", "createdAt": "2020-08-25T08:25:19Z", "author": {"login": "rdsr"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergInputFormat.java", "diffHunk": "@@ -51,6 +58,17 @@\n \n     forwardConfigSettings(job);\n \n+    //Convert Hive filter to Iceberg filter\n+    String hiveFilter = job.get(TableScanDesc.FILTER_EXPR_CONF_STR);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ=="}, "originalCommit": {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI3NTM0Nw==", "bodyText": "Do we need a test using HiveRunner ? Since Hive stores the table's schema in lowercase I think we might have to support a case insensitive match on the iceberg side.\ncc @pvary, @guilload", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r476275347", "createdAt": "2020-08-25T08:34:43Z", "author": {"login": "rdsr"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,243 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgumentFactory;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestHiveIcebergFilterFactory {\n+\n+  @Test\n+  public void testEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testNotEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startNot().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    Not expected = (Not) Expressions.not(Expressions.equal(\"salary\", 3000L));\n+    Not actual = (Not) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    UnboundPredicate childExpressionActual = (UnboundPredicate) actual.child();\n+    UnboundPredicate childExpressionExpected = Expressions.equal(\"salary\", 3000L);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.child().op(), expected.child().op());\n+    assertEquals(childExpressionActual.ref().name(), childExpressionExpected.ref().name());\n+    assertEquals(childExpressionActual.literal(), childExpressionExpected.literal());\n+  }\n+\n+  @Test\n+  public void testLessThanOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThan(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThan(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literal(), expected.literal());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testLessThanEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThanEquals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThanOrEqual(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testInOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().in(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.in(\"salary\", 3000L, 4000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literals(), expected.literals());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testBetweenOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .between(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    And expected = (And) Expressions.and(Expressions.greaterThanOrEqual(\"salary\", 3000L),\n+        Expressions.lessThanOrEqual(\"salary\", 3000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testIsNullOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().isNull(\"salary\", PredicateLeaf.Type.LONG).end().build();\n+\n+    UnboundPredicate expected = Expressions.isNull(\"salary\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testAndOperand() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24"}, "originalPosition": 134}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db95c5cd0f3adeb876590bc18d380923f5a27f74", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/db95c5cd0f3adeb876590bc18d380923f5a27f74", "committedDate": "2020-08-25T08:43:14Z", "message": "Change date conversions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b6752247deca9161f84132f64939518b218727c0", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/b6752247deca9161f84132f64939518b218727c0", "committedDate": "2020-08-25T08:46:03Z", "message": "timeunit nanos to micros"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e97a461fd77344073e70881a7a4f106267d80f70", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/e97a461fd77344073e70881a7a4f106267d80f70", "committedDate": "2020-08-26T15:04:34Z", "message": "fix faulty timestamp test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc2NTM4MDc4", "url": "https://github.com/apache/iceberg/pull/1326#pullrequestreview-476538078", "createdAt": "2020-08-27T09:20:55Z", "commit": {"oid": "e97a461fd77344073e70881a7a4f106267d80f70"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOToyMDo1NVrOHIHyMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOToyMDo1NVrOHIHyMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI3ODE5NA==", "bodyText": "Maybe logging would be nice here minimally on DEBUG level, but maybe on INFO level, like:\nLOG.info(\"Translated sarg=[{}] to expression=[{}]\", sarg, expression);\n\nNot sure about the toString implementations, but the general idea would be to see what went in and what came out.\nAlso we can add this later, just noting here so we do not forget :D", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r478278194", "createdAt": "2020-08-27T09:20:55Z", "author": {"login": "pvary"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,168 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.util.DateTimeUtil;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {\n+  }\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e97a461fd77344073e70881a7a4f106267d80f70"}, "originalPosition": 53}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfadba5bf8e691e48d3ea492faa9e7d7822e3891", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/cfadba5bf8e691e48d3ea492faa9e7d7822e3891", "committedDate": "2020-08-30T00:59:55Z", "message": "Fix date and timestamp conversion."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "614781ee46e4af2dd4e4bb69f36d0528081f8dc5", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/614781ee46e4af2dd4e4bb69f36d0528081f8dc5", "committedDate": "2020-08-31T14:49:18Z", "message": "Merge pull request #16 from rdblue/pr-1326-hive-ppd\n\nFix date and timestamp conversion"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef5b050dfb902950585b26cd01a0e2e8162dd9af", "author": {"user": {"login": "cmathiesen", "name": null}}, "url": "https://github.com/apache/iceberg/commit/ef5b050dfb902950585b26cd01a0e2e8162dd9af", "committedDate": "2020-08-31T15:13:50Z", "message": "Remove unused import"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4023, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}