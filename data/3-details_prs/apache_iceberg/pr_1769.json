{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIwODA3Njg3", "number": 1769, "title": "Spark: Add RollbackToTimestampProcedure", "bodyText": "This PR adds a procedure to rollback a table to a given point in time.\nResolves #1594.", "createdAt": "2020-11-13T19:33:39Z", "url": "https://github.com/apache/iceberg/pull/1769", "merged": true, "mergeCommit": {"oid": "008852a2233de700dae10d5e4004807e2ec29422"}, "closed": true, "closedAt": "2020-11-14T01:49:52Z", "author": {"login": "aokolnychyi"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdcMbZZAFqTUzMDM1MTM0NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdcRKVFgH2gAyNTIwODA3Njg3OjQ2MTE5MDAyOTQ2MDRiZmVlMjQzZjQwOGJjZTBhYjE1ODYxZTQwNTA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwMzUxMzQ1", "url": "https://github.com/apache/iceberg/pull/1769#pullrequestreview-530351345", "createdAt": "2020-11-13T19:35:54Z", "commit": {"oid": "74700a0450627f9aac9bede1efa79f1062768da1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxOTozNTo1NFrOHy8bwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxOTozNTo1NFrOHy8bwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE4MDk5Mg==", "bodyText": "Here we have the same problem as in other cases. If there is a concurrent operation after commit, the output may not be precise. To make it reliable, we may attach a UUID to this operation and fetch the snapshot by it. Any other ideas are welcome.", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523180992", "createdAt": "2020-11-13T19:35:54Z", "author": {"login": "aokolnychyi"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/procedures/RollbackToTimestampProcedure.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.procedures;\n+\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.spark.procedures.SparkProcedures.ProcedureBuilder;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n+import org.apache.spark.sql.connector.iceberg.catalog.ProcedureParameter;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * A procedure that rollbacks a table to a given point in time.\n+ */\n+class RollbackToTimestampProcedure extends BaseProcedure {\n+\n+  private static final ProcedureParameter[] PARAMETERS = new ProcedureParameter[]{\n+      ProcedureParameter.required(\"namespace\", DataTypes.StringType),\n+      ProcedureParameter.required(\"table\", DataTypes.StringType),\n+      ProcedureParameter.required(\"timestamp\", DataTypes.TimestampType)\n+  };\n+\n+  private static final StructType OUTPUT_TYPE = new StructType(new StructField[]{\n+      new StructField(\"previous_snapshot_id\", DataTypes.LongType, false, Metadata.empty()),\n+      new StructField(\"current_snapshot_id\", DataTypes.LongType, false, Metadata.empty())\n+  });\n+\n+  public static ProcedureBuilder builder() {\n+    return new BaseProcedure.Builder<RollbackToTimestampProcedure>() {\n+      @Override\n+      protected RollbackToTimestampProcedure doBuild() {\n+        return new RollbackToTimestampProcedure(tableCatalog());\n+      }\n+    };\n+  }\n+\n+  private RollbackToTimestampProcedure(TableCatalog catalog) {\n+    super(catalog);\n+  }\n+\n+  @Override\n+  public ProcedureParameter[] parameters() {\n+    return PARAMETERS;\n+  }\n+\n+  @Override\n+  public StructType outputType() {\n+    return OUTPUT_TYPE;\n+  }\n+\n+  @Override\n+  public InternalRow[] call(InternalRow args) {\n+    String namespace = args.getString(0);\n+    String tableName = args.getString(1);\n+    // timestamps in Spark have nanosecond precision so this conversion is lossy\n+    long timestampMillis = DateTimeUtils.toMillis(args.getLong(2));\n+\n+    return modifyIcebergTable(namespace, tableName, table -> {\n+      Snapshot previousSnapshot = table.currentSnapshot();\n+\n+      table.manageSnapshots()\n+          .rollbackToTime(timestampMillis)\n+          .commit();\n+\n+      Snapshot currentSnapshot = table.currentSnapshot();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74700a0450627f9aac9bede1efa79f1062768da1"}, "originalPosition": 87}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwMzUxNjAx", "url": "https://github.com/apache/iceberg/pull/1769#pullrequestreview-530351601", "createdAt": "2020-11-13T19:36:20Z", "commit": {"oid": "74700a0450627f9aac9bede1efa79f1062768da1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxOTozNjoyMVrOHy8cng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxOTozNjoyMVrOHy8cng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE4MTIxNA==", "bodyText": "I think this truncation should be fine.", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523181214", "createdAt": "2020-11-13T19:36:21Z", "author": {"login": "aokolnychyi"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/procedures/RollbackToTimestampProcedure.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.procedures;\n+\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.spark.procedures.SparkProcedures.ProcedureBuilder;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n+import org.apache.spark.sql.connector.iceberg.catalog.ProcedureParameter;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * A procedure that rollbacks a table to a given point in time.\n+ */\n+class RollbackToTimestampProcedure extends BaseProcedure {\n+\n+  private static final ProcedureParameter[] PARAMETERS = new ProcedureParameter[]{\n+      ProcedureParameter.required(\"namespace\", DataTypes.StringType),\n+      ProcedureParameter.required(\"table\", DataTypes.StringType),\n+      ProcedureParameter.required(\"timestamp\", DataTypes.TimestampType)\n+  };\n+\n+  private static final StructType OUTPUT_TYPE = new StructType(new StructField[]{\n+      new StructField(\"previous_snapshot_id\", DataTypes.LongType, false, Metadata.empty()),\n+      new StructField(\"current_snapshot_id\", DataTypes.LongType, false, Metadata.empty())\n+  });\n+\n+  public static ProcedureBuilder builder() {\n+    return new BaseProcedure.Builder<RollbackToTimestampProcedure>() {\n+      @Override\n+      protected RollbackToTimestampProcedure doBuild() {\n+        return new RollbackToTimestampProcedure(tableCatalog());\n+      }\n+    };\n+  }\n+\n+  private RollbackToTimestampProcedure(TableCatalog catalog) {\n+    super(catalog);\n+  }\n+\n+  @Override\n+  public ProcedureParameter[] parameters() {\n+    return PARAMETERS;\n+  }\n+\n+  @Override\n+  public StructType outputType() {\n+    return OUTPUT_TYPE;\n+  }\n+\n+  @Override\n+  public InternalRow[] call(InternalRow args) {\n+    String namespace = args.getString(0);\n+    String tableName = args.getString(1);\n+    // timestamps in Spark have nanosecond precision so this conversion is lossy\n+    long timestampMillis = DateTimeUtils.toMillis(args.getLong(2));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74700a0450627f9aac9bede1efa79f1062768da1"}, "originalPosition": 78}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwNDEyODQ5", "url": "https://github.com/apache/iceberg/pull/1769#pullrequestreview-530412849", "createdAt": "2020-11-13T21:01:40Z", "commit": {"oid": "74700a0450627f9aac9bede1efa79f1062768da1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMTowMTo0MVrOHy_cIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMTowMTo0MVrOHy_cIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzMDI0MA==", "bodyText": "Minor: Some of the setup could be put into a @Before method.", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523230240", "createdAt": "2020-11-13T21:01:41Z", "author": {"login": "rdblue"}, "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestRollbackToTimestampProcedure.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.time.LocalDateTime;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.spark.sql.AnalysisException;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchProcedureException;\n+import org.junit.After;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+public class TestRollbackToTimestampProcedure extends SparkExtensionsTestBase {\n+\n+  public TestRollbackToTimestampProcedure(String catalogName, String implementation, Map<String, String> config) {\n+    super(catalogName, implementation, config);\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampUsingPositionalArgs() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp('%s', '%s', TIMESTAMP '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), firstSnapshotTimestamp);\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"Rollback must be successful\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampUsingNamedArgs() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp(timestamp => TIMESTAMP '%s', namespace => '%s', table => '%s')\",\n+        catalogName, firstSnapshotTimestamp, tableIdent.namespace(), tableIdent.name());\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"Rollback must be successful\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampRefreshesRelationCache() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    Dataset<Row> query = spark.sql(\"SELECT * FROM \" + tableName + \" WHERE id = 1\");\n+    query.createOrReplaceTempView(\"tmp\");\n+\n+    spark.sql(\"CACHE TABLE tmp\");\n+\n+    assertEquals(\"View should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM tmp\"));\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp(namespace => '%s', table => '%s', timestamp => TIMESTAMP '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), firstSnapshotTimestamp);\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"View cache must be invalidated\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM tmp\"));\n+\n+    sql(\"UNCACHE TABLE tmp\");\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampWithQuotedIdentifiers() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74700a0450627f9aac9bede1efa79f1062768da1"}, "originalPosition": 164}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwNDEzMjMz", "url": "https://github.com/apache/iceberg/pull/1769#pullrequestreview-530413233", "createdAt": "2020-11-13T21:02:21Z", "commit": {"oid": "74700a0450627f9aac9bede1efa79f1062768da1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMTowMjoyMVrOHy_dPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMTowMjoyMVrOHy_dPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzMDUyNg==", "bodyText": "Can we use a waitUntilAfter(firstSnapshot.timestampMillis()) method instead? Sleep causes tests to take longer.", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523230526", "createdAt": "2020-11-13T21:02:21Z", "author": {"login": "rdblue"}, "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestRollbackToTimestampProcedure.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.time.LocalDateTime;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.spark.sql.AnalysisException;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchProcedureException;\n+import org.junit.After;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+public class TestRollbackToTimestampProcedure extends SparkExtensionsTestBase {\n+\n+  public TestRollbackToTimestampProcedure(String catalogName, String implementation, Map<String, String> config) {\n+    super(catalogName, implementation, config);\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampUsingPositionalArgs() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp('%s', '%s', TIMESTAMP '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), firstSnapshotTimestamp);\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"Rollback must be successful\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampUsingNamedArgs() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp(timestamp => TIMESTAMP '%s', namespace => '%s', table => '%s')\",\n+        catalogName, firstSnapshotTimestamp, tableIdent.namespace(), tableIdent.name());\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"Rollback must be successful\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampRefreshesRelationCache() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74700a0450627f9aac9bede1efa79f1062768da1"}, "originalPosition": 125}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwNDEzNTU2", "url": "https://github.com/apache/iceberg/pull/1769#pullrequestreview-530413556", "createdAt": "2020-11-13T21:02:52Z", "commit": {"oid": "74700a0450627f9aac9bede1efa79f1062768da1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d1d2fb2404d24d7a63ba20af0f79bb1db24af51", "author": {"user": {"login": "aokolnychyi", "name": "Anton Okolnychyi"}}, "url": "https://github.com/apache/iceberg/commit/8d1d2fb2404d24d7a63ba20af0f79bb1db24af51", "committedDate": "2020-11-14T00:59:17Z", "message": "Spark: Add RollbackToTimestampProcedure"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "da179197cf3518d519f43d4a316e682fb1e10fdb", "author": {"user": {"login": "aokolnychyi", "name": "Anton Okolnychyi"}}, "url": "https://github.com/apache/iceberg/commit/da179197cf3518d519f43d4a316e682fb1e10fdb", "committedDate": "2020-11-13T23:07:12Z", "message": "Avoid Thread.sleep"}, "afterCommit": {"oid": "8d1d2fb2404d24d7a63ba20af0f79bb1db24af51", "author": {"user": {"login": "aokolnychyi", "name": "Anton Okolnychyi"}}, "url": "https://github.com/apache/iceberg/commit/8d1d2fb2404d24d7a63ba20af0f79bb1db24af51", "committedDate": "2020-11-14T00:59:17Z", "message": "Spark: Add RollbackToTimestampProcedure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4611900294604bfee243f408bce0ab15861e4050", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/4611900294604bfee243f408bce0ab15861e4050", "committedDate": "2020-11-14T01:06:47Z", "message": "Merge branch 'master' into rollback-to-timestamp"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3752, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}