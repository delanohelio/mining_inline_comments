{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2NDEyMTk0", "number": 1125, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoxNDozM1rOEILOSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwMjo0NjowNlrOEJZvjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDA3OTQ1OnYy", "diffSide": "RIGHT", "path": "flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoxNDozM1rOGn-vIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNDoxMTo0NFrOGoCTJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3NTUyMw==", "bodyText": "How high have you tested? I usually test locally with ~1m rows.\nCould you also add tests with the new generation methods that @samarthjain added for Parquet vectorization? Those allow you to generate data that will be dictionary encoded and that will fall back to non-dictionary after a few dictionary pages. \n  \n    \n      iceberg/spark/src/test/java/org/apache/iceberg/spark/data/RandomData.java\n    \n    \n        Lines 99 to 106\n      in\n      705da1b\n    \n    \n    \n    \n\n        \n          \n           public static Iterable<Record> generateFallbackData(Schema schema, int numRecords, long seed, long numDictRecords) { \n        \n\n        \n          \n             return newIterable(() -> new FallbackDataGenerator(schema, seed, numDictRecords), schema, numRecords); \n        \n\n        \n          \n           } \n        \n\n        \n          \n            \n        \n\n        \n          \n           public static Iterable<GenericData.Record> generateDictionaryEncodableData( \n        \n\n        \n          \n               Schema schema, int numRecords, long seed, float nullPercentage) { \n        \n\n        \n          \n             return newIterable(() -> new DictionaryEncodedDataGenerator(schema, seed, nullPercentage), schema, numRecords); \n        \n\n        \n          \n           }", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444575523", "createdAt": "2020-06-24T00:14:33Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.parquet.Parquet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestFlinkParquetReaderWriter {\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  private static final Schema COMPLEX_SCHEMA = new Schema(\n+      required(1, \"roots\", Types.LongType.get()),\n+      optional(3, \"lime\", Types.ListType.ofRequired(4, Types.DoubleType.get())),\n+      required(5, \"strict\", Types.StructType.of(\n+          required(9, \"tangerine\", Types.StringType.get()),\n+          optional(6, \"hopeful\", Types.StructType.of(\n+              required(7, \"steel\", Types.FloatType.get()),\n+              required(8, \"lantern\", Types.DateType.get())\n+          )),\n+          optional(10, \"vehement\", Types.LongType.get())\n+      )),\n+      optional(11, \"metamorphosis\", Types.MapType.ofRequired(12, 13,\n+          Types.StringType.get(), Types.TimestampType.withZone())),\n+      required(14, \"winter\", Types.ListType.ofOptional(15, Types.StructType.of(\n+          optional(16, \"beet\", Types.DoubleType.get()),\n+          required(17, \"stamp\", Types.FloatType.get()),\n+          optional(18, \"wheeze\", Types.StringType.get())\n+      ))),\n+      optional(19, \"renovate\", Types.MapType.ofRequired(20, 21,\n+          Types.StringType.get(), Types.StructType.of(\n+              optional(22, \"jumpy\", Types.DoubleType.get()),\n+              required(23, \"koala\", Types.IntegerType.get()),\n+              required(24, \"couch rope\", Types.IntegerType.get())\n+          ))),\n+      optional(2, \"slide\", Types.StringType.get())\n+  );\n+\n+  @Test\n+  public void testCorrectness() throws IOException {\n+    int numRows = 2500;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYzMzg5NQ==", "bodyText": "OK, let me think about how to add those unit tests. Thanks.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444633895", "createdAt": "2020-06-24T04:11:44Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.parquet.Parquet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestFlinkParquetReaderWriter {\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  private static final Schema COMPLEX_SCHEMA = new Schema(\n+      required(1, \"roots\", Types.LongType.get()),\n+      optional(3, \"lime\", Types.ListType.ofRequired(4, Types.DoubleType.get())),\n+      required(5, \"strict\", Types.StructType.of(\n+          required(9, \"tangerine\", Types.StringType.get()),\n+          optional(6, \"hopeful\", Types.StructType.of(\n+              required(7, \"steel\", Types.FloatType.get()),\n+              required(8, \"lantern\", Types.DateType.get())\n+          )),\n+          optional(10, \"vehement\", Types.LongType.get())\n+      )),\n+      optional(11, \"metamorphosis\", Types.MapType.ofRequired(12, 13,\n+          Types.StringType.get(), Types.TimestampType.withZone())),\n+      required(14, \"winter\", Types.ListType.ofOptional(15, Types.StructType.of(\n+          optional(16, \"beet\", Types.DoubleType.get()),\n+          required(17, \"stamp\", Types.FloatType.get()),\n+          optional(18, \"wheeze\", Types.StringType.get())\n+      ))),\n+      optional(19, \"renovate\", Types.MapType.ofRequired(20, 21,\n+          Types.StringType.get(), Types.StructType.of(\n+              optional(22, \"jumpy\", Types.DoubleType.get()),\n+              required(23, \"koala\", Types.IntegerType.get()),\n+              required(24, \"couch rope\", Types.IntegerType.get())\n+          ))),\n+      optional(2, \"slide\", Types.StringType.get())\n+  );\n+\n+  @Test\n+  public void testCorrectness() throws IOException {\n+    int numRows = 2500;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3NTUyMw=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDA4MzMxOnYy", "diffSide": "RIGHT", "path": "flink/src/test/java/org/apache/iceberg/flink/data/RandomData.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoxNjo1MVrOGn-xZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoxNjo1MVrOGn-xZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3NjEwMw==", "bodyText": "Should this inherit from the one for Iceberg generics to avoid duplicating the list and map methods? Primitive and struct will need to be implemented, but this could reuse a lot there as well.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444576103", "createdAt": "2020-06-24T00:16:51Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/data/RandomData.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.ZoneOffset;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Supplier;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.TypeUtil;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.util.RandomUtil;\n+\n+import static java.time.temporal.ChronoUnit.MICROS;\n+\n+public class RandomData {\n+  private RandomData() {\n+  }\n+\n+  public static List<Row> generate(Schema schema, int numRecords, long seed) {\n+    RandomDataGenerator generator = new RandomDataGenerator(seed);\n+    List<Row> rows = Lists.newArrayListWithExpectedSize(numRecords);\n+    for (int i = 0; i < numRecords; i += 1) {\n+      rows.add((Row) TypeUtil.visit(schema, generator));\n+    }\n+\n+    return rows;\n+  }\n+\n+  private static class RandomDataGenerator extends TypeUtil.CustomOrderSchemaVisitor<Object> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDA5NTg5OnYy", "diffSide": "RIGHT", "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "isResolved": false, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyNDozNVrOGn-5Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowMzoxMFrOGpoQHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg==", "bodyText": "Instead of adding this interface, what about adding WriteBuilder.createStructWriter to do this? That way, the Flink builder could just inherit from the generic builder and override that one method.\nI think that would be cleaner because adding this interface requires also adding public methods to pass the factory. I'd rather not add those public methods if we can avoid it by adding a protected method and change the builder to a protected class.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444578082", "createdAt": "2020-06-24T00:24:35Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxNzIwNg==", "bodyText": "I guess we will also need to mark the WriteBuilder from private to public because it will be accessed by flink classes from outside package.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444617206", "createdAt": "2020-06-24T02:58:47Z", "author": {"login": "openinx"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTAzMzE0MQ==", "bodyText": "It could be protected, right?", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445033141", "createdAt": "2020-06-24T16:48:48Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTIyNjY4MA==", "bodyText": "protected is not enough for the outside flink package, the WriterBuilder is a static class in org.apache.iceberg.data.parquet , it must be public so that other packages could inherit it.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445226680", "createdAt": "2020-06-24T23:30:32Z", "author": {"login": "openinx"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTIzOTg5Nw==", "bodyText": "You're right. The class should be public, but the method that will be overridden should be protected.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445239897", "createdAt": "2020-06-25T00:16:36Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NzE2MA==", "bodyText": "Em, I've implemented two versions. the first version provides a  public  interfaces with protected StructureWriterFactory and StructReaderFactory, the second version use the inherit WriterBuilder  & ReaderBuilder #1125. For me , seems the first version looks much more concise. I plan to change to version#1 (with the  public interface and protected methods ). Thanks.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445257160", "createdAt": "2020-06-25T01:23:06Z", "author": {"login": "openinx"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTcwNjgyNQ==", "bodyText": "Could you post the branch with the inheritance version? I'd like to see it to compare. I don't like the extra public classes and methods, and I think that inheritance would be a cleaner public API. I'm curious why you think the other approach looks more concise, though.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445706825", "createdAt": "2020-06-25T17:02:33Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE4MTMyNQ==", "bodyText": "The inheritance version is here.\n\nI'm curious why you think the other approach looks more concise, though.\n\nBecause the inheritance version will need to expose the buildReader and buildWriter logic , for example this. If we change those logic, will also need to change in flink reader/writers. seems the same logic with the GenericParquetReader.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446181325", "createdAt": "2020-06-26T13:24:19Z", "author": {"login": "openinx"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwNDI4Ng==", "bodyText": "Okay, how about inheriting from the outer class, then? That way, the interface and the method that accepts the factory could be protected. Mainly, I don't think these should be public.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446304286", "createdAt": "2020-06-26T17:03:10Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDEwMDExOnYy", "diffSide": "RIGHT", "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyNzoyMlrOGn-72A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNTowNTozMlrOGo_C1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODc3Ng==", "bodyText": "Why change this to use the GenericRecord instance rather than the Record interface?\nI don't see much value in this change. We will just need to change it back if we want to add implementations of Record that are not generic, like we do with our internal classes that extend Avro's IndexedRecord. Ideally, I'd like to change those over to use our generics readers eventually.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444578776", "createdAt": "2020-06-24T00:27:22Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java", "diffHunk": "@@ -396,7 +409,12 @@ private FixedReader(ColumnDescriptor desc) {\n     }\n   }\n \n-  static class RecordReader extends StructReader<Record, Record> {\n+  public interface StructReaderFactory<T> {\n+\n+    StructReader<T, T> create(List<Type> types, List<ParquetValueReader<?>> readers, StructType struct);\n+  }\n+\n+  static class RecordReader extends StructReader<GenericRecord, GenericRecord> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYyOTE0MQ==", "bodyText": "I changed this because the buildReader method return the GenericRecord ParquetValueReader. Seems better to change the ParquetValueReader to be Record reader.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445629141", "createdAt": "2020-06-25T15:05:32Z", "author": {"login": "openinx"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java", "diffHunk": "@@ -396,7 +409,12 @@ private FixedReader(ColumnDescriptor desc) {\n     }\n   }\n \n-  static class RecordReader extends StructReader<Record, Record> {\n+  public interface StructReaderFactory<T> {\n+\n+    StructReader<T, T> create(List<Type> types, List<ParquetValueReader<?>> readers, StructType struct);\n+  }\n+\n+  static class RecordReader extends StructReader<GenericRecord, GenericRecord> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODc3Ng=="}, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDEwMzYwOnYy", "diffSide": "RIGHT", "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyOTo0NlrOGn--PQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyOTo0NlrOGn--PQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3OTM4OQ==", "bodyText": "Similar to the write path, I think it would be nice to refactor this to avoid exposing new public methods and interfaces.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444579389", "createdAt": "2020-06-24T00:29:46Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java", "diffHunk": "@@ -396,7 +409,12 @@ private FixedReader(ColumnDescriptor desc) {\n     }\n   }\n \n-  static class RecordReader extends StructReader<Record, Record> {\n+  public interface StructReaderFactory<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3NjY4MDQ5OnYy", "diffSide": "RIGHT", "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNToxMjowN1rOGo_VKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQyMzoyMjoyMlrOGpO_Jg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYzMzgzNA==", "bodyText": "I tried to mark this method to be protected but seems java8 don't allow to do that....", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445633834", "createdAt": "2020-06-25T15:12:07Z", "author": {"login": "openinx"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +290,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {\n+\n+    StructWriter<?> create(List<ParquetValueWriter<?>> writers);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg5MDM0Mg==", "bodyText": "Interface methods are always public.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445890342", "createdAt": "2020-06-25T23:22:22Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +290,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {\n+\n+    StructWriter<?> create(List<ParquetValueWriter<?>> writers);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYzMzgzNA=="}, "originalCommit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MDg2MjUxOnYy", "diffSide": "RIGHT", "path": "data/src/test/java/org/apache/iceberg/data/RandomGenericData.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowNTowN1rOGpoTrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowNTowN1rOGpoTrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwNTE5OA==", "bodyText": "How about RandomRecordGenerator instead of RandomRecordDataGenerator? I think that's more descriptive since it returns random records.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446305198", "createdAt": "2020-06-26T17:05:07Z", "author": {"login": "rdblue"}, "path": "data/src/test/java/org/apache/iceberg/data/RandomGenericData.java", "diffHunk": "@@ -55,11 +55,9 @@ private RandomGenericData() {}\n     return records;\n   }\n \n-  private static class RandomDataGenerator extends TypeUtil.CustomOrderSchemaVisitor<Object> {\n-    private final Random random;\n-\n-    private RandomDataGenerator(long seed) {\n-      this.random = new Random(seed);\n+  private static class RandomRecordDataGenerator extends RandomDataGenerator<Record> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MDg3MjkzOnYy", "diffSide": "RIGHT", "path": "flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowODo1MFrOGpoaZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowODo1MFrOGpoaZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwNjkxNg==", "bodyText": "Good to know that this passes, but I don't think we need to run with this high of a record count every time in CI. Could you reduce this to 20_000?", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446306916", "createdAt": "2020-06-26T17:08:50Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.parquet.Parquet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestFlinkParquetReaderWriter {\n+  private static final int NUM_RECORDS = 1_000_000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4Mjk0NDEzOnYy", "diffSide": "RIGHT", "path": "flink/src/main/java/org/apache/iceberg/flink/data/FlinkParquetReaders.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwMjo0NjowNlrOGp50Cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwMjo0NjowNlrOGp50Cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU5MjAxMA==", "bodyText": "I changed the buildReader to buildRowReader  because the parent buildReader will return with a ParquetValueReader <Record> data type, which clashes with this FlinkParquetReaders 's buildReader returned ParquetValueReader <Row>.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446592010", "createdAt": "2020-06-28T02:46:06Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/data/FlinkParquetReaders.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.parquet.GenericParquetReaders;\n+import org.apache.iceberg.parquet.ParquetSchemaUtil;\n+import org.apache.iceberg.parquet.ParquetValueReader;\n+import org.apache.iceberg.parquet.ParquetValueReaders;\n+import org.apache.iceberg.parquet.TypeWithSchemaVisitor;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Type;\n+\n+public class FlinkParquetReaders extends GenericParquetReaders {\n+  private FlinkParquetReaders() {\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  public static ParquetValueReader<Row> buildRowReader(Schema expectedSchema,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bffceda9758076f67236011d4ba4e560b92590c"}, "originalPosition": 41}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3907, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}