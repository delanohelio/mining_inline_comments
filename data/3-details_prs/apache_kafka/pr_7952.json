{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYyMzczMjI0", "number": 7952, "title": "KAFKA-9418: Add new sendOffsetsToTransaction API to KafkaProducer", "bodyText": "As title suggests, the change is bringing in the consumer group metadata as part of the transaction API for correct fencing after 447.\nThis PR mainly changes on the Producer end for compatible paths to old sendOffsetsToTxn(offsets, groupId) vs new sendOffsetsToTxn(offsets, groupMetadata).\nSome integration test extensions are also added to test out the validity of the new sendOffsets API.\nThis PR also contains some fixes towards the closed protocol PR.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-01-13T23:32:18Z", "url": "https://github.com/apache/kafka/pull/7952", "merged": true, "mergeCommit": {"oid": "de90175fc24357e20306c5a4de4f0f8ec8675ad2"}, "closed": true, "closedAt": "2020-01-22T21:48:37Z", "author": {"login": "abbccdda"}, "timelineItems": {"totalCount": 48, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb6Ym3zgBqjI5NDg4Mzc1MjQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb86WxSgFqTM0NjgxOTkwNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQyOTc2ODU3", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-342976857", "createdAt": "2020-01-15T03:53:53Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1Mzo1M1rOFdsviA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1Mzo1M1rOFdsviA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4NjA4OA==", "bodyText": "Addressing: #7897 (comment)", "url": "https://github.com/apache/kafka/pull/7952#discussion_r366686088", "createdAt": "2020-01-15T03:53:53Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/message/MessageTest.java", "diffHunk": "@@ -431,11 +431,11 @@ public void testTxnOffsetCommitRequestVersions() throws Exception {\n \n             if (version < 3) {\n                 final short finalVersion = version;\n-                assertThrows(UnsupportedVersionException.class, () -> testAllMessageRoundTripsFromVersion(finalVersion, requestData));\n+                assertThrows(UnsupportedVersionException.class, () -> testEquivalentMessageRoundTrip(finalVersion, requestData));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQyOTc3MDA3", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-342977007", "createdAt": "2020-01-15T03:54:37Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1NDozN1rOFdsv_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1NDozN1rOFdsv_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4NjIwNA==", "bodyText": "Addressing #7897 (comment)", "url": "https://github.com/apache/kafka/pull/7952#discussion_r366686204", "createdAt": "2020-01-15T03:54:37Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "diffHunk": "@@ -2489,16 +2489,20 @@ class GroupCoordinatorTest {\n     val rebalanceResult = staticMembersJoinAndRebalance(leaderInstanceId, followerInstanceId)\n \n     val leaderNoMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n-      Map(tp -> offset), groupInstanceId = leaderInstanceId)\n+      Map(tp -> offset), memberId = JoinGroupRequest.UNKNOWN_MEMBER_ID, groupInstanceId = leaderInstanceId)\n     assertEquals(Errors.FENCED_INSTANCE_ID, leaderNoMemberIdCommitOffsetResult (tp))\n \n+    val leaderInvalidMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQyOTc3MTEy", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-342977112", "createdAt": "2020-01-15T03:55:10Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1NToxMFrOFdswVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1NToxMFrOFdswVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4NjI5Mw==", "bodyText": "This and the following new tests are addressing the comments for separating valid and invalid scenario: #7897 (comment)", "url": "https://github.com/apache/kafka/pull/7952#discussion_r366686293", "createdAt": "2020-01-15T03:55:10Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "diffHunk": "@@ -2489,16 +2489,20 @@ class GroupCoordinatorTest {\n     val rebalanceResult = staticMembersJoinAndRebalance(leaderInstanceId, followerInstanceId)\n \n     val leaderNoMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n-      Map(tp -> offset), groupInstanceId = leaderInstanceId)\n+      Map(tp -> offset), memberId = JoinGroupRequest.UNKNOWN_MEMBER_ID, groupInstanceId = leaderInstanceId)\n     assertEquals(Errors.FENCED_INSTANCE_ID, leaderNoMemberIdCommitOffsetResult (tp))\n \n+    val leaderInvalidMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n+      Map(tp -> offset), memberId = \"invalid-member\", groupInstanceId = leaderInstanceId)\n+    assertEquals(Errors.FENCED_INSTANCE_ID, leaderInvalidMemberIdCommitOffsetResult (tp))\n+\n     val leaderCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n       Map(tp -> offset), rebalanceResult.leaderId, leaderInstanceId)\n     assertEquals(Errors.NONE, leaderCommitOffsetResult (tp))\n   }\n \n   @Test\n-  def testTxnCommitOffsetWithUnknownMemberId(): Unit = {\n+  def testTxnCommitOffsetWithInvalidMemberId(): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTc2MzMy", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343576332", "createdAt": "2020-01-15T22:52:00Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1MjowMFrOFeJCKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1MjowMFrOFeJCKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ==", "bodyText": "We will throw IllegalStateException if unexpected group fencing exception was thrown for old API", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367149611", "createdAt": "2020-01-15T22:52:00Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1497,15 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (isGroupFencingException(error)) {\n+                    if (enableGroupFencing) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 136}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTc3MTE2", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343577116", "createdAt": "2020-01-15T22:53:42Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1Mzo0MlrOFeJEbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1Mzo0MlrOFeJEbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MDE5MQ==", "bodyText": "We unify the API for groupId and groupMetadata commit here, which includes the groupId within the metadata struct.\nA boolean flag indicating whether to turn on global fencing shall be passed down to the txn commit sender to determine whether we should include (member.id, instance.id, generation.id) in the request.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367150191", "createdAt": "2020-01-15T22:53:42Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -329,17 +329,18 @@ private TransactionalRequestResult beginCompletingTransaction(TransactionResult\n     }\n \n     public synchronized TransactionalRequestResult sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTc3NDUw", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343577450", "createdAt": "2020-01-15T22:54:29Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NDozMFrOFeJFdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NDozMFrOFeJFdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MDQ1Mg==", "bodyText": "This separation is to avoid if-else loop complexity warning from checkstyle.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367150452", "createdAt": "2020-01-15T22:54:30Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1524,16 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isGroupFencingException(Errors error) {\n+        return error == Errors.FENCED_INSTANCE_ID\n+                   || error == Errors.UNKNOWN_MEMBER_ID\n+                   || error == Errors.ILLEGAL_GENERATION;\n+    }\n+\n+    private boolean isFatalException(Errors error) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 158}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTc3NzA5", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343577709", "createdAt": "2020-01-15T22:55:07Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NTowN1rOFeJGNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NTowN1rOFeJGNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MDY0NQ==", "bodyText": "When working with the multi-version API, I realized that by making the data initialization internal could save a lot of caller's effort.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367150645", "createdAt": "2020-01-15T22:55:07Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "diffHunk": "@@ -45,9 +45,39 @@\n \n         public final TxnOffsetCommitRequestData data;\n \n-        public Builder(TxnOffsetCommitRequestData data) {\n+        public Builder(final String transactionalId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTc4Mzcw", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343578370", "createdAt": "2020-01-15T22:56:36Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NjozN1rOFeJIPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NjozN1rOFeJIPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTE2NA==", "bodyText": "The test coverage for KafkaProducerTest is weak in general. We just did the bare minimum here to route the request through a full init->begin->commit->end workflow and make sure it is working properly.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367151164", "createdAt": "2020-01-15T22:56:37Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -689,6 +698,90 @@ public void testInitTransactionWhileThrottled() {\n         }\n     }\n \n+    @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTc5MTMz", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343579133", "createdAt": "2020-01-15T22:58:19Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1ODoyMFrOFeJKsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1ODoyMFrOFeJKsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg==", "bodyText": "The purpose of this cachedGroupMetadata is to avoid the creation of groupMetadata everytime we call the old API. It could also be served as a security check on whether the consumer group id has changed in the middle by sending out a warning indicating some illegal state. In Streams or other general EOS use cases, this should never happen.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367151792", "createdAt": "2020-01-15T22:58:20Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 78}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTc5NDI2", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343579426", "createdAt": "2020-01-15T22:58:58Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1ODo1OVrOFeJLqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1ODo1OVrOFeJLqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MjA0Mg==", "bodyText": "This is just leveraging the same security check here, no harm to do for both API calls.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367152042", "createdAt": "2020-01-15T22:58:59Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone\n+     * mode EOS applications are still relying on it. If the broker version is lower than 2.5.0 which doesn't support the new underlying protocol,\n+     * this API call will throw UnsupportedVersionException.\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.common.errors.IllegalGenerationException if the passed in consumer metadata has illegal generation\n+     * @throws org.apache.kafka.common.errors.UnknownMemberIdException if the passed in consumer metadata has unknown member.id\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,\n+               IllegalGenerationException,\n+               UnknownMemberIdException,\n+               FencedInstanceIdException {\n+        if (!cachedGroupMetadata.groupId().equals(groupMetadata.groupId())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 127}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTg0OTA1", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343584905", "createdAt": "2020-01-15T23:13:11Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoxMzoxMVrOFeJdIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoxMzoxMVrOFeJdIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1NjUxMw==", "bodyText": "The 3 tests here are primarily evaluating that when we are on groupMetadata mode, we could correctly detect FENCED_INSTANCE_ID, UNKNOWN_MEMBER_ID and ILLEGAL_GENERATION exceptions.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367156513", "createdAt": "2020-01-15T23:13:11Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -940,6 +948,204 @@ public void testUnsupportedForMessageFormatInTxnOffsetCommit() {\n         assertFatalError(UnsupportedForMessageFormatException.class);\n     }\n \n+    @Test\n+    public void testFencedInstanceIdInTxnOffsetCommitByGroupMetadata() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 47}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTg2MzA3", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343586307", "createdAt": "2020-01-15T23:16:45Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoyMDo0OFrOFeJl9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoyMTozMlrOFeJmyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODc3NA==", "bodyText": "A full test to set all 3 group fields", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367158774", "createdAt": "2020-01-15T23:20:48Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -2157,6 +2397,56 @@ public void shouldFailAbortIfAddOffsetsFailsWithFatalError() {\n         assertTrue(transactionManager.hasFatalError());\n     }\n \n+    @Test\n+    public void testSendOffsetsWithGroupMetadata() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 358}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODkzNg==", "bodyText": "Use new API for compatibility test.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367158936", "createdAt": "2020-01-15T23:21:24Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/TransactionsBounceTest.scala", "diffHunk": "@@ -71,7 +73,19 @@ class TransactionsBounceTest extends KafkaServerTestHarness {\n   }\n \n   @Test\n-  def testBrokerFailure(): Unit = {\n+  def testWithGroupId(): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODk4Ng==", "bodyText": "Same here for compatibility.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367158986", "createdAt": "2020-01-15T23:21:32Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/TransactionsTest.scala", "diffHunk": "@@ -227,7 +227,20 @@ class TransactionsTest extends KafkaServerTestHarness {\n   }\n \n   @Test\n-  def testSendOffsets() = {\n+  def testSendOffsetsWithGroupId() = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNjgyNDQy", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-343682442", "createdAt": "2020-01-16T05:38:29Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwNTozODoyOVrOFeOerA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODoyNjo0M1rOFejNfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIzODgyOA==", "bodyText": "Not from this patch, but this should be private.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367238828", "createdAt": "2020-01-16T05:38:29Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -28,7 +28,10 @@\n     final private String memberId;\n     final Optional<String> groupInstanceId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIzOTgzMQ==", "bodyText": "Hmm, this feels like premature optimization. The offsets map is more likely to be a problem. Also, I'm not sure we should restrict the usage. It is possible today to send offsets for multiple groups. Is there a good reason to restrict this even if it doesn't make sense in streams?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367239831", "createdAt": "2020-01-16T05:43:32Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3Mzk3MQ==", "bodyText": "I don't think this comment should be in the javadoc. If we did deprecate the other API, we would just mark the other as deprecated.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367573971", "createdAt": "2020-01-16T18:16:20Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NDY1NA==", "bodyText": "I'm wondering if we should use CommitFailedException. In the consumer, we do not expose illegal generation and unknown member id errors directly to the user.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367574654", "createdAt": "2020-01-16T18:17:53Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone\n+     * mode EOS applications are still relying on it. If the broker version is lower than 2.5.0 which doesn't support the new underlying protocol,\n+     * this API call will throw UnsupportedVersionException.\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.common.errors.IllegalGenerationException if the passed in consumer metadata has illegal generation", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NTk3Mg==", "bodyText": "nit: I think we can do away with enableGroupFencing and derive its value from ConsumerGroupMetadata. In spite of my comment on the previous PR, it may be simpler to just let the defaults be consistent with the expected default values and just have one path below.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367575972", "createdAt": "2020-01-16T18:20:52Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NjQwMQ==", "bodyText": "nit: this definition looks really awkward", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367576401", "createdAt": "2020-01-16T18:21:50Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +176,15 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException,\n+                                                                                     IllegalGenerationException,\n+                                                                                     UnknownMemberIdException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3ODQ5NQ==", "bodyText": "I think this check is overkill.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367578495", "createdAt": "2020-01-16T18:26:43Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1497,15 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (isGroupFencingException(error)) {\n+                    if (enableGroupFencing) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ=="}, "originalCommit": null, "originalPosition": 136}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0MTMxMDgy", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-344131082", "createdAt": "2020-01-16T18:40:48Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODo0MDo0OVrOFejmZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODo1MTo0NFrOFej6Dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NDg3MA==", "bodyText": "nit: if you want a new paragraph you need to add <p>", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367584870", "createdAt": "2020-01-16T18:40:49Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4Njg3OQ==", "bodyText": "ConsumerGroupMetadata does not have a proper toString() implementation -- if we want to log the object, we should add ConsumerGroupMetadata#toString() to ensure a readable log message.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367586879", "createdAt": "2020-01-16T18:45:25Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -329,17 +329,18 @@ private TransactionalRequestResult beginCompletingTransaction(TransactionResult\n     }\n \n     public synchronized TransactionalRequestResult sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                                            String consumerGroupId) {\n+                                                                            final ConsumerGroupMetadata groupMetadata,\n+                                                                            final boolean enableGroupFencing) {\n         ensureTransactional();\n         maybeFailWithError();\n         if (currentState != State.IN_TRANSACTION)\n             throw new KafkaException(\"Cannot send offsets to transaction either because the producer is not in an \" +\n                     \"active transaction\");\n \n-        log.debug(\"Begin adding offsets {} for consumer group {} to transaction\", offsets, consumerGroupId);\n+        log.debug(\"Begin adding offsets {} for consumer group {} to transaction\", offsets, groupMetadata);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NzMxOQ==", "bodyText": "nit: avoid double spaces", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367587319", "createdAt": "2020-01-16T18:46:17Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {\n         for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {\n             OffsetAndMetadata offsetAndMetadata = entry.getValue();\n             CommittedOffset committedOffset = new CommittedOffset(offsetAndMetadata.offset(),\n                     offsetAndMetadata.metadata(), offsetAndMetadata.leaderEpoch());\n             pendingTxnOffsetCommits.put(entry.getKey(), committedOffset);\n         }\n-        TxnOffsetCommitRequest.Builder builder = new TxnOffsetCommitRequest.Builder(\n-            new TxnOffsetCommitRequestData()\n-                .setTransactionalId(transactionalId)\n-                .setGroupId(consumerGroupId)\n-                .setProducerId(producerIdAndEpoch.producerId)\n-                .setProducerEpoch(producerIdAndEpoch.epoch)\n-                .setTopics(TxnOffsetCommitRequest.getTopics(pendingTxnOffsetCommits))\n-        );\n-        return new TxnOffsetCommitHandler(result, builder);\n+\n+        final  TxnOffsetCommitRequest.Builder builder;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4OTkwMw==", "bodyText": "Why this change? Should sendOffsetsToTransaction not be able to handle null gracefully? Seems it would be a regression if we change the behavior and start to fail on null?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367589903", "createdAt": "2020-01-16T18:51:44Z", "author": {"login": "mjsax"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -152,15 +151,15 @@ public void shouldBeginTransactions() {\n     @Test(expected = IllegalStateException.class)\n     public void shouldThrowOnSendOffsetsToTransactionIfTransactionsNotInitialized() {\n         buildMockProducer(true);\n-        producer.sendOffsetsToTransaction(null, null);\n+        producer.sendOffsetsToTransaction(null, \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0MTU2NDM5", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-344156439", "createdAt": "2020-01-16T19:22:23Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxOToyMjoyM1rOFekx2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQyMDoxNDo1MFrOFemNpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYwNDE4Nw==", "bodyText": "I also feel it may be overkill to cache the cachedGroupMetadata on the producer side -- is it part of the reasons violating ClassFanOutComplexity and ClassDataAbstractionCoupling?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367604187", "createdAt": "2020-01-16T19:22:23Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYwNjk0OA==", "bodyText": "nit: The first param offsets can be final as well.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367606948", "createdAt": "2020-01-16T19:28:29Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -329,17 +329,18 @@ private TransactionalRequestResult beginCompletingTransaction(TransactionResult\n     }\n \n     public synchronized TransactionalRequestResult sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                                            String consumerGroupId) {\n+                                                                            final ConsumerGroupMetadata groupMetadata,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYwNzUyOA==", "bodyText": "How do we distinguish with the case where only groupId is passed, v.s. the whole groupMetadata is passed but other fields are UNKNOWN_XXX? Do we guarantee that groupMetadata#generationId should never be UNKNOWN_GENERATION_ID (from the broker-side logic we would not check if the generationId < 0)? If yes then we can use that as the boolean flag and get rid of enableGroupFencing.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367607528", "createdAt": "2020-01-16T19:29:46Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NTk3Mg=="}, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyNzY4NA==", "bodyText": "See my other comment: it seems we initialize generationId / memberId as UNKNOWN anyways, which means that if enableFencing is false it would stay as UNKNOWN_XX and the broker would not check its generationId or memberId, so it seem we can get rid of the boolean flag indeed since if only groupId is passed in, the other fields' default value is sufficient to bypass the fencing.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367627684", "createdAt": "2020-01-16T20:14:50Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "diffHunk": "@@ -45,9 +45,39 @@\n \n         public final TxnOffsetCommitRequestData data;\n \n-        public Builder(TxnOffsetCommitRequestData data) {\n+        public Builder(final String transactionalId,\n+                       final String consumerGroupId,\n+                       final long producerId,\n+                       final short producerEpoch,\n+                       final Map<TopicPartition, CommittedOffset> pendingTxnOffsetCommits) {\n+            this(transactionalId,\n+                consumerGroupId,\n+                producerId,\n+                producerEpoch,\n+                pendingTxnOffsetCommits,\n+                JoinGroupRequest.UNKNOWN_MEMBER_ID,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0Mzc1MDk5", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-344375099", "createdAt": "2020-01-17T05:51:59Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNTo1MTo1OVrOFevcVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNTo1MTo1OVrOFevcVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc3ODkwMA==", "bodyText": "Test changes in this class are only for new API coverage.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367778900", "createdAt": "2020-01-17T05:51:59Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -16,14 +16,15 @@\n  */\n package org.apache.kafka.clients.producer;\n \n+import org.apache.kafka.clients.consumer.ConsumerGroupMetadata;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0Mzc2MDAx", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-344376001", "createdAt": "2020-01-17T05:55:53Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNTo1NTo1M1rOFevfNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNTo1NTo1M1rOFevfNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc3OTYzOA==", "bodyText": "After some thoughts, I feel hesitated to classify the FencedInstanceId as a sub type of CommitFailed, for producer exception handling we should abort the current transaction and let consumer rejoin the group as needed. For instanceId fenced, it is more fatal as an indicator of a malicious client that should fail the entire client. Like @hachikuji proposed, it makes sense for us to specify new EOS example code once the changes are merged so that we could make sure the API is user friendly: https://issues.apache.org/jira/browse/KAFKA-9447", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367779638", "createdAt": "2020-01-17T05:55:53Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 91}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0OTI1ODI0", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-344925824", "createdAt": "2020-01-18T05:04:32Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNTowNDozMlrOFfJkHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToyMTo0OVrOFfJmvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNjg3OA==", "bodyText": "I guess we could also get an auth error for the groupId.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368206878", "createdAt": "2020-01-18T05:04:32Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzEyMA==", "bodyText": "More of a meta comment, but after this  patch, it would be possible for users to use ephemeral transactional Ids since we can rely on the group coordinator fencing. One of the potential follow-ups is to figure out how to make this work from a security perspective. For example, we could piggyback on Group write permission to enforce access.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207120", "createdAt": "2020-01-18T05:10:20Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,11 +625,13 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzI2Ng==", "bodyText": "How about this?\n\n... if the commit failed and cannot be retried (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207266", "createdAt": "2020-01-18T05:14:02Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzI4Mw==", "bodyText": "It seems like we don't need to mention 0.11 here since the requirement for 2.5 is stricter.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207283", "createdAt": "2020-01-18T05:15:04Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzM1Mg==", "bodyText": "Not really sure why we need this method. Why not move the body into the sendOffsetsToTransaction with the same arguments?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207352", "createdAt": "2020-01-18T05:16:30Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,\n+               CommitFailedException,\n+               FencedInstanceIdException {\n+        sendOffsetsToTransactionInternal(offsets, groupMetadata);\n+    }\n+\n+    private void sendOffsetsToTransactionInternal(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata consumerGroupMetadata) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzM4Nw==", "bodyText": "nit: as mentioned elsewhere, I don't think we need to add all of these exceptions to the method. They are all runtime exceptions, so it's still up to the user to read the docs.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207387", "createdAt": "2020-01-18T05:17:50Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzQ3NQ==", "bodyText": "nit: we may as well spell out \"Transaction.\" Also, we should probably add :  before the message.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207475", "createdAt": "2020-01-18T05:20:00Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1482,11 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (error == Errors.UNKNOWN_MEMBER_ID\n+                        || error == Errors.ILLEGAL_GENERATION) {\n+                    abortableError(new CommitFailedException(\"Txn offset Commit failed due to consumer group metadata mismatch\" + error.exception().getMessage()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ==", "bodyText": "I still don't think this should be a fatal error for the producer. As long as we can still abort the transaction, it should be an abortable error. It's similar to the handling of GROUP_AUTHORIZATION_FAILED.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207549", "createdAt": "2020-01-18T05:21:49Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 124}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0OTc0NTA4", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-344974508", "createdAt": "2020-01-19T03:29:25Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwMzoyOToyNVrOFfM--g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwMzo0NToyMVrOFfNBEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MjkwNg==", "bodyText": "Why we still have other exceptions declared while in KafkaProducer only ProducerFenced is declared?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368262906", "createdAt": "2020-01-19T03:29:25Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/Producer.java", "diffHunk": "@@ -53,6 +57,15 @@\n     void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                   String consumerGroupId) throws ProducerFencedException;\n \n+    /**\n+     * See {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata)}\n+     */\n+    void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                  ConsumerGroupMetadata groupMetadata) throws ProducerFencedException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MzI5NQ==", "bodyText": "Where is this function defined?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368263295", "createdAt": "2020-01-19T03:40:33Z", "author": {"login": "guozhangwang"}, "path": "core/src/test/scala/integration/kafka/api/TransactionsBounceTest.scala", "diffHunk": "@@ -103,7 +117,7 @@ class TransactionsBounceTest extends KafkaServerTestHarness {\n             !shouldAbort), new ErrorLoggingCallback(outputTopic, record.key, record.value, true))\n         }\n         trace(s\"Sent ${records.size} messages. Committing offsets.\")\n-        producer.sendOffsetsToTransaction(TestUtils.consumerPositions(consumer).asJava, consumerGroup)\n+        commit(producer, consumerGroup, consumer)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MzQ0MA==", "bodyText": "Should we make fenced_instance_id non-fatal as well?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368263440", "createdAt": "2020-01-19T03:45:21Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, "originalCommit": null, "originalPosition": 124}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ1MDE4OTgw", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-345018980", "createdAt": "2020-01-19T18:49:40Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQxODo0OTo0MFrOFfQFJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQxOTowNDoxNFrOFfQIgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzYzOA==", "bodyText": "It's not really valid to commit offsets with a null groupId. Why don't we use requireNonNull?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313638", "createdAt": "2020-01-19T18:49:40Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +173,13 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {\n+        String groupId = groupMetadata != null ? groupMetadata.groupId() : null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzY0Nw==", "bodyText": "Might be worth adding a null check here for groupMetadata. Another simple validation is ensuring that if generationId > 0, then memberId should be non-empty.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313647", "createdAt": "2020-01-19T18:49:44Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,22 +623,60 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,\n+     *                               or encounters unexpected group fencing exception which should only be returned from\n+     *                               new {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata) sendOffsets}.\n      * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n      * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n      *         does not support transactions (i.e. if its version is lower than 0.11.0.0)\n-     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException  fatal error indicating the message\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n      *         format used for the offsets topic on the broker does not support transactions\n      * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n-     *         transactional.id is not authorized. See the exception for more details\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n      * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n      *         other unexpected error\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransaction(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException  if the commit failed and cannot be retried\n+     *         (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzc2Mg==", "bodyText": "Might be nice to have an overload which sets only groupId.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313762", "createdAt": "2020-01-19T18:51:38Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -26,9 +26,12 @@\n     final private String groupId;\n     final private int generationId;\n     final private String memberId;\n-    final Optional<String> groupInstanceId;\n+    final private Optional<String> groupInstanceId;\n \n-    public ConsumerGroupMetadata(String groupId, int generationId, String memberId, Optional<String> groupInstanceId) {\n+    public ConsumerGroupMetadata(String groupId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzk2OA==", "bodyText": "I think there's probably a good case to raise this one directly as an abortable error instead of getting wrapped in CommitFailedException. Although it is not fatal for the producer, the user shouldn't ignore it.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313968", "createdAt": "2020-01-19T18:55:52Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,16 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isGroupMetadataMisMatch(Errors error) {\n+        return error == Errors.FENCED_INSTANCE_ID", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDIwNQ==", "bodyText": "To ensure that we are really testing the state machine as expected, we should provide a valid groupId. Similarly below.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368314205", "createdAt": "2020-01-19T19:00:04Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -152,15 +154,17 @@ public void shouldBeginTransactions() {\n     @Test(expected = IllegalStateException.class)\n     public void shouldThrowOnSendOffsetsToTransactionIfTransactionsNotInitialized() {\n         buildMockProducer(true);\n-        producer.sendOffsetsToTransaction(null, null);\n+        String groupId = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDMzNQ==", "bodyText": "These test cases seem to be identical code other than the error. Can we factor out a helper?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368314335", "createdAt": "2020-01-19T19:01:42Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -940,6 +946,134 @@ public void testUnsupportedForMessageFormatInTxnOffsetCommit() {\n         assertFatalError(UnsupportedForMessageFormatException.class);\n     }\n \n+    @Test\n+    public void testFencedInstanceIdInTxnOffsetCommitByGroupMetadata() {\n+        final String consumerGroupId = \"consumer\";\n+        final long pid = 13131L;\n+        final short epoch = 1;\n+        final TopicPartition tp = new TopicPartition(\"foo\", 0);\n+        final String memberId = \"member\";\n+        final String fencedMemberId = \"fenced_member\";\n+        final String instanceId = \"instance\";\n+\n+        doInitTransactions(pid, epoch);\n+\n+        transactionManager.beginTransaction();\n+\n+        TransactionalRequestResult sendOffsetsResult = transactionManager.sendOffsetsToTransaction(\n+            singletonMap(tp, new OffsetAndMetadata(39L)),\n+            new ConsumerGroupMetadata(consumerGroupId, 5, fencedMemberId, Optional.of(instanceId)));\n+\n+        prepareAddOffsetsToTxnResponse(Errors.NONE, consumerGroupId, pid, epoch);\n+        sender.runOnce();  // AddOffsetsToTxn Handled, TxnOffsetCommit Enqueued\n+        sender.runOnce();  // FindCoordinator Enqueued\n+\n+        prepareFindCoordinatorResponse(Errors.NONE, false, CoordinatorType.GROUP, consumerGroupId);\n+        sender.runOnce();  // FindCoordinator Returned\n+\n+        client.prepareResponse(request -> {\n+            TxnOffsetCommitRequest txnOffsetCommitRequest = (TxnOffsetCommitRequest) request;\n+            assertEquals(consumerGroupId, txnOffsetCommitRequest.data.groupId());\n+            assertEquals(pid, txnOffsetCommitRequest.data.producerId());\n+            assertEquals(epoch, txnOffsetCommitRequest.data.producerEpoch());\n+            return txnOffsetCommitRequest.data.groupInstanceId().equals(instanceId)\n+                && !txnOffsetCommitRequest.data.memberId().equals(memberId);\n+        }, new TxnOffsetCommitResponse(0, singletonMap(tp, Errors.FENCED_INSTANCE_ID)));\n+\n+        sender.runOnce();  // TxnOffsetCommit Handled\n+\n+        assertTrue(transactionManager.hasError());\n+        assertTrue(transactionManager.lastError() instanceof CommitFailedException);\n+        assertTrue(sendOffsetsResult.isCompleted());\n+        assertFalse(sendOffsetsResult.isSuccessful());\n+        assertTrue(sendOffsetsResult.error() instanceof CommitFailedException);\n+        assertAbortableError(CommitFailedException.class);\n+    }\n+\n+    @Test\n+    public void testUnknownMemberIdInTxnOffsetCommitByGroupMetadata() {\n+        final String consumerGroupId = \"consumer\";\n+        final long pid = 13131L;\n+        final short epoch = 1;\n+        final TopicPartition tp = new TopicPartition(\"foo\", 0);\n+        final String memberId = \"member\";\n+        final String unknownMemberId = \"unknownMember\";\n+\n+        doInitTransactions(pid, epoch);\n+\n+        transactionManager.beginTransaction();\n+\n+        TransactionalRequestResult sendOffsetsResult = transactionManager.sendOffsetsToTransaction(\n+            singletonMap(tp, new OffsetAndMetadata(39L)),\n+            new ConsumerGroupMetadata(consumerGroupId, 5, unknownMemberId, Optional.empty()));\n+\n+        prepareAddOffsetsToTxnResponse(Errors.NONE, consumerGroupId, pid, epoch);\n+        sender.runOnce();  // AddOffsetsToTxn Handled, TxnOffsetCommit Enqueued\n+        sender.runOnce();  // FindCoordinator Enqueued\n+\n+        prepareFindCoordinatorResponse(Errors.NONE, false, CoordinatorType.GROUP, consumerGroupId);\n+        sender.runOnce();  // FindCoordinator Returned\n+\n+        client.prepareResponse(request -> {\n+            TxnOffsetCommitRequest txnOffsetCommitRequest = (TxnOffsetCommitRequest) request;\n+            assertEquals(consumerGroupId, txnOffsetCommitRequest.data.groupId());\n+            assertEquals(pid, txnOffsetCommitRequest.data.producerId());\n+            assertEquals(epoch, txnOffsetCommitRequest.data.producerEpoch());\n+            return !txnOffsetCommitRequest.data.memberId().equals(memberId);\n+        }, new TxnOffsetCommitResponse(0, singletonMap(tp, Errors.UNKNOWN_MEMBER_ID)));\n+        sender.runOnce();  // TxnOffsetCommit Handled\n+\n+        assertTrue(transactionManager.hasError());\n+        assertTrue(transactionManager.lastError() instanceof CommitFailedException);\n+        assertTrue(sendOffsetsResult.isCompleted());\n+        assertFalse(sendOffsetsResult.isSuccessful());\n+        assertTrue(sendOffsetsResult.error() instanceof CommitFailedException);\n+        assertAbortableError(CommitFailedException.class);\n+    }\n+\n+    @Test\n+    public void testIllegalGenerationInTxnOffsetCommitByGroupMetadata() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDQ5OA==", "bodyText": "Seems this test case would be more interesting if we tried to commit a separate set of offsets before aborting", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368314498", "createdAt": "2020-01-19T19:04:14Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -568,6 +638,31 @@ public void shouldPreserveCommittedConsumerGroupsOffsetsOnAbortIfTransactionsAre\n         assertThat(producer.consumerGroupOffsetsHistory(), equalTo(Collections.singletonList(expectedResult)));\n     }\n \n+    @Test\n+    public void shouldPreserveOffsetsFromCommitByGroupMetadataOnAbortIfTransactionsAreEnabled() {\n+        buildMockProducer(true);\n+        producer.initTransactions();\n+        producer.beginTransaction();\n+\n+        String group = \"g\";\n+        Map<TopicPartition, OffsetAndMetadata> groupCommit = new HashMap<TopicPartition, OffsetAndMetadata>() {\n+            {\n+                put(new TopicPartition(topic, 0), new OffsetAndMetadata(42L, null));\n+                put(new TopicPartition(topic, 1), new OffsetAndMetadata(73L, null));\n+            }\n+        };\n+        producer.sendOffsetsToTransaction(groupCommit, groupMetadata(group));\n+        producer.commitTransaction();\n+\n+        producer.beginTransaction();\n+        producer.abortTransaction();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 218}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e2486ce7d1650613e88aca761a556635084a8e1", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/4e2486ce7d1650613e88aca761a556635084a8e1", "committedDate": "2020-01-21T23:23:19Z", "message": "Revert \"revert client side changes\"\n\nThis reverts commit 437f8456983ba6234644c62a5cbfee5e77814cfb."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce8856cd302b9f4cfd05f5601e7552c4b6f933b4", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/ce8856cd302b9f4cfd05f5601e7552c4b6f933b4", "committedDate": "2020-01-21T23:23:19Z", "message": "add producer send offsets"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6770680646eb1309223d7293ee20e3327c3a1894", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/6770680646eb1309223d7293ee20e3327c3a1894", "committedDate": "2020-01-21T23:23:19Z", "message": "style fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eac6fe6f70d35ed320cbef5793ff0448e81e5619", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/eac6fe6f70d35ed320cbef5793ff0448e81e5619", "committedDate": "2020-01-21T23:23:19Z", "message": "address Matthias comments from previous PR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "49b163fc8b2443ad1c0ed9eafc2f1c83a0f60a96", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/49b163fc8b2443ad1c0ed9eafc2f1c83a0f60a96", "committedDate": "2020-01-21T23:23:19Z", "message": "illegal state tests for group related exception"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "850e6602c1eb3457ae5098aaf45cb8e8d8ddcc79", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/850e6602c1eb3457ae5098aaf45cb8e8d8ddcc79", "committedDate": "2020-01-21T23:23:19Z", "message": "hide details about txn commit data creation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2dd1a1dc742f38eb4cfa86fe91ba1fe088a13c40", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/2dd1a1dc742f38eb4cfa86fe91ba1fe088a13c40", "committedDate": "2020-01-21T23:23:19Z", "message": "premilinary producer txn API tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "271014808657ca81816d49f1292bd7fd14dc388c", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/271014808657ca81816d49f1292bd7fd14dc388c", "committedDate": "2020-01-21T23:23:19Z", "message": "txn commit test fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d45fa60572ee931a940f67063d812912e15102e6", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/d45fa60572ee931a940f67063d812912e15102e6", "committedDate": "2020-01-21T23:23:19Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "966c309d4e367300434557bd7b156878d1ffb3af", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/966c309d4e367300434557bd7b156878d1ffb3af", "committedDate": "2020-01-21T23:23:19Z", "message": "address Jason's comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88050c172b89ec1f6c4969988ce2cbb1adcf7089", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/88050c172b89ec1f6c4969988ce2cbb1adcf7089", "committedDate": "2020-01-21T23:23:19Z", "message": "Guozhang's comment for cleanup Producer.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aabe1a5c0f3c5be2d4946aa1b09af66fb2ad5656", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/aabe1a5c0f3c5be2d4946aa1b09af66fb2ad5656", "committedDate": "2020-01-21T23:23:19Z", "message": "address Jason's comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a08d25ecc111385e24d4bcff452a04b81587c525", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/a08d25ecc111385e24d4bcff452a04b81587c525", "committedDate": "2020-01-21T23:23:40Z", "message": "add checks to group metadata"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "a08d25ecc111385e24d4bcff452a04b81587c525", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/a08d25ecc111385e24d4bcff452a04b81587c525", "committedDate": "2020-01-21T23:23:40Z", "message": "add checks to group metadata"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/2706908e3524f76c2ef749d3907815de4360fd8f", "committedDate": "2020-01-22T04:31:02Z", "message": "expose FencedInstanceId exception"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2NzMxMDc0", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-346731074", "createdAt": "2020-01-22T16:35:26Z", "commit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjozNToyN1rOFgi1fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjo1MToyNFrOFgjafg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY2OTUwMw==", "bodyText": "nit: usually we write this like this:\nthis.groupInstanceId = requireNonNull(groupInstanceId, \"group.instance.id can't be null\");", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369669503", "createdAt": "2020-01-22T16:35:27Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -26,15 +29,29 @@\n     final private String groupId;\n     final private int generationId;\n     final private String memberId;\n-    final Optional<String> groupInstanceId;\n+    final private Optional<String> groupInstanceId;\n \n-    public ConsumerGroupMetadata(String groupId, int generationId, String memberId, Optional<String> groupInstanceId) {\n+    public ConsumerGroupMetadata(String groupId,\n+                                 int generationId,\n+                                 String memberId,\n+                                 Optional<String> groupInstanceId) {\n         this.groupId = groupId;\n         this.generationId = generationId;\n+\n+        Objects.requireNonNull(memberId, \"member.id can't be null\");\n         this.memberId = memberId;\n+\n+        Objects.requireNonNull(groupInstanceId, \"group.instance.id can't be null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MTUzNg==", "bodyText": "nit: I don't think there's any reason to mention this. Unexpected errors fall under KafkaException, which is listed below.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369671536", "createdAt": "2020-01-22T16:38:55Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,22 +622,61 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,\n+     *                               or encounters unexpected group fencing exception which should only be returned from", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MjQ1Ng==", "bodyText": "nit: we may as well move this check into ConsumerGroupMetadata since we have some other null checks there.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369672456", "createdAt": "2020-01-22T16:40:26Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -1228,6 +1270,17 @@ private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[]\n                         record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n     }\n \n+    private void throwIfInvalidGroupMetadata(ConsumerGroupMetadata groupMetadata) {\n+        if (groupMetadata == null) {\n+            throw new IllegalStateException(\"Consumer group metadata could not be null\");\n+        } else if (groupMetadata.groupId() == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3Mjc3MQ==", "bodyText": "I think these should all be IllegalArgumentException. The producer is not in an illegal state.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369672771", "createdAt": "2020-01-22T16:40:57Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -1228,6 +1270,17 @@ private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[]\n                         record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n     }\n \n+    private void throwIfInvalidGroupMetadata(ConsumerGroupMetadata groupMetadata) {\n+        if (groupMetadata == null) {\n+            throw new IllegalStateException(\"Consumer group metadata could not be null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3ODk3NA==", "bodyText": "Wait, how did we end up back here? I thought we agreed this should not be fatal for the producer? I think it should have a separate branch above, similar to the handling of GROUP_AUTHORIZATION_FAILED.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369678974", "createdAt": "2020-01-22T16:51:24Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, "originalCommit": null, "originalPosition": 124}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9cf4a2a546625f337c4e2e28da3e6b3a956fa309", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/9cf4a2a546625f337c4e2e28da3e6b3a956fa309", "committedDate": "2020-01-22T17:48:18Z", "message": "final comment"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "9cf4a2a546625f337c4e2e28da3e6b3a956fa309", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/9cf4a2a546625f337c4e2e28da3e6b3a956fa309", "committedDate": "2020-01-22T17:48:18Z", "message": "final comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e81e0daaec396ec5be7cc3d3cc2adae42f242e95", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/e81e0daaec396ec5be7cc3d3cc2adae42f242e95", "committedDate": "2020-01-22T18:43:20Z", "message": "move group.id null check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2ODE5OTA3", "url": "https://github.com/apache/kafka/pull/7952#pullrequestreview-346819907", "createdAt": "2020-01-22T18:49:45Z", "commit": {"oid": "e81e0daaec396ec5be7cc3d3cc2adae42f242e95"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1985, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}