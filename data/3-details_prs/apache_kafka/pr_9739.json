{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM4ODc2ODM0", "number": 9739, "title": "KAFKA-10636 Bypass log validation for writes to raft log", "bodyText": "Committer Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-12-13T07:15:12Z", "url": "https://github.com/apache/kafka/pull/9739", "merged": true, "mergeCommit": {"oid": "db73d86ea65413af73a95268f1a10787079f79d9"}, "closed": true, "closedAt": "2021-02-01T18:05:47Z", "author": {"login": "feyman2016"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdlrp5lgH2gAyNTM4ODc2ODM0OmVkMmZjNTY0ZWE1NDMxYTIwOGNiYjdlNTM0OTk2ZWUxODQzYmIyYTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABd17C1bgFqTU4MDYyMzI4Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/ed2fc564ea5431a208cbb7e534996ee1843bb2a6", "committedDate": "2020-12-13T07:04:07Z", "message": "initial commit"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwODkxOTg2", "url": "https://github.com/apache/kafka/pull/9739#pullrequestreview-550891986", "createdAt": "2020-12-13T07:17:19Z", "commit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QwNzoxNzoyMFrOIEwziw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QwNzoxNzoyMFrOIEwziw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTg2NDg0Mw==", "bodyText": "I intended to add a new AppendOrigin called Leader for this case, but then think it implies the same as the Replication, so just reuses it.", "url": "https://github.com/apache/kafka/pull/9739#discussion_r541864843", "createdAt": "2020-12-13T07:17:20Z", "author": {"login": "feyman2016"}, "path": "core/src/main/scala/kafka/raft/KafkaMetadataLog.scala", "diffHunk": "@@ -68,7 +68,7 @@ class KafkaMetadataLog(\n \n     val appendInfo = log.appendAsLeader(records.asInstanceOf[MemoryRecords],\n       leaderEpoch = epoch,\n-      origin = AppendOrigin.Coordinator)\n+      origin = AppendOrigin.Replication)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwODkyNDIz", "url": "https://github.com/apache/kafka/pull/9739#pullrequestreview-550892423", "createdAt": "2020-12-13T07:24:51Z", "commit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QwNzoyNDo1MVrOIEw3-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QwNzoyNDo1MVrOIEw3-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTg2NTk3Nw==", "bodyText": "This is necessary for the sanity check in Log.scala append()\n         if (batch.magic >= RecordBatch.MAGIC_VALUE_V2) {\n              maybeAssignEpochStartOffset(batch.partitionLeaderEpoch, batch.baseOffset)", "url": "https://github.com/apache/kafka/pull/9739#discussion_r541865977", "createdAt": "2020-12-13T07:24:51Z", "author": {"login": "feyman2016"}, "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1477,6 +1477,7 @@ private void appendBatch(\n     ) {\n         try {\n             int epoch = state.epoch();\n+            batch.data.batches().forEach(recordBatch -> recordBatch.setPartitionLeaderEpoch(epoch));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwOTAxMTkx", "url": "https://github.com/apache/kafka/pull/9739#pullrequestreview-550901191", "createdAt": "2020-12-13T09:24:50Z", "commit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QwOToyNDo1MFrOIEyC3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QwOToyNDo1MFrOIEyC3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTg4NTE1MQ==", "bodyText": "This can be replaced by val assignOffsets = if (origin != AppendOrigin.Replication)", "url": "https://github.com/apache/kafka/pull/9739#discussion_r541885151", "createdAt": "2020-12-13T09:24:50Z", "author": {"login": "dengziming"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1050,7 +1050,8 @@ class Log(@volatile private var _dir: File,\n                      leaderEpoch: Int,\n                      origin: AppendOrigin = AppendOrigin.Client,\n                      interBrokerProtocolVersion: ApiVersion = ApiVersion.latestVersion): LogAppendInfo = {\n-    append(records, origin, interBrokerProtocolVersion, assignOffsets = true, leaderEpoch, ignoreRecordSize = false)\n+    val assignOffsets = if (origin == AppendOrigin.Replication) false else true", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "621bbb2fdb63b3a72e80e0bdefb33e2b0bb3d033", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/621bbb2fdb63b3a72e80e0bdefb33e2b0bb3d033", "committedDate": "2020-12-13T14:47:38Z", "message": "fix tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwOTI5Nzk2", "url": "https://github.com/apache/kafka/pull/9739#pullrequestreview-550929796", "createdAt": "2020-12-13T15:11:59Z", "commit": {"oid": "621bbb2fdb63b3a72e80e0bdefb33e2b0bb3d033"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxNToxMTo1OVrOIE1pKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxNToxMTo1OVrOIE1pKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk0NDEwNA==", "bodyText": "Since now for AppendOrigin.Replication, the LogValidator is bypassed when Log.appendAsLeader is called, which has an assumption that the records to be appended should have leader epoch ready in its underlying batches. And moreover, the transaction/group coordinator are supposed to be calling the Log.appendAsLeader with origin = AppendOrigin.Coordinator.", "url": "https://github.com/apache/kafka/pull/9739#discussion_r541944104", "createdAt": "2020-12-13T15:11:59Z", "author": {"login": "feyman2016"}, "path": "core/src/test/scala/unit/kafka/log/LogCleanerTest.scala", "diffHunk": "@@ -599,12 +599,12 @@ class LogCleanerTest {\n     val log = makeLog(config = LogConfig.fromProps(logConfig.originals, logProps))\n \n     val appendFirstTransaction = appendTransactionalAsLeader(log, producerId, producerEpoch,\n-      origin = AppendOrigin.Replication)\n+      origin = AppendOrigin.Coordinator)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "621bbb2fdb63b3a72e80e0bdefb33e2b0bb3d033"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzOTE2MDMx", "url": "https://github.com/apache/kafka/pull/9739#pullrequestreview-563916031", "createdAt": "2021-01-08T00:05:22Z", "commit": {"oid": "621bbb2fdb63b3a72e80e0bdefb33e2b0bb3d033"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQwMDowNToyMlrOIQA_Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQwMDoxNDoyMVrOIQBJeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzY2NDI5MA==", "bodyText": "I was going to ask about adding a new AppendOrigin. I agree that the behavior should be the same as for Replication, but it seems like it could lead to confusion. Maybe we could add an AppendOrigin.RaftLeader. Then we can add a simple comment which emphasizes that the Raft leader is responsible for assigning offsets. That would also allow us to revert the changes in LogCleanerTest.", "url": "https://github.com/apache/kafka/pull/9739#discussion_r553664290", "createdAt": "2021-01-08T00:05:22Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/raft/KafkaMetadataLog.scala", "diffHunk": "@@ -68,7 +68,7 @@ class KafkaMetadataLog(\n \n     val appendInfo = log.appendAsLeader(records.asInstanceOf[MemoryRecords],\n       leaderEpoch = epoch,\n-      origin = AppendOrigin.Coordinator)\n+      origin = AppendOrigin.Replication)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTg2NDg0Mw=="}, "originalCommit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzY2NTQ4MQ==", "bodyText": "Hmm.. Do we need this? I thought we already set leader epoch here: https://github.com/apache/kafka/blob/trunk/raft/src/main/java/org/apache/kafka/raft/internals/BatchBuilder.java#L256.", "url": "https://github.com/apache/kafka/pull/9739#discussion_r553665481", "createdAt": "2021-01-08T00:09:05Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1477,6 +1477,7 @@ private void appendBatch(\n     ) {\n         try {\n             int epoch = state.epoch();\n+            batch.data.batches().forEach(recordBatch -> recordBatch.setPartitionLeaderEpoch(epoch));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTg2NTk3Nw=="}, "originalCommit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzY2NjczOA==", "bodyText": "By the way, it seems we might want to rename assignOffsets since we also rely on this flag for record validation. It's a bit on the verbose side, but maybe validateAndAssignOffsets to go along with the similarly named method in LogValidator?", "url": "https://github.com/apache/kafka/pull/9739#discussion_r553666738", "createdAt": "2021-01-08T00:13:36Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1050,7 +1050,8 @@ class Log(@volatile private var _dir: File,\n                      leaderEpoch: Int,\n                      origin: AppendOrigin = AppendOrigin.Client,\n                      interBrokerProtocolVersion: ApiVersion = ApiVersion.latestVersion): LogAppendInfo = {\n-    append(records, origin, interBrokerProtocolVersion, assignOffsets = true, leaderEpoch, ignoreRecordSize = false)\n+    val assignOffsets = if (origin == AppendOrigin.Replication) false else true", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTg4NTE1MQ=="}, "originalCommit": {"oid": "ed2fc564ea5431a208cbb7e534996ee1843bb2a6"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzY2NjkzOA==", "bodyText": "It would be helpful to have a test case which verifies appendAsLeader with the new append origin.", "url": "https://github.com/apache/kafka/pull/9739#discussion_r553666938", "createdAt": "2021-01-08T00:14:21Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1050,7 +1050,8 @@ class Log(@volatile private var _dir: File,\n                      leaderEpoch: Int,\n                      origin: AppendOrigin = AppendOrigin.Client,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "621bbb2fdb63b3a72e80e0bdefb33e2b0bb3d033"}, "originalPosition": 2}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56b1c6cc9c0df3b2eee222677b22fe66c3afb604", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/56b1c6cc9c0df3b2eee222677b22fe66c3afb604", "committedDate": "2021-01-16T15:23:24Z", "message": "update based on comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56228d5ff88333645517248264011da860f559fb", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/56228d5ff88333645517248264011da860f559fb", "committedDate": "2021-01-16T15:44:50Z", "message": "update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30952cb2e7bd8eb913d011e6c9f6dde87d14a2e7", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/30952cb2e7bd8eb913d011e6c9f6dde87d14a2e7", "committedDate": "2021-01-17T08:26:03Z", "message": "merge trunk"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcwMDA4Mzkw", "url": "https://github.com/apache/kafka/pull/9739#pullrequestreview-570008390", "createdAt": "2021-01-17T08:28:02Z", "commit": {"oid": "30952cb2e7bd8eb913d011e6c9f6dde87d14a2e7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xN1QwODoyODowMlrOIVMkCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xN1QwODoyODowMlrOIVMkCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTA5Njg0Mw==", "bodyText": "Fx checkstyle error", "url": "https://github.com/apache/kafka/pull/9739#discussion_r559096843", "createdAt": "2021-01-17T08:28:02Z", "author": {"login": "feyman2016"}, "path": "raft/src/main/java/org/apache/kafka/raft/internals/BatchAccumulator.java", "diffHunk": "@@ -19,7 +19,6 @@\n import org.apache.kafka.common.memory.MemoryPool;\n import org.apache.kafka.common.record.CompressionType;\n import org.apache.kafka.common.record.MemoryRecords;\n-import org.apache.kafka.common.record.RecordBatch;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30952cb2e7bd8eb913d011e6c9f6dde87d14a2e7"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa1049a848c06b99c2fbf73fbf04d8e52ff50f6a", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/aa1049a848c06b99c2fbf73fbf04d8e52ff50f6a", "committedDate": "2021-01-17T08:29:30Z", "message": "fix naming"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxNzg3MjQy", "url": "https://github.com/apache/kafka/pull/9739#pullrequestreview-571787242", "createdAt": "2021-01-20T00:57:12Z", "commit": {"oid": "aa1049a848c06b99c2fbf73fbf04d8e52ff50f6a"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMDo1NzoxMlrOIWoY9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMTowMTowMVrOIWoe0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDYwMTMzNQ==", "bodyText": "Good catch. Do we have any test cases in BatchAccumulatorTest which can be modified to catch this case?", "url": "https://github.com/apache/kafka/pull/9739#discussion_r560601335", "createdAt": "2021-01-20T00:57:12Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/raft/internals/BatchAccumulator.java", "diffHunk": "@@ -180,7 +179,7 @@ private void startNewBatch() {\n                 nextOffset,\n                 time.milliseconds(),\n                 false,\n-                RecordBatch.NO_PARTITION_LEADER_EPOCH,\n+                epoch,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa1049a848c06b99c2fbf73fbf04d8e52ff50f6a"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDYwMjgzMw==", "bodyText": "It is a little odd here is that we have to pass through leaderEpoch even though we expect the Raft leader to have set it already. Perhaps we should be validating it in analyzeAndValidateRecords. We can verify for each batch that the leader epoch matches when the append origin is RaftLeader. Does that make sense?", "url": "https://github.com/apache/kafka/pull/9739#discussion_r560602833", "createdAt": "2021-01-20T01:01:01Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1057,7 +1057,8 @@ class Log(@volatile private var _dir: File,\n                      leaderEpoch: Int,\n                      origin: AppendOrigin = AppendOrigin.Client,\n                      interBrokerProtocolVersion: ApiVersion = ApiVersion.latestVersion): LogAppendInfo = {\n-    append(records, origin, interBrokerProtocolVersion, assignOffsets = true, leaderEpoch, ignoreRecordSize = false)\n+    val validateAndAssignOffsets = origin != AppendOrigin.RaftLeader\n+    append(records, origin, interBrokerProtocolVersion, validateAndAssignOffsets, leaderEpoch, ignoreRecordSize = false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa1049a848c06b99c2fbf73fbf04d8e52ff50f6a"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ae4903a1ddf109892465d24dd1b935886c45b11", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/7ae4903a1ddf109892465d24dd1b935886c45b11", "committedDate": "2021-02-01T00:40:24Z", "message": "merge origin/trunk and fix based on comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89afaf3d8f72af4b5770bef9ae27989ad1a29860", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/89afaf3d8f72af4b5770bef9ae27989ad1a29860", "committedDate": "2021-02-01T15:17:00Z", "message": "Fix KafkaMetadataLogTest"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgwNjIzMjg2", "url": "https://github.com/apache/kafka/pull/9739#pullrequestreview-580623286", "createdAt": "2021-02-01T18:02:43Z", "commit": {"oid": "89afaf3d8f72af4b5770bef9ae27989ad1a29860"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2273, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}