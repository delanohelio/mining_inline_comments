{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzNjEzODcw", "number": 7972, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNDoxNDoyN1rODdsi7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNTowMjozNVrODpjB1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDY1MTMyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNDoxNDoyN1rOFmcdEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNDoxOToyMFrOFmcoPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTg1NjQwMw==", "bodyText": "The left side should be List", "url": "https://github.com/apache/kafka/pull/7972#discussion_r375856403", "createdAt": "2020-02-06T14:14:27Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -2243,21 +2245,36 @@ public DescribeReplicaLogDirsResult describeReplicaLogDirs(Collection<TopicParti\n             futures.put(replica, new KafkaFutureImpl<>());\n         }\n \n-        Map<Integer, Set<TopicPartition>> partitionsByBroker = new HashMap<>();\n+        Map<Integer, DescribeLogDirsRequestData> partitionsByBroker = new HashMap<>();\n \n         for (TopicPartitionReplica replica: replicas) {\n-            if (!partitionsByBroker.containsKey(replica.brokerId()))\n-                partitionsByBroker.put(replica.brokerId(), new HashSet<>());\n-            partitionsByBroker.get(replica.brokerId()).add(new TopicPartition(replica.topic(), replica.partition()));\n+            DescribeLogDirsRequestData requestData = partitionsByBroker.get(replica.brokerId());\n+            if (requestData == null) {\n+                requestData = new DescribeLogDirsRequestData();\n+                partitionsByBroker.put(replica.brokerId(), requestData);\n+            }\n+            DescribableLogDirTopic describableLogDirTopic = requestData.topics().find(replica.topic());\n+            if (describableLogDirTopic == null) {\n+                ArrayList<Integer> v = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTg1OTI2Mw==", "bodyText": "Also can we find a better name? What about partitionIndex?", "url": "https://github.com/apache/kafka/pull/7972#discussion_r375859263", "createdAt": "2020-02-06T14:19:20Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -2243,21 +2245,36 @@ public DescribeReplicaLogDirsResult describeReplicaLogDirs(Collection<TopicParti\n             futures.put(replica, new KafkaFutureImpl<>());\n         }\n \n-        Map<Integer, Set<TopicPartition>> partitionsByBroker = new HashMap<>();\n+        Map<Integer, DescribeLogDirsRequestData> partitionsByBroker = new HashMap<>();\n \n         for (TopicPartitionReplica replica: replicas) {\n-            if (!partitionsByBroker.containsKey(replica.brokerId()))\n-                partitionsByBroker.put(replica.brokerId(), new HashSet<>());\n-            partitionsByBroker.get(replica.brokerId()).add(new TopicPartition(replica.topic(), replica.partition()));\n+            DescribeLogDirsRequestData requestData = partitionsByBroker.get(replica.brokerId());\n+            if (requestData == null) {\n+                requestData = new DescribeLogDirsRequestData();\n+                partitionsByBroker.put(replica.brokerId(), requestData);\n+            }\n+            DescribableLogDirTopic describableLogDirTopic = requestData.topics().find(replica.topic());\n+            if (describableLogDirTopic == null) {\n+                ArrayList<Integer> v = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTg1NjQwMw=="}, "originalCommit": null, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDY2MDczOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNDoxNzowMlrOFmci_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNDoxNzowMlrOFmci_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTg1NzkxNw==", "bodyText": "Like in #7957 let's remove this field", "url": "https://github.com/apache/kafka/pull/7972#discussion_r375857917", "createdAt": "2020-02-06T14:17:02Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsRequest.java", "diffHunk": "@@ -49,105 +43,58 @@\n                     TOPIC_NAME,\n                     new Field(PARTITIONS_KEY_NAME, new ArrayOf(INT32), \"List of partition ids of the topic.\")))));\n \n-    /**\n-     * The version number is bumped to indicate that on quota violation brokers send out responses before throttling.\n-     */\n-    private static final Schema DESCRIBE_LOG_DIRS_REQUEST_V1 = DESCRIBE_LOG_DIRS_REQUEST_V0;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{DESCRIBE_LOG_DIRS_REQUEST_V0, DESCRIBE_LOG_DIRS_REQUEST_V1};\n-    }\n-\n-    private final Set<TopicPartition> topicPartitions;\n+    private final DescribeLogDirsRequestData data;\n+    private final short version;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMTg5MDg2OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/server/RequestQuotaTest.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzo1MTo1MVrOF2NJPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzo1MTo1MVrOF2NJPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM4Mjc4Mg==", "bodyText": "We can remove a bunch of brackets in this statement", "url": "https://github.com/apache/kafka/pull/7972#discussion_r392382782", "createdAt": "2020-03-13T17:51:51Z", "author": {"login": "mimaison"}, "path": "core/src/test/scala/unit/kafka/server/RequestQuotaTest.scala", "diffHunk": "@@ -446,7 +446,11 @@ class RequestQuotaTest extends BaseRequestTest {\n           new AlterReplicaLogDirsRequest.Builder(Collections.singletonMap(tp, logDir))\n \n         case ApiKeys.DESCRIBE_LOG_DIRS =>\n-          new DescribeLogDirsRequest.Builder(Collections.singleton(tp))\n+          val data = new DescribeLogDirsRequestData()\n+          data.topics().add(new DescribeLogDirsRequestData.DescribableLogDirTopic()\n+            .setTopic(tp.topic())\n+            .setPartitionIndex(Collections.singletonList(tp.partition())))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMTkwMjgxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzo1NjowNFrOF2NRZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzo1NjowNFrOF2NRZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM4NDg3MA==", "bodyText": "I think it's slightly more readable if each setter is called on a new line. There're a few places where setLogDir() is called inline in this file.", "url": "https://github.com/apache/kafka/pull/7972#discussion_r392384870", "createdAt": "2020-03-13T17:56:04Z", "author": {"login": "mimaison"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -671,25 +671,36 @@ class ReplicaManager(val config: KafkaConfig,\n \n         logsByDir.get(absolutePath) match {\n           case Some(logs) =>\n-            val replicaInfos = logs.filter { log =>\n-              partitions.contains(log.topicPartition)\n-            }.map { log =>\n-              log.topicPartition -> new ReplicaInfo(log.size, getLogEndOffsetLag(log.topicPartition, log.logEndOffset, log.isFuture), log.isFuture)\n-            }.toMap\n-\n-            (absolutePath, new LogDirInfo(Errors.NONE, replicaInfos.asJava))\n+            val topicInfos = logs.groupBy(_.topicPartition.topic).map{case (topic, logs) =>\n+              new DescribeLogDirsResponseData.DescribeLogDirsTopic().setName(topic).setPartitions(\n+                logs.filter { log =>\n+                  partitions.contains(log.topicPartition)\n+                }.map { log =>\n+                  new DescribeLogDirsResponseData.DescribeLogDirsPartition().\n+                    setPartitionSize(log.size).\n+                    setPartitionIndex(log.topicPartition.partition).\n+                    setOffsetLag(getLogEndOffsetLag(log.topicPartition, log.logEndOffset, log.isFuture))\n+                    .setIsFutureKey(log.isFuture)\n+                }.toList.asJava)\n+            }.toList.asJava\n+\n+            new DescribeLogDirsResponseData.DescribeLogDirsResult().setLogDir(absolutePath)\n+              .setErrorCode(Errors.NONE.code).setTopics(topicInfos)\n           case None =>\n-            (absolutePath, new LogDirInfo(Errors.NONE, Map.empty[TopicPartition, ReplicaInfo].asJava))\n+            new DescribeLogDirsResponseData.DescribeLogDirsResult().setLogDir(absolutePath)\n+              .setErrorCode(Errors.NONE.code)\n         }\n \n       } catch {\n         case _: KafkaStorageException =>\n-          (absolutePath, new LogDirInfo(Errors.KAFKA_STORAGE_ERROR, Map.empty[TopicPartition, ReplicaInfo].asJava))\n+          new DescribeLogDirsResponseData.DescribeLogDirsResult().setLogDir(absolutePath)\n+            .setErrorCode(Errors.KAFKA_STORAGE_ERROR.code)\n         case t: Throwable =>\n           error(s\"Error while describing replica in dir $absolutePath\", t)\n-          (absolutePath, new LogDirInfo(Errors.forException(t), Map.empty[TopicPartition, ReplicaInfo].asJava))\n+          new DescribeLogDirsResponseData.DescribeLogDirsResult().setLogDir(absolutePath)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMTkxMDYzOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsResponse.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzo1ODo0NFrOF2NWcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzo1ODo0NFrOF2NWcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM4NjE2MQ==", "bodyText": "Is this comment still acurate?", "url": "https://github.com/apache/kafka/pull/7972#discussion_r392386161", "createdAt": "2020-03-13T17:58:44Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsResponse.java", "diffHunk": "@@ -18,172 +18,80 @@\n package org.apache.kafka.common.requests;\n \n import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.DescribeLogDirsResponseData;\n+import org.apache.kafka.common.message.DescribeLogDirsResponseData.DescribeLogDirsPartition;\n+import org.apache.kafka.common.message.DescribeLogDirsResponseData.DescribeLogDirsResult;\n+import org.apache.kafka.common.message.DescribeLogDirsResponseData.DescribeLogDirsTopic;\n import org.apache.kafka.common.protocol.ApiKeys;\n import org.apache.kafka.common.protocol.Errors;\n-import org.apache.kafka.common.protocol.types.ArrayOf;\n-import org.apache.kafka.common.protocol.types.Field;\n-import org.apache.kafka.common.protocol.types.Schema;\n import org.apache.kafka.common.protocol.types.Struct;\n-import org.apache.kafka.common.utils.CollectionUtils;\n \n import java.nio.ByteBuffer;\n-import java.util.ArrayList;\n import java.util.HashMap;\n-import java.util.List;\n import java.util.Map;\n \n-import static org.apache.kafka.common.protocol.CommonFields.ERROR_CODE;\n-import static org.apache.kafka.common.protocol.CommonFields.PARTITION_ID;\n-import static org.apache.kafka.common.protocol.CommonFields.THROTTLE_TIME_MS;\n-import static org.apache.kafka.common.protocol.CommonFields.TOPIC_NAME;\n-import static org.apache.kafka.common.protocol.types.Type.BOOLEAN;\n-import static org.apache.kafka.common.protocol.types.Type.INT64;\n-import static org.apache.kafka.common.protocol.types.Type.STRING;\n-\n \n public class DescribeLogDirsResponse extends AbstractResponse {\n \n     public static final long INVALID_OFFSET_LAG = -1L;\n \n-    // request level key names\n-    private static final String LOG_DIRS_KEY_NAME = \"log_dirs\";\n-\n-    // dir level key names\n-    private static final String LOG_DIR_KEY_NAME = \"log_dir\";\n-    private static final String TOPICS_KEY_NAME = \"topics\";\n-\n-    // topic level key names\n-    private static final String PARTITIONS_KEY_NAME = \"partitions\";\n-\n-    // partition level key names\n-    private static final String SIZE_KEY_NAME = \"size\";\n-    private static final String OFFSET_LAG_KEY_NAME = \"offset_lag\";\n-    private static final String IS_FUTURE_KEY_NAME = \"is_future\";\n-\n-    private static final Schema DESCRIBE_LOG_DIRS_RESPONSE_V0 = new Schema(\n-            THROTTLE_TIME_MS,\n-            new Field(LOG_DIRS_KEY_NAME, new ArrayOf(new Schema(\n-                    ERROR_CODE,\n-                    new Field(LOG_DIR_KEY_NAME, STRING, \"The absolute log directory path.\"),\n-                    new Field(TOPICS_KEY_NAME, new ArrayOf(new Schema(\n-                            TOPIC_NAME,\n-                            new Field(PARTITIONS_KEY_NAME, new ArrayOf(new Schema(\n-                                    PARTITION_ID,\n-                                    new Field(SIZE_KEY_NAME, INT64, \"The size of the log segments of the partition in bytes.\"),\n-                                    new Field(OFFSET_LAG_KEY_NAME, INT64, \"The lag of the log's LEO w.r.t. partition's HW \" +\n-                                            \"(if it is the current log for the partition) or current replica's LEO \" +\n-                                            \"(if it is the future log for the partition)\"),\n-                                    new Field(IS_FUTURE_KEY_NAME, BOOLEAN, \"True if this log is created by \" +\n-                                            \"AlterReplicaLogDirsRequest and will replace the current log of the replica \" +\n-                                            \"in the future.\")))))))))));\n-\n-    /**\n-     * The version number is bumped to indicate that on quota violation brokers send out responses before throttling.\n-     */\n-    private static final Schema DESCRIBE_LOG_DIRS_RESPONSE_V1 = DESCRIBE_LOG_DIRS_RESPONSE_V0;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{DESCRIBE_LOG_DIRS_RESPONSE_V0, DESCRIBE_LOG_DIRS_RESPONSE_V1};\n-    }\n-\n-    private final int throttleTimeMs;\n-    private final Map<String, LogDirInfo> logDirInfos;\n-\n-    public DescribeLogDirsResponse(Struct struct) {\n-        throttleTimeMs = struct.get(THROTTLE_TIME_MS);\n-        logDirInfos = new HashMap<>();\n-\n-        for (Object logDirStructObj : struct.getArray(LOG_DIRS_KEY_NAME)) {\n-            Struct logDirStruct = (Struct) logDirStructObj;\n-            Errors error = Errors.forCode(logDirStruct.get(ERROR_CODE));\n-            String logDir = logDirStruct.getString(LOG_DIR_KEY_NAME);\n-            Map<TopicPartition, ReplicaInfo> replicaInfos = new HashMap<>();\n-\n-            for (Object topicStructObj : logDirStruct.getArray(TOPICS_KEY_NAME)) {\n-                Struct topicStruct = (Struct) topicStructObj;\n-                String topic = topicStruct.get(TOPIC_NAME);\n-\n-                for (Object partitionStructObj : topicStruct.getArray(PARTITIONS_KEY_NAME)) {\n-                    Struct partitionStruct = (Struct) partitionStructObj;\n-                    int partition = partitionStruct.get(PARTITION_ID);\n-                    long size = partitionStruct.getLong(SIZE_KEY_NAME);\n-                    long offsetLag = partitionStruct.getLong(OFFSET_LAG_KEY_NAME);\n-                    boolean isFuture = partitionStruct.getBoolean(IS_FUTURE_KEY_NAME);\n-                    ReplicaInfo replicaInfo = new ReplicaInfo(size, offsetLag, isFuture);\n-                    replicaInfos.put(new TopicPartition(topic, partition), replicaInfo);\n-                }\n-            }\n+    private final DescribeLogDirsResponseData data;\n \n-            logDirInfos.put(logDir, new LogDirInfo(error, replicaInfos));\n-        }\n+    public DescribeLogDirsResponse(Struct struct, short version) {\n+        this.data = new DescribeLogDirsResponseData(struct, version);\n     }\n \n     /**\n      * Constructor for version 0.\n      */", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0ODU5NjcxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsRequest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMzo1MjozNlrOF4vX4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMzo1MjozNlrOF4vX4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTA0MDczNw==", "bodyText": "This comment can now be removed", "url": "https://github.com/apache/kafka/pull/7972#discussion_r395040737", "createdAt": "2020-03-19T13:52:36Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsRequest.java", "diffHunk": "@@ -49,105 +43,55 @@\n                     TOPIC_NAME,\n                     new Field(PARTITIONS_KEY_NAME, new ArrayOf(INT32), \"List of partition ids of the topic.\")))));\n \n-    /**\n-     * The version number is bumped to indicate that on quota violation brokers send out responses before throttling.\n-     */\n-    private static final Schema DESCRIBE_LOG_DIRS_REQUEST_V1 = DESCRIBE_LOG_DIRS_REQUEST_V0;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{DESCRIBE_LOG_DIRS_REQUEST_V0, DESCRIBE_LOG_DIRS_REQUEST_V1};\n-    }\n-\n-    private final Set<TopicPartition> topicPartitions;\n+    private final DescribeLogDirsRequestData data;\n \n     public static class Builder extends AbstractRequest.Builder<DescribeLogDirsRequest> {\n-        private final Set<TopicPartition> topicPartitions;\n+        private final DescribeLogDirsRequestData data;\n \n         // topicPartitions == null indicates requesting all partitions, and an empty list indicates requesting no partitions.\n-        public Builder(Set<TopicPartition> partitions) {\n+        public Builder(DescribeLogDirsRequestData data) {\n             super(ApiKeys.DESCRIBE_LOG_DIRS);\n-            this.topicPartitions = partitions;\n+            this.data = data;\n         }\n \n         @Override\n         public DescribeLogDirsRequest build(short version) {\n-            return new DescribeLogDirsRequest(topicPartitions, version);\n+            return new DescribeLogDirsRequest(data, version);\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder builder = new StringBuilder();\n-            builder.append(\"(type=DescribeLogDirsRequest\")\n-                .append(\", topicPartitions=\")\n-                .append(topicPartitions)\n-                .append(\")\");\n-            return builder.toString();\n+            return data.toString();\n         }\n     }\n \n     public DescribeLogDirsRequest(Struct struct, short version) {\n         super(ApiKeys.DESCRIBE_LOG_DIRS, version);\n-\n-        if (struct.getArray(TOPICS_KEY_NAME) == null) {\n-            topicPartitions = null;\n-        } else {\n-            topicPartitions = new HashSet<>();\n-            for (Object topicStructObj : struct.getArray(TOPICS_KEY_NAME)) {\n-                Struct topicStruct = (Struct) topicStructObj;\n-                String topic = topicStruct.get(TOPIC_NAME);\n-                for (Object partitionObj : topicStruct.getArray(PARTITIONS_KEY_NAME)) {\n-                    int partition = (Integer) partitionObj;\n-                    topicPartitions.add(new TopicPartition(topic, partition));\n-                }\n-            }\n-        }\n+        this.data = new DescribeLogDirsRequestData(struct, version);\n     }\n \n     // topicPartitions == null indicates requesting all partitions, and an empty list indicates requesting no partitions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a7f72cba6def206c04a6ca5b1ba547faf85058cf"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0ODYyMzg0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMzo1ODozNlrOF4vo_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMzo1ODozNlrOF4vo_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTA0NTExNw==", "bodyText": "nit: Can we put this with the other import from the same package", "url": "https://github.com/apache/kafka/pull/7972#discussion_r395045117", "createdAt": "2020-03-19T13:58:36Z", "author": {"login": "mimaison"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -50,7 +51,7 @@ import org.apache.kafka.common.record._\n import org.apache.kafka.common.replica.PartitionView.DefaultPartitionView\n import org.apache.kafka.common.replica.ReplicaView.DefaultReplicaView\n import org.apache.kafka.common.replica.{ClientMetadata, _}\n-import org.apache.kafka.common.requests.DescribeLogDirsResponse.{LogDirInfo, ReplicaInfo}\n+import org.apache.kafka.common.message.DescribeLogDirsResponseData._", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a7f72cba6def206c04a6ca5b1ba547faf85058cf"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0ODkxNDExOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsRequest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNTowMTowN1rOF4yj9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNTowMTowN1rOF4yj9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTA5Mjk4MQ==", "bodyText": "This V0 schema should be deleted too", "url": "https://github.com/apache/kafka/pull/7972#discussion_r395092981", "createdAt": "2020-03-19T15:01:07Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsRequest.java", "diffHunk": "@@ -49,105 +43,54 @@\n                     TOPIC_NAME,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f72902e6c772f5254004d408b747cbe57824668c"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0ODkyMTE5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsRequest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNTowMjozNVrOF4yoZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNTowMjozNVrOF4yoZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTA5NDExOA==", "bodyText": "The comment above is out of date", "url": "https://github.com/apache/kafka/pull/7972#discussion_r395094118", "createdAt": "2020-03-19T15:02:35Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeLogDirsRequest.java", "diffHunk": "@@ -49,105 +43,54 @@\n                     TOPIC_NAME,\n                     new Field(PARTITIONS_KEY_NAME, new ArrayOf(INT32), \"List of partition ids of the topic.\")))));\n \n-    /**\n-     * The version number is bumped to indicate that on quota violation brokers send out responses before throttling.\n-     */\n-    private static final Schema DESCRIBE_LOG_DIRS_REQUEST_V1 = DESCRIBE_LOG_DIRS_REQUEST_V0;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{DESCRIBE_LOG_DIRS_REQUEST_V0, DESCRIBE_LOG_DIRS_REQUEST_V1};\n-    }\n-\n-    private final Set<TopicPartition> topicPartitions;\n+    private final DescribeLogDirsRequestData data;\n \n     public static class Builder extends AbstractRequest.Builder<DescribeLogDirsRequest> {\n-        private final Set<TopicPartition> topicPartitions;\n+        private final DescribeLogDirsRequestData data;\n \n-        // topicPartitions == null indicates requesting all partitions, and an empty list indicates requesting no partitions.\n-        public Builder(Set<TopicPartition> partitions) {\n+        public Builder(DescribeLogDirsRequestData data) {\n             super(ApiKeys.DESCRIBE_LOG_DIRS);\n-            this.topicPartitions = partitions;\n+            this.data = data;\n         }\n \n         @Override\n         public DescribeLogDirsRequest build(short version) {\n-            return new DescribeLogDirsRequest(topicPartitions, version);\n+            return new DescribeLogDirsRequest(data, version);\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder builder = new StringBuilder();\n-            builder.append(\"(type=DescribeLogDirsRequest\")\n-                .append(\", topicPartitions=\")\n-                .append(topicPartitions)\n-                .append(\")\");\n-            return builder.toString();\n+            return data.toString();\n         }\n     }\n \n     public DescribeLogDirsRequest(Struct struct, short version) {\n         super(ApiKeys.DESCRIBE_LOG_DIRS, version);\n-\n-        if (struct.getArray(TOPICS_KEY_NAME) == null) {\n-            topicPartitions = null;\n-        } else {\n-            topicPartitions = new HashSet<>();\n-            for (Object topicStructObj : struct.getArray(TOPICS_KEY_NAME)) {\n-                Struct topicStruct = (Struct) topicStructObj;\n-                String topic = topicStruct.get(TOPIC_NAME);\n-                for (Object partitionObj : topicStruct.getArray(PARTITIONS_KEY_NAME)) {\n-                    int partition = (Integer) partitionObj;\n-                    topicPartitions.add(new TopicPartition(topic, partition));\n-                }\n-            }\n-        }\n+        this.data = new DescribeLogDirsRequestData(struct, version);\n     }\n \n     // topicPartitions == null indicates requesting all partitions, and an empty list indicates requesting no partitions.\n-    public DescribeLogDirsRequest(Set<TopicPartition> topicPartitions, short version) {\n+    public DescribeLogDirsRequest(DescribeLogDirsRequestData data, short version) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f72902e6c772f5254004d408b747cbe57824668c"}, "originalPosition": 91}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4383, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}