{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyMDcwMjQz", "number": 8841, "title": "KAFKA-10123 Fix incorrect value for AWAIT_RESET#hasPosition", "bodyText": "Background\nWhen a partition subscription is initialized it has a null position and is in the INITIALIZING state. Depending on the consumer, it will then transition to one of the other states. Typically a consumer will either reset the offset to earliest/latest, or it will provide an offset (with or without offset metadata). For the reset case, we still have no position to act on so fetches should not occur.\nRecently we made changes for KAFKA-9724 (#8376) to prevent clients from entering the AWAIT_VALIDATION state when targeting older brokers. New logic to bypass offset validation as part of this change exposed this new issue.\nBug and Fix\nIn the partition subscriptions, the AWAIT_RESET state was incorrectly reporting that it had a position. In some cases a position might actually exist (e.g., if we were resetting offsets during a fetch after a truncation), but in the initialization case no position had been set. We saw this issue in system tests where there is a race between the offset reset completing and the first fetch request being issued.\nSince AWAIT_RESET#hasPosition was incorrectly returning true, the new logic to bypass offset validation was transitioning the subscription to FETCHING (even though no position existed).\nThe fix was simply to have AWAIT_RESET#hasPosition to return false which should have been the case from the start.\nAdditionally, this fix includes some guards against NPE when reading the position from the subscription.", "createdAt": "2020-06-09T21:16:08Z", "url": "https://github.com/apache/kafka/pull/8841", "merged": true, "mergeCommit": {"oid": "446196d6e9d66f45c64b483e3d375aaeaca28e3b"}, "closed": true, "closedAt": "2020-06-18T03:23:46Z", "author": {"login": "mumrah"}, "timelineItems": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcprhAmgH2gAyNDMyMDcwMjQzOjAzNGNhOTM4ZTkxZGM2ZjgxNDQwYjM5NzMzZTI5MDI4YTE3MjliY2E=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcsVw1nAFqTQzMjkxMzI0MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "034ca938e91dc6f81440b39733e29028a1729bca", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/034ca938e91dc6f81440b39733e29028a1729bca", "committedDate": "2020-06-09T20:58:57Z", "message": "Fix incorrect result for AWAIT_RESET#hasPosition\n\nAlso ensure we are updating the position with the current leader info even when\nfetching from older brokers"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3Nzc3NzQy", "url": "https://github.com/apache/kafka/pull/8841#pullrequestreview-427777742", "createdAt": "2020-06-10T07:26:34Z", "commit": {"oid": "034ca938e91dc6f81440b39733e29028a1729bca"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwNzoyNjozNFrOGhoGeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwNzoyNjozNFrOGhoGeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxMzIwOA==", "bodyText": "As it produced a bug, could you add some comment for this method?", "url": "https://github.com/apache/kafka/pull/8841#discussion_r437913208", "createdAt": "2020-06-10T07:26:34Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -978,7 +1000,7 @@ public boolean hasValidPosition() {\n \n             @Override\n             public boolean hasPosition() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034ca938e91dc6f81440b39733e29028a1729bca"}, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3Nzg3MDcx", "url": "https://github.com/apache/kafka/pull/8841#pullrequestreview-427787071", "createdAt": "2020-06-10T07:36:37Z", "commit": {"oid": "034ca938e91dc6f81440b39733e29028a1729bca"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwNzozNjozN1rOGhobkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwNzozNjozN1rOGhobkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxODYxMA==", "bodyText": "nit: newPosition can be created lazy.", "url": "https://github.com/apache/kafka/pull/8841#discussion_r437918610", "createdAt": "2020-06-10T07:36:37Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -799,6 +806,21 @@ private boolean maybeValidatePosition(Metadata.LeaderAndEpoch currentLeaderAndEp\n             return this.fetchState.equals(FetchStates.AWAIT_VALIDATION);\n         }\n \n+        /**\n+         * For older versions of the API, we cannot perform offset validation so we simply transition directly to FETCHING\n+         *\n+         * @param currentLeaderAndEpoch\n+         */\n+        private void updatePositionLeaderNoValidation(Metadata.LeaderAndEpoch currentLeaderAndEpoch) {\n+            if (position != null && !position.currentLeader.equals(currentLeaderAndEpoch)) {\n+                FetchPosition newPosition = new FetchPosition(position.offset, position.offsetEpoch, currentLeaderAndEpoch);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034ca938e91dc6f81440b39733e29028a1729bca"}, "originalPosition": 34}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e07605c5ff441814fb44acee4d630cca92c886f8", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/e07605c5ff441814fb44acee4d630cca92c886f8", "committedDate": "2020-06-10T14:59:04Z", "message": "Add some protection against NPE when reading the position"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MzY5MTc4", "url": "https://github.com/apache/kafka/pull/8841#pullrequestreview-428369178", "createdAt": "2020-06-10T19:36:47Z", "commit": {"oid": "e07605c5ff441814fb44acee4d630cca92c886f8"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTozNjo0OFrOGiDjDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTo0ODoxMVrOGiD6tQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2Mjg5NQ==", "bodyText": "Would it make sense to move hasPosition to TopicPartitionState? Then we could just turn this into a null check on position.", "url": "https://github.com/apache/kafka/pull/8841#discussion_r438362895", "createdAt": "2020-06-10T19:36:48Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -978,7 +1000,7 @@ public boolean hasValidPosition() {\n \n             @Override\n             public boolean hasPosition() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e07605c5ff441814fb44acee4d630cca92c886f8"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2ODk0OQ==", "bodyText": "I think the invariant that we try to maintain is that we should have a position if we are in the FETCHING state. I'd suggest we detect this in transitionState and raise the exception at that point. Otherwise, we could reach an illegal state and the consumer would just stop fetching the partition. Failing fast is probably preferable. What I have in mind is just something like this:\n        private void transitionState(FetchState newState, Runnable runIfTransitioned) {\n            FetchState nextState = this.fetchState.transitionTo(newState);\n            if (nextState.equals(newState)) {\n                if (position == null && (nextState == FETCHING || nextState == AWAIT_VALIDATION))\n                   throw new IllegalStateException();\n                this.fetchState = nextState;\n                runIfTransitioned.run();\n            }\n        }", "url": "https://github.com/apache/kafka/pull/8841#discussion_r438368949", "createdAt": "2020-06-10T19:48:11Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -675,36 +676,41 @@ private ListOffsetResult fetchOffsetsByTimes(Map<TopicPartition, Long> timestamp\n                     completedFetch.partition);\n         } else {\n             FetchPosition position = subscriptions.position(completedFetch.partition);\n-            if (completedFetch.nextFetchOffset == position.offset) {\n-                List<ConsumerRecord<K, V>> partRecords = completedFetch.fetchRecords(maxRecords);\n-\n-                log.trace(\"Returning {} fetched records at offset {} for assigned partition {}\",\n-                        partRecords.size(), position, completedFetch.partition);\n-\n-                if (completedFetch.nextFetchOffset > position.offset) {\n-                    FetchPosition nextPosition = new FetchPosition(\n-                            completedFetch.nextFetchOffset,\n-                            completedFetch.lastEpoch,\n-                            position.currentLeader);\n-                    log.trace(\"Update fetching position to {} for partition {}\", nextPosition, completedFetch.partition);\n-                    subscriptions.position(completedFetch.partition, nextPosition);\n-                }\n+            if (position != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e07605c5ff441814fb44acee4d630cca92c886f8"}, "originalPosition": 35}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fd47fb7c97c5c15e0a7458f7d6df116a28819ee", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/8fd47fb7c97c5c15e0a7458f7d6df116a28819ee", "committedDate": "2020-06-10T20:51:44Z", "message": "Fix some logic that was inverted with the change to AWAIT_RESET"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0795a276de2060cfb6d56243f5a7c944fa1b3a0b", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/0795a276de2060cfb6d56243f5a7c944fa1b3a0b", "committedDate": "2020-06-11T14:14:31Z", "message": "Fix logic inversion in resetMissingPositions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a8764e7ef6ba8fe9d81c968605c1b65301eb5e9", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/2a8764e7ef6ba8fe9d81c968605c1b65301eb5e9", "committedDate": "2020-06-11T18:00:53Z", "message": "Feedback from PR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c9e7ff335ce94b0bcf0094bfcb128bbcb2429d5a", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/c9e7ff335ce94b0bcf0094bfcb128bbcb2429d5a", "committedDate": "2020-06-11T18:01:27Z", "message": "Always skip validation regardless of position's leader+epoch"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d676c1e7f892ea4dbed194e44aadd262fd0f13d", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/7d676c1e7f892ea4dbed194e44aadd262fd0f13d", "committedDate": "2020-06-11T20:27:12Z", "message": "Merge remote-tracking branch 'apache-github/trunk' into KAFKA-10123"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01c18ce17c0d950214ddcbd8d4fb55a7421365ba", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/01c18ce17c0d950214ddcbd8d4fb55a7421365ba", "committedDate": "2020-06-12T02:39:32Z", "message": "Feedback from PR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37500eea93caf87f49c952dd56f39f3887dc1a5e", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/37500eea93caf87f49c952dd56f39f3887dc1a5e", "committedDate": "2020-06-12T14:18:31Z", "message": "Cleanup javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93", "committedDate": "2020-06-15T13:58:51Z", "message": "Merge remote-tracking branch 'apache-github/trunk' into KAFKA-10123"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNjgzNTQz", "url": "https://github.com/apache/kafka/pull/8841#pullrequestreview-431683543", "createdAt": "2020-06-16T16:26:55Z", "commit": {"oid": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNjoyOToyMVrOGkjkgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNjo0Njo1NlrOGkkS-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk4NDcwNQ==", "bodyText": "This comment applies to a few of the added null checks where we have already validated that the partition is \"fetchable.\" I am wondering if it would be more consistent to raise an exception.", "url": "https://github.com/apache/kafka/pull/8841#discussion_r440984705", "createdAt": "2020-06-16T16:29:21Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -675,36 +676,41 @@ private ListOffsetResult fetchOffsetsByTimes(Map<TopicPartition, Long> timestamp\n                     completedFetch.partition);\n         } else {\n             FetchPosition position = subscriptions.position(completedFetch.partition);\n-            if (completedFetch.nextFetchOffset == position.offset) {\n-                List<ConsumerRecord<K, V>> partRecords = completedFetch.fetchRecords(maxRecords);\n-\n-                log.trace(\"Returning {} fetched records at offset {} for assigned partition {}\",\n-                        partRecords.size(), position, completedFetch.partition);\n-\n-                if (completedFetch.nextFetchOffset > position.offset) {\n-                    FetchPosition nextPosition = new FetchPosition(\n-                            completedFetch.nextFetchOffset,\n-                            completedFetch.lastEpoch,\n-                            position.currentLeader);\n-                    log.trace(\"Update fetching position to {} for partition {}\", nextPosition, completedFetch.partition);\n-                    subscriptions.position(completedFetch.partition, nextPosition);\n-                }\n+            if (position != null) {\n+                if (completedFetch.nextFetchOffset == position.offset) {\n+                    List<ConsumerRecord<K, V>> partRecords = completedFetch.fetchRecords(maxRecords);\n+\n+                    log.trace(\"Returning {} fetched records at offset {} for assigned partition {}\",\n+                            partRecords.size(), position, completedFetch.partition);\n+\n+                    if (completedFetch.nextFetchOffset > position.offset) {\n+                        FetchPosition nextPosition = new FetchPosition(\n+                                completedFetch.nextFetchOffset,\n+                                completedFetch.lastEpoch,\n+                                position.currentLeader);\n+                        log.trace(\"Update fetching position to {} for partition {}\", nextPosition, completedFetch.partition);\n+                        subscriptions.position(completedFetch.partition, nextPosition);\n+                    }\n \n-                Long partitionLag = subscriptions.partitionLag(completedFetch.partition, isolationLevel);\n-                if (partitionLag != null)\n-                    this.sensors.recordPartitionLag(completedFetch.partition, partitionLag);\n+                    Long partitionLag = subscriptions.partitionLag(completedFetch.partition, isolationLevel);\n+                    if (partitionLag != null)\n+                        this.sensors.recordPartitionLag(completedFetch.partition, partitionLag);\n \n-                Long lead = subscriptions.partitionLead(completedFetch.partition);\n-                if (lead != null) {\n-                    this.sensors.recordPartitionLead(completedFetch.partition, lead);\n-                }\n+                    Long lead = subscriptions.partitionLead(completedFetch.partition);\n+                    if (lead != null) {\n+                        this.sensors.recordPartitionLead(completedFetch.partition, lead);\n+                    }\n \n-                return partRecords;\n+                    return partRecords;\n+                } else {\n+                    // these records aren't next in line based on the last consumed position, ignore them\n+                    // they must be from an obsolete request\n+                    log.debug(\"Ignoring fetched records for {} at offset {} since the current position is {}\",\n+                            completedFetch.partition, completedFetch.nextFetchOffset, position);\n+                }\n             } else {\n-                // these records aren't next in line based on the last consumed position, ignore them\n-                // they must be from an obsolete request\n-                log.debug(\"Ignoring fetched records for {} at offset {} since the current position is {}\",\n-                        completedFetch.partition, completedFetch.nextFetchOffset, position);\n+                log.warn(\"Ignoring fetched records for {} at offset {} since the current position is undefined\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5MDM0Mw==", "bodyText": "Should we change the name of this method to something like resetInitializingPositions?", "url": "https://github.com/apache/kafka/pull/8841#discussion_r440990343", "createdAt": "2020-06-16T16:37:01Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -647,7 +647,7 @@ public synchronized void resetMissingPositions() {\n         assignment.stream().forEach(state -> {\n             TopicPartition tp = state.topicPartition();\n             TopicPartitionState partitionState = state.value();\n-            if (!partitionState.hasPosition()) {\n+            if (partitionState.fetchState.equals(FetchStates.INITIALIZING)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5Mzc4MA==", "bodyText": "Since the usage is a bit different, maybe we could change the name to requiresPosition. Then this check seems a little more intuitive:\n                if (this.position == null && nextState.requiresPosition()) {\n                    throw new IllegalStateException(\"Transitioned subscription state to \" + nextState + \", but position is null\");\n                }", "url": "https://github.com/apache/kafka/pull/8841#discussion_r440993780", "createdAt": "2020-06-16T16:42:18Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -924,10 +949,19 @@ default FetchState transitionTo(FetchState newState) {\n             }\n         }\n \n+        /**\n+         * Return the valid states which this state can transition to\n+         */\n         Collection<FetchState> validTransitions();\n \n+        /**\n+         * Test if this state has a position", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5NjYwMw==", "bodyText": "Would it make sense to set position explicitly to null if the FetchState does not expect to have it. For example, it seems currently when we reset the offset, we leave position at whatever value it had previously. If we were initializing, then it would be null. If we had an offset out of range, it would be non-null. It might be easier to reason about the logic if it is always null in the AWAIT_RESET state.", "url": "https://github.com/apache/kafka/pull/8841#discussion_r440996603", "createdAt": "2020-06-16T16:46:56Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -745,6 +745,9 @@ private void transitionState(FetchState newState, Runnable runIfTransitioned) {\n             if (nextState.equals(newState)) {\n                 this.fetchState = nextState;\n                 runIfTransitioned.run();\n+                if (this.position == null && nextState.hasPosition()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93"}, "originalPosition": 33}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ad8e5a4fbcb7d835a70f868a7d6a41bddd8e998", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/4ad8e5a4fbcb7d835a70f868a7d6a41bddd8e998", "committedDate": "2020-06-16T19:19:43Z", "message": "Feedback from PR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56b2fca4790018429bfecf801433bf5fe0aeceb6", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/56b2fca4790018429bfecf801433bf5fe0aeceb6", "committedDate": "2020-06-16T19:19:47Z", "message": "Merge remote-tracking branch 'apache-github/trunk' into KAFKA-10123"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "994150ee13aa286713e0a608cb3b3093767cdfd3", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/994150ee13aa286713e0a608cb3b3093767cdfd3", "committedDate": "2020-06-16T20:02:13Z", "message": "Merge remote-tracking branch 'apache-github/trunk' into KAFKA-10123"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e12d62f270f029de1f9ee995f04fb24f2329bce2", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/e12d62f270f029de1f9ee995f04fb24f2329bce2", "committedDate": "2020-06-16T20:02:45Z", "message": "Merge remote-tracking branch 'mumrah/KAFKA-10123' into KAFKA-10123"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxODU4MzEx", "url": "https://github.com/apache/kafka/pull/8841#pullrequestreview-431858311", "createdAt": "2020-06-16T20:16:44Z", "commit": {"oid": "e12d62f270f029de1f9ee995f04fb24f2329bce2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMDoxNjo0NFrOGkrlRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMDoxNjo0NFrOGkrlRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNTk3Mw==", "bodyText": "nit: maybe we could check for null first so that we avoid the nesting below (and reduce the diff)\nif (position == null)\n  throw new IllegalStateException(\"Missing position for fetchable partition \" + completedFetch.partition);\n\nif (completedFetch.nextFetchOffset == position.offset) {\n...", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441115973", "createdAt": "2020-06-16T20:16:44Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -675,36 +676,40 @@ private ListOffsetResult fetchOffsetsByTimes(Map<TopicPartition, Long> timestamp\n                     completedFetch.partition);\n         } else {\n             FetchPosition position = subscriptions.position(completedFetch.partition);\n-            if (completedFetch.nextFetchOffset == position.offset) {\n-                List<ConsumerRecord<K, V>> partRecords = completedFetch.fetchRecords(maxRecords);\n-\n-                log.trace(\"Returning {} fetched records at offset {} for assigned partition {}\",\n-                        partRecords.size(), position, completedFetch.partition);\n-\n-                if (completedFetch.nextFetchOffset > position.offset) {\n-                    FetchPosition nextPosition = new FetchPosition(\n-                            completedFetch.nextFetchOffset,\n-                            completedFetch.lastEpoch,\n-                            position.currentLeader);\n-                    log.trace(\"Update fetching position to {} for partition {}\", nextPosition, completedFetch.partition);\n-                    subscriptions.position(completedFetch.partition, nextPosition);\n-                }\n+            if (position != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e12d62f270f029de1f9ee995f04fb24f2329bce2"}, "originalPosition": 35}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9885fa68582b988852b3da01796119b57df53fba", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/9885fa68582b988852b3da01796119b57df53fba", "committedDate": "2020-06-16T22:59:36Z", "message": "Reduce diff on Fetcher#fetchRecords"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf29e79c4e00c34b800280f533b8c3fcf6becbd9", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/bf29e79c4e00c34b800280f533b8c3fcf6becbd9", "committedDate": "2020-06-17T13:43:39Z", "message": "Update/remove assertions relating to position after a reset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "10f1e90d0288747c579dd760701e6c0f29052ba4", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/10f1e90d0288747c579dd760701e6c0f29052ba4", "committedDate": "2020-06-17T14:29:39Z", "message": "Checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyNTcyMTAx", "url": "https://github.com/apache/kafka/pull/8841#pullrequestreview-432572101", "createdAt": "2020-06-17T16:29:12Z", "commit": {"oid": "10f1e90d0288747c579dd760701e6c0f29052ba4"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxNjoyOToxMlrOGlNpUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxNjo1NjoyMVrOGlOrNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY3NDA2Ng==", "bodyText": "Hmm, if the position is null, we raise out of range?", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441674066", "createdAt": "2020-06-17T16:29:12Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -1281,11 +1291,12 @@ private CompletedFetch initializeCompletedFetch(CompletedFetch nextCompletedFetc\n                 Optional<Integer> clearedReplicaId = subscriptions.clearPreferredReadReplica(tp);\n                 if (!clearedReplicaId.isPresent()) {\n                     // If there's no preferred replica to clear, we're fetching from the leader so handle this error normally\n-                    if (fetchOffset != subscriptions.position(tp).offset) {\n+                    FetchPosition position = subscriptions.position(tp);\n+                    if (position != null && fetchOffset != position.offset) {\n                         log.debug(\"Discarding stale fetch response for partition {} since the fetched offset {} \" +\n-                                \"does not match the current offset {}\", tp, fetchOffset, subscriptions.position(tp));\n+                                \"does not match the current offset {}\", tp, fetchOffset, position);\n                     } else {\n-                        handleOffsetOutOfRange(subscriptions.position(tp), tp, \"error response in offset fetch\");\n+                        handleOffsetOutOfRange(position, tp, \"error response in offset fetch\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10f1e90d0288747c579dd760701e6c0f29052ba4"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY3NDc2OA==", "bodyText": "nit: rename variable as well?", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441674768", "createdAt": "2020-06-17T16:30:23Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java", "diffHunk": "@@ -783,7 +783,7 @@ public boolean rejoinNeededOrPending() {\n      * @return true iff the operation completed within the timeout\n      */\n     public boolean refreshCommittedOffsetsIfNeeded(Timer timer) {\n-        final Set<TopicPartition> missingFetchPositions = subscriptions.missingFetchPositions();\n+        final Set<TopicPartition> missingFetchPositions = subscriptions.initializingPartitions();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10f1e90d0288747c579dd760701e6c0f29052ba4"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY4MDYxOA==", "bodyText": "nit: document return", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441680618", "createdAt": "2020-06-17T16:40:07Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -782,6 +787,13 @@ private void reset(OffsetResetStrategy strategy) {\n             });\n         }\n \n+        /**\n+         * Check if the position exists and needs to be validated. If so, enter the AWAIT_VALIDATION state. This method\n+         * also will update the position with the current leader and epoch.\n+         *\n+         * @param currentLeaderAndEpoch leader and epoch to compare the offset with\n+         * @return", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10f1e90d0288747c579dd760701e6c0f29052ba4"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY4MzY1Mg==", "bodyText": "+1. Moving this into the transition function below seems reasonable.", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441683652", "createdAt": "2020-06-17T16:44:51Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -799,6 +806,21 @@ private boolean maybeValidatePosition(Metadata.LeaderAndEpoch currentLeaderAndEp\n             return this.fetchState.equals(FetchStates.AWAIT_VALIDATION);\n         }\n \n+        /**\n+         * For older versions of the API, we cannot perform offset validation so we simply transition directly to FETCHING\n+         *\n+         * @param currentLeaderAndEpoch\n+         */\n+        private void updatePositionLeaderNoValidation(Metadata.LeaderAndEpoch currentLeaderAndEpoch) {\n+            if (position != null && !position.currentLeader.equals(currentLeaderAndEpoch)) {\n+                FetchPosition newPosition = new FetchPosition(position.offset, position.offsetEpoch, currentLeaderAndEpoch);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxODYxMA=="}, "originalCommit": {"oid": "034ca938e91dc6f81440b39733e29028a1729bca"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY4NDA2Mw==", "bodyText": "nit: fix doc", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441684063", "createdAt": "2020-06-17T16:45:30Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -924,10 +951,19 @@ default FetchState transitionTo(FetchState newState) {\n             }\n         }\n \n+        /**\n+         * Return the valid states which this state can transition to\n+         */\n         Collection<FetchState> validTransitions();\n \n-        boolean hasPosition();\n+        /**\n+         * Test if this state has a position", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10f1e90d0288747c579dd760701e6c0f29052ba4"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY5MDkzNA==", "bodyText": "This test would might be more interesting if we did a seek which required validation. Could we provide an epoch in the fetch position? Maybe both cases should be covered?", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441690934", "createdAt": "2020-06-17T16:56:21Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/SubscriptionStateTest.java", "diffHunk": "@@ -673,4 +673,37 @@ public void onPartitionsRevoked(Collection<TopicPartition> partitions) {\n \n     }\n \n+    @Test\n+    public void resetOffsetNoValidation() {\n+        // Check that offset reset works when we can't validate offsets (older brokers)\n+\n+        Node broker1 = new Node(1, \"localhost\", 9092);\n+        state.assignFromUser(Collections.singleton(tp0));\n+\n+        // Reset offsets\n+        state.requestOffsetReset(tp0, OffsetResetStrategy.EARLIEST);\n+\n+        // Attempt to validate with older API version, should do nothing\n+        ApiVersions oldApis = new ApiVersions();\n+        oldApis.update(\"1\", NodeApiVersions.create(ApiKeys.OFFSET_FOR_LEADER_EPOCH.id, (short) 0, (short) 2));\n+        assertFalse(state.maybeValidatePositionForCurrentLeader(oldApis, tp0, new Metadata.LeaderAndEpoch(\n+                Optional.of(broker1), Optional.empty())));\n+        assertFalse(state.hasValidPosition(tp0));\n+        assertFalse(state.awaitingValidation(tp0));\n+        assertTrue(state.isOffsetResetNeeded(tp0));\n+\n+        // Complete the reset via unvalidated seek\n+        state.seekUnvalidated(tp0, new SubscriptionState.FetchPosition(10L));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10f1e90d0288747c579dd760701e6c0f29052ba4"}, "originalPosition": 51}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "332aeffedcbe435eafab63be4f51e7f4449e9891", "author": {"user": {"login": "mumrah", "name": "David Arthur"}}, "url": "https://github.com/apache/kafka/commit/332aeffedcbe435eafab63be4f51e7f4449e9891", "committedDate": "2020-06-17T18:55:26Z", "message": "Feedback from PR"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyOTEzMjQx", "url": "https://github.com/apache/kafka/pull/8841#pullrequestreview-432913241", "createdAt": "2020-06-18T03:20:06Z", "commit": {"oid": "332aeffedcbe435eafab63be4f51e7f4449e9891"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 560, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}