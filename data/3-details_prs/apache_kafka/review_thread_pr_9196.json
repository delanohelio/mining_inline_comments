{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY5MzYzMDU0", "number": 9196, "reviewThreads": {"totalCount": 35, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0MDowMVrOEbNqkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwODo0MDoyM1rOEf4uZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcwODk2OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/benchmarks/core/benchmark_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0MDowMVrOHFE-hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoyMDo1MlrOHFLQWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjQ3MA==", "bodyText": "No need to explicit conversion to int (result is already int)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086470", "createdAt": "2020-08-22T12:40:01Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/benchmarks/core/benchmark_test.py", "diffHunk": "@@ -88,7 +88,7 @@ def test_producer_throughput(self, acks, topic, num_producers=1, message_size=DE\n         self.validate_versions(client_version, broker_version)\n         self.start_kafka(security_protocol, security_protocol, broker_version, tls_version)\n         # Always generate the same total amount of data\n-        nrecords = int(self.target_data_size / message_size)\n+        nrecords = int(self.target_data_size // message_size)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTMzNw==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189337", "createdAt": "2020-08-23T08:20:52Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/benchmarks/core/benchmark_test.py", "diffHunk": "@@ -88,7 +88,7 @@ def test_producer_throughput(self, acks, topic, num_producers=1, message_size=DE\n         self.validate_versions(client_version, broker_version)\n         self.start_kafka(security_protocol, security_protocol, broker_version, tls_version)\n         # Always generate the same total amount of data\n-        nrecords = int(self.target_data_size / message_size)\n+        nrecords = int(self.target_data_size // message_size)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjQ3MA=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcwOTcyOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/monitor/http.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0MDo0OVrOHFE-4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoyMTowMVrOHFLQXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU2MQ==", "bodyText": "redundant conversion to iterator (.items() is already iterable)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086561", "createdAt": "2020-08-22T12:40:49Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -114,7 +114,7 @@ def metrics(self, host=None, client_id=None, name=None, group=None, tags=None):\n         Get any collected metrics that match the specified parameters, yielding each as a tuple of\n         (key, [<timestamp, value>, ...]) values.\n         \"\"\"\n-        for k, values in self._http_metrics.iteritems():\n+        for k, values in iter(self._http_metrics.items()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTM0MQ==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189341", "createdAt": "2020-08-23T08:21:01Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -114,7 +114,7 @@ def metrics(self, host=None, client_id=None, name=None, group=None, tags=None):\n         Get any collected metrics that match the specified parameters, yielding each as a tuple of\n         (key, [<timestamp, value>, ...]) values.\n         \"\"\"\n-        for k, values in self._http_metrics.iteritems():\n+        for k, values in iter(self._http_metrics.items()):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU2MQ=="}, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcwOTkzOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/monitor/http.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0MDo1OVrOHFE-9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoyMTowOVrOHFLQbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU4Mw==", "bodyText": "Same as above + tuple can be constructed from generator, no need to create list for that\nJust use tuple(raw_metric['tags'].items())", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086583", "createdAt": "2020-08-22T12:40:59Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -154,7 +154,7 @@ def do_POST(self):\n             name = raw_metric['name']\n             group = raw_metric['group']\n             # Convert to tuple of pairs because dicts & lists are unhashable\n-            tags = tuple([(k, v) for k, v in raw_metric['tags'].iteritems()]),\n+            tags = tuple([(k, v) for k, v in iter(raw_metric['tags'].items())]),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTM1OA==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189358", "createdAt": "2020-08-23T08:21:09Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -154,7 +154,7 @@ def do_POST(self):\n             name = raw_metric['name']\n             group = raw_metric['group']\n             # Convert to tuple of pairs because dicts & lists are unhashable\n-            tags = tuple([(k, v) for k, v in raw_metric['tags'].iteritems()]),\n+            tags = tuple([(k, v) for k, v in iter(raw_metric['tags'].items())]),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU4Mw=="}, "originalCommit": null, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMTUzOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/performance/producer_performance.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0MzoxMVrOHFE_tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODo1Mzo1OVrOHFLc_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njc3NA==", "bodyText": "No need to create iterator from items(), join can accept generator easily, no need to convert it to list.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086774", "createdAt": "2020-08-22T12:43:11Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/performance/producer_performance.py", "diffHunk": "@@ -78,7 +78,7 @@ def start_cmd(self, node):\n             'bootstrap_servers': self.kafka.bootstrap_servers(self.security_config.security_protocol),\n             'client_id': self.client_id,\n             'kafka_run_class': self.path.script(\"kafka-run-class.sh\", node),\n-            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.iteritems()])\n+            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in iter(self.http_metrics_client_configs.items())])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjU3Mg==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192572", "createdAt": "2020-08-23T08:53:59Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/performance/producer_performance.py", "diffHunk": "@@ -78,7 +78,7 @@ def start_cmd(self, node):\n             'bootstrap_servers': self.kafka.bootstrap_servers(self.security_config.security_protocol),\n             'client_id': self.client_id,\n             'kafka_run_class': self.path.script(\"kafka-run-class.sh\", node),\n-            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.iteritems()])\n+            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in iter(self.http_metrics_client_configs.items())])", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njc3NA=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMjA1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/security/security_config.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NDoxN1rOHFE_-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMzo0OVrOHFLNnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg0MA==", "bodyText": "No need to create iterator from iterable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086840", "createdAt": "2020-08-22T12:44:17Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/security/security_config.py", "diffHunk": "@@ -362,7 +362,7 @@ def props(self, prefix=''):\n             return \"\"\n         if self.has_sasl and not self.static_jaas_conf and 'sasl.jaas.config' not in self.properties:\n             raise Exception(\"JAAS configuration property has not yet been initialized\")\n-        config_lines = (prefix + key + \"=\" + value for key, value in self.properties.iteritems())\n+        config_lines = (prefix + key + \"=\" + value for key, value in iter(self.properties.items()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODYzNg==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188636", "createdAt": "2020-08-23T08:13:49Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/security/security_config.py", "diffHunk": "@@ -362,7 +362,7 @@ def props(self, prefix=''):\n             return \"\"\n         if self.has_sasl and not self.static_jaas_conf and 'sasl.jaas.config' not in self.properties:\n             raise Exception(\"JAAS configuration property has not yet been initialized\")\n-        config_lines = (prefix + key + \"=\" + value for key, value in self.properties.iteritems())\n+        config_lines = (prefix + key + \"=\" + value for key, value in iter(self.properties.items()))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg0MA=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMjM0OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/verifiable_consumer.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NDo1MVrOHFFAIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMzo0MlrOHFLNfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg4Mg==", "bodyText": "No need to create iterator from iterable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086882", "createdAt": "2020-08-22T12:44:51Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -361,7 +361,7 @@ def clean_node(self, node):\n \n     def current_assignment(self):\n         with self.lock:\n-            return { handler.node: handler.current_assignment() for handler in self.event_handlers.itervalues() }\n+            return { handler.node: handler.current_assignment() for handler in iter(self.event_handlers.values()) }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODYwNg==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188606", "createdAt": "2020-08-23T08:13:42Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -361,7 +361,7 @@ def clean_node(self, node):\n \n     def current_assignment(self):\n         with self.lock:\n-            return { handler.node: handler.current_assignment() for handler in self.event_handlers.itervalues() }\n+            return { handler.node: handler.current_assignment() for handler in iter(self.event_handlers.values()) }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg4Mg=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMjU3OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/verifiable_consumer.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NTowNVrOHFFAOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMzozNFrOHFLNdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkwNg==", "bodyText": "No need to create iterator from iterable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086906", "createdAt": "2020-08-22T12:45:05Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -372,7 +372,7 @@ def current_position(self, tp):\n \n     def owner(self, tp):\n         with self.lock:\n-            for handler in self.event_handlers.itervalues():\n+            for handler in iter(self.event_handlers.values()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODU5OQ==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188599", "createdAt": "2020-08-23T08:13:34Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -372,7 +372,7 @@ def current_position(self, tp):\n \n     def owner(self, tp):\n         with self.lock:\n-            for handler in self.event_handlers.itervalues():\n+            for handler in iter(self.event_handlers.values()):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkwNg=="}, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMjc0OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/verifiable_consumer.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NToxM1rOHFFATQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMzoyMlrOHFLNXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkyNQ==", "bodyText": "Same as above.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086925", "createdAt": "2020-08-22T12:45:13Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODU3NQ==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188575", "createdAt": "2020-08-23T08:13:22Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkyNQ=="}, "originalCommit": null, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMjk5OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/verifiable_consumer.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NToyMVrOHFFAZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMzoxNVrOHFLNTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk1MQ==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086951", "createdAt": "2020-08-22T12:45:21Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODU1OA==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188558", "createdAt": "2020-08-23T08:13:15Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk1MQ=="}, "originalCommit": null, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMzExOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/verifiable_consumer.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NToyOVrOHFFAdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMjoyM1rOHFLNFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk2Nw==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086967", "createdAt": "2020-08-22T12:45:29Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODUwMg==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188502", "createdAt": "2020-08-23T08:12:23Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk2Nw=="}, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMzMzOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/verifiable_consumer.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NTo0MFrOHFFAjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMjoxNFrOHFLNDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk4OQ==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086989", "createdAt": "2020-08-22T12:45:40Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODQ5NQ==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188495", "createdAt": "2020-08-23T08:12:14Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk4OQ=="}, "originalCommit": null, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMzQyOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/verifiable_consumer.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NTo0OFrOHFFAlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMjowNlrOHFLNAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk5OQ==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086999", "createdAt": "2020-08-22T12:45:48Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Rebalancing]\n \n     def dead_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODQ4Mg==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188482", "createdAt": "2020-08-23T08:12:06Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Rebalancing]\n \n     def dead_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk5OQ=="}, "originalCommit": null, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMzcxOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/verifiable_consumer.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NTo1NlrOHFFAtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMTo1NVrOHFLM8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzMQ==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087031", "createdAt": "2020-08-22T12:45:56Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Rebalancing]\n \n     def dead_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Dead]\n \n     def alive_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODQ2NQ==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188465", "createdAt": "2020-08-23T08:11:55Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Rebalancing]\n \n     def dead_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Dead]\n \n     def alive_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzMQ=="}, "originalCommit": null, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxMzc1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0NjoyMFrOHFFAvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMDo0MlrOHFLMdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzOA==", "bodyText": "No need to create iterator from iterable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087038", "createdAt": "2020-08-22T12:46:20Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "diffHunk": "@@ -86,14 +88,14 @@ def invoke_compatibility_program(self, features):\n                \"--topic %s \" % (self.zk.path.script(\"kafka-run-class.sh\", node),\n                                self.kafka.bootstrap_servers(),\n                                len(self.kafka.nodes),\n-                               self.topics.keys()[0]))\n-        for k, v in features.iteritems():\n+                               [*self.topics.keys()][0]))\n+        for k, v in iter(features.items()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODM0Mw==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188343", "createdAt": "2020-08-23T08:10:42Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "diffHunk": "@@ -86,14 +88,14 @@ def invoke_compatibility_program(self, features):\n                \"--topic %s \" % (self.zk.path.script(\"kafka-run-class.sh\", node),\n                                self.kafka.bootstrap_servers(),\n                                len(self.kafka.nodes),\n-                               self.topics.keys()[0]))\n-        for k, v in features.iteritems():\n+                               [*self.topics.keys()][0]))\n+        for k, v in iter(features.items()):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzOA=="}, "originalCommit": null, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxNDg2OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0ODozNVrOHFFBVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODo1MzowNVrOHFLcpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzE5MA==", "bodyText": "I suppose that next(iter(self.topics.keys())) is more readable, than this mix of brackets and stars", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087190", "createdAt": "2020-08-22T12:48:35Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "diffHunk": "@@ -86,14 +88,14 @@ def invoke_compatibility_program(self, features):\n                \"--topic %s \" % (self.zk.path.script(\"kafka-run-class.sh\", node),\n                                self.kafka.bootstrap_servers(),\n                                len(self.kafka.nodes),\n-                               self.topics.keys()[0]))\n-        for k, v in features.iteritems():\n+                               [*self.topics.keys()][0]))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjQ4NA==", "bodyText": "I made it list(self.topics.keys())[0] which seems even more readable.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192484", "createdAt": "2020-08-23T08:53:05Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "diffHunk": "@@ -86,14 +88,14 @@ def invoke_compatibility_program(self, features):\n                \"--topic %s \" % (self.zk.path.script(\"kafka-run-class.sh\", node),\n                                self.kafka.bootstrap_servers(),\n                                len(self.kafka.nodes),\n-                               self.topics.keys()[0]))\n-        for k, v in features.iteritems():\n+                               [*self.topics.keys()][0]))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzE5MA=="}, "originalCommit": null, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxNTA4OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/client/quota_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0ODo1OVrOHFFBcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMDoyNlrOHFLMVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzIxNg==", "bodyText": "No need to create iterator", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087216", "createdAt": "2020-08-22T12:48:59Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/client/quota_test.py", "diffHunk": "@@ -162,7 +162,7 @@ def test_quota(self, quota_type, override_quota=True, producer_num=1, consumer_n\n             jmx_attributes=['bytes-consumed-rate'], version=client_version)\n         consumer.run()\n \n-        for idx, messages in consumer.messages_consumed.iteritems():\n+        for idx, messages in iter(consumer.messages_consumed.items()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODMwOA==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188308", "createdAt": "2020-08-23T08:10:26Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/client/quota_test.py", "diffHunk": "@@ -162,7 +162,7 @@ def test_quota(self, quota_type, override_quota=True, producer_num=1, consumer_n\n             jmx_attributes=['bytes-consumed-rate'], version=client_version)\n         consumer.run()\n \n-        for idx, messages in consumer.messages_consumed.iteritems():\n+        for idx, messages in iter(consumer.messages_consumed.items()):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzIxNg=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxNjY5OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo1MDo1M1rOHFFCLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoyMzoxOFrOHFLRDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzQwNA==", "bodyText": "src_seqno_max = max(src_seqnos) if len(src_seqnos) else 0 is more readable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087404", "createdAt": "2020-08-22T12:50:53Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,14 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            if len(src_seqnos) == 0:\n+                src_seqno_max = 0\n+            else:\n+                src_seqno_max = max(src_seqnos)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTUxNw==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189517", "createdAt": "2020-08-23T08:23:18Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,14 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            if len(src_seqnos) == 0:\n+                src_seqno_max = 0\n+            else:\n+                src_seqno_max = max(src_seqnos)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzQwNA=="}, "originalCommit": null, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxNzkyOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo1MzoyMFrOHFFCxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODo1MzozNlrOHFLc1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzU1OQ==", "bodyText": "No need to create list and iterator, just\nsorted(seqno for seqno, count in src_seqno_counts.items() if count > 1)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087559", "createdAt": "2020-08-22T12:53:20Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,14 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            if len(src_seqnos) == 0:\n+                src_seqno_max = 0\n+            else:\n+                src_seqno_max = max(src_seqnos)\n             self.logger.debug(\"Max source seqno: %d\", src_seqno_max)\n             src_seqno_counts = Counter(src_seqnos)\n             missing_src_seqnos = sorted(set(range(src_seqno_max)).difference(set(src_seqnos)))\n-            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.iteritems() if count > 1])\n+            duplicate_src_seqnos = sorted([seqno for seqno,count in iter(src_seqno_counts.items()) if count > 1])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjUzMg==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192532", "createdAt": "2020-08-23T08:53:36Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,14 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            if len(src_seqnos) == 0:\n+                src_seqno_max = 0\n+            else:\n+                src_seqno_max = max(src_seqnos)\n             self.logger.debug(\"Max source seqno: %d\", src_seqno_max)\n             src_seqno_counts = Counter(src_seqnos)\n             missing_src_seqnos = sorted(set(range(src_seqno_max)).difference(set(src_seqnos)))\n-            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.iteritems() if count > 1])\n+            duplicate_src_seqnos = sorted([seqno for seqno,count in iter(src_seqno_counts.items()) if count > 1])", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzU1OQ=="}, "originalCommit": null, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxODUzOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/end_to_end.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo1NDoyM1rOHFFDGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoyMzo0M1rOHFLRKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzY0Mw==", "bodyText": "No need to create iterator", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087643", "createdAt": "2020-08-22T12:54:23Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/end_to_end.py", "diffHunk": "@@ -87,7 +85,7 @@ def on_record_consumed(self, record, node):\n \n     def await_consumed_offsets(self, last_acked_offsets, timeout_sec):\n         def has_finished_consuming():\n-            for partition, offset in last_acked_offsets.iteritems():\n+            for partition, offset in iter(last_acked_offsets.items()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTU0Nw==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189547", "createdAt": "2020-08-23T08:23:43Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/end_to_end.py", "diffHunk": "@@ -87,7 +85,7 @@ def on_record_consumed(self, record, node):\n \n     def await_consumed_offsets(self, last_acked_offsets, timeout_sec):\n         def has_finished_consuming():\n-            for partition, offset in last_acked_offsets.iteritems():\n+            for partition, offset in iter(last_acked_offsets.items()):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzY0Mw=="}, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxOTM1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo1NToyN1rOHFFDgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMDowN1rOHFLMOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc0NA==", "bodyText": "list(self.topics.keys())[topic_index] is more readable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087744", "createdAt": "2020-08-22T12:55:27Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "diffHunk": "@@ -119,7 +119,7 @@ def __init__(self, test_context):\n     def fail_broker_type(self, failure_mode, broker_type):\n         # Pick a random topic and bounce it's leader\n         topic_index = randint(0, len(self.topics.keys()) - 1)\n-        topic = self.topics.keys()[topic_index]\n+        topic = [*self.topics.keys()][topic_index]", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODI4MA==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188280", "createdAt": "2020-08-23T08:10:07Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "diffHunk": "@@ -119,7 +119,7 @@ def __init__(self, test_context):\n     def fail_broker_type(self, failure_mode, broker_type):\n         # Pick a random topic and bounce it's leader\n         topic_index = randint(0, len(self.topics.keys()) - 1)\n-        topic = self.topics.keys()[topic_index]\n+        topic = [*self.topics.keys()][topic_index]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc0NA=="}, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcxOTYwOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/verifiable_consumer_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo1NTo0MlrOHFFDng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODoxMDoxNFrOHFLMQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc3NA==", "bodyText": "No need to create iterator", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087774", "createdAt": "2020-08-22T12:55:42Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/verifiable_consumer_test.py", "diffHunk": "@@ -40,7 +40,7 @@ def _all_partitions(self, topic, num_partitions):\n \n     def _partitions(self, assignment):\n         partitions = []\n-        for parts in assignment.itervalues():\n+        for parts in iter(assignment.values()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODI4OA==", "bodyText": "fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188288", "createdAt": "2020-08-23T08:10:14Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/verifiable_consumer_test.py", "diffHunk": "@@ -40,7 +40,7 @@ def _all_partitions(self, topic, num_partitions):\n \n     def _partitions(self, assignment):\n         partitions = []\n-        for parts in assignment.itervalues():\n+        for parts in iter(assignment.values()):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc3NA=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcyMDI1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/version.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo1Njo1M1rOHFFD8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwODo0OTo1MFrOHFLbWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzg1OA==", "bodyText": "If you start to refactor this class, may be refactor also call to super constructor? LooseVersion is now normal class (in python3). Just super().__init__(version_string)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087858", "createdAt": "2020-08-22T12:56:53Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjE1NQ==", "bodyText": "There is no refactoring here :)\nMy goal is just to make python3 works for current tests.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192155", "createdAt": "2020-08-23T08:49:50Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzg1OA=="}, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTcyNjM3OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/version.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMzowNjowNFrOHFFGwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxOTozNlrOHFLm8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4ODU3Nw==", "bodyText": "You do not need all these functions above, if you call super method properly super()._cmp(other)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475088577", "createdAt": "2020-08-22T13:06:04Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):\n+        return self._cmp(other) == 0\n+\n+    def __lt__(self, other):\n+        return self._cmp(other) < 0\n+\n+    def __le__(self, other):\n+        return self._cmp(other) <= 0\n+\n+    def __gt__(self, other):\n+        return self._cmp(other) > 0\n+\n+    def __ge__(self, other):\n+        return self._cmp(other) >= 0\n+\n+    def _cmp(self, other):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjMxNg==", "bodyText": "Thanks.\nIt seems we can just override _cmp and that's it.\nI will double-check it with the tests run.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192316", "createdAt": "2020-08-23T08:51:20Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):\n+        return self._cmp(other) == 0\n+\n+    def __lt__(self, other):\n+        return self._cmp(other) < 0\n+\n+    def __le__(self, other):\n+        return self._cmp(other) <= 0\n+\n+    def __gt__(self, other):\n+        return self._cmp(other) > 0\n+\n+    def __ge__(self, other):\n+        return self._cmp(other) >= 0\n+\n+    def _cmp(self, other):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4ODU3Nw=="}, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTEyMA==", "bodyText": "Yes, but I don't understand why not call super methods properly, this approach is outdated even for python 2.7", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195120", "createdAt": "2020-08-23T09:19:36Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):\n+        return self._cmp(other) == 0\n+\n+    def __lt__(self, other):\n+        return self._cmp(other) < 0\n+\n+    def __le__(self, other):\n+        return self._cmp(other) <= 0\n+\n+    def __gt__(self, other):\n+        return self._cmp(other) > 0\n+\n+    def __ge__(self, other):\n+        return self._cmp(other) >= 0\n+\n+    def _cmp(self, other):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4ODU3Nw=="}, "originalCommit": null, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MDYwMzk3OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/performance/producer_performance.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxNToxM1rOHFLlSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxNToxM1rOHFLlSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NDY5Ng==", "bodyText": "You don't have to create list in order to use join, just\n ' '.join(\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.items())\nOr, even better, just\n ' '.join(\"%s=%s\" % kv for kv in self.http_metrics_client_configs.items())", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475194696", "createdAt": "2020-08-23T09:15:13Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/performance/producer_performance.py", "diffHunk": "@@ -78,7 +78,7 @@ def start_cmd(self, node):\n             'bootstrap_servers': self.kafka.bootstrap_servers(self.security_config.security_protocol),\n             'client_id': self.client_id,\n             'kafka_run_class': self.path.script(\"kafka-run-class.sh\", node),\n-            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.iteritems()])\n+            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.items()])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MDYwNTc1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/monitor/http.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxNzowM1rOHFLmFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxNzowM1rOHFLmFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NDkwMw==", "bodyText": "You don't have to create list here, use generator as ctor args :\ntags = tuple(raw_metric['tags'].items())", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475194903", "createdAt": "2020-08-23T09:17:03Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -154,7 +154,7 @@ def do_POST(self):\n             name = raw_metric['name']\n             group = raw_metric['group']\n             # Convert to tuple of pairs because dicts & lists are unhashable\n-            tags = tuple([(k, v) for k, v in raw_metric['tags'].iteritems()]),\n+            tags = tuple([(k, v) for k, v in raw_metric['tags'].items()]),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MDYwNjU2OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxODoxMlrOHFLmfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxODoxMlrOHFLmfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTAwNw==", "bodyText": "Rewrite please it like this:\nsorted(seqno for seqno,count in sink_seqno_counts.items() if count > 1)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195007", "createdAt": "2020-08-23T09:18:12Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -440,11 +441,11 @@ def test_bounce(self, clean, connect_protocol):\n             sink_seqnos = [msg['seqno'] for msg in sink_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because\n             # clean bouncing should commit on rebalance.\n-            sink_seqno_max = max(sink_seqnos)\n+            sink_seqno_max = max(sink_seqnos) if len(sink_seqnos) else 0\n             self.logger.debug(\"Max sink seqno: %d\", sink_seqno_max)\n             sink_seqno_counts = Counter(sink_seqnos)\n             missing_sink_seqnos = sorted(set(range(sink_seqno_max)).difference(set(sink_seqnos)))\n-            duplicate_sink_seqnos = sorted([seqno for seqno,count in sink_seqno_counts.iteritems() if count > 1])\n+            duplicate_sink_seqnos = sorted([seqno for seqno,count in iter(sink_seqno_counts.items()) if count > 1])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MDYwNjc1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxODoyOFrOHFLmlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxODoyOFrOHFLmlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTAyOQ==", "bodyText": "Rewrite please it like this:\nsorted(seqno for seqno,count in iter(sink_seqno_counts.items()) if count > 1)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195029", "createdAt": "2020-08-23T09:18:28Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,11 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            src_seqno_max = max(src_seqnos) if len(src_seqnos) else 0\n             self.logger.debug(\"Max source seqno: %d\", src_seqno_max)\n             src_seqno_counts = Counter(src_seqnos)\n             missing_src_seqnos = sorted(set(range(src_seqno_max)).difference(set(src_seqnos)))\n-            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.iteritems() if count > 1])\n+            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.items() if count > 1])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MDYxMzgxOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/verifiable_consumer.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToyNzozNVrOHFLqGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToyNzozNVrOHFLqGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTkyOQ==", "bodyText": "Please, remove list creation here also", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195929", "createdAt": "2020-08-23T09:27:35Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in self.event_handlers.values())\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in self.event_handlers.values())\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in self.event_handlers.values()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MDYxNTYxOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/verifiable_consumer_test.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOTozMDowNlrOHFLq-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOTozMDowNlrOHFLq-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NjE1Mg==", "bodyText": "You don't fix it, unfortunatelly", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475196152", "createdAt": "2020-08-23T09:30:06Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/verifiable_consumer_test.py", "diffHunk": "@@ -40,7 +40,7 @@ def _all_partitions(self, topic, num_partitions):\n \n     def _partitions(self, assignment):\n         partitions = []\n-        for parts in assignment.itervalues():\n+        for parts in iter(assignment.values()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3MDg2NDE1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/utils/__init__.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QxNDozNjo1OVrOHFNkNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QxNDozNjo1OVrOHFNkNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTIyNzE5MA==", "bodyText": "Oops, forgot new line...", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475227190", "createdAt": "2020-08-23T14:36:59Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/utils/__init__.py", "diffHunk": "@@ -13,4 +13,4 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-from util import kafkatest_version, is_version, is_int, is_int_with_prefix, node_is_reachable, validate_delivery\n+from .util import kafkatest_version, is_version, is_int, is_int_with_prefix, node_is_reachable, validate_delivery", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxODY0NjM0OnYy", "diffSide": "RIGHT", "path": "tests/docker/Dockerfile", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwODoyNDo0MlrOHMbsoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxMTozNjoxN1rOHMihmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5ODc1Mw==", "bodyText": "Add a comment explaining why the hold is necssary.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482798753", "createdAt": "2020-09-03T08:24:42Z", "author": {"login": "edenhill"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjkxMDYxNg==", "bodyText": "I tried to prevent python2 packages from install.\nBut, actually, we don't need this line.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482910616", "createdAt": "2020-09-03T11:36:17Z", "author": {"login": "nizhikov"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5ODc1Mw=="}, "originalCommit": null, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxODY1MjgwOnYy", "diffSide": "RIGHT", "path": "tests/docker/Dockerfile", "isResolved": true, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwODoyNjoxMlrOHMbwkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxMjoxOTo1M1rOHZqVzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw==", "bodyText": "Should ducktape no longer be version pinned? (it probably needs to be to avoid future build breakages of old kafka branches).\nOr is this just during Python3-ification of ducktape itself?", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482799763", "createdAt": "2020-09-03T08:26:12Z", "author": {"login": "edenhill"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg0NDUwOA==", "bodyText": "Should ducktape no longer be version pinned?\n\nNo. We should continue to use a specific version of the ducktape.\nCurrently, master branch of the ducktape contains unreleased fixes for python3.\nPlease, see the issue for details - confluentinc/ducktape#245\nOnce fixes will be released I will pin PR to a specific version.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482844508", "createdAt": "2020-09-03T09:35:41Z", "author": {"login": "nizhikov"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQzMjQwOA==", "bodyText": "Great!\nSuggest updating the title of this PR to include [DO NOT MERGE] until the ducktape version is updated.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r483432408", "createdAt": "2020-09-04T07:14:50Z", "author": {"login": "edenhill"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQ3NDQ4OA==", "bodyText": "Agree. Done.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r483474488", "createdAt": "2020-09-04T08:38:42Z", "author": {"login": "nizhikov"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgwNDg0OA==", "bodyText": "A new ducktape version needs to be released, and this line changed to a versioned pypi install, prior to merge, right?", "url": "https://github.com/apache/kafka/pull/9196#discussion_r495804848", "createdAt": "2020-09-28T09:25:41Z", "author": {"login": "edenhill"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgyMDc3Mg==", "bodyText": "Hello, @edenhill\nYes, but I'm a bit confused about ducktape release.\nCan't receive much feedback from maintainers.\nconfluentinc/ducktape#245", "url": "https://github.com/apache/kafka/pull/9196#discussion_r495820772", "createdAt": "2020-09-28T09:52:23Z", "author": {"login": "nizhikov"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgzNjM5Nw==", "bodyText": "I'll see what I can do.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r495836397", "createdAt": "2020-09-28T10:21:00Z", "author": {"login": "edenhill"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjY3MDE1OQ==", "bodyText": "Hello! Any news on ducktape release?", "url": "https://github.com/apache/kafka/pull/9196#discussion_r496670159", "createdAt": "2020-09-29T12:19:53Z", "author": {"login": "nizhikov"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, "originalCommit": null, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxODY5NzIwOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/core/network_degrade_test.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwODozNzo0MVrOHMcL7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxMDowMjoyMlrOHMfgGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNjc2NA==", "bodyText": "nit: I believe % is a bit deprecated in favour of .format(..) or f\"This means .. {measured_rates}\" (for >=3.6).", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482806764", "createdAt": "2020-09-03T08:37:41Z", "author": {"login": "edenhill"}, "path": "tests/kafkatest/tests/core/network_degrade_test.py", "diffHunk": "@@ -129,10 +129,10 @@ def test_rate(self, task_name, device_name, latency_ms, rate_limit_kbit):\n         self.logger.info(\"Measured rates: %s\" % measured_rates)\n \n         # We expect to see measured rates within an order of magnitude of our target rate\n-        low_kbps = rate_limit_kbit / 10\n+        low_kbps = rate_limit_kbit // 10\n         high_kbps = rate_limit_kbit * 10\n         acceptable_rates = [r for r in measured_rates if low_kbps < r < high_kbps]\n \n         msg = \"Expected most of the measured rates to be within an order of magnitude of target %d.\" % rate_limit_kbit\n-        msg += \" This means `tc` did not limit the bandwidth as expected.\"\n+        msg += \" This means `tc` did not limit the bandwidth as expected. Measured rates %s\" % str(measured_rates)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg1ODUzMw==", "bodyText": "Actually, this change unrelated. Reverted.\nI just trying to debug this test, because it fails(it fails in the trunk, also).\nAnyway, I think you are right and we can rewrite all usages of \"...\" % param to the new syntax.\nLet's do it in another PR?", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482858533", "createdAt": "2020-09-03T09:58:09Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/core/network_degrade_test.py", "diffHunk": "@@ -129,10 +129,10 @@ def test_rate(self, task_name, device_name, latency_ms, rate_limit_kbit):\n         self.logger.info(\"Measured rates: %s\" % measured_rates)\n \n         # We expect to see measured rates within an order of magnitude of our target rate\n-        low_kbps = rate_limit_kbit / 10\n+        low_kbps = rate_limit_kbit // 10\n         high_kbps = rate_limit_kbit * 10\n         acceptable_rates = [r for r in measured_rates if low_kbps < r < high_kbps]\n \n         msg = \"Expected most of the measured rates to be within an order of magnitude of target %d.\" % rate_limit_kbit\n-        msg += \" This means `tc` did not limit the bandwidth as expected.\"\n+        msg += \" This means `tc` did not limit the bandwidth as expected. Measured rates %s\" % str(measured_rates)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNjc2NA=="}, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg2MTA4MQ==", "bodyText": "Until % is officially deprecated we can keep them around, no need for bulk-fixing them, but new code should preferably use f\"\" or format().\nBut that's just my opinion.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482861081", "createdAt": "2020-09-03T10:02:22Z", "author": {"login": "edenhill"}, "path": "tests/kafkatest/tests/core/network_degrade_test.py", "diffHunk": "@@ -129,10 +129,10 @@ def test_rate(self, task_name, device_name, latency_ms, rate_limit_kbit):\n         self.logger.info(\"Measured rates: %s\" % measured_rates)\n \n         # We expect to see measured rates within an order of magnitude of our target rate\n-        low_kbps = rate_limit_kbit / 10\n+        low_kbps = rate_limit_kbit // 10\n         high_kbps = rate_limit_kbit * 10\n         acceptable_rates = [r for r in measured_rates if low_kbps < r < high_kbps]\n \n         msg = \"Expected most of the measured rates to be within an order of magnitude of target %d.\" % rate_limit_kbit\n-        msg += \" This means `tc` did not limit the bandwidth as expected.\"\n+        msg += \" This means `tc` did not limit the bandwidth as expected. Measured rates %s\" % str(measured_rates)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNjc2NA=="}, "originalCommit": null, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxODcwMDA3OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/core/replica_scale_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwODozODozNVrOHMcNyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwOTo0MTo1MlrOHMeu-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNzI0Mw==", "bodyText": "Since this PR is about upgrading to Python3 it probably shouldn't modify test parameters.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482807243", "createdAt": "2020-09-03T08:38:35Z", "author": {"login": "edenhill"}, "path": "tests/kafkatest/tests/core/replica_scale_test.py", "diffHunk": "@@ -48,7 +46,7 @@ def teardown(self):\n         self.zk.stop()\n \n     @cluster(num_nodes=12)\n-    @parametrize(topic_count=500, partition_count=34, replication_factor=3)\n+    @parametrize(topic_count=100, partition_count=34, replication_factor=3)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg0ODUwNg==", "bodyText": "Sorry, I decrease this variable to be able to run this tests in the Docker, otherwise it just freeze on my machine. Fixed.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482848506", "createdAt": "2020-09-03T09:41:52Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/core/replica_scale_test.py", "diffHunk": "@@ -48,7 +46,7 @@ def teardown(self):\n         self.zk.stop()\n \n     @cluster(num_nodes=12)\n-    @parametrize(topic_count=500, partition_count=34, replication_factor=3)\n+    @parametrize(topic_count=100, partition_count=34, replication_factor=3)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNzI0Mw=="}, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxODcwNjk0OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwODo0MDoyM1rOHMcSAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxMDowNjoxMVrOHMfoXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwODMyMA==", "bodyText": "alternatively:\ntopic = random.choice(list(self.topics.keys()))", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482808320", "createdAt": "2020-09-03T08:40:23Z", "author": {"login": "edenhill"}, "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "diffHunk": "@@ -119,7 +119,7 @@ def __init__(self, test_context):\n     def fail_broker_type(self, failure_mode, broker_type):\n         # Pick a random topic and bounce it's leader\n         topic_index = randint(0, len(self.topics.keys()) - 1)\n-        topic = self.topics.keys()[topic_index]\n+        topic = list(self.topics.keys())[topic_index]", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg2MzE5Ng==", "bodyText": "I tried to do minimal changes and just fix the syntax difference between python2 and python3.\nLet's keep it to simplify ongoing reviews?", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482863196", "createdAt": "2020-09-03T10:06:11Z", "author": {"login": "nizhikov"}, "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "diffHunk": "@@ -119,7 +119,7 @@ def __init__(self, test_context):\n     def fail_broker_type(self, failure_mode, broker_type):\n         # Pick a random topic and bounce it's leader\n         topic_index = randint(0, len(self.topics.keys()) - 1)\n-        topic = self.topics.keys()[topic_index]\n+        topic = list(self.topics.keys())[topic_index]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwODMyMA=="}, "originalCommit": null, "originalPosition": 14}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1931, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}