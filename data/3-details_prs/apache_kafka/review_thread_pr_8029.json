{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY5ODYxNzIw", "number": 8029, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QxNzoyODoyOVrODgdv0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo1MDoyMVrODhKTZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MzY4NDAxOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/Suppressed.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QxNzoyODoyOVrOFqr2OA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QxNzoyODoyOVrOFqr2OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDMwMjkwNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                     * Disable the changelog for store built by this {@link StoreBuilder}.\n          \n          \n            \n                     * Disable the changelog for this suppression's internal buffer.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r380302904", "createdAt": "2020-02-17T17:28:29Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/Suppressed.java", "diffHunk": "@@ -118,6 +119,25 @@ static StrictBufferConfig unbounded() {\n          * duplicate results downstream, but does not promise to eliminate them.\n          */\n         EagerBufferConfig emitEarlyWhenFull();\n+\n+        /**\n+         * Disable the changelog for store built by this {@link StoreBuilder}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08d14a6b742b9f52d642d74bc716c7e96e8e0033"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MzY4NTk1OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/Suppressed.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QxNzoyOToyMVrOFqr3bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QxNzoyOToyMVrOFqr3bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDMwMzIxNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                     * This will turn off fault-tolerance for your store.\n          \n          \n            \n                     * This will turn off fault-tolerance for the suppression, and will result in data loss in the event of a rebalance.\n          \n      \n    \n    \n  \n\nThis isn't a \"store\", but rather a buffer internally used for suppression. Also, it seems appropriate to be a little more dire in our warning here because the internal nature of the buffer may make it less obvious to people what the downside of disabling this changelog is.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r380303214", "createdAt": "2020-02-17T17:29:21Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/Suppressed.java", "diffHunk": "@@ -118,6 +119,25 @@ static StrictBufferConfig unbounded() {\n          * duplicate results downstream, but does not promise to eliminate them.\n          */\n         EagerBufferConfig emitEarlyWhenFull();\n+\n+        /**\n+         * Disable the changelog for store built by this {@link StoreBuilder}.\n+         * This will turn off fault-tolerance for your store.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08d14a6b742b9f52d642d74bc716c7e96e8e0033"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MDk3MDMyOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo0NjoxNlrOFrxK0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo0NjoxNlrOFrxK0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzODY3Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n          \n          \n            \n                        assertThat(CLUSTER.getAllTopicsInCluster(), contains(changeLog));\n          \n      \n    \n    \n  \n\nEquivalent, but gives a better error message when it fails.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381438672", "createdAt": "2020-02-19T17:46:16Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MDk3NTI3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo0NzozNlrOFrxN8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo0NzozNlrOFrxN8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzOTQ3NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void shouldWithLoggingEnable() {\n          \n          \n            \n                public void shouldAllowOverridingChangelogConfig() {\n          \n      \n    \n    \n  \n\nNot a big deal, but it's a little nicer when the test methods explain exactly what they are testing.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381439475", "createdAt": "2020-02-19T17:47:36Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MDk3NjQyOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo0Nzo1NlrOFrxOsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo1NDowNlrOFrxcJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzOTY2Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void shouldWithLoggingDisable() {\n          \n          \n            \n                public void should createChangelogByDefault() {", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381439666", "createdAt": "2020-02-19T17:47:56Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQ0MzExMA==", "bodyText": "It seems like this test would be more useful just as an assertion of the default behavior.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381443110", "createdAt": "2020-02-19T17:54:06Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzOTY2Ng=="}, "originalCommit": null, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MDk4MDU1OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo0OTowNlrOFrxRYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo0OTowNlrOFrxRYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQ0MDM1Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            .withLoggingEnabled(Collections.emptyMap())))", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381440353", "createdAt": "2020-02-19T17:49:06Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {\n+        final String testId = \"-shouldWithLoggingDisable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingDisable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(Collections.emptyMap())))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MDk4NDA3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo1MDoyMVrOFrxT1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo1MDoyMVrOFrxT1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQ0MDk4MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        assertThat(config.getProperty(\"retention.ms\"), Matchers.is(nullValue()));\n          \n          \n            \n                        assertThat(CLUSTER.getAllTopicsInCluster(), contains(changeLog));\n          \n      \n    \n    \n  \n\nAnd we can remove line 426, final Properties config = CLUSTER.getLogConfig(changeLog);, since it would be unused.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381440981", "createdAt": "2020-02-19T17:50:21Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {\n+        final String testId = \"-shouldWithLoggingDisable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingDisable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(Collections.emptyMap())))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), Matchers.is(nullValue()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 132}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4174, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}