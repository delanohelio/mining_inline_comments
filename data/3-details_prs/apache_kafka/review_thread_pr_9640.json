{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI1MzAwMjc4", "number": 9640, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwNDowMDo1N1rOFN-f5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0yMlQwNToxNjo0MVrOF1DHyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUwMTk5NzgxOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwNDowMDo1N1rOISetLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwNDowMDo1N1rOISetLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI0ODM2Nw==", "bodyText": "no need for this comment anymore", "url": "https://github.com/apache/kafka/pull/9640#discussion_r556248367", "createdAt": "2021-01-13T04:00:57Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -54,15 +58,17 @@\n     private final Map<String, Set<TaskId>> consumerToPreviousStatefulTaskIds = new TreeMap<>();\n \n     // the following four maps are used only for logging purposes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d80490a51817160ea0d69dfd18d49a14a4a54b3"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUwMjA0Mzc3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwNDoyNzo0MFrOISfHOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwNDoyNzo0MFrOISfHOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI1NTAzNQ==", "bodyText": "This map is great as a concise & efficient way to keep track of the tasks, but I'm worried that we're sacrificing some readability. I'm not sure we necessarily want to stuff everything into a single data structure, just reduce the duplication of effort in tracking tasks at both the client and consumer level. If you take a look at the activeTasks family of sets above, that's basically just a superset of all tasks in the consumerToAssignedActive map.\nBut consumerToAssignedActive and consumerToAssignedStandby, for example, actually track two completely orthogonal things, so I think it seems reasonable for them to be in two different data structures. WDYT?", "url": "https://github.com/apache/kafka/pull/9640#discussion_r556255035", "createdAt": "2021-01-13T04:27:40Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -54,15 +58,17 @@\n     private final Map<String, Set<TaskId>> consumerToPreviousStatefulTaskIds = new TreeMap<>();\n \n     // the following four maps are used only for logging purposes;\n-    // TODO KAFKA-10283: we could consider merging them with other book-keeping maps at client-levels\n-    //                   so that they would not be inconsistent\n-    private final Map<String, Set<TaskId>> consumerToPreviousActiveTaskIds = new TreeMap<>();\n-    private final Map<String, Set<TaskId>> consumerToAssignedActiveTaskIds = new TreeMap<>();\n-    private final Map<String, Set<TaskId>> consumerToAssignedStandbyTaskIds = new TreeMap<>();\n-    private final Map<String, Set<TaskId>> consumerToRevokingActiveTaskIds = new TreeMap<>();\n-\n+    private final Map<String, Map<TaskId, Set<ConsumerState>>> consumerToTaskIdsConsumerStates = new TreeMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d80490a51817160ea0d69dfd18d49a14a4a54b3"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUwMjA0OTMyOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwNDozMTozNVrOISfKgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwNDozMTozNVrOISfKgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI1NTg3Mg==", "bodyText": "This will print everything out with one task per line, right? That might be a problem (or at least, an annoyance) in apps with hundreds or more tasks in total. Also, just speaking from experience in debugging an application, it's more useful to present the information in terms of \"here is all the assigned active tasks, here are the revoking active, etc...\" just so you can see all the tasks of each type together. So we may want to keep the original format, or something similar at least", "url": "https://github.com/apache/kafka/pull/9640#discussion_r556255872", "createdAt": "2021-01-13T04:31:35Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -996,18 +996,19 @@ private void populatePartitionsByHostMaps(final Map<HostInfo, Set<TopicPartition\n                 log.debug(\"Requested client {} to schedule a followup rebalance\", clientId);\n             }\n \n-            log.info(\"Client {} per-consumer assignment:\\n\" +\n-                \"\\tprev owned active {}\\n\" +\n-                \"\\tprev owned standby {}\\n\" +\n-                \"\\tassigned active {}\\n\" +\n-                \"\\trevoking active {}\" +\n-                \"\\tassigned standby {}\\n\",\n-                clientId,\n-                clientMetadata.state.prevOwnedActiveTasksByConsumer(),\n-                clientMetadata.state.prevOwnedStandbyByConsumer(),\n-                clientMetadata.state.assignedActiveTasksByConsumer(),\n-                clientMetadata.state.revokingActiveTasksByConsumer(),\n-                clientMetadata.state.assignedStandbyTasksByConsumer());\n+            log.info(\"Client {} per-consumer assignment\\n {}\",\n+                     clientId,\n+                     clientMetadata.state.assignedTasksConsumerStateByConsumer()\n+                                         .entrySet()\n+                                         .stream()\n+                                         .map(e -> \"\\tconsumer : \" + e.getKey() + '\\n' +\n+                                                   e.getValue().entrySet()\n+                                                    .stream()\n+                                                    .map(taskIdEntry -> \"\\ttaskId : \" + taskIdEntry.getKey()\n+                                                                        + \" states : \" + taskIdEntry.getValue())\n+                                                    .collect(Collectors.joining(\"\\n\")))\n+                                         .collect(Collectors.joining(\"\\n\"))\n+            );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d80490a51817160ea0d69dfd18d49a14a4a54b3"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUwNjMyMzYzOnYy", "diffSide": "LEFT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMjo0ODoyMVrOITIQnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwNTo1MDo1NFrOIV_UMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjkyOTE4Mw==", "bodyText": "I think maybe @guozhangwang and I haven't really explained the purpose of this cleanup ticket very well...it's Guozhang's ticket so I'll let him correct me if I've misunderstood the ticket as well, but my impression was that we wanted to consolidate the client-level sets -- eg activeTasks or prevActiveTasks, on lines 46-49 in the current code -- with the consumer-level maps, eg consumerToPrevActiveTaskIds. So the point is not so much to combine any of the maps on lines 59 - 62, but instead to combine each map with its corresponding set in the ones on lines 46 - 49. Does that make sense?", "url": "https://github.com/apache/kafka/pull/9640#discussion_r556929183", "createdAt": "2021-01-13T22:48:21Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -53,16 +56,17 @@\n     private final Map<TopicPartition, String> ownedPartitions = new TreeMap<>(TOPIC_PARTITION_COMPARATOR);\n     private final Map<String, Set<TaskId>> consumerToPreviousStatefulTaskIds = new TreeMap<>();\n \n-    // the following four maps are used only for logging purposes;\n-    // TODO KAFKA-10283: we could consider merging them with other book-keeping maps at client-levels\n-    //                   so that they would not be inconsistent", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6c8d8e8b4ea115ee90c1e00cbaa4f91b518fdf3"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAwNDA3Ng==", "bodyText": "Oh, I was misunderstanding\n@ableegoldman\nIntegrating two structures, for example\nclass ClientStateTask { private final Set<TaskId> clientTaskIds private filnal Map<String, Set<TaskId>> consumerTaskIds }\nIs this form correct?\nthanks!", "url": "https://github.com/apache/kafka/pull/9640#discussion_r557004076", "createdAt": "2021-01-14T02:28:17Z", "author": {"login": "highluck"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -53,16 +56,17 @@\n     private final Map<TopicPartition, String> ownedPartitions = new TreeMap<>(TOPIC_PARTITION_COMPARATOR);\n     private final Map<String, Set<TaskId>> consumerToPreviousStatefulTaskIds = new TreeMap<>();\n \n-    // the following four maps are used only for logging purposes;\n-    // TODO KAFKA-10283: we could consider merging them with other book-keeping maps at client-levels\n-    //                   so that they would not be inconsistent", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjkyOTE4Mw=="}, "originalCommit": {"oid": "e6c8d8e8b4ea115ee90c1e00cbaa4f91b518fdf3"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA1MzA2Nw==", "bodyText": "@ableegoldman\nthanks for review\ni updated code\nadd class ClientStateTask\nThanks!", "url": "https://github.com/apache/kafka/pull/9640#discussion_r557053067", "createdAt": "2021-01-14T05:32:04Z", "author": {"login": "highluck"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -53,16 +56,17 @@\n     private final Map<TopicPartition, String> ownedPartitions = new TreeMap<>(TOPIC_PARTITION_COMPARATOR);\n     private final Map<String, Set<TaskId>> consumerToPreviousStatefulTaskIds = new TreeMap<>();\n \n-    // the following four maps are used only for logging purposes;\n-    // TODO KAFKA-10283: we could consider merging them with other book-keeping maps at client-levels\n-    //                   so that they would not be inconsistent", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjkyOTE4Mw=="}, "originalCommit": {"oid": "e6c8d8e8b4ea115ee90c1e00cbaa4f91b518fdf3"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTkyODM3MQ==", "bodyText": "@ableegoldman yes you're right. On the high-level I want to consolidate sets that always get updated at the same time, since it is vulnerable to bugs when we forget to update some of them while modifying the others. But for maps that are logically orthogonal (i.e. they are not always updated at the same time) then we could still keep them separated.", "url": "https://github.com/apache/kafka/pull/9640#discussion_r559928371", "createdAt": "2021-01-19T05:50:54Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -53,16 +56,17 @@\n     private final Map<TopicPartition, String> ownedPartitions = new TreeMap<>(TOPIC_PARTITION_COMPARATOR);\n     private final Map<String, Set<TaskId>> consumerToPreviousStatefulTaskIds = new TreeMap<>();\n \n-    // the following four maps are used only for logging purposes;\n-    // TODO KAFKA-10283: we could consider merging them with other book-keeping maps at client-levels\n-    //                   so that they would not be inconsistent", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjkyOTE4Mw=="}, "originalCommit": {"oid": "e6c8d8e8b4ea115ee90c1e00cbaa4f91b518fdf3"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUwNjMzMDk5OnYy", "diffSide": "LEFT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMjo1MTowM1rOITIU9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMjo1MTowM1rOITIU9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjkzMDI5Mw==", "bodyText": "Looks like you're IDE might have a conflicting style for import order. There's no \"official\" import order in the project, but in general we put static imports last rather than first.\nThere's actually an ongoing KIP/PR for cleaning this up but obviously it's a pretty big undertaking, so it's been in limbo a while. For now it may be best to just avoid reordering any of the imports, and just follow the existing order in the file", "url": "https://github.com/apache/kafka/pull/9640#discussion_r556930293", "createdAt": "2021-01-13T22:51:03Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -16,28 +16,31 @@\n  */\n package org.apache.kafka.streams.processor.internals.assignment;\n \n-import org.apache.kafka.common.TopicPartition;\n-import org.apache.kafka.streams.processor.TaskId;\n-import org.apache.kafka.streams.processor.internals.Task;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n+import static java.util.Collections.emptyMap;\n+import static java.util.Collections.unmodifiableMap;\n+import static java.util.Collections.unmodifiableSet;\n+import static java.util.Comparator.comparing;\n+import static org.apache.kafka.common.utils.Utils.union;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n \n import java.util.Collection;\n import java.util.Comparator;\n+import java.util.EnumMap;\n import java.util.HashSet;\n import java.util.Map;\n+import java.util.Map.Entry;\n import java.util.Set;\n-import java.util.stream.Collectors;\n import java.util.TreeMap;\n import java.util.TreeSet;\n import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n \n-import static java.util.Collections.emptyMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6c8d8e8b4ea115ee90c1e00cbaa4f91b518fdf3"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDI4NjY4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMjoyNzo0OFrOIWqPpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0yMFQwNDo1NTowNFrOJLyl-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDYzMTcxOA==", "bodyText": "Thanks for the update, I think we're closer but still not quite there yet since we've kind of just wrapped the existing data structures up into the new ClientStateTask class but still access those maps/sets like we did before. So there's not much added safety/consistency, which was the original intention of this ticket IIUC -- ie to make sure that activeTasks and consumerToAssignedActiveTaskIds hold the same set of tasks overall.\nGranted, this might turn out to be pretty difficult to do without a large refactoring of the assignment code. Part of the problem is just that we first assigned tasks at the client-level, at which point we don't know anything about the consumers for each task. Then later we assign tasks to consumers from inside the StreamsPartitionAssignor class, at which point we don't really care so much about the client-level tasks.\nBut I think we can still make some solid improvements here. For example what if we forget about refactoring any of the data structures for now, and just focus on adding some sanity checks -- eg inside assignActiveToConsumer we make sure that the task actually is assigned to this client to begin with, ie that  it exists in the activeTasks set. WDYT, does that make sense?", "url": "https://github.com/apache/kafka/pull/9640#discussion_r560631718", "createdAt": "2021-01-20T02:27:48Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -100,40 +94,41 @@ boolean reachedCapacity() {\n     }\n \n     public Set<TaskId> activeTasks() {\n-        return unmodifiableSet(activeTasks);\n+        return unmodifiableSet(assignedActiveTasks.taskIds());\n     }\n \n     public int activeTaskCount() {\n-        return activeTasks.size();\n+        return assignedActiveTasks.taskIds().size();\n     }\n \n     double activeTaskLoad() {\n         return ((double) activeTaskCount()) / capacity;\n     }\n \n     public void assignActiveTasks(final Collection<TaskId> tasks) {\n-        activeTasks.addAll(tasks);\n+        assignedActiveTasks.taskIds().addAll(tasks);\n     }\n \n     public void assignActiveToConsumer(final TaskId task, final String consumer) {\n-        consumerToAssignedActiveTaskIds.computeIfAbsent(consumer, k -> new HashSet<>()).add(task);\n+        assignedActiveTasks.consumerToTaskIds().computeIfAbsent(consumer, k -> new HashSet<>()).add(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a54851d5af195a3217ce26903b14dd1ae354c3f"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY0NTEwMA==", "bodyText": "@ableegoldman thanks for review!\nI have a question.\n\nDo you mean that the same structure is assigned to the client level when assigned to ActiveToConsumer?\nDo you mean that the set of TaskId and Client TaskId should be the same as the Consumer's set?", "url": "https://github.com/apache/kafka/pull/9640#discussion_r560645100", "createdAt": "2021-01-20T03:09:10Z", "author": {"login": "highluck"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -100,40 +94,41 @@ boolean reachedCapacity() {\n     }\n \n     public Set<TaskId> activeTasks() {\n-        return unmodifiableSet(activeTasks);\n+        return unmodifiableSet(assignedActiveTasks.taskIds());\n     }\n \n     public int activeTaskCount() {\n-        return activeTasks.size();\n+        return assignedActiveTasks.taskIds().size();\n     }\n \n     double activeTaskLoad() {\n         return ((double) activeTaskCount()) / capacity;\n     }\n \n     public void assignActiveTasks(final Collection<TaskId> tasks) {\n-        activeTasks.addAll(tasks);\n+        assignedActiveTasks.taskIds().addAll(tasks);\n     }\n \n     public void assignActiveToConsumer(final TaskId task, final String consumer) {\n-        consumerToAssignedActiveTaskIds.computeIfAbsent(consumer, k -> new HashSet<>()).add(task);\n+        assignedActiveTasks.consumerToTaskIds().computeIfAbsent(consumer, k -> new HashSet<>()).add(task);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDYzMTcxOA=="}, "originalCommit": {"oid": "9a54851d5af195a3217ce26903b14dd1ae354c3f"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTk0MTQzOQ==", "bodyText": "ping @ableegoldman\nthanks :)", "url": "https://github.com/apache/kafka/pull/9640#discussion_r581941439", "createdAt": "2021-02-24T13:04:28Z", "author": {"login": "highluck"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -100,40 +94,41 @@ boolean reachedCapacity() {\n     }\n \n     public Set<TaskId> activeTasks() {\n-        return unmodifiableSet(activeTasks);\n+        return unmodifiableSet(assignedActiveTasks.taskIds());\n     }\n \n     public int activeTaskCount() {\n-        return activeTasks.size();\n+        return assignedActiveTasks.taskIds().size();\n     }\n \n     double activeTaskLoad() {\n         return ((double) activeTaskCount()) / capacity;\n     }\n \n     public void assignActiveTasks(final Collection<TaskId> tasks) {\n-        activeTasks.addAll(tasks);\n+        assignedActiveTasks.taskIds().addAll(tasks);\n     }\n \n     public void assignActiveToConsumer(final TaskId task, final String consumer) {\n-        consumerToAssignedActiveTaskIds.computeIfAbsent(consumer, k -> new HashSet<>()).add(task);\n+        assignedActiveTasks.consumerToTaskIds().computeIfAbsent(consumer, k -> new HashSet<>()).add(task);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDYzMTcxOA=="}, "originalCommit": {"oid": "9a54851d5af195a3217ce26903b14dd1ae354c3f"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjM0MzAzMw==", "bodyText": "@highluck I think the main point here is that, inside the assignActiveToConsumer we first make sure that the task is already in the ClientStateTask.taskIds set, i.e. that the task is already assigned to the client before we assign it to the client's consumer in case any bugs caused inconsistent assignment: for example, we assigned the task to instance A but also at the same time assign it to consumer 2 of instance B: currently the data structure still does not guarantee that would never happen, but at least we can add such sanity check for now.", "url": "https://github.com/apache/kafka/pull/9640#discussion_r616343033", "createdAt": "2021-04-20T04:55:04Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -100,40 +94,41 @@ boolean reachedCapacity() {\n     }\n \n     public Set<TaskId> activeTasks() {\n-        return unmodifiableSet(activeTasks);\n+        return unmodifiableSet(assignedActiveTasks.taskIds());\n     }\n \n     public int activeTaskCount() {\n-        return activeTasks.size();\n+        return assignedActiveTasks.taskIds().size();\n     }\n \n     double activeTaskLoad() {\n         return ((double) activeTaskCount()) / capacity;\n     }\n \n     public void assignActiveTasks(final Collection<TaskId> tasks) {\n-        activeTasks.addAll(tasks);\n+        assignedActiveTasks.taskIds().addAll(tasks);\n     }\n \n     public void assignActiveToConsumer(final TaskId task, final String consumer) {\n-        consumerToAssignedActiveTaskIds.computeIfAbsent(consumer, k -> new HashSet<>()).add(task);\n+        assignedActiveTasks.consumerToTaskIds().computeIfAbsent(consumer, k -> new HashSet<>()).add(task);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDYzMTcxOA=="}, "originalCommit": {"oid": "9a54851d5af195a3217ce26903b14dd1ae354c3f"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzkxMTY5OTkzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0yMlQwNToxNjo0MVrOJNc9sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0yMlQwNToxNjo0MVrOJNc9sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxODA4NTgwOA==", "bodyText": "If the condition does not satisfy, then we should throw an illegal state exception indicating a bug.", "url": "https://github.com/apache/kafka/pull/9640#discussion_r618085808", "createdAt": "2021-04-22T05:16:41Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -110,7 +110,10 @@ public void assignActiveTasks(final Collection<TaskId> tasks) {\n     }\n \n     public void assignActiveToConsumer(final TaskId task, final String consumer) {\n-        assignedActiveTasks.consumerToTaskIds().computeIfAbsent(consumer, k -> new HashSet<>()).add(task);\n+        if (assignedActiveTasks.taskIds().contains(task)) {\n+            assignedActiveTasks.consumerToTaskIds()\n+                               .computeIfAbsent(consumer, k -> new HashSet<>()).add(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a13180b31585da5e0541d5087a1746ceb31c2f21"}, "originalPosition": 7}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3609, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}