{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgzMjUyOTI4", "number": 8215, "title": "KAFKA-9451: Update MockConsumer to support ConsumerGroupMetadata", "bodyText": "Part of KIP-447", "createdAt": "2020-03-03T23:43:34Z", "url": "https://github.com/apache/kafka/pull/8215", "merged": true, "mergeCommit": {"oid": "d3c7ef251a1ff9dfa94cd462d736a9f6592106dd"}, "closed": true, "closedAt": "2020-03-11T22:22:45Z", "author": {"login": "mjsax"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcKLVMnAFqTM2ODQwNzYyMw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcMgwZiAFqTM3MjQ5MzEwMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY4NDA3NjIz", "url": "https://github.com/apache/kafka/pull/8215#pullrequestreview-368407623", "createdAt": "2020-03-03T23:45:03Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QyMzo0NTowM1rOFxatFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QyMzo1NjozOVrOFxa7yA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjA3MQ==", "bodyText": "We need this later (not related to this PR, but to follow up PR for KIP-447)", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362071", "createdAt": "2020-03-03T23:45:03Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java", "diffHunk": "@@ -563,7 +563,7 @@ private Long getEndOffset(List<Long> offsets) {\n \n     @Override\n     public ConsumerGroupMetadata groupMetadata() {\n-        return null;\n+        return new ConsumerGroupMetadata(\"dummy.group.id\", 1, \"1\", Optional.empty());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjA5MQ==", "bodyText": "Side cleanup", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362091", "createdAt": "2020-03-03T23:45:08Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java", "diffHunk": "@@ -461,7 +461,7 @@ public synchronized void close() {\n         close(KafkaConsumer.DEFAULT_CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n     }\n \n-    @SuppressWarnings(\"deprecation\")\n+    @Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjExMQ==", "bodyText": "Side cleanup", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362111", "createdAt": "2020-03-03T23:45:11Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -308,7 +308,7 @@ private void verifyTransactionInFlight() {\n                 0L, 0, 0, Time.SYSTEM);\n         long offset = nextOffset(topicPartition);\n         Completion completion = new Completion(offset, new RecordMetadata(topicPartition, 0, offset,\n-                RecordBatch.NO_TIMESTAMP, Long.valueOf(0L), 0, 0), result, callback);\n+                RecordBatch.NO_TIMESTAMP, 0L, 0, 0), result, callback);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjE3Mg==", "bodyText": "Side cleanup (multiple in the file)", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362172", "createdAt": "2020-03-03T23:45:22Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -101,6 +101,7 @@\n     private boolean commitNeeded = false;\n     private boolean commitRequested = false;\n \n+    @SuppressWarnings(\"rawtypes\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjIzOQ==", "bodyText": "We move this into TaskManager", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362239", "createdAt": "2020-03-03T23:45:36Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -247,235 +241,6 @@ int getAssignmentErrorCode() {\n         return assignmentErrorCode.get();\n     }\n \n-    static abstract class AbstractTaskCreator<T extends Task> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjQyMw==", "bodyText": "This PR addresses this TODO", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362423", "createdAt": "2020-03-03T23:46:07Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -542,43 +305,21 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n             restoreConsumer,\n             userStateRestoreListener);\n \n-        final ThreadCache cache = new ThreadCache(logContext, cacheSizeBytes, streamsMetrics);\n-\n         final Map<TaskId, Producer<byte[], byte[]>> taskProducers = new HashMap<>();\n \n-        // TODO: refactor `TaskCreator` into `TaskManager`;\n-        //  this will allow to reduce the surface area of `taskProducers` that is passed to many classes atm", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 285}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjcwNg==", "bodyText": "We don't need to pass the producers into StreamThread any longer now", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362706", "createdAt": "2020-03-03T23:46:51Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -602,8 +343,6 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n         final StreamThread streamThread = new StreamThread(\n             time,\n             config,\n-            activeTaskCreator.threadProducer,\n-            taskProducers,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 331}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2Mjc1Nw==", "bodyText": "moved to TaskManager (alse method below)", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362757", "createdAt": "2020-03-03T23:47:02Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -686,14 +421,6 @@ private InternalConsumerConfig(final Map<String, Object> props) {\n         }\n     }\n \n-    private static String getTaskProducerClientId(final String threadClientId, final TaskId taskId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 357}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MzczMA==", "bodyText": "producerClientIds() contains the logic from above now", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387363730", "createdAt": "2020-03-03T23:50:05Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -1123,13 +850,11 @@ public final ThreadMetadata threadMetadata() {\n     StreamThread updateThreadMetadata(final String adminClientId) {\n \n         threadMetadata = new ThreadMetadata(\n-            this.getName(),\n-            this.state().name(),\n-            getConsumerClientId(this.getName()),\n-            getRestoreConsumerClientId(this.getName()),\n-            threadProducer == null ?\n-                Collections.emptySet() :\n-                Collections.singleton(getThreadProducerClientId(this.getName())),\n+            getName(),\n+            state().name(),\n+            getConsumerClientId(getName()),\n+            getRestoreConsumerClientId(getName()),\n+            taskManager.producerClientIds(getName()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 383}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2Mzg4MA==", "bodyText": "Getting producerClientIds is not moved into the TaskManager", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387363880", "createdAt": "2020-03-03T23:50:38Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -1139,11 +864,9 @@ StreamThread updateThreadMetadata(final String adminClientId) {\n \n     private void updateThreadMetadata(final Map<TaskId, Task> activeTasks,\n                                       final Map<TaskId, Task> standbyTasks) {\n-        final Set<String> producerClientIds = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 391}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2Mzk3MA==", "bodyText": "Logic move into TaskManager", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387363970", "createdAt": "2020-03-03T23:50:54Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -1198,22 +919,7 @@ public String toString(final String indent) {\n     }\n \n     public Map<MetricName, Metric> producerMetrics() {\n-        final LinkedHashMap<MetricName, Metric> result = new LinkedHashMap<>();\n-        if (threadProducer != null) {\n-            final Map<MetricName, ? extends Metric> producerMetrics = threadProducer.metrics();\n-            if (producerMetrics != null) {\n-                result.putAll(producerMetrics);\n-            }\n-        } else {\n-            // When EOS is turned on, each task will have its own producer client\n-            // and the producer object passed in here will be null. We would then iterate through\n-            // all the active tasks and add their metrics to the output metrics map.\n-            for (final StreamTask task : taskManager.fixmeStreamTasks().values()) {\n-                final Map<MetricName, ? extends Metric> taskProducerMetrics = taskProducers.get(task.id).metrics();\n-                result.putAll(taskProducerMetrics);\n-            }\n-        }\n-        return result;\n+        return taskManager.producerMetrics();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 438}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDI5MQ==", "bodyText": "I added this constructor to allow mocking both task creators -- otherwise TaskManagerTest would require complex mocking and major rewrite", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387364291", "createdAt": "2020-03-03T23:51:44Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -77,27 +316,127 @@\n \n     private boolean rebalanceInProgress = false;  // if we are in the middle of a rebalance, it is not safe to commit\n \n+    // for testing only", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 286}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDM4Mg==", "bodyText": "This is the actual constructor now", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387364382", "createdAt": "2020-03-03T23:52:02Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -77,27 +316,127 @@\n \n     private boolean rebalanceInProgress = false;  // if we are in the middle of a rebalance, it is not safe to commit\n \n+    // for testing only\n     TaskManager(final ChangelogReader changelogReader,\n                 final UUID processId,\n                 final String logPrefix,\n                 final StreamsMetricsImpl streamsMetrics,\n-                final StreamThread.AbstractTaskCreator<? extends Task> activeTaskCreator,\n-                final StreamThread.AbstractTaskCreator<? extends Task> standbyTaskCreator,\n+                final Producer<byte[], byte[]> threadProducer,\n                 final Map<TaskId, Producer<byte[], byte[]>> taskProducers,\n                 final InternalTopologyBuilder builder,\n-                final Admin adminClient) {\n+                final Admin adminClient,\n+                final AbstractTaskCreator<? extends Task> activeTaskCreator,\n+                final AbstractTaskCreator<? extends Task> standbyTaskCreator) {\n         this.changelogReader = changelogReader;\n         this.processId = processId;\n         this.logPrefix = logPrefix;\n         this.streamsMetrics = streamsMetrics;\n+        this.threadProducer = threadProducer;\n+        this.taskProducers = taskProducers;\n+        this.builder = builder;\n+        this.adminClient = adminClient;\n         this.activeTaskCreator = activeTaskCreator;\n         this.standbyTaskCreator = standbyTaskCreator;\n+\n+        final LogContext logContext = new LogContext(logPrefix);\n+        log = logContext.logger(getClass());\n+    }\n+\n+    TaskManager(final ChangelogReader changelogReader,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 315}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDUxOA==", "bodyText": "side cleanup", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387364518", "createdAt": "2020-03-03T23:52:27Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -155,6 +155,7 @@ public void punctuate(final long timestamp) {\n         }\n     };\n \n+    @SuppressWarnings(\"rawtypes\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDYwMw==", "bodyText": "This and the next test are moved to TaskManagerTest", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387364603", "createdAt": "2020-03-03T23:52:45Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -1827,82 +1811,6 @@ private void verifyLogMessagesForSkippedRecordsForInvalidTimestamps(final LogCap\n         ));\n     }\n \n-    @Test\n-    public void shouldConstructProducerMetricsWithoutEOS() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NTY4Mw==", "bodyText": "Minor change: We don't pass in threadId any longer but just call Thread.currentThread.getName() instead -- let me know what you think about it -- seems simpler to me to avoid passing around unnecessary parameters", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387365683", "createdAt": "2020-03-03T23:56:12Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -49,10 +60,237 @@\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n \n+import static org.apache.kafka.streams.StreamsConfig.EXACTLY_ONCE;\n import static org.apache.kafka.streams.processor.internals.Task.State.CREATED;\n import static org.apache.kafka.streams.processor.internals.Task.State.RESTORING;\n \n public class TaskManager {\n+\n+    static abstract class AbstractTaskCreator<T extends Task> {\n+        final String applicationId;\n+        final InternalTopologyBuilder builder;\n+        final StreamsConfig config;\n+        final StreamsMetricsImpl streamsMetrics;\n+        final StateDirectory stateDirectory;\n+        final ChangelogReader storeChangelogReader;\n+        final Time time;\n+        final Logger log;\n+\n+        AbstractTaskCreator(final InternalTopologyBuilder builder,\n+                            final StreamsConfig config,\n+                            final StreamsMetricsImpl streamsMetrics,\n+                            final StateDirectory stateDirectory,\n+                            final ChangelogReader storeChangelogReader,\n+                            final Time time,\n+                            final Logger log) {\n+            this.applicationId = config.getString(StreamsConfig.APPLICATION_ID_CONFIG);\n+            this.builder = builder;\n+            this.config = config;\n+            this.streamsMetrics = streamsMetrics;\n+            this.stateDirectory = stateDirectory;\n+            this.storeChangelogReader = storeChangelogReader;\n+            this.time = time;\n+            this.log = log;\n+        }\n+\n+        public InternalTopologyBuilder builder() {\n+            return builder;\n+        }\n+\n+        public StateDirectory stateDirectory() {\n+            return stateDirectory;\n+        }\n+\n+        Collection<T> createTasks(final Consumer<byte[], byte[]> consumer,\n+                                  final Map<TaskId, Set<TopicPartition>> tasksToBeCreated) {\n+            final List<T> createdTasks = new ArrayList<>();\n+            for (final Map.Entry<TaskId, Set<TopicPartition>> newTaskAndPartitions : tasksToBeCreated.entrySet()) {\n+                final TaskId taskId = newTaskAndPartitions.getKey();\n+                final Set<TopicPartition> partitions = newTaskAndPartitions.getValue();\n+                final T task = createTask(consumer, taskId, partitions);\n+                if (task != null) {\n+                    log.trace(\"Created task {} with assigned partitions {}\", taskId, partitions);\n+                    createdTasks.add(task);\n+                }\n+\n+            }\n+            return createdTasks;\n+        }\n+\n+        abstract T createTask(final Consumer<byte[], byte[]> consumer, final TaskId id, final Set<TopicPartition> partitions);\n+\n+        void close() {};\n+    }\n+\n+    static class TaskCreator extends AbstractTaskCreator<StreamTask> {\n+        private final ThreadCache cache;\n+        private final Producer<byte[], byte[]> threadProducer;\n+        private final Map<TaskId, Producer<byte[], byte[]>> taskProducers;\n+        private final KafkaClientSupplier clientSupplier;\n+        private final Sensor createTaskSensor;\n+\n+        TaskCreator(final InternalTopologyBuilder builder,\n+                    final StreamsConfig config,\n+                    final StreamsMetricsImpl streamsMetrics,\n+                    final StateDirectory stateDirectory,\n+                    final ChangelogReader storeChangelogReader,\n+                    final ThreadCache cache,\n+                    final Time time,\n+                    final KafkaClientSupplier clientSupplier,\n+                    final Producer<byte[], byte[]> threadProducer,\n+                    final Map<TaskId, Producer<byte[], byte[]>> taskProducers,\n+                    final Logger log) {\n+            super(\n+                builder,\n+                config,\n+                streamsMetrics,\n+                stateDirectory,\n+                storeChangelogReader,\n+                time,\n+                log);\n+\n+            this.threadProducer = threadProducer;\n+            this.taskProducers = taskProducers;\n+\n+            this.cache = cache;\n+            this.clientSupplier = clientSupplier;\n+\n+            this.createTaskSensor = ThreadMetrics.createTaskSensor(Thread.currentThread().getName(), streamsMetrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NTgzMg==", "bodyText": "Similar to above: don't pass threadId any longer", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387365832", "createdAt": "2020-03-03T23:56:39Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -49,10 +60,237 @@\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n \n+import static org.apache.kafka.streams.StreamsConfig.EXACTLY_ONCE;\n import static org.apache.kafka.streams.processor.internals.Task.State.CREATED;\n import static org.apache.kafka.streams.processor.internals.Task.State.RESTORING;\n \n public class TaskManager {\n+\n+    static abstract class AbstractTaskCreator<T extends Task> {\n+        final String applicationId;\n+        final InternalTopologyBuilder builder;\n+        final StreamsConfig config;\n+        final StreamsMetricsImpl streamsMetrics;\n+        final StateDirectory stateDirectory;\n+        final ChangelogReader storeChangelogReader;\n+        final Time time;\n+        final Logger log;\n+\n+        AbstractTaskCreator(final InternalTopologyBuilder builder,\n+                            final StreamsConfig config,\n+                            final StreamsMetricsImpl streamsMetrics,\n+                            final StateDirectory stateDirectory,\n+                            final ChangelogReader storeChangelogReader,\n+                            final Time time,\n+                            final Logger log) {\n+            this.applicationId = config.getString(StreamsConfig.APPLICATION_ID_CONFIG);\n+            this.builder = builder;\n+            this.config = config;\n+            this.streamsMetrics = streamsMetrics;\n+            this.stateDirectory = stateDirectory;\n+            this.storeChangelogReader = storeChangelogReader;\n+            this.time = time;\n+            this.log = log;\n+        }\n+\n+        public InternalTopologyBuilder builder() {\n+            return builder;\n+        }\n+\n+        public StateDirectory stateDirectory() {\n+            return stateDirectory;\n+        }\n+\n+        Collection<T> createTasks(final Consumer<byte[], byte[]> consumer,\n+                                  final Map<TaskId, Set<TopicPartition>> tasksToBeCreated) {\n+            final List<T> createdTasks = new ArrayList<>();\n+            for (final Map.Entry<TaskId, Set<TopicPartition>> newTaskAndPartitions : tasksToBeCreated.entrySet()) {\n+                final TaskId taskId = newTaskAndPartitions.getKey();\n+                final Set<TopicPartition> partitions = newTaskAndPartitions.getValue();\n+                final T task = createTask(consumer, taskId, partitions);\n+                if (task != null) {\n+                    log.trace(\"Created task {} with assigned partitions {}\", taskId, partitions);\n+                    createdTasks.add(task);\n+                }\n+\n+            }\n+            return createdTasks;\n+        }\n+\n+        abstract T createTask(final Consumer<byte[], byte[]> consumer, final TaskId id, final Set<TopicPartition> partitions);\n+\n+        void close() {};\n+    }\n+\n+    static class TaskCreator extends AbstractTaskCreator<StreamTask> {\n+        private final ThreadCache cache;\n+        private final Producer<byte[], byte[]> threadProducer;\n+        private final Map<TaskId, Producer<byte[], byte[]>> taskProducers;\n+        private final KafkaClientSupplier clientSupplier;\n+        private final Sensor createTaskSensor;\n+\n+        TaskCreator(final InternalTopologyBuilder builder,\n+                    final StreamsConfig config,\n+                    final StreamsMetricsImpl streamsMetrics,\n+                    final StateDirectory stateDirectory,\n+                    final ChangelogReader storeChangelogReader,\n+                    final ThreadCache cache,\n+                    final Time time,\n+                    final KafkaClientSupplier clientSupplier,\n+                    final Producer<byte[], byte[]> threadProducer,\n+                    final Map<TaskId, Producer<byte[], byte[]>> taskProducers,\n+                    final Logger log) {\n+            super(\n+                builder,\n+                config,\n+                streamsMetrics,\n+                stateDirectory,\n+                storeChangelogReader,\n+                time,\n+                log);\n+\n+            this.threadProducer = threadProducer;\n+            this.taskProducers = taskProducers;\n+\n+            this.cache = cache;\n+            this.clientSupplier = clientSupplier;\n+\n+            this.createTaskSensor = ThreadMetrics.createTaskSensor(Thread.currentThread().getName(), streamsMetrics);\n+        }\n+\n+        @Override\n+        StreamTask createTask(final Consumer<byte[], byte[]> mainConsumer,\n+                              final TaskId taskId,\n+                              final Set<TopicPartition> partitions) {\n+            createTaskSensor.record();\n+\n+            final String threadIdPrefix = String.format(\"stream-thread [%s] \", Thread.currentThread().getName());\n+            final String logPrefix = threadIdPrefix + String.format(\"%s [%s] \", \"task\", taskId);\n+            final LogContext logContext = new LogContext(logPrefix);\n+\n+            final ProcessorTopology topology = builder.buildSubtopology(taskId.topicGroupId);\n+\n+            final ProcessorStateManager stateManager = new ProcessorStateManager(\n+                taskId,\n+                partitions,\n+                Task.TaskType.ACTIVE,\n+                stateDirectory,\n+                topology.storeToChangelogTopic(),\n+                storeChangelogReader,\n+                logContext);\n+\n+            final StreamsProducer streamsProducer;\n+            if (threadProducer == null) {\n+                // create one producer per task for EOS\n+                // TODO: after KIP-447 this would be removed\n+                final Map<String, Object> producerConfigs = config.getProducerConfigs(getTaskProducerClientId(Thread.currentThread().getName(), taskId));\n+                producerConfigs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, applicationId + \"-\" + taskId);\n+                log.info(\"Creating producer client for task {}\", taskId);\n+                taskProducers.put(taskId, clientSupplier.getProducer(producerConfigs));\n+                streamsProducer = new StreamsProducer(logContext, taskProducers.get(taskId), applicationId, taskId);\n+            } else {\n+                streamsProducer = new StreamsProducer(logContext, threadProducer);\n+            }\n+\n+            final RecordCollector recordCollector = new RecordCollectorImpl(\n+                logContext,\n+                taskId,\n+                mainConsumer,\n+                streamsProducer,\n+                config.defaultProductionExceptionHandler(),\n+                EXACTLY_ONCE.equals(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG)),\n+                streamsMetrics);\n+\n+            return new StreamTask(\n+                taskId,\n+                partitions,\n+                topology,\n+                mainConsumer,\n+                config,\n+                streamsMetrics,\n+                stateDirectory,\n+                cache,\n+                time,\n+                stateManager,\n+                recordCollector);\n+        }\n+\n+        @Override\n+        public void close() {\n+            if (threadProducer != null) {\n+                try {\n+                    threadProducer.close();\n+                } catch (final Throwable e) {\n+                    log.error(\"Failed to close producer due to the following error:\", e);\n+                }\n+            }\n+        }\n+    }\n+\n+    static class StandbyTaskCreator extends AbstractTaskCreator<StandbyTask> {\n+        private final Sensor createTaskSensor;\n+\n+        StandbyTaskCreator(final InternalTopologyBuilder builder,\n+                           final StreamsConfig config,\n+                           final StreamsMetricsImpl streamsMetrics,\n+                           final StateDirectory stateDirectory,\n+                           final ChangelogReader storeChangelogReader,\n+                           final Time time,\n+                           final Logger log) {\n+            super(\n+                builder,\n+                config,\n+                streamsMetrics,\n+                stateDirectory,\n+                storeChangelogReader,\n+                time,\n+                log);\n+            createTaskSensor = ThreadMetrics.createTaskSensor(Thread.currentThread().getName(), streamsMetrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 221}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MTk0ODU4", "url": "https://github.com/apache/kafka/pull/8215#pullrequestreview-369194858", "createdAt": "2020-03-04T23:17:10Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMzoxNzoxMFrOFyBJaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMzoxNzoxMFrOFyBJaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk5MTkxMw==", "bodyText": "Need this to make MockConsumerTest pass.", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387991913", "createdAt": "2020-03-04T23:17:10Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -72,4 +72,21 @@ public String toString() {\n             memberId,\n             groupInstanceId.orElse(\"\"));\n     }\n+\n+    @Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MjEzNjkz", "url": "https://github.com/apache/kafka/pull/8215#pullrequestreview-369213693", "createdAt": "2020-03-05T00:05:40Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQwMDowNTo0MFrOFyCHZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQwMDowNTo0MFrOFyCHZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODAwNzc4Mw==", "bodyText": "Not sure I follow here: can we just use easy-mock for the creators here, what are the actual issues that would cause major re-write in the test class?", "url": "https://github.com/apache/kafka/pull/8215#discussion_r388007783", "createdAt": "2020-03-05T00:05:40Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -77,27 +316,127 @@\n \n     private boolean rebalanceInProgress = false;  // if we are in the middle of a rebalance, it is not safe to commit\n \n+    // for testing only", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDI5MQ=="}, "originalCommit": null, "originalPosition": 286}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNjg2NDY3", "url": "https://github.com/apache/kafka/pull/8215#pullrequestreview-370686467", "createdAt": "2020-03-06T23:31:05Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMzozMTowNVrOFzKb-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMzozNTo0NlrOFzKgQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5MjY5OA==", "bodyText": "I think it's actually a better idea to keep extracting the active / standby task creators out of the constructor of task-manager, since by doing that in the tests we can have mocks for those two, and also we can avoid the extra constructors you added below. Thoughts?\nAlso cc @abbccdda @vvcephei who reviewed / worked on the class cleanups recently.", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389192698", "createdAt": "2020-03-06T23:31:05Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -304,37 +303,20 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n             restoreConsumer,\n             userStateRestoreListener);\n \n-        final ThreadCache cache = new ThreadCache(logContext, cacheSizeBytes, streamsMetrics);\n-\n-        final ActiveTaskCreator activeTaskCreator = new ActiveTaskCreator(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5MzY2MQ==", "bodyText": "Thanks for the added test coverage!!", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389193661", "createdAt": "2020-03-06T23:35:03Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.Metric;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.metrics.KafkaMetric;\n+import org.apache.kafka.common.metrics.Measurable;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+import org.apache.kafka.test.MockClientSupplier;\n+import org.easymock.EasyMockRunner;\n+import org.easymock.Mock;\n+import org.easymock.MockType;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.easymock.EasyMock.anyString;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.mock;\n+import static org.easymock.EasyMock.replay;\n+import static org.junit.Assert.assertEquals;\n+\n+@RunWith(EasyMockRunner.class)\n+public class ActiveTaskCreatorTest {\n+\n+    @Mock(type = MockType.NICE)\n+    private InternalTopologyBuilder builder;\n+    @Mock(type = MockType.NICE)\n+    private StreamsConfig config;\n+    @Mock(type = MockType.NICE)\n+    private StateDirectory stateDirectory;\n+    @Mock(type = MockType.NICE)\n+    private ChangelogReader changeLogReader;\n+    @Mock(type = MockType.NICE)\n+    private Consumer<byte[], byte[]> consumer;\n+    @Mock(type = MockType.NICE)\n+    private Admin adminClient;\n+\n+    private final MockClientSupplier mockClientSupplier = new MockClientSupplier();\n+    final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(new Metrics(), \"clientId\", StreamsConfig.METRICS_LATEST);\n+\n+    private ActiveTaskCreator activeTaskCreator;\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithoutEOS() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5Mzc5NQ==", "bodyText": "This seems not used.", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389193795", "createdAt": "2020-03-06T23:35:46Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -105,6 +105,8 @@\n     private final TopicPartition t1p2 = new TopicPartition(topic1, 2);\n     private final Set<TopicPartition> taskId02Partitions = mkSet(t1p2);\n \n+    private final MockClientSupplier mockClientSupplier = new MockClientSupplier();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNzUxNTA2", "url": "https://github.com/apache/kafka/pull/8215#pullrequestreview-370751506", "createdAt": "2020-03-07T16:08:33Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wN1QxNjoxMDozNlrOFzO1tA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wN1QxODo1NDozN1rOFzRORQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTI2NDgyMA==", "bodyText": "Since we did this, could we also add test for StandbyTaskCreator to resolve https://issues.apache.org/jira/browse/KAFKA-9676?", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389264820", "createdAt": "2020-03-07T16:10:36Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.Metric;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.metrics.KafkaMetric;\n+import org.apache.kafka.common.metrics.Measurable;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+import org.apache.kafka.test.MockClientSupplier;\n+import org.easymock.EasyMockRunner;\n+import org.easymock.Mock;\n+import org.easymock.MockType;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.easymock.EasyMock.anyString;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.mock;\n+import static org.easymock.EasyMock.replay;\n+import static org.junit.Assert.assertEquals;\n+\n+@RunWith(EasyMockRunner.class)\n+public class ActiveTaskCreatorTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMwMzg3Nw==", "bodyText": "I also don't feel strong about this refactoring. In the effort of moving task creator towards TaskManager we are also passing in more parameters than what TaskManager needs as well. I would recommend we reduce the PR to address https://issues.apache.org/jira/browse/KAFKA-9676 only, since we do miss unit test coverage for task creators.", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389303877", "createdAt": "2020-03-07T18:54:37Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -304,37 +303,20 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n             restoreConsumer,\n             userStateRestoreListener);\n \n-        final ThreadCache cache = new ThreadCache(logContext, cacheSizeBytes, streamsMetrics);\n-\n-        final ActiveTaskCreator activeTaskCreator = new ActiveTaskCreator(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5MjY5OA=="}, "originalCommit": null, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNzkyMDEz", "url": "https://github.com/apache/kafka/pull/8215#pullrequestreview-370792013", "createdAt": "2020-03-07T22:16:39Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wN1QyMjoxNjozOVrOFzR-gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wN1QyMjoxNjozOVrOFzR-gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMxNjIyNQ==", "bodyText": "Could we use verify on mocks for both test cases?", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389316225", "createdAt": "2020-03-07T22:16:39Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.Metric;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.metrics.KafkaMetric;\n+import org.apache.kafka.common.metrics.Measurable;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+import org.apache.kafka.test.MockClientSupplier;\n+import org.easymock.EasyMockRunner;\n+import org.easymock.Mock;\n+import org.easymock.MockType;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.easymock.EasyMock.anyString;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.mock;\n+import static org.easymock.EasyMock.replay;\n+import static org.junit.Assert.assertEquals;\n+\n+@RunWith(EasyMockRunner.class)\n+public class ActiveTaskCreatorTest {\n+\n+    @Mock(type = MockType.NICE)\n+    private InternalTopologyBuilder builder;\n+    @Mock(type = MockType.NICE)\n+    private StreamsConfig config;\n+    @Mock(type = MockType.NICE)\n+    private StateDirectory stateDirectory;\n+    @Mock(type = MockType.NICE)\n+    private ChangelogReader changeLogReader;\n+    @Mock(type = MockType.NICE)\n+    private Consumer<byte[], byte[]> consumer;\n+    @Mock(type = MockType.NICE)\n+    private Admin adminClient;\n+\n+    private final MockClientSupplier mockClientSupplier = new MockClientSupplier();\n+    final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(new Metrics(), \"clientId\", StreamsConfig.METRICS_LATEST);\n+\n+    private ActiveTaskCreator activeTaskCreator;\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithoutEOS() {\n+        expect(config.getString(StreamsConfig.APPLICATION_ID_CONFIG)).andReturn(\"appId\");\n+        expect(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG)).andReturn(StreamsConfig.AT_LEAST_ONCE);\n+        expect(config.getProducerConfigs(anyString())).andReturn(Collections.emptyMap());\n+        replay(config);\n+\n+        activeTaskCreator = new ActiveTaskCreator(\n+            builder,\n+            config,\n+            streamsMetrics,\n+            stateDirectory,\n+            changeLogReader,\n+            new ThreadCache(new LogContext(), 0L, streamsMetrics),\n+            new MockTime(),\n+            mockClientSupplier,\n+            \"threadId\",\n+            new LogContext().logger(ActiveTaskCreator.class)\n+        );\n+\n+        final MetricName testMetricName = new MetricName(\"test_metric\", \"\", \"\", new HashMap<>());\n+        final Metric testMetric = new KafkaMetric(\n+            new Object(),\n+            testMetricName,\n+            (Measurable) (config, now) -> 0,\n+            null,\n+            new MockTime());\n+\n+        mockClientSupplier.producers.get(0).setMockMetrics(testMetricName, testMetric);\n+        final Map<MetricName, Metric> producerMetrics = activeTaskCreator.producerMetrics();\n+        assertEquals(testMetricName, producerMetrics.get(testMetricName).metricName());\n+    }\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithEOS() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNzk5NjQx", "url": "https://github.com/apache/kafka/pull/8215#pullrequestreview-370799641", "createdAt": "2020-03-08T02:07:01Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc7e21a4c2388b501616e01da11f047844d34246", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/fc7e21a4c2388b501616e01da11f047844d34246", "committedDate": "2020-03-10T23:52:09Z", "message": "KAFKA-9441: Refactor TaskManager"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "fc7e21a4c2388b501616e01da11f047844d34246", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/fc7e21a4c2388b501616e01da11f047844d34246", "committedDate": "2020-03-10T23:52:09Z", "message": "KAFKA-9441: Refactor TaskManager"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNDkzMTAx", "url": "https://github.com/apache/kafka/pull/8215#pullrequestreview-372493101", "createdAt": "2020-03-11T06:03:00Z", "commit": {"oid": "fc7e21a4c2388b501616e01da11f047844d34246"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1654, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}