{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDczMzYxOTk2", "number": 9219, "title": "KAFKA-10432: LeaderEpochCache is incorrectly recovered for leader epoch 0", "bodyText": "The leader epoch cache is incorrectly recovered for epoch 0 as the\nassignment is skipped when epoch == 0. This check was likely intended to\nprevent negative epochs from being applied or there was an assumption\nthat epochs started at 1.\nA test has been added to LogSegmentTest to show the LogSegment\nrecovery path works for the epoch cache. This was a test gap as none of the\nrecover calls supply a leader epoch cache to recover.", "createdAt": "2020-08-25T17:46:52Z", "url": "https://github.com/apache/kafka/pull/9219", "merged": true, "mergeCommit": {"oid": "d2521855b8eb8a0dbb6f94cd9bb5093276fb7db2"}, "closed": true, "closedAt": "2020-09-08T19:43:37Z", "author": {"login": "lbradstreet"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdCafZ1gH2gAyNDczMzYxOTk2Ojk3NDNiYzAzNjUzYTFmYmI0Mjc5NWE3YmVlY2E0YTllMWZhZTU5MTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdG5c2ggH2gAyNDczMzYxOTk2OjY3ZGM2YWU5MThhNzI4NWI0YjgxNDU0MzRkMjYzZjFlMWRkZmJlYmI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "9743bc03653a1fbb42795a7beeca4a9e1fae5919", "author": {"user": {"login": "lbradstreet", "name": "Lucas Bradstreet"}}, "url": "https://github.com/apache/kafka/commit/9743bc03653a1fbb42795a7beeca4a9e1fae5919", "committedDate": "2020-08-25T17:16:55Z", "message": "KAFKA-10432: LeaderEpochCache is incorrectly recovered for leader epoch 0\n\nThe leader epoch cache is incorrectly recovered for epoch 0 as the\nassignment is skipped when epoch == 0. This check was likely intended to\nprevent negative epochs from being applied or there was an assumption\nthat epochs started at 1.\n\nA test has been added to LogSegmentTest to show the LogSegment\nrecovery path works for the epoch cache. This was a test gap."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc1MDczNzI5", "url": "https://github.com/apache/kafka/pull/9219#pullrequestreview-475073729", "createdAt": "2020-08-26T00:35:42Z", "commit": {"oid": "9743bc03653a1fbb42795a7beeca4a9e1fae5919"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwMDozNTo0MlrOHG0pHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwMDozNTo0MlrOHG0pHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjkxNTk5Nw==", "bodyText": "nit: use arg names consistently?", "url": "https://github.com/apache/kafka/pull/9219#discussion_r476915997", "createdAt": "2020-08-26T00:35:42Z", "author": {"login": "hachikuji"}, "path": "core/src/test/scala/unit/kafka/log/LogSegmentTest.scala", "diffHunk": "@@ -367,6 +371,45 @@ class LogSegmentTest {\n     assertEquals(100L, abortedTxn.lastStableOffset)\n   }\n \n+  /**\n+   * Create a segment with some data, then recover the segment.\n+   * The epoch cache entries should reflect the segment.\n+   */\n+  @Test\n+  def testRecoveryRebuildsEpochCache(): Unit = {\n+    val seg = createSegment(0)\n+\n+    val checkpoint: LeaderEpochCheckpoint = new LeaderEpochCheckpoint {\n+      private var epochs = Seq.empty[EpochEntry]\n+\n+      override def write(epochs: Seq[EpochEntry]): Unit = {\n+        this.epochs = epochs.toVector\n+      }\n+\n+      override def read(): Seq[EpochEntry] = this.epochs\n+    }\n+\n+    val cache = new LeaderEpochFileCache(topicPartition, () => seg.readNextOffset, checkpoint)\n+    seg.append(largestOffset = 105L, largestTimestamp = RecordBatch.NO_TIMESTAMP,\n+      shallowOffsetOfMaxTimestamp = 104L, MemoryRecords.withRecords(104L, CompressionType.NONE, 0,\n+        new SimpleRecord(\"a\".getBytes), new SimpleRecord(\"b\".getBytes)))\n+\n+    seg.append(largestOffset = 107L, largestTimestamp = RecordBatch.NO_TIMESTAMP,\n+      shallowOffsetOfMaxTimestamp = 106L, MemoryRecords.withRecords(106L, CompressionType.NONE, 1,\n+        new SimpleRecord(\"a\".getBytes), new SimpleRecord(\"b\".getBytes)))\n+\n+    seg.append(largestOffset = 109L, largestTimestamp = RecordBatch.NO_TIMESTAMP,\n+      shallowOffsetOfMaxTimestamp = 108L, MemoryRecords.withRecords(108L, CompressionType.NONE, 1,\n+        new SimpleRecord(\"a\".getBytes), new SimpleRecord(\"b\".getBytes)))\n+\n+    seg.append(largestOffset = 111L, largestTimestamp = RecordBatch.NO_TIMESTAMP,\n+      shallowOffsetOfMaxTimestamp = 110, MemoryRecords.withRecords(110L, CompressionType.NONE, 2,\n+        new SimpleRecord(\"a\".getBytes), new SimpleRecord(\"b\".getBytes)))\n+\n+    seg.recover(new ProducerStateManager(topicPartition, logDir), Some(cache))\n+    assertEquals(ArrayBuffer(EpochEntry(0, 104L), EpochEntry(epoch=1, startOffset=106), EpochEntry(epoch=2, startOffset=110)), cache.epochEntries)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9743bc03653a1fbb42795a7beeca4a9e1fae5919"}, "originalPosition": 58}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17f622c2b10591fc48f55a3a29e7723a16f793d7", "author": {"user": {"login": "lbradstreet", "name": "Lucas Bradstreet"}}, "url": "https://github.com/apache/kafka/commit/17f622c2b10591fc48f55a3a29e7723a16f793d7", "committedDate": "2020-08-26T00:48:27Z", "message": "Consistently name parameters"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "67dc6ae918a7285b4b8145434d263f1e1ddfbebb", "author": {"user": {"login": "lbradstreet", "name": "Lucas Bradstreet"}}, "url": "https://github.com/apache/kafka/commit/67dc6ae918a7285b4b8145434d263f1e1ddfbebb", "committedDate": "2020-09-08T15:36:53Z", "message": "Merge branch 'trunk' into KAFKA-10432"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 812, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}