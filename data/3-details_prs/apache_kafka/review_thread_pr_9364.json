{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk2NzgxMTgw", "number": 9364, "reviewThreads": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMTowODoyN1rOEp8wmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNzozMjozMlrOEz5Idg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNDIyNTU1OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/Log.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMTowODoyN1rOHb7q5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxMzowMVrOHckMTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1MTIzOA==", "bodyText": "Could we add the new param to the javadoc above?", "url": "https://github.com/apache/kafka/pull/9364#discussion_r499051238", "createdAt": "2020-10-02T21:08:27Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -244,7 +244,8 @@ class Log(@volatile private var _dir: File,\n           val producerIdExpirationCheckIntervalMs: Int,\n           val topicPartition: TopicPartition,\n           val producerStateManager: ProducerStateManager,\n-          logDirFailureChannel: LogDirFailureChannel) extends Logging with KafkaMetricsGroup {\n+          logDirFailureChannel: LogDirFailureChannel,\n+          val hadCleanShutdown: Boolean = true) extends Logging with KafkaMetricsGroup {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxNTE1MQ==", "bodyText": "Done", "url": "https://github.com/apache/kafka/pull/9364#discussion_r499715151", "createdAt": "2020-10-05T16:13:01Z", "author": {"login": "RamanVerma"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -244,7 +244,8 @@ class Log(@volatile private var _dir: File,\n           val producerIdExpirationCheckIntervalMs: Int,\n           val topicPartition: TopicPartition,\n           val producerStateManager: ProducerStateManager,\n-          logDirFailureChannel: LogDirFailureChannel) extends Logging with KafkaMetricsGroup {\n+          logDirFailureChannel: LogDirFailureChannel,\n+          val hadCleanShutdown: Boolean = true) extends Logging with KafkaMetricsGroup {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1MTIzOA=="}, "originalCommit": null, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNDIzNTgyOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMToxMzoxMlrOHb7xMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwNjo1NjoyMFrOHmTIKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1Mjg0OA==", "bodyText": "It seems that all callers set expectDeletedFiles to false. So, do we need this param?", "url": "https://github.com/apache/kafka/pull/9364#discussion_r499052848", "createdAt": "2020-10-02T21:13:12Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -4447,9 +4504,10 @@ class LogTest {\n \n   private def recoverAndCheck(config: LogConfig,\n                               expectedKeys: Iterable[Long],\n-                              expectDeletedFiles: Boolean = true): Log = {\n+                              expectDeletedFiles: Boolean = true,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 368}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODc4NA==", "bodyText": "I think you meant the hadCleanShutdown parameter I added. I did not add the expectDeletedFiles parameter.\nI will remove the new parameter and add a comment here to indicate that the method always assumes we had a hard reset.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r499718784", "createdAt": "2020-10-05T16:18:39Z", "author": {"login": "RamanVerma"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -4447,9 +4504,10 @@ class LogTest {\n \n   private def recoverAndCheck(config: LogConfig,\n                               expectedKeys: Iterable[Long],\n-                              expectDeletedFiles: Boolean = true): Log = {\n+                              expectDeletedFiles: Boolean = true,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1Mjg0OA=="}, "originalCommit": null, "originalPosition": 368}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTkyMTMyMg==", "bodyText": "Done", "url": "https://github.com/apache/kafka/pull/9364#discussion_r509921322", "createdAt": "2020-10-22T06:56:20Z", "author": {"login": "RamanVerma"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -4447,9 +4504,10 @@ class LogTest {\n \n   private def recoverAndCheck(config: LogConfig,\n                               expectedKeys: Iterable[Long],\n-                              expectDeletedFiles: Boolean = true): Log = {\n+                              expectDeletedFiles: Boolean = true,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1Mjg0OA=="}, "originalCommit": null, "originalPosition": 368}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNDI1MTAxOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMToyMDowOVrOHb76fA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwNjo1NzoyOVrOHmTKQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1NTIyOA==", "bodyText": "The callers of createLog() in line 652 and 2205 seem to need lastShutdownClean to be false.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r499055228", "createdAt": "2020-10-02T21:20:09Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -4429,9 +4485,10 @@ class LogTest {\n                         scheduler: Scheduler = mockTime.scheduler,\n                         time: Time = mockTime,\n                         maxProducerIdExpirationMs: Int = 60 * 60 * 1000,\n-                        producerIdExpirationCheckIntervalMs: Int = LogManager.ProducerIdExpirationCheckIntervalMs): Log = {\n+                        producerIdExpirationCheckIntervalMs: Int = LogManager.ProducerIdExpirationCheckIntervalMs,\n+                        lastShutdownClean: Boolean = true): Log = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 356}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTkyMTg1OQ==", "bodyText": "Done", "url": "https://github.com/apache/kafka/pull/9364#discussion_r509921859", "createdAt": "2020-10-22T06:57:29Z", "author": {"login": "RamanVerma"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -4429,9 +4485,10 @@ class LogTest {\n                         scheduler: Scheduler = mockTime.scheduler,\n                         time: Time = mockTime,\n                         maxProducerIdExpirationMs: Int = 60 * 60 * 1000,\n-                        producerIdExpirationCheckIntervalMs: Int = LogManager.ProducerIdExpirationCheckIntervalMs): Log = {\n+                        producerIdExpirationCheckIntervalMs: Int = LogManager.ProducerIdExpirationCheckIntervalMs,\n+                        lastShutdownClean: Boolean = true): Log = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1NTIyOA=="}, "originalCommit": null, "originalPosition": 356}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNDI3MTUwOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMToyODo1NlrOHb8GuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoyNzo1M1rOHckwpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1ODM2MA==", "bodyText": "The change is unnecessary.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r499058360", "createdAt": "2020-10-02T21:28:56Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -2882,11 +2953,8 @@ class LogTest {\n     records.foreach(segment.append _)\n     segment.close()\n \n-    // Create clean shutdown file so that we do not split during the load\n-    createCleanShutdownFile()\n-\n     val logConfig = LogTest.createLogConfig(indexIntervalBytes = 1, fileDeleteDelayMs = 1000)\n-    val log = createLog(logDir, logConfig, recoveryPoint = Long.MaxValue)\n+    val log = createLog(logDir, logConfig, recoveryPoint = Long.MaxValue, lastShutdownClean = true)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcyNDQ1NQ==", "bodyText": "Removed", "url": "https://github.com/apache/kafka/pull/9364#discussion_r499724455", "createdAt": "2020-10-05T16:27:53Z", "author": {"login": "RamanVerma"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -2882,11 +2953,8 @@ class LogTest {\n     records.foreach(segment.append _)\n     segment.close()\n \n-    // Create clean shutdown file so that we do not split during the load\n-    createCleanShutdownFile()\n-\n     val logConfig = LogTest.createLogConfig(indexIntervalBytes = 1, fileDeleteDelayMs = 1000)\n-    val log = createLog(logDir, logConfig, recoveryPoint = Long.MaxValue)\n+    val log = createLog(logDir, logConfig, recoveryPoint = Long.MaxValue, lastShutdownClean = true)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1ODM2MA=="}, "originalCommit": null, "originalPosition": 238}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNDI3MzU3OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMToyOTo1MlrOHb8IAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjozOToxOVrOHclKdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1ODY5MQ==", "bodyText": "The change is unnecessary.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r499058691", "createdAt": "2020-10-02T21:29:52Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -3073,9 +3139,8 @@ class LogTest {\n     // check if recovery was attempted. Even if the recovery point is 0L, recovery should not be attempted as the\n     // clean shutdown file exists.\n     recoveryPoint = log.logEndOffset\n-    log = createLog(logDir, logConfig)\n+    log = createLog(logDir, logConfig, lastShutdownClean = true)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 310}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTczMTA2MQ==", "bodyText": "Removed.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r499731061", "createdAt": "2020-10-05T16:39:19Z", "author": {"login": "RamanVerma"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -3073,9 +3139,8 @@ class LogTest {\n     // check if recovery was attempted. Even if the recovery point is 0L, recovery should not be attempted as the\n     // clean shutdown file exists.\n     recoveryPoint = log.logEndOffset\n-    log = createLog(logDir, logConfig)\n+    log = createLog(logDir, logConfig, lastShutdownClean = true)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA1ODY5MQ=="}, "originalCommit": null, "originalPosition": 310}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5ODAzNzA3OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogManager.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QwMDoxMDo0MlrOHm4IOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNFQwMjo1ODoxMlrOHnl6kQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDUyNzU0NA==", "bodyText": "This is an existing issue, but cleanShutdownFile.delete() doesn't seem to throw IOException.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r510527544", "createdAt": "2020-10-23T00:10:42Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -298,26 +300,38 @@ class LogManager(logDirs: Seq[File],\n   /**\n    * Recover and load all logs in the given data directories\n    */\n-  private def loadLogs(): Unit = {\n+  private[log] def loadLogs(): Unit = {\n     info(s\"Loading logs from log dirs $liveLogDirs\")\n     val startMs = time.hiResClockMs()\n     val threadPools = ArrayBuffer.empty[ExecutorService]\n     val offlineDirs = mutable.Set.empty[(String, IOException)]\n-    val jobs = mutable.Map.empty[File, Seq[Future[_]]]\n+    val jobs = ArrayBuffer.empty[Seq[Future[_]]]\n     var numTotalLogs = 0\n \n     for (dir <- liveLogDirs) {\n       val logDirAbsolutePath = dir.getAbsolutePath\n+      var hadCleanShutdown: Boolean = false\n       try {\n         val pool = Executors.newFixedThreadPool(numRecoveryThreadsPerDataDir)\n         threadPools.append(pool)\n \n         val cleanShutdownFile = new File(dir, Log.CleanShutdownFile)\n         if (cleanShutdownFile.exists) {\n           info(s\"Skipping recovery for all logs in $logDirAbsolutePath since clean shutdown file was found\")\n+          // Cache the clean shutdown status and use that for rest of log loading workflow. Delete the CleanShutdownFile\n+          // so that if broker crashes while loading the log, it is considered hard shutdown during the next boot up. KAFKA-10471\n+          try {\n+            cleanShutdownFile.delete()\n+          } catch {\n+            case e: IOException =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTI3NzcxMw==", "bodyText": "java.nio.file.Files API throws IOException but not the one used here java.io.File. Will remove this exception", "url": "https://github.com/apache/kafka/pull/9364#discussion_r511277713", "createdAt": "2020-10-24T02:58:12Z", "author": {"login": "RamanVerma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -298,26 +300,38 @@ class LogManager(logDirs: Seq[File],\n   /**\n    * Recover and load all logs in the given data directories\n    */\n-  private def loadLogs(): Unit = {\n+  private[log] def loadLogs(): Unit = {\n     info(s\"Loading logs from log dirs $liveLogDirs\")\n     val startMs = time.hiResClockMs()\n     val threadPools = ArrayBuffer.empty[ExecutorService]\n     val offlineDirs = mutable.Set.empty[(String, IOException)]\n-    val jobs = mutable.Map.empty[File, Seq[Future[_]]]\n+    val jobs = ArrayBuffer.empty[Seq[Future[_]]]\n     var numTotalLogs = 0\n \n     for (dir <- liveLogDirs) {\n       val logDirAbsolutePath = dir.getAbsolutePath\n+      var hadCleanShutdown: Boolean = false\n       try {\n         val pool = Executors.newFixedThreadPool(numRecoveryThreadsPerDataDir)\n         threadPools.append(pool)\n \n         val cleanShutdownFile = new File(dir, Log.CleanShutdownFile)\n         if (cleanShutdownFile.exists) {\n           info(s\"Skipping recovery for all logs in $logDirAbsolutePath since clean shutdown file was found\")\n+          // Cache the clean shutdown status and use that for rest of log loading workflow. Delete the CleanShutdownFile\n+          // so that if broker crashes while loading the log, it is considered hard shutdown during the next boot up. KAFKA-10471\n+          try {\n+            cleanShutdownFile.delete()\n+          } catch {\n+            case e: IOException =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDUyNzU0NA=="}, "originalCommit": null, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5ODA1OTY2OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QwMDoyMzoyOFrOHm4U2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNVQwNDozMzowNFrOHn2SIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDUzMDc3Nw==", "bodyText": "Hmm, it seems that this tests expects a clean shutdown.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r510530777", "createdAt": "2020-10-23T00:23:28Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -1257,7 +1328,7 @@ class LogTest {\n     log.close()\n \n     // After reloading log, producer state should not be regenerated\n-    val reloadedLog = createLog(logDir, logConfig, logStartOffset = 1L)\n+    val reloadedLog = createLog(logDir, logConfig, logStartOffset = 1L, lastShutdownClean = false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU0NTg5MA==", "bodyText": "Jun, this test was not creating a clean shut down file before opening the log again. So, it would have been going through log recovery code path earlier as well.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r511545890", "createdAt": "2020-10-25T04:33:04Z", "author": {"login": "RamanVerma"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -1257,7 +1328,7 @@ class LogTest {\n     log.close()\n \n     // After reloading log, producer state should not be regenerated\n-    val reloadedLog = createLog(logDir, logConfig, logStartOffset = 1L)\n+    val reloadedLog = createLog(logDir, logConfig, logStartOffset = 1L, lastShutdownClean = false)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDUzMDc3Nw=="}, "originalCommit": null, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwMDk5NzE5OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QxNjoxMDozOVrOHnUbVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNVQwNDozMDozN1rOHn2RcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDk5MTE4OQ==", "bodyText": "It seems that this expects a clean shutdown.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r510991189", "createdAt": "2020-10-23T16:10:39Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -2131,12 +2202,12 @@ class LogTest {\n       assertEquals(\"Should have same number of time index entries as before.\", numTimeIndexEntries, log.activeSegment.timeIndex.entries)\n     }\n \n-    log = createLog(logDir, logConfig, recoveryPoint = lastOffset)\n+    log = createLog(logDir, logConfig, recoveryPoint = lastOffset, lastShutdownClean = false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU0NTcxMg==", "bodyText": "Jun, this test was not creating a clean shut down file before opening the log again. So, it would have gone through the recovery path. Hence, I have set lastShutdownClean parameter to false. Similarly, for line 2210.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r511545712", "createdAt": "2020-10-25T04:30:37Z", "author": {"login": "RamanVerma"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -2131,12 +2202,12 @@ class LogTest {\n       assertEquals(\"Should have same number of time index entries as before.\", numTimeIndexEntries, log.activeSegment.timeIndex.entries)\n     }\n \n-    log = createLog(logDir, logConfig, recoveryPoint = lastOffset)\n+    log = createLog(logDir, logConfig, recoveryPoint = lastOffset, lastShutdownClean = false)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDk5MTE4OQ=="}, "originalCommit": null, "originalPosition": 225}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwMTAyNDc1OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QxNjoxODoxMVrOHnUsgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QxNjoxODoxMVrOHnUsgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDk5NTU4Nw==", "bodyText": "It seem the createLog() call on line 3976 inside testRecoverOnlyLastSegment() needs to have lastShutdownClean = false.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r510995587", "createdAt": "2020-10-23T16:18:11Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -3623,7 +3690,7 @@ class LogTest {\n     log.close()\n \n     // reopen the log and recover from the beginning\n-    val recoveredLog = createLog(logDir, LogConfig())\n+    val recoveredLog = createLog(logDir, LogConfig(), lastShutdownClean = false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 292}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwMTA4NzMzOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QxNjozNjoyM1rOHnVTkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QxNjozNjoyM1rOHnVTkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTAwNTU4NA==", "bodyText": "This is an existing problem. Since no callers are explicitly setting expectDeletedFiles, could we just remove this param?", "url": "https://github.com/apache/kafka/pull/9364#discussion_r511005584", "createdAt": "2020-10-23T16:36:23Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -4445,11 +4504,9 @@ class LogTest {\n     (log, segmentWithOverflow)\n   }\n \n-  private def recoverAndCheck(config: LogConfig,\n-                              expectedKeys: Iterable[Long],\n-                              expectDeletedFiles: Boolean = true): Log = {\n-    LogTest.recoverAndCheck(logDir, config, expectedKeys, brokerTopicStats, mockTime, mockTime.scheduler,\n-      expectDeletedFiles)\n+  private def recoverAndCheck(config: LogConfig, expectedKeys: Iterable[Long], expectDeletedFiles: Boolean = true) = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 343}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwOTg2NzE0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQyMjo0ODoxNVrOHolM9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQyMjo0ODoxNVrOHolM9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjMxNDYxMw==", "bodyText": "This line seems unnecessary since hadCleanShutdown is initialized to false.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r512314613", "createdAt": "2020-10-26T22:48:15Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -298,26 +300,32 @@ class LogManager(logDirs: Seq[File],\n   /**\n    * Recover and load all logs in the given data directories\n    */\n-  private def loadLogs(): Unit = {\n+  private[log] def loadLogs(): Unit = {\n     info(s\"Loading logs from log dirs $liveLogDirs\")\n     val startMs = time.hiResClockMs()\n     val threadPools = ArrayBuffer.empty[ExecutorService]\n     val offlineDirs = mutable.Set.empty[(String, IOException)]\n-    val jobs = mutable.Map.empty[File, Seq[Future[_]]]\n+    val jobs = ArrayBuffer.empty[Seq[Future[_]]]\n     var numTotalLogs = 0\n \n     for (dir <- liveLogDirs) {\n       val logDirAbsolutePath = dir.getAbsolutePath\n+      var hadCleanShutdown: Boolean = false\n       try {\n         val pool = Executors.newFixedThreadPool(numRecoveryThreadsPerDataDir)\n         threadPools.append(pool)\n \n         val cleanShutdownFile = new File(dir, Log.CleanShutdownFile)\n         if (cleanShutdownFile.exists) {\n           info(s\"Skipping recovery for all logs in $logDirAbsolutePath since clean shutdown file was found\")\n+          // Cache the clean shutdown status and use that for rest of log loading workflow. Delete the CleanShutdownFile\n+          // so that if broker crashes while loading the log, it is considered hard shutdown during the next boot up. KAFKA-10471\n+          cleanShutdownFile.delete()\n+          hadCleanShutdown = true\n         } else {\n           // log recovery itself is being performed by `Log` class during initialization\n           info(s\"Attempting recovery for all logs in $logDirAbsolutePath since no clean shutdown file was found\")\n+          hadCleanShutdown = false", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwOTg4NTE1OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQyMjo1NTowOFrOHolXaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQyMjo1NTowOFrOHolXaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjMxNzI4OA==", "bodyText": "It seems we don't need to set hadCleanShutdown to true.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r512317288", "createdAt": "2020-10-26T22:55:08Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -978,10 +1051,10 @@ class LogTest {\n       producerIdExpirationCheckIntervalMs = 30000,\n       topicPartition = Log.parseTopicPartitionName(logDir),\n       producerStateManager = stateManager,\n-      logDirFailureChannel = null)\n+      logDirFailureChannel = null,\n+      hadCleanShutdown = true)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 182}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwOTg4NjQ2OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQyMjo1NTo0NVrOHolYNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQyMjo1NTo0NVrOHolYNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjMxNzQ5Mw==", "bodyText": "It seems we don't need to set hadCleanShutdown to true.", "url": "https://github.com/apache/kafka/pull/9364#discussion_r512317493", "createdAt": "2020-10-26T22:55:45Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -1021,10 +1092,10 @@ class LogTest {\n       producerIdExpirationCheckIntervalMs = 30000,\n       topicPartition = Log.parseTopicPartitionName(logDir),\n       producerStateManager = stateManager,\n-      logDirFailureChannel = null)\n+      logDirFailureChannel = null,\n+      hadCleanShutdown = true)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 204}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyODQ4ODg2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/Log.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNzozMjozMlrOHrZUHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNzozMjozMlrOHrZUHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTI2NTU2Ng==", "bodyText": "It seems that hadCleanShutdown doesn't need to be exposed as a public val?", "url": "https://github.com/apache/kafka/pull/9364#discussion_r515265566", "createdAt": "2020-10-30T17:32:32Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -244,7 +246,8 @@ class Log(@volatile private var _dir: File,\n           val producerIdExpirationCheckIntervalMs: Int,\n           val topicPartition: TopicPartition,\n           val producerStateManager: ProducerStateManager,\n-          logDirFailureChannel: LogDirFailureChannel) extends Logging with KafkaMetricsGroup {\n+          logDirFailureChannel: LogDirFailureChannel,\n+          val hadCleanShutdown: Boolean = true) extends Logging with KafkaMetricsGroup {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cdfd934e70a527d15275716581950938ec80a2b0"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1904, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}