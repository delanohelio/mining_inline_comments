{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYxNjA1Mzc4", "number": 7932, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDo0NTo0OVrODXTZWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QyMToyODoxOVrODXqXug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzYxNjI0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDo0NTo0OVrOFcjT2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNToxMTozNVrOFc6EWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4Mjk2OQ==", "bodyText": "I am not sure if this completely fixes the issue. Let's say we have one non active segment with offset range [100, 190) and an active segment of [200, 300). With this change, we will set the latestOffset in the map to 190 (which is an improvement from 0). However, this can still trigger another round of unnecessary cleaning since the first segment will still be treated as cleanable (instead of cleaned).\nOne way to fix this more completely is that when we have finished iterating all batches in a segment, we update the latest offset in the map to the start offset of the next segment. In the above example, this will set the latest offset of the map to 200 and the next round of cleaning won't be triggered until the active segment rolls.", "url": "https://github.com/apache/kafka/pull/7932#discussion_r365482969", "createdAt": "2020-01-11T00:45:49Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "diffHunk": "@@ -931,11 +931,15 @@ private[log] class Cleaner(val id: Int,\n             stats.indexMessagesRead(batch.countOrNull)\n           } else {\n             for (record <- batch.asScala) {\n-              if (record.hasKey && record.offset >= startOffset) {\n-                if (map.size < maxDesiredMapSize)\n-                  map.put(record.key, record.offset)\n-                else\n-                  return true\n+              if (record.hasKey) {\n+                if (record.offset >= startOffset) {\n+                  if (map.size < maxDesiredMapSize)\n+                    map.put(record.key, record.offset)\n+                  else\n+                    return true\n+                } else {\n+                  map.updateLatestOffset(record.offset + 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2ec1054ed03d946b71d15b32eb050eb47d6fa20"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg1NTgzMw==", "bodyText": "You were right here. Please, have a look at new fix proposal, and test covering specific issue.", "url": "https://github.com/apache/kafka/pull/7932#discussion_r365855833", "createdAt": "2020-01-13T15:11:35Z", "author": {"login": "trajakovic"}, "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "diffHunk": "@@ -931,11 +931,15 @@ private[log] class Cleaner(val id: Int,\n             stats.indexMessagesRead(batch.countOrNull)\n           } else {\n             for (record <- batch.asScala) {\n-              if (record.hasKey && record.offset >= startOffset) {\n-                if (map.size < maxDesiredMapSize)\n-                  map.put(record.key, record.offset)\n-                else\n-                  return true\n+              if (record.hasKey) {\n+                if (record.offset >= startOffset) {\n+                  if (map.size < maxDesiredMapSize)\n+                    map.put(record.key, record.offset)\n+                  else\n+                    return true\n+                } else {\n+                  map.updateLatestOffset(record.offset + 1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4Mjk2OQ=="}, "originalCommit": {"oid": "b2ec1054ed03d946b71d15b32eb050eb47d6fa20"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MDIyMDY4OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNTowODo0OVrOFc5-Xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNTowODo0OVrOFc5-Xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg1NDMwMw==", "bodyText": "@junrao\nwell you were right, and after i wrote test case(es), first fix didn't resolve issue, so I've reverted the code, and give 2nd chance to fix it.", "url": "https://github.com/apache/kafka/pull/7932#discussion_r365854303", "createdAt": "2020-01-13T15:08:49Z", "author": {"login": "trajakovic"}, "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "diffHunk": "@@ -957,6 +961,12 @@ private[log] class Cleaner(val id: Int,\n       if(position == startPosition)\n         growBuffersOrFail(segment.log, position, maxLogMessageSize, records)\n     }\n+\n+    // check for missing offsets at the end of logSegment\n+    if (lastOffsetInSegment < nextSegmentStartOffset - 1L) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0c2dcc39fefdabeb67534a93b0bd32d53dbe815"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MDI0MjE4OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNToxNDo1MFrOFc6LdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxOToyNToxN1rOFdB4jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg1NzY1Mg==", "bodyText": "Don't know more idiomatic way to write this in Scala", "url": "https://github.com/apache/kafka/pull/7932#discussion_r365857652", "createdAt": "2020-01-13T15:14:50Z", "author": {"login": "trajakovic"}, "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "diffHunk": "@@ -867,6 +867,11 @@ private[log] class Cleaner(val id: Int,\n                                   stats: CleanerStats): Unit = {\n     map.clear()\n     val dirty = log.logSegments(start, end).toBuffer\n+    val nextSegmentStartOffsets : mutable.Buffer[Long] = if (dirty.nonEmpty) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0c2dcc39fefdabeb67534a93b0bd32d53dbe815"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg3NTk5MA==", "bodyText": "Since it's a mutable buffer, how about assigning it to an empty buffer in the declaration, then appending the offsets from dirty as well as the end offset in an if block. We could also avoid the :+ \ud83d\ude01", "url": "https://github.com/apache/kafka/pull/7932#discussion_r365875990", "createdAt": "2020-01-13T15:47:50Z", "author": {"login": "mumrah"}, "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "diffHunk": "@@ -867,6 +867,11 @@ private[log] class Cleaner(val id: Int,\n                                   stats: CleanerStats): Unit = {\n     map.clear()\n     val dirty = log.logSegments(start, end).toBuffer\n+    val nextSegmentStartOffsets : mutable.Buffer[Long] = if (dirty.nonEmpty) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg1NzY1Mg=="}, "originalCommit": {"oid": "e0c2dcc39fefdabeb67534a93b0bd32d53dbe815"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk4Mzg4Nw==", "bodyText": "thx @mumrah\nadded your suggestion(s)", "url": "https://github.com/apache/kafka/pull/7932#discussion_r365983887", "createdAt": "2020-01-13T19:25:17Z", "author": {"login": "trajakovic"}, "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "diffHunk": "@@ -867,6 +867,11 @@ private[log] class Cleaner(val id: Int,\n                                   stats: CleanerStats): Unit = {\n     map.clear()\n     val dirty = log.logSegments(start, end).toBuffer\n+    val nextSegmentStartOffsets : mutable.Buffer[Long] = if (dirty.nonEmpty) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg1NzY1Mg=="}, "originalCommit": {"oid": "e0c2dcc39fefdabeb67534a93b0bd32d53dbe815"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MTExNzEwOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxOTo1MDoxOFrOFdCnKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMDoxNTo0OFrOFdSVhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk5NTgxNg==", "bodyText": "It would be useful to add a comment on why we need to do this. Also, not sure if we need to do the test in the line below since nextSegment's start offset is guaranteed to be larger than all offsets in previous segments.", "url": "https://github.com/apache/kafka/pull/7932#discussion_r365995816", "createdAt": "2020-01-13T19:50:18Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "diffHunk": "@@ -953,6 +962,12 @@ private[log] class Cleaner(val id: Int,\n       if(position == startPosition)\n         growBuffersOrFail(segment.log, position, maxLogMessageSize, records)\n     }\n+\n+    // check for missing offsets at the end of logSegment", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c464ac94f7cf025d430dea6a3f12627e75a6794"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1MzQ0Ng==", "bodyText": "@junrao  I'm gonna need help explaining why is this happening in live kafka since I'm unaware of origin of probelm when/why and how.\nalso, I'm gonna remove if condition and always updateLatsOffset to expected end of segment as you suggested", "url": "https://github.com/apache/kafka/pull/7932#discussion_r366253446", "createdAt": "2020-01-14T10:15:48Z", "author": {"login": "trajakovic"}, "path": "core/src/main/scala/kafka/log/LogCleaner.scala", "diffHunk": "@@ -953,6 +962,12 @@ private[log] class Cleaner(val id: Int,\n       if(position == startPosition)\n         growBuffersOrFail(segment.log, position, maxLogMessageSize, records)\n     }\n+\n+    // check for missing offsets at the end of logSegment", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk5NTgxNg=="}, "originalCommit": {"oid": "2c464ac94f7cf025d430dea6a3f12627e75a6794"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MTM4MDQyOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogCleanerTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QyMToyODoxOVrOFdFKfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMDowNTowMVrOFdSBAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjAzNzYyOQ==", "bodyText": "The error logging is a bit unintuitive. How about \"Cleaning point should pass offset gap\"? Ditto below.", "url": "https://github.com/apache/kafka/pull/7932#discussion_r366037629", "createdAt": "2020-01-13T21:28:19Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogCleanerTest.scala", "diffHunk": "@@ -1561,6 +1561,49 @@ class LogCleanerTest {\n     assertEquals(\"The tombstone should be retained.\", 1, log.logSegments.head.log.batches.iterator.next().lastOffset)\n   }\n \n+  /**\n+   * Verify that the clean is able to move beyond missing offsets records in dirty log\n+   */\n+  @Test\n+  def testCleaningBeyondMissingOffsets(): Unit = {\n+    val logProps = new Properties()\n+    logProps.put(LogConfig.SegmentBytesProp, 1024*1024: java.lang.Integer)\n+    logProps.put(LogConfig.CleanupPolicyProp, LogConfig.Compact)\n+    val logConfig = LogConfig(logProps)\n+    val cleaner = makeCleaner(Int.MaxValue)\n+\n+    {\n+      val log = makeLog(dir = TestUtils.randomPartitionLogDir(tmpdir), config = logConfig)\n+      writeToLog(log, (0 to 9) zip (0 to 9), (0L to 9L))\n+      // roll new segment with baseOffset 11, leaving previous with holes in offset range [9,10]\n+      log.roll(Some(11L))\n+\n+      // active segment record\n+      log.appendAsFollower(messageWithOffset(1015, 1015, 11L))\n+\n+      val (nextDirtyOffset, _) = cleaner.clean(LogToClean(log.topicPartition, log, 0L, log.activeSegment.baseOffset, needCompactionNow = true))\n+      assertEquals(\"Missing offsets should be skipped until next segment baseOffset\", log.activeSegment.baseOffset, nextDirtyOffset)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c464ac94f7cf025d430dea6a3f12627e75a6794"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI0ODE5Mw==", "bodyText": "understood", "url": "https://github.com/apache/kafka/pull/7932#discussion_r366248193", "createdAt": "2020-01-14T10:05:01Z", "author": {"login": "trajakovic"}, "path": "core/src/test/scala/unit/kafka/log/LogCleanerTest.scala", "diffHunk": "@@ -1561,6 +1561,49 @@ class LogCleanerTest {\n     assertEquals(\"The tombstone should be retained.\", 1, log.logSegments.head.log.batches.iterator.next().lastOffset)\n   }\n \n+  /**\n+   * Verify that the clean is able to move beyond missing offsets records in dirty log\n+   */\n+  @Test\n+  def testCleaningBeyondMissingOffsets(): Unit = {\n+    val logProps = new Properties()\n+    logProps.put(LogConfig.SegmentBytesProp, 1024*1024: java.lang.Integer)\n+    logProps.put(LogConfig.CleanupPolicyProp, LogConfig.Compact)\n+    val logConfig = LogConfig(logProps)\n+    val cleaner = makeCleaner(Int.MaxValue)\n+\n+    {\n+      val log = makeLog(dir = TestUtils.randomPartitionLogDir(tmpdir), config = logConfig)\n+      writeToLog(log, (0 to 9) zip (0 to 9), (0L to 9L))\n+      // roll new segment with baseOffset 11, leaving previous with holes in offset range [9,10]\n+      log.roll(Some(11L))\n+\n+      // active segment record\n+      log.appendAsFollower(messageWithOffset(1015, 1015, 11L))\n+\n+      val (nextDirtyOffset, _) = cleaner.clean(LogToClean(log.topicPartition, log, 0L, log.activeSegment.baseOffset, needCompactionNow = true))\n+      assertEquals(\"Missing offsets should be skipped until next segment baseOffset\", log.activeSegment.baseOffset, nextDirtyOffset)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjAzNzYyOQ=="}, "originalCommit": {"oid": "2c464ac94f7cf025d430dea6a3f12627e75a6794"}, "originalPosition": 25}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4335, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}