{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE2NDc3NDAx", "number": 8650, "title": "MINOR: Added unit tests for ConnectionQuotas", "bodyText": "Added ConnectionQuotasTest, a unit test for ConnectionQuotas. We test connection limits functionality in SocketServerTest (max connections per IP), and DynamicConnectionQuotaTest (max broker-wide and per listener connection limits), which is an integration test. It is useful to have unit tests that directly test ConnectionQuotas.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-05-12T04:29:37Z", "url": "https://github.com/apache/kafka/pull/8650", "merged": true, "mergeCommit": {"oid": "f6781f42ff35b7ca597f889f96b28c5b2da62d4a"}, "closed": true, "closedAt": "2020-05-21T16:21:05Z", "author": {"login": "apovzner"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcgcbJRgH2gAyNDE2NDc3NDAxOjkyNTJmZjk0MzkwOWUwN2ViMGMyNGJkZDRlYTg5MzQ2MzZjMjEyZjM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcjO4o3AH2gAyNDE2NDc3NDAxOmZmMmU0NzNmYTdlYjIwM2MwNGI1NmEwZDlkYzU0OWNmNzhlZDNjZGM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "author": {"user": {"login": "apovzner", "name": "Anna Povzner"}}, "url": "https://github.com/apache/kafka/commit/9252ff943909e07eb0c24bdd4ea8934636c212f3", "committedDate": "2020-05-12T04:18:39Z", "message": "MINOR: Added unit test for ConnectionQuotas"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5ODAyODM2", "url": "https://github.com/apache/kafka/pull/8650#pullrequestreview-409802836", "createdAt": "2020-05-12T08:14:38Z", "commit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "state": "COMMENTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwODoxNDozOVrOGT7M1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwODo1NTowNlrOGT81Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0NjA3MQ==", "bodyText": "I think that intercept does not assert that the exception is thrown but return the intercepted exception. It would be better to use assertThrown here.\nDo we really need to use an executor here? It seems that inc should throw immediately if the listener does not exist.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423546071", "createdAt": "2020-05-12T08:14:39Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0OTIzMw==", "bodyText": "nit: the space before listener is not needed. i would use curly braces here to stay consistent with the foreach below.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423549233", "createdAt": "2020-05-12T08:19:40Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0OTcxMA==", "bodyText": "nit: the space before the last closing parenthesis is not needed.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423549710", "createdAt": "2020-05-12T08:20:23Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1MjcyOQ==", "bodyText": "Number of connections on $listener: to stay consistent with the other tests?\nnit: a space is missing after the first coma.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423552729", "createdAt": "2020-05-12T08:25:02Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1MzQzMA==", "bodyText": "I think that this does not assert as mentioned earlier. Moreover, I think that this deserves its own unit test as it is not really related to the current one.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423553430", "createdAt": "2020-05-12T08:26:06Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1ODkyOQ==", "bodyText": "What's the reason behind using an executor here? It seems that you always wait immediately get on the future thus we could directly do it in the main thread, isn't it? I would personally avoid them if not really necessary.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423558929", "createdAt": "2020-05-12T08:34:30Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2MzY4MQ==", "bodyText": "You may want to assert here.\nI would reduce the waiting time to 10ms (or 100ms) to avoid always waiting 1s.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423563681", "createdAt": "2020-05-12T08:41:46Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2NTUwMQ==", "bodyText": "nit: extra space after the last dot.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423565501", "createdAt": "2020-05-12T08:44:36Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2NTkwOQ==", "bodyText": "Same comment as before.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423565909", "createdAt": "2020-05-12T08:45:13Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2OTE3NA==", "bodyText": "nit: I would use curly braces here to stay consistent with the foreach below.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423569174", "createdAt": "2020-05-12T08:49:48Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2OTgwMQ==", "bodyText": "Number of connections on $listener: to stay consistent with other tests?", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423569801", "createdAt": "2020-05-12T08:50:35Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\", listenerMaxConnections, connectionQuotas.get(listener.defaultClientIp))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 244}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MDAxNQ==", "bodyText": "nit: curly braces.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423570015", "createdAt": "2020-05-12T08:50:59Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\", listenerMaxConnections, connectionQuotas.get(listener.defaultClientIp))\n+        assertFalse(s\"Total number of connections on $listener should be exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listener.listenerName))\n+      }\n+\n+      // since every listener has exactly the max number of listener connections,\n+      // every listener should block on the next connection creation, even the inter-broker listener\n+      val futures2 = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, 1)): Runnable) )", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MDQxMw==", "bodyText": "you may want to assert here.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423570413", "createdAt": "2020-05-12T08:51:34Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\", listenerMaxConnections, connectionQuotas.get(listener.defaultClientIp))\n+        assertFalse(s\"Total number of connections on $listener should be exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listener.listenerName))\n+      }\n+\n+      // since every listener has exactly the max number of listener connections,\n+      // every listener should block on the next connection creation, even the inter-broker listener\n+      val futures2 = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, 1)): Runnable) )\n+      futures2.foreach { future =>\n+        intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 253}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MTQyNA==", "bodyText": "Could we assert the number of connections after this line?", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423571424", "createdAt": "2020-05-12T08:53:02Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\", listenerMaxConnections, connectionQuotas.get(listener.defaultClientIp))\n+        assertFalse(s\"Total number of connections on $listener should be exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listener.listenerName))\n+      }\n+\n+      // since every listener has exactly the max number of listener connections,\n+      // every listener should block on the next connection creation, even the inter-broker listener\n+      val futures2 = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, 1)): Runnable) )\n+      futures2.foreach { future =>\n+        intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      }\n+      listeners.values.foreach { listener =>\n+        // free up one connection slot\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+      }\n+      // all connections should get added\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 260}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3Mjc5MQ==", "bodyText": "A general comment. It would be great if we could break long lines in order to keep them under a reasonable size. I don't know if we have a strict guideline on this but we tend to do it.", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423572791", "createdAt": "2020-05-12T08:55:06Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3"}, "originalPosition": 147}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "117200f87ab443c88dd9e1a6f52ac7ffe357b196", "author": {"user": {"login": "apovzner", "name": "Anna Povzner"}}, "url": "https://github.com/apache/kafka/commit/117200f87ab443c88dd9e1a6f52ac7ffe357b196", "committedDate": "2020-05-13T20:39:49Z", "message": "addressed review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyOTc4NTc3", "url": "https://github.com/apache/kafka/pull/8650#pullrequestreview-412978577", "createdAt": "2020-05-15T21:28:07Z", "commit": {"oid": "117200f87ab443c88dd9e1a6f52ac7ffe357b196"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df9fd8b79c22337a6b14c6c1c092a03008eddc99", "author": {"user": {"login": "apovzner", "name": "Anna Povzner"}}, "url": "https://github.com/apache/kafka/commit/df9fd8b79c22337a6b14c6c1c092a03008eddc99", "committedDate": "2020-05-20T20:07:59Z", "message": "fixed test that was waiting on wrong future"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff2e473fa7eb203c04b56a0d9dc549cf78ed3cdc", "author": {"user": {"login": "apovzner", "name": "Anna Povzner"}}, "url": "https://github.com/apache/kafka/commit/ff2e473fa7eb203c04b56a0d9dc549cf78ed3cdc", "committedDate": "2020-05-20T20:13:58Z", "message": "changed variable name in test so it is easier to differentiate"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 950, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}