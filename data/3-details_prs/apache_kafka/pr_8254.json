{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1Mjk3NTc5", "number": 8254, "title": "KIP-557: Add Emit On Change Support", "bodyText": "This is the initial draft PR for adding emit on change. For reference of the design document, please see here.\nhttps://cwiki.apache.org/confluence/display/KAFKA/KIP-557%3A+Add+emit+on+change+support+for+Kafka+Streams\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-03-08T18:29:07Z", "url": "https://github.com/apache/kafka/pull/8254", "merged": true, "mergeCommit": {"oid": "f54cece73e6116566979bcf6a865d803b7c18974"}, "closed": true, "closedAt": "2020-05-12T18:19:33Z", "author": {"login": "ConcurrencyPractitioner"}, "timelineItems": {"totalCount": 47, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcLtm7lAH2gAyMzg1Mjk3NTc5OjgwZGU1YmJhMDYyMWFhNzFlNWRjZjI5Y2ZkMzA0NjViYzE1NzFiYzM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABchIv79gFqTQxMTU1Mjg3MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "80de5bba0621aa71e5dcf29cfd30465bc1571bc3", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/80de5bba0621aa71e5dcf29cfd30465bc1571bc3", "committedDate": "2020-03-08T18:27:30Z", "message": "[KIP-557] Add emit on change support"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1aaaa01b4b410ce06eb879dcb14d8cef243b638b", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/1aaaa01b4b410ce06eb879dcb14d8cef243b638b", "committedDate": "2020-03-14T03:37:11Z", "message": "Adding some class modifications"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec46f57050bb75cd662fd07664f8ab7470b638a5", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/ec46f57050bb75cd662fd07664f8ab7470b638a5", "committedDate": "2020-03-14T03:38:24Z", "message": "Adding class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c19bf7d21a022b7fc59b313f451a49de07f51ed", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/2c19bf7d21a022b7fc59b313f451a49de07f51ed", "committedDate": "2020-03-14T03:40:01Z", "message": "Merge branch 'trunk' into EMIT-ON-CHANGE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e3ffa93503b2429ef7d3c3149eae06030c9425cb", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/e3ffa93503b2429ef7d3c3149eae06030c9425cb", "committedDate": "2020-03-14T17:36:46Z", "message": "Adding test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a14725adcd4efa4dc29b3e2cc0b97cc28c42e20f", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/a14725adcd4efa4dc29b3e2cc0b97cc28c42e20f", "committedDate": "2020-03-14T17:38:05Z", "message": "Merge branch 'EMIT-ON-CHANGE' of https://github.com/ConcurrencyPractitioner/kafka into EMIT-ON-CHANGE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d3c7ab0c879e36900273a5e4eb19485da5b5e6f", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/6d3c7ab0c879e36900273a5e4eb19485da5b5e6f", "committedDate": "2020-03-15T03:21:47Z", "message": "Adding sensor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "81c19bd7329dce0aa2bb0148a95e9e65afb7ad7e", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/81c19bd7329dce0aa2bb0148a95e9e65afb7ad7e", "committedDate": "2020-03-15T21:44:05Z", "message": "Add working sensor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "209d37662114b871cbdb9a7ee36632daad53ca08", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/209d37662114b871cbdb9a7ee36632daad53ca08", "committedDate": "2020-03-15T21:58:25Z", "message": "Bumping processor level"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1ODg4MDcw", "url": "https://github.com/apache/kafka/pull/8254#pullrequestreview-385888070", "createdAt": "2020-04-01T19:33:00Z", "commit": {"oid": "209d37662114b871cbdb9a7ee36632daad53ca08"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxOTozMzowMFrOF_PitA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMDowNzoxOFrOF_QsbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg1OTI1Mg==", "bodyText": "Maybe we can be a little more conservative and avoid creating the new type TimestampedSerializedKeyValueStore, and therefore avoid changing the decorators at all. I'd like to avoid any reasonable possibility of users encountering the new methods.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            store = (TimestampedSerializedKeyValueStore<K, V>) context.getStateStore(queryableName);\n          \n          \n            \n                            final StateStore stateStore = context.getStateStore(queryableName);\n          \n          \n            \n                            try {\n          \n          \n            \n                                store = ((WrappedStateStore<MeteredTimestampedKeyValueStore<K, V>, K, V>) stateStore).wrapped();\n          \n          \n            \n                            } catch (final ClassCastException e) {\n          \n          \n            \n                                throw new IllegalStateException(\"Unexpected store type: \" + stateStore.getClass() + \" for store: \" + queryableName, e);\n          \n          \n            \n                            }\n          \n      \n    \n    \n  \n\nNote, I know this is an awkward hack, but the whole state store hierarchy is a mess, which will take some work to clean up. Until then, I'm personally comfortable saying that internally we can depend on always having a single layer of wrapper over the MeteredTimestamped store and just unwrapping it to get access to the new methods. The advantage is that we really minimize the surface area we have to change to implement this feature (and therefore minimize building a lot more on top of the mess we already have). The risk is small: we don't get compiler checking, but any/all of our tests would fail if we broke this assumption.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r401859252", "createdAt": "2020-04-01T19:33:00Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableSource.java", "diffHunk": "@@ -86,12 +90,16 @@ public void init(final ProcessorContext context) {\n             metrics = (StreamsMetricsImpl) context.metrics();\n             droppedRecordsSensor = droppedRecordsSensorOrSkippedRecordsSensor(Thread.currentThread().getName(), context.taskId().toString(), metrics);\n             if (queryableName != null) {\n-                store = (TimestampedKeyValueStore<K, V>) context.getStateStore(queryableName);\n+                store = (TimestampedSerializedKeyValueStore<K, V>) context.getStateStore(queryableName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "209d37662114b871cbdb9a7ee36632daad53ca08"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg3NTYyMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @Test\n          \n          \n            \n                public void testKTableEmitOnChange() {\n          \n          \n            \n                    final StreamsBuilder builder = new StreamsBuilder();\n          \n          \n            \n                    final String topic1 = \"topic1\";\n          \n          \n            \n            \n          \n          \n            \n                    final KTable<String, Integer> table1 =\n          \n          \n            \n                        builder.table(topic1, Consumed.with(Serdes.String(), Serdes.Integer()), Materialized.as(\"store\"));\n          \n          \n            \n            \n          \n          \n            \n                    final MockProcessorSupplier<String, Integer> supplier = new MockProcessorSupplier<>();\n          \n          \n            \n                    table1.toStream().process(supplier);\n          \n          \n            \n            \n          \n          \n            \n                    try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n          \n          \n            \n                        final TestInputTopic<String, Integer> inputTopic =\n          \n          \n            \n                                driver.createInputTopic(topic1, new StringSerializer(), new IntegerSerializer());\n          \n          \n            \n                        inputTopic.pipeInput(\"A\", 1, 10L);\n          \n          \n            \n                        inputTopic.pipeInput(\"B\", 2, 11L);\n          \n          \n            \n                        inputTopic.pipeInput(\"A\", 1, 10L);\n          \n          \n            \n                        inputTopic.pipeInput(\"B\", 3, 13L);\n          \n          \n            \n            \n          \n          \n            \n                        assertEquals(1.0,\n          \n          \n            \n                            getMetricByName(driver.metrics(), \"idempotent-update-skip-total\", \"stream-processor-node-metrics\").metricValue());\n          \n          \n            \n                    }\n          \n          \n            \n            \n          \n          \n            \n                    assertEquals(\n          \n          \n            \n                        asList(new KeyValueTimestamp<>(\"A\", 1, 10L),\n          \n          \n            \n                            new KeyValueTimestamp<>(\"B\", 2, 11L),\n          \n          \n            \n                            new KeyValueTimestamp<>(\"B\", 3, 13L)),\n          \n          \n            \n                        supplier.theCapturedProcessor().processed);\n          \n          \n            \n                }\n          \n          \n            \n                @Test\n          \n          \n            \n                public void testKTableEmitOnChange() {\n          \n          \n            \n                    final StreamsBuilder builder = new StreamsBuilder();\n          \n          \n            \n                    final String topic1 = \"topic1\";\n          \n          \n            \n            \n          \n          \n            \n                    builder.table(topic1, Consumed.with(Serdes.String(), Serdes.Integer()), Materialized.as(\"store\"))\n          \n          \n            \n                           .toStream()\n          \n          \n            \n                           .to(\"output\");\n          \n          \n            \n            \n          \n          \n            \n                    try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n          \n          \n            \n                        final TestInputTopic<String, Integer> inputTopic =\n          \n          \n            \n                            driver.createInputTopic(topic1, new StringSerializer(), new IntegerSerializer());\n          \n          \n            \n                        final TestOutputTopic<String, Integer> outputTopic =\n          \n          \n            \n                            driver.createOutputTopic(\"output\", new StringDeserializer(), new IntegerDeserializer());\n          \n          \n            \n            \n          \n          \n            \n                        inputTopic.pipeInput(\"A\", 1, 10L);\n          \n          \n            \n                        inputTopic.pipeInput(\"B\", 2, 11L);\n          \n          \n            \n                        inputTopic.pipeInput(\"A\", 1, 12L);\n          \n          \n            \n                        inputTopic.pipeInput(\"B\", 3, 13L);\n          \n          \n            \n            \n          \n          \n            \n                        assertThat(\n          \n          \n            \n                            getMetricByName(driver.metrics(), \"idempotent-update-skip-total\", \"stream-processor-node-metrics\").metricValue(),\n          \n          \n            \n                            is(1.0)\n          \n          \n            \n                        );\n          \n          \n            \n            \n          \n          \n            \n                        assertThat(\n          \n          \n            \n                            outputTopic.readRecordsToList(),\n          \n          \n            \n                            is(\n          \n          \n            \n                                asList(new TestRecord<>(\"A\", 1, Instant.ofEpochMilli(10L)),\n          \n          \n            \n                                       new TestRecord<>(\"B\", 2, Instant.ofEpochMilli(11L)),\n          \n          \n            \n                                       new TestRecord<>(\"B\", 3, Instant.ofEpochMilli(13L)))\n          \n          \n            \n                            )\n          \n          \n            \n                        );\n          \n          \n            \n                    }\n          \n          \n            \n                }\n          \n      \n    \n    \n  \n\nVery nice test!\nTwo suggestions for the price of one:\n\nIt's basically the same either way, but since we're using TopologyTestDriver and TestInputTopic, let's use TestOutputTopic as well instead of MockProcessorSupplier for the verification.\nIn the KTable context, we agreed to consider the update idempotent even if the timestamp is different, as long as the value is the same. Therefore, I've changed the update to A to have timestamp 12 instead of 10.\n\nOf course, we'd need several more tests to really verify all the angles of this feature.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r401875621", "createdAt": "2020-04-01T20:02:24Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableSourceTest.java", "diffHunk": "@@ -85,6 +85,36 @@ public void testKTable() {\n             supplier.theCapturedProcessor().processed);\n     }\n \n+    @Test\n+    public void testKTableEmitOnChange() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final String topic1 = \"topic1\";\n+\n+        final KTable<String, Integer> table1 =\n+            builder.table(topic1, Consumed.with(Serdes.String(), Serdes.Integer()), Materialized.as(\"store\"));\n+\n+        final MockProcessorSupplier<String, Integer> supplier = new MockProcessorSupplier<>();\n+        table1.toStream().process(supplier);\n+\n+        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n+            final TestInputTopic<String, Integer> inputTopic =\n+                    driver.createInputTopic(topic1, new StringSerializer(), new IntegerSerializer());\n+            inputTopic.pipeInput(\"A\", 1, 10L);\n+            inputTopic.pipeInput(\"B\", 2, 11L);\n+            inputTopic.pipeInput(\"A\", 1, 10L);\n+            inputTopic.pipeInput(\"B\", 3, 13L);\n+\n+            assertEquals(1.0,\n+                getMetricByName(driver.metrics(), \"idempotent-update-skip-total\", \"stream-processor-node-metrics\").metricValue());\n+        }\n+\n+        assertEquals(\n+            asList(new KeyValueTimestamp<>(\"A\", 1, 10L),\n+                new KeyValueTimestamp<>(\"B\", 2, 11L),\n+                new KeyValueTimestamp<>(\"B\", 3, 13L)),\n+            supplier.theCapturedProcessor().processed);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "209d37662114b871cbdb9a7ee36632daad53ca08"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg3ODEyNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public boolean putIfDifferent(final K key,\n          \n          \n            \n                                              final ValueAndTimestamp<V> newValue,\n          \n          \n            \n                                              final byte[] oldSerializedValue) {\n          \n          \n            \n                    final Bytes serializedNewValueBytes = Bytes.wrap(serdes.rawValue(newValue));\n          \n          \n            \n                    final Bytes serializedOldValueBytes = Bytes.wrap(oldSerializedValue);\n          \n          \n            \n                    if (serializedNewValueBytes == null ||\n          \n          \n            \n                        !serializedNewValueBytes.equals(serializedOldValueBytes)) {\n          \n          \n            \n                        super.put(key, newValue);\n          \n          \n            \n                        return true;\n          \n          \n            \n                    }\n          \n          \n            \n                    return false;\n          \n          \n            \n                }\n          \n          \n            \n                public boolean putIfDifferentValues(final K key,\n          \n          \n            \n                                                    final ValueAndTimestamp<V> newValue,\n          \n          \n            \n                                                    final byte[] oldSerializedValue) {\n          \n          \n            \n                    try {\n          \n          \n            \n                        return maybeMeasureLatency(\n          \n          \n            \n                            () -> {\n          \n          \n            \n                                final byte[] newSerializedValue = serdes.rawValue(newValue);\n          \n          \n            \n                                if (ValueAndTimestampSerializer.maskTimestampAndCompareValues(oldSerializedValue, newSerializedValue)) {\n          \n          \n            \n                                    return false;\n          \n          \n            \n                                } else {\n          \n          \n            \n                                    wrapped().put(keyBytes(key), newSerializedValue);\n          \n          \n            \n                                    return true;\n          \n          \n            \n                                }\n          \n          \n            \n                            },\n          \n          \n            \n                            time,\n          \n          \n            \n                            putSensor\n          \n          \n            \n                        );\n          \n          \n            \n                    } catch (final ProcessorStateException e) {\n          \n          \n            \n                        final String message = String.format(e.getMessage(), key, newValue);\n          \n          \n            \n                        throw new ProcessorStateException(message, e);\n          \n          \n            \n                    }\n          \n          \n            \n                }\n          \n      \n    \n    \n  \n\nRecommending a few tweaks here as well:\n\nWe need to measure the put latency including serialization\nWe should avoid serializing twice (which happens when you delegate to super.put)\nFor KTables at least, we should ignore the timestamp when deciding whether to really put it or not, so I renamed the method to clarify it's only comparing the value, and I also created an extra comparison method in the ValueAndTimestampSerializer (since it manages the schema, it can safely skip over the timestamp in the serialized data).\n\nHere's what I sketched for the ValueAndTimestampSerializer method:\n    public static boolean maskTimestampAndCompareValues(final byte[] left, final byte[] right) {\n        // adapted from Arrays.equals\n        if (left == right)\n            return true;\n        if (left ==null || right ==null)\n            return false;\n\n        final int length = left.length;\n        if (right.length != length)\n            return false;\n\n        // skip the timestamp when comparing just the values\n        for (int i=Long.BYTES; i<length; i++)\n            if (left[i] != right[i])\n                return false;\n\n        return true;\n    }", "url": "https://github.com/apache/kafka/pull/8254#discussion_r401878124", "createdAt": "2020-04-01T20:07:18Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStore.java", "diffHunk": "@@ -53,4 +56,28 @@ void initStoreSerde(final ProcessorContext context) {\n             keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n             valueSerde == null ? new ValueAndTimestampSerde<>((Serde<V>) context.valueSerde()) : valueSerde);\n     }\n+\n+    public RawAndDeserializedValue<V> getWithBinary(final K key) {\n+        try {\n+            final byte[] serializedValue = wrapped().get(keyBytes(key));\n+            return new RawAndDeserializedValue<V>(serializedValue,\n+                maybeMeasureLatency(() -> outerValue(serializedValue), time, getSensor));\n+        } catch (final ProcessorStateException e) {\n+            final String message = String.format(e.getMessage(), key);\n+            throw new ProcessorStateException(message, e);\n+        }\n+    }\n+\n+    public boolean putIfDifferent(final K key,\n+                                  final ValueAndTimestamp<V> newValue,\n+                                  final byte[] oldSerializedValue) {\n+        final Bytes serializedNewValueBytes = Bytes.wrap(serdes.rawValue(newValue));\n+        final Bytes serializedOldValueBytes = Bytes.wrap(oldSerializedValue);\n+        if (serializedNewValueBytes == null ||\n+            !serializedNewValueBytes.equals(serializedOldValueBytes)) {\n+            super.put(key, newValue);\n+            return true;\n+        }\n+        return false;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "209d37662114b871cbdb9a7ee36632daad53ca08"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fef99c9f69143a89547fe36de6b76b908c5db90", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/8fef99c9f69143a89547fe36de6b76b908c5db90", "committedDate": "2020-04-02T15:59:34Z", "message": "Update streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableSourceTest.java\n\nCo-Authored-By: John Roesler <vvcephei@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d7c4ad32ea71d1dca26037447ec7ab69fab63e2", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/1d7c4ad32ea71d1dca26037447ec7ab69fab63e2", "committedDate": "2020-04-02T16:04:47Z", "message": "Update streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableSource.java\n\nCo-Authored-By: John Roesler <vvcephei@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d062bfaeb5bec8df605f36748f32b8bb917728e3", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/d062bfaeb5bec8df605f36748f32b8bb917728e3", "committedDate": "2020-04-02T16:10:23Z", "message": "Update streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStore.java\n\nCo-Authored-By: John Roesler <vvcephei@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d0737f583eedc4b27014f59c3bcf32846d9fd77e", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/d0737f583eedc4b27014f59c3bcf32846d9fd77e", "committedDate": "2020-04-02T16:37:43Z", "message": "Fixing compilation errors and other issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "afdde96abfe246fa7dd70059f1d71111728ba81f", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/afdde96abfe246fa7dd70059f1d71111728ba81f", "committedDate": "2020-04-02T16:38:54Z", "message": "Removing unneeded class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35c16b11cae35ee04a064b2044dc388c59299503", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/35c16b11cae35ee04a064b2044dc388c59299503", "committedDate": "2020-04-02T16:41:58Z", "message": "Removing all vestiges of new class"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NzcwOTQ1", "url": "https://github.com/apache/kafka/pull/8254#pullrequestreview-386770945", "createdAt": "2020-04-02T20:41:02Z", "commit": {"oid": "35c16b11cae35ee04a064b2044dc388c59299503"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQyMDo0MTowMlrOF_8TTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQyMDo0MTowMlrOF_8TTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjU5MjU4OQ==", "bodyText": "Ah, missed this the last time though. We should also perform the wrapped().get inside the lambda, so that the time to perform the get is included in the latency.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r402592589", "createdAt": "2020-04-02T20:41:02Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStore.java", "diffHunk": "@@ -53,4 +56,47 @@ void initStoreSerde(final ProcessorContext context) {\n             keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n             valueSerde == null ? new ValueAndTimestampSerde<>((Serde<V>) context.valueSerde()) : valueSerde);\n     }\n-}\n\\ No newline at end of file\n+\n+    public RawAndDeserializedValue<V> getWithBinary(final K key) {\n+        try {\n+            final byte[] serializedValue = wrapped().get(keyBytes(key));\n+            return new RawAndDeserializedValue<V>(serializedValue,\n+                maybeMeasureLatency(() -> outerValue(serializedValue), time, getSensor));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "35c16b11cae35ee04a064b2044dc388c59299503"}, "originalPosition": 33}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/9e7649b61352d118f90bfb765dc522b942504681", "committedDate": "2020-04-03T16:38:28Z", "message": "Adding more inclusive lambda"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3NDY0NDE1", "url": "https://github.com/apache/kafka/pull/8254#pullrequestreview-387464415", "createdAt": "2020-04-03T17:53:05Z", "commit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3NTQ1ODIx", "url": "https://github.com/apache/kafka/pull/8254#pullrequestreview-387545821", "createdAt": "2020-04-03T20:03:46Z", "commit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4OTU4NzE0", "url": "https://github.com/apache/kafka/pull/8254#pullrequestreview-388958714", "createdAt": "2020-04-07T09:49:56Z", "commit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwOTo0OTo1NlrOGB7x7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMDo0NDoxOFrOGB9srw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDY4MTE5Ng==", "bodyText": "req: Please change formatting to comply with code style guidelines\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            skippedIdempotentUpdatesSensor = skippedIdempotentUpdatesSensor(Thread.currentThread().getName(),\n          \n          \n            \n                                                                                            context.taskId().toString(),\n          \n          \n            \n                                                                                            ((InternalProcessorContext) context).currentNode().name(),\n          \n          \n            \n                                                                                            metrics);\n          \n          \n            \n                            skippedIdempotentUpdatesSensor = skippedIdempotentUpdatesSensor(\n          \n          \n            \n                                Thread.currentThread().getName(), \n          \n          \n            \n                                context.taskId().toString(), \n          \n          \n            \n                                ((InternalProcessorContext) context).currentNode().name(), \n          \n          \n            \n                                metrics\n          \n          \n            \n                            );", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404681196", "createdAt": "2020-04-07T09:49:56Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableSource.java", "diffHunk": "@@ -86,12 +91,21 @@ public void init(final ProcessorContext context) {\n             metrics = (StreamsMetricsImpl) context.metrics();\n             droppedRecordsSensor = droppedRecordsSensorOrSkippedRecordsSensor(Thread.currentThread().getName(), context.taskId().toString(), metrics);\n             if (queryableName != null) {\n-                store = (TimestampedKeyValueStore<K, V>) context.getStateStore(queryableName);\n+                final StateStore stateStore = context.getStateStore(queryableName);\n+                try {\n+                    store = ((WrappedStateStore<MeteredTimestampedKeyValueStore<K, V>, K, V>) stateStore).wrapped();\n+                } catch (final ClassCastException e) {\n+                    throw new IllegalStateException(\"Unexpected store type: \" + stateStore.getClass() + \" for store: \" + queryableName, e);\n+                }\n                 tupleForwarder = new TimestampedTupleForwarder<>(\n                     store,\n                     context,\n                     new TimestampedCacheFlushListener<>(context),\n                     sendOldValues);\n+                skippedIdempotentUpdatesSensor = skippedIdempotentUpdatesSensor(Thread.currentThread().getName(),\n+                                                                                context.taskId().toString(),\n+                                                                                ((InternalProcessorContext) context).currentNode().name(),\n+                                                                                metrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDY4MjI2Nw==", "bodyText": "req: Please add a unit test in ProcessorNodeMetricsTest.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404682267", "createdAt": "2020-04-07T09:51:39Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/ProcessorNodeMetrics.java", "diffHunk": "@@ -108,6 +114,22 @@ public static Sensor suppressionEmitSensor(final String threadId,\n         );\n     }\n \n+    public static Sensor skippedIdempotentUpdatesSensor(final String threadId,\n+            final String taskId,\n+            final String processorNodeId,\n+            final StreamsMetricsImpl streamsMetrics) {\n+        return throughputSensor(\n+            threadId,\n+            taskId,\n+            processorNodeId,\n+            IDEMPOTENT_UPDATE_SKIP,\n+            IDEMPOTENT_UPDATE_SKIP_RATE_DESCRIPTION,\n+            IDEMPOTENT_UPDATE_SKIP_TOTAL_DESCRIPTION,\n+            RecordingLevel.DEBUG,\n+            streamsMetrics\n+        );\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDY5MDUzMQ==", "bodyText": "prop: Delete this comment since it is not very useful.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404690531", "createdAt": "2020-04-07T10:05:22Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializer.java", "diffHunk": "@@ -34,6 +34,25 @@\n         timestampSerializer = new LongSerializer();\n     }\n \n+    public static boolean maskTimestampAndCompareValues(final byte[] left, final byte[] right) {\n+        // adapted from Arrays.equals", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDY5MzUzNA==", "bodyText": "prop: Please use braces to delimit the scopes of the loop and the ifs.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404693534", "createdAt": "2020-04-07T10:10:21Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializer.java", "diffHunk": "@@ -34,6 +34,25 @@\n         timestampSerializer = new LongSerializer();\n     }\n \n+    public static boolean maskTimestampAndCompareValues(final byte[] left, final byte[] right) {\n+        // adapted from Arrays.equals\n+        if (left == right)\n+            return true;\n+        if (left == null || right == null)\n+            return false;\n+\n+        final int length = left.length;\n+        if (right.length != length)\n+            return false;\n+\n+        // skip the timestamp when comparing just the values\n+        for (int i = Long.BYTES; i < length; i++)\n+            if (left[i] != right[i])\n+                return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDY5NjkwMA==", "bodyText": "prop: Instead of adding the comment, factor out this code to a method named skipTimestampAndCompareValues().", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404696900", "createdAt": "2020-04-07T10:16:08Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializer.java", "diffHunk": "@@ -34,6 +34,25 @@\n         timestampSerializer = new LongSerializer();\n     }\n \n+    public static boolean maskTimestampAndCompareValues(final byte[] left, final byte[] right) {\n+        // adapted from Arrays.equals\n+        if (left == right)\n+            return true;\n+        if (left == null || right == null)\n+            return false;\n+\n+        final int length = left.length;\n+        if (right.length != length)\n+            return false;\n+\n+        // skip the timestamp when comparing just the values\n+        for (int i = Long.BYTES; i < length; i++)\n+            if (left[i] != right[i])\n+                return false;\n+\n+        return true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDcwNDg1NA==", "bodyText": "Q: If the record is out-of-order, shouldn't you put the value into the state store regardless of whether it is different from the old value or not? I think this would be more correct because the old value is actually the idempotent update to the new out-of-order value. This is one of the rare cases where we can correct the order. WDYT?", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404704854", "createdAt": "2020-04-07T10:29:52Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableSource.java", "diffHunk": "@@ -119,8 +134,13 @@ public void process(final K key, final V value) {\n                 } else {\n                     oldValue = null;\n                 }\n-                store.put(key, ValueAndTimestamp.make(value, context().timestamp()));\n-                tupleForwarder.maybeForward(key, value, oldValue);\n+                final boolean isDifferentValue = \n+                    store.putIfDifferentValues(key, ValueAndTimestamp.make(value, context().timestamp()), tuple.serializedValue);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDcxMTUwNg==", "bodyText": "Q: Why do you need the TopologyTestDriver here? I see that the other test use it. I guess you could simply instantiate a KTableSource, get the processor from it, and test directly the processor.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404711506", "createdAt": "2020-04-07T10:42:17Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableSourceTest.java", "diffHunk": "@@ -85,6 +89,40 @@ public void testKTable() {\n             supplier.theCapturedProcessor().processed);\n     }\n \n+    @Test\n+    public void testKTableSourceEmitOnChange() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDcxMTk4NQ==", "bodyText": "req: Please add unit tests for this method.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404711985", "createdAt": "2020-04-07T10:43:07Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializer.java", "diffHunk": "@@ -34,6 +34,25 @@\n         timestampSerializer = new LongSerializer();\n     }\n \n+    public static boolean maskTimestampAndCompareValues(final byte[] left, final byte[] right) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDcxMjI0Mw==", "bodyText": "req: Please add unit tests for this method.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404712243", "createdAt": "2020-04-07T10:43:38Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStore.java", "diffHunk": "@@ -53,4 +56,48 @@ void initStoreSerde(final ProcessorContext context) {\n             keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n             valueSerde == null ? new ValueAndTimestampSerde<>((Serde<V>) context.valueSerde()) : valueSerde);\n     }\n-}\n\\ No newline at end of file\n+\n+    public RawAndDeserializedValue<V> getWithBinary(final K key) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDcxMjYyMw==", "bodyText": "req: Please add unit tests for this method.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r404712623", "createdAt": "2020-04-07T10:44:18Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStore.java", "diffHunk": "@@ -53,4 +56,48 @@ void initStoreSerde(final ProcessorContext context) {\n             keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n             valueSerde == null ? new ValueAndTimestampSerde<>((Serde<V>) context.valueSerde()) : valueSerde);\n     }\n-}\n\\ No newline at end of file\n+\n+    public RawAndDeserializedValue<V> getWithBinary(final K key) {\n+        try {\n+            return maybeMeasureLatency(() -> { \n+                final byte[] serializedValue = wrapped().get(keyBytes(key));\n+                return new RawAndDeserializedValue<V>(serializedValue, outerValue(serializedValue));\n+            }, time, getSensor);\n+        } catch (final ProcessorStateException e) {\n+            final String message = String.format(e.getMessage(), key);\n+            throw new ProcessorStateException(message, e);\n+        }\n+    }\n+\n+    public boolean putIfDifferentValues(final K key,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e7649b61352d118f90bfb765dc522b942504681"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21a734591ee0110c3b8131dd77b1b2fe0221235c", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/21a734591ee0110c3b8131dd77b1b2fe0221235c", "committedDate": "2020-04-07T23:42:21Z", "message": "Update streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableSource.java\n\nCo-Authored-By: Bruno Cadonna <bruno@confluent.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c4257e1a3c4f8e36587ee8fa1f568df10fe9ce32", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/c4257e1a3c4f8e36587ee8fa1f568df10fe9ce32", "committedDate": "2020-04-11T22:50:22Z", "message": "Adding some modifications"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6ff8b650b10f404352eafee98eec1af4c764884b", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/6ff8b650b10f404352eafee98eec1af4c764884b", "committedDate": "2020-04-11T22:50:54Z", "message": "Merge branch 'EMIT-ON-CHANGE' of https://github.com/ConcurrencyPractitioner/kafka into EMIT-ON-CHANGE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "860d41be1f724795c4187d56497f95c24aeb7667", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/860d41be1f724795c4187d56497f95c24aeb7667", "committedDate": "2020-04-11T22:52:55Z", "message": "Pushing changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2871c6b5e284d0a6a7435d83acf9dc2a603dccc4", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/2871c6b5e284d0a6a7435d83acf9dc2a603dccc4", "committedDate": "2020-04-11T23:03:27Z", "message": "Realiging diffs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "367ebafe0a26941890d1e35ae1154f22b689b336", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/367ebafe0a26941890d1e35ae1154f22b689b336", "committedDate": "2020-04-11T23:32:58Z", "message": "Adding tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "449efd96a0971fd8cf498850461e468237129c83", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/449efd96a0971fd8cf498850461e468237129c83", "committedDate": "2020-04-13T20:21:44Z", "message": "Adding test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9cd3726269010fdd03d583d8733236e5ad785324", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/9cd3726269010fdd03d583d8733236e5ad785324", "committedDate": "2020-04-15T16:37:47Z", "message": "Adding fixed getWithBinary TEst"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cdad3484f9b8146beafaf02af7afcdaf010c94d4", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/cdad3484f9b8146beafaf02af7afcdaf010c94d4", "committedDate": "2020-04-15T16:44:56Z", "message": "Fixing description"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "48cc4d93641cf96549debca0d08a300d824602d9", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/48cc4d93641cf96549debca0d08a300d824602d9", "committedDate": "2020-04-17T16:12:22Z", "message": "Making some test changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de0fc6d8cc5a0480d8ac3dc2ef0452795f2abc56", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/de0fc6d8cc5a0480d8ac3dc2ef0452795f2abc56", "committedDate": "2020-04-23T20:11:25Z", "message": "Merge branch 'trunk' into EMIT-ON-CHANGE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d396fd4e60e29eb4a4d1c4c4963ada8809562839", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/d396fd4e60e29eb4a4d1c4c4963ada8809562839", "committedDate": "2020-04-23T20:31:37Z", "message": "Making some modifications to test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d931074dd15f1af94312fad27d5a3cd61321adf", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/7d931074dd15f1af94312fad27d5a3cd61321adf", "committedDate": "2020-04-23T20:31:45Z", "message": "Merge branch 'EMIT-ON-CHANGE' of https://github.com/ConcurrencyPractitioner/kafka into EMIT-ON-CHANGE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "07d40aff0ef33920e2cbdc24020ecae8929ef9d8", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/07d40aff0ef33920e2cbdc24020ecae8929ef9d8", "committedDate": "2020-04-24T19:55:21Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into EMIT-ON-CHANGE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4779b27b1c475cd8de848fbc62219a291e6ce3e2", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/4779b27b1c475cd8de848fbc62219a291e6ce3e2", "committedDate": "2020-04-24T19:57:16Z", "message": "Fixing details"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ddbf2cf17c07a37959875e4ad79b1c4ad818c05a", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/ddbf2cf17c07a37959875e4ad79b1c4ad818c05a", "committedDate": "2020-04-25T01:49:14Z", "message": "Catching bad modification"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAxNDg1MTU0", "url": "https://github.com/apache/kafka/pull/8254#pullrequestreview-401485154", "createdAt": "2020-04-28T04:14:40Z", "commit": {"oid": "ddbf2cf17c07a37959875e4ad79b1c4ad818c05a"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwNDoxNDo0MFrOGNBw3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwNDozNjowNFrOGNCJpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMxMzU2Nw==", "bodyText": "Ah, we'd better get rid of all the printlns before merging.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r416313567", "createdAt": "2020-04-28T04:14:40Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableSource.java", "diffHunk": "@@ -108,7 +126,9 @@ public void process(final K key, final V value) {\n             }\n \n             if (queryableName != null) {\n-                final ValueAndTimestamp<V> oldValueAndTimestamp = store.get(key);\n+                final RawAndDeserializedValue<V> tuple = store.getWithBinary(key);\n+                System.out.println(\"Old value found to be: \" + tuple.value);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ddbf2cf17c07a37959875e4ad79b1c4ad818c05a"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMxNjU0NQ==", "bodyText": "That last ); should go on a new line.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r416316545", "createdAt": "2020-04-28T04:25:05Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/ProcessorNodeMetricsTest.java", "diffHunk": "@@ -97,6 +97,27 @@ public void shouldGetSuppressionEmitSensor() {\n             () -> ProcessorNodeMetrics.suppressionEmitSensor(THREAD_ID, TASK_ID, PROCESSOR_NODE_ID, streamsMetrics));\n     }\n \n+    @Test\n+    public void shouldGetIdempotentUpdateSkipSensor() {\n+        final String metricNamePrefix = \"idempotent-update-skip\";\n+        final String descriptionOfCount = \"The total number of skipped idempotent updates\";\n+        final String descriptionOfRate = \"The average number of skipped idempotent updates per second\";\n+        expect(streamsMetrics.nodeLevelSensor(THREAD_ID, TASK_ID, PROCESSOR_NODE_ID, metricNamePrefix, RecordingLevel.DEBUG))\n+            .andReturn(expectedSensor);\n+        expect(streamsMetrics.nodeLevelTagMap(THREAD_ID, TASK_ID, PROCESSOR_NODE_ID)).andReturn(tagMap);\n+        StreamsMetricsImpl.addInvocationRateAndCountToSensor(\n+            expectedSensor,\n+            StreamsMetricsImpl.PROCESSOR_NODE_LEVEL_GROUP,\n+            tagMap,\n+            metricNamePrefix,\n+            descriptionOfRate,\n+            descriptionOfCount\n+        );\n+\n+        verifySensor(\n+            () -> ProcessorNodeMetrics.skippedIdempotentUpdatesSensor(THREAD_ID, TASK_ID, PROCESSOR_NODE_ID, streamsMetrics));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ddbf2cf17c07a37959875e4ad79b1c4ad818c05a"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMxNzM3Mg==", "bodyText": "Since you mocked the inner store get, you shouldn't need to actually do a put, right?", "url": "https://github.com/apache/kafka/pull/8254#discussion_r416317372", "createdAt": "2020-04-28T04:27:55Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStoreTest.java", "diffHunk": "@@ -181,6 +183,41 @@ public void shouldWriteBytesToInnerStoreAndRecordPutMetric() {\n         verify(inner);\n     }\n \n+    @Test\n+    public void shouldGetWithBinary() {\n+        expect(inner.get(keyBytes)).andReturn(valueAndTimestampBytes);\n+\n+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));\n+        expectLastCall();\n+        init();\n+\n+        metered.put(key, valueAndTimestamp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ddbf2cf17c07a37959875e4ad79b1c4ad818c05a"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMxOTczNg==", "bodyText": "It's kind of hard to read this test since it depends partly on externally constructed data and partially on data (like newValueAndTimestamp) created in the method itself.\nSince there were other comments that need to be addressed, I'll go ahead and also add a couple of nits, if you don't mind...\nInstead of testing two cases in one test method, can you split it into two test methods. I.e., one for L213, and another for L218. Also when you do that, can you just create all the values and serializedValues that you need in the test itself?\nThanks!", "url": "https://github.com/apache/kafka/pull/8254#discussion_r416319736", "createdAt": "2020-04-28T04:35:37Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStoreTest.java", "diffHunk": "@@ -181,6 +183,41 @@ public void shouldWriteBytesToInnerStoreAndRecordPutMetric() {\n         verify(inner);\n     }\n \n+    @Test\n+    public void shouldGetWithBinary() {\n+        expect(inner.get(keyBytes)).andReturn(valueAndTimestampBytes);\n+\n+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));\n+        expectLastCall();\n+        init();\n+\n+        metered.put(key, valueAndTimestamp);\n+\n+        final RawAndDeserializedValue<String> valueWithBinary = metered.getWithBinary(key);\n+        assertEquals(valueWithBinary.value, valueAndTimestamp);\n+        assertEquals(valueWithBinary.serializedValue, valueAndTimestampBytes);\n+    }\n+\n+    @SuppressWarnings(\"resource\")\n+    @Test\n+    public void shouldPutIfDifferentValues() {\n+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ddbf2cf17c07a37959875e4ad79b1c4ad818c05a"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMxOTkxMQ==", "bodyText": "Can you also split this out into a separate method, please? Thanks!", "url": "https://github.com/apache/kafka/pull/8254#discussion_r416319911", "createdAt": "2020-04-28T04:36:04Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializerTest.java", "diffHunk": "@@ -50,6 +52,21 @@ public void shouldSerializeNonNullDataUsingTheInternalSerializer() {\n         assertThat(deserialized, is(valueAndTimestamp));\n     }\n \n+    @Test\n+    public void shouldCompareSerializedValuesWithoutTimestamp() {\n+        final String value = \"food\";\n+\n+        final ValueAndTimestamp<String> oldValueAndTimestamp = ValueAndTimestamp.make(value, TIMESTAMP);\n+        final byte[] oldSerializedValue = STRING_SERDE.serializer().serialize(TOPIC, oldValueAndTimestamp);\n+        final ValueAndTimestamp<String> newValueAndTimestamp = ValueAndTimestamp.make(value, TIMESTAMP + 1);\n+        final byte[] newSerializedValue = STRING_SERDE.serializer().serialize(TOPIC, newValueAndTimestamp);\n+        assertTrue(ValueAndTimestampSerializer.maskTimestampAndCompareValues(oldSerializedValue, newSerializedValue));\n+\n+        final ValueAndTimestamp<String> outOfOrderValueAndTimestamp = ValueAndTimestamp.make(value, TIMESTAMP - 1);\n+        final byte[] outOfOrderSerializedValue = STRING_SERDE.serializer().serialize(TOPIC, outOfOrderValueAndTimestamp);\n+        assertFalse(ValueAndTimestampSerializer.maskTimestampAndCompareValues(oldSerializedValue, outOfOrderSerializedValue));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ddbf2cf17c07a37959875e4ad79b1c4ad818c05a"}, "originalPosition": 25}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "197ddd2c25311c611b8c456660d92130a778730b", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/197ddd2c25311c611b8c456660d92130a778730b", "committedDate": "2020-04-29T15:30:37Z", "message": "Resolving most comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "527ba28787f3d3db7f4d36d406f33afdc5b4e1da", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/527ba28787f3d3db7f4d36d406f33afdc5b4e1da", "committedDate": "2020-04-29T15:34:24Z", "message": "Deleting massive amount of print statements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bae2860750a042f3ab568ea301aff4caa9bab383", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/bae2860750a042f3ab568ea301aff4caa9bab383", "committedDate": "2020-04-29T15:35:51Z", "message": "Final removal"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf5532f3946fd7064222e940a6469343f9d46a01", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/bf5532f3946fd7064222e940a6469343f9d46a01", "committedDate": "2020-04-29T15:50:31Z", "message": "Resolving last comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5NTIyNjI4", "url": "https://github.com/apache/kafka/pull/8254#pullrequestreview-409522628", "createdAt": "2020-05-11T20:54:02Z", "commit": {"oid": "bf5532f3946fd7064222e940a6469343f9d46a01"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQyMDo1NDowMlrOGTs_wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQyMTowMDoxMlrOGTtMdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzMxMzM0Ng==", "bodyText": "Ah, sorry to say, one more thing slipped by me before. We should verify(inner) at the end of both of these tests. It should actually fail for shouldNotPutIfSameValuesAndGreaterTimestamp because we should not call inner.put in this case. To fix that, we would just delete L202, where we set up the mock for inner.put. Then, the mock would be initialized to expect no calls, and the verification would fail if we did call it.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r423313346", "createdAt": "2020-05-11T20:54:02Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStoreTest.java", "diffHunk": "@@ -181,6 +183,52 @@ public void shouldWriteBytesToInnerStoreAndRecordPutMetric() {\n         verify(inner);\n     }\n \n+    @Test\n+    public void shouldGetWithBinary() {\n+        expect(inner.get(keyBytes)).andReturn(valueAndTimestampBytes);\n+\n+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));\n+        expectLastCall();\n+        init();\n+\n+        final RawAndDeserializedValue<String> valueWithBinary = metered.getWithBinary(key);\n+        assertEquals(valueWithBinary.value, valueAndTimestamp);\n+        assertEquals(valueWithBinary.serializedValue, valueAndTimestampBytes);\n+    }\n+\n+    @SuppressWarnings(\"resource\")\n+    @Test\n+    public void shouldNotPutIfSameValuesAndGreaterTimestamp() {\n+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));\n+        expectLastCall();\n+        init();\n+\n+        metered.put(key, valueAndTimestamp);\n+        final ValueAndTimestampSerde<String> stringSerde = new ValueAndTimestampSerde<>(Serdes.String());\n+        final byte[] encodedOldValue = stringSerde.serializer().serialize(\"TOPIC\", valueAndTimestamp);\n+\n+        final ValueAndTimestamp<String> newValueAndTimestamp = ValueAndTimestamp.make(\"value\", 98L);\n+        assertFalse(metered.putIfDifferentValues(key,\n+                                                 newValueAndTimestamp,\n+                                                 encodedOldValue));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf5532f3946fd7064222e940a6469343f9d46a01"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzMxMzYyNg==", "bodyText": "As I mentioned in the earlier comment, we're missing a verify(inner) call at the end of this test.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r423313626", "createdAt": "2020-05-11T20:54:30Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStoreTest.java", "diffHunk": "@@ -181,6 +183,52 @@ public void shouldWriteBytesToInnerStoreAndRecordPutMetric() {\n         verify(inner);\n     }\n \n+    @Test\n+    public void shouldGetWithBinary() {\n+        expect(inner.get(keyBytes)).andReturn(valueAndTimestampBytes);\n+\n+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));\n+        expectLastCall();\n+        init();\n+\n+        final RawAndDeserializedValue<String> valueWithBinary = metered.getWithBinary(key);\n+        assertEquals(valueWithBinary.value, valueAndTimestamp);\n+        assertEquals(valueWithBinary.serializedValue, valueAndTimestampBytes);\n+    }\n+\n+    @SuppressWarnings(\"resource\")\n+    @Test\n+    public void shouldNotPutIfSameValuesAndGreaterTimestamp() {\n+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));\n+        expectLastCall();\n+        init();\n+\n+        metered.put(key, valueAndTimestamp);\n+        final ValueAndTimestampSerde<String> stringSerde = new ValueAndTimestampSerde<>(Serdes.String());\n+        final byte[] encodedOldValue = stringSerde.serializer().serialize(\"TOPIC\", valueAndTimestamp);\n+\n+        final ValueAndTimestamp<String> newValueAndTimestamp = ValueAndTimestamp.make(\"value\", 98L);\n+        assertFalse(metered.putIfDifferentValues(key,\n+                                                 newValueAndTimestamp,\n+                                                 encodedOldValue));\n+    }\n+\n+    @SuppressWarnings(\"resource\")\n+    @Test\n+    public void shouldPutIfOutOfOrder() {\n+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));\n+        expectLastCall();\n+        init();\n+\n+        metered.put(key, valueAndTimestamp);\n+\n+        final ValueAndTimestampSerde<String> stringSerde = new ValueAndTimestampSerde<>(Serdes.String());\n+        final byte[] encodedOldValue = stringSerde.serializer().serialize(\"TOPIC\", valueAndTimestamp);\n+\n+        final ValueAndTimestamp<String> outOfOrderValueAndTimestamp = ValueAndTimestamp.make(\"value\", 95L);\n+        assertTrue(metered.putIfDifferentValues(key, outOfOrderValueAndTimestamp, encodedOldValue));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf5532f3946fd7064222e940a6469343f9d46a01"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzMxNjU5Nw==", "bodyText": "Ah, upon reading that last test, I realized that I previously overlooked when you added the timestamp comparison to this method. We should change the method name for maintainability. It no longer just \"masks the timestamp and compares the values\". Can we instead call it \"compareValuesAndCheckForIncreasingTimestamp\" or something? I can almost guarantee that one or more people will be badly misled by the current method name.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r423316597", "createdAt": "2020-05-11T21:00:12Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializer.java", "diffHunk": "@@ -34,6 +34,51 @@\n         timestampSerializer = new LongSerializer();\n     }\n \n+    private static boolean skipTimestampAndCompareValues(final byte[] left, final byte[] right) {\n+        for (int i = Long.BYTES; i < left.length; i++) {\n+            if (left[i] != right[i]) {\n+                return false;\n+            }\n+        }\n+        return true;\n+    }\n+\n+    private static long extractTimestamp(final byte[] bytes) {\n+        final byte[] timestampBytes = new byte[Long.BYTES];\n+        for (int i = 0; i < Long.BYTES; i++) {\n+            timestampBytes[i] = bytes[i];\n+        }\n+        return ByteBuffer.wrap(timestampBytes).getLong();\n+    }\n+\n+    /**\n+     * @param left  the serialized byte array of the old record in state store\n+     * @param right the serialized byte array of the new record being processed\n+     * @return true if the two serialized values are the same (excluding timestamp) or \n+     *              if the timestamp of right is less than left (indicating out of order record)\n+     *         false otherwise\n+     */\n+    public static boolean maskTimestampAndCompareValues(final byte[] left, final byte[] right) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf5532f3946fd7064222e940a6469343f9d46a01"}, "originalPosition": 28}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9aa12d20bddadde43f4d64d7c6cd2ba597eb079", "author": {"user": {"login": "ConcurrencyPractitioner", "name": "Richard Yu"}}, "url": "https://github.com/apache/kafka/commit/d9aa12d20bddadde43f4d64d7c6cd2ba597eb079", "committedDate": "2020-05-11T23:53:39Z", "message": "Addressing some last comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEwMjk5MDM5", "url": "https://github.com/apache/kafka/pull/8254#pullrequestreview-410299039", "createdAt": "2020-05-12T18:10:38Z", "commit": {"oid": "d9aa12d20bddadde43f4d64d7c6cd2ba597eb079"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxODoxMDozOFrOGUS7kA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxODoxMDozOFrOGUS7kA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkzNDg2NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    expectLastCall();", "url": "https://github.com/apache/kafka/pull/8254#discussion_r423934864", "createdAt": "2020-05-12T18:10:38Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStoreTest.java", "diffHunk": "@@ -181,6 +183,53 @@ public void shouldWriteBytesToInnerStoreAndRecordPutMetric() {\n         verify(inner);\n     }\n \n+    @Test\n+    public void shouldGetWithBinary() {\n+        expect(inner.get(keyBytes)).andReturn(valueAndTimestampBytes);\n+\n+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));\n+        expectLastCall();\n+        init();\n+\n+        final RawAndDeserializedValue<String> valueWithBinary = metered.getWithBinary(key);\n+        assertEquals(valueWithBinary.value, valueAndTimestamp);\n+        assertEquals(valueWithBinary.serializedValue, valueAndTimestampBytes);\n+    }\n+\n+    @SuppressWarnings(\"resource\")\n+    @Test\n+    public void shouldNotPutIfSameValuesAndGreaterTimestamp() {\n+        expectLastCall();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d9aa12d20bddadde43f4d64d7c6cd2ba597eb079"}, "originalPosition": 36}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a3d93dbcd9324ad3a4393541a86258df61722de", "author": {"user": {"login": "vvcephei", "name": "John Roesler"}}, "url": "https://github.com/apache/kafka/commit/2a3d93dbcd9324ad3a4393541a86258df61722de", "committedDate": "2020-05-12T18:10:56Z", "message": "minor test fix"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExNTUyODcx", "url": "https://github.com/apache/kafka/pull/8254#pullrequestreview-411552871", "createdAt": "2020-05-14T07:57:10Z", "commit": {"oid": "2a3d93dbcd9324ad3a4393541a86258df61722de"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNzo1NzoxMVrOGVQWWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNzo1NzoxMVrOGVQWWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDk0MTE0NQ==", "bodyText": "@ConcurrencyPractitioner @vvcephei I'm trying to understand this to debug some broken tests in ksql. Couple questions:\nWhen the timestamp of the newer value is lower (ignoring the value), why do we want to put the new value into the store? Surely the store should have the value with the newer timestamp? Otherwise we could wind up with a corrupt store.\nDon't we still want to put the value in the store (even if we don't forward it on to the next context) if the values are the same but the timestamp is newer? Otherwise if we get an out-of-order update with a different value, but a timestamp in between the rows with the same value, we'd incorrectly put that value into the store, e.g. the following updates:\nTS: 1, K: X, V: A\nTS: 3, K: X, V: A\nTS: 2, K: X, V: B\nwould result in the table containing K: X, V: B, which is wrong.", "url": "https://github.com/apache/kafka/pull/8254#discussion_r424941145", "createdAt": "2020-05-14T07:57:11Z", "author": {"login": "rodesai"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStore.java", "diffHunk": "@@ -53,4 +56,48 @@ void initStoreSerde(final ProcessorContext context) {\n             keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n             valueSerde == null ? new ValueAndTimestampSerde<>((Serde<V>) context.valueSerde()) : valueSerde);\n     }\n-}\n\\ No newline at end of file\n+\n+    public RawAndDeserializedValue<V> getWithBinary(final K key) {\n+        try {\n+            return maybeMeasureLatency(() -> { \n+                final byte[] serializedValue = wrapped().get(keyBytes(key));\n+                return new RawAndDeserializedValue<V>(serializedValue, outerValue(serializedValue));\n+            }, time, getSensor);\n+        } catch (final ProcessorStateException e) {\n+            final String message = String.format(e.getMessage(), key);\n+            throw new ProcessorStateException(message, e);\n+        }\n+    }\n+\n+    public boolean putIfDifferentValues(final K key,\n+                                        final ValueAndTimestamp<V> newValue,\n+                                        final byte[] oldSerializedValue) {\n+        try {\n+            return maybeMeasureLatency(\n+                () -> {\n+                    final byte[] newSerializedValue = serdes.rawValue(newValue);\n+                    if (ValueAndTimestampSerializer.compareValuesAndCheckForIncreasingTimestamp(oldSerializedValue, newSerializedValue)) {\n+                        return false;\n+                    } else {\n+                        wrapped().put(keyBytes(key), newSerializedValue);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a3d93dbcd9324ad3a4393541a86258df61722de"}, "originalPosition": 51}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 170, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}