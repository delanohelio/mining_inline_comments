{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA0OTAwMjA4", "number": 8504, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QwMzoyNjo1N1rODywJsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMjowNDozMFrOD7120w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NTQ0MzA2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QwMzoyNjo1N1rOGG-qLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMlQwMTozNzoxMVrOGParBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk3MTI0NQ==", "bodyText": "This is the fix.  We'll generate the repartitionNode if it's the first time through or if the user has provided a name for the repartition topic.  Otherwise, we cache the repartitionNode for use in subsequent joins on the same KStream object.", "url": "https://github.com/apache/kafka/pull/8504#discussion_r409971245", "createdAt": "2020-04-17T03:26:57Z", "author": {"login": "bbejeck"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java", "diffHunk": "@@ -989,16 +994,18 @@ private void to(final TopicNameExtractor<K, V> topicExtractor,\n             null,\n             optimizableRepartitionNodeBuilder);\n \n-        final OptimizableRepartitionNode<K, V> optimizableRepartitionNode = optimizableRepartitionNodeBuilder.build();\n-        builder.addGraphNode(streamsGraphNode, optimizableRepartitionNode);\n+        if (repartitionNode == null || !name.equals(repartitionName)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM4MDg1Mg==", "bodyText": "Hmmm... I am wondering if just bumping the index would be sufficient and the optimizer would merge the node automatically?\nI am also not sure about the code structure: so far, the DSL layer does not know much about optimizations (even if we \"leak\" a little bit into it, as we built up the StreamsGraphNode graph... We would push some optimization decisions into the DSL layer thus spreading out \"optimization code\"? On the other hand, just inserting one OptimizableRepartitionNode is much more efficient than inserting multiple and let the optimizer remove them later?\nI am also wondering, if we could do the same for other repartition topics?\nLast question: this method is also use for stream-table joins and thus, if one joins a stream with two tables, would this change be backward incompatible? Or would two stream-table joins fail with the same InvalidTopologyException?", "url": "https://github.com/apache/kafka/pull/8504#discussion_r413380852", "createdAt": "2020-04-22T22:39:55Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java", "diffHunk": "@@ -989,16 +994,18 @@ private void to(final TopicNameExtractor<K, V> topicExtractor,\n             null,\n             optimizableRepartitionNodeBuilder);\n \n-        final OptimizableRepartitionNode<K, V> optimizableRepartitionNode = optimizableRepartitionNodeBuilder.build();\n-        builder.addGraphNode(streamsGraphNode, optimizableRepartitionNode);\n+        if (repartitionNode == null || !name.equals(repartitionName)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk3MTI0NQ=="}, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg2MDY5Ng==", "bodyText": "Hmmm... I am wondering if just bumping the index would be sufficient and the optimizer would merge the node automatically?\n\nI hadn't thought of that, but it should work.  I initially had concerns for topology compatibility,  but I don't think that is the case since users can't create re-use a KStream node in joins that needs repartitioning.\n\nI am also not sure about the code structure: so far, the DSL layer does not know much about optimizations (even if we \"leak\" a little bit into it, as we built up the StreamsGraphNode graph... We would push some optimization decisions into the DSL layer thus spreading out \"optimization code\"? On the other hand, just inserting one OptimizableRepartitionNode is much more efficient than inserting multiple and let the optimizer remove them later?\n\nYeah, I agree the current approach is leaking too much optimization into the current code.  I think it will be better to just go ahead and create the topology \"as is\" and let the optimizer do its job.\n\nI am also wondering, if we could do the same for other repartition topics?\n\nWe probably should have a consistent approach.  How about I make the changes in this PR for the Join repartition topics (incrementing the index of the repartition node name) and do a follow-on PR to address the other repartition topics?\n\nLast question: this method is also use for stream-table joins and thus, if one joins a stream with two tables, would this change be backward incompatible? Or would two stream-table joins fail with the same InvalidTopologyException?\n\nI believe two stream-table joins without this fix will fail with the same exception, but I'll add some tests to confirm.", "url": "https://github.com/apache/kafka/pull/8504#discussion_r413860696", "createdAt": "2020-04-23T14:47:12Z", "author": {"login": "bbejeck"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java", "diffHunk": "@@ -989,16 +994,18 @@ private void to(final TopicNameExtractor<K, V> topicExtractor,\n             null,\n             optimizableRepartitionNodeBuilder);\n \n-        final OptimizableRepartitionNode<K, V> optimizableRepartitionNode = optimizableRepartitionNodeBuilder.build();\n-        builder.addGraphNode(streamsGraphNode, optimizableRepartitionNode);\n+        if (repartitionNode == null || !name.equals(repartitionName)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk3MTI0NQ=="}, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDczMTAwMQ==", "bodyText": "Since you made the mistake of asking my opinion, here it is :) :\n\nbumping the index\n\nIt's true that users can't currently reuse the KStream, so there's no compatibility issue there, but we can't bump the index for the first repartition topic, or we would break every topology that uses generated repartition topic names already. So, either way, we have to cache something to tell us to do something different on the \"first reuse\" (i.e., the second use of the KStream).\nSince we have to do that anyway, maybe it's fine to just cache the repartition node itself instead of a flag that says \"bump the index next time\".\n\nleaking optimizations into the DSL\n\nI'm on the fence about whether this is an \"optimization\" or \"reasonable behavior\". It sort of feels like the latter, and the only reason we needed to introduce the \"repartition-collapsing\" optimization is that we failed to introduce reasonable behavior from the beginning. Also, my read is that the DSL builder and the optimizer are not cleanly separated right now anyway, and if we ever want to build more optimizations, we'll most likely need to make another pass on both anyway. We're also starting to think about topology evolution (cc @cadonna ), which makes this a less scary prospect, as we can then implement a mechanism to compatibly introduce new optimizations. In other words, I'm not taking a hard stance, but leaning in the direction of doing the more efficient thing than the more pure thing, since we're not currently super pure anyway.\n\nOther repartition topics\n\nI think we'd better leave it alone for now, implement topology evolution, then migrate to a completely pure and consistent approach.", "url": "https://github.com/apache/kafka/pull/8504#discussion_r414731001", "createdAt": "2020-04-24T17:09:33Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java", "diffHunk": "@@ -989,16 +994,18 @@ private void to(final TopicNameExtractor<K, V> topicExtractor,\n             null,\n             optimizableRepartitionNodeBuilder);\n \n-        final OptimizableRepartitionNode<K, V> optimizableRepartitionNode = optimizableRepartitionNodeBuilder.build();\n-        builder.addGraphNode(streamsGraphNode, optimizableRepartitionNode);\n+        if (repartitionNode == null || !name.equals(repartitionName)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk3MTI0NQ=="}, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODgxODgyMg==", "bodyText": "We probably should have a consistent approach. How about I make the changes in this PR for the Join repartition topics (incrementing the index of the repartition node name) and do a follow-on PR to address the other repartition topics?\n\n@bbejeck Works for me.\n\nI'm on the fence about whether this is an \"optimization\" or \"reasonable behavior\".\n\n@bbejeck @vvcephei That was my reasoning from my other comments about \"don't make the same mistake again\", too (cf. #8504 (comment)). Atm, we just need to keep the old behavior for backward compatibility reasons and only give \"reasonable\" behavior via opt-in to the optimization. IMHO, optimization should be the default behavior anyway (not the other way round; we just have it that way due to compatibility constraints) and you should even be able to turn it off (if possible)", "url": "https://github.com/apache/kafka/pull/8504#discussion_r418818822", "createdAt": "2020-05-02T01:37:11Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java", "diffHunk": "@@ -989,16 +994,18 @@ private void to(final TopicNameExtractor<K, V> topicExtractor,\n             null,\n             optimizableRepartitionNodeBuilder);\n \n-        final OptimizableRepartitionNode<K, V> optimizableRepartitionNode = optimizableRepartitionNodeBuilder.build();\n-        builder.addGraphNode(streamsGraphNode, optimizableRepartitionNode);\n+        if (repartitionNode == null || !name.equals(repartitionName)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk3MTI0NQ=="}, "originalCommit": null, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDcyMDYyOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMTo1MzozOVrOGUaUhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMTo1MzozOVrOGUaUhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA1NTk0MQ==", "bodyText": "This is the default. Why setting is explicitly?", "url": "https://github.com/apache/kafka/pull/8504#discussion_r424055941", "createdAt": "2020-05-12T21:53:39Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "diffHunk": "@@ -77,6 +79,38 @@ public void shouldLogAndMeterOnSkippedRecordsWithNullValueWithBuiltInMetricsVers\n         shouldLogAndMeterOnSkippedRecordsWithNullValue(StreamsConfig.METRICS_LATEST);\n     }\n \n+\n+    @Test\n+    public void shouldReuseRepartitionTopicWithGeneratedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDc0OTYzOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMjowNDozMFrOGUanGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNzo1MzozMFrOGY81bA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA2MDY5Nw==", "bodyText": "Sorry for being undecided... Reading the code now, I am wondering if this behavior may become problematic with regard to topology upgrade. Assume, the first join is removed. Technically, the new topology is compatible, but we would now generate a new repartition topic name, and thus it's not compatible. This could be fixed by inserting a repartition() in the new code enforcing the old name -- however, this makes me wonder if we might want to throw a \"naming conflict\" (ie, cannot pick a name) exception based on the original topology for this case when both operators are named, and tell people to insert repartition() right away? For this case, if they later remove a join it's clear what is happening to them.\nIe, we should still not create two repartition topics what would be \"bad\" (user could still enforce if by calling repartition() twice), but just throw with an informative error message? -- Curious what @vvcephei thinks?", "url": "https://github.com/apache/kafka/pull/8504#discussion_r424060697", "createdAt": "2020-05-12T22:04:30Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "diffHunk": "@@ -77,6 +79,38 @@ public void shouldLogAndMeterOnSkippedRecordsWithNullValueWithBuiltInMetricsVers\n         shouldLogAndMeterOnSkippedRecordsWithNullValue(StreamsConfig.METRICS_LATEST);\n     }\n \n+\n+    @Test\n+    public void shouldReuseRepartitionTopicWithGeneratedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-to\");\n+        assertEquals(expectedTopologyWithGeneratedRepartitionTopic, builder.build(props).describe().toString());\n+    }\n+\n+    @Test\n+    public void shouldCreateRepartitionTopicsWithUserProvidedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        final StreamJoined<String, String, String> streamJoined = StreamJoined.with(Serdes.String(), Serdes.String(), Serdes.String());\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"first-join\")).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"second-join\")).to(\"out-two\");\n+        final Topology topology =  builder.build(props);\n+        System.out.println(topology.describe().toString());\n+        assertEquals(expectedTopologyWithUserNamedRepartitionTopics, topology.describe().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM0MzA1NQ==", "bodyText": "This could be fixed by inserting a repartition() i the new code enforcing the old name -- however, this make me wonder if we might want to throw a \"naming conflict\" (ie, cannot pick a name) exception based on the original topology for this case when both operators are named, and tell people to insert repartition() right away? For this case, if they later remove a join it's clear what is happening to them.\n\nI see your point, but I think that is a bad user experience and IMHO leaks too much detail about an operation we want to handle automatically.\nI'm leaning towards the simpler case of what we had before.  With generated names re-use the reputation node, but if the user creates a new join with explicit names, just go ahead and create two repartition topics.\nWDYT?", "url": "https://github.com/apache/kafka/pull/8504#discussion_r428343055", "createdAt": "2020-05-20T22:26:26Z", "author": {"login": "bbejeck"}, "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "diffHunk": "@@ -77,6 +79,38 @@ public void shouldLogAndMeterOnSkippedRecordsWithNullValueWithBuiltInMetricsVers\n         shouldLogAndMeterOnSkippedRecordsWithNullValue(StreamsConfig.METRICS_LATEST);\n     }\n \n+\n+    @Test\n+    public void shouldReuseRepartitionTopicWithGeneratedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-to\");\n+        assertEquals(expectedTopologyWithGeneratedRepartitionTopic, builder.build(props).describe().toString());\n+    }\n+\n+    @Test\n+    public void shouldCreateRepartitionTopicsWithUserProvidedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        final StreamJoined<String, String, String> streamJoined = StreamJoined.with(Serdes.String(), Serdes.String(), Serdes.String());\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"first-join\")).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"second-join\")).to(\"out-two\");\n+        final Topology topology =  builder.build(props);\n+        System.out.println(topology.describe().toString());\n+        assertEquals(expectedTopologyWithUserNamedRepartitionTopics, topology.describe().toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA2MDY5Nw=="}, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM3NjczNA==", "bodyText": "I guess both are acceptable solutions (ie, creating two repartition topics or throwing an exception). Your proposal is more user friendly but results in a more expensive deployment. The question might be, what do we try to optimize for?\n\\cc @vvcephei @guozhangwang", "url": "https://github.com/apache/kafka/pull/8504#discussion_r428376734", "createdAt": "2020-05-21T00:11:32Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "diffHunk": "@@ -77,6 +79,38 @@ public void shouldLogAndMeterOnSkippedRecordsWithNullValueWithBuiltInMetricsVers\n         shouldLogAndMeterOnSkippedRecordsWithNullValue(StreamsConfig.METRICS_LATEST);\n     }\n \n+\n+    @Test\n+    public void shouldReuseRepartitionTopicWithGeneratedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-to\");\n+        assertEquals(expectedTopologyWithGeneratedRepartitionTopic, builder.build(props).describe().toString());\n+    }\n+\n+    @Test\n+    public void shouldCreateRepartitionTopicsWithUserProvidedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        final StreamJoined<String, String, String> streamJoined = StreamJoined.with(Serdes.String(), Serdes.String(), Serdes.String());\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"first-join\")).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"second-join\")).to(\"out-two\");\n+        final Topology topology =  builder.build(props);\n+        System.out.println(topology.describe().toString());\n+        assertEquals(expectedTopologyWithUserNamedRepartitionTopics, topology.describe().toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA2MDY5Nw=="}, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2NDE0Mg==", "bodyText": "Thanks for the discussion, all.\nComing back to this proposal, and considering the points you've raised, it seems like we should re-use the generated repartition node when the name is generated, and create two repartition nodes when they are named.\nThe purpose of re-using the repartition node in this PR isn't exactly to optimize anything, just to avoid throwing the exception that happens when we currently try to create the exact same repartition node twice. We could instead always create two nodes, but this is needlessly wasteful. Reusing the same-named node makes perfect sense.\nWhen the operations are named, on the other hand, there is no problem right now, since we are creating differently named nodes. Since there's no problem, we shouldn't \"solve\" it ;)\nIt's true that this isn't the most optimal physical plan, but for anyone who cares enough to look into it, they can just add the repartition node first, as you suggested @mjsax; we don't need to throw an exception to force them to fine-tune their program.\nThe other option is that they can enable topology optimization, which will also collapse the named repartition nodes in a well-defined way.\nCompatibility is a concern, and it seems like it's satisfied if we follow this path:\n\nYou currently cannot reuse the same stream in two anonymous joins, so we can share the node without breaking any program\nYou currently can reuse the same stream in two named joins, and we will create two (named) repartition topics. We have no choice but to maintain this, or we will break compatibility.\nInserting a repartition node is well defined to break compatibility, so people will know they have to reset.\nAdding Optimization is well defined to break compatibility, so people will know they have to reset.\n\nHave I missed some consideration?\nThanks,\n-John", "url": "https://github.com/apache/kafka/pull/8504#discussion_r428764142", "createdAt": "2020-05-21T16:22:47Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "diffHunk": "@@ -77,6 +79,38 @@ public void shouldLogAndMeterOnSkippedRecordsWithNullValueWithBuiltInMetricsVers\n         shouldLogAndMeterOnSkippedRecordsWithNullValue(StreamsConfig.METRICS_LATEST);\n     }\n \n+\n+    @Test\n+    public void shouldReuseRepartitionTopicWithGeneratedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-to\");\n+        assertEquals(expectedTopologyWithGeneratedRepartitionTopic, builder.build(props).describe().toString());\n+    }\n+\n+    @Test\n+    public void shouldCreateRepartitionTopicsWithUserProvidedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        final StreamJoined<String, String, String> streamJoined = StreamJoined.with(Serdes.String(), Serdes.String(), Serdes.String());\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"first-join\")).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"second-join\")).to(\"out-two\");\n+        final Topology topology =  builder.build(props);\n+        System.out.println(topology.describe().toString());\n+        assertEquals(expectedTopologyWithUserNamedRepartitionTopics, topology.describe().toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA2MDY5Nw=="}, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODgxMjUxNg==", "bodyText": "Thanks @vvcephei -- that is convincing.", "url": "https://github.com/apache/kafka/pull/8504#discussion_r428812516", "createdAt": "2020-05-21T17:47:46Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "diffHunk": "@@ -77,6 +79,38 @@ public void shouldLogAndMeterOnSkippedRecordsWithNullValueWithBuiltInMetricsVers\n         shouldLogAndMeterOnSkippedRecordsWithNullValue(StreamsConfig.METRICS_LATEST);\n     }\n \n+\n+    @Test\n+    public void shouldReuseRepartitionTopicWithGeneratedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-to\");\n+        assertEquals(expectedTopologyWithGeneratedRepartitionTopic, builder.build(props).describe().toString());\n+    }\n+\n+    @Test\n+    public void shouldCreateRepartitionTopicsWithUserProvidedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        final StreamJoined<String, String, String> streamJoined = StreamJoined.with(Serdes.String(), Serdes.String(), Serdes.String());\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"first-join\")).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"second-join\")).to(\"out-two\");\n+        final Topology topology =  builder.build(props);\n+        System.out.println(topology.describe().toString());\n+        assertEquals(expectedTopologyWithUserNamedRepartitionTopics, topology.describe().toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA2MDY5Nw=="}, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODgxNTcyNA==", "bodyText": "Thanks for the discussion @vvcephei and @mjsax. I'll revert this PR to its original state which conforms to @vvcephei's comments above.", "url": "https://github.com/apache/kafka/pull/8504#discussion_r428815724", "createdAt": "2020-05-21T17:53:30Z", "author": {"login": "bbejeck"}, "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "diffHunk": "@@ -77,6 +79,38 @@ public void shouldLogAndMeterOnSkippedRecordsWithNullValueWithBuiltInMetricsVers\n         shouldLogAndMeterOnSkippedRecordsWithNullValue(StreamsConfig.METRICS_LATEST);\n     }\n \n+\n+    @Test\n+    public void shouldReuseRepartitionTopicWithGeneratedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(\"out-to\");\n+        assertEquals(expectedTopologyWithGeneratedRepartitionTopic, builder.build(props).describe().toString());\n+    }\n+\n+    @Test\n+    public void shouldCreateRepartitionTopicsWithUserProvidedName() {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final Properties props = new Properties();\n+        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION, StreamsConfig.NO_OPTIMIZATION);\n+        final KStream<String, String> stream1 = builder.stream(\"topic\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream2 = builder.stream(\"topic2\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> stream3 = builder.stream(\"topic3\", Consumed.with(Serdes.String(), Serdes.String()));\n+        final KStream<String, String> newStream = stream1.map((k, v) -> new KeyValue<>(v, k));\n+        final StreamJoined<String, String, String> streamJoined = StreamJoined.with(Serdes.String(), Serdes.String(), Serdes.String());\n+        newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"first-join\")).to(\"out-one\");\n+        newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(\"second-join\")).to(\"out-two\");\n+        final Topology topology =  builder.build(props);\n+        System.out.println(topology.describe().toString());\n+        assertEquals(expectedTopologyWithUserNamedRepartitionTopics, topology.describe().toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA2MDY5Nw=="}, "originalCommit": null, "originalPosition": 45}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3028, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}