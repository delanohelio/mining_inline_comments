{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIxMjkyMDM3", "number": 8706, "title": "KAFKA-10030 allow fetching a key from a single partition", "bodyText": "StreamThreadStateStoreProvider#stores throws exception whenever taskId is not found, which is not correct behaviour in multi-threaded env where state store partitions are distributed among several StreamTasks.\nfinal Task task = tasks.get(keyTaskId);\nif (task == null) {\nthrow new InvalidStateStoreException(\nString.format(\"The specified partition %d for store %s does not exist.\",\nstoreQueryParams.partition(),\nstoreName));\n}\nReproducible with KStream number of threads more then 1\nStoreQueryIntegrationTest#streamsConfiguration\nconfig.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2);\nSuggested solution is to not throw exception if at least one state store is found, which is always true when using StoreQueryParameters.withPartition\nhttps://issues.apache.org/jira/browse/KAFKA-10030?jql=project%20%3D%20KAFKA%20AND%20component%20%3D%20streams\n@mjsax @guozhangwang", "createdAt": "2020-05-21T11:06:57Z", "url": "https://github.com/apache/kafka/pull/8706", "merged": true, "mergeCommit": {"oid": "ec67788d9d50151f98d6c8ad88d1ce5b7ea173e4"}, "closed": true, "closedAt": "2020-06-02T01:06:29Z", "author": {"login": "dima5rr"}, "timelineItems": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcjbpUcAH2gAyNDIxMjkyMDM3OjQzOWJiMjlkNTFiMmU2Zjg1MjIwMTNhN2VhZjQyYWRjYzc0MjM4ZjU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcmLPvOgFqTQyMTM1MDMwNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "439bb29d51b2e6f8522013a7eaf42adcc74238f5", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/439bb29d51b2e6f8522013a7eaf42adcc74238f5", "committedDate": "2020-05-21T11:06:00Z", "message": "MAJOR: Fix allow fetching key from single partition"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "891abd9e8d70bc08892b9f61ab081acf9befed31", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/891abd9e8d70bc08892b9f61ab081acf9befed31", "committedDate": "2020-05-21T11:22:37Z", "message": "break if at least one state store is found"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2Mzg0NDIz", "url": "https://github.com/apache/kafka/pull/8706#pullrequestreview-416384423", "createdAt": "2020-05-21T18:21:41Z", "commit": {"oid": "891abd9e8d70bc08892b9f61ab081acf9befed31"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxODoyMTo0MVrOGY9xsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxODoyMTo0MVrOGY9xsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODgzMTE1Mg==", "bodyText": "We should write a proper test case instead of \"piggy-backing\" it into an existing test.", "url": "https://github.com/apache/kafka/pull/8706#discussion_r428831152", "createdAt": "2020-05-21T18:21:41Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -332,6 +332,7 @@ private Properties streamsConfiguration() {\n         config.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 200);\n         config.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 1000);\n         config.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n+        config.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "891abd9e8d70bc08892b9f61ab081acf9befed31"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d49d97837452f01a84ca2cb41247f15b0432bc34", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/d49d97837452f01a84ca2cb41247f15b0432bc34", "committedDate": "2020-05-21T20:34:36Z", "message": "[TESTS] add dedicated tests running streams with multiple threads"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3fd8aff27c7370a851469e3ee9f2990a124172fd", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/3fd8aff27c7370a851469e3ee9f2990a124172fd", "committedDate": "2020-05-21T20:43:41Z", "message": "[TESTS] remove unused import"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MjUxMTcw", "url": "https://github.com/apache/kafka/pull/8706#pullrequestreview-417251170", "createdAt": "2020-05-23T05:07:32Z", "commit": {"oid": "3fd8aff27c7370a851469e3ee9f2990a124172fd"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yM1QwNTowNzozMlrOGZnhYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yM1QwNTowNzozMlrOGZnhYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUxNTEwNg==", "bodyText": "stale stores \"are\" not enabled?", "url": "https://github.com/apache/kafka/pull/8706#discussion_r429515106", "createdAt": "2020-05-23T05:07:32Z", "author": {"login": "brary"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -296,6 +297,87 @@ public void shouldQuerySpecificStalePartitionStores() throws Exception {\n         assertThat(store4.get(key), is(nullValue()));\n     }\n \n+    @Test\n+    public void shouldQuerySpecificActivePartitionStoresMultiStreamThreads() throws Exception {\n+        final int batch1NumMessages = 100;\n+        final int key = 1;\n+        final Semaphore semaphore = new Semaphore(0);\n+        final int numStreamThreads = 2;\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n+                Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n+                        .withCachingDisabled())\n+                .toStream()\n+                .peek((k, v) -> semaphore.release());\n+\n+        final Properties streamsConfiguration1 = streamsConfiguration();\n+        streamsConfiguration1.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final Properties streamsConfiguration2 = streamsConfiguration();\n+        streamsConfiguration2.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration1);\n+        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration2);\n+        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n+\n+        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n+\n+        assertTrue(numStreamThreads > 1);\n+        assertTrue(kafkaStreams1.localThreadsMetadata().size() > 1);\n+        assertTrue(kafkaStreams2.localThreadsMetadata().size() > 1);\n+\n+        produceValueRange(key, 0, batch1NumMessages);\n+\n+        // Assert that all messages in the first batch were processed in a timely manner\n+        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n+        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, new IntegerSerializer());\n+\n+        //key belongs to this partition\n+        final int keyPartition = keyQueryMetadata.getPartition();\n+\n+        //key doesn't belongs to this partition\n+        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n+        final boolean kafkaStreams1IsActive = (keyQueryMetadata.getActiveHost().port() % 2) == 1;\n+\n+        StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n+                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n+                        .withPartition(keyPartition);\n+        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n+        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n+        if (kafkaStreams1IsActive) {\n+            store1 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n+        } else {\n+            store2 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n+        }\n+\n+        if (kafkaStreams1IsActive) {\n+            assertThat(store1, is(notNullValue()));\n+            assertThat(store2, is(nullValue()));\n+        } else {\n+            assertThat(store2, is(notNullValue()));\n+            assertThat(store1, is(nullValue()));\n+        }\n+\n+        // Assert that only active for a specific requested partition serves key if stale stores and not enabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3fd8aff27c7370a851469e3ee9f2990a124172fd"}, "originalPosition": 74}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8e956159426a1c0ede7122a3c87ab489d7487b0", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/c8e956159426a1c0ede7122a3c87ab489d7487b0", "committedDate": "2020-05-23T18:25:32Z", "message": "[TESTS] add dedicated test for multiple stream threads"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5NTA1MTc1", "url": "https://github.com/apache/kafka/pull/8706#pullrequestreview-419505175", "createdAt": "2020-05-27T18:37:08Z", "commit": {"oid": "c8e956159426a1c0ede7122a3c87ab489d7487b0"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxODozNzowOFrOGbYJZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxODozOToxN1rOGbYNzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM2MDM1Nw==", "bodyText": "We should extend QueryableStoreProviderTest for this case -- throwing this exception moves from StreamThreadStateStoreProvider to here and we should not just remove the test from StreamThreadStateStoreProviderTest but add a new one to QueryableStoreProviderTest, too.", "url": "https://github.com/apache/kafka/pull/8706#discussion_r431360357", "createdAt": "2020-05-27T18:37:08Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/QueryableStoreProvider.java", "diffHunk": "@@ -58,9 +58,21 @@ public QueryableStoreProvider(final List<StreamThreadStateStoreProvider> storePr\n         }\n         final List<T> allStores = new ArrayList<>();\n         for (final StreamThreadStateStoreProvider storeProvider : storeProviders) {\n-            allStores.addAll(storeProvider.stores(storeQueryParameters));\n+            final List<T> stores = storeProvider.stores(storeQueryParameters);\n+            if (stores != null && !stores.isEmpty()) {\n+                allStores.addAll(stores);\n+                if (storeQueryParameters.partition() != null) {\n+                    break;\n+                }\n+            }\n         }\n         if (allStores.isEmpty()) {\n+            if (storeQueryParameters.partition() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8e956159426a1c0ede7122a3c87ab489d7487b0"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM2MTQ4NQ==", "bodyText": "numStreamThreads is a final variable -> assertion can be removed", "url": "https://github.com/apache/kafka/pull/8706#discussion_r431361485", "createdAt": "2020-05-27T18:39:17Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -296,6 +289,75 @@ public void shouldQuerySpecificStalePartitionStores() throws Exception {\n         assertThat(store4.get(key), is(nullValue()));\n     }\n \n+    @Test\n+    public void shouldQuerySpecificStalePartitionStoresMultiStreamThreads() throws Exception {\n+        final int batch1NumMessages = 100;\n+        final int key = 1;\n+        final Semaphore semaphore = new Semaphore(0);\n+        final int numStreamThreads = 2;\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n+                Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n+                        .withCachingDisabled())\n+                .toStream()\n+                .peek((k, v) -> semaphore.release());\n+\n+        final Properties streamsConfiguration1 = streamsConfiguration();\n+        streamsConfiguration1.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final Properties streamsConfiguration2 = streamsConfiguration();\n+        streamsConfiguration2.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration1);\n+        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration2);\n+        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n+\n+        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n+\n+        assertTrue(numStreamThreads > 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8e956159426a1c0ede7122a3c87ab489d7487b0"}, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5NzIyMzg5", "url": "https://github.com/apache/kafka/pull/8706#pullrequestreview-419722389", "createdAt": "2020-05-28T01:44:17Z", "commit": {"oid": "c8e956159426a1c0ede7122a3c87ab489d7487b0"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad2b7fc8d767c669ed3c1081429c885206ec9a21", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/ad2b7fc8d767c669ed3c1081429c885206ec9a21", "committedDate": "2020-05-28T08:56:29Z", "message": "[TESTS] provide StateStoreProviderStub to query partitioned store"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74dd371196c105603d049d4cc5d4a42f8796dca5", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/74dd371196c105603d049d4cc5d4a42f8796dca5", "committedDate": "2020-05-28T09:04:06Z", "message": "[TESTS] provide StateStoreProviderStub to query partitioned store"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56b0121ea5b7c09248011c40ca8632bdd0b52466", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/56b0121ea5b7c09248011c40ca8632bdd0b52466", "committedDate": "2020-05-28T09:05:48Z", "message": "[TESTS] provide StateStoreProviderStub to query partitioned store"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c9e1e69b66e441815c0a0a57777455f2aa8f397", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/2c9e1e69b66e441815c0a0a57777455f2aa8f397", "committedDate": "2020-05-28T09:10:53Z", "message": "[TESTS] query with partition test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db0f2388d4629d1e687b0c09d162577d5ed2acff", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/db0f2388d4629d1e687b0c09d162577d5ed2acff", "committedDate": "2020-05-28T12:27:00Z", "message": "[TESTS] find all stores with the same name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/4f251f7cbaa5db21450a3c93556cd98d93c1ef6e", "committedDate": "2020-05-28T12:28:13Z", "message": "[TESTS] find all stores with the same name"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNTE4Njc5", "url": "https://github.com/apache/kafka/pull/8706#pullrequestreview-420518679", "createdAt": "2020-05-28T21:51:46Z", "commit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMTo1MTo0NlrOGcIA4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMjowMToyM1rOGcIRFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NDYxMA==", "bodyText": "Thinking about this one more, stores can never be null? Can we remove this check?", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432144610", "createdAt": "2020-05-28T21:51:46Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/QueryableStoreProvider.java", "diffHunk": "@@ -58,9 +58,21 @@ public QueryableStoreProvider(final List<StreamThreadStateStoreProvider> storePr\n         }\n         final List<T> allStores = new ArrayList<>();\n         for (final StreamThreadStateStoreProvider storeProvider : storeProviders) {\n-            allStores.addAll(storeProvider.stores(storeQueryParameters));\n+            final List<T> stores = storeProvider.stores(storeQueryParameters);\n+            if (stores != null && !stores.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NTEyMQ==", "bodyText": "As above: stores should never be null, and thus we don't need this change? Also the check for isEmpty does give us much, we can still call addAll even it stores is empty?", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432145121", "createdAt": "2020-05-28T21:53:02Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/WrappingStoreProvider.java", "diffHunk": "@@ -48,7 +48,9 @@ public void setStoreQueryParameters(final StoreQueryParameters storeQueryParamet\n         final List<T> allStores = new ArrayList<>();\n         for (final StreamThreadStateStoreProvider provider : storeProviders) {\n             final List<T> stores = provider.stores(storeQueryParameters);\n-            allStores.addAll(stores);\n+            if (stores != null && !stores.isEmpty()) {\n+                allStores.addAll(stores);\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NjUwNQ==", "bodyText": "It might be better to test if the right store is returned instead of just checking for not-null? For this, in before() we need to get a reference on the store we pass into addStore()?", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432146505", "createdAt": "2020-05-28T21:56:12Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/QueryableStoreProviderTest.java", "diffHunk": "@@ -88,5 +91,23 @@ public void shouldFindGlobalStores() {\n         assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(\"global\", QueryableStoreTypes.keyValueStore())));\n     }\n \n+    @Test\n+    public void shouldReturnKVStoreWithPartitionWhenItExists() {\n+        assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions - 1)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0ODc1Ng==", "bodyText": "Can we split this as follows:\nfinal StoreQueryParameters parameters = (StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions + 1);\n\nfinal InvalidStateStoreException exception = asserThrows(\n  InvalidStateStoreException.class,\n  () -> storeProvider.getStore(parameters)\n);\nassertThat(exception.message(), equalTo(\"...\"));\n\nAnd remove the (excpected = ...) annotation.\n(1) We should always limit the code that might throw the exception (eg, if withPartition would throw an InvalidStateStoreException the test should fail, but would pass in it's current setup) (2) We should always verify the exception cause -- getStore() could throw an InvalidStateStoreException or multiple reasons and we should make sure it's throwing for the reason under test.\nSame below for the windowed case", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432148756", "createdAt": "2020-05-28T22:01:23Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/QueryableStoreProviderTest.java", "diffHunk": "@@ -88,5 +91,23 @@ public void shouldFindGlobalStores() {\n         assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(\"global\", QueryableStoreTypes.keyValueStore())));\n     }\n \n+    @Test\n+    public void shouldReturnKVStoreWithPartitionWhenItExists() {\n+        assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions - 1)));\n+    }\n+\n+    @Test(expected = InvalidStateStoreException.class)\n+    public void shouldThrowExceptionWhenKVStoreWithPartitionDoesntExists() {\n+        storeProvider.getStore(StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions + 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 29}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7836004c631beb69184d2601a974645312b71312", "author": {"user": {"login": "dima5rr", "name": "Dima Reznik"}}, "url": "https://github.com/apache/kafka/commit/7836004c631beb69184d2601a974645312b71312", "committedDate": "2020-05-29T10:13:23Z", "message": "[TESTS] always verify the exception cause"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMzQ5NzIw", "url": "https://github.com/apache/kafka/pull/8706#pullrequestreview-421349720", "createdAt": "2020-05-29T23:38:37Z", "commit": {"oid": "7836004c631beb69184d2601a974645312b71312"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMzUwMzA3", "url": "https://github.com/apache/kafka/pull/8706#pullrequestreview-421350307", "createdAt": "2020-05-29T23:41:21Z", "commit": {"oid": "7836004c631beb69184d2601a974645312b71312"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMzo0MToyMVrOGcvBEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMzo0MToyMVrOGcvBEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc4MzYzMg==", "bodyText": "nit: space", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432783632", "createdAt": "2020-05-29T23:41:21Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/test/StateStoreProviderStub.java", "diffHunk": "@@ -22,16 +22,22 @@\n import org.apache.kafka.streams.state.QueryableStoreType;\n import org.apache.kafka.streams.state.internals.StreamThreadStateStoreProvider;\n \n+import java.util.AbstractMap.SimpleEntry;\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.stream.Collectors;\n \n public class StateStoreProviderStub extends StreamThreadStateStoreProvider {\n \n-    private final Map<String, StateStore> stores = new HashMap<>();\n+    //<store name : partition> -> state store", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7836004c631beb69184d2601a974645312b71312"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1131, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}