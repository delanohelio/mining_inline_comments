{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMwMDkwNTY2", "number": 8826, "reviewThreads": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxNjozOTo1N1rOEJXNkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo0NjoxNFrOE-6keg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjUyOTQ3OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxNjozOTo1N1rOGp23Rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxNzoyMTowNFrOGp3FbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU0MzY4Ng==", "bodyText": "I'm confused, why does convert the type of config will change the way we interpret the config value?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r446543686", "createdAt": "2020-06-27T16:39:57Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,23 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n+    @SuppressWarnings(\"unchecked\")\n     protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+        Map<String, Object> parsedConfigs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU0NzMwOA==", "bodyText": "Does it make sense to just change the logging\n\nPardon me, I failed to get your point.\n\nAnd in terms of misleading, does this log confuse the user by any chance?\n\nfor example, the ssl-related configs used to create ssl protocol are viewed as unknown when creating KafkaAdmin.\n\nwhy does convert the type of config will change the way we interpret the config value?\n\nthe fix is unrelated to the type of config. The configs returned by this method is changed to the inner map (RecordingMap) of AbstractConfig so the keys used to call Map#get will be added to used list of AbstractConfig.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r446547308", "createdAt": "2020-06-27T17:21:04Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,23 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n+    @SuppressWarnings(\"unchecked\")\n     protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+        Map<String, Object> parsedConfigs;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU0MzY4Ng=="}, "originalCommit": null, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MTI3MjU1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwMToyMTozNFrOHwIDSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwMTo1OToyMVrOHwIwBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNTYxMQ==", "bodyText": "Does this cover the case when listenerName is not null? I guess that can only happen on the server side and since we don't log unused configs on the server, so maybe this is ok for now?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r520225611", "createdAt": "2020-11-10T01:21:34Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,25 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n-    protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+    @SuppressWarnings(\"unchecked\")\n+    static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n+        Map<String, Object> parsedConfigs;\n         if (listenerName == null)\n-            parsedConfigs = config.values();\n+            parsedConfigs = (Map<String, Object>) config.values();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIzNzA2MA==", "bodyText": "if (listenerName == null)\n            parsedConfigs = (Map<String, Object>) config.values();\n        else\n            parsedConfigs = config.valuesWithPrefixOverride(listenerName.configPrefix());\nthe method config.valuesWithPrefixOverride also returns ```RecordingMap so it is ok.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r520237060", "createdAt": "2020-11-10T01:59:21Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,25 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n-    protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+    @SuppressWarnings(\"unchecked\")\n+    static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n+        Map<String, Object> parsedConfigs;\n         if (listenerName == null)\n-            parsedConfigs = config.values();\n+            parsedConfigs = (Map<String, Object>) config.values();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNTYxMQ=="}, "originalCommit": null, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MTI3NzQ3OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwMToyMzo1NVrOHwIGHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwNjozOTo0NFrOH3CRBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNjMzNQ==", "bodyText": "(1) \"so we should not wrap it to a immutable map\": It's kind of weird to have a comment on what we don't do.\n(2) to return map  => to returned map", "url": "https://github.com/apache/kafka/pull/8826#discussion_r520226335", "createdAt": "2020-11-10T01:23:55Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,25 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n-    protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+    @SuppressWarnings(\"unchecked\")\n+    static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n+        Map<String, Object> parsedConfigs;\n         if (listenerName == null)\n-            parsedConfigs = config.values();\n+            parsedConfigs = (Map<String, Object>) config.values();\n         else\n             parsedConfigs = config.valuesWithPrefixOverride(listenerName.configPrefix());\n \n-        // include any custom configs from original configs\n-        Map<String, Object> configs = new HashMap<>(parsedConfigs);\n         config.originals().entrySet().stream()\n             .filter(e -> !parsedConfigs.containsKey(e.getKey())) // exclude already parsed configs\n             // exclude already parsed listener prefix configs\n             .filter(e -> !(listenerName != null && e.getKey().startsWith(listenerName.configPrefix()) &&\n                 parsedConfigs.containsKey(e.getKey().substring(listenerName.configPrefix().length()))))\n             // exclude keys like `{mechanism}.some.prop` if \"listener.name.\" prefix is present and key `some.prop` exists in parsed configs.\n             .filter(e -> !(listenerName != null && parsedConfigs.containsKey(e.getKey().substring(e.getKey().indexOf('.') + 1))))\n-            .forEach(e -> configs.put(e.getKey(), e.getValue()));\n-        return configs;\n+            .forEach(e -> parsedConfigs.put(e.getKey(), e.getValue()));\n+        // The callers may add new elements to return map so we should not wrap it to a immutable map. Otherwise,\n+        // the callers have to create a new map to carry more elements and then following Get ops are not recorded.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ3NzA1MA==", "bodyText": "This comment is still not very clear to me. Are you saying if the caller needs to add more elements, it needs to create a new RecordingMap for the additional elements to be recorded?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r526477050", "createdAt": "2020-11-18T22:52:44Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,25 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n-    protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+    @SuppressWarnings(\"unchecked\")\n+    static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n+        Map<String, Object> parsedConfigs;\n         if (listenerName == null)\n-            parsedConfigs = config.values();\n+            parsedConfigs = (Map<String, Object>) config.values();\n         else\n             parsedConfigs = config.valuesWithPrefixOverride(listenerName.configPrefix());\n \n-        // include any custom configs from original configs\n-        Map<String, Object> configs = new HashMap<>(parsedConfigs);\n         config.originals().entrySet().stream()\n             .filter(e -> !parsedConfigs.containsKey(e.getKey())) // exclude already parsed configs\n             // exclude already parsed listener prefix configs\n             .filter(e -> !(listenerName != null && e.getKey().startsWith(listenerName.configPrefix()) &&\n                 parsedConfigs.containsKey(e.getKey().substring(listenerName.configPrefix().length()))))\n             // exclude keys like `{mechanism}.some.prop` if \"listener.name.\" prefix is present and key `some.prop` exists in parsed configs.\n             .filter(e -> !(listenerName != null && parsedConfigs.containsKey(e.getKey().substring(e.getKey().indexOf('.') + 1))))\n-            .forEach(e -> configs.put(e.getKey(), e.getValue()));\n-        return configs;\n+            .forEach(e -> parsedConfigs.put(e.getKey(), e.getValue()));\n+        // The callers may add new elements to return map so we should not wrap it to a immutable map. Otherwise,\n+        // the callers have to create a new map to carry more elements and then following Get ops are not recorded.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNjMzNQ=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzQ3MDg1NQ==", "bodyText": "Sorry for unclear comment. I will revise this comment and move it to method docs", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527470855", "createdAt": "2020-11-20T06:39:44Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,25 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n-    protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+    @SuppressWarnings(\"unchecked\")\n+    static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n+        Map<String, Object> parsedConfigs;\n         if (listenerName == null)\n-            parsedConfigs = config.values();\n+            parsedConfigs = (Map<String, Object>) config.values();\n         else\n             parsedConfigs = config.valuesWithPrefixOverride(listenerName.configPrefix());\n \n-        // include any custom configs from original configs\n-        Map<String, Object> configs = new HashMap<>(parsedConfigs);\n         config.originals().entrySet().stream()\n             .filter(e -> !parsedConfigs.containsKey(e.getKey())) // exclude already parsed configs\n             // exclude already parsed listener prefix configs\n             .filter(e -> !(listenerName != null && e.getKey().startsWith(listenerName.configPrefix()) &&\n                 parsedConfigs.containsKey(e.getKey().substring(listenerName.configPrefix().length()))))\n             // exclude keys like `{mechanism}.some.prop` if \"listener.name.\" prefix is present and key `some.prop` exists in parsed configs.\n             .filter(e -> !(listenerName != null && parsedConfigs.containsKey(e.getKey().substring(e.getKey().indexOf('.') + 1))))\n-            .forEach(e -> configs.put(e.getKey(), e.getValue()));\n-        return configs;\n+            .forEach(e -> parsedConfigs.put(e.getKey(), e.getValue()));\n+        // The callers may add new elements to return map so we should not wrap it to a immutable map. Otherwise,\n+        // the callers have to create a new map to carry more elements and then following Get ops are not recorded.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNjMzNQ=="}, "originalCommit": null, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MTI4MTE2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwMToyNToyN1rOHwIINw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwMToyNToyN1rOHwIINw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNjg3MQ==", "bodyText": "common/config/* is part of the public interface. This method seems internal. So, could we not expose it publicly to the end user?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r520226871", "createdAt": "2020-11-10T01:25:27Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -582,6 +582,13 @@ public int hashCode() {\n         return originals.hashCode();\n     }\n \n+    /**\n+     * @return true if the input map is a recording map. otherwise, false\n+     */\n+    public static boolean isRecording(Map<String, ?> map) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MTcyOTc3OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNToyNDo1N1rOHwMOJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwNjowODo1NVrOH8Zc8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg==", "bodyText": "I tried running console-producer with/without this PR. It doesn't seem to WARN any unused SSL configs in either test. Do you know why?\n\n@junrao this is the root cause.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r520293926", "createdAt": "2020-11-10T05:24:57Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ2MTE1OQ==", "bodyText": "Hmm, why is this necessary since we reset used to empty in the next line?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r526461159", "createdAt": "2020-11-18T22:19:33Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg=="}, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM0NzY1Mg==", "bodyText": "ConfigDef#parse (https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/config/ConfigDef.java#L468) tries to get all elements from input maps so all gets are recorded. In order to avoid recording, we pass a copy instead of RecordingMap.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527347652", "createdAt": "2020-11-20T02:06:09Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg=="}, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk3MjU1Mg==", "bodyText": "Ok. I guess the issue is in the following, where we pass in a RecordingMap to construct ProducerConfig.\nhttps://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L384\nHowever, that code seems no longer necessary since we are now setting clientId in ProducerConfig.postProcessParsedConfig(). Could we just avoid constructing ProducerConfig there?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527972552", "createdAt": "2020-11-20T21:13:25Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg=="}, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODE2OTAwMg==", "bodyText": "However, that code seems no longer necessary since we are now setting clientId in ProducerConfig.postProcessParsedConfig(). Could we just avoid constructing ProducerConfig there?\n\nI don't think so. The configs passed to configurable object is origins so the generated \"client.id\" is not included. However, your feedback inspires me that we don't need to create a new ProducerConfig. Instead, we can use overrideConfig to set generated client.id to those configurable object. Will update it later.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r528169002", "createdAt": "2020-11-21T08:41:32Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg=="}, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk5OTY1Mw==", "bodyText": "Hmm, I am still a bit confused. My understanding is that with the latest change, ProducerConfig will only be instantiated once and thus the passed in originals will never be a RecordingMap. But it seems this is still needed? Could you explain a bit more why this is the case?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r532999653", "createdAt": "2020-12-01T00:48:34Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg=="}, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA5MzYxNg==", "bodyText": "But it seems this is still needed?\n\nIt is not necessary with the latest change. I kept it as a total solution (if someone pass RecordingMap in the future). However, I'm going to remove it to make this PR simpler.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533093616", "createdAt": "2020-12-01T06:08:55Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg=="}, "originalCommit": null, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDg0NTI2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/security/ssl/SslFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzo1NjozM1rOH2q0vQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMjoyMTozN1rOH27BDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA4Njc4MQ==", "bodyText": "When will the input configs not be recording?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527086781", "createdAt": "2020-11-19T17:56:33Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/security/ssl/SslFactory.java", "diffHunk": "@@ -79,14 +79,29 @@ public SslFactory(Mode mode,\n         this.keystoreVerifiableUsingTruststore = keystoreVerifiableUsingTruststore;\n     }\n \n+    /**\n+     * @return true if the input map is a recording map. otherwise, false\n+     */\n+    static boolean isRecording(Map<String, ?> map) {\n+        // AbstractConfig is a public APIs and RecordingMap is a internal class\n+        // In order to avoid touching public interface, we just compare the class name here.\n+        return map.getClass().getSimpleName().equals(\"RecordingMap\");\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n     @Override\n     public void configure(Map<String, ?> configs) throws KafkaException {\n         if (sslEngineFactory != null) {\n             throw new IllegalStateException(\"SslFactory was already configured.\");\n         }\n         this.endpointIdentification = (String) configs.get(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG);\n \n-        Map<String, Object> nextConfigs = new HashMap<>(configs);\n+        // it should keep using the input map if it is recording.\n+        // Otherwise, the used configs are not recorded and then AbstractConfig can produce misleading warnings:\n+        // \"The configuration 'xxx' was supplied but isn't a known config.\"\n+        Map<String, Object> nextConfigs = isRecording(configs)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM1MjA3OA==", "bodyText": "Currently, the use cases of non-RecordingMap happens on tests. However, it seems to me we don't give a good definition of Configurable#configure. It is hard to say what we should pass to it. immutable map, mutable map and RecordingMap are alternatives. I want to keep flexibility but it is ok to me to rewrite related tests to make sure all pass are RecordingMap", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527352078", "createdAt": "2020-11-20T02:21:37Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/security/ssl/SslFactory.java", "diffHunk": "@@ -79,14 +79,29 @@ public SslFactory(Mode mode,\n         this.keystoreVerifiableUsingTruststore = keystoreVerifiableUsingTruststore;\n     }\n \n+    /**\n+     * @return true if the input map is a recording map. otherwise, false\n+     */\n+    static boolean isRecording(Map<String, ?> map) {\n+        // AbstractConfig is a public APIs and RecordingMap is a internal class\n+        // In order to avoid touching public interface, we just compare the class name here.\n+        return map.getClass().getSimpleName().equals(\"RecordingMap\");\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n     @Override\n     public void configure(Map<String, ?> configs) throws KafkaException {\n         if (sslEngineFactory != null) {\n             throw new IllegalStateException(\"SslFactory was already configured.\");\n         }\n         this.endpointIdentification = (String) configs.get(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG);\n \n-        Map<String, Object> nextConfigs = new HashMap<>(configs);\n+        // it should keep using the input map if it is recording.\n+        // Otherwise, the used configs are not recorded and then AbstractConfig can produce misleading warnings:\n+        // \"The configuration 'xxx' was supplied but isn't a known config.\"\n+        Map<String, Object> nextConfigs = isRecording(configs)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA4Njc4MQ=="}, "originalCommit": null, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDg3NzM2OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxODowNDo0OFrOH2rJRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMjoyMzo0NVrOH27Dag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MjAzOA==", "bodyText": "consumer is unused.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527092038", "createdAt": "2020-11-19T18:04:48Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -2588,6 +2589,21 @@ public void deserializerShouldSeeGeneratedClientId() {\n         consumer.close();\n     }\n \n+    @Test\n+    public void testUnusedConfigs() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n+        props.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLS\");\n+        ConsumerConfig config = new ConsumerConfig(ConsumerConfig.appendDeserializerToConfig(props, new StringDeserializer(), new StringDeserializer()));\n+\n+        assertTrue(new ConsumerConfig(config.originals(), false).unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+        assertTrue(config.unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        try (KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(config, null, null)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM1MjY4Mg==", "bodyText": "It tests the specify config is recorded when constructing KafkaConsumer", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527352682", "createdAt": "2020-11-20T02:23:45Z", "author": {"login": "chia7712"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -2588,6 +2589,21 @@ public void deserializerShouldSeeGeneratedClientId() {\n         consumer.close();\n     }\n \n+    @Test\n+    public void testUnusedConfigs() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n+        props.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLS\");\n+        ConsumerConfig config = new ConsumerConfig(ConsumerConfig.appendDeserializerToConfig(props, new StringDeserializer(), new StringDeserializer()));\n+\n+        assertTrue(new ConsumerConfig(config.originals(), false).unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+        assertTrue(config.unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        try (KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(config, null, null)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MjAzOA=="}, "originalCommit": null, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDkwNjI5OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxODoxMTo1NlrOH2rbHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwNjozNzowMFrOH3CNpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5NjYwNw==", "bodyText": "Should we use the private static constructor in this class? Ditto below.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527096607", "createdAt": "2020-11-19T18:11:56Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -366,8 +379,9 @@ public void testMetadataFetch() throws InterruptedException {\n         // Return empty cluster 4 times and cluster from then on\n         when(metadata.fetch()).thenReturn(emptyCluster, emptyCluster, emptyCluster, emptyCluster, onePartitionCluster);\n \n-        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(configs, new StringSerializer(),\n-                new StringSerializer(), metadata, new MockClient(Time.SYSTEM, metadata), null, Time.SYSTEM) {\n+        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzQ2OTk5MQ==", "bodyText": "copy that", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527469991", "createdAt": "2020-11-20T06:37:00Z", "author": {"login": "chia7712"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -366,8 +379,9 @@ public void testMetadataFetch() throws InterruptedException {\n         // Return empty cluster 4 times and cluster from then on\n         when(metadata.fetch()).thenReturn(emptyCluster, emptyCluster, emptyCluster, emptyCluster, onePartitionCluster);\n \n-        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(configs, new StringSerializer(),\n-                new StringSerializer(), metadata, new MockClient(Time.SYSTEM, metadata), null, Time.SYSTEM) {\n+        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5NjYwNw=="}, "originalCommit": null, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDkxMzA1OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxODoxMzoyOVrOH2rfFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMjoyMzo1NFrOH27Dng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5NzYyMg==", "bodyText": "producer is unused.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527097622", "createdAt": "2020-11-19T18:13:29Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -1290,6 +1308,23 @@ public void serializerShouldSeeGeneratedClientId() {\n         producer.close();\n     }\n \n+    @Test\n+    public void testUnusedConfigs() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n+        props.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLS\");\n+        ProducerConfig config = new ProducerConfig(ProducerConfig.appendSerializerToConfig(props,\n+                new StringSerializer(), new StringSerializer()));\n+\n+        assertTrue(new ProducerConfig(config.originals(), false).unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+        assertTrue(config.unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        try (KafkaProducer<byte[], byte[]> producer = new KafkaProducer<>(config, null, null,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 275}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM1MjczNA==", "bodyText": "It tests the specify config is recorded when constructing KafkaProducer", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527352734", "createdAt": "2020-11-20T02:23:54Z", "author": {"login": "chia7712"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -1290,6 +1308,23 @@ public void serializerShouldSeeGeneratedClientId() {\n         producer.close();\n     }\n \n+    @Test\n+    public void testUnusedConfigs() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n+        props.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLS\");\n+        ProducerConfig config = new ProducerConfig(ProducerConfig.appendSerializerToConfig(props,\n+                new StringSerializer(), new StringSerializer()));\n+\n+        assertTrue(new ProducerConfig(config.originals(), false).unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+        assertTrue(config.unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        try (KafkaProducer<byte[], byte[]> producer = new KafkaProducer<>(config, null, null,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5NzYyMg=="}, "originalCommit": null, "originalPosition": 275}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0Mzk1NjE5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMDo1NjoxMlrOH8T4IA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwNjowNjo1MFrOH8Zaeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwMjI3Mg==", "bodyText": "Could we just do config.get(ProducerConfig.TRANSACTIONAL_ID_CONFIG) here?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533002272", "createdAt": "2020-12-01T00:56:12Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -314,27 +315,23 @@ public KafkaProducer(Properties properties) {\n      *                         be called in the producer when the serializer is passed in directly.\n      */\n     public KafkaProducer(Properties properties, Serializer<K> keySerializer, Serializer<V> valueSerializer) {\n-        this(Utils.propsToMap(properties), keySerializer, valueSerializer, null, null, null,\n-                Time.SYSTEM);\n+        this(Utils.propsToMap(properties), keySerializer, valueSerializer);\n     }\n \n     // visible for testing\n     @SuppressWarnings(\"unchecked\")\n-    KafkaProducer(Map<String, Object> configs,\n+    KafkaProducer(ProducerConfig config,\n                   Serializer<K> keySerializer,\n                   Serializer<V> valueSerializer,\n                   ProducerMetadata metadata,\n                   KafkaClient kafkaClient,\n                   ProducerInterceptors<K, V> interceptors,\n                   Time time) {\n-        ProducerConfig config = new ProducerConfig(ProducerConfig.appendSerializerToConfig(configs, keySerializer,\n-                valueSerializer));\n         try {\n-            Map<String, Object> userProvidedConfigs = config.originals();\n             this.producerConfig = config;\n             this.time = time;\n \n-            String transactionalId = (String) userProvidedConfigs.get(ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n+            String transactionalId = (String) config.originals().get(ProducerConfig.TRANSACTIONAL_ID_CONFIG);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA5Mjk4Ng==", "bodyText": "good point.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533092986", "createdAt": "2020-12-01T06:06:50Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -314,27 +315,23 @@ public KafkaProducer(Properties properties) {\n      *                         be called in the producer when the serializer is passed in directly.\n      */\n     public KafkaProducer(Properties properties, Serializer<K> keySerializer, Serializer<V> valueSerializer) {\n-        this(Utils.propsToMap(properties), keySerializer, valueSerializer, null, null, null,\n-                Time.SYSTEM);\n+        this(Utils.propsToMap(properties), keySerializer, valueSerializer);\n     }\n \n     // visible for testing\n     @SuppressWarnings(\"unchecked\")\n-    KafkaProducer(Map<String, Object> configs,\n+    KafkaProducer(ProducerConfig config,\n                   Serializer<K> keySerializer,\n                   Serializer<V> valueSerializer,\n                   ProducerMetadata metadata,\n                   KafkaClient kafkaClient,\n                   ProducerInterceptors<K, V> interceptors,\n                   Time time) {\n-        ProducerConfig config = new ProducerConfig(ProducerConfig.appendSerializerToConfig(configs, keySerializer,\n-                valueSerializer));\n         try {\n-            Map<String, Object> userProvidedConfigs = config.originals();\n             this.producerConfig = config;\n             this.time = time;\n \n-            String transactionalId = (String) userProvidedConfigs.get(ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n+            String transactionalId = (String) config.originals().get(ProducerConfig.TRANSACTIONAL_ID_CONFIG);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwMjI3Mg=="}, "originalCommit": null, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDAzMTU0OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/network/ChannelBuildersTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMToyOTo0N1rOH8UjVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwNjowNjo0MVrOH8ZaXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxMzMzMw==", "bodyText": "Should gssapi.sasl.kerberos.service.name be sasl.kerberos.service.name?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533013333", "createdAt": "2020-12-01T01:29:47Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/common/network/ChannelBuildersTest.java", "diffHunk": "@@ -79,25 +80,52 @@ public void testChannelBuilderConfigs() {\n \n         // test configs with listener prefix\n         Map<String, Object> configs = ChannelBuilders.channelBuilderConfigs(securityConfig, new ListenerName(\"listener1\"));\n+\n         assertNull(configs.get(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"gssapi.sasl.kerberos.service.name\"), \"testkafka\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"sasl.kerberos.service.name\"), \"testkafkaglobal\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA5Mjk1Nw==", "bodyText": "you are right.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533092957", "createdAt": "2020-12-01T06:06:41Z", "author": {"login": "chia7712"}, "path": "clients/src/test/java/org/apache/kafka/common/network/ChannelBuildersTest.java", "diffHunk": "@@ -79,25 +80,52 @@ public void testChannelBuilderConfigs() {\n \n         // test configs with listener prefix\n         Map<String, Object> configs = ChannelBuilders.channelBuilderConfigs(securityConfig, new ListenerName(\"listener1\"));\n+\n         assertNull(configs.get(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"gssapi.sasl.kerberos.service.name\"), \"testkafka\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"sasl.kerberos.service.name\"), \"testkafkaglobal\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxMzMzMw=="}, "originalCommit": null, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDAzNjA1OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/network/ChannelBuildersTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTozMTozOVrOH8Ulyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwNToyMToxMVrOH8Ymjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxMzk2Mg==", "bodyText": "Do we need to instantiate again?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533013962", "createdAt": "2020-12-01T01:31:39Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/common/network/ChannelBuildersTest.java", "diffHunk": "@@ -79,25 +80,52 @@ public void testChannelBuilderConfigs() {\n \n         // test configs with listener prefix\n         Map<String, Object> configs = ChannelBuilders.channelBuilderConfigs(securityConfig, new ListenerName(\"listener1\"));\n+\n         assertNull(configs.get(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"gssapi.sasl.kerberos.service.name\"), \"testkafka\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"sasl.kerberos.service.name\"), \"testkafkaglobal\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));\n+\n         assertNull(configs.get(\"listener.name.listener1.sasl.kerberos.service.name\"));\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.sasl.kerberos.service.name\"));\n \n         assertNull(configs.get(\"plain.sasl.server.callback.handler.class\"));\n+        assertFalse(securityConfig.unused().contains(\"plain.sasl.server.callback.handler.class\"));\n+\n         assertEquals(configs.get(\"listener.name.listener1.gssapi.config1.key\"), \"custom.config1\");\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.gssapi.config1.key\"));\n+\n         assertEquals(configs.get(\"custom.config2.key\"), \"custom.config2\");\n+        assertFalse(securityConfig.unused().contains(\"custom.config2.key\"));\n \n         // test configs without listener prefix\n+        securityConfig = new TestSecurityConfig(props);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA3OTY5NQ==", "bodyText": "We need a new RecordingMap to test different key without listener prefix. Otherwise, the key may be used by previous test.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533079695", "createdAt": "2020-12-01T05:21:11Z", "author": {"login": "chia7712"}, "path": "clients/src/test/java/org/apache/kafka/common/network/ChannelBuildersTest.java", "diffHunk": "@@ -79,25 +80,52 @@ public void testChannelBuilderConfigs() {\n \n         // test configs with listener prefix\n         Map<String, Object> configs = ChannelBuilders.channelBuilderConfigs(securityConfig, new ListenerName(\"listener1\"));\n+\n         assertNull(configs.get(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"gssapi.sasl.kerberos.service.name\"), \"testkafka\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"sasl.kerberos.service.name\"), \"testkafkaglobal\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));\n+\n         assertNull(configs.get(\"listener.name.listener1.sasl.kerberos.service.name\"));\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.sasl.kerberos.service.name\"));\n \n         assertNull(configs.get(\"plain.sasl.server.callback.handler.class\"));\n+        assertFalse(securityConfig.unused().contains(\"plain.sasl.server.callback.handler.class\"));\n+\n         assertEquals(configs.get(\"listener.name.listener1.gssapi.config1.key\"), \"custom.config1\");\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.gssapi.config1.key\"));\n+\n         assertEquals(configs.get(\"custom.config2.key\"), \"custom.config2\");\n+        assertFalse(securityConfig.unused().contains(\"custom.config2.key\"));\n \n         // test configs without listener prefix\n+        securityConfig = new TestSecurityConfig(props);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxMzk2Mg=="}, "originalCommit": null, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDA2Nzc4OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo0NjoxNFrOH8U32g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwNjowOToyOVrOH8Zdqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxODU4Ng==", "bodyText": "Is this test necessary? Do we still have a case where we pass in a RecordingMap to  ProducerConfig?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533018586", "createdAt": "2020-12-01T01:46:14Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -1271,27 +1270,48 @@ public void testProducerJmxPrefix() throws  Exception {\n         producer.close();\n     }\n \n-    private ProducerMetadata newMetadata(long refreshBackoffMs, long expirationMs) {\n-        return new ProducerMetadata(refreshBackoffMs, expirationMs, defaultMetadataIdleMs,\n+    private static ProducerMetadata newMetadata(long refreshBackoffMs, long expirationMs) {\n+        return new ProducerMetadata(refreshBackoffMs, expirationMs, DEFAULT_METADATA_IDLE_MS,\n                 new LogContext(), new ClusterResourceListeners(), Time.SYSTEM);\n     }\n \n     @Test\n-    public void serializerShouldSeeGeneratedClientId() {\n+    public void configurableObjectsShouldSeeGeneratedClientId() {\n         Properties props = new Properties();\n         props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n         props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, SerializerForClientId.class.getName());\n         props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, SerializerForClientId.class.getName());\n+        props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, PartitionerForClientId.class.getName());\n+        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ProducerInterceptorForClientId.class.getName());\n \n         KafkaProducer<byte[], byte[]> producer = new KafkaProducer<>(props);\n-        assertEquals(2, SerializerForClientId.CLIENT_IDS.size());\n-        assertEquals(SerializerForClientId.CLIENT_IDS.get(0), producer.getClientId());\n-        assertEquals(SerializerForClientId.CLIENT_IDS.get(1), producer.getClientId());\n+        assertNotNull(producer.getClientId());\n+        assertNotEquals(0, producer.getClientId().length());\n+        assertEquals(4, CLIENT_IDS.size());\n+        CLIENT_IDS.forEach(id -> assertEquals(id, producer.getClientId()));\n         producer.close();\n     }\n \n+    @Test\n+    public void testUnusedConfigs() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n+        props.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLS\");\n+        ProducerConfig config = new ProducerConfig(ProducerConfig.appendSerializerToConfig(props,\n+                new StringSerializer(), new StringSerializer()));\n+\n+        assertTrue(new ProducerConfig(config.originals(), false).unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 387}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA5MzgwMg==", "bodyText": "I'm going to remove this test assertTrue(new ProducerConfig(config.originals(), false).unused().co...", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533093802", "createdAt": "2020-12-01T06:09:29Z", "author": {"login": "chia7712"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -1271,27 +1270,48 @@ public void testProducerJmxPrefix() throws  Exception {\n         producer.close();\n     }\n \n-    private ProducerMetadata newMetadata(long refreshBackoffMs, long expirationMs) {\n-        return new ProducerMetadata(refreshBackoffMs, expirationMs, defaultMetadataIdleMs,\n+    private static ProducerMetadata newMetadata(long refreshBackoffMs, long expirationMs) {\n+        return new ProducerMetadata(refreshBackoffMs, expirationMs, DEFAULT_METADATA_IDLE_MS,\n                 new LogContext(), new ClusterResourceListeners(), Time.SYSTEM);\n     }\n \n     @Test\n-    public void serializerShouldSeeGeneratedClientId() {\n+    public void configurableObjectsShouldSeeGeneratedClientId() {\n         Properties props = new Properties();\n         props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n         props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, SerializerForClientId.class.getName());\n         props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, SerializerForClientId.class.getName());\n+        props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, PartitionerForClientId.class.getName());\n+        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ProducerInterceptorForClientId.class.getName());\n \n         KafkaProducer<byte[], byte[]> producer = new KafkaProducer<>(props);\n-        assertEquals(2, SerializerForClientId.CLIENT_IDS.size());\n-        assertEquals(SerializerForClientId.CLIENT_IDS.get(0), producer.getClientId());\n-        assertEquals(SerializerForClientId.CLIENT_IDS.get(1), producer.getClientId());\n+        assertNotNull(producer.getClientId());\n+        assertNotEquals(0, producer.getClientId().length());\n+        assertEquals(4, CLIENT_IDS.size());\n+        CLIENT_IDS.forEach(id -> assertEquals(id, producer.getClientId()));\n         producer.close();\n     }\n \n+    @Test\n+    public void testUnusedConfigs() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n+        props.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLS\");\n+        ProducerConfig config = new ProducerConfig(ProducerConfig.appendSerializerToConfig(props,\n+                new StringSerializer(), new StringSerializer()));\n+\n+        assertTrue(new ProducerConfig(config.originals(), false).unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxODU4Ng=="}, "originalCommit": null, "originalPosition": 387}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2545, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}