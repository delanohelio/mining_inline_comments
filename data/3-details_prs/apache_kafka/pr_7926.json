{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYxMjIxMDQ1", "number": 7926, "title": "MINOR: Improve AuthorizerIntegrationTest", "bodyText": "This is another round in my effort to clean up some of the integration tests and improve build time. This patch improves the authorizer integration tests in the following ways:\n\nWe use a separate principal for inter-broker communications. This ensures that ACLs set in the test cases do not interfere with inter-broker communication. We had two test cases (testCreateTopicAuthorizationWithClusterCreate and testAuthorizationWithTopicExisting) which depend on topic creation and were timing out because of inter-broker metadata propagation failures. The timeouts were treated as successfully satisfying the expectation of authorization. So the tests passed, but not because of the intended reason.\nPreviously GroupAuthorizerIntegrationTest was inheriting all of the tests from AuthorizerIntegrationTest. This seemed like overkill since the ACL evaluation logic is essentially the same.\n\nTotally this should take about 5-10 minutes off the total build time and make the authorizer integration tests a little more resilient to problems with inter-broker communication.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-01-10T00:24:49Z", "url": "https://github.com/apache/kafka/pull/7926", "merged": true, "mergeCommit": {"oid": "5359b2e3bc1cf13a301f32490a6630802afc4974"}, "closed": true, "closedAt": "2020-02-24T20:12:34Z", "author": {"login": "hachikuji"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb9SMDdAFqTM0NzY0OTA4Mg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcHbmQ5gFqTM2MzMxNTIyOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NjQ5MDgy", "url": "https://github.com/apache/kafka/pull/7926#pullrequestreview-347649082", "createdAt": "2020-01-23T22:23:08Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QyMjoyMzowOVrOFhOnqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QyMjozMzo0N1rOFhO3Tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4Njg1OQ==", "bodyText": "Probably a good idea to mention the motivation for this in the PR description.", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370386859", "createdAt": "2020-01-23T22:23:09Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1113,8 +1113,8 @@ class KafkaController(val config: KafkaConfig,\n     // so we will keep the previous behavior and don't reject the request\n     if (brokerEpoch != AbstractControlRequest.UNKNOWN_BROKER_EPOCH) {\n       val cachedBrokerEpoch = controllerContext.liveBrokerIdAndEpochs(id)\n-      if (brokerEpoch < cachedBrokerEpoch) {\n-        val stateBrokerEpochErrorMessage = \"Received controlled shutdown request from an old broker epoch \" +\n+      if (brokerEpoch != cachedBrokerEpoch) {\n+        val stateBrokerEpochErrorMessage = \"Received controlled shutdown request from an invalid broker epoch \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4NzI0Mg==", "bodyText": "Why do we have to pass this?", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370387242", "createdAt": "2020-01-23T22:24:12Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/unit/kafka/utils/TestUtils.scala", "diffHunk": "@@ -1192,21 +1199,26 @@ object TestUtils extends Logging {\n     trustManager\n   }\n \n-  def waitAndVerifyAcls(expected: Set[AccessControlEntry], authorizer: JAuthorizer, resource: ResourcePattern) = {\n+  def waitAndVerifyAcls(expected: Set[AccessControlEntry],\n+                        authorizer: JAuthorizer,\n+                        resource: ResourcePattern,\n+                        accessControlEntryFilter: AccessControlEntryFilter = AccessControlEntryFilter.ANY): Unit = {\n     val newLine = scala.util.Properties.lineSeparator\n \n-    val filter = new AclBindingFilter(resource.toFilter, AccessControlEntryFilter.ANY)\n+    val filter = new AclBindingFilter(resource.toFilter, accessControlEntryFilter)\n     waitUntilTrue(() => authorizer.acls(filter).asScala.map(_.entry).toSet == expected,\n       s\"expected acls:${expected.mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\" +\n-        s\"but got:${authorizer.acls(filter).asScala.map(_.entry).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\", waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)\n+        s\"but got:${authorizer.acls(filter).asScala.map(_.entry).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\",\n+      waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4NzQ0MQ==", "bodyText": "Why do we have to pass this?", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370387441", "createdAt": "2020-01-23T22:24:42Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/unit/kafka/utils/TestUtils.scala", "diffHunk": "@@ -1192,21 +1199,26 @@ object TestUtils extends Logging {\n     trustManager\n   }\n \n-  def waitAndVerifyAcls(expected: Set[AccessControlEntry], authorizer: JAuthorizer, resource: ResourcePattern) = {\n+  def waitAndVerifyAcls(expected: Set[AccessControlEntry],\n+                        authorizer: JAuthorizer,\n+                        resource: ResourcePattern,\n+                        accessControlEntryFilter: AccessControlEntryFilter = AccessControlEntryFilter.ANY): Unit = {\n     val newLine = scala.util.Properties.lineSeparator\n \n-    val filter = new AclBindingFilter(resource.toFilter, AccessControlEntryFilter.ANY)\n+    val filter = new AclBindingFilter(resource.toFilter, accessControlEntryFilter)\n     waitUntilTrue(() => authorizer.acls(filter).asScala.map(_.entry).toSet == expected,\n       s\"expected acls:${expected.mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\" +\n-        s\"but got:${authorizer.acls(filter).asScala.map(_.entry).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\", waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)\n+        s\"but got:${authorizer.acls(filter).asScala.map(_.entry).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\",\n+      waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)\n   }\n \n   def waitAndVerifyAcls(expected: Set[Acl], authorizer: Authorizer, resource: Resource) = {\n     val newLine = scala.util.Properties.lineSeparator\n \n     waitUntilTrue(() => authorizer.getAcls(resource) == expected,\n       s\"expected acls:${expected.mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\" +\n-        s\"but got:${authorizer.getAcls(resource).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\", waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)\n+        s\"but got:${authorizer.getAcls(resource).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\",\n+      waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4ODE4Ng==", "bodyText": "How is this different from bootstrapServers() below?", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370388186", "createdAt": "2020-01-23T22:26:43Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/unit/kafka/utils/TestUtils.scala", "diffHunk": "@@ -208,6 +207,14 @@ object TestUtils extends Logging {\n     }.mkString(\",\")\n   }\n \n+  def getBrokerListStrFromServers(servers: Seq[KafkaServer], listenerName: ListenerName): String = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4ODY0Nw==", "bodyText": "Nit: maybe store the authorizer in a val since it's used many times.", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370388647", "createdAt": "2020-01-23T22:27:56Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/unit/kafka/utils/TestUtils.scala", "diffHunk": "@@ -1715,4 +1727,17 @@ object TestUtils extends Logging {\n     waitUntilTrue(() => adminClient.listPartitionReassignments().reassignments().get().isEmpty,\n       s\"There still are ongoing reassignments\", pause = pause)\n   }\n+\n+  def addAndVerifyAcls(server: KafkaServer, acls: Set[AccessControlEntry], resource: ResourcePattern): Unit = {\n+    val aclBindings = acls.map { acl => new AclBinding(resource, acl) }\n+    server.dataPlaneRequestProcessor.authorizer.get", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4OTM1OA==", "bodyText": "Do we need these methods?", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370389358", "createdAt": "2020-01-23T22:29:51Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/integration/kafka/api/EndToEndAuthorizationTest.scala", "diffHunk": "@@ -90,8 +89,12 @@ abstract class EndToEndAuthorizationTest extends IntegrationTestHarness with Sas\n   val prefixedGroupResource =  new ResourcePattern(GROUP, groupPrefix, PREFIXED)\n   val wildcardTopicResource =  new ResourcePattern(TOPIC, wildcard, LITERAL)\n   val wildcardGroupResource =  new ResourcePattern(GROUP, wildcard, LITERAL)\n-  def kafkaPrincipalStr = s\"$kafkaPrincipalType:$kafkaPrincipal\"\n-  def clientPrincipalStr = s\"$kafkaPrincipalType:$clientPrincipal\"\n+\n+  def clientPrincipal: KafkaPrincipal\n+  def kafkaPrincipal: KafkaPrincipal\n+\n+  def kafkaPrincipalStr: String = kafkaPrincipal.toString\n+  def clientPrincipalStr: String = clientPrincipal.toString", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM5MDMyOQ==", "bodyText": "We can't use one of the utility methods in TestUtils?", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370390329", "createdAt": "2020-01-23T22:32:28Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/integration/kafka/api/GroupAuthorizerIntegrationTest.scala", "diffHunk": "@@ -12,30 +12,139 @@\n  */\n package kafka.api\n \n-import java.util.Properties\n+import java.util.{Collections, Properties}\n+import java.util.concurrent.ExecutionException\n \n import kafka.api.GroupAuthorizerIntegrationTest._\n+import kafka.security.auth.SimpleAclAuthorizer\n+import kafka.security.authorizer.AuthorizerUtils.WildcardHost\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import org.apache.kafka.clients.consumer.ConsumerConfig\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerRecord}\n+import org.apache.kafka.common.TopicPartition\n+import org.apache.kafka.common.acl.{AccessControlEntry, AclOperation, AclPermissionType}\n import org.apache.kafka.common.config.internals.BrokerSecurityConfigs\n+import org.apache.kafka.common.errors.TopicAuthorizationException\n+import org.apache.kafka.common.network.ListenerName\n+import org.apache.kafka.common.resource.{PatternType, Resource, ResourcePattern, ResourceType}\n import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+import org.scalatest.Assertions.intercept\n \n+import scala.collection.JavaConverters._\n \n object GroupAuthorizerIntegrationTest {\n-  val GroupPrincipalType = \"Group\"\n-  val TestGroupPrincipal = new KafkaPrincipal(GroupPrincipalType, \"testGroup\")\n+  val BrokerPrincipal = new KafkaPrincipal(\"Group\", \"broker\")\n+  val ClientPrincipal = new KafkaPrincipal(\"Group\", \"client\")\n+\n+  val BrokerListenerName = \"BROKER\"\n+  val ClientListenerName = \"CLIENT\"\n+\n   class GroupPrincipalBuilder extends KafkaPrincipalBuilder {\n     override def build(context: AuthenticationContext): KafkaPrincipal = {\n-      TestGroupPrincipal\n+      context.listenerName match {\n+        case BrokerListenerName => BrokerPrincipal\n+        case ClientListenerName => ClientPrincipal\n+        case listenerName => throw new IllegalArgumentException(s\"No principal mapped to listener $listenerName\")\n+      }\n     }\n   }\n }\n \n-class GroupAuthorizerIntegrationTest extends AuthorizerIntegrationTest {\n-  override val kafkaPrincipalType = GroupPrincipalType\n-  override def userPrincipal = TestGroupPrincipal\n+class GroupAuthorizerIntegrationTest extends BaseRequestTest {\n+\n+  val brokerId: Integer = 0\n+\n+  override def brokerCount: Int = 1\n+  override def interBrokerListenerName: ListenerName = new ListenerName(BrokerListenerName)\n+  override def listenerName: ListenerName = new ListenerName(ClientListenerName)\n+\n+  def brokerPrincipal: KafkaPrincipal = BrokerPrincipal\n+  def clientPrincipal: KafkaPrincipal = ClientPrincipal\n \n   override def brokerPropertyOverrides(properties: Properties): Unit = {\n-    properties.setProperty(BrokerSecurityConfigs.PRINCIPAL_BUILDER_CLASS_CONFIG,\n-      classOf[GroupPrincipalBuilder].getName)\n-    super.brokerPropertyOverrides(properties)\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[SimpleAclAuthorizer].getName)\n+    properties.put(KafkaConfig.BrokerIdProp, brokerId.toString)\n+    properties.put(KafkaConfig.OffsetsTopicPartitionsProp, \"1\")\n+    properties.put(KafkaConfig.OffsetsTopicReplicationFactorProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicPartitionsProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicReplicationFactorProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicMinISRProp, \"1\")\n+    properties.put(BrokerSecurityConfigs.PRINCIPAL_BUILDER_CLASS_CONFIG, classOf[GroupPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    doSetup(createOffsetsTopic = false)\n+\n+    // Allow inter-broker communication\n+    TestUtils.addAndVerifyAcls(servers.head,\n+      Set(createAcl(AclOperation.CLUSTER_ACTION, AclPermissionType.ALLOW, principal = BrokerPrincipal)),\n+      new ResourcePattern(ResourceType.CLUSTER, Resource.CLUSTER_NAME, PatternType.LITERAL))\n+\n+    TestUtils.createOffsetsTopic(zkClient, servers)\n+  }\n+\n+  private def createAcl(aclOperation: AclOperation,\n+                        aclPermissionType: AclPermissionType,\n+                        principal: KafkaPrincipal = ClientPrincipal): AccessControlEntry = {\n+    new AccessControlEntry(principal.toString, WildcardHost, aclOperation, aclPermissionType)\n+  }\n+\n+  @Test\n+  def testUnauthorizedProduceAndConsume(): Unit = {\n+    val topic = \"topic\"\n+    val topicPartition = new TopicPartition(\"topic\", 0)\n+\n+    createTopic(topic)\n+\n+    val producer = createProducer()\n+    intercept[TopicAuthorizationException] {\n+      sendRecords(producer, numRecords = 10, topicPartition)\n+    }\n+\n+    val consumer = createConsumer(configsToRemove = List(ConsumerConfig.GROUP_ID_CONFIG))\n+    consumer.assign(List(topicPartition).asJava)\n+    val e = intercept[TopicAuthorizationException] {\n+      TestUtils.pollUntilAtLeastNumRecords(consumer, numRecords = 10)\n+    }\n+    assertEquals(Collections.singleton(topic), e.unauthorizedTopics())\n+  }\n+\n+  @Test\n+  def testAuthorizedProduceAndConsume(): Unit = {\n+    val topic = \"topic\"\n+    val topicPartition = new TopicPartition(\"topic\", 0)\n+\n+    createTopic(topic)\n+\n+    TestUtils.addAndVerifyAcls(servers.head,\n+      Set(createAcl(AclOperation.WRITE, AclPermissionType.ALLOW)),\n+      new ResourcePattern(ResourceType.TOPIC, topic, PatternType.LITERAL))\n+    val producer = createProducer()\n+    sendRecords(producer, numRecords = 10, topicPartition)\n+\n+    TestUtils.addAndVerifyAcls(servers.head,\n+      Set(createAcl(AclOperation.READ, AclPermissionType.ALLOW)),\n+      new ResourcePattern(ResourceType.TOPIC, topic, PatternType.LITERAL))\n+    val consumer = createConsumer(configsToRemove = List(ConsumerConfig.GROUP_ID_CONFIG))\n+    consumer.assign(List(topicPartition).asJava)\n+    TestUtils.pollUntilAtLeastNumRecords(consumer, numRecords = 10)\n   }\n+\n+  private def sendRecords(producer: KafkaProducer[Array[Byte], Array[Byte]],", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM5MDU3OQ==", "bodyText": "Nit: no () needed for the second parameter.", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370390579", "createdAt": "2020-01-23T22:33:09Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/integration/kafka/api/GroupAuthorizerIntegrationTest.scala", "diffHunk": "@@ -12,30 +12,139 @@\n  */\n package kafka.api\n \n-import java.util.Properties\n+import java.util.{Collections, Properties}\n+import java.util.concurrent.ExecutionException\n \n import kafka.api.GroupAuthorizerIntegrationTest._\n+import kafka.security.auth.SimpleAclAuthorizer\n+import kafka.security.authorizer.AuthorizerUtils.WildcardHost\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import org.apache.kafka.clients.consumer.ConsumerConfig\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerRecord}\n+import org.apache.kafka.common.TopicPartition\n+import org.apache.kafka.common.acl.{AccessControlEntry, AclOperation, AclPermissionType}\n import org.apache.kafka.common.config.internals.BrokerSecurityConfigs\n+import org.apache.kafka.common.errors.TopicAuthorizationException\n+import org.apache.kafka.common.network.ListenerName\n+import org.apache.kafka.common.resource.{PatternType, Resource, ResourcePattern, ResourceType}\n import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+import org.scalatest.Assertions.intercept\n \n+import scala.collection.JavaConverters._\n \n object GroupAuthorizerIntegrationTest {\n-  val GroupPrincipalType = \"Group\"\n-  val TestGroupPrincipal = new KafkaPrincipal(GroupPrincipalType, \"testGroup\")\n+  val BrokerPrincipal = new KafkaPrincipal(\"Group\", \"broker\")\n+  val ClientPrincipal = new KafkaPrincipal(\"Group\", \"client\")\n+\n+  val BrokerListenerName = \"BROKER\"\n+  val ClientListenerName = \"CLIENT\"\n+\n   class GroupPrincipalBuilder extends KafkaPrincipalBuilder {\n     override def build(context: AuthenticationContext): KafkaPrincipal = {\n-      TestGroupPrincipal\n+      context.listenerName match {\n+        case BrokerListenerName => BrokerPrincipal\n+        case ClientListenerName => ClientPrincipal\n+        case listenerName => throw new IllegalArgumentException(s\"No principal mapped to listener $listenerName\")\n+      }\n     }\n   }\n }\n \n-class GroupAuthorizerIntegrationTest extends AuthorizerIntegrationTest {\n-  override val kafkaPrincipalType = GroupPrincipalType\n-  override def userPrincipal = TestGroupPrincipal\n+class GroupAuthorizerIntegrationTest extends BaseRequestTest {\n+\n+  val brokerId: Integer = 0\n+\n+  override def brokerCount: Int = 1\n+  override def interBrokerListenerName: ListenerName = new ListenerName(BrokerListenerName)\n+  override def listenerName: ListenerName = new ListenerName(ClientListenerName)\n+\n+  def brokerPrincipal: KafkaPrincipal = BrokerPrincipal\n+  def clientPrincipal: KafkaPrincipal = ClientPrincipal\n \n   override def brokerPropertyOverrides(properties: Properties): Unit = {\n-    properties.setProperty(BrokerSecurityConfigs.PRINCIPAL_BUILDER_CLASS_CONFIG,\n-      classOf[GroupPrincipalBuilder].getName)\n-    super.brokerPropertyOverrides(properties)\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[SimpleAclAuthorizer].getName)\n+    properties.put(KafkaConfig.BrokerIdProp, brokerId.toString)\n+    properties.put(KafkaConfig.OffsetsTopicPartitionsProp, \"1\")\n+    properties.put(KafkaConfig.OffsetsTopicReplicationFactorProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicPartitionsProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicReplicationFactorProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicMinISRProp, \"1\")\n+    properties.put(BrokerSecurityConfigs.PRINCIPAL_BUILDER_CLASS_CONFIG, classOf[GroupPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    doSetup(createOffsetsTopic = false)\n+\n+    // Allow inter-broker communication\n+    TestUtils.addAndVerifyAcls(servers.head,\n+      Set(createAcl(AclOperation.CLUSTER_ACTION, AclPermissionType.ALLOW, principal = BrokerPrincipal)),\n+      new ResourcePattern(ResourceType.CLUSTER, Resource.CLUSTER_NAME, PatternType.LITERAL))\n+\n+    TestUtils.createOffsetsTopic(zkClient, servers)\n+  }\n+\n+  private def createAcl(aclOperation: AclOperation,\n+                        aclPermissionType: AclPermissionType,\n+                        principal: KafkaPrincipal = ClientPrincipal): AccessControlEntry = {\n+    new AccessControlEntry(principal.toString, WildcardHost, aclOperation, aclPermissionType)\n+  }\n+\n+  @Test\n+  def testUnauthorizedProduceAndConsume(): Unit = {\n+    val topic = \"topic\"\n+    val topicPartition = new TopicPartition(\"topic\", 0)\n+\n+    createTopic(topic)\n+\n+    val producer = createProducer()\n+    intercept[TopicAuthorizationException] {\n+      sendRecords(producer, numRecords = 10, topicPartition)\n+    }\n+\n+    val consumer = createConsumer(configsToRemove = List(ConsumerConfig.GROUP_ID_CONFIG))\n+    consumer.assign(List(topicPartition).asJava)\n+    val e = intercept[TopicAuthorizationException] {\n+      TestUtils.pollUntilAtLeastNumRecords(consumer, numRecords = 10)\n+    }\n+    assertEquals(Collections.singleton(topic), e.unauthorizedTopics())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM5MDg2Mg==", "bodyText": "Would it make sense to change this method to take a KafkaPrincipal?", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370390862", "createdAt": "2020-01-23T22:33:47Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/integration/kafka/api/DelegationTokenEndToEndAuthorizationTest.scala", "diffHunk": "@@ -51,15 +51,15 @@ class DelegationTokenEndToEndAuthorizationTest extends EndToEndAuthorizationTest\n     super.configureSecurityBeforeServersStart()\n     zkClient.makeSurePersistentPathExists(ConfigEntityChangeNotificationZNode.path)\n     // Create broker admin credentials before starting brokers\n-    createScramCredentials(zkConnect, kafkaPrincipal, kafkaPassword)\n+    createScramCredentials(zkConnect, kafkaPrincipal.getName, kafkaPassword)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 27}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4f7faf8badc0629a09ad88031d1d3a9a295ed56", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/a4f7faf8badc0629a09ad88031d1d3a9a295ed56", "committedDate": "2020-02-19T05:35:48Z", "message": "MINOR: Fix AuthorizerIntegrationTest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "512722a8556f50f604294d649cd04e208441de86", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/512722a8556f50f604294d649cd04e208441de86", "committedDate": "2020-02-19T05:35:48Z", "message": "Fix failing end to end tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35ea2e51a7a2c5ae023f7873ca4701acc2d94c1a", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/35ea2e51a7a2c5ae023f7873ca4701acc2d94c1a", "committedDate": "2020-02-19T05:35:48Z", "message": "Fix failing tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "80582d538456bda78a4585b7c41b3ab83951385c", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/80582d538456bda78a4585b7c41b3ab83951385c", "committedDate": "2020-02-19T05:35:48Z", "message": "Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f420573957635f7746bbb144293edbcef6f9a8a1", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/f420573957635f7746bbb144293edbcef6f9a8a1", "committedDate": "2020-02-19T05:35:48Z", "message": "Revert change in controller epoch change"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "f420573957635f7746bbb144293edbcef6f9a8a1", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/f420573957635f7746bbb144293edbcef6f9a8a1", "committedDate": "2020-02-19T05:35:48Z", "message": "Revert change in controller epoch change"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYzMjYxNzUy", "url": "https://github.com/apache/kafka/pull/7926#pullrequestreview-363261752", "createdAt": "2020-02-24T09:44:44Z", "commit": {"oid": "f420573957635f7746bbb144293edbcef6f9a8a1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYzMzE1MjI5", "url": "https://github.com/apache/kafka/pull/7926#pullrequestreview-363315229", "createdAt": "2020-02-24T11:12:47Z", "commit": {"oid": "f420573957635f7746bbb144293edbcef6f9a8a1"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1930, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}