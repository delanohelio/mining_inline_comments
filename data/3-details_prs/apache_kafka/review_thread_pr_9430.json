{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAzMTU1NDgx", "number": 9430, "reviewThreads": {"totalCount": 40, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwOTo1MzoxMlrOFPH1pQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo1OTowNlrOFYkgTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDAxMzgxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwOTo1MzoxMlrOIUTTRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMTo1NzowMFrOIZjkCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE1ODY2MA==", "bodyText": "Is having empty string as default necessary? It shows as (default: ) in the description which looks weird.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558158660", "createdAt": "2021-01-15T09:53:12Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -33,15 +35,26 @@ object GetOffsetShell {\n \n   def main(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionOpt = parser.accepts(\"topic-partitions\", \"Comma separated list of topic-partition specifications to get the offsets for, with the format of topic:partition. The 'topic' part can be a regex or may be omitted to only specify the partitions, and query all authorized topics.\" +\n+                                            \" The 'partition' part can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions of the specified topic.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic:partition,...,topic:partition\")\n+                           .ofType(classOf[String])\n+                           .defaultsTo(\"\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY2Nzk3OQ==", "bodyText": "Not at all, thank you for catching this", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563667979", "createdAt": "2021-01-25T11:57:00Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -33,15 +35,26 @@ object GetOffsetShell {\n \n   def main(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionOpt = parser.accepts(\"topic-partitions\", \"Comma separated list of topic-partition specifications to get the offsets for, with the format of topic:partition. The 'topic' part can be a regex or may be omitted to only specify the partitions, and query all authorized topics.\" +\n+                                            \" The 'partition' part can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions of the specified topic.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic:partition,...,topic:partition\")\n+                           .ofType(classOf[String])\n+                           .defaultsTo(\"\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE1ODY2MA=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDA0NjY2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwOTo1Njo1NlrOIUTqdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMTo1OTozMVrOIZjplw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE2NDU5OQ==", "bodyText": "We should replace $topicPartitionOpt by --topic-partitions in order to remain consistent with the other descriptions. $topicPartitionOpt generates [topic-partitions] in the description.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558164599", "createdAt": "2021-01-15T09:56:56Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -33,15 +35,26 @@ object GetOffsetShell {\n \n   def main(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionOpt = parser.accepts(\"topic-partitions\", \"Comma separated list of topic-partition specifications to get the offsets for, with the format of topic:partition. The 'topic' part can be a regex or may be omitted to only specify the partitions, and query all authorized topics.\" +\n+                                            \" The 'partition' part can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions of the specified topic.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic:partition,...,topic:partition\")\n+                           .ofType(classOf[String])\n+                           .defaultsTo(\"\")\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Ignored if $topicPartitionOpt is present.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY2OTM5OQ==", "bodyText": "Thanks, fixed it", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563669399", "createdAt": "2021-01-25T11:59:31Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -33,15 +35,26 @@ object GetOffsetShell {\n \n   def main(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionOpt = parser.accepts(\"topic-partitions\", \"Comma separated list of topic-partition specifications to get the offsets for, with the format of topic:partition. The 'topic' part can be a regex or may be omitted to only specify the partitions, and query all authorized topics.\" +\n+                                            \" The 'partition' part can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions of the specified topic.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic:partition,...,topic:partition\")\n+                           .ofType(classOf[String])\n+                           .defaultsTo(\"\")\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Ignored if $topicPartitionOpt is present.\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE2NDU5OQ=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDA0ODE2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwOTo1NzowNFrOIUTrgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwOTo1NzowNFrOIUTrgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE2NDg2NA==", "bodyText": "ditto", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558164864", "createdAt": "2021-01-15T09:57:04Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -33,15 +35,26 @@ object GetOffsetShell {\n \n   def main(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionOpt = parser.accepts(\"topic-partitions\", \"Comma separated list of topic-partition specifications to get the offsets for, with the format of topic:partition. The 'topic' part can be a regex or may be omitted to only specify the partitions, and query all authorized topics.\" +\n+                                            \" The 'partition' part can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions of the specified topic.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic:partition,...,topic:partition\")\n+                           .ofType(classOf[String])\n+                           .defaultsTo(\"\")\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Ignored if $topicPartitionOpt is present.\")\n                            .withRequiredArg\n                            .describedAs(\"topic\")\n                            .ofType(classOf[String])\n-    val partitionOpt = parser.accepts(\"partitions\", \"comma separated list of partition ids. If not specified, it will find offsets for all partitions\")\n+    val partitionOpt = parser.accepts(\"partitions\", s\"Comma separated list of partition ids to get the offsets for. If not present, all partitions of the authorized topics are queried. Ignored if $topicPartitionOpt is present.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDA3ODA2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDowMDowOVrOIUUAGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDowMDowOVrOIUUAGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE3MDEzNg==", "bodyText": "How about Property file containing configs to be passed to Consumer Client. to remain inline with description of that field used by other command line tools?", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558170136", "createdAt": "2021-01-15T10:00:09Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -51,28 +64,30 @@ object GetOffsetShell {\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Consumer config properties file.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDEyNDkwOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDowNTozMVrOIUUg-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjowMDoyMlrOIZjrhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE3ODU1NA==", "bodyText": "Should we also verify combination of arguments that are not valid? I am thinking about --topic-partitions vs --topic and --partitions. That would be better than silently ignoring.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558178554", "createdAt": "2021-01-15T10:05:31Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -51,28 +64,30 @@ object GetOffsetShell {\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Consumer config properties file.\")\n                            .withRequiredArg\n-                           .describedAs(\"ms\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1000)\n+                           .describedAs(\"config file\")\n+                           .ofType(classOf[String])\n+    val excludeInternalTopicsOpt = parser.accepts(\"exclude-internal-topics\", s\"By default, internal topics are included. If specified, internal topics are excluded.\")\n \n-   if (args.length == 0)\n-      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic offsets.\")\n+    if (args.length == 0)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY2OTg5NQ==", "bodyText": "I agree, good catch", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563669895", "createdAt": "2021-01-25T12:00:22Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -51,28 +64,30 @@ object GetOffsetShell {\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Consumer config properties file.\")\n                            .withRequiredArg\n-                           .describedAs(\"ms\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1000)\n+                           .describedAs(\"config file\")\n+                           .ofType(classOf[String])\n+    val excludeInternalTopicsOpt = parser.accepts(\"exclude-internal-topics\", s\"By default, internal topics are included. If specified, internal topics are excluded.\")\n \n-   if (args.length == 0)\n-      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic offsets.\")\n+    if (args.length == 0)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE3ODU1NA=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDIyMTEzOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDoxNzoyOFrOIUViEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDoxNzoyOFrOIUViEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE5NTIxNw==", "bodyText": "nit: We usually structure blocks as follow:\nruleSpecs.map { ruleSpec => \n  ...\n}\n\nWe can avoid the parenthesis.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558195217", "createdAt": "2021-01-15T10:17:28Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 188}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDMyOTM5OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDozMDo1MFrOIUWrQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjowMToxOVrOIZjtqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODIxMzk1NQ==", "bodyText": "Let's try to remain inline with https://cwiki.apache.org/confluence/display/KAFKA/KIP-629%3A+Use+racially+neutral+terms+in+our+codebase. We should name the variable includeList.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558213955", "createdAt": "2021-01-15T10:30:50Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {\n+      val parts = ruleSpec.split(\":\")\n+      if (parts.length == 1) {\n+        val whitelist = IncludeList(parts(0))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY3MDQ0Mw==", "bodyText": "Thanks for the catch", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563670443", "createdAt": "2021-01-25T12:01:19Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {\n+      val parts = ruleSpec.split(\":\")\n+      if (parts.length == 1) {\n+        val whitelist = IncludeList(parts(0))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODIxMzk1NQ=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 191}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDM0MzgxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDozMjo1N1rOIUW1GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjowNTozNVrOIZj2vA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODIxNjQ3Mw==", "bodyText": "Should we handle the case where it is not a number and provide a meaning full error to the user?", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558216473", "createdAt": "2021-01-15T10:32:57Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {\n+      val parts = ruleSpec.split(\":\")\n+      if (parts.length == 1) {\n+        val whitelist = IncludeList(parts(0))\n+        tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics)\n+      } else if (parts.length == 2) {\n+        val partitionFilter = createPartitionFilter(parts(1))\n+\n+        if (parts(0).trim().isEmpty) {\n+          tp: PartitionInfo => partitionFilter.apply(tp.partition)\n+        } else {\n+          val whitelist = IncludeList(parts(0))\n+          tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics) && partitionFilter.apply(tp.partition)\n+        }\n+      } else {\n+        throw new IllegalArgumentException(s\"Invalid topic-partition rule: $ruleSpec\")\n+      }\n+    })\n+\n+    tp => rules.exists(rule => rule.apply(tp))\n+  }\n+\n+  /**\n+   * Creates a partition filter based on a single id or a range.\n+   * Expected format:\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n+   */\n+  private def createPartitionFilter(spec: String): Int => Boolean = {\n+    if (spec.indexOf('-') != -1) {\n+      val rangeParts = spec.split(\"-\", -1)\n+      if(rangeParts.length != 2 || rangeParts(0).isEmpty && rangeParts(1).isEmpty) {\n+        throw new IllegalArgumentException(s\"Invalid range specification: $spec\")\n+      }\n+\n+      if(rangeParts(0).isEmpty) {\n+        val max = rangeParts(1).toInt\n+        partition: Int => partition < max\n+      } else if(rangeParts(1).isEmpty) {\n+        val min = rangeParts(0).toInt\n+        partition: Int => partition >= min\n+      } else {\n+        val min = rangeParts(0).toInt\n+        val max = rangeParts(1).toInt\n+\n+        if (min > max) {\n+          throw new IllegalArgumentException(s\"Range lower bound cannot be greater than upper bound: $spec\")\n+        }\n+\n+        partition: Int => partition >= min && partition < max\n+      }\n+    } else {\n+      val number = spec.toInt", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY3Mjc2NA==", "bodyText": "You are right, should be handled, fixed it", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563672764", "createdAt": "2021-01-25T12:05:35Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {\n+      val parts = ruleSpec.split(\":\")\n+      if (parts.length == 1) {\n+        val whitelist = IncludeList(parts(0))\n+        tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics)\n+      } else if (parts.length == 2) {\n+        val partitionFilter = createPartitionFilter(parts(1))\n+\n+        if (parts(0).trim().isEmpty) {\n+          tp: PartitionInfo => partitionFilter.apply(tp.partition)\n+        } else {\n+          val whitelist = IncludeList(parts(0))\n+          tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics) && partitionFilter.apply(tp.partition)\n+        }\n+      } else {\n+        throw new IllegalArgumentException(s\"Invalid topic-partition rule: $ruleSpec\")\n+      }\n+    })\n+\n+    tp => rules.exists(rule => rule.apply(tp))\n+  }\n+\n+  /**\n+   * Creates a partition filter based on a single id or a range.\n+   * Expected format:\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n+   */\n+  private def createPartitionFilter(spec: String): Int => Boolean = {\n+    if (spec.indexOf('-') != -1) {\n+      val rangeParts = spec.split(\"-\", -1)\n+      if(rangeParts.length != 2 || rangeParts(0).isEmpty && rangeParts(1).isEmpty) {\n+        throw new IllegalArgumentException(s\"Invalid range specification: $spec\")\n+      }\n+\n+      if(rangeParts(0).isEmpty) {\n+        val max = rangeParts(1).toInt\n+        partition: Int => partition < max\n+      } else if(rangeParts(1).isEmpty) {\n+        val min = rangeParts(0).toInt\n+        partition: Int => partition >= min\n+      } else {\n+        val min = rangeParts(0).toInt\n+        val max = rangeParts(1).toInt\n+\n+        if (min > max) {\n+          throw new IllegalArgumentException(s\"Range lower bound cannot be greater than upper bound: $spec\")\n+        }\n+\n+        partition: Int => partition >= min && partition < max\n+      }\n+    } else {\n+      val number = spec.toInt", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODIxNjQ3Mw=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 239}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDM3MTYxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDozODozOFrOIUXGhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDozODozOFrOIUXGhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODIyMDkzNA==", "bodyText": "nit: A space is missing after if. There are couple of similar cases below.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558220934", "createdAt": "2021-01-15T10:38:38Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {\n+      val parts = ruleSpec.split(\":\")\n+      if (parts.length == 1) {\n+        val whitelist = IncludeList(parts(0))\n+        tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics)\n+      } else if (parts.length == 2) {\n+        val partitionFilter = createPartitionFilter(parts(1))\n+\n+        if (parts(0).trim().isEmpty) {\n+          tp: PartitionInfo => partitionFilter.apply(tp.partition)\n+        } else {\n+          val whitelist = IncludeList(parts(0))\n+          tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics) && partitionFilter.apply(tp.partition)\n+        }\n+      } else {\n+        throw new IllegalArgumentException(s\"Invalid topic-partition rule: $ruleSpec\")\n+      }\n+    })\n+\n+    tp => rules.exists(rule => rule.apply(tp))\n+  }\n+\n+  /**\n+   * Creates a partition filter based on a single id or a range.\n+   * Expected format:\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n+   */\n+  private def createPartitionFilter(spec: String): Int => Boolean = {\n+    if (spec.indexOf('-') != -1) {\n+      val rangeParts = spec.split(\"-\", -1)\n+      if(rangeParts.length != 2 || rangeParts(0).isEmpty && rangeParts(1).isEmpty) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 218}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDQwMTAzOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMDo0NzowNlrOIUXYXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjowNzozOVrOIZj7GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODIyNTUwMw==", "bodyText": "Could we simplify this block to something like the following?\nval topicFilter = IncludeList(topicOpt.getOrElse(\".*\"))\nt => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics)) && (partitionIds.isEmpty || partitionIds.contains(t.partition))", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558225503", "createdAt": "2021-01-15T10:47:06Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {\n+      val parts = ruleSpec.split(\":\")\n+      if (parts.length == 1) {\n+        val whitelist = IncludeList(parts(0))\n+        tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics)\n+      } else if (parts.length == 2) {\n+        val partitionFilter = createPartitionFilter(parts(1))\n+\n+        if (parts(0).trim().isEmpty) {\n+          tp: PartitionInfo => partitionFilter.apply(tp.partition)\n+        } else {\n+          val whitelist = IncludeList(parts(0))\n+          tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics) && partitionFilter.apply(tp.partition)\n+        }\n+      } else {\n+        throw new IllegalArgumentException(s\"Invalid topic-partition rule: $ruleSpec\")\n+      }\n+    })\n+\n+    tp => rules.exists(rule => rule.apply(tp))\n+  }\n+\n+  /**\n+   * Creates a partition filter based on a single id or a range.\n+   * Expected format:\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n+   */\n+  private def createPartitionFilter(spec: String): Int => Boolean = {\n+    if (spec.indexOf('-') != -1) {\n+      val rangeParts = spec.split(\"-\", -1)\n+      if(rangeParts.length != 2 || rangeParts(0).isEmpty && rangeParts(1).isEmpty) {\n+        throw new IllegalArgumentException(s\"Invalid range specification: $spec\")\n+      }\n+\n+      if(rangeParts(0).isEmpty) {\n+        val max = rangeParts(1).toInt\n+        partition: Int => partition < max\n+      } else if(rangeParts(1).isEmpty) {\n+        val min = rangeParts(0).toInt\n+        partition: Int => partition >= min\n+      } else {\n+        val min = rangeParts(0).toInt\n+        val max = rangeParts(1).toInt\n+\n+        if (min > max) {\n+          throw new IllegalArgumentException(s\"Range lower bound cannot be greater than upper bound: $spec\")\n+        }\n+\n+        partition: Int => partition >= min && partition < max\n+      }\n+    } else {\n+      val number = spec.toInt\n+      partition: Int => partition == number\n+    }\n   }\n \n+  /**\n+   * Creates a topic-partition filter based on a topic pattern and a set of partition ids.\n+   */\n+  private def createTopicPartitionFilterWithTopicAndPartitionPattern(topicOpt: Option[String], excludeInternalTopics: Boolean, partitionIds: Set[Int]): Option[PartitionInfo => Boolean] = {\n+    topicOpt match {\n+      case Some(topic) =>\n+        val topicsFilter = IncludeList(topic)\n+        if(partitionIds.isEmpty)\n+          Some(t => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics))\n+        else\n+          Some(t => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics) && partitionIds.contains(t.partition))\n+      case None =>\n+        if(excludeInternalTopics) {\n+          if(partitionIds.isEmpty)\n+            Some(t => !Topic.isInternal(t.topic))\n+          else\n+            Some(t => !Topic.isInternal(t.topic) && partitionIds.contains(t.partition))\n+        } else {\n+          if(partitionIds.isEmpty)\n+            None\n+          else\n+            Some(t => partitionIds.contains(t.partition))\n+        }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 267}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY3Mzg4MQ==", "bodyText": "I was mostly focusing on avoiding unnecessary filtering, but you are right, it shouldn't be an issue, your code is much cleaner", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563673881", "createdAt": "2021-01-25T12:07:39Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {\n+      val parts = ruleSpec.split(\":\")\n+      if (parts.length == 1) {\n+        val whitelist = IncludeList(parts(0))\n+        tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics)\n+      } else if (parts.length == 2) {\n+        val partitionFilter = createPartitionFilter(parts(1))\n+\n+        if (parts(0).trim().isEmpty) {\n+          tp: PartitionInfo => partitionFilter.apply(tp.partition)\n+        } else {\n+          val whitelist = IncludeList(parts(0))\n+          tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics) && partitionFilter.apply(tp.partition)\n+        }\n+      } else {\n+        throw new IllegalArgumentException(s\"Invalid topic-partition rule: $ruleSpec\")\n+      }\n+    })\n+\n+    tp => rules.exists(rule => rule.apply(tp))\n+  }\n+\n+  /**\n+   * Creates a partition filter based on a single id or a range.\n+   * Expected format:\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n+   */\n+  private def createPartitionFilter(spec: String): Int => Boolean = {\n+    if (spec.indexOf('-') != -1) {\n+      val rangeParts = spec.split(\"-\", -1)\n+      if(rangeParts.length != 2 || rangeParts(0).isEmpty && rangeParts(1).isEmpty) {\n+        throw new IllegalArgumentException(s\"Invalid range specification: $spec\")\n+      }\n+\n+      if(rangeParts(0).isEmpty) {\n+        val max = rangeParts(1).toInt\n+        partition: Int => partition < max\n+      } else if(rangeParts(1).isEmpty) {\n+        val min = rangeParts(0).toInt\n+        partition: Int => partition >= min\n+      } else {\n+        val min = rangeParts(0).toInt\n+        val max = rangeParts(1).toInt\n+\n+        if (min > max) {\n+          throw new IllegalArgumentException(s\"Range lower bound cannot be greater than upper bound: $spec\")\n+        }\n+\n+        partition: Int => partition >= min && partition < max\n+      }\n+    } else {\n+      val number = spec.toInt\n+      partition: Int => partition == number\n+    }\n   }\n \n+  /**\n+   * Creates a topic-partition filter based on a topic pattern and a set of partition ids.\n+   */\n+  private def createTopicPartitionFilterWithTopicAndPartitionPattern(topicOpt: Option[String], excludeInternalTopics: Boolean, partitionIds: Set[Int]): Option[PartitionInfo => Boolean] = {\n+    topicOpt match {\n+      case Some(topic) =>\n+        val topicsFilter = IncludeList(topic)\n+        if(partitionIds.isEmpty)\n+          Some(t => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics))\n+        else\n+          Some(t => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics) && partitionIds.contains(t.partition))\n+      case None =>\n+        if(excludeInternalTopics) {\n+          if(partitionIds.isEmpty)\n+            Some(t => !Topic.isInternal(t.topic))\n+          else\n+            Some(t => !Topic.isInternal(t.topic) && partitionIds.contains(t.partition))\n+        } else {\n+          if(partitionIds.isEmpty)\n+            None\n+          else\n+            Some(t => partitionIds.contains(t.partition))\n+        }\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODIyNTUwMw=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 267}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDgwNDc1OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMjo1MzoyM1rOIUbJcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjowODowNVrOIZj8Wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI4NzIxOQ==", "bodyText": "This block of code is identical to the one use at L132. Could we extract the predicate in a function and use it in both cases?", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558287219", "createdAt": "2021-01-15T12:53:23Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY3NDIwMg==", "bodyText": "Removed unnecessary sorting, no duplication", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563674202", "createdAt": "2021-01-25T12:08:05Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI4NzIxOQ=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 162}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDgwNjIyOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMjo1Mzo0OFrOIUbKTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjowODoyM1rOIZj9HQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI4NzQzOA==", "bodyText": "Do we really need to sort the partitions here? What are the benefits?", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558287438", "createdAt": "2021-01-15T12:53:48Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -89,33 +104,40 @@ object GetOffsetShell {\n     }\n     val listOffsetsTimestamp = options.valueOf(timeOpt).longValue\n \n-    val config = new Properties\n+    val topicPartitionFilter = if (options.has(topicPartitionOpt)) {\n+      Some(createTopicPartitionFilterWithPatternList(options.valueOf(topicPartitionOpt), excludeInternalTopics))\n+    } else {\n+      createTopicPartitionFilterWithTopicAndPartitionPattern(\n+        if (options.has(topicOpt)) Some(options.valueOf(topicOpt)) else None,\n+        excludeInternalTopics,\n+        partitionIdsRequested\n+      )\n+    }\n+\n+    val config = if (options.has(commandConfigOpt))\n+      Utils.loadProps(options.valueOf(commandConfigOpt))\n+    else\n+      new Properties\n     config.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n     config.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId)\n     val consumer = new KafkaConsumer(config, new ByteArrayDeserializer, new ByteArrayDeserializer)\n \n-    val partitionInfos = listPartitionInfos(consumer, topic, partitionIdsRequested) match {\n-      case None =>\n-        System.err.println(s\"Topic $topic does not exist\")\n-        Exit.exit(1)\n-      case Some(p) if p.isEmpty =>\n-        if (partitionIdsRequested.isEmpty)\n-          System.err.println(s\"Topic $topic has 0 partitions\")\n-        else\n-          System.err.println(s\"Topic $topic does not have any of the requested partitions ${partitionIdsRequested.mkString(\",\")}\")\n-        Exit.exit(1)\n-      case Some(p) => p\n-    }\n+    val partitionInfos = listPartitionInfos(consumer, topicPartitionFilter)\n \n-    if (partitionIdsRequested.nonEmpty) {\n-      (partitionIdsRequested -- partitionInfos.map(_.partition)).foreach { partitionId =>\n-        System.err.println(s\"Error: partition $partitionId does not exist\")\n-      }\n+    if (partitionInfos.isEmpty) {\n+      System.err.println(s\"Could not match any topic-partitions with the specified filters\")\n+      Exit.exit(1)\n     }\n \n-    val topicPartitions = partitionInfos.sortBy(_.partition).flatMap { p =>\n+    val topicPartitions = partitionInfos.sortWith((tp1, tp2) => {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY3NDM5Nw==", "bodyText": "No point, good catch", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563674397", "createdAt": "2021-01-25T12:08:23Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -89,33 +104,40 @@ object GetOffsetShell {\n     }\n     val listOffsetsTimestamp = options.valueOf(timeOpt).longValue\n \n-    val config = new Properties\n+    val topicPartitionFilter = if (options.has(topicPartitionOpt)) {\n+      Some(createTopicPartitionFilterWithPatternList(options.valueOf(topicPartitionOpt), excludeInternalTopics))\n+    } else {\n+      createTopicPartitionFilterWithTopicAndPartitionPattern(\n+        if (options.has(topicOpt)) Some(options.valueOf(topicOpt)) else None,\n+        excludeInternalTopics,\n+        partitionIdsRequested\n+      )\n+    }\n+\n+    val config = if (options.has(commandConfigOpt))\n+      Utils.loadProps(options.valueOf(commandConfigOpt))\n+    else\n+      new Properties\n     config.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n     config.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId)\n     val consumer = new KafkaConsumer(config, new ByteArrayDeserializer, new ByteArrayDeserializer)\n \n-    val partitionInfos = listPartitionInfos(consumer, topic, partitionIdsRequested) match {\n-      case None =>\n-        System.err.println(s\"Topic $topic does not exist\")\n-        Exit.exit(1)\n-      case Some(p) if p.isEmpty =>\n-        if (partitionIdsRequested.isEmpty)\n-          System.err.println(s\"Topic $topic has 0 partitions\")\n-        else\n-          System.err.println(s\"Topic $topic does not have any of the requested partitions ${partitionIdsRequested.mkString(\",\")}\")\n-        Exit.exit(1)\n-      case Some(p) => p\n-    }\n+    val partitionInfos = listPartitionInfos(consumer, topicPartitionFilter)\n \n-    if (partitionIdsRequested.nonEmpty) {\n-      (partitionIdsRequested -- partitionInfos.map(_.partition)).foreach { partitionId =>\n-        System.err.println(s\"Error: partition $partitionId does not exist\")\n-      }\n+    if (partitionInfos.isEmpty) {\n+      System.err.println(s\"Could not match any topic-partitions with the specified filters\")\n+      Exit.exit(1)\n     }\n \n-    val topicPartitions = partitionInfos.sortBy(_.partition).flatMap { p =>\n+    val topicPartitions = partitionInfos.sortWith((tp1, tp2) => {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI4NzQzOA=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDgyMTMxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMjo1ODowN1rOIUbTTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjowODo0MlrOIZj90A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI4OTc0Mw==", "bodyText": "It might be worth doing the filtering in the flatMap directly. It would avoid having the construct the full list and to filter it afterwards. What do you think?", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558289743", "createdAt": "2021-01-15T12:58:07Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {\n+      val parts = ruleSpec.split(\":\")\n+      if (parts.length == 1) {\n+        val whitelist = IncludeList(parts(0))\n+        tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics)\n+      } else if (parts.length == 2) {\n+        val partitionFilter = createPartitionFilter(parts(1))\n+\n+        if (parts(0).trim().isEmpty) {\n+          tp: PartitionInfo => partitionFilter.apply(tp.partition)\n+        } else {\n+          val whitelist = IncludeList(parts(0))\n+          tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics) && partitionFilter.apply(tp.partition)\n+        }\n+      } else {\n+        throw new IllegalArgumentException(s\"Invalid topic-partition rule: $ruleSpec\")\n+      }\n+    })\n+\n+    tp => rules.exists(rule => rule.apply(tp))\n+  }\n+\n+  /**\n+   * Creates a partition filter based on a single id or a range.\n+   * Expected format:\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n+   */\n+  private def createPartitionFilter(spec: String): Int => Boolean = {\n+    if (spec.indexOf('-') != -1) {\n+      val rangeParts = spec.split(\"-\", -1)\n+      if(rangeParts.length != 2 || rangeParts(0).isEmpty && rangeParts(1).isEmpty) {\n+        throw new IllegalArgumentException(s\"Invalid range specification: $spec\")\n+      }\n+\n+      if(rangeParts(0).isEmpty) {\n+        val max = rangeParts(1).toInt\n+        partition: Int => partition < max\n+      } else if(rangeParts(1).isEmpty) {\n+        val min = rangeParts(0).toInt\n+        partition: Int => partition >= min\n+      } else {\n+        val min = rangeParts(0).toInt\n+        val max = rangeParts(1).toInt\n+\n+        if (min > max) {\n+          throw new IllegalArgumentException(s\"Range lower bound cannot be greater than upper bound: $spec\")\n+        }\n+\n+        partition: Int => partition >= min && partition < max\n+      }\n+    } else {\n+      val number = spec.toInt\n+      partition: Int => partition == number\n+    }\n   }\n \n+  /**\n+   * Creates a topic-partition filter based on a topic pattern and a set of partition ids.\n+   */\n+  private def createTopicPartitionFilterWithTopicAndPartitionPattern(topicOpt: Option[String], excludeInternalTopics: Boolean, partitionIds: Set[Int]): Option[PartitionInfo => Boolean] = {\n+    topicOpt match {\n+      case Some(topic) =>\n+        val topicsFilter = IncludeList(topic)\n+        if(partitionIds.isEmpty)\n+          Some(t => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics))\n+        else\n+          Some(t => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics) && partitionIds.contains(t.partition))\n+      case None =>\n+        if(excludeInternalTopics) {\n+          if(partitionIds.isEmpty)\n+            Some(t => !Topic.isInternal(t.topic))\n+          else\n+            Some(t => !Topic.isInternal(t.topic) && partitionIds.contains(t.partition))\n+        } else {\n+          if(partitionIds.isEmpty)\n+            None\n+          else\n+            Some(t => partitionIds.contains(t.partition))\n+        }\n+    }\n+  }\n+\n+  /**\n+   * Return the partition infos. Filter them with topicPartitionFilter if specified.\n+   */\n+  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topicPartitionFilter: Option[PartitionInfo => Boolean]): Seq[PartitionInfo] = {\n+    val topicListUnfiltered = consumer.listTopics.asScala.values.flatMap { tp => tp.asScala }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 274}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY3NDU3Ng==", "bodyText": "I agree, fixed it", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563674576", "createdAt": "2021-01-25T12:08:42Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +154,119 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n \n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  private def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map(ruleSpec => {\n+      val parts = ruleSpec.split(\":\")\n+      if (parts.length == 1) {\n+        val whitelist = IncludeList(parts(0))\n+        tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics)\n+      } else if (parts.length == 2) {\n+        val partitionFilter = createPartitionFilter(parts(1))\n+\n+        if (parts(0).trim().isEmpty) {\n+          tp: PartitionInfo => partitionFilter.apply(tp.partition)\n+        } else {\n+          val whitelist = IncludeList(parts(0))\n+          tp: PartitionInfo => whitelist.isTopicAllowed(tp.topic, excludeInternalTopics) && partitionFilter.apply(tp.partition)\n+        }\n+      } else {\n+        throw new IllegalArgumentException(s\"Invalid topic-partition rule: $ruleSpec\")\n+      }\n+    })\n+\n+    tp => rules.exists(rule => rule.apply(tp))\n+  }\n+\n+  /**\n+   * Creates a partition filter based on a single id or a range.\n+   * Expected format:\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n+   */\n+  private def createPartitionFilter(spec: String): Int => Boolean = {\n+    if (spec.indexOf('-') != -1) {\n+      val rangeParts = spec.split(\"-\", -1)\n+      if(rangeParts.length != 2 || rangeParts(0).isEmpty && rangeParts(1).isEmpty) {\n+        throw new IllegalArgumentException(s\"Invalid range specification: $spec\")\n+      }\n+\n+      if(rangeParts(0).isEmpty) {\n+        val max = rangeParts(1).toInt\n+        partition: Int => partition < max\n+      } else if(rangeParts(1).isEmpty) {\n+        val min = rangeParts(0).toInt\n+        partition: Int => partition >= min\n+      } else {\n+        val min = rangeParts(0).toInt\n+        val max = rangeParts(1).toInt\n+\n+        if (min > max) {\n+          throw new IllegalArgumentException(s\"Range lower bound cannot be greater than upper bound: $spec\")\n+        }\n+\n+        partition: Int => partition >= min && partition < max\n+      }\n+    } else {\n+      val number = spec.toInt\n+      partition: Int => partition == number\n+    }\n   }\n \n+  /**\n+   * Creates a topic-partition filter based on a topic pattern and a set of partition ids.\n+   */\n+  private def createTopicPartitionFilterWithTopicAndPartitionPattern(topicOpt: Option[String], excludeInternalTopics: Boolean, partitionIds: Set[Int]): Option[PartitionInfo => Boolean] = {\n+    topicOpt match {\n+      case Some(topic) =>\n+        val topicsFilter = IncludeList(topic)\n+        if(partitionIds.isEmpty)\n+          Some(t => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics))\n+        else\n+          Some(t => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics) && partitionIds.contains(t.partition))\n+      case None =>\n+        if(excludeInternalTopics) {\n+          if(partitionIds.isEmpty)\n+            Some(t => !Topic.isInternal(t.topic))\n+          else\n+            Some(t => !Topic.isInternal(t.topic) && partitionIds.contains(t.partition))\n+        } else {\n+          if(partitionIds.isEmpty)\n+            None\n+          else\n+            Some(t => partitionIds.contains(t.partition))\n+        }\n+    }\n+  }\n+\n+  /**\n+   * Return the partition infos. Filter them with topicPartitionFilter if specified.\n+   */\n+  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topicPartitionFilter: Option[PartitionInfo => Boolean]): Seq[PartitionInfo] = {\n+    val topicListUnfiltered = consumer.listTopics.asScala.values.flatMap { tp => tp.asScala }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI4OTc0Mw=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 274}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDg1MzUyOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzowNzo0OVrOIUbmiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzowNzo0OVrOIUbmiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5NDY2Nw==", "bodyText": "nit: map(tp => { => map { tp =>", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558294667", "createdAt": "2021-01-15T13:07:49Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {\n+  private val topicCount = 4\n+  private val offsetTopicPartitionCount = 4\n+  private val topicPattern = Pattern.compile(\"test.*\")\n+\n+  override def generateConfigs: collection.Seq[KafkaConfig] = TestUtils.createBrokerConfigs(1, zkConnect)\n+    .map(p => {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDg1ODQwOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzowOTowMFrOIUbpUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjowOTo0OVrOIZkAcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5NTM3OQ==", "bodyText": "It would be better to use assertEquals as well as it outputs the values when the test fails. The same applies to all the test it seems.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558295379", "createdAt": "2021-01-15T13:09:00Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {\n+  private val topicCount = 4\n+  private val offsetTopicPartitionCount = 4\n+  private val topicPattern = Pattern.compile(\"test.*\")\n+\n+  override def generateConfigs: collection.Seq[KafkaConfig] = TestUtils.createBrokerConfigs(1, zkConnect)\n+    .map(p => {\n+      p.put(KafkaConfig.OffsetsTopicPartitionsProp, offsetTopicPartitionCount)\n+      p\n+    }).map(KafkaConfig.fromProps)\n+\n+  @Before\n+  def createTopicAndConsume(): Unit = {\n+    Range(1, topicCount + 1).foreach(i => createTopic(topicName(i), i))\n+\n+    val props = new Properties()\n+    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n+    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.GROUP_ID_CONFIG, \"GetOffsetShellTest\")\n+\n+    // Send X messages to each partition of topicX\n+    val producer = new KafkaProducer[String, String](props)\n+    Range(1, topicCount + 1).foreach(i => Range(0, i*i)\n+      .foreach(msgCount => producer.send(new ProducerRecord[String, String](topicName(i), msgCount % i, null, \"val\" + msgCount))))\n+    producer.close()\n+\n+    // Consume so consumer offsets topic is created\n+    val consumer = new KafkaConsumer[String, String](props)\n+    consumer.subscribe(topicPattern)\n+    consumer.poll(Duration.ofMillis(1000))\n+    consumer.commitSync()\n+    consumer.close()\n+  }\n+\n+  @Test\n+  def testNoFilterOptions(): Unit = {\n+    val offsets = executeAndParse(Array())\n+    assertTrue(expectedOffsets() sameElements offsets.filter(r => !isConsumerOffsetTopicPartition(r)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY3NTI1MQ==", "bodyText": "Completely agree, fixed it", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563675251", "createdAt": "2021-01-25T12:09:49Z", "author": {"login": "urbandan"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {\n+  private val topicCount = 4\n+  private val offsetTopicPartitionCount = 4\n+  private val topicPattern = Pattern.compile(\"test.*\")\n+\n+  override def generateConfigs: collection.Seq[KafkaConfig] = TestUtils.createBrokerConfigs(1, zkConnect)\n+    .map(p => {\n+      p.put(KafkaConfig.OffsetsTopicPartitionsProp, offsetTopicPartitionCount)\n+      p\n+    }).map(KafkaConfig.fromProps)\n+\n+  @Before\n+  def createTopicAndConsume(): Unit = {\n+    Range(1, topicCount + 1).foreach(i => createTopic(topicName(i), i))\n+\n+    val props = new Properties()\n+    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n+    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.GROUP_ID_CONFIG, \"GetOffsetShellTest\")\n+\n+    // Send X messages to each partition of topicX\n+    val producer = new KafkaProducer[String, String](props)\n+    Range(1, topicCount + 1).foreach(i => Range(0, i*i)\n+      .foreach(msgCount => producer.send(new ProducerRecord[String, String](topicName(i), msgCount % i, null, \"val\" + msgCount))))\n+    producer.close()\n+\n+    // Consume so consumer offsets topic is created\n+    val consumer = new KafkaConsumer[String, String](props)\n+    consumer.subscribe(topicPattern)\n+    consumer.poll(Duration.ofMillis(1000))\n+    consumer.commitSync()\n+    consumer.close()\n+  }\n+\n+  @Test\n+  def testNoFilterOptions(): Unit = {\n+    val offsets = executeAndParse(Array())\n+    assertTrue(expectedOffsets() sameElements offsets.filter(r => !isConsumerOffsetTopicPartition(r)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5NTM3OQ=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDg5ODkxOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzoyMTowM1rOIUcCEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjoyMzo1MVrOIZkgbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMTcxMw==", "bodyText": "I am not sure to understand why you filter the offsets with !isConsumerOffsetTopicPartition. In this case, we expect --exclude-internal-topics to already do this, no?\nIn general, if --exclude-internal-topics is not set, we should verify that internal topics are there as well. I wouldn't filter them out from the result set.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558301713", "createdAt": "2021-01-15T13:21:03Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {\n+  private val topicCount = 4\n+  private val offsetTopicPartitionCount = 4\n+  private val topicPattern = Pattern.compile(\"test.*\")\n+\n+  override def generateConfigs: collection.Seq[KafkaConfig] = TestUtils.createBrokerConfigs(1, zkConnect)\n+    .map(p => {\n+      p.put(KafkaConfig.OffsetsTopicPartitionsProp, offsetTopicPartitionCount)\n+      p\n+    }).map(KafkaConfig.fromProps)\n+\n+  @Before\n+  def createTopicAndConsume(): Unit = {\n+    Range(1, topicCount + 1).foreach(i => createTopic(topicName(i), i))\n+\n+    val props = new Properties()\n+    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n+    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.GROUP_ID_CONFIG, \"GetOffsetShellTest\")\n+\n+    // Send X messages to each partition of topicX\n+    val producer = new KafkaProducer[String, String](props)\n+    Range(1, topicCount + 1).foreach(i => Range(0, i*i)\n+      .foreach(msgCount => producer.send(new ProducerRecord[String, String](topicName(i), msgCount % i, null, \"val\" + msgCount))))\n+    producer.close()\n+\n+    // Consume so consumer offsets topic is created\n+    val consumer = new KafkaConsumer[String, String](props)\n+    consumer.subscribe(topicPattern)\n+    consumer.poll(Duration.ofMillis(1000))\n+    consumer.commitSync()\n+    consumer.close()\n+  }\n+\n+  @Test\n+  def testNoFilterOptions(): Unit = {\n+    val offsets = executeAndParse(Array())\n+    assertTrue(expectedOffsets() sameElements offsets.filter(r => !isConsumerOffsetTopicPartition(r)))\n+    assertEquals(offsetTopicPartitionCount, offsets.count(isConsumerOffsetTopicPartition))\n+  }\n+\n+  @Test\n+  def testInternalExcluded(): Unit = {\n+    val offsets = executeAndParse(Array(\"--exclude-internal-topics\"))\n+    assertTrue(expectedOffsets() sameElements offsets.filter(r => !isConsumerOffsetTopicPartition(r)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY4MzQzNw==", "bodyText": "I wasn't sure if I should define any expectations on the end offsets of the internal topic, that's why I was testing it separately.\nBut I think you are right, so I refactored the code to handle all topics uniformly", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563683437", "createdAt": "2021-01-25T12:23:51Z", "author": {"login": "urbandan"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {\n+  private val topicCount = 4\n+  private val offsetTopicPartitionCount = 4\n+  private val topicPattern = Pattern.compile(\"test.*\")\n+\n+  override def generateConfigs: collection.Seq[KafkaConfig] = TestUtils.createBrokerConfigs(1, zkConnect)\n+    .map(p => {\n+      p.put(KafkaConfig.OffsetsTopicPartitionsProp, offsetTopicPartitionCount)\n+      p\n+    }).map(KafkaConfig.fromProps)\n+\n+  @Before\n+  def createTopicAndConsume(): Unit = {\n+    Range(1, topicCount + 1).foreach(i => createTopic(topicName(i), i))\n+\n+    val props = new Properties()\n+    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n+    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.GROUP_ID_CONFIG, \"GetOffsetShellTest\")\n+\n+    // Send X messages to each partition of topicX\n+    val producer = new KafkaProducer[String, String](props)\n+    Range(1, topicCount + 1).foreach(i => Range(0, i*i)\n+      .foreach(msgCount => producer.send(new ProducerRecord[String, String](topicName(i), msgCount % i, null, \"val\" + msgCount))))\n+    producer.close()\n+\n+    // Consume so consumer offsets topic is created\n+    val consumer = new KafkaConsumer[String, String](props)\n+    consumer.subscribe(topicPattern)\n+    consumer.poll(Duration.ofMillis(1000))\n+    consumer.commitSync()\n+    consumer.close()\n+  }\n+\n+  @Test\n+  def testNoFilterOptions(): Unit = {\n+    val offsets = executeAndParse(Array())\n+    assertTrue(expectedOffsets() sameElements offsets.filter(r => !isConsumerOffsetTopicPartition(r)))\n+    assertEquals(offsetTopicPartitionCount, offsets.count(isConsumerOffsetTopicPartition))\n+  }\n+\n+  @Test\n+  def testInternalExcluded(): Unit = {\n+    val offsets = executeAndParse(Array(\"--exclude-internal-topics\"))\n+    assertTrue(expectedOffsets() sameElements offsets.filter(r => !isConsumerOffsetTopicPartition(r)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMTcxMw=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDkwMzE0OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzoyMjoxN1rOIUcEpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzoyMjoxN1rOIUcEpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMjM3Mg==", "bodyText": "nit: r => r._2 <= 1 is quite hard to read. It might be better to deconstruct the record so we can name the variable partition.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558302372", "createdAt": "2021-01-15T13:22:17Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {\n+  private val topicCount = 4\n+  private val offsetTopicPartitionCount = 4\n+  private val topicPattern = Pattern.compile(\"test.*\")\n+\n+  override def generateConfigs: collection.Seq[KafkaConfig] = TestUtils.createBrokerConfigs(1, zkConnect)\n+    .map(p => {\n+      p.put(KafkaConfig.OffsetsTopicPartitionsProp, offsetTopicPartitionCount)\n+      p\n+    }).map(KafkaConfig.fromProps)\n+\n+  @Before\n+  def createTopicAndConsume(): Unit = {\n+    Range(1, topicCount + 1).foreach(i => createTopic(topicName(i), i))\n+\n+    val props = new Properties()\n+    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n+    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])\n+    props.put(ConsumerConfig.GROUP_ID_CONFIG, \"GetOffsetShellTest\")\n+\n+    // Send X messages to each partition of topicX\n+    val producer = new KafkaProducer[String, String](props)\n+    Range(1, topicCount + 1).foreach(i => Range(0, i*i)\n+      .foreach(msgCount => producer.send(new ProducerRecord[String, String](topicName(i), msgCount % i, null, \"val\" + msgCount))))\n+    producer.close()\n+\n+    // Consume so consumer offsets topic is created\n+    val consumer = new KafkaConsumer[String, String](props)\n+    consumer.subscribe(topicPattern)\n+    consumer.poll(Duration.ofMillis(1000))\n+    consumer.commitSync()\n+    consumer.close()\n+  }\n+\n+  @Test\n+  def testNoFilterOptions(): Unit = {\n+    val offsets = executeAndParse(Array())\n+    assertTrue(expectedOffsets() sameElements offsets.filter(r => !isConsumerOffsetTopicPartition(r)))\n+    assertEquals(offsetTopicPartitionCount, offsets.count(isConsumerOffsetTopicPartition))\n+  }\n+\n+  @Test\n+  def testInternalExcluded(): Unit = {\n+    val offsets = executeAndParse(Array(\"--exclude-internal-topics\"))\n+    assertTrue(expectedOffsets() sameElements offsets.filter(r => !isConsumerOffsetTopicPartition(r)))\n+    assertEquals(0, offsets.count(isConsumerOffsetTopicPartition))\n+  }\n+\n+  @Test\n+  def testTopicNameArg(): Unit = {\n+    Range(1, topicCount + 1).foreach(i => {\n+      val offsets = executeAndParse(Array(\"--topic\", topicName(i)))\n+      assertTrue(\"Offset output did not match for \" + topicName(i), expectedOffsetsForTopic(i) sameElements offsets)\n+    })\n+  }\n+\n+  @Test\n+  def testTopicPatternArg(): Unit = {\n+    val offsets = executeAndParse(Array(\"--topic\", \"topic.*\"))\n+    assertTrue(expectedOffsets() sameElements offsets)\n+  }\n+\n+  @Test\n+  def testPartitionsArg(): Unit = {\n+    val offsets = executeAndParse(Array(\"--partitions\", \"0,1\"))\n+    assertTrue(expectedOffsets().filter(r => r._2 <= 1) sameElements offsets.filter(r => !isConsumerOffsetTopicPartition(r)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDkwNjkyOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzoyMzoyM1rOIUcHBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNjowMDozM1rOIZt69A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMjk4Mw==", "bodyText": "It would be great if we could add few tests to verify the mutually exclusive arguments. We should also add unit tests to verify the parsing of the specs. We could make the relevant package private so we can access them from here.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558302983", "createdAt": "2021-01-15T13:23:23Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzgzNzY4NA==", "bodyText": "Agree, added coverage for the arguments and the filter parsing as well", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563837684", "createdAt": "2021-01-25T16:00:33Z", "author": {"login": "urbandan"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMjk4Mw=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNDkxMDM0OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzoyNDoyM1rOIUcJGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMjoyNDo0M1rOIZkiaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzUxNQ==", "bodyText": "Is test.* correct? It seems that topics are named topic....", "url": "https://github.com/apache/kafka/pull/9430#discussion_r558303515", "createdAt": "2021-01-15T13:24:23Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {\n+  private val topicCount = 4\n+  private val offsetTopicPartitionCount = 4\n+  private val topicPattern = Pattern.compile(\"test.*\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzY4Mzk0Nw==", "bodyText": "Was used by the dummy consumer, removed", "url": "https://github.com/apache/kafka/pull/9430#discussion_r563683947", "createdAt": "2021-01-25T12:24:43Z", "author": {"login": "urbandan"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,194 @@\n+package kafka.tools\n+\n+import java.time.Duration\n+import java.util.Properties\n+import java.util.regex.Pattern\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.{StringDeserializer, StringSerializer}\n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {\n+  private val topicCount = 4\n+  private val offsetTopicPartitionCount = 4\n+  private val topicPattern = Pattern.compile(\"test.*\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzUxNQ=="}, "originalCommit": {"oid": "7c3fee195e9245287f1db02e41d6afcb772911d7"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1OTMyMjg2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QwNzo0MjozNVrOIa6P8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNToxMjozN1rOIfHMOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTA4ODI0MA==", "bodyText": "How about moving the computation of partitionIdsRequested to L112? It does not make sense to do all of this if options.has(topicPartitionsOpt).", "url": "https://github.com/apache/kafka/pull/9430#discussion_r565088240", "createdAt": "2021-01-27T07:42:35Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -33,49 +34,65 @@ object GetOffsetShell {\n \n   def main(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionsOpt = parser.accepts(\"topic-partitions\", \"Comma separated list of topic-partition specifications to get the offsets for, with the format of topic:partition. The 'topic' part can be a regex or may be omitted to only specify the partitions, and query all authorized topics.\" +\n+                                            \" The 'partition' part can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions of the specified topic.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic:partition,...,topic:partition\")\n+                           .ofType(classOf[String])\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"topic\")\n                            .ofType(classOf[String])\n-    val partitionOpt = parser.accepts(\"partitions\", \"comma separated list of partition ids. If not specified, it will find offsets for all partitions\")\n+    val partitionsOpt = parser.accepts(\"partitions\", s\"Comma separated list of partition ids to get the offsets for. If not present, all partitions of the authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"partition ids\")\n                            .ofType(classOf[String])\n-                           .defaultsTo(\"\")\n-    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently commited record timestamp is given.]\")\n+    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently committed record timestamp is given.]\")\n                            .withRequiredArg\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Property file containing configs to be passed to Consumer Client.\")\n                            .withRequiredArg\n-                           .describedAs(\"ms\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1000)\n+                           .describedAs(\"config file\")\n+                           .ofType(classOf[String])\n+    val excludeInternalTopicsOpt = parser.accepts(\"exclude-internal-topics\", s\"By default, internal topics are included. If specified, internal topics are excluded.\")\n \n-   if (args.length == 0)\n-      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic offsets.\")\n+    if (args.length == 0)\n+      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic-partition offsets.\")\n \n     val options = parser.parse(args : _*)\n \n-    CommandLineUtils.checkRequiredArgs(parser, options, brokerListOpt, topicOpt)\n+    val effectiveBrokerListOpt = if (options.has(bootstrapServerOpt))\n+      bootstrapServerOpt\n+    else\n+      brokerListOpt\n+\n+    CommandLineUtils.checkRequiredArgs(parser, options, effectiveBrokerListOpt)\n \n     val clientId = \"GetOffsetShell\"\n-    val brokerList = options.valueOf(brokerListOpt)\n+    val brokerList = options.valueOf(effectiveBrokerListOpt)\n+\n     ToolsUtils.validatePortOrDie(parser, brokerList)\n-    val topic = options.valueOf(topicOpt)\n+    val excludeInternalTopics = options.has(excludeInternalTopicsOpt)\n+\n+    if (options.has(topicPartitionsOpt) && (options.has(topicOpt) || options.has(partitionsOpt))) {\n+      System.err.println(s\"--topic-partitions cannot be used with --topic or --partitions\")\n+      Exit.exit(1)\n+    }\n+\n     val partitionIdsRequested: Set[Int] = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "446a9bf18538db20a759d9704bd31b614d4ae291"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQ5NDU4Ng==", "bodyText": "Good catch, thank you", "url": "https://github.com/apache/kafka/pull/9430#discussion_r569494586", "createdAt": "2021-02-03T15:12:37Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -33,49 +34,65 @@ object GetOffsetShell {\n \n   def main(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionsOpt = parser.accepts(\"topic-partitions\", \"Comma separated list of topic-partition specifications to get the offsets for, with the format of topic:partition. The 'topic' part can be a regex or may be omitted to only specify the partitions, and query all authorized topics.\" +\n+                                            \" The 'partition' part can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions of the specified topic.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic:partition,...,topic:partition\")\n+                           .ofType(classOf[String])\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"topic\")\n                            .ofType(classOf[String])\n-    val partitionOpt = parser.accepts(\"partitions\", \"comma separated list of partition ids. If not specified, it will find offsets for all partitions\")\n+    val partitionsOpt = parser.accepts(\"partitions\", s\"Comma separated list of partition ids to get the offsets for. If not present, all partitions of the authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"partition ids\")\n                            .ofType(classOf[String])\n-                           .defaultsTo(\"\")\n-    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently commited record timestamp is given.]\")\n+    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently committed record timestamp is given.]\")\n                            .withRequiredArg\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Property file containing configs to be passed to Consumer Client.\")\n                            .withRequiredArg\n-                           .describedAs(\"ms\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1000)\n+                           .describedAs(\"config file\")\n+                           .ofType(classOf[String])\n+    val excludeInternalTopicsOpt = parser.accepts(\"exclude-internal-topics\", s\"By default, internal topics are included. If specified, internal topics are excluded.\")\n \n-   if (args.length == 0)\n-      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic offsets.\")\n+    if (args.length == 0)\n+      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic-partition offsets.\")\n \n     val options = parser.parse(args : _*)\n \n-    CommandLineUtils.checkRequiredArgs(parser, options, brokerListOpt, topicOpt)\n+    val effectiveBrokerListOpt = if (options.has(bootstrapServerOpt))\n+      bootstrapServerOpt\n+    else\n+      brokerListOpt\n+\n+    CommandLineUtils.checkRequiredArgs(parser, options, effectiveBrokerListOpt)\n \n     val clientId = \"GetOffsetShell\"\n-    val brokerList = options.valueOf(brokerListOpt)\n+    val brokerList = options.valueOf(effectiveBrokerListOpt)\n+\n     ToolsUtils.validatePortOrDie(parser, brokerList)\n-    val topic = options.valueOf(topicOpt)\n+    val excludeInternalTopics = options.has(excludeInternalTopicsOpt)\n+\n+    if (options.has(topicPartitionsOpt) && (options.has(topicOpt) || options.has(partitionsOpt))) {\n+      System.err.println(s\"--topic-partitions cannot be used with --topic or --partitions\")\n+      Exit.exit(1)\n+    }\n+\n     val partitionIdsRequested: Set[Int] = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTA4ODI0MA=="}, "originalCommit": {"oid": "446a9bf18538db20a759d9704bd31b614d4ae291"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1OTM3NjYyOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QwNzo1ODozOVrOIa6vyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNToxNTowNlrOIfHTwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTA5NjM5Mg==", "bodyText": "I am not fan of using Exit.exit all over the places. I know that it was already like this before but I do wonder if we could improve this by throwing exceptions instead and by catching them in the main. I think that this would require to strip down the main function a bit.\nAnother reason for this is that the new code throws IllegalArgumentException in few places but I don't think that we catch them anywhere, do we? What do you think?", "url": "https://github.com/apache/kafka/pull/9430#discussion_r565096392", "createdAt": "2021-01-27T07:58:39Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -89,33 +106,34 @@ object GetOffsetShell {\n     }\n     val listOffsetsTimestamp = options.valueOf(timeOpt).longValue\n \n-    val config = new Properties\n+    val topicPartitionFilter = if (options.has(topicPartitionsOpt)) {\n+      createTopicPartitionFilterWithPatternList(options.valueOf(topicPartitionsOpt), excludeInternalTopics)\n+    } else {\n+      createTopicPartitionFilterWithTopicAndPartitionPattern(\n+        if (options.has(topicOpt)) Some(options.valueOf(topicOpt)) else None,\n+        excludeInternalTopics,\n+        partitionIdsRequested\n+      )\n+    }\n+\n+    val config = if (options.has(commandConfigOpt))\n+      Utils.loadProps(options.valueOf(commandConfigOpt))\n+    else\n+      new Properties\n     config.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n     config.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId)\n     val consumer = new KafkaConsumer(config, new ByteArrayDeserializer, new ByteArrayDeserializer)\n \n-    val partitionInfos = listPartitionInfos(consumer, topic, partitionIdsRequested) match {\n-      case None =>\n-        System.err.println(s\"Topic $topic does not exist\")\n-        Exit.exit(1)\n-      case Some(p) if p.isEmpty =>\n-        if (partitionIdsRequested.isEmpty)\n-          System.err.println(s\"Topic $topic has 0 partitions\")\n-        else\n-          System.err.println(s\"Topic $topic does not have any of the requested partitions ${partitionIdsRequested.mkString(\",\")}\")\n-        Exit.exit(1)\n-      case Some(p) => p\n-    }\n+    val partitionInfos = listPartitionInfos(consumer, topicPartitionFilter)\n \n-    if (partitionIdsRequested.nonEmpty) {\n-      (partitionIdsRequested -- partitionInfos.map(_.partition)).foreach { partitionId =>\n-        System.err.println(s\"Error: partition $partitionId does not exist\")\n-      }\n+    if (partitionInfos.isEmpty) {\n+      System.err.println(s\"Could not match any topic-partitions with the specified filters\")\n+      Exit.exit(1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "446a9bf18538db20a759d9704bd31b614d4ae291"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQ5NjUxMg==", "bodyText": "Overall, I agree. Removed the exit calls, but left other util calls possibly invoking exit.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r569496512", "createdAt": "2021-02-03T15:15:06Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -89,33 +106,34 @@ object GetOffsetShell {\n     }\n     val listOffsetsTimestamp = options.valueOf(timeOpt).longValue\n \n-    val config = new Properties\n+    val topicPartitionFilter = if (options.has(topicPartitionsOpt)) {\n+      createTopicPartitionFilterWithPatternList(options.valueOf(topicPartitionsOpt), excludeInternalTopics)\n+    } else {\n+      createTopicPartitionFilterWithTopicAndPartitionPattern(\n+        if (options.has(topicOpt)) Some(options.valueOf(topicOpt)) else None,\n+        excludeInternalTopics,\n+        partitionIdsRequested\n+      )\n+    }\n+\n+    val config = if (options.has(commandConfigOpt))\n+      Utils.loadProps(options.valueOf(commandConfigOpt))\n+    else\n+      new Properties\n     config.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n     config.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId)\n     val consumer = new KafkaConsumer(config, new ByteArrayDeserializer, new ByteArrayDeserializer)\n \n-    val partitionInfos = listPartitionInfos(consumer, topic, partitionIdsRequested) match {\n-      case None =>\n-        System.err.println(s\"Topic $topic does not exist\")\n-        Exit.exit(1)\n-      case Some(p) if p.isEmpty =>\n-        if (partitionIdsRequested.isEmpty)\n-          System.err.println(s\"Topic $topic has 0 partitions\")\n-        else\n-          System.err.println(s\"Topic $topic does not have any of the requested partitions ${partitionIdsRequested.mkString(\",\")}\")\n-        Exit.exit(1)\n-      case Some(p) => p\n-    }\n+    val partitionInfos = listPartitionInfos(consumer, topicPartitionFilter)\n \n-    if (partitionIdsRequested.nonEmpty) {\n-      (partitionIdsRequested -- partitionInfos.map(_.partition)).foreach { partitionId =>\n-        System.err.println(s\"Error: partition $partitionId does not exist\")\n-      }\n+    if (partitionInfos.isEmpty) {\n+      System.err.println(s\"Could not match any topic-partitions with the specified filters\")\n+      Exit.exit(1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTA5NjM5Mg=="}, "originalCommit": {"oid": "446a9bf18538db20a759d9704bd31b614d4ae291"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1OTQxMzc2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QwODowOTozMVrOIa7GMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNToxNToxNlrOIfHUVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTEwMjEzMQ==", "bodyText": "I just learnt that we can actually compare TopicPartition with the following comparator in Scala:\n  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n    (a.topic(), a.partition()) < (b.topic(), b.partition())\n  }\n\nand do partitionOffsets.toSeq.sortWith(compareTopicPartitions).foreach { .... This makes the code a bit more readable.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r565102131", "createdAt": "2021-01-27T08:09:31Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +150,104 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "446a9bf18538db20a759d9704bd31b614d4ae291"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQ5NjY2MQ==", "bodyText": "Thanks, refactored it", "url": "https://github.com/apache/kafka/pull/9430#discussion_r569496661", "createdAt": "2021-02-03T15:15:16Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +150,104 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTEwMjEzMQ=="}, "originalCommit": {"oid": "446a9bf18538db20a759d9704bd31b614d4ae291"}, "originalPosition": 162}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1OTUxNjMxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QwODozNjoyN1rOIa8Dpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxNToxNjoyMlrOIfHXpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTExNzg2Mw==", "bodyText": "Out of curiosity, did you consider using a regex to parse the rule spec? It seems to me that something like this  ([^:]*):([0-9]*)(?:-([0-9]*))? could work and could directly extract all the required parts. I haven't tested it. That could reduce the code while making the grammar of the rule spec more explicit.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r565117863", "createdAt": "2021-01-27T08:36:27Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +150,104 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  /**\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n+   */\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "446a9bf18538db20a759d9704bd31b614d4ae291"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQ5NzUxMA==", "bodyText": "I personally prefer not using regex, but I see your point - switched to regex usage.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r569497510", "createdAt": "2021-02-03T15:16:22Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +150,104 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => {\n+      val topicComp = tp1._1.topic.compareTo(tp2._1.topic)\n+      if (topicComp == 0)\n+        tp1._1.partition < tp2._1.partition\n+      else\n+        topicComp < 0\n+    }).foreach { case (tp, offset) =>\n+      println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  /**\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n+   */\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTExNzg2Mw=="}, "originalCommit": {"oid": "446a9bf18538db20a759d9704bd31b614d4ae291"}, "originalPosition": 183}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1OTUzMjExOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QwODo0MDoxN1rOIa8NAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QwODo0MDoxN1rOIa8NAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTEyMDI1Nw==", "bodyText": "nit: .map(line => { -> .map { line =>", "url": "https://github.com/apache/kafka/pull/9430#discussion_r565120257", "createdAt": "2021-01-27T08:40:17Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/kafka/tools/GetOffsetShellTest.scala", "diffHunk": "@@ -0,0 +1,207 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.tools\n+\n+import java.util.Properties\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.{Exit, Logging, TestUtils}\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n+import org.apache.kafka.common.serialization.StringSerializer\n+import org.junit.Assert.assertEquals\n+import org.junit.{Before, Test}\n+\n+class GetOffsetShellTest extends KafkaServerTestHarness with Logging {\n+  private val topicCount = 4\n+  private val offsetTopicPartitionCount = 4\n+\n+  override def generateConfigs: collection.Seq[KafkaConfig] = TestUtils.createBrokerConfigs(1, zkConnect)\n+    .map { p =>\n+      p.put(KafkaConfig.OffsetsTopicPartitionsProp, Int.box(offsetTopicPartitionCount))\n+      p\n+    }.map(KafkaConfig.fromProps)\n+\n+  @Before\n+  def createTestAndInternalTopics(): Unit = {\n+    Range(1, topicCount + 1).foreach(i => createTopic(topicName(i), i))\n+\n+    val props = new Properties()\n+    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n+    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer])\n+\n+    // Send X messages to each partition of topicX\n+    val producer = new KafkaProducer[String, String](props)\n+    Range(1, topicCount + 1).foreach(i => Range(0, i*i)\n+      .foreach(msgCount => producer.send(new ProducerRecord[String, String](topicName(i), msgCount % i, null, \"val\" + msgCount))))\n+    producer.close()\n+\n+    TestUtils.createOffsetsTopic(zkClient, servers)\n+  }\n+\n+  @Test\n+  def testNoFilterOptions(): Unit = {\n+    val offsets = executeAndParse(Array())\n+    assertEquals(expectedOffsetsWithInternal(), offsets)\n+  }\n+\n+  @Test\n+  def testInternalExcluded(): Unit = {\n+    val offsets = executeAndParse(Array(\"--exclude-internal-topics\"))\n+    assertEquals(expectedTestTopicOffsets(), offsets)\n+  }\n+\n+  @Test\n+  def testTopicNameArg(): Unit = {\n+    Range(1, topicCount + 1).foreach(i => {\n+      val offsets = executeAndParse(Array(\"--topic\", topicName(i)))\n+      assertEquals(\"Offset output did not match for \" + topicName(i), expectedOffsetsForTopic(i), offsets)\n+    })\n+  }\n+\n+  @Test\n+  def testTopicPatternArg(): Unit = {\n+    val offsets = executeAndParse(Array(\"--topic\", \"topic.*\"))\n+    assertEquals(expectedTestTopicOffsets(), offsets)\n+  }\n+\n+  @Test\n+  def testPartitionsArg(): Unit = {\n+    val offsets = executeAndParse(Array(\"--partitions\", \"0,1\"))\n+    assertEquals(expectedOffsetsWithInternal().filter { case (_, partition, _) => partition <= 1 }, offsets)\n+  }\n+\n+  @Test\n+  def testTopicPatternArgWithPartitionsArg(): Unit = {\n+    val offsets = executeAndParse(Array(\"--topic\", \"topic.*\", \"--partitions\", \"0,1\"))\n+    assertEquals(expectedTestTopicOffsets().filter { case (_, partition, _) => partition <= 1 }, offsets)\n+  }\n+\n+  @Test\n+  def testTopicPartitionsArg(): Unit = {\n+    val offsets = executeAndParse(Array(\"--topic-partitions\", \"topic1:0,topic2:1,topic(3|4):2,__.*:3\"))\n+    assertEquals(\n+      List(\n+        (\"__consumer_offsets\", 3, Some(0)),\n+        (\"topic1\", 0, Some(1)),\n+        (\"topic2\", 1, Some(2)),\n+        (\"topic3\", 2, Some(3)),\n+        (\"topic4\", 2, Some(4))\n+      ),\n+      offsets\n+    )\n+  }\n+\n+  @Test\n+  def testTopicPartitionsArgWithInternalExcluded(): Unit = {\n+    val offsets = executeAndParse(Array(\"--topic-partitions\",\n+      \"topic1:0,topic2:1,topic(3|4):2,__.*:3\", \"--exclude-internal-topics\"))\n+    assertEquals(\n+      List(\n+        (\"topic1\", 0, Some(1)),\n+        (\"topic2\", 1, Some(2)),\n+        (\"topic3\", 2, Some(3)),\n+        (\"topic4\", 2, Some(4))\n+      ),\n+      offsets\n+    )\n+  }\n+\n+  @Test\n+  def testTopicPartitionsNotFoundForNonExistentTopic(): Unit = {\n+    assertExitCodeIsOne(Array(\"--topic\", \"some_nonexistent_topic\"))\n+  }\n+\n+  @Test\n+  def testTopicPartitionsNotFoundForExcludedInternalTopic(): Unit = {\n+    assertExitCodeIsOne(Array(\"--topic\", \"some_nonexistent_topic:*\"))\n+  }\n+\n+  @Test\n+  def testTopicPartitionsNotFoundForNonMatchingTopicPartitionPattern(): Unit = {\n+    assertExitCodeIsOne(Array(\"--topic-partitions\", \"__consumer_offsets\", \"--exclude-internal-topics\"))\n+  }\n+\n+  @Test\n+  def testTopicPartitionsFlagWithTopicFlagCauseExit(): Unit = {\n+    assertExitCodeIsOne(Array(\"--topic-partitions\", \"__consumer_offsets\", \"--topic\", \"topic1\"))\n+  }\n+\n+  @Test\n+  def testTopicPartitionsFlagWithPartitionsFlagCauseExit(): Unit = {\n+    assertExitCodeIsOne(Array(\"--topic-partitions\", \"__consumer_offsets\", \"--partitions\", \"0\"))\n+  }\n+\n+  private def expectedOffsetsWithInternal(): List[(String, Int, Option[Long])] = {\n+    Range(0, offsetTopicPartitionCount).map(i => (\"__consumer_offsets\", i, Some(0L))).toList ++ expectedTestTopicOffsets()\n+  }\n+\n+  private def expectedTestTopicOffsets(): List[(String, Int, Option[Long])] = {\n+    Range(1, topicCount + 1).flatMap(i => expectedOffsetsForTopic(i)).toList\n+  }\n+\n+  private def expectedOffsetsForTopic(i: Int): List[(String, Int, Option[Long])] = {\n+    val name = topicName(i)\n+    Range(0, i).map(p => (name, p, Some(i.toLong))).toList\n+  }\n+\n+  private def topicName(i: Int): String = \"topic\" + i\n+\n+  private def assertExitCodeIsOne(args: Array[String]): Unit = {\n+    var exitStatus: Option[Int] = None\n+    Exit.setExitProcedure { (status, _) =>\n+      exitStatus = Some(status)\n+      throw new RuntimeException\n+    }\n+\n+    try {\n+      GetOffsetShell.main(addBootstrapServer(args))\n+    } catch {\n+      case e: RuntimeException =>\n+    } finally {\n+      Exit.resetExitProcedure()\n+    }\n+\n+    assertEquals(Some(1), exitStatus)\n+  }\n+\n+  private def executeAndParse(args: Array[String]): List[(String, Int, Option[Long])] = {\n+    val output = executeAndGrabOutput(args)\n+    output.split(System.lineSeparator())\n+      .map(_.split(\":\"))\n+      .filter(_.length >= 2)\n+      .map(line => {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "446a9bf18538db20a759d9704bd31b614d4ae291"}, "originalPosition": 189}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTU5NzA5OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzozMTo1OVrOIhjCSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQwODowNDowMVrOIiI0wQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA0Nzk0NQ==", "bodyText": "It seems that we need to print out something here for the user. The default exit procedure doesn't do anything with the provided message. Take a look at the other commands to see how we handle this.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572047945", "createdAt": "2021-02-08T13:31:59Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,131 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val topicPartitionPattern = Pattern.compile( \"([^:,]*)(?::([0-9]*)(?:-([0-9]*))?)?\")\n \n   def main(args: Array[String]): Unit = {\n+    try {\n+      fetchOffsets(args)\n+    } catch {\n+      case e: Exception => Exit.exit(1, Some(e.getMessage))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjY2NzA3Mw==", "bodyText": "Thanks, good catch", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572667073", "createdAt": "2021-02-09T08:04:01Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,131 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val topicPartitionPattern = Pattern.compile( \"([^:,]*)(?::([0-9]*)(?:-([0-9]*))?)?\")\n \n   def main(args: Array[String]): Unit = {\n+    try {\n+      fetchOffsets(args)\n+    } catch {\n+      case e: Exception => Exit.exit(1, Some(e.getMessage))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA0Nzk0NQ=="}, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTYwMDA4OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzozMjozM1rOIhjD-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo1NzoyN1rOIipB7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA0ODM3OA==", "bodyText": "nit: sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)) -> sortWith(compareTopicPartitions)", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572048378", "createdAt": "2021-02-08T13:32:33Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjY2NjMzNw==", "bodyText": "The current compareTopicPartitions method expects TopicPartitions, but we have tuples in the collection.\nShould I change compareTopicPartitions to expect tuples?", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572666337", "createdAt": "2021-02-09T08:02:27Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA0ODM3OA=="}, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzE5NDczNQ==", "bodyText": "No, that's fine as it is then. I missed this.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r573194735", "createdAt": "2021-02-09T19:57:27Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA0ODM3OA=="}, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 191}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTYwMzIxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzozMzoyNFrOIhjF8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQwODowNDozNlrOIiI14g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA0ODg4MA==", "bodyText": "I don't think that matcher.groupCount() == 0 is necessary. My understanding is that it will never be 0 as we have groups defined in the regex.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572048880", "createdAt": "2021-02-08T13:33:24Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }\n+    tp => rules.exists(rule => rule.apply(tp))\n   }\n \n+  def parseRuleSpec(ruleSpec: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    def wrapNullOrEmpty(s: String): Option[String] = {\n+      if (s == null || s.isEmpty)\n+        None\n+      else\n+        Some(s)\n+    }\n+\n+    val matcher = topicPartitionPattern.matcher(ruleSpec)\n+    if (!matcher.matches() || matcher.groupCount() == 0)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjY2NzM2Mg==", "bodyText": "True, good catch", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572667362", "createdAt": "2021-02-09T08:04:36Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }\n+    tp => rules.exists(rule => rule.apply(tp))\n   }\n \n+  def parseRuleSpec(ruleSpec: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    def wrapNullOrEmpty(s: String): Option[String] = {\n+      if (s == null || s.isEmpty)\n+        None\n+      else\n+        Some(s)\n+    }\n+\n+    val matcher = topicPartitionPattern.matcher(ruleSpec)\n+    if (!matcher.matches() || matcher.groupCount() == 0)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA0ODg4MA=="}, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 232}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTYwOTE1OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzozNDo0MVrOIhjJeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzozNDo0MVrOIhjJeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA0OTc4NA==", "bodyText": "It seems that checking matcher.groupCount() >= 2 is not necessary. Groups will be null anyway if they are not filled.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572049784", "createdAt": "2021-02-08T13:34:41Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }\n+    tp => rules.exists(rule => rule.apply(tp))\n   }\n \n+  def parseRuleSpec(ruleSpec: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    def wrapNullOrEmpty(s: String): Option[String] = {\n+      if (s == null || s.isEmpty)\n+        None\n+      else\n+        Some(s)\n+    }\n+\n+    val matcher = topicPartitionPattern.matcher(ruleSpec)\n+    if (!matcher.matches() || matcher.groupCount() == 0)\n+      throw new IllegalArgumentException(s\"Invalid rule specification: $ruleSpec\")\n+\n+    val topicPattern = wrapNullOrEmpty(matcher.group(1))\n+    val lowerRange = if (matcher.groupCount() >= 2) wrapNullOrEmpty(matcher.group(2)) else None", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 236}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTY0MDY4OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0MToxMlrOIhjb3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQwODowOToxOVrOIiI_5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA1NDQ5Mw==", "bodyText": "I think that we could further simplify this by differentiating the range case from the single partition case in the regex directly. We could for instance use the following regex: \"([^:,]*)(?::(?:([0-9]*)|(?:([0-9]*)-([0-9]*))))?\".\nIt allows to do something like this for the processing:\n    val matcher = topicPartitionPattern.matcher(ruleSpec)\n    if (!matcher.matches())\n      throw new IllegalArgumentException(s\"Invalid rule specification: $ruleSpec\")\n\n    def group(group: Int): Option[String] = {\n      Option(matcher.group(group)).filter(s => s != null && s.nonEmpty)\n    }\n\n    val topicFilter = IncludeList(group(1).getOrElse(\".*\"))\n    val partitionFilter = group(2).map(_.toInt) match {\n      case Some(partition) =>\n        (p: Int) => p == partition\n      case None =>\n        val lowerRange = group(3).map(_.toInt).getOrElse(0)\n        val upperRange = group(4).map(_.toInt).getOrElse(Int.MaxValue)\n        (p: Int) => p >= lowerRange && p < upperRange\n    }\n\nBasically, if no single partition is provided, we use a range with 0 and Int.MaxValue as defaults.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572054493", "createdAt": "2021-02-08T13:41:12Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }\n+    tp => rules.exists(rule => rule.apply(tp))\n   }\n \n+  def parseRuleSpec(ruleSpec: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    def wrapNullOrEmpty(s: String): Option[String] = {\n+      if (s == null || s.isEmpty)\n+        None\n+      else\n+        Some(s)\n+    }\n+\n+    val matcher = topicPartitionPattern.matcher(ruleSpec)\n+    if (!matcher.matches() || matcher.groupCount() == 0)\n+      throw new IllegalArgumentException(s\"Invalid rule specification: $ruleSpec\")\n+\n+    val topicPattern = wrapNullOrEmpty(matcher.group(1))\n+    val lowerRange = if (matcher.groupCount() >= 2) wrapNullOrEmpty(matcher.group(2)) else None\n+    val upperRangeSection = if (matcher.groupCount() >= 3) matcher.group(3) else null\n+    val upperRange = wrapNullOrEmpty(upperRangeSection)\n+    val isRange = upperRangeSection != null\n+\n+    val includeList = IncludeList(topicPattern.getOrElse(\".*\"))\n+\n+    val partitionFilter: Int => Boolean = if (lowerRange.isEmpty && upperRange.isEmpty) {\n+      _ => true\n+    } else if (lowerRange.isEmpty) {\n+      val upperBound = upperRange.get.toInt\n+      p => p < upperBound\n+    } else if (upperRange.isEmpty) {\n+      val lowerBound = lowerRange.get.toInt\n+      if (isRange) {\n+        p => p >= lowerBound\n+      }\n+      else {\n+        p => p == lowerBound\n+      }\n+    } else {\n+      val upperBound = upperRange.get.toInt\n+      val lowerBound = lowerRange.get.toInt\n+      p => p >= lowerBound && p < upperBound\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 260}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjY2OTkyNQ==", "bodyText": "Thank you, changed implementation to this", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572669925", "createdAt": "2021-02-09T08:09:19Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }\n+    tp => rules.exists(rule => rule.apply(tp))\n   }\n \n+  def parseRuleSpec(ruleSpec: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    def wrapNullOrEmpty(s: String): Option[String] = {\n+      if (s == null || s.isEmpty)\n+        None\n+      else\n+        Some(s)\n+    }\n+\n+    val matcher = topicPartitionPattern.matcher(ruleSpec)\n+    if (!matcher.matches() || matcher.groupCount() == 0)\n+      throw new IllegalArgumentException(s\"Invalid rule specification: $ruleSpec\")\n+\n+    val topicPattern = wrapNullOrEmpty(matcher.group(1))\n+    val lowerRange = if (matcher.groupCount() >= 2) wrapNullOrEmpty(matcher.group(2)) else None\n+    val upperRangeSection = if (matcher.groupCount() >= 3) matcher.group(3) else null\n+    val upperRange = wrapNullOrEmpty(upperRangeSection)\n+    val isRange = upperRangeSection != null\n+\n+    val includeList = IncludeList(topicPattern.getOrElse(\".*\"))\n+\n+    val partitionFilter: Int => Boolean = if (lowerRange.isEmpty && upperRange.isEmpty) {\n+      _ => true\n+    } else if (lowerRange.isEmpty) {\n+      val upperBound = upperRange.get.toInt\n+      p => p < upperBound\n+    } else if (upperRange.isEmpty) {\n+      val lowerBound = lowerRange.get.toInt\n+      if (isRange) {\n+        p => p >= lowerBound\n+      }\n+      else {\n+        p => p == lowerBound\n+      }\n+    } else {\n+      val upperBound = upperRange.get.toInt\n+      val lowerBound = lowerRange.get.toInt\n+      p => p >= lowerBound && p < upperBound\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA1NDQ5Mw=="}, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 260}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTY0Njc0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0Mjo0MlrOIhjfww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0xMFQxMTo0MzoyOVrOIjFg-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA1NTQ5MQ==", "bodyText": "Not related to your changes but it seems that we never close the consumer. It would be great if we could do it.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572055491", "createdAt": "2021-02-08T13:42:42Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,131 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val topicPartitionPattern = Pattern.compile( \"([^:,]*)(?::([0-9]*)(?:-([0-9]*))?)?\")\n \n   def main(args: Array[String]): Unit = {\n+    try {\n+      fetchOffsets(args)\n+    } catch {\n+      case e: Exception => Exit.exit(1, Some(e.getMessage))\n+    }\n+  }\n+\n+  private def fetchOffsets(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionsOpt = parser.accepts(\"topic-partitions\", s\"Comma separated list of topic-partition patterns to get the offsets for, with the format of '$topicPartitionPattern'.\" +\n+                                            \" The first group is an optional regex for the topic name, if omitted, it matches any topic name.\" +\n+                                            \" The section after ':' describes a 'partition' pattern, which can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic1:1,topic2:0-3,topic3,topic4:5-,topic5:-3\")\n+                           .ofType(classOf[String])\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"topic\")\n                            .ofType(classOf[String])\n-    val partitionOpt = parser.accepts(\"partitions\", \"comma separated list of partition ids. If not specified, it will find offsets for all partitions\")\n+    val partitionsOpt = parser.accepts(\"partitions\", s\"Comma separated list of partition ids to get the offsets for. If not present, all partitions of the authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"partition ids\")\n                            .ofType(classOf[String])\n-                           .defaultsTo(\"\")\n-    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently commited record timestamp is given.]\")\n+    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently committed record timestamp is given.]\")\n                            .withRequiredArg\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Property file containing configs to be passed to Consumer Client.\")\n                            .withRequiredArg\n-                           .describedAs(\"ms\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1000)\n+                           .describedAs(\"config file\")\n+                           .ofType(classOf[String])\n+    val excludeInternalTopicsOpt = parser.accepts(\"exclude-internal-topics\", s\"By default, internal topics are included. If specified, internal topics are excluded.\")\n \n-   if (args.length == 0)\n-      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic offsets.\")\n+    if (args.length == 0)\n+      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic-partition offsets.\")\n \n     val options = parser.parse(args : _*)\n \n-    CommandLineUtils.checkRequiredArgs(parser, options, brokerListOpt, topicOpt)\n+    val effectiveBrokerListOpt = if (options.has(bootstrapServerOpt))\n+      bootstrapServerOpt\n+    else\n+      brokerListOpt\n+\n+    CommandLineUtils.checkRequiredArgs(parser, options, effectiveBrokerListOpt)\n \n     val clientId = \"GetOffsetShell\"\n-    val brokerList = options.valueOf(brokerListOpt)\n+    val brokerList = options.valueOf(effectiveBrokerListOpt)\n+\n     ToolsUtils.validatePortOrDie(parser, brokerList)\n-    val topic = options.valueOf(topicOpt)\n-    val partitionIdsRequested: Set[Int] = {\n-      val partitionsString = options.valueOf(partitionOpt)\n-      if (partitionsString.isEmpty)\n-        Set.empty\n-      else\n-        partitionsString.split(\",\").map { partitionString =>\n-          try partitionString.toInt\n-          catch {\n-            case _: NumberFormatException =>\n-              System.err.println(s\"--partitions expects a comma separated list of numeric partition ids, but received: $partitionsString\")\n-              Exit.exit(1)\n-          }\n-        }.toSet\n+    val excludeInternalTopics = options.has(excludeInternalTopicsOpt)\n+\n+    if (options.has(topicPartitionsOpt) && (options.has(topicOpt) || options.has(partitionsOpt))) {\n+      throw new IllegalArgumentException(\"--topic-partitions cannot be used with --topic or --partitions\")\n     }\n+\n     val listOffsetsTimestamp = options.valueOf(timeOpt).longValue\n \n-    val config = new Properties\n+    val topicPartitionFilter = if (options.has(topicPartitionsOpt)) {\n+      createTopicPartitionFilterWithPatternList(options.valueOf(topicPartitionsOpt), excludeInternalTopics)\n+    } else {\n+      val partitionIdsRequested: Set[Int] = {\n+        val partitionsString = options.valueOf(partitionsOpt)\n+        if (partitionsString == null || partitionsString.isEmpty)\n+          Set.empty\n+        else\n+          partitionsString.split(\",\").map { partitionString =>\n+            try partitionString.toInt\n+            catch {\n+              case _: NumberFormatException =>\n+                throw new IllegalArgumentException(s\"--partitions expects a comma separated list of numeric \" +\n+                  s\"partition ids, but received: $partitionsString\")\n+            }\n+          }.toSet\n+      }\n+\n+      createTopicPartitionFilterWithTopicAndPartitionPattern(\n+        if (options.has(topicOpt)) Some(options.valueOf(topicOpt)) else None,\n+        excludeInternalTopics,\n+        partitionIdsRequested\n+      )\n+    }\n+\n+    val config = if (options.has(commandConfigOpt))\n+      Utils.loadProps(options.valueOf(commandConfigOpt))\n+    else\n+      new Properties\n     config.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n     config.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId)\n     val consumer = new KafkaConsumer(config, new ByteArrayDeserializer, new ByteArrayDeserializer)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzIwMTQ3MA==", "bodyText": "Could we address this one as well? We could add a try/finally.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r573201470", "createdAt": "2021-02-09T20:08:27Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,131 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val topicPartitionPattern = Pattern.compile( \"([^:,]*)(?::([0-9]*)(?:-([0-9]*))?)?\")\n \n   def main(args: Array[String]): Unit = {\n+    try {\n+      fetchOffsets(args)\n+    } catch {\n+      case e: Exception => Exit.exit(1, Some(e.getMessage))\n+    }\n+  }\n+\n+  private def fetchOffsets(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionsOpt = parser.accepts(\"topic-partitions\", s\"Comma separated list of topic-partition patterns to get the offsets for, with the format of '$topicPartitionPattern'.\" +\n+                                            \" The first group is an optional regex for the topic name, if omitted, it matches any topic name.\" +\n+                                            \" The section after ':' describes a 'partition' pattern, which can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic1:1,topic2:0-3,topic3,topic4:5-,topic5:-3\")\n+                           .ofType(classOf[String])\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"topic\")\n                            .ofType(classOf[String])\n-    val partitionOpt = parser.accepts(\"partitions\", \"comma separated list of partition ids. If not specified, it will find offsets for all partitions\")\n+    val partitionsOpt = parser.accepts(\"partitions\", s\"Comma separated list of partition ids to get the offsets for. If not present, all partitions of the authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"partition ids\")\n                            .ofType(classOf[String])\n-                           .defaultsTo(\"\")\n-    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently commited record timestamp is given.]\")\n+    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently committed record timestamp is given.]\")\n                            .withRequiredArg\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Property file containing configs to be passed to Consumer Client.\")\n                            .withRequiredArg\n-                           .describedAs(\"ms\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1000)\n+                           .describedAs(\"config file\")\n+                           .ofType(classOf[String])\n+    val excludeInternalTopicsOpt = parser.accepts(\"exclude-internal-topics\", s\"By default, internal topics are included. If specified, internal topics are excluded.\")\n \n-   if (args.length == 0)\n-      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic offsets.\")\n+    if (args.length == 0)\n+      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic-partition offsets.\")\n \n     val options = parser.parse(args : _*)\n \n-    CommandLineUtils.checkRequiredArgs(parser, options, brokerListOpt, topicOpt)\n+    val effectiveBrokerListOpt = if (options.has(bootstrapServerOpt))\n+      bootstrapServerOpt\n+    else\n+      brokerListOpt\n+\n+    CommandLineUtils.checkRequiredArgs(parser, options, effectiveBrokerListOpt)\n \n     val clientId = \"GetOffsetShell\"\n-    val brokerList = options.valueOf(brokerListOpt)\n+    val brokerList = options.valueOf(effectiveBrokerListOpt)\n+\n     ToolsUtils.validatePortOrDie(parser, brokerList)\n-    val topic = options.valueOf(topicOpt)\n-    val partitionIdsRequested: Set[Int] = {\n-      val partitionsString = options.valueOf(partitionOpt)\n-      if (partitionsString.isEmpty)\n-        Set.empty\n-      else\n-        partitionsString.split(\",\").map { partitionString =>\n-          try partitionString.toInt\n-          catch {\n-            case _: NumberFormatException =>\n-              System.err.println(s\"--partitions expects a comma separated list of numeric partition ids, but received: $partitionsString\")\n-              Exit.exit(1)\n-          }\n-        }.toSet\n+    val excludeInternalTopics = options.has(excludeInternalTopicsOpt)\n+\n+    if (options.has(topicPartitionsOpt) && (options.has(topicOpt) || options.has(partitionsOpt))) {\n+      throw new IllegalArgumentException(\"--topic-partitions cannot be used with --topic or --partitions\")\n     }\n+\n     val listOffsetsTimestamp = options.valueOf(timeOpt).longValue\n \n-    val config = new Properties\n+    val topicPartitionFilter = if (options.has(topicPartitionsOpt)) {\n+      createTopicPartitionFilterWithPatternList(options.valueOf(topicPartitionsOpt), excludeInternalTopics)\n+    } else {\n+      val partitionIdsRequested: Set[Int] = {\n+        val partitionsString = options.valueOf(partitionsOpt)\n+        if (partitionsString == null || partitionsString.isEmpty)\n+          Set.empty\n+        else\n+          partitionsString.split(\",\").map { partitionString =>\n+            try partitionString.toInt\n+            catch {\n+              case _: NumberFormatException =>\n+                throw new IllegalArgumentException(s\"--partitions expects a comma separated list of numeric \" +\n+                  s\"partition ids, but received: $partitionsString\")\n+            }\n+          }.toSet\n+      }\n+\n+      createTopicPartitionFilterWithTopicAndPartitionPattern(\n+        if (options.has(topicOpt)) Some(options.valueOf(topicOpt)) else None,\n+        excludeInternalTopics,\n+        partitionIdsRequested\n+      )\n+    }\n+\n+    val config = if (options.has(commandConfigOpt))\n+      Utils.loadProps(options.valueOf(commandConfigOpt))\n+    else\n+      new Properties\n     config.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n     config.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId)\n     val consumer = new KafkaConsumer(config, new ByteArrayDeserializer, new ByteArrayDeserializer)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA1NTQ5MQ=="}, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzY2MTQzMg==", "bodyText": "Sorry, missed this one, fixed it", "url": "https://github.com/apache/kafka/pull/9430#discussion_r573661432", "createdAt": "2021-02-10T11:43:29Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,131 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val topicPartitionPattern = Pattern.compile( \"([^:,]*)(?::([0-9]*)(?:-([0-9]*))?)?\")\n \n   def main(args: Array[String]): Unit = {\n+    try {\n+      fetchOffsets(args)\n+    } catch {\n+      case e: Exception => Exit.exit(1, Some(e.getMessage))\n+    }\n+  }\n+\n+  private def fetchOffsets(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionsOpt = parser.accepts(\"topic-partitions\", s\"Comma separated list of topic-partition patterns to get the offsets for, with the format of '$topicPartitionPattern'.\" +\n+                                            \" The first group is an optional regex for the topic name, if omitted, it matches any topic name.\" +\n+                                            \" The section after ':' describes a 'partition' pattern, which can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic1:1,topic2:0-3,topic3,topic4:5-,topic5:-3\")\n+                           .ofType(classOf[String])\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"topic\")\n                            .ofType(classOf[String])\n-    val partitionOpt = parser.accepts(\"partitions\", \"comma separated list of partition ids. If not specified, it will find offsets for all partitions\")\n+    val partitionsOpt = parser.accepts(\"partitions\", s\"Comma separated list of partition ids to get the offsets for. If not present, all partitions of the authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"partition ids\")\n                            .ofType(classOf[String])\n-                           .defaultsTo(\"\")\n-    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently commited record timestamp is given.]\")\n+    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently committed record timestamp is given.]\")\n                            .withRequiredArg\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Property file containing configs to be passed to Consumer Client.\")\n                            .withRequiredArg\n-                           .describedAs(\"ms\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1000)\n+                           .describedAs(\"config file\")\n+                           .ofType(classOf[String])\n+    val excludeInternalTopicsOpt = parser.accepts(\"exclude-internal-topics\", s\"By default, internal topics are included. If specified, internal topics are excluded.\")\n \n-   if (args.length == 0)\n-      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic offsets.\")\n+    if (args.length == 0)\n+      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic-partition offsets.\")\n \n     val options = parser.parse(args : _*)\n \n-    CommandLineUtils.checkRequiredArgs(parser, options, brokerListOpt, topicOpt)\n+    val effectiveBrokerListOpt = if (options.has(bootstrapServerOpt))\n+      bootstrapServerOpt\n+    else\n+      brokerListOpt\n+\n+    CommandLineUtils.checkRequiredArgs(parser, options, effectiveBrokerListOpt)\n \n     val clientId = \"GetOffsetShell\"\n-    val brokerList = options.valueOf(brokerListOpt)\n+    val brokerList = options.valueOf(effectiveBrokerListOpt)\n+\n     ToolsUtils.validatePortOrDie(parser, brokerList)\n-    val topic = options.valueOf(topicOpt)\n-    val partitionIdsRequested: Set[Int] = {\n-      val partitionsString = options.valueOf(partitionOpt)\n-      if (partitionsString.isEmpty)\n-        Set.empty\n-      else\n-        partitionsString.split(\",\").map { partitionString =>\n-          try partitionString.toInt\n-          catch {\n-            case _: NumberFormatException =>\n-              System.err.println(s\"--partitions expects a comma separated list of numeric partition ids, but received: $partitionsString\")\n-              Exit.exit(1)\n-          }\n-        }.toSet\n+    val excludeInternalTopics = options.has(excludeInternalTopicsOpt)\n+\n+    if (options.has(topicPartitionsOpt) && (options.has(topicOpt) || options.has(partitionsOpt))) {\n+      throw new IllegalArgumentException(\"--topic-partitions cannot be used with --topic or --partitions\")\n     }\n+\n     val listOffsetsTimestamp = options.valueOf(timeOpt).longValue\n \n-    val config = new Properties\n+    val topicPartitionFilter = if (options.has(topicPartitionsOpt)) {\n+      createTopicPartitionFilterWithPatternList(options.valueOf(topicPartitionsOpt), excludeInternalTopics)\n+    } else {\n+      val partitionIdsRequested: Set[Int] = {\n+        val partitionsString = options.valueOf(partitionsOpt)\n+        if (partitionsString == null || partitionsString.isEmpty)\n+          Set.empty\n+        else\n+          partitionsString.split(\",\").map { partitionString =>\n+            try partitionString.toInt\n+            catch {\n+              case _: NumberFormatException =>\n+                throw new IllegalArgumentException(s\"--partitions expects a comma separated list of numeric \" +\n+                  s\"partition ids, but received: $partitionsString\")\n+            }\n+          }.toSet\n+      }\n+\n+      createTopicPartitionFilterWithTopicAndPartitionPattern(\n+        if (options.has(topicOpt)) Some(options.valueOf(topicOpt)) else None,\n+        excludeInternalTopics,\n+        partitionIdsRequested\n+      )\n+    }\n+\n+    val config = if (options.has(commandConfigOpt))\n+      Utils.loadProps(options.valueOf(commandConfigOpt))\n+    else\n+      new Properties\n     config.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList)\n     config.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId)\n     val consumer = new KafkaConsumer(config, new ByteArrayDeserializer, new ByteArrayDeserializer)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA1NTQ5MQ=="}, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 153}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTY1MzIzOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0NDoxMlrOIhjjrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0NDoxMlrOIhjjrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA1NjQ5NQ==", "bodyText": "nit: We tend to use parenthesis instead of curly braces when the lambda is on a single line.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572056495", "createdAt": "2021-02-08T13:44:12Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 219}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTY1ODA2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0NToyMFrOIhjmog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0NToyMFrOIhjmog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA1NzI1MA==", "bodyText": "The null instead of the None is quite subtile. I did not see it at first. See my comment which suggest to push more to the regex.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572057250", "createdAt": "2021-02-08T13:45:20Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }\n+    tp => rules.exists(rule => rule.apply(tp))\n   }\n \n+  def parseRuleSpec(ruleSpec: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    def wrapNullOrEmpty(s: String): Option[String] = {\n+      if (s == null || s.isEmpty)\n+        None\n+      else\n+        Some(s)\n+    }\n+\n+    val matcher = topicPartitionPattern.matcher(ruleSpec)\n+    if (!matcher.matches() || matcher.groupCount() == 0)\n+      throw new IllegalArgumentException(s\"Invalid rule specification: $ruleSpec\")\n+\n+    val topicPattern = wrapNullOrEmpty(matcher.group(1))\n+    val lowerRange = if (matcher.groupCount() >= 2) wrapNullOrEmpty(matcher.group(2)) else None\n+    val upperRangeSection = if (matcher.groupCount() >= 3) matcher.group(3) else null", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 237}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTY2MjYxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0NjoxMlrOIhjpXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0NjoxMlrOIhjpXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA1Nzk0OA==", "bodyText": "nit: The parenthesis after topic and partition could be omitted. It seems that we could call partitionFilter directly without the apply.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572057948", "createdAt": "2021-02-08T13:46:12Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }\n+    tp => rules.exists(rule => rule.apply(tp))\n   }\n \n+  def parseRuleSpec(ruleSpec: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    def wrapNullOrEmpty(s: String): Option[String] = {\n+      if (s == null || s.isEmpty)\n+        None\n+      else\n+        Some(s)\n+    }\n+\n+    val matcher = topicPartitionPattern.matcher(ruleSpec)\n+    if (!matcher.matches() || matcher.groupCount() == 0)\n+      throw new IllegalArgumentException(s\"Invalid rule specification: $ruleSpec\")\n+\n+    val topicPattern = wrapNullOrEmpty(matcher.group(1))\n+    val lowerRange = if (matcher.groupCount() >= 2) wrapNullOrEmpty(matcher.group(2)) else None\n+    val upperRangeSection = if (matcher.groupCount() >= 3) matcher.group(3) else null\n+    val upperRange = wrapNullOrEmpty(upperRangeSection)\n+    val isRange = upperRangeSection != null\n+\n+    val includeList = IncludeList(topicPattern.getOrElse(\".*\"))\n+\n+    val partitionFilter: Int => Boolean = if (lowerRange.isEmpty && upperRange.isEmpty) {\n+      _ => true\n+    } else if (lowerRange.isEmpty) {\n+      val upperBound = upperRange.get.toInt\n+      p => p < upperBound\n+    } else if (upperRange.isEmpty) {\n+      val lowerBound = lowerRange.get.toInt\n+      if (isRange) {\n+        p => p >= lowerBound\n+      }\n+      else {\n+        p => p == lowerBound\n+      }\n+    } else {\n+      val upperBound = upperRange.get.toInt\n+      val lowerBound = lowerRange.get.toInt\n+      p => p >= lowerBound && p < upperBound\n+    }\n+\n+    tp => includeList.isTopicAllowed(tp.topic(), excludeInternalTopics) && partitionFilter.apply(tp.partition())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 262}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTY2ODA0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0NzoyMFrOIhjsmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo0NzoyMFrOIhjsmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA1ODc3Nw==", "bodyText": "nit: We should use parenthesis here instead of curly braces. filter(topicPartitionFilter) might even work directly as well.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572058777", "createdAt": "2021-02-08T13:47:20Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +161,85 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n-    else\n-      Some(partitionInfos.filter(p => partitionIds.contains(p.partition)))\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }\n+    tp => rules.exists(rule => rule.apply(tp))\n   }\n \n+  def parseRuleSpec(ruleSpec: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    def wrapNullOrEmpty(s: String): Option[String] = {\n+      if (s == null || s.isEmpty)\n+        None\n+      else\n+        Some(s)\n+    }\n+\n+    val matcher = topicPartitionPattern.matcher(ruleSpec)\n+    if (!matcher.matches() || matcher.groupCount() == 0)\n+      throw new IllegalArgumentException(s\"Invalid rule specification: $ruleSpec\")\n+\n+    val topicPattern = wrapNullOrEmpty(matcher.group(1))\n+    val lowerRange = if (matcher.groupCount() >= 2) wrapNullOrEmpty(matcher.group(2)) else None\n+    val upperRangeSection = if (matcher.groupCount() >= 3) matcher.group(3) else null\n+    val upperRange = wrapNullOrEmpty(upperRangeSection)\n+    val isRange = upperRangeSection != null\n+\n+    val includeList = IncludeList(topicPattern.getOrElse(\".*\"))\n+\n+    val partitionFilter: Int => Boolean = if (lowerRange.isEmpty && upperRange.isEmpty) {\n+      _ => true\n+    } else if (lowerRange.isEmpty) {\n+      val upperBound = upperRange.get.toInt\n+      p => p < upperBound\n+    } else if (upperRange.isEmpty) {\n+      val lowerBound = lowerRange.get.toInt\n+      if (isRange) {\n+        p => p >= lowerBound\n+      }\n+      else {\n+        p => p == lowerBound\n+      }\n+    } else {\n+      val upperBound = upperRange.get.toInt\n+      val lowerBound = lowerRange.get.toInt\n+      p => p >= lowerBound && p < upperBound\n+    }\n+\n+    tp => includeList.isTopicAllowed(tp.topic(), excludeInternalTopics) && partitionFilter.apply(tp.partition())\n+  }\n+\n+  /**\n+   * Creates a topic-partition filter based on a topic pattern and a set of partition ids.\n+   */\n+  def createTopicPartitionFilterWithTopicAndPartitionPattern(topicOpt: Option[String], excludeInternalTopics: Boolean, partitionIds: Set[Int]): PartitionInfo => Boolean = {\n+    val topicsFilter = IncludeList(topicOpt.getOrElse(\".*\"))\n+    t => topicsFilter.isTopicAllowed(t.topic, excludeInternalTopics) && (partitionIds.isEmpty || partitionIds.contains(t.partition))\n+  }\n+\n+  /**\n+   * Return the partition infos. Filter them with topicPartitionFilter.\n+   */\n+  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topicPartitionFilter: PartitionInfo => Boolean): Seq[PartitionInfo] = {\n+    consumer.listTopics.asScala.values.flatMap { partitions =>\n+      partitions.asScala.filter { tp => topicPartitionFilter.apply(tp) }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 278}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTY5MDkwOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo1MjoyN1rOIhj6dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo1MjoyN1rOIhj6dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA2MjMyNw==", "bodyText": "nit: We usually capitalize the first letter of constant in Scala.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572062327", "createdAt": "2021-02-08T13:52:27Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,131 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val topicPartitionPattern = Pattern.compile( \"([^:,]*)(?::([0-9]*)(?:-([0-9]*))?)?\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYwNTcwMjk3OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxMzo1NToxOVrOIhkCIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQwODoxNDoxOVrOIiJLPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA2NDI4OQ==", "bodyText": "nit: Should we consider moving this block in an method?", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572064289", "createdAt": "2021-02-08T13:55:19Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,131 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val topicPartitionPattern = Pattern.compile( \"([^:,]*)(?::([0-9]*)(?:-([0-9]*))?)?\")\n \n   def main(args: Array[String]): Unit = {\n+    try {\n+      fetchOffsets(args)\n+    } catch {\n+      case e: Exception => Exit.exit(1, Some(e.getMessage))\n+    }\n+  }\n+\n+  private def fetchOffsets(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionsOpt = parser.accepts(\"topic-partitions\", s\"Comma separated list of topic-partition patterns to get the offsets for, with the format of '$topicPartitionPattern'.\" +\n+                                            \" The first group is an optional regex for the topic name, if omitted, it matches any topic name.\" +\n+                                            \" The section after ':' describes a 'partition' pattern, which can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic1:1,topic2:0-3,topic3,topic4:5-,topic5:-3\")\n+                           .ofType(classOf[String])\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"topic\")\n                            .ofType(classOf[String])\n-    val partitionOpt = parser.accepts(\"partitions\", \"comma separated list of partition ids. If not specified, it will find offsets for all partitions\")\n+    val partitionsOpt = parser.accepts(\"partitions\", s\"Comma separated list of partition ids to get the offsets for. If not present, all partitions of the authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"partition ids\")\n                            .ofType(classOf[String])\n-                           .defaultsTo(\"\")\n-    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently commited record timestamp is given.]\")\n+    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently committed record timestamp is given.]\")\n                            .withRequiredArg\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Property file containing configs to be passed to Consumer Client.\")\n                            .withRequiredArg\n-                           .describedAs(\"ms\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1000)\n+                           .describedAs(\"config file\")\n+                           .ofType(classOf[String])\n+    val excludeInternalTopicsOpt = parser.accepts(\"exclude-internal-topics\", s\"By default, internal topics are included. If specified, internal topics are excluded.\")\n \n-   if (args.length == 0)\n-      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic offsets.\")\n+    if (args.length == 0)\n+      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic-partition offsets.\")\n \n     val options = parser.parse(args : _*)\n \n-    CommandLineUtils.checkRequiredArgs(parser, options, brokerListOpt, topicOpt)\n+    val effectiveBrokerListOpt = if (options.has(bootstrapServerOpt))\n+      bootstrapServerOpt\n+    else\n+      brokerListOpt\n+\n+    CommandLineUtils.checkRequiredArgs(parser, options, effectiveBrokerListOpt)\n \n     val clientId = \"GetOffsetShell\"\n-    val brokerList = options.valueOf(brokerListOpt)\n+    val brokerList = options.valueOf(effectiveBrokerListOpt)\n+\n     ToolsUtils.validatePortOrDie(parser, brokerList)\n-    val topic = options.valueOf(topicOpt)\n-    val partitionIdsRequested: Set[Int] = {\n-      val partitionsString = options.valueOf(partitionOpt)\n-      if (partitionsString.isEmpty)\n-        Set.empty\n-      else\n-        partitionsString.split(\",\").map { partitionString =>\n-          try partitionString.toInt\n-          catch {\n-            case _: NumberFormatException =>\n-              System.err.println(s\"--partitions expects a comma separated list of numeric partition ids, but received: $partitionsString\")\n-              Exit.exit(1)\n-          }\n-        }.toSet\n+    val excludeInternalTopics = options.has(excludeInternalTopicsOpt)\n+\n+    if (options.has(topicPartitionsOpt) && (options.has(topicOpt) || options.has(partitionsOpt))) {\n+      throw new IllegalArgumentException(\"--topic-partitions cannot be used with --topic or --partitions\")\n     }\n+\n     val listOffsetsTimestamp = options.valueOf(timeOpt).longValue\n \n-    val config = new Properties\n+    val topicPartitionFilter = if (options.has(topicPartitionsOpt)) {\n+      createTopicPartitionFilterWithPatternList(options.valueOf(topicPartitionsOpt), excludeInternalTopics)\n+    } else {\n+      val partitionIdsRequested: Set[Int] = {\n+        val partitionsString = options.valueOf(partitionsOpt)\n+        if (partitionsString == null || partitionsString.isEmpty)\n+          Set.empty\n+        else\n+          partitionsString.split(\",\").map { partitionString =>\n+            try partitionString.toInt\n+            catch {\n+              case _: NumberFormatException =>\n+                throw new IllegalArgumentException(s\"--partitions expects a comma separated list of numeric \" +\n+                  s\"partition ids, but received: $partitionsString\")\n+            }\n+          }.toSet", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjY3MjgzMQ==", "bodyText": "I agree, more readable", "url": "https://github.com/apache/kafka/pull/9430#discussion_r572672831", "createdAt": "2021-02-09T08:14:19Z", "author": {"login": "urbandan"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,131 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val topicPartitionPattern = Pattern.compile( \"([^:,]*)(?::([0-9]*)(?:-([0-9]*))?)?\")\n \n   def main(args: Array[String]): Unit = {\n+    try {\n+      fetchOffsets(args)\n+    } catch {\n+      case e: Exception => Exit.exit(1, Some(e.getMessage))\n+    }\n+  }\n+\n+  private def fetchOffsets(args: Array[String]): Unit = {\n     val parser = new OptionParser(false)\n-    val brokerListOpt = parser.accepts(\"broker-list\", \"REQUIRED: The list of hostname and port of the server to connect to.\")\n+    val brokerListOpt = parser.accepts(\"broker-list\", \"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n                            .withRequiredArg\n-                           .describedAs(\"hostname:port,...,hostname:port\")\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n                            .ofType(classOf[String])\n-    val topicOpt = parser.accepts(\"topic\", \"REQUIRED: The topic to get offset from.\")\n+    val bootstrapServerOpt = parser.accepts(\"bootstrap-server\", \"REQUIRED. The server(s) to connect to in the form HOST1:PORT1,HOST2:PORT2.\")\n+                           .requiredUnless(\"broker-list\")\n+                           .withRequiredArg\n+                           .describedAs(\"HOST1:PORT1,...,HOST3:PORT3\")\n+                           .ofType(classOf[String])\n+    val topicPartitionsOpt = parser.accepts(\"topic-partitions\", s\"Comma separated list of topic-partition patterns to get the offsets for, with the format of '$topicPartitionPattern'.\" +\n+                                            \" The first group is an optional regex for the topic name, if omitted, it matches any topic name.\" +\n+                                            \" The section after ':' describes a 'partition' pattern, which can be: a number, a range in the format of 'NUMBER-NUMBER' (lower inclusive, upper exclusive), an inclusive lower bound in the format of 'NUMBER-', an exclusive upper bound in the format of '-NUMBER' or may be omitted to accept all partitions.\")\n+                           .withRequiredArg\n+                           .describedAs(\"topic1:1,topic2:0-3,topic3,topic4:5-,topic5:-3\")\n+                           .ofType(classOf[String])\n+    val topicOpt = parser.accepts(\"topic\", s\"The topic to get the offsets for. It also accepts a regular expression. If not present, all authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"topic\")\n                            .ofType(classOf[String])\n-    val partitionOpt = parser.accepts(\"partitions\", \"comma separated list of partition ids. If not specified, it will find offsets for all partitions\")\n+    val partitionsOpt = parser.accepts(\"partitions\", s\"Comma separated list of partition ids to get the offsets for. If not present, all partitions of the authorized topics are queried. Cannot be used if --topic-partitions is present.\")\n                            .withRequiredArg\n                            .describedAs(\"partition ids\")\n                            .ofType(classOf[String])\n-                           .defaultsTo(\"\")\n-    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently commited record timestamp is given.]\")\n+    val timeOpt = parser.accepts(\"time\", \"timestamp of the offsets before that. [Note: No offset is returned, if the timestamp greater than recently committed record timestamp is given.]\")\n                            .withRequiredArg\n                            .describedAs(\"timestamp/-1(latest)/-2(earliest)\")\n                            .ofType(classOf[java.lang.Long])\n                            .defaultsTo(-1L)\n-    parser.accepts(\"offsets\", \"DEPRECATED AND IGNORED: number of offsets returned\")\n-                           .withRequiredArg\n-                           .describedAs(\"count\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1)\n-    parser.accepts(\"max-wait-ms\", \"DEPRECATED AND IGNORED: The max amount of time each fetch request waits.\")\n+    val commandConfigOpt = parser.accepts(\"command-config\", s\"Property file containing configs to be passed to Consumer Client.\")\n                            .withRequiredArg\n-                           .describedAs(\"ms\")\n-                           .ofType(classOf[java.lang.Integer])\n-                           .defaultsTo(1000)\n+                           .describedAs(\"config file\")\n+                           .ofType(classOf[String])\n+    val excludeInternalTopicsOpt = parser.accepts(\"exclude-internal-topics\", s\"By default, internal topics are included. If specified, internal topics are excluded.\")\n \n-   if (args.length == 0)\n-      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic offsets.\")\n+    if (args.length == 0)\n+      CommandLineUtils.printUsageAndDie(parser, \"An interactive shell for getting topic-partition offsets.\")\n \n     val options = parser.parse(args : _*)\n \n-    CommandLineUtils.checkRequiredArgs(parser, options, brokerListOpt, topicOpt)\n+    val effectiveBrokerListOpt = if (options.has(bootstrapServerOpt))\n+      bootstrapServerOpt\n+    else\n+      brokerListOpt\n+\n+    CommandLineUtils.checkRequiredArgs(parser, options, effectiveBrokerListOpt)\n \n     val clientId = \"GetOffsetShell\"\n-    val brokerList = options.valueOf(brokerListOpt)\n+    val brokerList = options.valueOf(effectiveBrokerListOpt)\n+\n     ToolsUtils.validatePortOrDie(parser, brokerList)\n-    val topic = options.valueOf(topicOpt)\n-    val partitionIdsRequested: Set[Int] = {\n-      val partitionsString = options.valueOf(partitionOpt)\n-      if (partitionsString.isEmpty)\n-        Set.empty\n-      else\n-        partitionsString.split(\",\").map { partitionString =>\n-          try partitionString.toInt\n-          catch {\n-            case _: NumberFormatException =>\n-              System.err.println(s\"--partitions expects a comma separated list of numeric partition ids, but received: $partitionsString\")\n-              Exit.exit(1)\n-          }\n-        }.toSet\n+    val excludeInternalTopics = options.has(excludeInternalTopicsOpt)\n+\n+    if (options.has(topicPartitionsOpt) && (options.has(topicOpt) || options.has(partitionsOpt))) {\n+      throw new IllegalArgumentException(\"--topic-partitions cannot be used with --topic or --partitions\")\n     }\n+\n     val listOffsetsTimestamp = options.valueOf(timeOpt).longValue\n \n-    val config = new Properties\n+    val topicPartitionFilter = if (options.has(topicPartitionsOpt)) {\n+      createTopicPartitionFilterWithPatternList(options.valueOf(topicPartitionsOpt), excludeInternalTopics)\n+    } else {\n+      val partitionIdsRequested: Set[Int] = {\n+        val partitionsString = options.valueOf(partitionsOpt)\n+        if (partitionsString == null || partitionsString.isEmpty)\n+          Set.empty\n+        else\n+          partitionsString.split(\",\").map { partitionString =>\n+            try partitionString.toInt\n+            catch {\n+              case _: NumberFormatException =>\n+                throw new IllegalArgumentException(s\"--partitions expects a comma separated list of numeric \" +\n+                  s\"partition ids, but received: $partitionsString\")\n+            }\n+          }.toSet", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjA2NDI4OQ=="}, "originalCommit": {"oid": "2b1cc08f973759074521bdbeeabc626e283fdd77"}, "originalPosition": 137}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYxMzAzNTQ0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo0NzoyNFrOIiopQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo0NzoyNFrOIiopQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzE4ODQxNw==", "bodyText": "nit: The space before \" could be removed.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r573188417", "createdAt": "2021-02-09T19:47:24Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,120 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val TopicPartitionPattern = Pattern.compile( \"([^:,]*)(?::(?:([0-9]*)|(?:([0-9]*)-([0-9]*))))?\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e69e1dc50566e19afd9a62b47976552a5c6f9d5"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYxMzA2MzM2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo1NDo0NFrOIio6sQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo1NDo0NFrOIio6sQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzE5Mjg4MQ==", "bodyText": "We could use println here to be consistent with the other command line tools. Moreover, you need to use curly braces around e.getMessage: s\"Error: ${e.getMessage}\".", "url": "https://github.com/apache/kafka/pull/9430#discussion_r573192881", "createdAt": "2021-02-09T19:54:44Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -20,102 +20,120 @@ package kafka.tools\n \n import java.util.Properties\n import joptsimple._\n-import kafka.utils.{CommandLineUtils, Exit, ToolsUtils}\n+import kafka.utils.{CommandLineUtils, Exit, IncludeList, ToolsUtils}\n import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer}\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n import org.apache.kafka.common.serialization.ByteArrayDeserializer\n+import org.apache.kafka.common.utils.Utils\n \n+import java.util.regex.Pattern\n import scala.jdk.CollectionConverters._\n import scala.collection.Seq\n+import scala.math.Ordering.Implicits.infixOrderingOps\n \n object GetOffsetShell {\n+  private val TopicPartitionPattern = Pattern.compile( \"([^:,]*)(?::(?:([0-9]*)|(?:([0-9]*)-([0-9]*))))?\")\n \n   def main(args: Array[String]): Unit = {\n+    try {\n+      fetchOffsets(args)\n+    } catch {\n+      case e: Exception =>\n+        System.err.println(s\"Error occurred: $e.getMessage\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e69e1dc50566e19afd9a62b47976552a5c6f9d5"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYxMzA4MDczOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo1ODo0NFrOIipFFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo1ODo0NFrOIipFFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzE5NTU0Mw==", "bodyText": ".map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) } => .map(ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics)) - We usually don't use curly braces when the lambda is on one line.", "url": "https://github.com/apache/kafka/pull/9430#discussion_r573195543", "createdAt": "2021-02-09T19:58:44Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +150,79 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e69e1dc50566e19afd9a62b47976552a5c6f9d5"}, "originalPosition": 206}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzYxMzA4MjM5OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo1OTowNlrOIipGGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQxOTo1OTowNlrOIipGGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzE5NTgwMQ==", "bodyText": "tp.partition() => tp.partition", "url": "https://github.com/apache/kafka/pull/9430#discussion_r573195801", "createdAt": "2021-02-09T19:59:06Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/GetOffsetShell.scala", "diffHunk": "@@ -132,23 +150,79 @@ object GetOffsetShell {\n         }\n     }\n \n-    partitionOffsets.toArray.sortBy { case (tp, _) => tp.partition }.foreach { case (tp, offset) =>\n-      println(s\"$topic:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n+    partitionOffsets.toSeq.sortWith((tp1, tp2) => compareTopicPartitions(tp1._1, tp2._1)).foreach {\n+      case (tp, offset) => println(s\"${tp.topic}:${tp.partition}:${Option(offset).getOrElse(\"\")}\")\n     }\n+  }\n \n+  def compareTopicPartitions(a: TopicPartition, b: TopicPartition): Boolean = {\n+    (a.topic(), a.partition()) < (b.topic(), b.partition())\n   }\n \n   /**\n-   * Return the partition infos for `topic`. If the topic does not exist, `None` is returned.\n+   * Creates a topic-partition filter based on a list of patterns.\n+   * Expected format:\n+   * List: TopicPartitionPattern(, TopicPartitionPattern)*\n+   * TopicPartitionPattern: TopicPattern(:PartitionPattern)? | :PartitionPattern\n+   * TopicPattern: REGEX\n+   * PartitionPattern: NUMBER | NUMBER-(NUMBER)? | -NUMBER\n    */\n-  private def listPartitionInfos(consumer: KafkaConsumer[_, _], topic: String, partitionIds: Set[Int]): Option[Seq[PartitionInfo]] = {\n-    val partitionInfos = consumer.listTopics.asScala.filter { case (k, _) => k == topic }.values.flatMap(_.asScala).toBuffer\n-    if (partitionInfos.isEmpty)\n-      None\n-    else if (partitionIds.isEmpty)\n-      Some(partitionInfos)\n+  def createTopicPartitionFilterWithPatternList(topicPartitions: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val ruleSpecs = topicPartitions.split(\",\")\n+    val rules = ruleSpecs.map { ruleSpec => parseRuleSpec(ruleSpec, excludeInternalTopics) }\n+    tp => rules.exists { rule => rule.apply(tp) }\n+  }\n+\n+  def parseRuleSpec(ruleSpec: String, excludeInternalTopics: Boolean): PartitionInfo => Boolean = {\n+    val matcher = TopicPartitionPattern.matcher(ruleSpec)\n+    if (!matcher.matches())\n+      throw new IllegalArgumentException(s\"Invalid rule specification: $ruleSpec\")\n+\n+    def group(group: Int): Option[String] = {\n+      Option(matcher.group(group)).filter(s => s != null && s.nonEmpty)\n+    }\n+\n+    val topicFilter = IncludeList(group(1).getOrElse(\".*\"))\n+    val partitionFilter = group(2).map(_.toInt) match {\n+      case Some(partition) =>\n+        (p: Int) => p == partition\n+      case None =>\n+        val lowerRange = group(3).map(_.toInt).getOrElse(0)\n+        val upperRange = group(4).map(_.toInt).getOrElse(Int.MaxValue)\n+        (p: Int) => p >= lowerRange && p < upperRange\n+    }\n+\n+    tp => topicFilter.isTopicAllowed(tp.topic, excludeInternalTopics) && partitionFilter(tp.partition())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e69e1dc50566e19afd9a62b47976552a5c6f9d5"}, "originalPosition": 229}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1775, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}