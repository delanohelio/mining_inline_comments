{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUwNTc3MjU0", "number": 9032, "reviewThreads": {"totalCount": 53, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjozMzoyMFrOEVMOog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMjowOTo0MFrOEd5s3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjU1OTA2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjozMzoyMFrOG7zxbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjozMzoyMFrOG7zxbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM2NzQwNw==", "bodyText": "It would be good to document here that users that are specified but not  present will be silently omitted from the result", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465367407", "createdAt": "2020-08-04T22:33:20Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -1214,6 +1215,60 @@ default AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlterati\n      */\n     AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlteration> entries, AlterClientQuotasOptions options);\n \n+    /**\n+     * <p>Describe all SASL/SCRAM credentials.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @return The DescribeUserScramCredentialsResult.\n+     */\n+    default DescribeUserScramCredentialsResult describeUserScramCredentials() {\n+        return describeUserScramCredentials(null, new DescribeUserScramCredentialsOptions());\n+    }\n+\n+    /**\n+     * <p>Describe SASL/SCRAM credentials for the given users.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @param users the users for which credentials are to be described; all users' credentials are described if null or empty\n+     * @return The DescribeUserScramCredentialsResult.\n+     */\n+    default DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users) {\n+        return describeUserScramCredentials(users, new DescribeUserScramCredentialsOptions());\n+    }\n+\n+    /**\n+     * <p>Describe SASL/SCRAM credentials.\n+     *\n+     * @param users the users for which credentials are to be described; all users' credentials are described if null or empty", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjU3MzI0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramMechanism.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjozOTo0OVrOG7z5zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjozOTo0OVrOG7z5zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM2OTU1MA==", "bodyText": "Hmm... for consistency with from(byte), shouldn't we return UNKNOWN if we don't know the name?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465369550", "createdAt": "2020-08-04T22:39:49Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramMechanism.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+/**\n+ * Representation of a SASL/SCRAM Mechanism.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public enum ScramMechanism {\n+    UNKNOWN((byte) 0),\n+    SCRAM_SHA_256((byte) 1),\n+    SCRAM_SHA_512((byte) 2);\n+\n+    /**\n+     *\n+     * @param b the byte representation\n+     * @return the instance corresponding to the given byte value, otherwise {@link #UNKNOWN}\n+     */\n+    public static ScramMechanism from(byte b) {\n+        for (ScramMechanism scramMechanism : ScramMechanism.values()) {\n+            if (scramMechanism.type == b) {\n+                return scramMechanism;\n+            }\n+        }\n+        return UNKNOWN;\n+    }\n+\n+    /**\n+     *\n+     * @param mechanismName the SASL SCRAM mechanism name\n+     * @return the corresponding SASL SCRAM mechanism enum\n+     * @see <a href=\"https://tools.ietf.org/html/rfc5802#section-4>\n+     *     Salted Challenge Response Authentication Mechanism (SCRAM) SASL and GSS-API Mechanisms, Section 4</a>\n+     */\n+    public static ScramMechanism fromMechanismName(String mechanismName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjU4MDI2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/AdminManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjo0MjozOVrOG7z92g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjo0MjozOVrOG7z92g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MDU4Ng==", "bodyText": "I'd really prefer some way to just get the value byte out of the ScramMechanism object, rather than relying on the ordering of enum entries.  If we are going to rely on the ordering, that would have to be prominently documented in the class (but let's not....)", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465370586", "createdAt": "2020-08-04T22:42:39Z", "author": {"login": "cmccabe"}, "path": "core/src/main/scala/kafka/server/AdminManager.scala", "diffHunk": "@@ -980,4 +984,137 @@ class AdminManager(val config: KafkaConfig,\n       entry.entity -> apiError\n     }.toMap\n   }\n+\n+  def describeUserScramCredentials(users: Seq[String]): DescribeUserScramCredentialsResponseData = {\n+    val retval = new DescribeUserScramCredentialsResponseData()\n+\n+    def addToResults(user: String, userConfig: Properties) = {\n+      val configKeys = userConfig.stringPropertyNames\n+      val hasScramCredential = !ScramMechanism.values().toList.filter(key => key != ScramMechanism.UNKNOWN && configKeys.contains(key.toMechanismName)).isEmpty\n+      if (hasScramCredential) {\n+        val userScramCredentials = new UserScramCredential().setName(user)\n+        ScramMechanism.values().foreach(mechanism => if (mechanism != ScramMechanism.UNKNOWN) {\n+          val propertyValue = userConfig.getProperty(mechanism.toMechanismName)\n+          if (propertyValue != null) {\n+            val iterations = ScramCredentialUtils.credentialFromString(propertyValue).iterations\n+            userScramCredentials.credentialInfos.add(new CredentialInfo().setMechanism(mechanism.ordinal.toByte).setIterations(iterations))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjYwMzQ0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjo1MjozOFrOG70LjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxOTo0Mzo1MVrOHDWgHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NDA5Mg==", "bodyText": "We should have a defined ApiException and Errors entry for errors like this.  We could maybe use InvalidConfigurationException / INVALID_CONFIG", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465374092", "createdAt": "2020-08-04T22:52:38Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.from(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new IllegalArgumentException(\"Unknown SCRAM mechanism\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc0NDI3MQ==", "bodyText": "How about InvalidRequestException?  It's already used in this class, and it might be more appropriate than InvalidConfigurationException.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465744271", "createdAt": "2020-08-05T13:55:22Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.from(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new IllegalArgumentException(\"Unknown SCRAM mechanism\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NDA5Mg=="}, "originalCommit": null, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQxMDQ4MA==", "bodyText": "I think UnsupportedSaslMechanismException is actually appropriate here -- it already exists and corresponds to Errors.UNSUPPORTED_SASL_MECHANISM.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r469410480", "createdAt": "2020-08-12T17:06:39Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.from(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new IllegalArgumentException(\"Unknown SCRAM mechanism\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NDA5Mg=="}, "originalCommit": null, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI3NjQ0Ng==", "bodyText": "ok", "url": "https://github.com/apache/kafka/pull/9032#discussion_r473276446", "createdAt": "2020-08-19T19:43:51Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.from(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new IllegalArgumentException(\"Unknown SCRAM mechanism\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NDA5Mg=="}, "originalCommit": null, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjYwNzU4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjo1NDozMlrOG70N-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxODoyNzoxNlrOG_tYrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NDcxMw==", "bodyText": "We should have a defined ApiException subclass for this.  NoSuchAlgorithmException could probably be shoehorned into INVALID_CONFIG.  InvalidKeyException probably needs its own defined error code (which we should add to the KIP).\nThis may seem bureaucratic, but think about it this way: maybe we'll want to do this on the broker side eventually.  Then we need a way to serialize, which plain old java exceptions don't have.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465374713", "createdAt": "2020-08-04T22:54:32Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.from(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new IllegalArgumentException(\"Unknown SCRAM mechanism\"));\n+            }\n+        });\n+        // Creating an upsertion may throw InvalidKeyException or NoSuchAlgorithmException,\n+        // so keep track of which users are affected by such a failure and immediately fail all their alterations\n+        final Map<String, Map<ScramMechanism, AlterUserScramCredentialsRequestData.ScramCredentialUpsertion>> userInsertions = new HashMap<>();\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialUpsertion)\n+                .filter(alteration -> !userIllegalAlterationExceptions.containsKey(alteration.getUser()))\n+                .forEach(alteration -> {\n+                    UserScramCredentialUpsertion upsertion = (UserScramCredentialUpsertion) alteration;\n+                    String user = upsertion.getUser();\n+                    try {\n+                        ScramMechanism mechanism = upsertion.getInfo().getMechanism();\n+                        if (mechanism == null || mechanism == ScramMechanism.UNKNOWN)\n+                            throw new IllegalArgumentException(\"Unknown SCRAM mechanism\");\n+                        userInsertions.putIfAbsent(user, new HashMap<>());\n+                        userInsertions.get(user).put(mechanism, getScramCredentialUpsertion(upsertion));\n+                    } catch (Exception e) {\n+                        // we might overwrite aa exception from a previous upsertion, but we don't really care\n+                        // since we just needs to mark this user as having at least one illegal alteration\n+                        // and make an exception instance available for completing the corresponding future exceptionally\n+                        userIllegalAlterationExceptions.put(user, e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc1MTAwNQ==", "bodyText": "I wonder if InvalidRequestException is indeed the right one.  On the broker side, in kafka.server.AdminManager, the code looks like this:\n    invalidUsers.foreach(user => retval.results.add(new AlterUserScramCredentialsResult().setUser(user)\n      .setErrorCode(Errors.INVALID_REQUEST.code).setErrorMessage(\"Unknown SCRAM mechanism or too few iterations\")))", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465751005", "createdAt": "2020-08-05T14:04:43Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.from(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new IllegalArgumentException(\"Unknown SCRAM mechanism\"));\n+            }\n+        });\n+        // Creating an upsertion may throw InvalidKeyException or NoSuchAlgorithmException,\n+        // so keep track of which users are affected by such a failure and immediately fail all their alterations\n+        final Map<String, Map<ScramMechanism, AlterUserScramCredentialsRequestData.ScramCredentialUpsertion>> userInsertions = new HashMap<>();\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialUpsertion)\n+                .filter(alteration -> !userIllegalAlterationExceptions.containsKey(alteration.getUser()))\n+                .forEach(alteration -> {\n+                    UserScramCredentialUpsertion upsertion = (UserScramCredentialUpsertion) alteration;\n+                    String user = upsertion.getUser();\n+                    try {\n+                        ScramMechanism mechanism = upsertion.getInfo().getMechanism();\n+                        if (mechanism == null || mechanism == ScramMechanism.UNKNOWN)\n+                            throw new IllegalArgumentException(\"Unknown SCRAM mechanism\");\n+                        userInsertions.putIfAbsent(user, new HashMap<>());\n+                        userInsertions.get(user).put(mechanism, getScramCredentialUpsertion(upsertion));\n+                    } catch (Exception e) {\n+                        // we might overwrite aa exception from a previous upsertion, but we don't really care\n+                        // since we just needs to mark this user as having at least one illegal alteration\n+                        // and make an exception instance available for completing the corresponding future exceptionally\n+                        userIllegalAlterationExceptions.put(user, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NDcxMw=="}, "originalCommit": null, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3NDY2NA==", "bodyText": "The pattern in Kafka has always been to have very specific error codes and exceptions.  Unfortunately INVALID_REQUEST is documented like this:\n\"This most likely occurs because of a request being malformed by the \" +\n\"client library or the message was sent to an incompatible broker. See the broker logs \" +\n\"for more details.\",\n\nSo we probably need a new error code here", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468874664", "createdAt": "2020-08-11T21:27:03Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.from(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new IllegalArgumentException(\"Unknown SCRAM mechanism\"));\n+            }\n+        });\n+        // Creating an upsertion may throw InvalidKeyException or NoSuchAlgorithmException,\n+        // so keep track of which users are affected by such a failure and immediately fail all their alterations\n+        final Map<String, Map<ScramMechanism, AlterUserScramCredentialsRequestData.ScramCredentialUpsertion>> userInsertions = new HashMap<>();\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialUpsertion)\n+                .filter(alteration -> !userIllegalAlterationExceptions.containsKey(alteration.getUser()))\n+                .forEach(alteration -> {\n+                    UserScramCredentialUpsertion upsertion = (UserScramCredentialUpsertion) alteration;\n+                    String user = upsertion.getUser();\n+                    try {\n+                        ScramMechanism mechanism = upsertion.getInfo().getMechanism();\n+                        if (mechanism == null || mechanism == ScramMechanism.UNKNOWN)\n+                            throw new IllegalArgumentException(\"Unknown SCRAM mechanism\");\n+                        userInsertions.putIfAbsent(user, new HashMap<>());\n+                        userInsertions.get(user).put(mechanism, getScramCredentialUpsertion(upsertion));\n+                    } catch (Exception e) {\n+                        // we might overwrite aa exception from a previous upsertion, but we don't really care\n+                        // since we just needs to mark this user as having at least one illegal alteration\n+                        // and make an exception instance available for completing the corresponding future exceptionally\n+                        userIllegalAlterationExceptions.put(user, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NDcxMw=="}, "originalCommit": null, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQyMTUyMw==", "bodyText": "NoSuchAlgorithmException is thrown if we don't support the (otherwise valid) SCRAM mechanism.  For example, this might occur if we add support for a new SCRAM mechanism but the client is running an older JRE that doesn't support the algorithm associated with that newer mechanism.  UnsupportedSaslMechanismException would be appropriate here, I think.\nInvalidKeyException is thrown if the password to be salted is unacceptable -- i.e. if it is empty.  I will add a new UnacceptablePasswordException and Errors.UNACCEPTABLE_PASSWORD as a starting point for further review/discussion.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r469421523", "createdAt": "2020-08-12T17:25:02Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.from(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new IllegalArgumentException(\"Unknown SCRAM mechanism\"));\n+            }\n+        });\n+        // Creating an upsertion may throw InvalidKeyException or NoSuchAlgorithmException,\n+        // so keep track of which users are affected by such a failure and immediately fail all their alterations\n+        final Map<String, Map<ScramMechanism, AlterUserScramCredentialsRequestData.ScramCredentialUpsertion>> userInsertions = new HashMap<>();\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialUpsertion)\n+                .filter(alteration -> !userIllegalAlterationExceptions.containsKey(alteration.getUser()))\n+                .forEach(alteration -> {\n+                    UserScramCredentialUpsertion upsertion = (UserScramCredentialUpsertion) alteration;\n+                    String user = upsertion.getUser();\n+                    try {\n+                        ScramMechanism mechanism = upsertion.getInfo().getMechanism();\n+                        if (mechanism == null || mechanism == ScramMechanism.UNKNOWN)\n+                            throw new IllegalArgumentException(\"Unknown SCRAM mechanism\");\n+                        userInsertions.putIfAbsent(user, new HashMap<>());\n+                        userInsertions.get(user).put(mechanism, getScramCredentialUpsertion(upsertion));\n+                    } catch (Exception e) {\n+                        // we might overwrite aa exception from a previous upsertion, but we don't really care\n+                        // since we just needs to mark this user as having at least one illegal alteration\n+                        // and make an exception instance available for completing the corresponding future exceptionally\n+                        userIllegalAlterationExceptions.put(user, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NDcxMw=="}, "originalCommit": null, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzA2OA==", "bodyText": "Actually, we also have to deal with too few/too many iterations as well as empty username.  These, along with empty password, are a class unto themselves -- unacceptable credentials.  So I'm abandoning the specific \"UnacceptablePasswordException/Errors.UNACCEPTABLE_PASSWORD\" in favor of \"UnacceptableCredentialException/Errors.UNACCEPTABLE_CREDENTIAL\"", "url": "https://github.com/apache/kafka/pull/9032#discussion_r469457068", "createdAt": "2020-08-12T18:27:16Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.from(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new IllegalArgumentException(\"Unknown SCRAM mechanism\"));\n+            }\n+        });\n+        // Creating an upsertion may throw InvalidKeyException or NoSuchAlgorithmException,\n+        // so keep track of which users are affected by such a failure and immediately fail all their alterations\n+        final Map<String, Map<ScramMechanism, AlterUserScramCredentialsRequestData.ScramCredentialUpsertion>> userInsertions = new HashMap<>();\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialUpsertion)\n+                .filter(alteration -> !userIllegalAlterationExceptions.containsKey(alteration.getUser()))\n+                .forEach(alteration -> {\n+                    UserScramCredentialUpsertion upsertion = (UserScramCredentialUpsertion) alteration;\n+                    String user = upsertion.getUser();\n+                    try {\n+                        ScramMechanism mechanism = upsertion.getInfo().getMechanism();\n+                        if (mechanism == null || mechanism == ScramMechanism.UNKNOWN)\n+                            throw new IllegalArgumentException(\"Unknown SCRAM mechanism\");\n+                        userInsertions.putIfAbsent(user, new HashMap<>());\n+                        userInsertions.get(user).put(mechanism, getScramCredentialUpsertion(upsertion));\n+                    } catch (Exception e) {\n+                        // we might overwrite aa exception from a previous upsertion, but we don't really care\n+                        // since we just needs to mark this user as having at least one illegal alteration\n+                        // and make an exception instance available for completing the corresponding future exceptionally\n+                        userIllegalAlterationExceptions.put(user, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NDcxMw=="}, "originalCommit": null, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjYyNzI5OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/admin/ConfigCommand.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMzowMzozMFrOG70ZtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMzowMzozMFrOG70ZtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3NzcxNw==", "bodyText": "it would be good to split this off into its own function (after verifying that we weren't trying to do both SCRAM + quota)", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465377717", "createdAt": "2020-08-04T23:03:30Z", "author": {"login": "cmccabe"}, "path": "core/src/main/scala/kafka/admin/ConfigCommand.scala", "diffHunk": "@@ -365,45 +368,90 @@ object ConfigCommand extends Config {\n         adminClient.incrementalAlterConfigs(Map(configResource -> alterLogLevelEntries).asJava, alterOptions).all().get(60, TimeUnit.SECONDS)\n \n       case ConfigType.User | ConfigType.Client =>\n-        val nonQuotaConfigsToAdd = configsToBeAdded.keys.filterNot(QuotaConfigs.isQuotaConfig)\n-        if (nonQuotaConfigsToAdd.nonEmpty)\n-          throw new IllegalArgumentException(s\"Only quota configs can be added for '$entityTypeHead' using --bootstrap-server. Unexpected config names: $nonQuotaConfigsToAdd\")\n-        val nonQuotaConfigsToDelete = configsToBeDeleted.filterNot(QuotaConfigs.isQuotaConfig)\n-        if (nonQuotaConfigsToDelete.nonEmpty)\n-          throw new IllegalArgumentException(s\"Only quota configs can be deleted for '$entityTypeHead' using --bootstrap-server. Unexpected config names: $nonQuotaConfigsToDelete\")\n-\n-\n-        val oldConfig = getClientQuotasConfig(adminClient, entityTypes, entityNames)\n-\n-        val invalidConfigs = configsToBeDeleted.filterNot(oldConfig.contains)\n-        if (invalidConfigs.nonEmpty)\n-          throw new InvalidConfigurationException(s\"Invalid config(s): ${invalidConfigs.mkString(\",\")}\")\n-\n-        val alterEntityTypes = entityTypes.map { entType =>\n-          entType match {\n-            case ConfigType.User => ClientQuotaEntity.USER\n-            case ConfigType.Client => ClientQuotaEntity.CLIENT_ID\n-            case _ => throw new IllegalArgumentException(s\"Unexpected entity type: ${entType}\")\n+        val hasQuotaConfigsToAdd = configsToBeAdded.keys.exists(QuotaConfigs.isQuotaConfig)\n+        val scramConfigsToAddMap = configsToBeAdded.filter(entry => ScramMechanism.isScram(entry._1))\n+        val unknownConfigsToAdd = configsToBeAdded.keys.filterNot(key => ScramMechanism.isScram(key) || QuotaConfigs.isQuotaConfig(key))\n+        val hasQuotaConfigsToDelete = configsToBeDeleted.exists(QuotaConfigs.isQuotaConfig)\n+        val scramConfigsToDelete = configsToBeDeleted.filter(ScramMechanism.isScram)\n+        val unknownConfigsToDelete = configsToBeDeleted.filterNot(key => ScramMechanism.isScram(key) || QuotaConfigs.isQuotaConfig(key))\n+        if (entityTypeHead == ConfigType.Client || entityTypes.size == 2) { // size==2 for case where users is specified first on the command line, before clients\n+          // either just a client or both a user and a client\n+          if (unknownConfigsToAdd.nonEmpty || scramConfigsToAddMap.nonEmpty)\n+            throw new IllegalArgumentException(s\"Only quota configs can be added for '${ConfigType.Client}' using --bootstrap-server. Unexpected config names: ${unknownConfigsToAdd ++ scramConfigsToAddMap.keys}\")\n+          if (unknownConfigsToDelete.nonEmpty || scramConfigsToDelete.nonEmpty)\n+            throw new IllegalArgumentException(s\"Only quota configs can be deleted for '${ConfigType.Client}' using --bootstrap-server. Unexpected config names: ${unknownConfigsToDelete ++ scramConfigsToDelete}\")\n+        } else { // ConfigType.User\n+          if (unknownConfigsToAdd.nonEmpty)\n+            throw new IllegalArgumentException(s\"Only quota and SCRAM credential configs can be added for '${ConfigType.User}' using --bootstrap-server. Unexpected config names: $unknownConfigsToAdd\")\n+          if (unknownConfigsToDelete.nonEmpty)\n+            throw new IllegalArgumentException(s\"Only quota and SCRAM credential configs can be deleted for '${ConfigType.User}' using --bootstrap-server. Unexpected config names: $unknownConfigsToDelete\")\n+          if (scramConfigsToAddMap.nonEmpty || scramConfigsToDelete.nonEmpty) {\n+            if (entityNames.exists(_.isEmpty)) // either --entity-type users --entity-default or --user-defaults\n+              throw new IllegalArgumentException(\"The use of --entity-default or --user-defaults is not allowed with User SCRAM Credentials using --bootstrap-server.\")\n+            if (hasQuotaConfigsToAdd || hasQuotaConfigsToDelete)\n+              throw new IllegalArgumentException(s\"Cannot alter both quota and SCRAM credential configs simultaneously for '${ConfigType.User}' using --bootstrap-server.\")\n           }\n         }\n-        val alterEntityNames = entityNames.map(en => if (en.nonEmpty) en else null)\n \n-        // Explicitly populate a HashMap to ensure nulls are recorded properly.\n-        val alterEntityMap = new java.util.HashMap[String, String]\n-        alterEntityTypes.zip(alterEntityNames).foreach { case (k, v) => alterEntityMap.put(k, v) }\n-        val entity = new ClientQuotaEntity(alterEntityMap)\n+        if (hasQuotaConfigsToAdd || hasQuotaConfigsToDelete) {\n+          // handle altering client/user quota configs", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjYyOTg0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/admin/ConfigCommand.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMzowNDo0OFrOG70bSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMzowNDo0OFrOG70bSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3ODEyMg==", "bodyText": "it would be good to split this off into its own function (after verifying that we weren't trying to do both SCRAM + quota) or multiple entity names", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465378122", "createdAt": "2020-08-04T23:04:48Z", "author": {"login": "cmccabe"}, "path": "core/src/main/scala/kafka/admin/ConfigCommand.scala", "diffHunk": "@@ -365,45 +368,90 @@ object ConfigCommand extends Config {\n         adminClient.incrementalAlterConfigs(Map(configResource -> alterLogLevelEntries).asJava, alterOptions).all().get(60, TimeUnit.SECONDS)\n \n       case ConfigType.User | ConfigType.Client =>\n-        val nonQuotaConfigsToAdd = configsToBeAdded.keys.filterNot(QuotaConfigs.isQuotaConfig)\n-        if (nonQuotaConfigsToAdd.nonEmpty)\n-          throw new IllegalArgumentException(s\"Only quota configs can be added for '$entityTypeHead' using --bootstrap-server. Unexpected config names: $nonQuotaConfigsToAdd\")\n-        val nonQuotaConfigsToDelete = configsToBeDeleted.filterNot(QuotaConfigs.isQuotaConfig)\n-        if (nonQuotaConfigsToDelete.nonEmpty)\n-          throw new IllegalArgumentException(s\"Only quota configs can be deleted for '$entityTypeHead' using --bootstrap-server. Unexpected config names: $nonQuotaConfigsToDelete\")\n-\n-\n-        val oldConfig = getClientQuotasConfig(adminClient, entityTypes, entityNames)\n-\n-        val invalidConfigs = configsToBeDeleted.filterNot(oldConfig.contains)\n-        if (invalidConfigs.nonEmpty)\n-          throw new InvalidConfigurationException(s\"Invalid config(s): ${invalidConfigs.mkString(\",\")}\")\n-\n-        val alterEntityTypes = entityTypes.map { entType =>\n-          entType match {\n-            case ConfigType.User => ClientQuotaEntity.USER\n-            case ConfigType.Client => ClientQuotaEntity.CLIENT_ID\n-            case _ => throw new IllegalArgumentException(s\"Unexpected entity type: ${entType}\")\n+        val hasQuotaConfigsToAdd = configsToBeAdded.keys.exists(QuotaConfigs.isQuotaConfig)\n+        val scramConfigsToAddMap = configsToBeAdded.filter(entry => ScramMechanism.isScram(entry._1))\n+        val unknownConfigsToAdd = configsToBeAdded.keys.filterNot(key => ScramMechanism.isScram(key) || QuotaConfigs.isQuotaConfig(key))\n+        val hasQuotaConfigsToDelete = configsToBeDeleted.exists(QuotaConfigs.isQuotaConfig)\n+        val scramConfigsToDelete = configsToBeDeleted.filter(ScramMechanism.isScram)\n+        val unknownConfigsToDelete = configsToBeDeleted.filterNot(key => ScramMechanism.isScram(key) || QuotaConfigs.isQuotaConfig(key))\n+        if (entityTypeHead == ConfigType.Client || entityTypes.size == 2) { // size==2 for case where users is specified first on the command line, before clients\n+          // either just a client or both a user and a client\n+          if (unknownConfigsToAdd.nonEmpty || scramConfigsToAddMap.nonEmpty)\n+            throw new IllegalArgumentException(s\"Only quota configs can be added for '${ConfigType.Client}' using --bootstrap-server. Unexpected config names: ${unknownConfigsToAdd ++ scramConfigsToAddMap.keys}\")\n+          if (unknownConfigsToDelete.nonEmpty || scramConfigsToDelete.nonEmpty)\n+            throw new IllegalArgumentException(s\"Only quota configs can be deleted for '${ConfigType.Client}' using --bootstrap-server. Unexpected config names: ${unknownConfigsToDelete ++ scramConfigsToDelete}\")\n+        } else { // ConfigType.User\n+          if (unknownConfigsToAdd.nonEmpty)\n+            throw new IllegalArgumentException(s\"Only quota and SCRAM credential configs can be added for '${ConfigType.User}' using --bootstrap-server. Unexpected config names: $unknownConfigsToAdd\")\n+          if (unknownConfigsToDelete.nonEmpty)\n+            throw new IllegalArgumentException(s\"Only quota and SCRAM credential configs can be deleted for '${ConfigType.User}' using --bootstrap-server. Unexpected config names: $unknownConfigsToDelete\")\n+          if (scramConfigsToAddMap.nonEmpty || scramConfigsToDelete.nonEmpty) {\n+            if (entityNames.exists(_.isEmpty)) // either --entity-type users --entity-default or --user-defaults\n+              throw new IllegalArgumentException(\"The use of --entity-default or --user-defaults is not allowed with User SCRAM Credentials using --bootstrap-server.\")\n+            if (hasQuotaConfigsToAdd || hasQuotaConfigsToDelete)\n+              throw new IllegalArgumentException(s\"Cannot alter both quota and SCRAM credential configs simultaneously for '${ConfigType.User}' using --bootstrap-server.\")\n           }\n         }\n-        val alterEntityNames = entityNames.map(en => if (en.nonEmpty) en else null)\n \n-        // Explicitly populate a HashMap to ensure nulls are recorded properly.\n-        val alterEntityMap = new java.util.HashMap[String, String]\n-        alterEntityTypes.zip(alterEntityNames).foreach { case (k, v) => alterEntityMap.put(k, v) }\n-        val entity = new ClientQuotaEntity(alterEntityMap)\n+        if (hasQuotaConfigsToAdd || hasQuotaConfigsToDelete) {\n+          // handle altering client/user quota configs\n+          val oldConfig = getClientQuotasConfig(adminClient, entityTypes, entityNames)\n \n-        val alterOptions = new AlterClientQuotasOptions().validateOnly(false)\n-        val alterOps = (configsToBeAddedMap.map { case (key, value) =>\n-          val doubleValue = try value.toDouble catch {\n-            case _: NumberFormatException =>\n-              throw new IllegalArgumentException(s\"Cannot parse quota configuration value for ${key}: ${value}\")\n+          val invalidConfigs = configsToBeDeleted.filterNot(oldConfig.contains)\n+          if (invalidConfigs.nonEmpty)\n+            throw new InvalidConfigurationException(s\"Invalid config(s): ${invalidConfigs.mkString(\",\")}\")\n+\n+          val alterEntityTypes = entityTypes.map { entType =>\n+            entType match {\n+              case ConfigType.User => ClientQuotaEntity.USER\n+              case ConfigType.Client => ClientQuotaEntity.CLIENT_ID\n+              case _ => throw new IllegalArgumentException(s\"Unexpected entity type: ${entType}\")\n+            }\n+          }\n+          val alterEntityNames = entityNames.map(en => if (en.nonEmpty) en else null)\n+\n+          // Explicitly populate a HashMap to ensure nulls are recorded properly.\n+          val alterEntityMap = new java.util.HashMap[String, String]\n+          alterEntityTypes.zip(alterEntityNames).foreach { case (k, v) => alterEntityMap.put(k, v) }\n+          val entity = new ClientQuotaEntity(alterEntityMap)\n+\n+          val alterOptions = new AlterClientQuotasOptions().validateOnly(false)\n+          val alterOps = (configsToBeAddedMap.map { case (key, value) =>\n+            val doubleValue = try value.toDouble catch {\n+              case _: NumberFormatException =>\n+                throw new IllegalArgumentException(s\"Cannot parse quota configuration value for ${key}: ${value}\")\n+            }\n+            new ClientQuotaAlteration.Op(key, doubleValue)\n+          } ++ configsToBeDeleted.map(key => new ClientQuotaAlteration.Op(key, null))).asJavaCollection\n+\n+          adminClient.alterClientQuotas(Collections.singleton(new ClientQuotaAlteration(entity, alterOps)), alterOptions)\n+            .all().get(60, TimeUnit.SECONDS)\n+        } else {\n+          // handle altering user SCRAM credential configs", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjcyOTczOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/AdminManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMzo1NDoxM1rOG71Wzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMzo1NDoxM1rOG71Wzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM5MzM1OA==", "bodyText": "It would be good to avoid confusing empty with null.  Why not use Option[Seq[String]]", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465393358", "createdAt": "2020-08-04T23:54:13Z", "author": {"login": "cmccabe"}, "path": "core/src/main/scala/kafka/server/AdminManager.scala", "diffHunk": "@@ -980,4 +984,137 @@ class AdminManager(val config: KafkaConfig,\n       entry.entity -> apiError\n     }.toMap\n   }\n+\n+  def describeUserScramCredentials(users: Seq[String]): DescribeUserScramCredentialsResponseData = {\n+    val retval = new DescribeUserScramCredentialsResponseData()\n+\n+    def addToResults(user: String, userConfig: Properties) = {\n+      val configKeys = userConfig.stringPropertyNames\n+      val hasScramCredential = !ScramMechanism.values().toList.filter(key => key != ScramMechanism.UNKNOWN && configKeys.contains(key.toMechanismName)).isEmpty\n+      if (hasScramCredential) {\n+        val userScramCredentials = new UserScramCredential().setName(user)\n+        ScramMechanism.values().foreach(mechanism => if (mechanism != ScramMechanism.UNKNOWN) {\n+          val propertyValue = userConfig.getProperty(mechanism.toMechanismName)\n+          if (propertyValue != null) {\n+            val iterations = ScramCredentialUtils.credentialFromString(propertyValue).iterations\n+            userScramCredentials.credentialInfos.add(new CredentialInfo().setMechanism(mechanism.ordinal.toByte).setIterations(iterations))\n+          }\n+        })\n+        retval.userScramCredentials.add(userScramCredentials)\n+      }\n+    }\n+\n+    if (users.isEmpty)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwOTcyOTM2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxNjo0NDozMlrOG8R-XA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxOTowMToyN1rOG_ujYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg2MjIzNg==", "bodyText": "Does this need to be controller for Describe? It looks similar to DescribeAcls where we use LeastLoadedNode.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465862236", "createdAt": "2020-08-05T16:44:32Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY4MTIzMQ==", "bodyText": "The KIP says It will be will be sent to the controller, and will return NOT_CONTROLLER if the receiving broker is not the controller. It says this for both Describe and Alter.  I agree it doesn't seem necessary for Describe.  Would it require an email to the list for notification if we decide to change it?  Or would a KIP update be sufficient?  Do you think we should change it?  @cmccabe any thoughts here as well?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r466681231", "createdAt": "2020-08-06T20:55:39Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg2MjIzNg=="}, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA1MjI2OQ==", "bodyText": "Let's see what @cmccabe thinks. We can do whatever we intend to do for similar describe APIs in the KIP-500 world. If we are changing, then we should update the KIP and send a note to the KIP discussion thread.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r467052269", "createdAt": "2020-08-07T13:49:00Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg2MjIzNg=="}, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MzQyOA==", "bodyText": "We're planning on getting rid of ControllerNodeProvider as part of KIP-590, so I think these should all just use leastLoadedNode.  Right now they set / fetch stuff in ZK directly anyway.\nYes, it will require an email to the mailing list, but I don't think it's a big change", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468873428", "createdAt": "2020-08-11T21:24:33Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg2MjIzNg=="}, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ3NjE5NQ==", "bodyText": "Ok, switching Describe to not require that it be done on the controller.\n\nplanning on getting rid of ControllerNodeProvider as part of KIP-590\n\nLeaving Alter alone for now under the assumption that we will fix it as part of the KIP-590 PR.  Let me know if you wish me to change this now instead.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r469476195", "createdAt": "2020-08-12T19:01:27Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg2MjIzNg=="}, "originalCommit": null, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDI1NjYyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOToxNjo1NFrOG8XLtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOToxNjo1NFrOG8XLtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0NzU3Mg==", "bodyText": "typo: iterations", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465947572", "createdAt": "2020-08-05T19:16:54Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.fromType(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new InvalidRequestException(\"Unknown SCRAM mechanism\"));\n+            }\n+        });\n+        // Creating an upsertion may throw InvalidKeyException or NoSuchAlgorithmException,\n+        // so keep track of which users are affected by such a failure and immediately fail all their alterations\n+        final Map<String, Map<ScramMechanism, AlterUserScramCredentialsRequestData.ScramCredentialUpsertion>> userInsertions = new HashMap<>();\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialUpsertion)\n+                .filter(alteration -> !userIllegalAlterationExceptions.containsKey(alteration.getUser()))\n+                .forEach(alteration -> {\n+                    UserScramCredentialUpsertion upsertion = (UserScramCredentialUpsertion) alteration;\n+                    String user = upsertion.getUser();\n+                    try {\n+                        ScramMechanism mechanism = upsertion.getInfo().getMechanism();\n+                        if (mechanism == null || mechanism == ScramMechanism.UNKNOWN)\n+                            throw new InvalidRequestException(\"Unknown SCRAM mechanism\");\n+                        userInsertions.putIfAbsent(user, new HashMap<>());\n+                        userInsertions.get(user).put(mechanism, getScramCredentialUpsertion(upsertion));\n+                    } catch (Exception e) {\n+                        // we might overwrite an exception from a previous upsertion, but we don't really care\n+                        // since we just need to mark this user as having at least one illegal alteration\n+                        // and make an exception instance available for completing the corresponding future exceptionally\n+                        userIllegalAlterationExceptions.put(user, e);\n+                    }\n+                });\n+        // fail any users immediately that have an illegal alteration as identified above\n+        userIllegalAlterationExceptions.entrySet().stream().forEach(entry -> {\n+            futures.get(entry.getKey()).completeExceptionally(entry.getValue());\n+        });\n+\n+        // submit alterations for users that do not have an illegal upsertion as identified above\n+        Call call = new Call(\"alterUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public AlterUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new AlterUserScramCredentialsRequest.Builder(\n+                        new AlterUserScramCredentialsRequestData().setUpsertions(alterations.stream()\n+                                .filter(a -> a instanceof UserScramCredentialUpsertion)\n+                                .filter(a -> !userIllegalAlterationExceptions.containsKey(a.getUser()))\n+                                .map(a -> userInsertions.get(a.getUser()).get(((UserScramCredentialUpsertion) a).getInfo().getMechanism()))\n+                                .collect(Collectors.toList()))\n+                        .setDeletions(alterations.stream()\n+                                .filter(a -> a instanceof UserScramCredentialDeletion)\n+                                .filter(a -> !userIllegalAlterationExceptions.containsKey(a.getUser()))\n+                                .map(d ->\n+                                getScramCredentialDeletion((UserScramCredentialDeletion) d)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                AlterUserScramCredentialsResponse response = (AlterUserScramCredentialsResponse) abstractResponse;\n+                // Check for controller change\n+                for (Errors error : response.errorCounts().keySet()) {\n+                    if (error == Errors.NOT_CONTROLLER) {\n+                        handleNotControllerError(error);\n+                    }\n+                }\n+                response.data().results().forEach(result -> {\n+                    KafkaFutureImpl<Void> future = futures.get(result.user());\n+                    if (future == null) {\n+                        log.warn(\"Server response mentioned unknown user {}\", result.user());\n+                    } else {\n+                        Errors error = Errors.forCode(result.errorCode());\n+                        if (error != Errors.NONE) {\n+                            future.completeExceptionally(error.exception());\n+                        } else {\n+                            future.complete(null);\n+                        }\n+                    }\n+                });\n+                completeUnrealizedFutures(\n+                    futures.entrySet().stream(),\n+                    user -> \"The broker response did not contain a result for user \" + user);\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                completeAllExceptionally(futures.values(), throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new AlterUserScramCredentialsResult(new HashMap<>(futures));\n+    }\n+\n+    private static AlterUserScramCredentialsRequestData.ScramCredentialUpsertion getScramCredentialUpsertion(UserScramCredentialUpsertion u) throws InvalidKeyException, NoSuchAlgorithmException {\n+        AlterUserScramCredentialsRequestData.ScramCredentialUpsertion retval = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion();\n+        return retval.setName(u.getUser())\n+                .setMechanism(u.getInfo().getMechanism().getType())\n+                .setIterations(u.getInfo().getIterations())\n+                .setSalt(u.getSalt())\n+                .setSaltedPassword(getSaltedPasword(u.getInfo().getMechanism(), u.getPassword(), u.getSalt(), u.getInfo().getIterations()));\n+    }\n+\n+    private static AlterUserScramCredentialsRequestData.ScramCredentialDeletion getScramCredentialDeletion(UserScramCredentialDeletion d) {\n+        return new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(d.getUser()).setMechanism(d.getMechanism().getType());\n+    }\n+\n+    private static byte[] getSaltedPasword(ScramMechanism publicScramMechanism, byte[] password, byte[] salt, int interations) throws NoSuchAlgorithmException, InvalidKeyException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 213}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDI4NTEwOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/admin/ConfigCommand.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOToyNTo1M1rOG8Xdpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QxODowNDo1MVrOG9jHgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1MjE2Ng==", "bodyText": "What do we do if the user is not a SCRAM user? Won't this throw an exception? Can we make sure that user without quota or SCRAM credential doesn't print any errors or exceptions?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465952166", "createdAt": "2020-08-05T19:25:53Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/admin/ConfigCommand.scala", "diffHunk": "@@ -508,7 +563,15 @@ object ConfigCommand extends Config {\n \n       val entityStr = (entitySubstr(ClientQuotaEntity.USER) ++ entitySubstr(ClientQuotaEntity.CLIENT_ID)).mkString(\", \")\n       val entriesStr = entries.asScala.map(e => s\"${e._1}=${e._2}\").mkString(\", \")\n-      println(s\"Configs for ${entityStr} are ${entriesStr}\")\n+      println(s\"Quota configs for ${entityStr} are ${entriesStr}\")\n+    }\n+    // we describe user SCRAM credentials only when we are not describing client information\n+    // and we are not given either --entity-default or --user-defaults\n+    if (!entityTypes.contains(ConfigType.Client) && !entityNames.contains(\"\")) {\n+      getUserScramCredentialConfigs(adminClient, entityNames).foreach { case (user, description) =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE5MTY4MA==", "bodyText": "I'm adding core/src/test/scala/unit/kafka/admin/UserScramCredentialsCommandTest.scala -- let me know if this test covers this case.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r467191680", "createdAt": "2020-08-07T18:04:51Z", "author": {"login": "rondagostino"}, "path": "core/src/main/scala/kafka/admin/ConfigCommand.scala", "diffHunk": "@@ -508,7 +563,15 @@ object ConfigCommand extends Config {\n \n       val entityStr = (entitySubstr(ClientQuotaEntity.USER) ++ entitySubstr(ClientQuotaEntity.CLIENT_ID)).mkString(\", \")\n       val entriesStr = entries.asScala.map(e => s\"${e._1}=${e._2}\").mkString(\", \")\n-      println(s\"Configs for ${entityStr} are ${entriesStr}\")\n+      println(s\"Quota configs for ${entityStr} are ${entriesStr}\")\n+    }\n+    // we describe user SCRAM credentials only when we are not describing client information\n+    // and we are not given either --entity-default or --user-defaults\n+    if (!entityTypes.contains(ConfigType.Client) && !entityNames.contains(\"\")) {\n+      getUserScramCredentialConfigs(adminClient, entityNames).foreach { case (user, description) =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1MjE2Ng=="}, "originalCommit": null, "originalPosition": 213}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDI5ODg1OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/AdminManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTozMDoxMVrOG8XmQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTozMDoxMVrOG8XmQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1NDM3MA==", "bodyText": "should we catch exception?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465954370", "createdAt": "2020-08-05T19:30:11Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/AdminManager.scala", "diffHunk": "@@ -980,4 +984,137 @@ class AdminManager(val config: KafkaConfig,\n       entry.entity -> apiError\n     }.toMap\n   }\n+\n+  def describeUserScramCredentials(users: Option[Seq[String]]): DescribeUserScramCredentialsResponseData = {\n+    val retval = new DescribeUserScramCredentialsResponseData()\n+\n+    def addToResults(user: String, userConfig: Properties) = {\n+      val configKeys = userConfig.stringPropertyNames\n+      val hasScramCredential = !ScramMechanism.values().toList.filter(key => key != ScramMechanism.UNKNOWN && configKeys.contains(key.getMechanismName)).isEmpty\n+      if (hasScramCredential) {\n+        val userScramCredentials = new UserScramCredential().setName(user)\n+        ScramMechanism.values().foreach(mechanism => if (mechanism != ScramMechanism.UNKNOWN) {\n+          val propertyValue = userConfig.getProperty(mechanism.getMechanismName)\n+          if (propertyValue != null) {\n+            val iterations = ScramCredentialUtils.credentialFromString(propertyValue).iterations\n+            userScramCredentials.credentialInfos.add(new CredentialInfo().setMechanism(mechanism.getType).setIterations(iterations))\n+          }\n+        })\n+        retval.userScramCredentials.add(userScramCredentials)\n+      }\n+    }\n+\n+    if (!users.isDefined || users.get.isEmpty)\n+      // describe all users\n+      adminZkClient.fetchAllEntityConfigs(ConfigType.User).foreach { case (user, properties) => addToResults(user, properties) }\n+    else {\n+      // describe specific users\n+      // https://stackoverflow.com/questions/24729544/how-to-find-duplicates-in-a-list\n+      val duplicatedUsers = users.get.groupBy(identity).collect { case (x, Seq(_, _, _*)) => x }\n+      if (duplicatedUsers.nonEmpty) {\n+        retval.setError(Errors.INVALID_REQUEST.code())\n+        retval.setErrorMessage(s\"Cannot describe SCRAM credentials for the same user twice in a single request: ${duplicatedUsers.mkString(\"[\", \", \", \"]\")}\")\n+      } else\n+        users.get.foreach { user => addToResults(user, adminZkClient.fetchEntityConfig(ConfigType.User, Sanitizer.sanitize(user))) }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDMwMzM2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/AdminManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTozMTozOVrOG8XpPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTozMTozOVrOG8XpPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1NTEzMg==", "bodyText": "Can't we return an exception message that says exactly why, instead of x or y", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465955132", "createdAt": "2020-08-05T19:31:39Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/AdminManager.scala", "diffHunk": "@@ -980,4 +984,137 @@ class AdminManager(val config: KafkaConfig,\n       entry.entity -> apiError\n     }.toMap\n   }\n+\n+  def describeUserScramCredentials(users: Option[Seq[String]]): DescribeUserScramCredentialsResponseData = {\n+    val retval = new DescribeUserScramCredentialsResponseData()\n+\n+    def addToResults(user: String, userConfig: Properties) = {\n+      val configKeys = userConfig.stringPropertyNames\n+      val hasScramCredential = !ScramMechanism.values().toList.filter(key => key != ScramMechanism.UNKNOWN && configKeys.contains(key.getMechanismName)).isEmpty\n+      if (hasScramCredential) {\n+        val userScramCredentials = new UserScramCredential().setName(user)\n+        ScramMechanism.values().foreach(mechanism => if (mechanism != ScramMechanism.UNKNOWN) {\n+          val propertyValue = userConfig.getProperty(mechanism.getMechanismName)\n+          if (propertyValue != null) {\n+            val iterations = ScramCredentialUtils.credentialFromString(propertyValue).iterations\n+            userScramCredentials.credentialInfos.add(new CredentialInfo().setMechanism(mechanism.getType).setIterations(iterations))\n+          }\n+        })\n+        retval.userScramCredentials.add(userScramCredentials)\n+      }\n+    }\n+\n+    if (!users.isDefined || users.get.isEmpty)\n+      // describe all users\n+      adminZkClient.fetchAllEntityConfigs(ConfigType.User).foreach { case (user, properties) => addToResults(user, properties) }\n+    else {\n+      // describe specific users\n+      // https://stackoverflow.com/questions/24729544/how-to-find-duplicates-in-a-list\n+      val duplicatedUsers = users.get.groupBy(identity).collect { case (x, Seq(_, _, _*)) => x }\n+      if (duplicatedUsers.nonEmpty) {\n+        retval.setError(Errors.INVALID_REQUEST.code())\n+        retval.setErrorMessage(s\"Cannot describe SCRAM credentials for the same user twice in a single request: ${duplicatedUsers.mkString(\"[\", \", \", \"]\")}\")\n+      } else\n+        users.get.foreach { user => addToResults(user, adminZkClient.fetchEntityConfig(ConfigType.User, Sanitizer.sanitize(user))) }\n+    }\n+    retval\n+  }\n+\n+  def alterUserScramCredentials(upsertions: Seq[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion],\n+                                deletions: Seq[AlterUserScramCredentialsRequestData.ScramCredentialDeletion]): AlterUserScramCredentialsResponseData = {\n+\n+    def scramMechanism(mechanism: Byte): ScramMechanism = {\n+      ScramMechanism.fromType(mechanism)\n+    }\n+\n+    def mechanismName(mechanism: Byte): String = {\n+      scramMechanism(mechanism).getMechanismName\n+    }\n+\n+    val retval = new AlterUserScramCredentialsResponseData()\n+\n+    // fail any user that is invalid due to an empty user name, an unknown SCRAM mechanism, or not enough iterations\n+    val invalidUsers = (\n+      upsertions.filter(upsertion => {\n+        if (upsertion.name.isEmpty)\n+          true\n+        else {\n+          val publicScramMechanism = scramMechanism(upsertion.mechanism)\n+          publicScramMechanism == ScramMechanism.UNKNOWN ||\n+            (upsertion.iterations != -1 &&\n+              InternalScramMechanism.forMechanismName(publicScramMechanism.getMechanismName).minIterations > upsertion.iterations)\n+        }\n+      }).map(_.name) ++ deletions.filter(deletions => deletions.name.isEmpty || scramMechanism(deletions.mechanism) == ScramMechanism.UNKNOWN).map(_.name))\n+      .toSet\n+    invalidUsers.foreach(user => retval.results.add(new AlterUserScramCredentialsResult().setUser(user)\n+      .setErrorCode(Errors.INVALID_REQUEST.code).setErrorMessage(\"Unknown SCRAM mechanism or too few iterations\")))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDMxNDU3OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/AdminManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTozNToyMVrOG8XwiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTozNToyMVrOG8XwiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1NzAwMA==", "bodyText": "Do we include this kind of comment in code?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465957000", "createdAt": "2020-08-05T19:35:21Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/AdminManager.scala", "diffHunk": "@@ -980,4 +984,137 @@ class AdminManager(val config: KafkaConfig,\n       entry.entity -> apiError\n     }.toMap\n   }\n+\n+  def describeUserScramCredentials(users: Option[Seq[String]]): DescribeUserScramCredentialsResponseData = {\n+    val retval = new DescribeUserScramCredentialsResponseData()\n+\n+    def addToResults(user: String, userConfig: Properties) = {\n+      val configKeys = userConfig.stringPropertyNames\n+      val hasScramCredential = !ScramMechanism.values().toList.filter(key => key != ScramMechanism.UNKNOWN && configKeys.contains(key.getMechanismName)).isEmpty\n+      if (hasScramCredential) {\n+        val userScramCredentials = new UserScramCredential().setName(user)\n+        ScramMechanism.values().foreach(mechanism => if (mechanism != ScramMechanism.UNKNOWN) {\n+          val propertyValue = userConfig.getProperty(mechanism.getMechanismName)\n+          if (propertyValue != null) {\n+            val iterations = ScramCredentialUtils.credentialFromString(propertyValue).iterations\n+            userScramCredentials.credentialInfos.add(new CredentialInfo().setMechanism(mechanism.getType).setIterations(iterations))\n+          }\n+        })\n+        retval.userScramCredentials.add(userScramCredentials)\n+      }\n+    }\n+\n+    if (!users.isDefined || users.get.isEmpty)\n+      // describe all users\n+      adminZkClient.fetchAllEntityConfigs(ConfigType.User).foreach { case (user, properties) => addToResults(user, properties) }\n+    else {\n+      // describe specific users\n+      // https://stackoverflow.com/questions/24729544/how-to-find-duplicates-in-a-list\n+      val duplicatedUsers = users.get.groupBy(identity).collect { case (x, Seq(_, _, _*)) => x }\n+      if (duplicatedUsers.nonEmpty) {\n+        retval.setError(Errors.INVALID_REQUEST.code())\n+        retval.setErrorMessage(s\"Cannot describe SCRAM credentials for the same user twice in a single request: ${duplicatedUsers.mkString(\"[\", \", \", \"]\")}\")\n+      } else\n+        users.get.foreach { user => addToResults(user, adminZkClient.fetchEntityConfig(ConfigType.User, Sanitizer.sanitize(user))) }\n+    }\n+    retval\n+  }\n+\n+  def alterUserScramCredentials(upsertions: Seq[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion],\n+                                deletions: Seq[AlterUserScramCredentialsRequestData.ScramCredentialDeletion]): AlterUserScramCredentialsResponseData = {\n+\n+    def scramMechanism(mechanism: Byte): ScramMechanism = {\n+      ScramMechanism.fromType(mechanism)\n+    }\n+\n+    def mechanismName(mechanism: Byte): String = {\n+      scramMechanism(mechanism).getMechanismName\n+    }\n+\n+    val retval = new AlterUserScramCredentialsResponseData()\n+\n+    // fail any user that is invalid due to an empty user name, an unknown SCRAM mechanism, or not enough iterations\n+    val invalidUsers = (\n+      upsertions.filter(upsertion => {\n+        if (upsertion.name.isEmpty)\n+          true\n+        else {\n+          val publicScramMechanism = scramMechanism(upsertion.mechanism)\n+          publicScramMechanism == ScramMechanism.UNKNOWN ||\n+            (upsertion.iterations != -1 &&\n+              InternalScramMechanism.forMechanismName(publicScramMechanism.getMechanismName).minIterations > upsertion.iterations)\n+        }\n+      }).map(_.name) ++ deletions.filter(deletions => deletions.name.isEmpty || scramMechanism(deletions.mechanism) == ScramMechanism.UNKNOWN).map(_.name))\n+      .toSet\n+    invalidUsers.foreach(user => retval.results.add(new AlterUserScramCredentialsResult().setUser(user)\n+      .setErrorCode(Errors.INVALID_REQUEST.code).setErrorMessage(\"Unknown SCRAM mechanism or too few iterations\")))\n+\n+    val initiallyValidUserMechanismPairs = (upsertions.filter(upsertion => !invalidUsers.contains(upsertion.name)).map(upsertion => (upsertion.name, upsertion.mechanism)) ++\n+      deletions.filter(deletion => !invalidUsers.contains(deletion.name)).map(deletion => (deletion.name, deletion.mechanism)))\n+\n+    // https://stackoverflow.com/questions/24729544/how-to-find-duplicates-in-a-list", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDMyOTQ3OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/AdminManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTo0MDoxNVrOG8X57w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTo0MDoxNVrOG8X57w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1OTQwNw==", "bodyText": "Shouldn't we also limit the max value for iterations?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465959407", "createdAt": "2020-08-05T19:40:15Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/AdminManager.scala", "diffHunk": "@@ -980,4 +984,137 @@ class AdminManager(val config: KafkaConfig,\n       entry.entity -> apiError\n     }.toMap\n   }\n+\n+  def describeUserScramCredentials(users: Option[Seq[String]]): DescribeUserScramCredentialsResponseData = {\n+    val retval = new DescribeUserScramCredentialsResponseData()\n+\n+    def addToResults(user: String, userConfig: Properties) = {\n+      val configKeys = userConfig.stringPropertyNames\n+      val hasScramCredential = !ScramMechanism.values().toList.filter(key => key != ScramMechanism.UNKNOWN && configKeys.contains(key.getMechanismName)).isEmpty\n+      if (hasScramCredential) {\n+        val userScramCredentials = new UserScramCredential().setName(user)\n+        ScramMechanism.values().foreach(mechanism => if (mechanism != ScramMechanism.UNKNOWN) {\n+          val propertyValue = userConfig.getProperty(mechanism.getMechanismName)\n+          if (propertyValue != null) {\n+            val iterations = ScramCredentialUtils.credentialFromString(propertyValue).iterations\n+            userScramCredentials.credentialInfos.add(new CredentialInfo().setMechanism(mechanism.getType).setIterations(iterations))\n+          }\n+        })\n+        retval.userScramCredentials.add(userScramCredentials)\n+      }\n+    }\n+\n+    if (!users.isDefined || users.get.isEmpty)\n+      // describe all users\n+      adminZkClient.fetchAllEntityConfigs(ConfigType.User).foreach { case (user, properties) => addToResults(user, properties) }\n+    else {\n+      // describe specific users\n+      // https://stackoverflow.com/questions/24729544/how-to-find-duplicates-in-a-list\n+      val duplicatedUsers = users.get.groupBy(identity).collect { case (x, Seq(_, _, _*)) => x }\n+      if (duplicatedUsers.nonEmpty) {\n+        retval.setError(Errors.INVALID_REQUEST.code())\n+        retval.setErrorMessage(s\"Cannot describe SCRAM credentials for the same user twice in a single request: ${duplicatedUsers.mkString(\"[\", \", \", \"]\")}\")\n+      } else\n+        users.get.foreach { user => addToResults(user, adminZkClient.fetchEntityConfig(ConfigType.User, Sanitizer.sanitize(user))) }\n+    }\n+    retval\n+  }\n+\n+  def alterUserScramCredentials(upsertions: Seq[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion],\n+                                deletions: Seq[AlterUserScramCredentialsRequestData.ScramCredentialDeletion]): AlterUserScramCredentialsResponseData = {\n+\n+    def scramMechanism(mechanism: Byte): ScramMechanism = {\n+      ScramMechanism.fromType(mechanism)\n+    }\n+\n+    def mechanismName(mechanism: Byte): String = {\n+      scramMechanism(mechanism).getMechanismName\n+    }\n+\n+    val retval = new AlterUserScramCredentialsResponseData()\n+\n+    // fail any user that is invalid due to an empty user name, an unknown SCRAM mechanism, or not enough iterations\n+    val invalidUsers = (\n+      upsertions.filter(upsertion => {\n+        if (upsertion.name.isEmpty)\n+          true\n+        else {\n+          val publicScramMechanism = scramMechanism(upsertion.mechanism)\n+          publicScramMechanism == ScramMechanism.UNKNOWN ||\n+            (upsertion.iterations != -1 &&\n+              InternalScramMechanism.forMechanismName(publicScramMechanism.getMechanismName).minIterations > upsertion.iterations)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDMyOTUyOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/AdminManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTo0MDoxNVrOG8X59w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTo0MDoxNVrOG8X59w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1OTQxNQ==", "bodyText": "Shouldn't we also limit the max value for iterations?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465959415", "createdAt": "2020-08-05T19:40:15Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/AdminManager.scala", "diffHunk": "@@ -980,4 +984,137 @@ class AdminManager(val config: KafkaConfig,\n       entry.entity -> apiError\n     }.toMap\n   }\n+\n+  def describeUserScramCredentials(users: Option[Seq[String]]): DescribeUserScramCredentialsResponseData = {\n+    val retval = new DescribeUserScramCredentialsResponseData()\n+\n+    def addToResults(user: String, userConfig: Properties) = {\n+      val configKeys = userConfig.stringPropertyNames\n+      val hasScramCredential = !ScramMechanism.values().toList.filter(key => key != ScramMechanism.UNKNOWN && configKeys.contains(key.getMechanismName)).isEmpty\n+      if (hasScramCredential) {\n+        val userScramCredentials = new UserScramCredential().setName(user)\n+        ScramMechanism.values().foreach(mechanism => if (mechanism != ScramMechanism.UNKNOWN) {\n+          val propertyValue = userConfig.getProperty(mechanism.getMechanismName)\n+          if (propertyValue != null) {\n+            val iterations = ScramCredentialUtils.credentialFromString(propertyValue).iterations\n+            userScramCredentials.credentialInfos.add(new CredentialInfo().setMechanism(mechanism.getType).setIterations(iterations))\n+          }\n+        })\n+        retval.userScramCredentials.add(userScramCredentials)\n+      }\n+    }\n+\n+    if (!users.isDefined || users.get.isEmpty)\n+      // describe all users\n+      adminZkClient.fetchAllEntityConfigs(ConfigType.User).foreach { case (user, properties) => addToResults(user, properties) }\n+    else {\n+      // describe specific users\n+      // https://stackoverflow.com/questions/24729544/how-to-find-duplicates-in-a-list\n+      val duplicatedUsers = users.get.groupBy(identity).collect { case (x, Seq(_, _, _*)) => x }\n+      if (duplicatedUsers.nonEmpty) {\n+        retval.setError(Errors.INVALID_REQUEST.code())\n+        retval.setErrorMessage(s\"Cannot describe SCRAM credentials for the same user twice in a single request: ${duplicatedUsers.mkString(\"[\", \", \", \"]\")}\")\n+      } else\n+        users.get.foreach { user => addToResults(user, adminZkClient.fetchEntityConfig(ConfigType.User, Sanitizer.sanitize(user))) }\n+    }\n+    retval\n+  }\n+\n+  def alterUserScramCredentials(upsertions: Seq[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion],\n+                                deletions: Seq[AlterUserScramCredentialsRequestData.ScramCredentialDeletion]): AlterUserScramCredentialsResponseData = {\n+\n+    def scramMechanism(mechanism: Byte): ScramMechanism = {\n+      ScramMechanism.fromType(mechanism)\n+    }\n+\n+    def mechanismName(mechanism: Byte): String = {\n+      scramMechanism(mechanism).getMechanismName\n+    }\n+\n+    val retval = new AlterUserScramCredentialsResponseData()\n+\n+    // fail any user that is invalid due to an empty user name, an unknown SCRAM mechanism, or not enough iterations\n+    val invalidUsers = (\n+      upsertions.filter(upsertion => {\n+        if (upsertion.name.isEmpty)\n+          true\n+        else {\n+          val publicScramMechanism = scramMechanism(upsertion.mechanism)\n+          publicScramMechanism == ScramMechanism.UNKNOWN ||\n+            (upsertion.iterations != -1 &&\n+              InternalScramMechanism.forMechanismName(publicScramMechanism.getMechanismName).minIterations > upsertion.iterations)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDM0MzIyOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTo0NDoxMlrOG8YCKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTo0NDoxMlrOG8YCKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk2MTUxNA==", "bodyText": "I think we should also not allow users who authenticated using delegation tokens to create or update users. We don't allow these users to create new tokens, it would be odd if they could create a new user or the password of the user of the token.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r465961514", "createdAt": "2020-08-05T19:44:12Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -2973,6 +2975,40 @@ class KafkaApis(val requestChannel: RequestChannel,\n     }\n   }\n \n+  def handleDescribeUserScramCredentialsRequest(request: RequestChannel.Request): Unit = {\n+    val describeUserScramCredentialsRequest = request.body[DescribeUserScramCredentialsRequest]\n+\n+    if (!controller.isActive) {\n+      sendResponseMaybeThrottle(request, requestThrottleMs =>\n+        describeUserScramCredentialsRequest.getErrorResponse(requestThrottleMs, Errors.NOT_CONTROLLER.exception))\n+    } else if (authorize(request.context, DESCRIBE, CLUSTER, CLUSTER_NAME)) {\n+      val result = adminManager.describeUserScramCredentials(\n+        Option(describeUserScramCredentialsRequest.data.users.asScala.map(_.name).toList))\n+      sendResponseMaybeThrottle(request, requestThrottleMs =>\n+        new DescribeUserScramCredentialsResponse(result.setThrottleTimeMs(requestThrottleMs)))\n+    } else {\n+      sendResponseMaybeThrottle(request, requestThrottleMs =>\n+        describeUserScramCredentialsRequest.getErrorResponse(requestThrottleMs, Errors.CLUSTER_AUTHORIZATION_FAILED.exception))\n+    }\n+  }\n+\n+  def handleAlterUserScramCredentialsRequest(request: RequestChannel.Request): Unit = {\n+    val alterUserScramCredentialsRequest = request.body[AlterUserScramCredentialsRequest]\n+\n+    if (!controller.isActive) {\n+      sendResponseMaybeThrottle(request, requestThrottleMs =>\n+        alterUserScramCredentialsRequest.getErrorResponse(requestThrottleMs, Errors.NOT_CONTROLLER.exception))\n+    } else if (authorize(request.context, ALTER, CLUSTER, CLUSTER_NAME)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMjg3MzQ1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxMTowNDo1OFrOG-KHJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxOTozNzoxOVrOHEQdWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzgzMDU2Ng==", "bodyText": "Should we throw an exception for users which don't exist to be consistent with other APIs?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r467830566", "createdAt": "2020-08-10T11:04:58Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -1214,6 +1215,64 @@ default AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlterati\n      */\n     AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlteration> entries, AlterClientQuotasOptions options);\n \n+    /**\n+     * <p>Describe all SASL/SCRAM credentials.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @return The DescribeUserScramCredentialsResult.\n+     */\n+    default DescribeUserScramCredentialsResult describeUserScramCredentials() {\n+        return describeUserScramCredentials(null, new DescribeUserScramCredentialsOptions());\n+    }\n+\n+    /**\n+     * <p>Describe SASL/SCRAM credentials for the given users.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @param users the users for which credentials are to be described; all users' credentials are described if null\n+     *              or empty.  A user explicitly specified here that does not have a SCRAM credential will not appear\n+     *              in the results.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE0OTIzNg==", "bodyText": "Hmm, good question.  The KIP doesn't state what do do here.  @cmccabe thoughts?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468149236", "createdAt": "2020-08-10T20:01:58Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -1214,6 +1215,64 @@ default AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlterati\n      */\n     AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlteration> entries, AlterClientQuotasOptions options);\n \n+    /**\n+     * <p>Describe all SASL/SCRAM credentials.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @return The DescribeUserScramCredentialsResult.\n+     */\n+    default DescribeUserScramCredentialsResult describeUserScramCredentials() {\n+        return describeUserScramCredentials(null, new DescribeUserScramCredentialsOptions());\n+    }\n+\n+    /**\n+     * <p>Describe SASL/SCRAM credentials for the given users.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @param users the users for which credentials are to be described; all users' credentials are described if null\n+     *              or empty.  A user explicitly specified here that does not have a SCRAM credential will not appear\n+     *              in the results.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzgzMDU2Ng=="}, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MTQ1Mw==", "bodyText": "I originally was thinking we could just omit them.  But thinking about it more, I think we should have an error code to be consistent with our other APIs.  We'll need a new error code like USER_NOT_FOUND.  And we'll also need to add a per-user error code-- something we don't currently have.  But it shouldn't be too hard to do.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468871453", "createdAt": "2020-08-11T21:20:15Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -1214,6 +1215,64 @@ default AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlterati\n      */\n     AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlteration> entries, AlterClientQuotasOptions options);\n \n+    /**\n+     * <p>Describe all SASL/SCRAM credentials.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @return The DescribeUserScramCredentialsResult.\n+     */\n+    default DescribeUserScramCredentialsResult describeUserScramCredentials() {\n+        return describeUserScramCredentials(null, new DescribeUserScramCredentialsOptions());\n+    }\n+\n+    /**\n+     * <p>Describe SASL/SCRAM credentials for the given users.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @param users the users for which credentials are to be described; all users' credentials are described if null\n+     *              or empty.  A user explicitly specified here that does not have a SCRAM credential will not appear\n+     *              in the results.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzgzMDU2Ng=="}, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MTg4Nw==", "bodyText": "(Another advantage to having a per-user error code is that in the future, we may have more reasons why describing a user might fail, and these might be per-user)", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468871887", "createdAt": "2020-08-11T21:21:08Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -1214,6 +1215,64 @@ default AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlterati\n      */\n     AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlteration> entries, AlterClientQuotasOptions options);\n \n+    /**\n+     * <p>Describe all SASL/SCRAM credentials.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @return The DescribeUserScramCredentialsResult.\n+     */\n+    default DescribeUserScramCredentialsResult describeUserScramCredentials() {\n+        return describeUserScramCredentials(null, new DescribeUserScramCredentialsOptions());\n+    }\n+\n+    /**\n+     * <p>Describe SASL/SCRAM credentials for the given users.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @param users the users for which credentials are to be described; all users' credentials are described if null\n+     *              or empty.  A user explicitly specified here that does not have a SCRAM credential will not appear\n+     *              in the results.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzgzMDU2Ng=="}, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQ5NDg5MQ==", "bodyText": "@rondagostino : It still says \"A user explicitly specified here that does not have a SCRAM credential will not appear in the results\".  I thought we agreed that such a user would get an error code?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472494891", "createdAt": "2020-08-18T21:10:14Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -1214,6 +1215,64 @@ default AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlterati\n      */\n     AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlteration> entries, AlterClientQuotasOptions options);\n \n+    /**\n+     * <p>Describe all SASL/SCRAM credentials.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @return The DescribeUserScramCredentialsResult.\n+     */\n+    default DescribeUserScramCredentialsResult describeUserScramCredentials() {\n+        return describeUserScramCredentials(null, new DescribeUserScramCredentialsOptions());\n+    }\n+\n+    /**\n+     * <p>Describe SASL/SCRAM credentials for the given users.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @param users the users for which credentials are to be described; all users' credentials are described if null\n+     *              or empty.  A user explicitly specified here that does not have a SCRAM credential will not appear\n+     *              in the results.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzgzMDU2Ng=="}, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIyNjAxMQ==", "bodyText": "I reworked this Javadoc to list all possible exceptions for both alter and describe.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r474226011", "createdAt": "2020-08-20T19:37:19Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -1214,6 +1215,64 @@ default AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlterati\n      */\n     AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlteration> entries, AlterClientQuotasOptions options);\n \n+    /**\n+     * <p>Describe all SASL/SCRAM credentials.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @return The DescribeUserScramCredentialsResult.\n+     */\n+    default DescribeUserScramCredentialsResult describeUserScramCredentials() {\n+        return describeUserScramCredentials(null, new DescribeUserScramCredentialsOptions());\n+    }\n+\n+    /**\n+     * <p>Describe SASL/SCRAM credentials for the given users.\n+     *\n+     * <p>This is a convenience method for {@link #describeUserScramCredentials(List, DescribeUserScramCredentialsOptions)}\n+     *\n+     * @param users the users for which credentials are to be described; all users' credentials are described if null\n+     *              or empty.  A user explicitly specified here that does not have a SCRAM credential will not appear\n+     *              in the results.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzgzMDU2Ng=="}, "originalCommit": null, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMjk5NjIzOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramMechanism.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxMTo0NToyOVrOG-LOTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMDozNToyNFrOG-e3og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzg0ODc4MQ==", "bodyText": "We don't use get prefix elsewhere, just mechanismName()?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r467848781", "createdAt": "2020-08-10T11:45:29Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramMechanism.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+/**\n+ * Representation of a SASL/SCRAM Mechanism.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public enum ScramMechanism {\n+    UNKNOWN((byte) 0),\n+    SCRAM_SHA_256((byte) 1),\n+    SCRAM_SHA_512((byte) 2);\n+\n+    /**\n+     *\n+     * @param type the type indicator\n+     * @return the instance corresponding to the given type indicator, otherwise {@link #UNKNOWN}\n+     */\n+    public static ScramMechanism fromType(byte type) {\n+        for (ScramMechanism scramMechanism : ScramMechanism.values()) {\n+            if (scramMechanism.type == type) {\n+                return scramMechanism;\n+            }\n+        }\n+        return UNKNOWN;\n+    }\n+\n+    /**\n+     *\n+     * @param mechanismName the SASL SCRAM mechanism name\n+     * @return the corresponding SASL SCRAM mechanism enum, otherwise {@link #UNKNOWN}\n+     * @see <a href=\"https://tools.ietf.org/html/rfc5802#section-4>\n+     *     Salted Challenge Response Authentication Mechanism (SCRAM) SASL and GSS-API Mechanisms, Section 4</a>\n+     */\n+    public static ScramMechanism fromMechanismName(String mechanismName) {\n+        ScramMechanism retvalFoundMechanism = ScramMechanism.valueOf(mechanismName.replace('-', '_'));\n+        return retvalFoundMechanism != null ? retvalFoundMechanism : UNKNOWN;\n+    }\n+\n+    /**\n+     *\n+     * @return the corresponding SASL SCRAM mechanism name\n+     * @see <a href=\"https://tools.ietf.org/html/rfc5802#section-4>\n+     *     Salted Challenge Response Authentication Mechanism (SCRAM) SASL and GSS-API Mechanisms, Section 4</a>\n+     */\n+    public String getMechanismName() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE3MDY1OA==", "bodyText": "I made the changes here and also removed all get prefixes on getters within ScramCredentialInfo and UserScramCredential{Alteration,Deletion,Upsertion,Description}", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468170658", "createdAt": "2020-08-10T20:35:24Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramMechanism.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+/**\n+ * Representation of a SASL/SCRAM Mechanism.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public enum ScramMechanism {\n+    UNKNOWN((byte) 0),\n+    SCRAM_SHA_256((byte) 1),\n+    SCRAM_SHA_512((byte) 2);\n+\n+    /**\n+     *\n+     * @param type the type indicator\n+     * @return the instance corresponding to the given type indicator, otherwise {@link #UNKNOWN}\n+     */\n+    public static ScramMechanism fromType(byte type) {\n+        for (ScramMechanism scramMechanism : ScramMechanism.values()) {\n+            if (scramMechanism.type == type) {\n+                return scramMechanism;\n+            }\n+        }\n+        return UNKNOWN;\n+    }\n+\n+    /**\n+     *\n+     * @param mechanismName the SASL SCRAM mechanism name\n+     * @return the corresponding SASL SCRAM mechanism enum, otherwise {@link #UNKNOWN}\n+     * @see <a href=\"https://tools.ietf.org/html/rfc5802#section-4>\n+     *     Salted Challenge Response Authentication Mechanism (SCRAM) SASL and GSS-API Mechanisms, Section 4</a>\n+     */\n+    public static ScramMechanism fromMechanismName(String mechanismName) {\n+        ScramMechanism retvalFoundMechanism = ScramMechanism.valueOf(mechanismName.replace('-', '_'));\n+        return retvalFoundMechanism != null ? retvalFoundMechanism : UNKNOWN;\n+    }\n+\n+    /**\n+     *\n+     * @return the corresponding SASL SCRAM mechanism name\n+     * @see <a href=\"https://tools.ietf.org/html/rfc5802#section-4>\n+     *     Salted Challenge Response Authentication Mechanism (SCRAM) SASL and GSS-API Mechanisms, Section 4</a>\n+     */\n+    public String getMechanismName() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzg0ODc4MQ=="}, "originalCommit": null, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMjk5NzI1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramMechanism.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxMTo0NTo1NFrOG-LO6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxMTo0NTo1NFrOG-LO6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzg0ODkzOA==", "bodyText": "As before, type()?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r467848938", "createdAt": "2020-08-10T11:45:54Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramMechanism.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+/**\n+ * Representation of a SASL/SCRAM Mechanism.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public enum ScramMechanism {\n+    UNKNOWN((byte) 0),\n+    SCRAM_SHA_256((byte) 1),\n+    SCRAM_SHA_512((byte) 2);\n+\n+    /**\n+     *\n+     * @param type the type indicator\n+     * @return the instance corresponding to the given type indicator, otherwise {@link #UNKNOWN}\n+     */\n+    public static ScramMechanism fromType(byte type) {\n+        for (ScramMechanism scramMechanism : ScramMechanism.values()) {\n+            if (scramMechanism.type == type) {\n+                return scramMechanism;\n+            }\n+        }\n+        return UNKNOWN;\n+    }\n+\n+    /**\n+     *\n+     * @param mechanismName the SASL SCRAM mechanism name\n+     * @return the corresponding SASL SCRAM mechanism enum, otherwise {@link #UNKNOWN}\n+     * @see <a href=\"https://tools.ietf.org/html/rfc5802#section-4>\n+     *     Salted Challenge Response Authentication Mechanism (SCRAM) SASL and GSS-API Mechanisms, Section 4</a>\n+     */\n+    public static ScramMechanism fromMechanismName(String mechanismName) {\n+        ScramMechanism retvalFoundMechanism = ScramMechanism.valueOf(mechanismName.replace('-', '_'));\n+        return retvalFoundMechanism != null ? retvalFoundMechanism : UNKNOWN;\n+    }\n+\n+    /**\n+     *\n+     * @return the corresponding SASL SCRAM mechanism name\n+     * @see <a href=\"https://tools.ietf.org/html/rfc5802#section-4>\n+     *     Salted Challenge Response Authentication Mechanism (SCRAM) SASL and GSS-API Mechanisms, Section 4</a>\n+     */\n+    public String getMechanismName() {\n+        return this.mechanismName;\n+    }\n+\n+    /**\n+     *\n+     * @return the type indicator for this SASL SCRAM mechanism\n+     */\n+    public byte getType() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMzAwNDk2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialsDescription.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxMTo0ODozNlrOG-LThQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxMTo0ODozNlrOG-LThQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzg1MDExNw==", "bodyText": "Remove get prefix", "url": "https://github.com/apache/kafka/pull/9032#discussion_r467850117", "createdAt": "2020-08-10T11:48:36Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialsDescription.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+/**\n+ * Representation of all SASL/SCRAM credentials associated with a user that can be retrieved.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public class UserScramCredentialsDescription {\n+    private final String name;\n+    private final List<ScramCredentialInfo> infos;\n+\n+    /**\n+     *\n+     * @param name the required user name\n+     * @param infos the required SASL/SCRAM credential representations for the user\n+     */\n+    public UserScramCredentialsDescription(String name, List<ScramCredentialInfo> infos) {\n+        this.name = Objects.requireNonNull(name);\n+        this.infos = Collections.unmodifiableList(new ArrayList<>(Objects.requireNonNull(infos)));\n+    }\n+\n+    /**\n+     *\n+     * @return the user name\n+     */\n+    public String getName() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMzAwNjY3OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialsDescription.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxMTo0OToxMVrOG-LUfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxMTo0OToxMVrOG-LUfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzg1MDM2Nw==", "bodyText": "credentialInfos()?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r467850367", "createdAt": "2020-08-10T11:49:11Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialsDescription.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+/**\n+ * Representation of all SASL/SCRAM credentials associated with a user that can be retrieved.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public class UserScramCredentialsDescription {\n+    private final String name;\n+    private final List<ScramCredentialInfo> infos;\n+\n+    /**\n+     *\n+     * @param name the required user name\n+     * @param infos the required SASL/SCRAM credential representations for the user\n+     */\n+    public UserScramCredentialsDescription(String name, List<ScramCredentialInfo> infos) {\n+        this.name = Objects.requireNonNull(name);\n+        this.infos = Collections.unmodifiableList(new ArrayList<>(Objects.requireNonNull(infos)));\n+    }\n+\n+    /**\n+     *\n+     * @return the user name\n+     */\n+    public String getName() {\n+        return name;\n+    }\n+\n+    /**\n+     *\n+     * @return the unmodifiable list of SASL/SCRAM credential representations for the user\n+     */\n+    public List<ScramCredentialInfo> getInfos() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMzg3MjI0OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/server/AlterUserScramCredentialsRequestTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNToyNzo0NFrOG-TgiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMjozNzowN1rOG-iHZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NDUyMA==", "bodyText": "Do we test for empty password?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r467984520", "createdAt": "2020-08-10T15:27:44Z", "author": {"login": "rajinisivaram"}, "path": "core/src/test/scala/unit/kafka/server/AlterUserScramCredentialsRequestTest.scala", "diffHunk": "@@ -0,0 +1,387 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.server\n+\n+\n+import java.nio.charset.StandardCharsets\n+import java.util\n+import java.util.Properties\n+\n+import kafka.network.SocketServer\n+import kafka.security.authorizer.AclAuthorizer\n+import org.apache.kafka.clients.admin.ScramMechanism\n+import org.apache.kafka.common.acl.AclOperation\n+import org.apache.kafka.common.message.{AlterUserScramCredentialsRequestData, DescribeUserScramCredentialsRequestData}\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{AlterUserScramCredentialsRequest, AlterUserScramCredentialsResponse, DescribeUserScramCredentialsRequest, DescribeUserScramCredentialsResponse}\n+import org.apache.kafka.common.resource.ResourceType\n+import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.apache.kafka.server.authorizer.{Action, AuthorizableRequestContext, AuthorizationResult}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * Test AlterUserScramCredentialsRequest/Response API for the cases where either no credentials are altered\n+ * or failure is expected due to lack of authorization, sending the request to a non-controller broker, or some other issue.\n+ * Also tests the Alter and Describe APIs for the case where credentials are successfully altered/described.\n+ */\n+class AlterUserScramCredentialsRequestTest extends BaseRequestTest {\n+  override def brokerPropertyOverrides(properties: Properties): Unit = {\n+    properties.put(KafkaConfig.ControlledShutdownEnableProp, \"false\")\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[AlterCredentialsTest.TestAuthorizer].getName)\n+    properties.put(KafkaConfig.PrincipalBuilderClassProp, classOf[AlterCredentialsTest.TestPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    AlterCredentialsTest.principal = KafkaPrincipal.ANONYMOUS // default is to be authorized\n+    super.setUp()\n+  }\n+\n+  @Test\n+  def testAlterNothing(): Unit = {\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialDeletion])\n+        .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(0, results.size)\n+  }\n+\n+  @Test\n+  def testAlterNothingNotAuthorized(): Unit = {\n+    AlterCredentialsTest.principal = AlterCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialDeletion])\n+        .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(0, results.size)\n+  }\n+\n+  @Test\n+  def testAlterSomethingNotAuthorized(): Unit = {\n+    AlterCredentialsTest.principal = AlterCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)))\n+        .setUpsertions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_512.getType)))).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(2, results.size)\n+    assertTrue(\"Expected not authorized\",\n+      results.get(0).errorCode == Errors.CLUSTER_AUTHORIZATION_FAILED.code && results.get(1).errorCode == Errors.CLUSTER_AUTHORIZATION_FAILED.code)\n+  }\n+\n+  @Test\n+  def testAlterSameThingTwice(): Unit = {\n+    val deletion1 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+    val deletion2 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+    val upsertion1 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+      .setIterations(-1).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val upsertion2 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+      .setIterations(-1).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val requests = List (\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletion1, deletion1))\n+          .setUpsertions(util.Arrays.asList(upsertion2, upsertion2))).build(),\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletion1, deletion2))\n+          .setUpsertions(util.Arrays.asList(upsertion1, upsertion2))).build(),\n+    )\n+    requests.foreach(request => {\n+      val response = sendAlterUserScramCredentialsRequest(request)\n+      val results = response.data.results\n+      assertEquals(2, results.size)\n+      assertTrue(\"Expected error when altering the same credential twice in a single request\",\n+        results.get(0).errorCode == Errors.INVALID_REQUEST.code && results.get(1).errorCode == Errors.INVALID_REQUEST.code)\n+    })\n+  }\n+\n+  @Test\n+  def testAlterEmptyUser(): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIyMzg0Ng==", "bodyText": "Added a test for it in UserScramCredentialsCommandTest.  We can't test for it here because we get a salted password here, and I don't think it is possible for that to be an empty string and allow a successful SASL/SCRAM authentication.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468223846", "createdAt": "2020-08-10T22:37:07Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/unit/kafka/server/AlterUserScramCredentialsRequestTest.scala", "diffHunk": "@@ -0,0 +1,387 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.server\n+\n+\n+import java.nio.charset.StandardCharsets\n+import java.util\n+import java.util.Properties\n+\n+import kafka.network.SocketServer\n+import kafka.security.authorizer.AclAuthorizer\n+import org.apache.kafka.clients.admin.ScramMechanism\n+import org.apache.kafka.common.acl.AclOperation\n+import org.apache.kafka.common.message.{AlterUserScramCredentialsRequestData, DescribeUserScramCredentialsRequestData}\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{AlterUserScramCredentialsRequest, AlterUserScramCredentialsResponse, DescribeUserScramCredentialsRequest, DescribeUserScramCredentialsResponse}\n+import org.apache.kafka.common.resource.ResourceType\n+import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.apache.kafka.server.authorizer.{Action, AuthorizableRequestContext, AuthorizationResult}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * Test AlterUserScramCredentialsRequest/Response API for the cases where either no credentials are altered\n+ * or failure is expected due to lack of authorization, sending the request to a non-controller broker, or some other issue.\n+ * Also tests the Alter and Describe APIs for the case where credentials are successfully altered/described.\n+ */\n+class AlterUserScramCredentialsRequestTest extends BaseRequestTest {\n+  override def brokerPropertyOverrides(properties: Properties): Unit = {\n+    properties.put(KafkaConfig.ControlledShutdownEnableProp, \"false\")\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[AlterCredentialsTest.TestAuthorizer].getName)\n+    properties.put(KafkaConfig.PrincipalBuilderClassProp, classOf[AlterCredentialsTest.TestPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    AlterCredentialsTest.principal = KafkaPrincipal.ANONYMOUS // default is to be authorized\n+    super.setUp()\n+  }\n+\n+  @Test\n+  def testAlterNothing(): Unit = {\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialDeletion])\n+        .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(0, results.size)\n+  }\n+\n+  @Test\n+  def testAlterNothingNotAuthorized(): Unit = {\n+    AlterCredentialsTest.principal = AlterCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialDeletion])\n+        .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(0, results.size)\n+  }\n+\n+  @Test\n+  def testAlterSomethingNotAuthorized(): Unit = {\n+    AlterCredentialsTest.principal = AlterCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)))\n+        .setUpsertions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_512.getType)))).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(2, results.size)\n+    assertTrue(\"Expected not authorized\",\n+      results.get(0).errorCode == Errors.CLUSTER_AUTHORIZATION_FAILED.code && results.get(1).errorCode == Errors.CLUSTER_AUTHORIZATION_FAILED.code)\n+  }\n+\n+  @Test\n+  def testAlterSameThingTwice(): Unit = {\n+    val deletion1 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+    val deletion2 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+    val upsertion1 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+      .setIterations(-1).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val upsertion2 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+      .setIterations(-1).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val requests = List (\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletion1, deletion1))\n+          .setUpsertions(util.Arrays.asList(upsertion2, upsertion2))).build(),\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletion1, deletion2))\n+          .setUpsertions(util.Arrays.asList(upsertion1, upsertion2))).build(),\n+    )\n+    requests.foreach(request => {\n+      val response = sendAlterUserScramCredentialsRequest(request)\n+      val results = response.data.results\n+      assertEquals(2, results.size)\n+      assertTrue(\"Expected error when altering the same credential twice in a single request\",\n+        results.get(0).errorCode == Errors.INVALID_REQUEST.code && results.get(1).errorCode == Errors.INVALID_REQUEST.code)\n+    })\n+  }\n+\n+  @Test\n+  def testAlterEmptyUser(): Unit = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NDUyMA=="}, "originalCommit": null, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMzg3NDQwOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/server/AlterUserScramCredentialsRequestTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNToyODoxNlrOG-Th1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNToyODoxNlrOG-Th1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NDg1Mg==", "bodyText": "assertEquals so we know what the error was if test fails? (mutliple places)", "url": "https://github.com/apache/kafka/pull/9032#discussion_r467984852", "createdAt": "2020-08-10T15:28:16Z", "author": {"login": "rajinisivaram"}, "path": "core/src/test/scala/unit/kafka/server/AlterUserScramCredentialsRequestTest.scala", "diffHunk": "@@ -0,0 +1,387 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.server\n+\n+\n+import java.nio.charset.StandardCharsets\n+import java.util\n+import java.util.Properties\n+\n+import kafka.network.SocketServer\n+import kafka.security.authorizer.AclAuthorizer\n+import org.apache.kafka.clients.admin.ScramMechanism\n+import org.apache.kafka.common.acl.AclOperation\n+import org.apache.kafka.common.message.{AlterUserScramCredentialsRequestData, DescribeUserScramCredentialsRequestData}\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{AlterUserScramCredentialsRequest, AlterUserScramCredentialsResponse, DescribeUserScramCredentialsRequest, DescribeUserScramCredentialsResponse}\n+import org.apache.kafka.common.resource.ResourceType\n+import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.apache.kafka.server.authorizer.{Action, AuthorizableRequestContext, AuthorizationResult}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * Test AlterUserScramCredentialsRequest/Response API for the cases where either no credentials are altered\n+ * or failure is expected due to lack of authorization, sending the request to a non-controller broker, or some other issue.\n+ * Also tests the Alter and Describe APIs for the case where credentials are successfully altered/described.\n+ */\n+class AlterUserScramCredentialsRequestTest extends BaseRequestTest {\n+  override def brokerPropertyOverrides(properties: Properties): Unit = {\n+    properties.put(KafkaConfig.ControlledShutdownEnableProp, \"false\")\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[AlterCredentialsTest.TestAuthorizer].getName)\n+    properties.put(KafkaConfig.PrincipalBuilderClassProp, classOf[AlterCredentialsTest.TestPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    AlterCredentialsTest.principal = KafkaPrincipal.ANONYMOUS // default is to be authorized\n+    super.setUp()\n+  }\n+\n+  @Test\n+  def testAlterNothing(): Unit = {\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialDeletion])\n+        .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(0, results.size)\n+  }\n+\n+  @Test\n+  def testAlterNothingNotAuthorized(): Unit = {\n+    AlterCredentialsTest.principal = AlterCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialDeletion])\n+        .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(0, results.size)\n+  }\n+\n+  @Test\n+  def testAlterSomethingNotAuthorized(): Unit = {\n+    AlterCredentialsTest.principal = AlterCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)))\n+        .setUpsertions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_512.getType)))).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(2, results.size)\n+    assertTrue(\"Expected not authorized\",\n+      results.get(0).errorCode == Errors.CLUSTER_AUTHORIZATION_FAILED.code && results.get(1).errorCode == Errors.CLUSTER_AUTHORIZATION_FAILED.code)\n+  }\n+\n+  @Test\n+  def testAlterSameThingTwice(): Unit = {\n+    val deletion1 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+    val deletion2 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+    val upsertion1 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+      .setIterations(-1).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val upsertion2 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_256.getType)\n+      .setIterations(-1).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val requests = List (\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletion1, deletion1))\n+          .setUpsertions(util.Arrays.asList(upsertion2, upsertion2))).build(),\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletion1, deletion2))\n+          .setUpsertions(util.Arrays.asList(upsertion1, upsertion2))).build(),\n+    )\n+    requests.foreach(request => {\n+      val response = sendAlterUserScramCredentialsRequest(request)\n+      val results = response.data.results\n+      assertEquals(2, results.size)\n+      assertTrue(\"Expected error when altering the same credential twice in a single request\",\n+        results.get(0).errorCode == Errors.INVALID_REQUEST.code && results.get(1).errorCode == Errors.INVALID_REQUEST.code)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyNDAzMTk5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramCredentialInfo.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNTo1Njo1NFrOG-VFQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMDoxMDoxMVrOG-dzeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAxMDMwNw==", "bodyText": "or -1?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468010307", "createdAt": "2020-08-10T15:56:54Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramCredentialInfo.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import java.util.Objects;\n+\n+/**\n+ * Mechanism and iterations for a SASL/SCRAM credential associated with a user.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public class ScramCredentialInfo {\n+    private final ScramMechanism mechanism;\n+    private final int iterations;\n+\n+    /**\n+     *\n+     * @param mechanism the required mechanism\n+     * @param iterations the number of iterations used when creating the credential\n+     */\n+    public ScramCredentialInfo(ScramMechanism mechanism, int iterations) {\n+        this.mechanism = Objects.requireNonNull(mechanism);\n+        this.iterations = iterations;\n+    }\n+\n+    /**\n+     *\n+     * @return the mechanism\n+     */\n+    public ScramMechanism getMechanism() {\n+        return mechanism;\n+    }\n+\n+    /**\n+     *\n+     * @return the number of iterations used when creating the credential", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE1MzIxMA==", "bodyText": "TBD.  No change needed if we are getting rid of -1 as a special value.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468153210", "createdAt": "2020-08-10T20:10:11Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/ScramCredentialInfo.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import java.util.Objects;\n+\n+/**\n+ * Mechanism and iterations for a SASL/SCRAM credential associated with a user.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public class ScramCredentialInfo {\n+    private final ScramMechanism mechanism;\n+    private final int iterations;\n+\n+    /**\n+     *\n+     * @param mechanism the required mechanism\n+     * @param iterations the number of iterations used when creating the credential\n+     */\n+    public ScramCredentialInfo(ScramMechanism mechanism, int iterations) {\n+        this.mechanism = Objects.requireNonNull(mechanism);\n+        this.iterations = iterations;\n+    }\n+\n+    /**\n+     *\n+     * @return the mechanism\n+     */\n+    public ScramMechanism getMechanism() {\n+        return mechanism;\n+    }\n+\n+    /**\n+     *\n+     * @return the number of iterations used when creating the credential", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAxMDMwNw=="}, "originalCommit": null, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyNDE1OTIxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNjoyOToyM1rOG-WSYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNDozODoxMlrOG-7DRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAzMDA0OQ==", "bodyText": "Iterations can be -1 here? Won't we end up sending a password without applying the salt properly?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468030049", "createdAt": "2020-08-10T16:29:23Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.fromType(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new InvalidRequestException(\"Unknown SCRAM mechanism\"));\n+            }\n+        });\n+        // Creating an upsertion may throw InvalidKeyException or NoSuchAlgorithmException,\n+        // so keep track of which users are affected by such a failure and immediately fail all their alterations\n+        final Map<String, Map<ScramMechanism, AlterUserScramCredentialsRequestData.ScramCredentialUpsertion>> userInsertions = new HashMap<>();\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialUpsertion)\n+                .filter(alteration -> !userIllegalAlterationExceptions.containsKey(alteration.getUser()))\n+                .forEach(alteration -> {\n+                    UserScramCredentialUpsertion upsertion = (UserScramCredentialUpsertion) alteration;\n+                    String user = upsertion.getUser();\n+                    try {\n+                        ScramMechanism mechanism = upsertion.getInfo().getMechanism();\n+                        if (mechanism == null || mechanism == ScramMechanism.UNKNOWN)\n+                            throw new InvalidRequestException(\"Unknown SCRAM mechanism\");\n+                        userInsertions.putIfAbsent(user, new HashMap<>());\n+                        userInsertions.get(user).put(mechanism, getScramCredentialUpsertion(upsertion));\n+                    } catch (Exception e) {\n+                        // we might overwrite an exception from a previous upsertion, but we don't really care\n+                        // since we just need to mark this user as having at least one illegal alteration\n+                        // and make an exception instance available for completing the corresponding future exceptionally\n+                        userIllegalAlterationExceptions.put(user, e);\n+                    }\n+                });\n+        // fail any users immediately that have an illegal alteration as identified above\n+        userIllegalAlterationExceptions.entrySet().stream().forEach(entry -> {\n+            futures.get(entry.getKey()).completeExceptionally(entry.getValue());\n+        });\n+\n+        // submit alterations for users that do not have an illegal upsertion as identified above\n+        Call call = new Call(\"alterUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public AlterUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new AlterUserScramCredentialsRequest.Builder(\n+                        new AlterUserScramCredentialsRequestData().setUpsertions(alterations.stream()\n+                                .filter(a -> a instanceof UserScramCredentialUpsertion)\n+                                .filter(a -> !userIllegalAlterationExceptions.containsKey(a.getUser()))\n+                                .map(a -> userInsertions.get(a.getUser()).get(((UserScramCredentialUpsertion) a).getInfo().getMechanism()))\n+                                .collect(Collectors.toList()))\n+                        .setDeletions(alterations.stream()\n+                                .filter(a -> a instanceof UserScramCredentialDeletion)\n+                                .filter(a -> !userIllegalAlterationExceptions.containsKey(a.getUser()))\n+                                .map(d ->\n+                                getScramCredentialDeletion((UserScramCredentialDeletion) d)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                AlterUserScramCredentialsResponse response = (AlterUserScramCredentialsResponse) abstractResponse;\n+                // Check for controller change\n+                for (Errors error : response.errorCounts().keySet()) {\n+                    if (error == Errors.NOT_CONTROLLER) {\n+                        handleNotControllerError(error);\n+                    }\n+                }\n+                response.data().results().forEach(result -> {\n+                    KafkaFutureImpl<Void> future = futures.get(result.user());\n+                    if (future == null) {\n+                        log.warn(\"Server response mentioned unknown user {}\", result.user());\n+                    } else {\n+                        Errors error = Errors.forCode(result.errorCode());\n+                        if (error != Errors.NONE) {\n+                            future.completeExceptionally(error.exception(result.errorMessage()));\n+                        } else {\n+                            future.complete(null);\n+                        }\n+                    }\n+                });\n+                completeUnrealizedFutures(\n+                    futures.entrySet().stream(),\n+                    user -> \"The broker response did not contain a result for user \" + user);\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                completeAllExceptionally(futures.values(), throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new AlterUserScramCredentialsResult(new HashMap<>(futures));\n+    }\n+\n+    private static AlterUserScramCredentialsRequestData.ScramCredentialUpsertion getScramCredentialUpsertion(UserScramCredentialUpsertion u) throws InvalidKeyException, NoSuchAlgorithmException {\n+        AlterUserScramCredentialsRequestData.ScramCredentialUpsertion retval = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion();\n+        return retval.setName(u.getUser())\n+                .setMechanism(u.getInfo().getMechanism().getType())\n+                .setIterations(u.getInfo().getIterations())\n+                .setSalt(u.getSalt())\n+                .setSaltedPassword(getSaltedPasword(u.getInfo().getMechanism(), u.getPassword(), u.getSalt(), u.getInfo().getIterations()));\n+    }\n+\n+    private static AlterUserScramCredentialsRequestData.ScramCredentialDeletion getScramCredentialDeletion(UserScramCredentialDeletion d) {\n+        return new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(d.getUser()).setMechanism(d.getMechanism().getType());\n+    }\n+\n+    private static byte[] getSaltedPasword(ScramMechanism publicScramMechanism, byte[] password, byte[] salt, int iterations) throws NoSuchAlgorithmException, InvalidKeyException {\n+        return new ScramFormatter(org.apache.kafka.common.security.scram.internals.ScramMechanism.forMechanismName(publicScramMechanism.getMechanismName()))\n+                .hi(password, salt, iterations);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 215}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE1MjExMw==", "bodyText": "Yeah, I think there is a fundamental problem with allowing the value -1 for iterations.  The KIP says \"Note that if the number of iterations is set to -1, the server-side default will be used.\". But we are on the client at this point in the code, and there is no concept for \"server-side default\" for SCRAM iterations in Kafka.  And unfortunately since we are salting the password here, we need to know the number of iterations.  So I think we need to do either of the following:\n\nAdd an ability to define server-side default number of iterations per SASL/SCRAM mechanism in Kafka and allow clients to learn them.\nGet rid of -1 as a special value.\n\nIt's pretty clear to me that (2) is the way to go, but @rajinisivaram and @cmccabe please chime in.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468152113", "createdAt": "2020-08-10T20:07:51Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.fromType(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new InvalidRequestException(\"Unknown SCRAM mechanism\"));\n+            }\n+        });\n+        // Creating an upsertion may throw InvalidKeyException or NoSuchAlgorithmException,\n+        // so keep track of which users are affected by such a failure and immediately fail all their alterations\n+        final Map<String, Map<ScramMechanism, AlterUserScramCredentialsRequestData.ScramCredentialUpsertion>> userInsertions = new HashMap<>();\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialUpsertion)\n+                .filter(alteration -> !userIllegalAlterationExceptions.containsKey(alteration.getUser()))\n+                .forEach(alteration -> {\n+                    UserScramCredentialUpsertion upsertion = (UserScramCredentialUpsertion) alteration;\n+                    String user = upsertion.getUser();\n+                    try {\n+                        ScramMechanism mechanism = upsertion.getInfo().getMechanism();\n+                        if (mechanism == null || mechanism == ScramMechanism.UNKNOWN)\n+                            throw new InvalidRequestException(\"Unknown SCRAM mechanism\");\n+                        userInsertions.putIfAbsent(user, new HashMap<>());\n+                        userInsertions.get(user).put(mechanism, getScramCredentialUpsertion(upsertion));\n+                    } catch (Exception e) {\n+                        // we might overwrite an exception from a previous upsertion, but we don't really care\n+                        // since we just need to mark this user as having at least one illegal alteration\n+                        // and make an exception instance available for completing the corresponding future exceptionally\n+                        userIllegalAlterationExceptions.put(user, e);\n+                    }\n+                });\n+        // fail any users immediately that have an illegal alteration as identified above\n+        userIllegalAlterationExceptions.entrySet().stream().forEach(entry -> {\n+            futures.get(entry.getKey()).completeExceptionally(entry.getValue());\n+        });\n+\n+        // submit alterations for users that do not have an illegal upsertion as identified above\n+        Call call = new Call(\"alterUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public AlterUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new AlterUserScramCredentialsRequest.Builder(\n+                        new AlterUserScramCredentialsRequestData().setUpsertions(alterations.stream()\n+                                .filter(a -> a instanceof UserScramCredentialUpsertion)\n+                                .filter(a -> !userIllegalAlterationExceptions.containsKey(a.getUser()))\n+                                .map(a -> userInsertions.get(a.getUser()).get(((UserScramCredentialUpsertion) a).getInfo().getMechanism()))\n+                                .collect(Collectors.toList()))\n+                        .setDeletions(alterations.stream()\n+                                .filter(a -> a instanceof UserScramCredentialDeletion)\n+                                .filter(a -> !userIllegalAlterationExceptions.containsKey(a.getUser()))\n+                                .map(d ->\n+                                getScramCredentialDeletion((UserScramCredentialDeletion) d)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                AlterUserScramCredentialsResponse response = (AlterUserScramCredentialsResponse) abstractResponse;\n+                // Check for controller change\n+                for (Errors error : response.errorCounts().keySet()) {\n+                    if (error == Errors.NOT_CONTROLLER) {\n+                        handleNotControllerError(error);\n+                    }\n+                }\n+                response.data().results().forEach(result -> {\n+                    KafkaFutureImpl<Void> future = futures.get(result.user());\n+                    if (future == null) {\n+                        log.warn(\"Server response mentioned unknown user {}\", result.user());\n+                    } else {\n+                        Errors error = Errors.forCode(result.errorCode());\n+                        if (error != Errors.NONE) {\n+                            future.completeExceptionally(error.exception(result.errorMessage()));\n+                        } else {\n+                            future.complete(null);\n+                        }\n+                    }\n+                });\n+                completeUnrealizedFutures(\n+                    futures.entrySet().stream(),\n+                    user -> \"The broker response did not contain a result for user \" + user);\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                completeAllExceptionally(futures.values(), throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new AlterUserScramCredentialsResult(new HashMap<>(futures));\n+    }\n+\n+    private static AlterUserScramCredentialsRequestData.ScramCredentialUpsertion getScramCredentialUpsertion(UserScramCredentialUpsertion u) throws InvalidKeyException, NoSuchAlgorithmException {\n+        AlterUserScramCredentialsRequestData.ScramCredentialUpsertion retval = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion();\n+        return retval.setName(u.getUser())\n+                .setMechanism(u.getInfo().getMechanism().getType())\n+                .setIterations(u.getInfo().getIterations())\n+                .setSalt(u.getSalt())\n+                .setSaltedPassword(getSaltedPasword(u.getInfo().getMechanism(), u.getPassword(), u.getSalt(), u.getInfo().getIterations()));\n+    }\n+\n+    private static AlterUserScramCredentialsRequestData.ScramCredentialDeletion getScramCredentialDeletion(UserScramCredentialDeletion d) {\n+        return new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(d.getUser()).setMechanism(d.getMechanism().getType());\n+    }\n+\n+    private static byte[] getSaltedPasword(ScramMechanism publicScramMechanism, byte[] password, byte[] salt, int iterations) throws NoSuchAlgorithmException, InvalidKeyException {\n+        return new ScramFormatter(org.apache.kafka.common.security.scram.internals.ScramMechanism.forMechanismName(publicScramMechanism.getMechanismName()))\n+                .hi(password, salt, iterations);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAzMDA0OQ=="}, "originalCommit": null, "originalPosition": 215}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODYzMjM4OA==", "bodyText": "Agree that we should just get rid of -1.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468632388", "createdAt": "2020-08-11T14:38:12Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -4071,6 +4081,168 @@ void handleFailure(Throwable throwable) {\n         return new AlterClientQuotasResult(Collections.unmodifiableMap(futures));\n     }\n \n+    @Override\n+    public DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users, DescribeUserScramCredentialsOptions options) {\n+        final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> future = new KafkaFutureImpl<>();\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public DescribeUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new DescribeUserScramCredentialsRequest.Builder(\n+                        new DescribeUserScramCredentialsRequestData().setUsers(users.stream().map(user ->\n+                                new DescribeUserScramCredentialsRequestData.UserName().setName(user)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                DescribeUserScramCredentialsResponse response = (DescribeUserScramCredentialsResponse) abstractResponse;\n+                Errors error = Errors.forCode(response.data().error());\n+                switch (error) {\n+                    case NONE:\n+                        DescribeUserScramCredentialsResponseData data = response.data();\n+                        future.complete(data.userScramCredentials().stream().collect(Collectors.toMap(\n+                            DescribeUserScramCredentialsResponseData.UserScramCredential::name,\n+                            userScramCredential -> {\n+                                List<ScramCredentialInfo> scramCredentialInfos = userScramCredential.credentialInfos().stream().map(\n+                                    credentialInfo -> new ScramCredentialInfo(ScramMechanism.fromType(credentialInfo.mechanism()), credentialInfo.iterations()))\n+                                        .collect(Collectors.toList());\n+                                return new UserScramCredentialsDescription(userScramCredential.name(), scramCredentialInfos);\n+                            })));\n+                        break;\n+                    case NOT_CONTROLLER:\n+                        handleNotControllerError(error);\n+                        break;\n+                    default:\n+                        future.completeExceptionally(new ApiError(error, response.data().errorMessage()).exception());\n+                        break;\n+                }\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                future.completeExceptionally(throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new DescribeUserScramCredentialsResult(future);\n+    }\n+\n+    @Override\n+    public AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations,\n+                                                                     AlterUserScramCredentialsOptions options) {\n+        final long now = time.milliseconds();\n+        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>();\n+        for (UserScramCredentialAlteration alteration: alterations) {\n+            futures.put(alteration.getUser(), new KafkaFutureImpl<>());\n+        }\n+        final Map<String, Exception> userIllegalAlterationExceptions = new HashMap<>();\n+        // We need to keep track of users with deletions of an unknown SCRAM mechanism\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialDeletion).forEach(alteration -> {\n+            UserScramCredentialDeletion deletion = (UserScramCredentialDeletion) alteration;\n+            ScramMechanism mechanism = deletion.getMechanism();\n+            if (mechanism == null || mechanism == ScramMechanism.UNKNOWN) {\n+                userIllegalAlterationExceptions.put(deletion.getUser(), new InvalidRequestException(\"Unknown SCRAM mechanism\"));\n+            }\n+        });\n+        // Creating an upsertion may throw InvalidKeyException or NoSuchAlgorithmException,\n+        // so keep track of which users are affected by such a failure and immediately fail all their alterations\n+        final Map<String, Map<ScramMechanism, AlterUserScramCredentialsRequestData.ScramCredentialUpsertion>> userInsertions = new HashMap<>();\n+        alterations.stream().filter(a -> a instanceof UserScramCredentialUpsertion)\n+                .filter(alteration -> !userIllegalAlterationExceptions.containsKey(alteration.getUser()))\n+                .forEach(alteration -> {\n+                    UserScramCredentialUpsertion upsertion = (UserScramCredentialUpsertion) alteration;\n+                    String user = upsertion.getUser();\n+                    try {\n+                        ScramMechanism mechanism = upsertion.getInfo().getMechanism();\n+                        if (mechanism == null || mechanism == ScramMechanism.UNKNOWN)\n+                            throw new InvalidRequestException(\"Unknown SCRAM mechanism\");\n+                        userInsertions.putIfAbsent(user, new HashMap<>());\n+                        userInsertions.get(user).put(mechanism, getScramCredentialUpsertion(upsertion));\n+                    } catch (Exception e) {\n+                        // we might overwrite an exception from a previous upsertion, but we don't really care\n+                        // since we just need to mark this user as having at least one illegal alteration\n+                        // and make an exception instance available for completing the corresponding future exceptionally\n+                        userIllegalAlterationExceptions.put(user, e);\n+                    }\n+                });\n+        // fail any users immediately that have an illegal alteration as identified above\n+        userIllegalAlterationExceptions.entrySet().stream().forEach(entry -> {\n+            futures.get(entry.getKey()).completeExceptionally(entry.getValue());\n+        });\n+\n+        // submit alterations for users that do not have an illegal upsertion as identified above\n+        Call call = new Call(\"alterUserScramCredentials\", calcDeadlineMs(now, options.timeoutMs()),\n+                new ControllerNodeProvider()) {\n+            @Override\n+            public AlterUserScramCredentialsRequest.Builder createRequest(int timeoutMs) {\n+                return new AlterUserScramCredentialsRequest.Builder(\n+                        new AlterUserScramCredentialsRequestData().setUpsertions(alterations.stream()\n+                                .filter(a -> a instanceof UserScramCredentialUpsertion)\n+                                .filter(a -> !userIllegalAlterationExceptions.containsKey(a.getUser()))\n+                                .map(a -> userInsertions.get(a.getUser()).get(((UserScramCredentialUpsertion) a).getInfo().getMechanism()))\n+                                .collect(Collectors.toList()))\n+                        .setDeletions(alterations.stream()\n+                                .filter(a -> a instanceof UserScramCredentialDeletion)\n+                                .filter(a -> !userIllegalAlterationExceptions.containsKey(a.getUser()))\n+                                .map(d ->\n+                                getScramCredentialDeletion((UserScramCredentialDeletion) d)).collect(Collectors.toList())));\n+            }\n+\n+            @Override\n+            public void handleResponse(AbstractResponse abstractResponse) {\n+                AlterUserScramCredentialsResponse response = (AlterUserScramCredentialsResponse) abstractResponse;\n+                // Check for controller change\n+                for (Errors error : response.errorCounts().keySet()) {\n+                    if (error == Errors.NOT_CONTROLLER) {\n+                        handleNotControllerError(error);\n+                    }\n+                }\n+                response.data().results().forEach(result -> {\n+                    KafkaFutureImpl<Void> future = futures.get(result.user());\n+                    if (future == null) {\n+                        log.warn(\"Server response mentioned unknown user {}\", result.user());\n+                    } else {\n+                        Errors error = Errors.forCode(result.errorCode());\n+                        if (error != Errors.NONE) {\n+                            future.completeExceptionally(error.exception(result.errorMessage()));\n+                        } else {\n+                            future.complete(null);\n+                        }\n+                    }\n+                });\n+                completeUnrealizedFutures(\n+                    futures.entrySet().stream(),\n+                    user -> \"The broker response did not contain a result for user \" + user);\n+            }\n+\n+            @Override\n+            void handleFailure(Throwable throwable) {\n+                completeAllExceptionally(futures.values(), throwable);\n+            }\n+        };\n+        runnable.call(call, now);\n+        return new AlterUserScramCredentialsResult(new HashMap<>(futures));\n+    }\n+\n+    private static AlterUserScramCredentialsRequestData.ScramCredentialUpsertion getScramCredentialUpsertion(UserScramCredentialUpsertion u) throws InvalidKeyException, NoSuchAlgorithmException {\n+        AlterUserScramCredentialsRequestData.ScramCredentialUpsertion retval = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion();\n+        return retval.setName(u.getUser())\n+                .setMechanism(u.getInfo().getMechanism().getType())\n+                .setIterations(u.getInfo().getIterations())\n+                .setSalt(u.getSalt())\n+                .setSaltedPassword(getSaltedPasword(u.getInfo().getMechanism(), u.getPassword(), u.getSalt(), u.getInfo().getIterations()));\n+    }\n+\n+    private static AlterUserScramCredentialsRequestData.ScramCredentialDeletion getScramCredentialDeletion(UserScramCredentialDeletion d) {\n+        return new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(d.getUser()).setMechanism(d.getMechanism().getType());\n+    }\n+\n+    private static byte[] getSaltedPasword(ScramMechanism publicScramMechanism, byte[] password, byte[] salt, int iterations) throws NoSuchAlgorithmException, InvalidKeyException {\n+        return new ScramFormatter(org.apache.kafka.common.security.scram.internals.ScramMechanism.forMechanismName(publicScramMechanism.getMechanismName()))\n+                .hi(password, salt, iterations);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAzMDA0OQ=="}, "originalCommit": null, "originalPosition": 215}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyOTU4MDI3OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "isResolved": true, "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMToyMjo1OFrOG_JuHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxOTo1Mjo1OVrOHERE_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw==", "bodyText": "If we're going to have a per-user error, then we need Map<String, KafkaFuture<...>>.  This will also be useful if we need to add more per-user errors in the future.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468872733", "createdAt": "2020-08-11T21:22:58Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTY4MDcwMg==", "bodyText": "Now that I'm working on this, I discovered that there is no other API that can describe or list everything that works this way.  Everything that can describe or list everything returns a single future.  Every describe or list API that returns a map of keys to futures requires a non-empty list of keys to describe or list.  For example:\n\nlistTopics() lists all topics and returns a single Future; the describeTopics() API returns a map of names to futures but requires a non-empty list of topics to describe.\ndescribeConfigs() returns a map of resources to futures but requires a non-empty list of resources to describe.\ndescribeLogDirs() returns a map of broker IDs to futures but requires a non-empty list of brokers to describe.\ndescribeReplicaLogDirs() returns a map of replicas to futures but requires a non-empty list of replicas to describe.\ndescribeConsumerGroups() returns a map of consumer groups to futures but requires a non-empty list of consumer groups to describe.\nlistPartitionReassignments() allows listing all or a subset of reassignments and returns a single future.\nlistOffsets() returns a map of topic-partitions to futures but requires a non-empty list of topic-partitions to describe.\ndescribeClientQuotas() allows listing all or a subset of quotas and returns a single future.\n\nI think if we made this change here we would be off the beaten path.  That's not necessarily bad, but what tipped me off to this was the fact that when we list everything we have to create a future for every user that gets returned, and we don't know that list of users when we make the request, so there's really no way to implement it.\nWe could create two separate APIs: one for describing some explicit, non-empty list of users, which would return a map of users to futures, and another one that describes everything, which returns a single future.  listTopics() vs describeTopics() works this way, for example, though the information returned in the two is very different: when listing you just get the names, and when describing you get a lot more.  I don't see us distinguishing between listing vs. describing in terms of data -- we are going to send back the same two things (mechanism and iterations) regardless.  So we would probably be talking about creating a describeUserScramCredentials() API and a describeAllUserScramCredentials() API with the first taking a list and returning a map of futures and the second not taking a list and returning a single future.\nBut I'm thinking we should just keep it the way it is -- take a possibly-empty list and return a single future regardles of whether the list was empty or not.\nThoughts?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r469680702", "createdAt": "2020-08-13T03:52:24Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDEwMTU5OQ==", "bodyText": "I don't see the need for multiple futures; everything is returning in a single response from Kafka, and I can't think of why it would be necessary to have some users' credential descriptions available to the API caller but others not.  I'll take a look at keeping a single future for the response but moving the error status from the top level down into each per-user result.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r470101599", "createdAt": "2020-08-13T17:09:29Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDMzOTczNw==", "bodyText": "I kept the top-level error information but added per-user error information in addition.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r470339737", "createdAt": "2020-08-14T00:45:20Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwNzk0Nw==", "bodyText": "Thinking about this more, I would prefer having both a list RPC to show everything, and a describe RPC to show only some things.  There are a few reasons why.  One is that even though we currently only make one RPC, in the future we might make more than one.  In that case we would want multiple futures.\nAnother is that the general pattern in Kafka is that list RPCs show everything, but describe RPCs show only some things.  It's true that there are some places where we violate this pattern, but I still think it's worth trying to follow where we can.  Maybe this should be documented better so that when we add new RPCs, people aren't confused about whether to use \"list\" or \"describe.\"\nI also feel like in AdminClient, errors should be handled with futures pretty much all the time, unless there is a really strong reason not to.  This allows people to use an async style of programming.  In contrast, mixing in some errors that aren't futures, but need to be checked explicitly is very likely to confuse people.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472507947", "createdAt": "2020-08-18T21:38:12Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU3MDgyMw==", "bodyText": "a list RPC to show everything, and a describe RPC to show only some things.\n\nDo you mean a list RPC that takes no arguments and returns every credential defined for every user and a describe RPC that takes 1 or more users and returns every credential defined for those specified users, and they both return the same information for each credential?\nOr do you mean a list RPC and a describe RPC that return different sets of information (as is done with list vs. describe topics)?  I think you mean the former (two RPCs, each returning the same thing), but I want to be certain I understand.\n\nThere are a few reasons why. One is that even though we currently only make one RPC, in the future we might make more than one. In that case we would want multiple futures.\n\nI don't understand what this is referring to.  By \"we currently only make one RPC\" to what are you referring?\n\nI also feel like in AdminClient, errors should be handled with futures pretty much all the time\n\nAgreed.  Will convert to using futures always, whenever we arrive at the final decision on what the RPCs need to look like.\nI'm wondering if we convert to returning futures everywhere, can we stick with the one describe RPC?  For example, could the admin client return a Future<Map<String, Future<UserScramCredentialDescription>>>?  Would that work, and if so, would that be a reasonable way to proceed?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472570823", "createdAt": "2020-08-19T00:45:44Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU3NDU2OQ==", "bodyText": "If we do decide to go with 2 separate APIs, then I might be concerned about using list() vs describe() if they return the same set of information (i.e. mechanism and iterations).  Perhaps using two separate names gives us room to expand describe() to return more information later on, though.  But if not, and they will always return the same information, then maybe describeAll() and describe() (or listAll() and list()) might be better?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472574569", "createdAt": "2020-08-19T00:59:40Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU3NTMyNg==", "bodyText": "I can see reasonable arguments for all the possibilities, so if you feel strongly about one of them then I would be fine with it.  For example, list() and describe() even though they return the same thing (now -- describe() could return more later potentially).  Just let me know.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472575326", "createdAt": "2020-08-19T01:02:25Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjY4ODkyNg==", "bodyText": "I thought about this more and I think I see a good way out of this difficulty.  We should just have an accessor method like userInfo(String name) that returns a KafkaFuture<user info>.  We can dynamically create this future if needed.  Then we can have a single RPC and a single API which is just describe", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472688926", "createdAt": "2020-08-19T04:48:02Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjk0Nzg1Mg==", "bodyText": "Ok, I think I follow now.  You are saying that we could potentially implement describe by invoking 1+N requests to Kafka: one to get the list of credentials (either the list of all of them if we are asking for them all, or the explicitly requested ones we wanted), and then another N requests to get the data for each one.  This on the surface seems like an anti-pattern, but it is not unreasonable for the case where the data is expensive to get in the first place \u2014 maybe we are forced to make 1 or more round-trips for each anyway.  So as a general, reusable pattern, yes, I believe it works.\nSo when we invoke describe, whether it is describe-all or just an explicit few, we return a single future, and that future returns a list of instances (UserName in this case): either 1 instance for each user that has at least 1 credential for the describe-all case, or one instance per distinct user explicitly requested otherwise.  Then each UserName instance has the accessor you mentioned, which in this case returns  Future.\nDo I have that right?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472947852", "createdAt": "2020-08-19T11:08:33Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIzNjE1OQ==", "bodyText": "Ok, we have two levels of Futures now:\n\nDescribeUserScramCredentialsResult has a KafkaFuture<List<UserScramCredentialsDescriptionResult>>\nUserScramCredentialsDescriptionResult has a user name and a KafkaFuture<UserScramCredentialsDescription>\n\nI think this is where we want to end up.  Let me know if you agree.  I also added some logic in AlterUserScramCredentialsRequestTest to confirm the behavior of the per-user futures and associated errors.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r474236159", "createdAt": "2020-08-20T19:52:59Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<Map<String, UserScramCredentialsDescription>> future;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjczMw=="}, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyOTYwMzY2OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/admin/UserScramCredentialsCommandTest.scala", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTozMDo1MVrOG_J8aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QwMTo1MDo0NlrOG_5LdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3NjM5NQ==", "bodyText": "How does this interact with JUnit running tests concurrently?  cc @ijuma @hachikuji", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468876395", "createdAt": "2020-08-11T21:30:51Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/unit/kafka/admin/UserScramCredentialsCommandTest.scala", "diffHunk": "@@ -0,0 +1,127 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.admin\n+\n+import java.io.{ByteArrayOutputStream, PrintStream}\n+import java.nio.charset.StandardCharsets\n+\n+import kafka.server.BaseRequestTest\n+import kafka.utils.Exit\n+import org.junit.Assert._\n+import org.junit.Test\n+\n+class UserScramCredentialsCommandTest extends BaseRequestTest {\n+  override def brokerCount = 1\n+  var exitStatus: Option[Int] = None\n+  var exitMessage: Option[String] = None\n+\n+  case class ConfigCommandResult(stdout: String, exitStatus: Option[Int] = None)\n+\n+  private def runConfigCommandViaBroker(args: Array[String]) : ConfigCommandResult = {\n+    val byteArrayOutputStream = new ByteArrayOutputStream()\n+    val utf8 = StandardCharsets.UTF_8.name\n+    val printStream = new PrintStream(byteArrayOutputStream, true, utf8)\n+    var exitStatus: Option[Int] = None\n+    Exit.setExitProcedure { (status, _) =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTY0Njc3Nw==", "bodyText": "Hmm, good point, I think there may be a problem here in general because there is only a single exit procedure that can be set globally, and multiple tests that set/reset it in parallel will collide.  There are 16 Scala test classes in core out of 260 that do this -- so 6% of test classes.  So I think this will introduce some flakiness to these 16 tests.  Does this sound correct to you, and should we open a separate ticket for this as opposed to trying to fix it here?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r469646777", "createdAt": "2020-08-13T01:37:22Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/unit/kafka/admin/UserScramCredentialsCommandTest.scala", "diffHunk": "@@ -0,0 +1,127 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.admin\n+\n+import java.io.{ByteArrayOutputStream, PrintStream}\n+import java.nio.charset.StandardCharsets\n+\n+import kafka.server.BaseRequestTest\n+import kafka.utils.Exit\n+import org.junit.Assert._\n+import org.junit.Test\n+\n+class UserScramCredentialsCommandTest extends BaseRequestTest {\n+  override def brokerCount = 1\n+  var exitStatus: Option[Int] = None\n+  var exitMessage: Option[String] = None\n+\n+  case class ConfigCommandResult(stdout: String, exitStatus: Option[Int] = None)\n+\n+  private def runConfigCommandViaBroker(args: Array[String]) : ConfigCommandResult = {\n+    val byteArrayOutputStream = new ByteArrayOutputStream()\n+    val utf8 = StandardCharsets.UTF_8.name\n+    val printStream = new PrintStream(byteArrayOutputStream, true, utf8)\n+    var exitStatus: Option[Int] = None\n+    Exit.setExitProcedure { (status, _) =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3NjM5NQ=="}, "originalCommit": null, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTY1MDI5Mw==", "bodyText": "Actually, I think this may not be an issue since parallel tests in Gradle run in separate processes rather than separate threads.  From https://docs.gradle.org/current/dsl/org.gradle.api.tasks.testing.Test.html: \"Test are always run in (one or more) separate JVMs.\"", "url": "https://github.com/apache/kafka/pull/9032#discussion_r469650293", "createdAt": "2020-08-13T01:50:46Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/unit/kafka/admin/UserScramCredentialsCommandTest.scala", "diffHunk": "@@ -0,0 +1,127 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.admin\n+\n+import java.io.{ByteArrayOutputStream, PrintStream}\n+import java.nio.charset.StandardCharsets\n+\n+import kafka.server.BaseRequestTest\n+import kafka.utils.Exit\n+import org.junit.Assert._\n+import org.junit.Test\n+\n+class UserScramCredentialsCommandTest extends BaseRequestTest {\n+  override def brokerCount = 1\n+  var exitStatus: Option[Int] = None\n+  var exitMessage: Option[String] = None\n+\n+  case class ConfigCommandResult(stdout: String, exitStatus: Option[Int] = None)\n+\n+  private def runConfigCommandViaBroker(args: Array[String]) : ConfigCommandResult = {\n+    val byteArrayOutputStream = new ByteArrayOutputStream()\n+    val utf8 = StandardCharsets.UTF_8.name\n+    val printStream = new PrintStream(byteArrayOutputStream, true, utf8)\n+    var exitStatus: Option[Int] = None\n+    Exit.setExitProcedure { (status, _) =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3NjM5NQ=="}, "originalCommit": null, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyOTYzODg5OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/server/DescribeUserScramCredentialsRequestTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTo0MzoyNVrOG_KRqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QwMDo0MToxNFrOG_3y6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg4MTgzMg==", "bodyText": "It's kind of a code smell to be mutating static data during a JUnit test.  There are ways to run JUnit tests in parallel (although I think our current setup only runs at the granularity of test classes, not test methods?)  At the very least we'd have to document that this is not thread-safe and that it will prevent us from parellelizing this test class in the future.\nRather than doing this, how about having two separate test authorizers, and choosing the one you want for each individual JUnit test method?\nIn order to fit this into our bass-akwards inheritance based test design ( :( ) you could check the name of the test in brokerPropertyOverrides using one of these methods: https://stackoverflow.com/questions/473401/get-name-of-currently-executing-test-in-junit-4", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468881832", "createdAt": "2020-08-11T21:43:25Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/unit/kafka/server/DescribeUserScramCredentialsRequestTest.scala", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.server\n+\n+import java.util\n+import java.util.Properties\n+\n+import kafka.network.SocketServer\n+import kafka.security.authorizer.AclAuthorizer\n+import org.apache.kafka.common.acl.AclOperation\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsRequestData\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsRequestData.UserName\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{DescribeUserScramCredentialsRequest, DescribeUserScramCredentialsResponse}\n+import org.apache.kafka.common.resource.ResourceType\n+import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.apache.kafka.server.authorizer.{Action, AuthorizableRequestContext, AuthorizationResult}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * Test DescribeUserScramCredentialsRequest/Response API for the cases where no credentials exist\n+ * or failure is expected due to lack of authorization, sending the request to a non-controller broker, or some other issue.\n+ * Testing the API for the case where there are actually credentials to describe is performed elsewhere.\n+ */\n+class DescribeUserScramCredentialsRequestTest extends BaseRequestTest {\n+  override def brokerPropertyOverrides(properties: Properties): Unit = {\n+    properties.put(KafkaConfig.ControlledShutdownEnableProp, \"false\")\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[DescribeCredentialsTest.TestAuthorizer].getName)\n+    properties.put(KafkaConfig.PrincipalBuilderClassProp, classOf[DescribeCredentialsTest.TestPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    DescribeCredentialsTest.principal = KafkaPrincipal.ANONYMOUS // default is to be authorized\n+    super.setUp()\n+  }\n+\n+  @Test\n+  def testDescribeNothing(): Unit = {\n+    val request = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData()).build()\n+    val response = sendDescribeUserScramCredentialsRequest(request)\n+\n+    val error = response.data.error\n+    assertEquals(\"Expected no error when routed correctly\", Errors.NONE.code, error)\n+    assertEquals(\"Expected no credentials\", 0, response.data.userScramCredentials.size)\n+  }\n+\n+  @Test\n+  def testDescribeNotController(): Unit = {\n+    val request = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData()).build()\n+    val response = sendDescribeUserScramCredentialsRequest(request, notControllerSocketServer)\n+\n+    val error = response.data.error\n+    assertEquals(\"Expected controller error when routed incorrectly\", Errors.NOT_CONTROLLER.code, error)\n+  }\n+\n+  @Test\n+  def testDescribeNotAuthorized(): Unit = {\n+    DescribeCredentialsTest.principal = DescribeCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData()).build()\n+    val response = sendDescribeUserScramCredentialsRequest(request)\n+\n+    val error = response.data.error\n+    assertEquals(\"Expected not authorized error\", Errors.CLUSTER_AUTHORIZATION_FAILED.code, error)\n+  }\n+\n+  @Test\n+  def testDescribeSameUserTwice(): Unit = {\n+    val user = new UserName().setName(\"user1\")\n+    val request = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData().setUsers(List(user, user).asJava)).build()\n+    val response = sendDescribeUserScramCredentialsRequest(request)\n+\n+    val error = response.data.error\n+    assertEquals(\"Expected invalid request error\", Errors.INVALID_REQUEST.code, error)\n+  }\n+\n+\n+  private def sendDescribeUserScramCredentialsRequest(request: DescribeUserScramCredentialsRequest, socketServer: SocketServer = controllerSocketServer): DescribeUserScramCredentialsResponse = {\n+    connectAndReceive[DescribeUserScramCredentialsResponse](request, destination = socketServer)\n+  }\n+}\n+\n+object DescribeCredentialsTest {\n+  val UnauthorizedPrincipal = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"Unauthorized\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTYyNzYyNA==", "bodyText": "@cmccabe Thanks.  I copied this approach from kafka.server.RequestQuotaTest.  I fixed it here in DesrcibeUserScramCredentialsRequestTest and AlterUserScramCredentialsRequestTest but was unable to fix it in RequestQuotaTest because that test is checking every possible API, and of course certain APIs need to succeed for Kafka to start successfully.  So that test needs to mutate the behavior after setUp().  These tests don't since these APIs aren't necessary for Kafka to start.  So I was able to fix it here but was unable to fix it where I got the approach from.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r469627624", "createdAt": "2020-08-13T00:41:14Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/unit/kafka/server/DescribeUserScramCredentialsRequestTest.scala", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.server\n+\n+import java.util\n+import java.util.Properties\n+\n+import kafka.network.SocketServer\n+import kafka.security.authorizer.AclAuthorizer\n+import org.apache.kafka.common.acl.AclOperation\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsRequestData\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsRequestData.UserName\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{DescribeUserScramCredentialsRequest, DescribeUserScramCredentialsResponse}\n+import org.apache.kafka.common.resource.ResourceType\n+import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.apache.kafka.server.authorizer.{Action, AuthorizableRequestContext, AuthorizationResult}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * Test DescribeUserScramCredentialsRequest/Response API for the cases where no credentials exist\n+ * or failure is expected due to lack of authorization, sending the request to a non-controller broker, or some other issue.\n+ * Testing the API for the case where there are actually credentials to describe is performed elsewhere.\n+ */\n+class DescribeUserScramCredentialsRequestTest extends BaseRequestTest {\n+  override def brokerPropertyOverrides(properties: Properties): Unit = {\n+    properties.put(KafkaConfig.ControlledShutdownEnableProp, \"false\")\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[DescribeCredentialsTest.TestAuthorizer].getName)\n+    properties.put(KafkaConfig.PrincipalBuilderClassProp, classOf[DescribeCredentialsTest.TestPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    DescribeCredentialsTest.principal = KafkaPrincipal.ANONYMOUS // default is to be authorized\n+    super.setUp()\n+  }\n+\n+  @Test\n+  def testDescribeNothing(): Unit = {\n+    val request = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData()).build()\n+    val response = sendDescribeUserScramCredentialsRequest(request)\n+\n+    val error = response.data.error\n+    assertEquals(\"Expected no error when routed correctly\", Errors.NONE.code, error)\n+    assertEquals(\"Expected no credentials\", 0, response.data.userScramCredentials.size)\n+  }\n+\n+  @Test\n+  def testDescribeNotController(): Unit = {\n+    val request = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData()).build()\n+    val response = sendDescribeUserScramCredentialsRequest(request, notControllerSocketServer)\n+\n+    val error = response.data.error\n+    assertEquals(\"Expected controller error when routed incorrectly\", Errors.NOT_CONTROLLER.code, error)\n+  }\n+\n+  @Test\n+  def testDescribeNotAuthorized(): Unit = {\n+    DescribeCredentialsTest.principal = DescribeCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData()).build()\n+    val response = sendDescribeUserScramCredentialsRequest(request)\n+\n+    val error = response.data.error\n+    assertEquals(\"Expected not authorized error\", Errors.CLUSTER_AUTHORIZATION_FAILED.code, error)\n+  }\n+\n+  @Test\n+  def testDescribeSameUserTwice(): Unit = {\n+    val user = new UserName().setName(\"user1\")\n+    val request = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData().setUsers(List(user, user).asJava)).build()\n+    val response = sendDescribeUserScramCredentialsRequest(request)\n+\n+    val error = response.data.error\n+    assertEquals(\"Expected invalid request error\", Errors.INVALID_REQUEST.code, error)\n+  }\n+\n+\n+  private def sendDescribeUserScramCredentialsRequest(request: DescribeUserScramCredentialsRequest, socketServer: SocketServer = controllerSocketServer): DescribeUserScramCredentialsResponse = {\n+    connectAndReceive[DescribeUserScramCredentialsResponse](request, destination = socketServer)\n+  }\n+}\n+\n+object DescribeCredentialsTest {\n+  val UnauthorizedPrincipal = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"Unauthorized\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg4MTgzMg=="}, "originalCommit": null, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyOTY0NDU0OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/server/AlterUserScramCredentialsRequestTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTo0NToxN1rOG_KU9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTo0NToxN1rOG_KU9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg4MjY3Ng==", "bodyText": "Same comment applies here as in the describe test: don't mutate static data.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468882676", "createdAt": "2020-08-11T21:45:17Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/unit/kafka/server/AlterUserScramCredentialsRequestTest.scala", "diffHunk": "@@ -0,0 +1,396 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.server\n+\n+\n+import java.nio.charset.StandardCharsets\n+import java.util\n+import java.util.Properties\n+\n+import kafka.network.SocketServer\n+import kafka.security.authorizer.AclAuthorizer\n+import org.apache.kafka.clients.admin.ScramMechanism\n+import org.apache.kafka.common.acl.AclOperation\n+import org.apache.kafka.common.message.{AlterUserScramCredentialsRequestData, DescribeUserScramCredentialsRequestData}\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{AlterUserScramCredentialsRequest, AlterUserScramCredentialsResponse, DescribeUserScramCredentialsRequest, DescribeUserScramCredentialsResponse}\n+import org.apache.kafka.common.resource.ResourceType\n+import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.apache.kafka.server.authorizer.{Action, AuthorizableRequestContext, AuthorizationResult}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * Test AlterUserScramCredentialsRequest/Response API for the cases where either no credentials are altered\n+ * or failure is expected due to lack of authorization, sending the request to a non-controller broker, or some other issue.\n+ * Also tests the Alter and Describe APIs for the case where credentials are successfully altered/described.\n+ */\n+class AlterUserScramCredentialsRequestTest extends BaseRequestTest {\n+  override def brokerPropertyOverrides(properties: Properties): Unit = {\n+    properties.put(KafkaConfig.ControlledShutdownEnableProp, \"false\")\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[AlterCredentialsTest.TestAuthorizer].getName)\n+    properties.put(KafkaConfig.PrincipalBuilderClassProp, classOf[AlterCredentialsTest.TestPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    AlterCredentialsTest.principal = KafkaPrincipal.ANONYMOUS // default is to be authorized\n+    super.setUp()\n+  }\n+\n+  @Test\n+  def testAlterNothing(): Unit = {\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialDeletion])\n+        .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(0, results.size)\n+  }\n+\n+  @Test\n+  def testAlterNothingNotAuthorized(): Unit = {\n+    AlterCredentialsTest.principal = AlterCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialDeletion])\n+        .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(0, results.size)\n+  }\n+\n+  @Test\n+  def testAlterSomethingNotAuthorized(): Unit = {\n+    AlterCredentialsTest.principal = AlterCredentialsTest.UnauthorizedPrincipal\n+\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)))\n+        .setUpsertions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_512.`type`)))).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(2, results.size)\n+    val msg = \"Expected not authorized\"\n+    assertEquals(msg, Errors.CLUSTER_AUTHORIZATION_FAILED.code, results.get(0).errorCode)\n+    assertEquals(msg, Errors.CLUSTER_AUTHORIZATION_FAILED.code, results.get(1).errorCode)\n+  }\n+\n+  @Test\n+  def testAlterSameThingTwice(): Unit = {\n+    val deletion1 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)\n+    val deletion2 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)\n+    val upsertion1 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)\n+      .setIterations(4096).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val upsertion2 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)\n+      .setIterations(4096).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val requests = List (\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletion1, deletion1))\n+          .setUpsertions(util.Arrays.asList(upsertion2, upsertion2))).build(),\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletion1, deletion2))\n+          .setUpsertions(util.Arrays.asList(upsertion1, upsertion2))).build(),\n+    )\n+    requests.foreach(request => {\n+      val response = sendAlterUserScramCredentialsRequest(request)\n+      val results = response.data.results\n+      assertEquals(2, results.size)\n+      val msg = \"Expected error when altering the same credential twice in a single request\"\n+      assertEquals(msg, Errors.INVALID_REQUEST.code, results.get(0).errorCode)\n+      assertEquals(msg, Errors.INVALID_REQUEST.code, results.get(1).errorCode)\n+    })\n+  }\n+\n+  @Test\n+  def testAlterEmptyUser(): Unit = {\n+    val deletionEmpty = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"\").setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)\n+    val upsertionEmpty = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"\").setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)\n+      .setIterations(4096).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val requests = List (\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletionEmpty))\n+          .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build(),\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialDeletion])\n+          .setUpsertions(util.Arrays.asList(upsertionEmpty))).build(),\n+      new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletionEmpty, deletionEmpty))\n+          .setUpsertions(util.Arrays.asList(upsertionEmpty))).build(),\n+    )\n+    requests.foreach(request => {\n+      val response = sendAlterUserScramCredentialsRequest(request)\n+      val results = response.data.results\n+      assertEquals(1, results.size)\n+      assertEquals(\"Expected error when altering an empty user\", Errors.INVALID_REQUEST.code, results.get(0).errorCode)\n+      assertEquals(\"\\\"\\\" is an illegal user name\", results.get(0).errorMessage)\n+    })\n+  }\n+\n+  private val user1 = \"user1\"\n+  private val user2 = \"user2\"\n+\n+  @Test\n+  def testAlterUnknownMechanism(): Unit = {\n+    val deletionUnknown1 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(user1).setMechanism(ScramMechanism.UNKNOWN.`type`)\n+    val deletionValid1 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(user1).setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)\n+    val deletionUnknown2 = new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(user2).setMechanism(10.toByte)\n+    val user3 = \"user3\"\n+    val upsertionUnknown3 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(user3).setMechanism(ScramMechanism.UNKNOWN.`type`)\n+      .setIterations(8192).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val upsertionValid3 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(user3).setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)\n+      .setIterations(8192).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val user4 = \"user4\"\n+    val upsertionUnknown4 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(user4).setMechanism(10.toByte)\n+      .setIterations(8192).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val user5 = \"user5\"\n+    val upsertionUnknown5 = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(user5).setMechanism(ScramMechanism.UNKNOWN.`type`)\n+      .setIterations(8192).setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+        new AlterUserScramCredentialsRequestData()\n+          .setDeletions(util.Arrays.asList(deletionUnknown1, deletionValid1, deletionUnknown2))\n+          .setUpsertions(util.Arrays.asList(upsertionUnknown3, upsertionValid3, upsertionUnknown4, upsertionUnknown5))).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+    val results = response.data.results\n+    assertEquals(5, results.size)\n+    assertEquals(\"Expected error when altering the credentials with unknown SCRAM mechanisms\",\n+      0, results.asScala.filterNot(_.errorCode == Errors.INVALID_REQUEST.code).size)\n+    results.asScala.foreach(result => assertEquals(\"Unknown SCRAM mechanism\", result.errorMessage))\n+  }\n+\n+  @Test\n+  def testAlterTooFewIterations(): Unit = {\n+    val upsertionTooFewIterations = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(user1)\n+      .setMechanism(ScramMechanism.SCRAM_SHA_256.`type`).setIterations(1)\n+      .setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Collections.emptyList())\n+        .setUpsertions(util.Arrays.asList(upsertionTooFewIterations))).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+    val results = response.data.results\n+    assertEquals(1, results.size)\n+    assertEquals(\"Expected error when altering the credentials with too few iterations\",\n+      0, results.asScala.filterNot(_.errorCode == Errors.INVALID_REQUEST.code).size)\n+    assertEquals(\"Too few iterations\", results.get(0).errorMessage)\n+  }\n+\n+  @Test\n+  def testAlterTooManyIterations(): Unit = {\n+    val upsertionTooFewIterations = new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(user1)\n+      .setMechanism(ScramMechanism.SCRAM_SHA_256.`type`).setIterations(Integer.MAX_VALUE)\n+      .setSalt(\"salt\".getBytes).setSaltedPassword(\"saltedPassword\".getBytes)\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Collections.emptyList())\n+        .setUpsertions(util.Arrays.asList(upsertionTooFewIterations))).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+    val results = response.data.results\n+    assertEquals(1, results.size)\n+    assertEquals(\"Expected error when altering the credentials with too many iterations\",\n+      0, results.asScala.filterNot(_.errorCode == Errors.INVALID_REQUEST.code).size)\n+    assertEquals(\"Too many iterations\", results.get(0).errorMessage)\n+  }\n+\n+  @Test\n+  def testDeleteSomethingThatDoesNotExist(): Unit = {\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)))\n+        .setUpsertions(new util.ArrayList[AlterUserScramCredentialsRequestData.ScramCredentialUpsertion])).build()\n+    val response = sendAlterUserScramCredentialsRequest(request)\n+\n+    val results = response.data.results\n+    assertEquals(1, results.size)\n+    assertEquals(\"Expected error when deleting a non-existing credential\", Errors.RESOURCE_NOT_FOUND.code, results.get(0).errorCode)\n+  }\n+\n+  @Test\n+  def testAlterNotController(): Unit = {\n+    val request = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialDeletion().setName(\"name1\").setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)))\n+        .setUpsertions(util.Arrays.asList(new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion().setName(\"name2\").setMechanism(ScramMechanism.SCRAM_SHA_512.`type`)))).build()\n+    val response = sendAlterUserScramCredentialsRequest(request, notControllerSocketServer)\n+\n+    val results = response.data.results\n+    assertEquals(2, results.size)\n+    val msg = \"Expected controller error when routed incorrectly\"\n+    assertEquals(msg, Errors.NOT_CONTROLLER.code, results.get(0).errorCode)\n+    assertEquals(msg, Errors.NOT_CONTROLLER.code, results.get(1).errorCode)\n+  }\n+\n+  @Test\n+  def testAlterAndDescribe(): Unit = {\n+    // create a bunch of credentials\n+    val request1 = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setUpsertions(util.Arrays.asList(\n+          new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion()\n+            .setName(user1).setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)\n+            .setIterations(4096)\n+            .setSalt(\"salt\".getBytes(StandardCharsets.UTF_8))\n+            .setSaltedPassword(\"saltedPassword\".getBytes(StandardCharsets.UTF_8)),\n+          new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion()\n+            .setName(user1).setMechanism(ScramMechanism.SCRAM_SHA_512.`type`)\n+            .setIterations(8192)\n+            .setSalt(\"salt\".getBytes(StandardCharsets.UTF_8))\n+            .setSaltedPassword(\"saltedPassword\".getBytes(StandardCharsets.UTF_8)),\n+          new AlterUserScramCredentialsRequestData.ScramCredentialUpsertion()\n+            .setName(user2).setMechanism(ScramMechanism.SCRAM_SHA_512.`type`)\n+            .setIterations(8192)\n+            .setSalt(\"salt\".getBytes(StandardCharsets.UTF_8))\n+            .setSaltedPassword(\"saltedPassword\".getBytes(StandardCharsets.UTF_8)),\n+        ))).build()\n+    val response1 = sendAlterUserScramCredentialsRequest(request1)\n+    val results1 = response1.data.results\n+    assertEquals(2, results1.size)\n+    assertEquals(\"Expected no error when creating the credentials\",\n+      0, results1.asScala.filterNot(_.errorCode == Errors.NONE.code).size)\n+    assertTrue(results1.asScala.exists(_.user == user1))\n+    assertTrue(results1.asScala.exists(_.user == user2))\n+    // now describe them all\n+    val request2 = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData()).build()\n+    val response2 = sendDescribeUserScramCredentialsRequest(request2)\n+    assertEquals(\"Expected no error when describing the credentials\",\n+      Errors.NONE.code, response2.data.error)\n+    val results2 = response2.data.userScramCredentials\n+    assertEquals(2, results2.size)\n+    assertTrue(s\"Expected result to contain '$user1' with 2 credentials: $results2\",\n+      results2.asScala.exists(usc => usc.name == user1 && usc.credentialInfos.size == 2))\n+    assertTrue(s\"Expected result to contain '$user2' with 1 credential: $results2\",\n+      results2.asScala.exists(usc => usc.name == user2 && usc.credentialInfos.size == 1))\n+    assertTrue(s\"Expected result to contain '$user1' with SCRAM_SHA_256/4096 and SCRAM_SHA_512/8192 credentials: $results2\",\n+      results2.asScala.exists(usc => usc.name == user1 && usc.credentialInfos.asScala.exists(info =>\n+        info.mechanism == ScramMechanism.SCRAM_SHA_256.`type` && info.iterations == 4096)\n+        && usc.credentialInfos.asScala.exists(info =>\n+        info.mechanism == ScramMechanism.SCRAM_SHA_512.`type` && info.iterations == 8192)))\n+    assertTrue(s\"Expected result to contain '$user2' with SCRAM_SHA_512/8192 credential: $results2\",\n+      results2.asScala.exists(usc => usc.name == user2 && usc.credentialInfos.asScala.exists(info =>\n+        info.mechanism == ScramMechanism.SCRAM_SHA_512.`type` && info.iterations == 8192)))\n+    // now describe just one\n+    val request3 = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData().setUsers(util.Arrays.asList(\n+        new DescribeUserScramCredentialsRequestData.UserName().setName(user1)))).build()\n+    val response3 = sendDescribeUserScramCredentialsRequest(request3)\n+    assertEquals(\"Expected no error when describing the credentials\",Errors.NONE.code, response3.data.error)\n+    val results3 = response3.data.userScramCredentials\n+    assertEquals(1, results3.size)\n+    assertTrue(s\"Expected result to contain '$user1' with 2 credentials: $results3\",\n+      results3.asScala.exists(usc => usc.name == user1 && usc.credentialInfos.size == 2))\n+    assertTrue(s\"Expected result to contain '$user1' with SCRAM_SHA_256/4096 and SCRAM_SHA_512/8192 credentials: $results3\",\n+      results3.asScala.exists(usc => usc.name == user1 && usc.credentialInfos.asScala.exists(info =>\n+        info.mechanism == ScramMechanism.SCRAM_SHA_256.`type` && info.iterations == 4096)\n+        && usc.credentialInfos.asScala.exists(info =>\n+        info.mechanism == ScramMechanism.SCRAM_SHA_512.`type` && info.iterations == 8192)))\n+    // now delete a couple of credentials\n+    val request4 = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Arrays.asList(\n+          new AlterUserScramCredentialsRequestData.ScramCredentialDeletion()\n+            .setName(user1).setMechanism(ScramMechanism.SCRAM_SHA_256.`type`),\n+          new AlterUserScramCredentialsRequestData.ScramCredentialDeletion()\n+            .setName(user2).setMechanism(ScramMechanism.SCRAM_SHA_512.`type`),\n+        ))).build()\n+    val response4 = sendAlterUserScramCredentialsRequest(request4)\n+    val results4 = response4.data.results\n+    assertEquals(2, results4.size)\n+    assertEquals(\"Expected no error when deleting the credentials\",\n+      0, results4.asScala.filterNot(_.errorCode == Errors.NONE.code).size)\n+    assertTrue(s\"Expected result to contain '$user1'\", results4.asScala.exists(_.user == user1))\n+    assertTrue(s\"Expected result to contain '$user2'\", results4.asScala.exists(_.user == user2))\n+    // now describe them all, which should just yield 1 credential\n+    val request5 = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData()).build()\n+    val response5 = sendDescribeUserScramCredentialsRequest(request5)\n+    assertEquals(\"Expected no error when describing the credentials\", Errors.NONE.code, response5.data.error)\n+    val results5 = response5.data.userScramCredentials\n+    assertEquals(1, results5.size)\n+    assertTrue(s\"Expected result to contain '$user1' with 1 credential: $results5\",\n+      results5.asScala.exists(usc => usc.name == user1 && usc.credentialInfos.size == 1))\n+    assertTrue(s\"Expected result to contain '$user1' with SCRAM_SHA_512/8192 credential: $results5\",\n+      results5.asScala.exists(usc => usc.name == user1 && usc.credentialInfos.asScala.exists(info =>\n+        info.mechanism == ScramMechanism.SCRAM_SHA_512.`type` && info.iterations == 8192)))\n+    // now delete the last one\n+    val request6 = new AlterUserScramCredentialsRequest.Builder(\n+      new AlterUserScramCredentialsRequestData()\n+        .setDeletions(util.Arrays.asList(\n+          new AlterUserScramCredentialsRequestData.ScramCredentialDeletion()\n+            .setName(user1).setMechanism(ScramMechanism.SCRAM_SHA_512.`type`),\n+        ))).build()\n+    val response6 = sendAlterUserScramCredentialsRequest(request6)\n+    val results6 = response6.data.results\n+    assertEquals(1, results6.size)\n+    assertEquals(\"Expected no error when deleting the credentials\",\n+      0, results4.asScala.filterNot(_.errorCode == Errors.NONE.code).size)\n+    assertTrue(s\"Expected result to contain '$user1'\", results6.asScala.exists(_.user == user1))\n+    // now describe them all, which should yield 0 credentials\n+    val request7 = new DescribeUserScramCredentialsRequest.Builder(\n+      new DescribeUserScramCredentialsRequestData()).build()\n+    val response7 = sendDescribeUserScramCredentialsRequest(request7)\n+    assertEquals(\"Expected no error when describing the credentials\",\n+      Errors.NONE.code, response7.data.error)\n+    val results7 = response7.data.userScramCredentials\n+    assertEquals(0, results7.size)\n+  }\n+\n+  private def sendAlterUserScramCredentialsRequest(request: AlterUserScramCredentialsRequest, socketServer: SocketServer = controllerSocketServer): AlterUserScramCredentialsResponse = {\n+    connectAndReceive[AlterUserScramCredentialsResponse](request, destination = socketServer)\n+  }\n+\n+  private def sendDescribeUserScramCredentialsRequest(request: DescribeUserScramCredentialsRequest, socketServer: SocketServer = controllerSocketServer): DescribeUserScramCredentialsResponse = {\n+    connectAndReceive[DescribeUserScramCredentialsResponse](request, destination = socketServer)\n+  }\n+}\n+\n+object AlterCredentialsTest {\n+  val UnauthorizedPrincipal = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"Unauthorized\")\n+  // Principal used for all client connections. This is modified by tests which\n+  // check unauthorized code path\n+  var principal = KafkaPrincipal.ANONYMOUS", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 377}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyOTY1NjY5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/errors/ResourceNotFoundException.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTo0OTo0N1rOG_KcQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTo0OTo0N1rOG_KcQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg4NDU0NQ==", "bodyText": "We've always set serialVersionUID in exception classes, to appease the Java gods.\n    private static final long serialVersionUID = 1L;\n\nit's not really necessary since we don't plan on using Java's built-in serialization framework, but I think some tools complain if they don't see it.  And anyway, it's the pattern... for now.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468884545", "createdAt": "2020-08-11T21:49:47Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/common/errors/ResourceNotFoundException.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.errors;\n+\n+/**\n+ * Exception thrown due to a request for a resource that does not exist.\n+ */\n+public class ResourceNotFoundException extends ApiException {\n+    private final String resource;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyOTY2NTE4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialUpsertion.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTo1MjozM1rOG_KhIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMDo0NDoyMFrOHAjN1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg4NTc5NQ==", "bodyText": "I think we can avoid a trip through BigInteger with something like this:\n      SecureRandom random = new SecureRandom();\n      byte bytes[] = new byte[length];\n      random.nextBytes(bytes);", "url": "https://github.com/apache/kafka/pull/9032#discussion_r468885795", "createdAt": "2020-08-11T21:52:33Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialUpsertion.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import java.math.BigInteger;\n+import java.nio.charset.StandardCharsets;\n+import java.security.SecureRandom;\n+import java.util.Objects;\n+\n+/**\n+ * A request to update/insert a SASL/SCRAM credential for a user.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public class UserScramCredentialUpsertion extends UserScramCredentialAlteration {\n+    private final ScramCredentialInfo info;\n+    private final byte[] salt;\n+    private final byte[] password;\n+\n+    /**\n+     * Constructor that generates a random salt\n+     *\n+     * @param user the user for which the credential is to be updated/inserted\n+     * @param credentialInfo the mechanism and iterations to be used\n+     * @param password the password\n+     */\n+    public UserScramCredentialUpsertion(String user, ScramCredentialInfo credentialInfo, String password) {\n+        this(user, credentialInfo, password.getBytes(StandardCharsets.UTF_8));\n+    }\n+\n+    /**\n+     * Constructor that generates a random salt\n+     *\n+     * @param user the user for which the credential is to be updated/inserted\n+     * @param credentialInfo the mechanism and iterations to be used\n+     * @param password the password\n+     */\n+    public UserScramCredentialUpsertion(String user, ScramCredentialInfo credentialInfo, byte[] password) {\n+        this(user, credentialInfo, password, generateRandomSalt());\n+    }\n+\n+    /**\n+     * Constructor that accepts an explicit salt\n+     *\n+     * @param user the user for which the credential is to be updated/inserted\n+     * @param credentialInfo the mechanism and iterations to be used\n+     * @param password the password\n+     * @param salt the salt to be used\n+     */\n+    public UserScramCredentialUpsertion(String user, ScramCredentialInfo credentialInfo, byte[] password, byte[] salt) {\n+        super(Objects.requireNonNull(user));\n+        this.info = Objects.requireNonNull(credentialInfo);\n+        this.password = Objects.requireNonNull(password);\n+        this.salt = Objects.requireNonNull(salt);\n+    }\n+\n+    /**\n+     *\n+     * @return the mechanism and iterations\n+     */\n+    public ScramCredentialInfo credentialInfo() {\n+        return info;\n+    }\n+\n+    /**\n+     *\n+     * @return the salt\n+     */\n+    public byte[] salt() {\n+        return salt;\n+    }\n+\n+    /**\n+     *\n+     * @return the password\n+     */\n+    public byte[] password() {\n+        return password;\n+    }\n+\n+    private static byte[] generateRandomSalt() {\n+        return new BigInteger(130, new SecureRandom()).toString(Character.MAX_RADIX).getBytes(StandardCharsets.UTF_8);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTYzNzI2Ng==", "bodyText": "@cmccabe  I think the approach you suggest leaves out how to identify length which itself needs to be randomized.  I got the current implementation from org.apache.kafka.common.security.scram.internals.ScramFormatter.  I would have invoked ScramFormatter.secureRandomBytes() directly, but it is not static and I did not want to either instantiate an instance or change methods to static (though the class is internal, so I could have done that). I instead replicated the logic here.  The array length ends up being random with this approach, as do the bytes in the array.  Let me know what you think.  Currently I've left this as-is.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r469637266", "createdAt": "2020-08-13T01:10:32Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialUpsertion.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import java.math.BigInteger;\n+import java.nio.charset.StandardCharsets;\n+import java.security.SecureRandom;\n+import java.util.Objects;\n+\n+/**\n+ * A request to update/insert a SASL/SCRAM credential for a user.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public class UserScramCredentialUpsertion extends UserScramCredentialAlteration {\n+    private final ScramCredentialInfo info;\n+    private final byte[] salt;\n+    private final byte[] password;\n+\n+    /**\n+     * Constructor that generates a random salt\n+     *\n+     * @param user the user for which the credential is to be updated/inserted\n+     * @param credentialInfo the mechanism and iterations to be used\n+     * @param password the password\n+     */\n+    public UserScramCredentialUpsertion(String user, ScramCredentialInfo credentialInfo, String password) {\n+        this(user, credentialInfo, password.getBytes(StandardCharsets.UTF_8));\n+    }\n+\n+    /**\n+     * Constructor that generates a random salt\n+     *\n+     * @param user the user for which the credential is to be updated/inserted\n+     * @param credentialInfo the mechanism and iterations to be used\n+     * @param password the password\n+     */\n+    public UserScramCredentialUpsertion(String user, ScramCredentialInfo credentialInfo, byte[] password) {\n+        this(user, credentialInfo, password, generateRandomSalt());\n+    }\n+\n+    /**\n+     * Constructor that accepts an explicit salt\n+     *\n+     * @param user the user for which the credential is to be updated/inserted\n+     * @param credentialInfo the mechanism and iterations to be used\n+     * @param password the password\n+     * @param salt the salt to be used\n+     */\n+    public UserScramCredentialUpsertion(String user, ScramCredentialInfo credentialInfo, byte[] password, byte[] salt) {\n+        super(Objects.requireNonNull(user));\n+        this.info = Objects.requireNonNull(credentialInfo);\n+        this.password = Objects.requireNonNull(password);\n+        this.salt = Objects.requireNonNull(salt);\n+    }\n+\n+    /**\n+     *\n+     * @return the mechanism and iterations\n+     */\n+    public ScramCredentialInfo credentialInfo() {\n+        return info;\n+    }\n+\n+    /**\n+     *\n+     * @return the salt\n+     */\n+    public byte[] salt() {\n+        return salt;\n+    }\n+\n+    /**\n+     *\n+     * @return the password\n+     */\n+    public byte[] password() {\n+        return password;\n+    }\n+\n+    private static byte[] generateRandomSalt() {\n+        return new BigInteger(130, new SecureRandom()).toString(Character.MAX_RADIX).getBytes(StandardCharsets.UTF_8);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg4NTc5NQ=="}, "originalCommit": null, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDMzOTAzMQ==", "bodyText": "The latest commit changes the methods on org.apache.kafka.common.security.scram.internals.ScramFormatter to be static, and I now reuse that logic.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r470339031", "createdAt": "2020-08-14T00:44:20Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialUpsertion.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import java.math.BigInteger;\n+import java.nio.charset.StandardCharsets;\n+import java.security.SecureRandom;\n+import java.util.Objects;\n+\n+/**\n+ * A request to update/insert a SASL/SCRAM credential for a user.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public class UserScramCredentialUpsertion extends UserScramCredentialAlteration {\n+    private final ScramCredentialInfo info;\n+    private final byte[] salt;\n+    private final byte[] password;\n+\n+    /**\n+     * Constructor that generates a random salt\n+     *\n+     * @param user the user for which the credential is to be updated/inserted\n+     * @param credentialInfo the mechanism and iterations to be used\n+     * @param password the password\n+     */\n+    public UserScramCredentialUpsertion(String user, ScramCredentialInfo credentialInfo, String password) {\n+        this(user, credentialInfo, password.getBytes(StandardCharsets.UTF_8));\n+    }\n+\n+    /**\n+     * Constructor that generates a random salt\n+     *\n+     * @param user the user for which the credential is to be updated/inserted\n+     * @param credentialInfo the mechanism and iterations to be used\n+     * @param password the password\n+     */\n+    public UserScramCredentialUpsertion(String user, ScramCredentialInfo credentialInfo, byte[] password) {\n+        this(user, credentialInfo, password, generateRandomSalt());\n+    }\n+\n+    /**\n+     * Constructor that accepts an explicit salt\n+     *\n+     * @param user the user for which the credential is to be updated/inserted\n+     * @param credentialInfo the mechanism and iterations to be used\n+     * @param password the password\n+     * @param salt the salt to be used\n+     */\n+    public UserScramCredentialUpsertion(String user, ScramCredentialInfo credentialInfo, byte[] password, byte[] salt) {\n+        super(Objects.requireNonNull(user));\n+        this.info = Objects.requireNonNull(credentialInfo);\n+        this.password = Objects.requireNonNull(password);\n+        this.salt = Objects.requireNonNull(salt);\n+    }\n+\n+    /**\n+     *\n+     * @return the mechanism and iterations\n+     */\n+    public ScramCredentialInfo credentialInfo() {\n+        return info;\n+    }\n+\n+    /**\n+     *\n+     * @return the salt\n+     */\n+    public byte[] salt() {\n+        return salt;\n+    }\n+\n+    /**\n+     *\n+     * @return the password\n+     */\n+    public byte[] password() {\n+        return password;\n+    }\n+\n+    private static byte[] generateRandomSalt() {\n+        return new BigInteger(130, new SecureRandom()).toString(Character.MAX_RADIX).getBytes(StandardCharsets.UTF_8);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg4NTc5NQ=="}, "originalCommit": null, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MzQ0MDg2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialsDescription.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMToxNDoxNlrOHCm7JA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMToxNDoxNlrOHCm7JA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQ5NjkzMg==", "bodyText": "It would be good to throw the exception here if there is one, so that it wasn't possible to ignore the problem", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472496932", "createdAt": "2020-08-18T21:14:16Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialsDescription.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.errors.ApiException;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+/**\n+ * Representation of all SASL/SCRAM credentials associated with a user that can be retrieved, or an exception indicating\n+ * why credentials could not be retrieved.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public class UserScramCredentialsDescription {\n+    private final String name;\n+    private final Optional<ApiException> exception;\n+    private final List<ScramCredentialInfo> credentialInfos;\n+\n+    /**\n+     * Constructor for when SASL/SCRAM credentials associated with a user could not be retrieved\n+     *\n+     * @param name the required user name\n+     * @param exception the required exception indicating why the credentials for the user could not be retrieved\n+     */\n+    public UserScramCredentialsDescription(String name, ApiException exception) {\n+        this(name, Optional.of(Objects.requireNonNull(exception)), Collections.emptyList());\n+    }\n+\n+    /**\n+     * Constructor for when SASL/SCRAM credentials associated with a user are successfully retrieved\n+     *\n+     * @param name the required user name\n+     * @param credentialInfos the required SASL/SCRAM credential representations for the user\n+     */\n+    public UserScramCredentialsDescription(String name, List<ScramCredentialInfo> credentialInfos) {\n+        this(name, Optional.empty(), Objects.requireNonNull(credentialInfos));\n+    }\n+\n+    private UserScramCredentialsDescription(String name, Optional<ApiException> exception, List<ScramCredentialInfo> credentialInfos) {\n+        this.name = Objects.requireNonNull(name);\n+        this.exception = Objects.requireNonNull(exception);\n+        this.credentialInfos = Collections.unmodifiableList(new ArrayList<>(credentialInfos));\n+    }\n+\n+    /**\n+     *\n+     * @return the user name\n+     */\n+    public String name() {\n+        return name;\n+    }\n+\n+    /**\n+     *\n+     * @return the exception, if any, that prevented the user's SASL/SCRAM credentials from being retrieved\n+     */\n+    public Optional<ApiException> exception() {\n+        return exception;\n+    }\n+\n+    /**\n+     *\n+     * @return the always non-null/unmodifiable list of SASL/SCRAM credential representations for the user\n+     * (empty if {@link #exception} defines an exception)\n+     */\n+    public List<ScramCredentialInfo> credentialInfos() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MzQ1MzUzOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/protocol/ProtoUtilsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMToxODoxMlrOHCnCeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMToxODoxMlrOHCnCeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQ5ODgwOQ==", "bodyText": "I know it's not strictly necessary, but it would be nice to have a \"break\" after the default clause too", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472498809", "createdAt": "2020-08-18T21:18:12Z", "author": {"login": "cmccabe"}, "path": "clients/src/test/java/org/apache/kafka/common/protocol/ProtoUtilsTest.java", "diffHunk": "@@ -26,11 +26,18 @@\n     public void testDelayedAllocationSchemaDetection() throws Exception {\n         //verifies that schemas known to retain a reference to the underlying byte buffer are correctly detected.\n         for (ApiKeys key : ApiKeys.values()) {\n-            if (key == ApiKeys.PRODUCE || key == ApiKeys.JOIN_GROUP || key == ApiKeys.SYNC_GROUP || key == ApiKeys.SASL_AUTHENTICATE\n-                || key == ApiKeys.EXPIRE_DELEGATION_TOKEN || key == ApiKeys.RENEW_DELEGATION_TOKEN) {\n-                assertTrue(key + \" should require delayed allocation\", key.requiresDelayedAllocation);\n-            } else {\n-                assertFalse(key + \" should not require delayed allocation\", key.requiresDelayedAllocation);\n+            switch (key) {\n+                case PRODUCE:\n+                case JOIN_GROUP:\n+                case SYNC_GROUP:\n+                case SASL_AUTHENTICATE:\n+                case EXPIRE_DELEGATION_TOKEN:\n+                case RENEW_DELEGATION_TOKEN:\n+                case ALTER_USER_SCRAM_CREDENTIALS:\n+                    assertTrue(key + \" should require delayed allocation\", key.requiresDelayedAllocation);\n+                    break;\n+                default:\n+                    assertFalse(key + \" should not require delayed allocation\", key.requiresDelayedAllocation);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MzQ2ODcyOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/admin/ConfigCommandTest.scala", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMToyMzoyMFrOHCnLmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwNDo1NDo0NlrOHCy6FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwMTE0Nw==", "bodyText": "sorry, this might be a silly question, but how are these constraints different when using --zookeeper?  should we test that as well", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472501147", "createdAt": "2020-08-18T21:23:20Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/unit/kafka/admin/ConfigCommandTest.scala", "diffHunk": "@@ -486,7 +486,9 @@ class ConfigCommandTest extends ZooKeeperTestHarness with Logging {\n   }\n \n   @Test\n-  def shouldNotAlterNonQuotaClientConfigUsingBootstrapServer(): Unit = {\n+  def shouldNotAlterNonQuotaNonScramUserOrClientConfigUsingBootstrapServer(): Unit = {\n+    // when using --bootstrap-server, it should be illegal to alter anything that is not a quota and not a SCRAM credential\n+    // for both user and client entities", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMDI1Mw==", "bodyText": "@cmccabe Good question, actually.  There is already a check to make sure a non-existent config cannot be deleted via --zookeeper: shouldNotUpdateConfigIfNonExistingConfigIsDeletedUsingZookeper().  This test passes, of course.\nHowever, there is no check to make sure an unrecognized config can be added, and in fact if I add that test it fails; the code will gladly go ahead and add anything we wish (and it will gladly go ahead and delete it if we wish as well -- the above test is only checking that something that doesn't exist can't be deleted).\nThe next question, of course, is whether we should \"fix\" this or not.  What do you think?  To fix it we would need the full set of allowed configs at the User, Client, Topic, and Broker levels and then insert code to check accordingly.  Since the ZooKeeper update path is going away due to KIP-500, I'm wondering if we can just leave it alone?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472530253", "createdAt": "2020-08-18T22:32:53Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/unit/kafka/admin/ConfigCommandTest.scala", "diffHunk": "@@ -486,7 +486,9 @@ class ConfigCommandTest extends ZooKeeperTestHarness with Logging {\n   }\n \n   @Test\n-  def shouldNotAlterNonQuotaClientConfigUsingBootstrapServer(): Unit = {\n+  def shouldNotAlterNonQuotaNonScramUserOrClientConfigUsingBootstrapServer(): Unit = {\n+    // when using --bootstrap-server, it should be illegal to alter anything that is not a quota and not a SCRAM credential\n+    // for both user and client entities", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwMTE0Nw=="}, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjY5MzI2OA==", "bodyText": "Yeah, I think we should leave it alone for now, for the reasons you state.  But thanks for the context.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r472693268", "createdAt": "2020-08-19T04:54:46Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/unit/kafka/admin/ConfigCommandTest.scala", "diffHunk": "@@ -486,7 +486,9 @@ class ConfigCommandTest extends ZooKeeperTestHarness with Logging {\n   }\n \n   @Test\n-  def shouldNotAlterNonQuotaClientConfigUsingBootstrapServer(): Unit = {\n+  def shouldNotAlterNonQuotaNonScramUserOrClientConfigUsingBootstrapServer(): Unit = {\n+    // when using --bootstrap-server, it should be illegal to alter anything that is not a quota and not a SCRAM credential\n+    // for both user and client entities", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwMTE0Nw=="}, "originalCommit": null, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NTM0ODA4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwNToyODoxOVrOHEcEcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQyMDo0MDoyMFrOHE8rxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQxNjI0Mw==", "bodyText": "Based on our offline discussion, I thought we were going to have three methods here:\nKafkaFuture<Map<String, UserScramCredentialsDescription>> all()\n\nReturns all the users that were listed, or throws an exception if there was an error describing any of them.\nKafkaFuture<List<String>> users();\n\nReturns the names of all the users that were described, whether the describing was successful or not.\nKafkaFuture<UserScramCredentialDescription> description(String userName);\n\nReturns a future describing userName, or RESOURCE_NOT_FOUND if the user was not listed or not found.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r474416243", "createdAt": "2020-08-21T05:28:19Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.List;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<List<UserScramCredentialsDescriptionResult>> future;\n+\n+    /**\n+     *\n+     * @param future the required future representing the result of the call\n+     */\n+    public DescribeUserScramCredentialsResult(KafkaFuture<List<UserScramCredentialsDescriptionResult>> future) {\n+        this.future = Objects.requireNonNull(future);\n+    }\n+\n+    /**\n+     *\n+     * @return the future representing the result of the call\n+     */\n+    public KafkaFuture<List<UserScramCredentialsDescriptionResult>> future() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1MDU5Nw==", "bodyText": "Sorry, my mistake.  This now reflects what we discussed.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r474950597", "createdAt": "2020-08-21T20:40:20Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.List;\n+import java.util.Objects;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<List<UserScramCredentialsDescriptionResult>> future;\n+\n+    /**\n+     *\n+     * @param future the required future representing the result of the call\n+     */\n+    public DescribeUserScramCredentialsResult(KafkaFuture<List<UserScramCredentialsDescriptionResult>> future) {\n+        this.future = Objects.requireNonNull(future);\n+    }\n+\n+    /**\n+     *\n+     * @return the future representing the result of the call\n+     */\n+    public KafkaFuture<List<UserScramCredentialsDescriptionResult>> future() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQxNjI0Mw=="}, "originalCommit": null, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NTM1MTA2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialsDescription.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwNToyOTo1OFrOHEcGKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwNToyOTo1OFrOHEcGKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQxNjY4Mg==", "bodyText": "As I commented above, I think we should not have the exception here.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r474416682", "createdAt": "2020-08-21T05:29:58Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/UserScramCredentialsDescription.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.errors.ApiException;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+/**\n+ * Representation of all SASL/SCRAM credentials associated with a user that can be retrieved, or an exception indicating\n+ * why credentials could not be retrieved.\n+ *\n+ * @see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-554%3A+Add+Broker-side+SCRAM+Config+API\">KIP-554: Add Broker-side SCRAM Config API</a>\n+ */\n+public class UserScramCredentialsDescription {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3Mzk5NDQzOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNToyMjowMlrOHFqKhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNToyMjowMlrOHFqKhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY5NTc1MA==", "bodyText": "We don't need this extra future, right?  We can just use requestedUserFuture directly if we want to use that", "url": "https://github.com/apache/kafka/pull/9032#discussion_r475695750", "createdAt": "2020-08-24T15:22:02Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+import org.apache.kafka.common.errors.ResourceNotFoundException;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<List<String>> usersFuture;\n+    private final Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures;\n+\n+    /**\n+     *\n+     * @param usersFuture the future indicating the users described by the call\n+     * @param perUserFutures the required map of user names to futures representing the results of describing each\n+     *                       user's SCRAM credentials.\n+     */\n+    public DescribeUserScramCredentialsResult(KafkaFuture<List<String>> usersFuture,\n+                                              Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures) {\n+        this.usersFuture = Objects.requireNonNull(usersFuture);\n+        this.perUserFutures = Objects.requireNonNull(perUserFutures);\n+    }\n+\n+    /**\n+     *\n+     * @return a future for the results of all requested (either explicitly or implicitly via describe-all) users.\n+     * The future will complete successfully only if the users future first completes successfully and then all the\n+     * futures for the user descriptions complete successfully.\n+     */\n+    public KafkaFuture<Map<String, UserScramCredentialsDescription>> all() {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(users());\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            KafkaFuture<Void> succeedsOnlyIfAllDescriptionsSucceed = KafkaFuture.allOf(perUserFutures.values().toArray(\n+                    new KafkaFuture[perUserFutures.size()]));\n+            KafkaFuture<Map<String, UserScramCredentialsDescription>> mapFuture = succeedsOnlyIfAllDescriptionsSucceed.thenApply(void2 ->\n+                perUserFutures.entrySet().stream().collect(Collectors.toMap(\n+                    e -> e.getKey(),\n+                    e -> valueFromFutureGuaranteedToSucceedAtThisPoint(e.getValue()))));\n+            /* At this point it is only the users future that is guaranteed to have succeeded.\n+             * We want to return the future to the map, but we have to return a map at this point.\n+             * We need to dereference the future while propagating any exception.\n+             */\n+            return valueFromFuturePropagatingExceptionsAsUnchecked(mapFuture);\n+        });\n+    }\n+\n+    /**\n+     *\n+     * @return a future indicating the distinct users that were requested (either explicitly or implicitly via\n+     * describe-all).  The future will not complete successfully if the user is not authorized to perform the describe\n+     * operation; otherwise, it will complete successfully as long as the list of users with credentials can be\n+     * successfully determined within some hard-coded timeout period.\n+     */\n+    public KafkaFuture<List<String>> users() {\n+        return usersFuture;\n+    }\n+\n+    /**\n+     *\n+     * @param userName the name of the user description being requested\n+     * @return a future indicating the description results for the given user. The future will complete exceptionally if\n+     * the future returned by {@link #users()} completes exceptionally.  If the given user does not exist in the list\n+     * of requested users then the future will complete exceptionally with\n+     * {@link org.apache.kafka.common.errors.ResourceNotFoundException}.\n+     */\n+    public KafkaFuture<UserScramCredentialsDescription> description(String userName) {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(usersFuture);\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            // it is possible that there is no future for this user (for example, the original describe request was for\n+            // users 1, 2, and 3 but this is looking for user 4), so explicitly take care of that case\n+            KafkaFuture<UserScramCredentialsDescription> requestedUserFuture = perUserFutures.get(userName);\n+            if (requestedUserFuture == null) {\n+                throw new ResourceNotFoundException(\"No such user: \" + userName);\n+            }\n+            KafkaFuture<Void> succeedsOnlyIfRequestedUserFutureSucceeds = KafkaFuture.allOf(requestedUserFuture);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3Mzk5OTYyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNToyMzoxNVrOHFqNqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNzoxODoyNlrOHFuxXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY5NjU1NA==", "bodyText": "You should not be calling get() here.\nIn general it seems like what you really want is a single future behind the scenes that returns everything that you fetched from your single RPC.  Then you just need a few translation functions that pull out the part you need for each future that you're returning to the user.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r475696554", "createdAt": "2020-08-24T15:23:15Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+import org.apache.kafka.common.errors.ResourceNotFoundException;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<List<String>> usersFuture;\n+    private final Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures;\n+\n+    /**\n+     *\n+     * @param usersFuture the future indicating the users described by the call\n+     * @param perUserFutures the required map of user names to futures representing the results of describing each\n+     *                       user's SCRAM credentials.\n+     */\n+    public DescribeUserScramCredentialsResult(KafkaFuture<List<String>> usersFuture,\n+                                              Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures) {\n+        this.usersFuture = Objects.requireNonNull(usersFuture);\n+        this.perUserFutures = Objects.requireNonNull(perUserFutures);\n+    }\n+\n+    /**\n+     *\n+     * @return a future for the results of all requested (either explicitly or implicitly via describe-all) users.\n+     * The future will complete successfully only if the users future first completes successfully and then all the\n+     * futures for the user descriptions complete successfully.\n+     */\n+    public KafkaFuture<Map<String, UserScramCredentialsDescription>> all() {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(users());\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            KafkaFuture<Void> succeedsOnlyIfAllDescriptionsSucceed = KafkaFuture.allOf(perUserFutures.values().toArray(\n+                    new KafkaFuture[perUserFutures.size()]));\n+            KafkaFuture<Map<String, UserScramCredentialsDescription>> mapFuture = succeedsOnlyIfAllDescriptionsSucceed.thenApply(void2 ->\n+                perUserFutures.entrySet().stream().collect(Collectors.toMap(\n+                    e -> e.getKey(),\n+                    e -> valueFromFutureGuaranteedToSucceedAtThisPoint(e.getValue()))));\n+            /* At this point it is only the users future that is guaranteed to have succeeded.\n+             * We want to return the future to the map, but we have to return a map at this point.\n+             * We need to dereference the future while propagating any exception.\n+             */\n+            return valueFromFuturePropagatingExceptionsAsUnchecked(mapFuture);\n+        });\n+    }\n+\n+    /**\n+     *\n+     * @return a future indicating the distinct users that were requested (either explicitly or implicitly via\n+     * describe-all).  The future will not complete successfully if the user is not authorized to perform the describe\n+     * operation; otherwise, it will complete successfully as long as the list of users with credentials can be\n+     * successfully determined within some hard-coded timeout period.\n+     */\n+    public KafkaFuture<List<String>> users() {\n+        return usersFuture;\n+    }\n+\n+    /**\n+     *\n+     * @param userName the name of the user description being requested\n+     * @return a future indicating the description results for the given user. The future will complete exceptionally if\n+     * the future returned by {@link #users()} completes exceptionally.  If the given user does not exist in the list\n+     * of requested users then the future will complete exceptionally with\n+     * {@link org.apache.kafka.common.errors.ResourceNotFoundException}.\n+     */\n+    public KafkaFuture<UserScramCredentialsDescription> description(String userName) {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(usersFuture);\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            // it is possible that there is no future for this user (for example, the original describe request was for\n+            // users 1, 2, and 3 but this is looking for user 4), so explicitly take care of that case\n+            KafkaFuture<UserScramCredentialsDescription> requestedUserFuture = perUserFutures.get(userName);\n+            if (requestedUserFuture == null) {\n+                throw new ResourceNotFoundException(\"No such user: \" + userName);\n+            }\n+            KafkaFuture<Void> succeedsOnlyIfRequestedUserFutureSucceeds = KafkaFuture.allOf(requestedUserFuture);\n+            KafkaFuture<UserScramCredentialsDescription> descriptionFuture = succeedsOnlyIfRequestedUserFutureSucceeds.thenApply(void2 ->\n+                valueFromFutureGuaranteedToSucceedAtThisPoint(requestedUserFuture));\n+            /* At this point it is only the users future that is guaranteed to have succeeded.\n+             * We want to return the future to the description, but we have to return a description at this point.\n+             * We need to dereference the future while propagating any exception.\n+             */\n+            return valueFromFuturePropagatingExceptionsAsUnchecked(descriptionFuture);\n+        });\n+    }\n+\n+    private static <T> T valueFromFutureGuaranteedToSucceedAtThisPoint(KafkaFuture<T> future) {\n+        try {\n+            return future.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1MDA1OA==", "bodyText": "a single future behind the scenes that returns everything that you fetched from your single RPC\n\nThat would introduce an assumption that none of the users' results are available until all of the users' results are available.  For example, currently this class accepts two arguments in its constructor: a future to a list of user names, and a map of usernames-to-futures for the results of each user.  If instead for the second argument we accept a single future to a map of usernames-to-results, then that future must succeed all the time (because we need to distinguish between successes and failures for different users).  Each user's result would have to contain the error code, and no user's results will be available to the client until all of the users' results (the underlying map) is available.  It is true that this is how it is implemented today -- no user's results will be available until all users' results are available, and each of the individual results has an error code -- but Is it acceptable to impose such an all-or-nothing result availability constraint?  The idea of flexibility in the API going forward is an ambiguous one, so we should explicitly decide here whether to keep it the way it is now (allowing different users to complete at different times even though it isn't possible right now) vs. changing the constructor and constraining the results for any particular user to be available only after the results for all users are available.  What do you think?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r475750058", "createdAt": "2020-08-24T16:42:01Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+import org.apache.kafka.common.errors.ResourceNotFoundException;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<List<String>> usersFuture;\n+    private final Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures;\n+\n+    /**\n+     *\n+     * @param usersFuture the future indicating the users described by the call\n+     * @param perUserFutures the required map of user names to futures representing the results of describing each\n+     *                       user's SCRAM credentials.\n+     */\n+    public DescribeUserScramCredentialsResult(KafkaFuture<List<String>> usersFuture,\n+                                              Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures) {\n+        this.usersFuture = Objects.requireNonNull(usersFuture);\n+        this.perUserFutures = Objects.requireNonNull(perUserFutures);\n+    }\n+\n+    /**\n+     *\n+     * @return a future for the results of all requested (either explicitly or implicitly via describe-all) users.\n+     * The future will complete successfully only if the users future first completes successfully and then all the\n+     * futures for the user descriptions complete successfully.\n+     */\n+    public KafkaFuture<Map<String, UserScramCredentialsDescription>> all() {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(users());\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            KafkaFuture<Void> succeedsOnlyIfAllDescriptionsSucceed = KafkaFuture.allOf(perUserFutures.values().toArray(\n+                    new KafkaFuture[perUserFutures.size()]));\n+            KafkaFuture<Map<String, UserScramCredentialsDescription>> mapFuture = succeedsOnlyIfAllDescriptionsSucceed.thenApply(void2 ->\n+                perUserFutures.entrySet().stream().collect(Collectors.toMap(\n+                    e -> e.getKey(),\n+                    e -> valueFromFutureGuaranteedToSucceedAtThisPoint(e.getValue()))));\n+            /* At this point it is only the users future that is guaranteed to have succeeded.\n+             * We want to return the future to the map, but we have to return a map at this point.\n+             * We need to dereference the future while propagating any exception.\n+             */\n+            return valueFromFuturePropagatingExceptionsAsUnchecked(mapFuture);\n+        });\n+    }\n+\n+    /**\n+     *\n+     * @return a future indicating the distinct users that were requested (either explicitly or implicitly via\n+     * describe-all).  The future will not complete successfully if the user is not authorized to perform the describe\n+     * operation; otherwise, it will complete successfully as long as the list of users with credentials can be\n+     * successfully determined within some hard-coded timeout period.\n+     */\n+    public KafkaFuture<List<String>> users() {\n+        return usersFuture;\n+    }\n+\n+    /**\n+     *\n+     * @param userName the name of the user description being requested\n+     * @return a future indicating the description results for the given user. The future will complete exceptionally if\n+     * the future returned by {@link #users()} completes exceptionally.  If the given user does not exist in the list\n+     * of requested users then the future will complete exceptionally with\n+     * {@link org.apache.kafka.common.errors.ResourceNotFoundException}.\n+     */\n+    public KafkaFuture<UserScramCredentialsDescription> description(String userName) {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(usersFuture);\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            // it is possible that there is no future for this user (for example, the original describe request was for\n+            // users 1, 2, and 3 but this is looking for user 4), so explicitly take care of that case\n+            KafkaFuture<UserScramCredentialsDescription> requestedUserFuture = perUserFutures.get(userName);\n+            if (requestedUserFuture == null) {\n+                throw new ResourceNotFoundException(\"No such user: \" + userName);\n+            }\n+            KafkaFuture<Void> succeedsOnlyIfRequestedUserFutureSucceeds = KafkaFuture.allOf(requestedUserFuture);\n+            KafkaFuture<UserScramCredentialsDescription> descriptionFuture = succeedsOnlyIfRequestedUserFutureSucceeds.thenApply(void2 ->\n+                valueFromFutureGuaranteedToSucceedAtThisPoint(requestedUserFuture));\n+            /* At this point it is only the users future that is guaranteed to have succeeded.\n+             * We want to return the future to the description, but we have to return a description at this point.\n+             * We need to dereference the future while propagating any exception.\n+             */\n+            return valueFromFuturePropagatingExceptionsAsUnchecked(descriptionFuture);\n+        });\n+    }\n+\n+    private static <T> T valueFromFutureGuaranteedToSucceedAtThisPoint(KafkaFuture<T> future) {\n+        try {\n+            return future.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY5NjU1NA=="}, "originalCommit": null, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc3MTIzMA==", "bodyText": "You should not be calling get() here\n\nLooking at the implementation of KafkaFutureImpl I agree we should not be calling get() because I think it means when the users future completes, the thread that completes it will wait until the results future for that user also completes.  If this is indeed the case then we definitely do not want to be calling get() in our code.  One way to make a hard dependency on the users future completing without causing the admin client thread to block as just described is to provide a 2-level results hierarchy as was previously implemented.  This forces the user to complete 2 futures and to do it in their own thread.\nI wonder if we have the constructor accept 2 futures rather than 1+N futures we would still create a dependency between the 2 that would block the admin client thread.  Perhaps the second future would have to already have a dependency on the users future built into it.\nOne thing we have to be careful about is the constraints we put on the arguments to the constructor -- those constraints, whatever they end up being, have to be clearly documented.  If we don't have to impose any -- then that's great.  But if we have to impose/document some, then we should compare that with the 2-level results hierarchy I had provided earlier -- that imposes no constraints whatsoever.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r475771230", "createdAt": "2020-08-24T17:18:26Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+import org.apache.kafka.common.errors.ResourceNotFoundException;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<List<String>> usersFuture;\n+    private final Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures;\n+\n+    /**\n+     *\n+     * @param usersFuture the future indicating the users described by the call\n+     * @param perUserFutures the required map of user names to futures representing the results of describing each\n+     *                       user's SCRAM credentials.\n+     */\n+    public DescribeUserScramCredentialsResult(KafkaFuture<List<String>> usersFuture,\n+                                              Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures) {\n+        this.usersFuture = Objects.requireNonNull(usersFuture);\n+        this.perUserFutures = Objects.requireNonNull(perUserFutures);\n+    }\n+\n+    /**\n+     *\n+     * @return a future for the results of all requested (either explicitly or implicitly via describe-all) users.\n+     * The future will complete successfully only if the users future first completes successfully and then all the\n+     * futures for the user descriptions complete successfully.\n+     */\n+    public KafkaFuture<Map<String, UserScramCredentialsDescription>> all() {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(users());\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            KafkaFuture<Void> succeedsOnlyIfAllDescriptionsSucceed = KafkaFuture.allOf(perUserFutures.values().toArray(\n+                    new KafkaFuture[perUserFutures.size()]));\n+            KafkaFuture<Map<String, UserScramCredentialsDescription>> mapFuture = succeedsOnlyIfAllDescriptionsSucceed.thenApply(void2 ->\n+                perUserFutures.entrySet().stream().collect(Collectors.toMap(\n+                    e -> e.getKey(),\n+                    e -> valueFromFutureGuaranteedToSucceedAtThisPoint(e.getValue()))));\n+            /* At this point it is only the users future that is guaranteed to have succeeded.\n+             * We want to return the future to the map, but we have to return a map at this point.\n+             * We need to dereference the future while propagating any exception.\n+             */\n+            return valueFromFuturePropagatingExceptionsAsUnchecked(mapFuture);\n+        });\n+    }\n+\n+    /**\n+     *\n+     * @return a future indicating the distinct users that were requested (either explicitly or implicitly via\n+     * describe-all).  The future will not complete successfully if the user is not authorized to perform the describe\n+     * operation; otherwise, it will complete successfully as long as the list of users with credentials can be\n+     * successfully determined within some hard-coded timeout period.\n+     */\n+    public KafkaFuture<List<String>> users() {\n+        return usersFuture;\n+    }\n+\n+    /**\n+     *\n+     * @param userName the name of the user description being requested\n+     * @return a future indicating the description results for the given user. The future will complete exceptionally if\n+     * the future returned by {@link #users()} completes exceptionally.  If the given user does not exist in the list\n+     * of requested users then the future will complete exceptionally with\n+     * {@link org.apache.kafka.common.errors.ResourceNotFoundException}.\n+     */\n+    public KafkaFuture<UserScramCredentialsDescription> description(String userName) {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(usersFuture);\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            // it is possible that there is no future for this user (for example, the original describe request was for\n+            // users 1, 2, and 3 but this is looking for user 4), so explicitly take care of that case\n+            KafkaFuture<UserScramCredentialsDescription> requestedUserFuture = perUserFutures.get(userName);\n+            if (requestedUserFuture == null) {\n+                throw new ResourceNotFoundException(\"No such user: \" + userName);\n+            }\n+            KafkaFuture<Void> succeedsOnlyIfRequestedUserFutureSucceeds = KafkaFuture.allOf(requestedUserFuture);\n+            KafkaFuture<UserScramCredentialsDescription> descriptionFuture = succeedsOnlyIfRequestedUserFutureSucceeds.thenApply(void2 ->\n+                valueFromFutureGuaranteedToSucceedAtThisPoint(requestedUserFuture));\n+            /* At this point it is only the users future that is guaranteed to have succeeded.\n+             * We want to return the future to the description, but we have to return a description at this point.\n+             * We need to dereference the future while propagating any exception.\n+             */\n+            return valueFromFuturePropagatingExceptionsAsUnchecked(descriptionFuture);\n+        });\n+    }\n+\n+    private static <T> T valueFromFutureGuaranteedToSucceedAtThisPoint(KafkaFuture<T> future) {\n+        try {\n+            return future.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY5NjU1NA=="}, "originalCommit": null, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDAxNDAwOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNToyNjozMVrOHFqWfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNjo1MzoxOVrOHFt4ZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY5ODgxMw==", "bodyText": "I think it would be better to make this \"a future indicating the users that were listed\" (rather than \"requested\").  It's maybe a bit of a subtle distinction but think about things like requesting the null user, or the empty string user.  It's awkward to put that here.  I think if we explicitly request a user but it doesn't exist, it should be omitted from here as well.  That gives us more flexibility in the future with the API.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r475698813", "createdAt": "2020-08-24T15:26:31Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+import org.apache.kafka.common.errors.ResourceNotFoundException;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<List<String>> usersFuture;\n+    private final Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures;\n+\n+    /**\n+     *\n+     * @param usersFuture the future indicating the users described by the call\n+     * @param perUserFutures the required map of user names to futures representing the results of describing each\n+     *                       user's SCRAM credentials.\n+     */\n+    public DescribeUserScramCredentialsResult(KafkaFuture<List<String>> usersFuture,\n+                                              Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures) {\n+        this.usersFuture = Objects.requireNonNull(usersFuture);\n+        this.perUserFutures = Objects.requireNonNull(perUserFutures);\n+    }\n+\n+    /**\n+     *\n+     * @return a future for the results of all requested (either explicitly or implicitly via describe-all) users.\n+     * The future will complete successfully only if the users future first completes successfully and then all the\n+     * futures for the user descriptions complete successfully.\n+     */\n+    public KafkaFuture<Map<String, UserScramCredentialsDescription>> all() {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(users());\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            KafkaFuture<Void> succeedsOnlyIfAllDescriptionsSucceed = KafkaFuture.allOf(perUserFutures.values().toArray(\n+                    new KafkaFuture[perUserFutures.size()]));\n+            KafkaFuture<Map<String, UserScramCredentialsDescription>> mapFuture = succeedsOnlyIfAllDescriptionsSucceed.thenApply(void2 ->\n+                perUserFutures.entrySet().stream().collect(Collectors.toMap(\n+                    e -> e.getKey(),\n+                    e -> valueFromFutureGuaranteedToSucceedAtThisPoint(e.getValue()))));\n+            /* At this point it is only the users future that is guaranteed to have succeeded.\n+             * We want to return the future to the map, but we have to return a map at this point.\n+             * We need to dereference the future while propagating any exception.\n+             */\n+            return valueFromFuturePropagatingExceptionsAsUnchecked(mapFuture);\n+        });\n+    }\n+\n+    /**\n+     *\n+     * @return a future indicating the distinct users that were requested (either explicitly or implicitly via", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1NjY0NQ==", "bodyText": "We've gone back and forth on this.  The KIP does not explicitly state what to do in the case of a describe request for a user that does not have credentials, and we originally coded it to silently drop them, but then we changed it to be consistent with other APIs and raise an error (#9032 (comment)).  I agree that it isn't totally clear what to do.  Rather than making the change back, I'll leave both this Javadoc and the underlying implementation as-is right now unill we discuss further and decide for sure what we want.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r475756645", "createdAt": "2020-08-24T16:53:19Z", "author": {"login": "rondagostino"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+import org.apache.kafka.common.errors.ResourceNotFoundException;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<List<String>> usersFuture;\n+    private final Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures;\n+\n+    /**\n+     *\n+     * @param usersFuture the future indicating the users described by the call\n+     * @param perUserFutures the required map of user names to futures representing the results of describing each\n+     *                       user's SCRAM credentials.\n+     */\n+    public DescribeUserScramCredentialsResult(KafkaFuture<List<String>> usersFuture,\n+                                              Map<String, KafkaFuture<UserScramCredentialsDescription>> perUserFutures) {\n+        this.usersFuture = Objects.requireNonNull(usersFuture);\n+        this.perUserFutures = Objects.requireNonNull(perUserFutures);\n+    }\n+\n+    /**\n+     *\n+     * @return a future for the results of all requested (either explicitly or implicitly via describe-all) users.\n+     * The future will complete successfully only if the users future first completes successfully and then all the\n+     * futures for the user descriptions complete successfully.\n+     */\n+    public KafkaFuture<Map<String, UserScramCredentialsDescription>> all() {\n+        KafkaFuture<Void> succeedsOnlyIfUsersFutureSucceeds = KafkaFuture.allOf(users());\n+        return succeedsOnlyIfUsersFutureSucceeds.thenApply(void1 -> {\n+            KafkaFuture<Void> succeedsOnlyIfAllDescriptionsSucceed = KafkaFuture.allOf(perUserFutures.values().toArray(\n+                    new KafkaFuture[perUserFutures.size()]));\n+            KafkaFuture<Map<String, UserScramCredentialsDescription>> mapFuture = succeedsOnlyIfAllDescriptionsSucceed.thenApply(void2 ->\n+                perUserFutures.entrySet().stream().collect(Collectors.toMap(\n+                    e -> e.getKey(),\n+                    e -> valueFromFutureGuaranteedToSucceedAtThisPoint(e.getValue()))));\n+            /* At this point it is only the users future that is guaranteed to have succeeded.\n+             * We want to return the future to the map, but we have to return a map at this point.\n+             * We need to dereference the future while propagating any exception.\n+             */\n+            return valueFromFuturePropagatingExceptionsAsUnchecked(mapFuture);\n+        });\n+    }\n+\n+    /**\n+     *\n+     * @return a future indicating the distinct users that were requested (either explicitly or implicitly via", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY5ODgxMw=="}, "originalCommit": null, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjE5NTkzOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/security/security_config.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToyODozNVrOHIeP_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToyODozNVrOHIeP_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0NjI3MQ==", "bodyText": "I think we should just have a separate function for this, since there's no code shared between when creating_broker_user=True and when it is False.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r478646271", "createdAt": "2020-08-27T19:28:35Z", "author": {"login": "cmccabe"}, "path": "tests/kafkatest/services/security/security_config.py", "diffHunk": "@@ -276,18 +287,19 @@ def setup_node(self, node):\n         if java_version(node) <= 11 and self.properties.get('tls.version') == 'TLSv1.3':\n             self.properties.update({'tls.version': 'TLSv1.2'})\n \n-    def setup_credentials(self, node, path, zk_connect, broker):\n-        if broker:\n-            self.maybe_create_scram_credentials(node, zk_connect, path, self.interbroker_sasl_mechanism,\n+    def setup_credentials(self, node, path, connect, creating_broker_user):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjIwMDQ2OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/security/security_config.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToyOTo1OFrOHIeSpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo0Mjo1MlrOHIesXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0Njk1MA==", "bodyText": "As we discussed offline, I think eventually the admin client should log in as its own admin user, not as the broker.  But we can save that for a follow-on.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r478646950", "createdAt": "2020-08-27T19:29:58Z", "author": {"login": "cmccabe"}, "path": "tests/kafkatest/services/security/security_config.py", "diffHunk": "@@ -350,6 +362,14 @@ def kafka_opts(self):\n         else:\n             return \"\"\n \n+    def export_kafka_opts_for_admin_client_as_broker(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1MzUzNQ==", "bodyText": "Yes, created https://issues.apache.org/jira/browse/KAFKA-10443 to track this.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r478653535", "createdAt": "2020-08-27T19:42:52Z", "author": {"login": "rondagostino"}, "path": "tests/kafkatest/services/security/security_config.py", "diffHunk": "@@ -350,6 +362,14 @@ def kafka_opts(self):\n         else:\n             return \"\"\n \n+    def export_kafka_opts_for_admin_client_as_broker(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0Njk1MA=="}, "originalCommit": null, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjIzMzk4OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/kafka/kafka.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo0MDoyMlrOHIenXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxNzoxNzoxM1rOHKBesA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1MjI1NA==", "bodyText": "It's sort of weird that we're creating files on the fly with '<(echo '%s') rather than just using a file in /mnt/security.  This will result in some pretty long command lines, right?\nConsidering this is an existing pattern in kafka.py (but nowhere else?), let's file a follow-on JIRA to look into this and fix it.  Unless there's some really good reason why kafka.py is doing this, but I can't think of any.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r478652254", "createdAt": "2020-08-27T19:40:22Z", "author": {"login": "cmccabe"}, "path": "tests/kafkatest/services/kafka/kafka.py", "diffHunk": "@@ -575,10 +577,21 @@ def set_unclean_leader_election(self, topic, value=True, node=None):\n         node.account.ssh(cmd)\n \n     def _connect_setting_kafka_configs(self, node):\n+        # Use this for everything related to kafka-configs except User SCRAM Credentials\n         if node.version.kafka_configs_command_uses_bootstrap_server():\n-            return \"--bootstrap-server %s \" % self.bootstrap_servers(self.security_protocol)\n+            return \"--bootstrap-server %s --command-config <(echo '%s')\" % (self.bootstrap_servers(self.security_protocol),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3MjA0OA==", "bodyText": "I created https://issues.apache.org/jira/browse/KAFKA-10451 to track this.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r480272048", "createdAt": "2020-08-31T17:17:13Z", "author": {"login": "rondagostino"}, "path": "tests/kafkatest/services/kafka/kafka.py", "diffHunk": "@@ -575,10 +577,21 @@ def set_unclean_leader_election(self, topic, value=True, node=None):\n         node.account.ssh(cmd)\n \n     def _connect_setting_kafka_configs(self, node):\n+        # Use this for everything related to kafka-configs except User SCRAM Credentials\n         if node.version.kafka_configs_command_uses_bootstrap_server():\n-            return \"--bootstrap-server %s \" % self.bootstrap_servers(self.security_protocol)\n+            return \"--bootstrap-server %s --command-config <(echo '%s')\" % (self.bootstrap_servers(self.security_protocol),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1MjI1NA=="}, "originalCommit": null, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjI1OTU1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/version.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo0Nzo1OFrOHIe3OQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo0Nzo1OFrOHIe3OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjMxMw==", "bodyText": "I don't think this is quite right.  It should be self >= V_2_7_0, right?  And we should add 2.7 to the version.py file.\nmaster branch is already identifying itself as 2.7 anyway.\n[cmccabe@zeratul kafka2]$ git grep 2.7.0 | tail -n 10\ndocs/upgrade.html:<h5><a id=\"upgrade_270_notable\" href=\"#upgrade_270_notable\">Notable changes in 2.7.0</a></h5>\ngradle.properties:version=2.7.0-SNAPSHOT\nkafka-merge-pr.py:DEFAULT_FIX_VERSION = os.environ.get(\"DEFAULT_FIX_VERSION\", \"2.7.0\")\nstreams/quickstart/java/pom.xml:        <version>2.7.0-SNAPSHOT</version>\nstreams/quickstart/java/src/main/resources/archetype-resources/pom.xml:        <kafka.version>2.7.0-SNAPSHOT</kafka.version>\nstreams/quickstart/pom.xml:    <version>2.7.0-SNAPSHOT</version>\nstreams/src/main/java/org/apache/kafka/streams/StreamsBuilder.java:     * @deprecated Since 2.7.0; use {@link #addGlobalStore(StoreBuilder, String, Consumed, ProcessorSupplier)} instead.\nstreams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/StreamsBuilder.scala:    \"2.7.0\"\ntests/kafkatest/__init__.py:__version__ = '2.7.0.dev0'\ntests/kafkatest/version.py:DEV_VERSION = KafkaVersion(\"2.7.0-SNAPSHOT\")\n\nSimilarly supports_tls_to_zookeeper should be checking for 2.5 and later, not \"after 2.4\" (they should be the same, but what if someone messed up incrementing LATEST_2_4, etc....)  It's always better to be explicit about what version something appeared in than to say it happened \"after (but not including) some version X\"", "url": "https://github.com/apache/kafka/pull/9032#discussion_r478656313", "createdAt": "2020-08-27T19:47:58Z", "author": {"login": "cmccabe"}, "path": "tests/kafkatest/version.py", "diffHunk": "@@ -63,8 +63,13 @@ def reassign_partitions_command_supports_bootstrap_server(self):\n         return self >= V_2_5_0\n \n     def kafka_configs_command_uses_bootstrap_server(self):\n+        # everything except User SCRAM Credentials (KIP-554)\n         return self >= V_2_6_0\n \n+    def kafka_configs_command_uses_bootstrap_server_scram(self):\n+        # User SCRAM Credentials (KIP-554)\n+        return self > LATEST_2_6", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjI2NTYzOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/utils/JaasTestUtils.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo0OTo1M1rOHIe6-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxNzozNjoxOVrOHKCGGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NzI3NQ==", "bodyText": "Can we not have these be naked constants?  Maybe we could iterate over an enum or something?  If we add another mechanism, it would be nice not to have to manually edit this.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r478657275", "createdAt": "2020-08-27T19:49:53Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/unit/kafka/utils/JaasTestUtils.scala", "diffHunk": "@@ -169,6 +169,18 @@ object JaasTestUtils {\n     jaasFile\n   }\n \n+  // Returns a SASL/SCRAM configuration using credentials for the given user and password\n+  def scramClientLoginModule(mechanism: String, scramUser: String, scramPassword: String): String = {\n+    mechanism match {\n+      case \"SCRAM-SHA-256\" | \"SCRAM-SHA-512\" =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI4MjEzOQ==", "bodyText": "I fixed this in the other places in this file as well", "url": "https://github.com/apache/kafka/pull/9032#discussion_r480282139", "createdAt": "2020-08-31T17:36:19Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/unit/kafka/utils/JaasTestUtils.scala", "diffHunk": "@@ -169,6 +169,18 @@ object JaasTestUtils {\n     jaasFile\n   }\n \n+  // Returns a SASL/SCRAM configuration using credentials for the given user and password\n+  def scramClientLoginModule(mechanism: String, scramUser: String, scramPassword: String): String = {\n+    mechanism match {\n+      case \"SCRAM-SHA-256\" | \"SCRAM-SHA-512\" =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NzI3NQ=="}, "originalCommit": null, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzgzNDk5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMTozOTowNFrOHJVKUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMTozOTowNFrOHJVKUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU0NTkzNg==", "bodyText": "There's no reason to call allOf on a single future.  After all, allOf's function is convert multiple futures to a single one.  But if you already have a single future, this is not needed.\nYou could use dataFuture.thenApply, but that will not trigger if dataFuture is completed exceptionally.\nInstead, what you want here is something like the following:\ndataFuture.whenComplete( (data, exception) -> if (exception != null) { ... error ... }  else { ... handle data ... }", "url": "https://github.com/apache/kafka/pull/9032#discussion_r479545936", "createdAt": "2020-08-28T21:39:04Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+import org.apache.kafka.common.errors.ResourceNotFoundException;\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsResponseData;\n+import org.apache.kafka.common.protocol.Errors;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<DescribeUserScramCredentialsResponseData> dataFuture;\n+\n+    /**\n+     * Package-private constructor\n+     *\n+     * @param dataFuture the future indicating response data from the call\n+     */\n+    DescribeUserScramCredentialsResult(KafkaFuture<DescribeUserScramCredentialsResponseData> dataFuture) {\n+        this.dataFuture = Objects.requireNonNull(dataFuture);\n+    }\n+\n+    /**\n+     *\n+     * @return a future for the results of all described users with map keys (one per user) being consistent with the\n+     * contents of the list returned by {@link #users()}. The future will complete successfully only if all such user\n+     * descriptions complete successfully.\n+     */\n+    public KafkaFuture<Map<String, UserScramCredentialsDescription>> all() {\n+        return KafkaFuture.allOf(dataFuture).thenApply(v -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzgzOTAzOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMTo0MDo0MlrOHJVMiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMTo0MDo0MlrOHJVMiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU0NjUwNQ==", "bodyText": "The call to get() here isn't needed.  See the comment about about using KafkaFuture#whenComplete.  Chaining future results is a big part of the power of CompletableFuture (which KafkaFuture is a clone of... long story...)", "url": "https://github.com/apache/kafka/pull/9032#discussion_r479546505", "createdAt": "2020-08-28T21:40:42Z", "author": {"login": "cmccabe"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeUserScramCredentialsResult.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.clients.admin;\n+\n+import org.apache.kafka.common.KafkaFuture;\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+import org.apache.kafka.common.errors.ResourceNotFoundException;\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsResponseData;\n+import org.apache.kafka.common.protocol.Errors;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The result of the {@link Admin#describeUserScramCredentials()} call.\n+ *\n+ * The API of this class is evolving, see {@link Admin} for details.\n+ */\n+@InterfaceStability.Evolving\n+public class DescribeUserScramCredentialsResult {\n+    private final KafkaFuture<DescribeUserScramCredentialsResponseData> dataFuture;\n+\n+    /**\n+     * Package-private constructor\n+     *\n+     * @param dataFuture the future indicating response data from the call\n+     */\n+    DescribeUserScramCredentialsResult(KafkaFuture<DescribeUserScramCredentialsResponseData> dataFuture) {\n+        this.dataFuture = Objects.requireNonNull(dataFuture);\n+    }\n+\n+    /**\n+     *\n+     * @return a future for the results of all described users with map keys (one per user) being consistent with the\n+     * contents of the list returned by {@link #users()}. The future will complete successfully only if all such user\n+     * descriptions complete successfully.\n+     */\n+    public KafkaFuture<Map<String, UserScramCredentialsDescription>> all() {\n+        return KafkaFuture.allOf(dataFuture).thenApply(v -> {\n+            DescribeUserScramCredentialsResponseData data = valueFromFutureGuaranteedToSucceedAtThisPoint(dataFuture);\n+            /* Check to make sure every individual described user succeeded.  Note that a successfully described user\n+             * is one that appears with *either* a NONE error code or a RESOURCE_NOT_FOUND error code. The\n+             * RESOURCE_NOT_FOUND means the client explicitly requested a describe of that particular user but it could\n+             * not be described because it does not exist; such a user will not appear as a key in the returned map.\n+             */\n+            Optional<DescribeUserScramCredentialsResponseData.DescribeUserScramCredentialsResult> optionalFirstFailedDescribe =\n+                    data.results().stream().filter(result ->\n+                        result.errorCode() != Errors.NONE.code() && result.errorCode() != Errors.RESOURCE_NOT_FOUND.code()).findFirst();\n+            if (optionalFirstFailedDescribe.isPresent()) {\n+                throw Errors.forCode(optionalFirstFailedDescribe.get().errorCode()).exception(optionalFirstFailedDescribe.get().errorMessage());\n+            }\n+            Map<String, UserScramCredentialsDescription> retval = new HashMap<>();\n+            data.results().stream().forEach(userResult ->\n+                    retval.put(userResult.user(), new UserScramCredentialsDescription(userResult.user(),\n+                            getScramCredentialInfosFor(userResult))));\n+            return retval;\n+        });\n+    }\n+\n+    /**\n+     *\n+     * @return a future indicating the distinct users that meet the request criteria and that have at least one\n+     * credential.  The future will not complete successfully if the user is not authorized to perform the describe\n+     * operation; otherwise, it will complete successfully as long as the list of users with credentials can be\n+     * successfully determined within some hard-coded timeout period. Note that the returned list will not include users\n+     * that do not exist/have no credentials: a request to describe an explicit list of users, none of which existed/had\n+     * a credential, will result in a future that returns an empty list being returned here. A returned list will\n+     * include users that have a credential but that could not be described.\n+     */\n+    public KafkaFuture<List<String>> users() {\n+        return KafkaFuture.allOf(dataFuture).thenApply(v -> {\n+            DescribeUserScramCredentialsResponseData data = valueFromFutureGuaranteedToSucceedAtThisPoint(dataFuture);\n+            return data.results().stream()\n+                    .filter(result -> result.errorCode() != Errors.RESOURCE_NOT_FOUND.code())\n+                    .map(result -> result.user()).collect(Collectors.toList());\n+        });\n+    }\n+\n+    /**\n+     *\n+     * @param userName the name of the user description being requested\n+     * @return a future indicating the description results for the given user. The future will complete exceptionally if\n+     * the future returned by {@link #users()} completes exceptionally.  Note that if the given user does not exist in\n+     * the list of described users then the returned future will complete exceptionally with\n+     * {@link org.apache.kafka.common.errors.ResourceNotFoundException}.\n+     */\n+    public KafkaFuture<UserScramCredentialsDescription> description(String userName) {\n+        return KafkaFuture.allOf(dataFuture).thenApply(v -> {\n+            DescribeUserScramCredentialsResponseData data = valueFromFutureGuaranteedToSucceedAtThisPoint(dataFuture);\n+            // it is possible that there is no future for this user (for example, the original describe request was for\n+            // users 1, 2, and 3 but this is looking for user 4), so explicitly take care of that case\n+            Optional<DescribeUserScramCredentialsResponseData.DescribeUserScramCredentialsResult> optionalUserResult =\n+                    data.results().stream().filter(result -> result.user().equals(userName)).findFirst();\n+            if (!optionalUserResult.isPresent()) {\n+                throw new ResourceNotFoundException(\"No such user: \" + userName);\n+            }\n+            DescribeUserScramCredentialsResponseData.DescribeUserScramCredentialsResult userResult = optionalUserResult.get();\n+            if (userResult.errorCode() != Errors.NONE.code()) {\n+                // RESOURCE_NOT_FOUND is included here\n+                throw Errors.forCode(userResult.errorCode()).exception(userResult.errorMessage());\n+            }\n+            return new UserScramCredentialsDescription(userResult.user(), getScramCredentialInfosFor(userResult));\n+        });\n+    }\n+\n+    private static List<ScramCredentialInfo> getScramCredentialInfosFor(\n+            DescribeUserScramCredentialsResponseData.DescribeUserScramCredentialsResult userResult) {\n+        return userResult.credentialInfos().stream().map(c ->\n+                new ScramCredentialInfo(ScramMechanism.fromType(c.mechanism()), c.iterations()))\n+                .collect(Collectors.toList());\n+    }\n+\n+    private static <T> T valueFromFutureGuaranteedToSucceedAtThisPoint(KafkaFuture<T> future) {\n+        try {\n+            return future.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5Nzg1MDAzOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/server/ClientQuotasRequestTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMTo0NjowNlrOHJVS2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMTo0NjowNlrOHJVS2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU0ODEyMQ==", "bodyText": "This should go with the other java imports, which I guess are combined in this file", "url": "https://github.com/apache/kafka/pull/9032#discussion_r479548121", "createdAt": "2020-08-28T21:46:06Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/unit/kafka/server/ClientQuotasRequestTest.scala", "diffHunk": "@@ -17,6 +17,8 @@\n \n package kafka.server\n \n+import java.util", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5Nzg2OTUyOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/admin/UserScramCredentialsCommandTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMTo1NTo0M1rOHJVeVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxODoxMzo0N1rOHKDTlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1MTA2MQ==", "bodyText": "is it useful to log the exception here at debug level?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r479551061", "createdAt": "2020-08-28T21:55:43Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/unit/kafka/admin/UserScramCredentialsCommandTest.scala", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.admin\n+\n+import java.io.{ByteArrayOutputStream, PrintStream}\n+import java.nio.charset.StandardCharsets\n+\n+import kafka.server.BaseRequestTest\n+import kafka.utils.Exit\n+import org.junit.Assert._\n+import org.junit.Test\n+\n+class UserScramCredentialsCommandTest extends BaseRequestTest {\n+  override def brokerCount = 1\n+  var exitStatus: Option[Int] = None\n+  var exitMessage: Option[String] = None\n+\n+  case class ConfigCommandResult(stdout: String, exitStatus: Option[Int] = None)\n+\n+  private def runConfigCommandViaBroker(args: Array[String]) : ConfigCommandResult = {\n+    val byteArrayOutputStream = new ByteArrayOutputStream()\n+    val utf8 = StandardCharsets.UTF_8.name\n+    val printStream = new PrintStream(byteArrayOutputStream, true, utf8)\n+    var exitStatus: Option[Int] = None\n+    Exit.setExitProcedure { (status, _) =>\n+      exitStatus = Some(status)\n+      throw new RuntimeException\n+    }\n+    try {\n+      Console.withOut(printStream) {\n+        ConfigCommand.main(Array(\"--bootstrap-server\", brokerList) ++ args)\n+      }\n+      ConfigCommandResult(byteArrayOutputStream.toString(utf8))\n+    } catch {\n+      case e: Exception => {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDMwMTk3Mw==", "bodyText": "Logging it at debug level doesn't hurt, so I added it.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r480301973", "createdAt": "2020-08-31T18:13:47Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/unit/kafka/admin/UserScramCredentialsCommandTest.scala", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.admin\n+\n+import java.io.{ByteArrayOutputStream, PrintStream}\n+import java.nio.charset.StandardCharsets\n+\n+import kafka.server.BaseRequestTest\n+import kafka.utils.Exit\n+import org.junit.Assert._\n+import org.junit.Test\n+\n+class UserScramCredentialsCommandTest extends BaseRequestTest {\n+  override def brokerCount = 1\n+  var exitStatus: Option[Int] = None\n+  var exitMessage: Option[String] = None\n+\n+  case class ConfigCommandResult(stdout: String, exitStatus: Option[Int] = None)\n+\n+  private def runConfigCommandViaBroker(args: Array[String]) : ConfigCommandResult = {\n+    val byteArrayOutputStream = new ByteArrayOutputStream()\n+    val utf8 = StandardCharsets.UTF_8.name\n+    val printStream = new PrintStream(byteArrayOutputStream, true, utf8)\n+    var exitStatus: Option[Int] = None\n+    Exit.setExitProcedure { (status, _) =>\n+      exitStatus = Some(status)\n+      throw new RuntimeException\n+    }\n+    try {\n+      Console.withOut(printStream) {\n+        ConfigCommand.main(Array(\"--bootstrap-server\", brokerList) ++ args)\n+      }\n+      ConfigCommandResult(byteArrayOutputStream.toString(utf8))\n+    } catch {\n+      case e: Exception => {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1MTA2MQ=="}, "originalCommit": null, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5Nzg4MTA2OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMjowMjowM1rOHJVlKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxODo1NTozNlrOHKEr0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1MjgxMA==", "bodyText": "Is it necessary to wait for the change to be applied on all brokers after completing the admin client call?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r479552810", "createdAt": "2020-08-28T22:02:03Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala", "diffHunk": "@@ -1047,8 +1047,8 @@ class DynamicBrokerReconfigurationTest extends ZooKeeperTestHarness with SaslSet\n \n   @Test\n   def testAddRemoveSaslListeners(): Unit = {\n-    createScramCredentials(zkConnect, JaasTestUtils.KafkaScramUser, JaasTestUtils.KafkaScramPassword)\n-    createScramCredentials(zkConnect, JaasTestUtils.KafkaScramAdmin, JaasTestUtils.KafkaScramAdminPassword)\n+    createScramCredentials(adminClients.head, JaasTestUtils.KafkaScramUser, JaasTestUtils.KafkaScramPassword)\n+    createScramCredentials(adminClients.head, JaasTestUtils.KafkaScramAdmin, JaasTestUtils.KafkaScramAdminPassword)\n     initializeKerberos()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDMyNDU2MA==", "bodyText": "Good point.  It wasn't waiting before, and it probably didn't/doesn't matter since we were spending time initializing Kerberos, but I added the check anyway just to be safe.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r480324560", "createdAt": "2020-08-31T18:55:36Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala", "diffHunk": "@@ -1047,8 +1047,8 @@ class DynamicBrokerReconfigurationTest extends ZooKeeperTestHarness with SaslSet\n \n   @Test\n   def testAddRemoveSaslListeners(): Unit = {\n-    createScramCredentials(zkConnect, JaasTestUtils.KafkaScramUser, JaasTestUtils.KafkaScramPassword)\n-    createScramCredentials(zkConnect, JaasTestUtils.KafkaScramAdmin, JaasTestUtils.KafkaScramAdminPassword)\n+    createScramCredentials(adminClients.head, JaasTestUtils.KafkaScramUser, JaasTestUtils.KafkaScramPassword)\n+    createScramCredentials(adminClients.head, JaasTestUtils.KafkaScramAdmin, JaasTestUtils.KafkaScramAdminPassword)\n     initializeKerberos()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1MjgxMA=="}, "originalCommit": null, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5Nzg4Nzk5OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMjowNTozNFrOHJVpIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxOTowNDo1OVrOHKE_Yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1MzgyNw==", "bodyText": "So the reason for not using the SaslSertup#createScramCredentials method here is because we want the admin client itself to be authenticated with SCRAM?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r479553827", "createdAt": "2020-08-28T22:05:34Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala", "diffHunk": "@@ -42,7 +42,18 @@ class SaslScramSslEndToEndAuthorizationTest extends SaslEndToEndAuthorizationTes\n   override def setUp(): Unit = {\n     super.setUp()\n     // Create client credentials after starting brokers so that dynamic credential creation is also tested\n-    createScramCredentials(zkConnect, JaasTestUtils.KafkaScramUser, JaasTestUtils.KafkaScramPassword)\n-    createScramCredentials(zkConnect, JaasTestUtils.KafkaScramUser2, JaasTestUtils.KafkaScramPassword2)\n+    createScramCredentialWithScramAdminClient(JaasTestUtils.KafkaScramUser, JaasTestUtils.KafkaScramPassword)\n+    createScramCredentialWithScramAdminClient(JaasTestUtils.KafkaScramUser2, JaasTestUtils.KafkaScramPassword2)\n+  }\n+\n+  private def createScramCredentialWithScramAdminClient(user: String, password: String) = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDMyOTU3MA==", "bodyText": "It was a goal to eliminate all SCRAM credential creation via ZooKeeper where possible.  The only places that do so after this PR are when credentials have to be created before the brokers are started (i.e. when the inter-broker security protocol is SASL/SCRAM).  This code used to create the credential directly via ZooKeeper, but since it occurs after the brokers start it can use the admin client.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r480329570", "createdAt": "2020-08-31T19:04:59Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala", "diffHunk": "@@ -42,7 +42,18 @@ class SaslScramSslEndToEndAuthorizationTest extends SaslEndToEndAuthorizationTes\n   override def setUp(): Unit = {\n     super.setUp()\n     // Create client credentials after starting brokers so that dynamic credential creation is also tested\n-    createScramCredentials(zkConnect, JaasTestUtils.KafkaScramUser, JaasTestUtils.KafkaScramPassword)\n-    createScramCredentials(zkConnect, JaasTestUtils.KafkaScramUser2, JaasTestUtils.KafkaScramPassword2)\n+    createScramCredentialWithScramAdminClient(JaasTestUtils.KafkaScramUser, JaasTestUtils.KafkaScramPassword)\n+    createScramCredentialWithScramAdminClient(JaasTestUtils.KafkaScramUser2, JaasTestUtils.KafkaScramPassword2)\n+  }\n+\n+  private def createScramCredentialWithScramAdminClient(user: String, password: String) = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1MzgyNw=="}, "originalCommit": null, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5Nzg5MTMyOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/integration/kafka/api/SaslClientsWithInvalidCredentialsTest.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMjowNzoxOFrOHJVrFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMDowNzozNlrOHKHfHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1NDMyNA==", "bodyText": "It feels like we are accumulating a lot of these \"create an admin client, but with SCRAM\" functions.  Since all these tests ultimately subclass SaslSetup, can't we have a common function there?", "url": "https://github.com/apache/kafka/pull/9032#discussion_r479554324", "createdAt": "2020-08-28T22:07:18Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/integration/kafka/api/SaslClientsWithInvalidCredentialsTest.scala", "diffHunk": "@@ -248,4 +250,25 @@ class SaslClientsWithInvalidCredentialsTest extends IntegrationTestHarness with\n     producerConfig.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, \"true\")\n     createProducer()\n   }\n+\n+  private def createScramAdminClient(user: String, password: String): Admin = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MDQ2Mw==", "bodyText": "Ok, I added the following code to SaslSetup, and we implement that first method in the 3 test classes that use this functionality.\n  def createPrivilegedAdminClient(): Admin = {\n    // create an admin client instance that is authorized to create credentials\n    throw new UnsupportedOperationException(\"Must implement this if a test needs to use it\")\n  }\n\n  def createScramCredentialsViaPrivilegedAdminClient(userName: String, password: String): Unit = {\n    val privilegedAdminClient = createPrivilegedAdminClient() // must explicitly implement this method\n    try {\n      // create the SCRAM credential for the given user\n      createScramCredentials(privilegedAdminClient, userName, password)\n    } finally {\n      privilegedAdminClient.close()\n    }\n  }", "url": "https://github.com/apache/kafka/pull/9032#discussion_r480370463", "createdAt": "2020-08-31T20:07:36Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/integration/kafka/api/SaslClientsWithInvalidCredentialsTest.scala", "diffHunk": "@@ -248,4 +250,25 @@ class SaslClientsWithInvalidCredentialsTest extends IntegrationTestHarness with\n     producerConfig.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, \"true\")\n     createProducer()\n   }\n+\n+  private def createScramAdminClient(user: String, password: String): Admin = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1NDMyNA=="}, "originalCommit": null, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5Nzg5NTM1OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/integration/kafka/api/EndToEndAuthorizationTest.scala", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMjowOTo0MFrOHJVtXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMToyNDo1NFrOHKJvlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1NDkxMQ==", "bodyText": "can we create a common function in SaslSetup for this?  Seems to be repeated in a lot of tests.", "url": "https://github.com/apache/kafka/pull/9032#discussion_r479554911", "createdAt": "2020-08-28T22:09:40Z", "author": {"login": "cmccabe"}, "path": "core/src/test/scala/integration/kafka/api/EndToEndAuthorizationTest.scala", "diffHunk": "@@ -545,6 +558,16 @@ abstract class EndToEndAuthorizationTest extends IntegrationTestHarness with Sas\n     }\n   }\n \n+  protected def createScramAdminClient(scramMechanism: String, user: String, password: String): Admin = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MDYzNA==", "bodyText": "See above", "url": "https://github.com/apache/kafka/pull/9032#discussion_r480370634", "createdAt": "2020-08-31T20:07:57Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/integration/kafka/api/EndToEndAuthorizationTest.scala", "diffHunk": "@@ -545,6 +558,16 @@ abstract class EndToEndAuthorizationTest extends IntegrationTestHarness with Sas\n     }\n   }\n \n+  protected def createScramAdminClient(scramMechanism: String, user: String, password: String): Admin = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1NDkxMQ=="}, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQwNzQ0NQ==", "bodyText": "Ok, this now invokes a new method on SaslSetup().", "url": "https://github.com/apache/kafka/pull/9032#discussion_r480407445", "createdAt": "2020-08-31T21:24:54Z", "author": {"login": "rondagostino"}, "path": "core/src/test/scala/integration/kafka/api/EndToEndAuthorizationTest.scala", "diffHunk": "@@ -545,6 +558,16 @@ abstract class EndToEndAuthorizationTest extends IntegrationTestHarness with Sas\n     }\n   }\n \n+  protected def createScramAdminClient(scramMechanism: String, user: String, password: String): Admin = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTU1NDkxMQ=="}, "originalCommit": null, "originalPosition": 68}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2280, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}