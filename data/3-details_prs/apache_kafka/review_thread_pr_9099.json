{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4NDIxMjc4", "number": 9099, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMzo0MDo0NVrOETQk6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMzo0NzozMVrOETQw7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjI5OTk0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/tools/ConsoleConsumer.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMzo0MDo0NVrOG4487Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNDo0NDo1OFrOG7jyRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMwNjU0MQ==", "bodyText": "init(props: Properties) has been deprecated. It would be great if we could keep using configure(configs: Map[String, _]) as before. I think that we should also try to directly extract the values from the Map instead of using a Properties.", "url": "https://github.com/apache/kafka/pull/9099#discussion_r462306541", "createdAt": "2020-07-29T13:40:45Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/tools/ConsoleConsumer.scala", "diffHunk": "@@ -459,48 +466,32 @@ class DefaultMessageFormatter extends MessageFormatter {\n   var printKey = false\n   var printValue = true\n   var printPartition = false\n-  var keySeparator = \"\\t\".getBytes(StandardCharsets.UTF_8)\n-  var lineSeparator = \"\\n\".getBytes(StandardCharsets.UTF_8)\n+  var printOffset = false\n+  var printHeaders = false\n+  var keySeparator = utfBytes(\"\\t\")\n+  var lineSeparator = utfBytes(\"\\n\")\n+  var headersSeparator = utfBytes(\",\")\n+  var nullLiteral = utfBytes(\"null\")\n \n   var keyDeserializer: Option[Deserializer[_]] = None\n   var valueDeserializer: Option[Deserializer[_]] = None\n-\n-  override def configure(configs: Map[String, _]): Unit = {\n-    val props = new java.util.Properties()\n-    configs.asScala.foreach { case (key, value) => props.put(key, value.toString) }\n-    if (props.containsKey(\"print.timestamp\"))\n-      printTimestamp = props.getProperty(\"print.timestamp\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"print.key\"))\n-      printKey = props.getProperty(\"print.key\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"print.value\"))\n-      printValue = props.getProperty(\"print.value\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"print.partition\"))\n-      printPartition = props.getProperty(\"print.partition\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"key.separator\"))\n-      keySeparator = props.getProperty(\"key.separator\").getBytes(StandardCharsets.UTF_8)\n-    if (props.containsKey(\"line.separator\"))\n-      lineSeparator = props.getProperty(\"line.separator\").getBytes(StandardCharsets.UTF_8)\n-    // Note that `toString` will be called on the instance returned by `Deserializer.deserialize`\n-    if (props.containsKey(\"key.deserializer\")) {\n-      keyDeserializer = Some(Class.forName(props.getProperty(\"key.deserializer\")).getDeclaredConstructor()\n-        .newInstance().asInstanceOf[Deserializer[_]])\n-      keyDeserializer.get.configure(propertiesWithKeyPrefixStripped(\"key.deserializer.\", props).asScala.asJava, true)\n-    }\n-    // Note that `toString` will be called on the instance returned by `Deserializer.deserialize`\n-    if (props.containsKey(\"value.deserializer\")) {\n-      valueDeserializer = Some(Class.forName(props.getProperty(\"value.deserializer\")).getDeclaredConstructor()\n-        .newInstance().asInstanceOf[Deserializer[_]])\n-      valueDeserializer.get.configure(propertiesWithKeyPrefixStripped(\"value.deserializer.\", props).asScala.asJava, false)\n-    }\n-  }\n-\n-  private def propertiesWithKeyPrefixStripped(prefix: String, props: Properties): Properties = {\n-    val newProps = new Properties()\n-    props.asScala.foreach { case (key, value) =>\n-      if (key.startsWith(prefix) && key.length > prefix.length)\n-        newProps.put(key.substring(prefix.length), value)\n-    }\n-    newProps\n+  var headersDeserializer: Option[Deserializer[_]] = None\n+\n+  override def init(props: Properties): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTEwNTQ3Ng==", "bodyText": "@dajac\nI have replaced init with configure and changed code to extract the values directly from Map. Please review again.", "url": "https://github.com/apache/kafka/pull/9099#discussion_r465105476", "createdAt": "2020-08-04T14:44:58Z", "author": {"login": "badaiaqrandista"}, "path": "core/src/main/scala/kafka/tools/ConsoleConsumer.scala", "diffHunk": "@@ -459,48 +466,32 @@ class DefaultMessageFormatter extends MessageFormatter {\n   var printKey = false\n   var printValue = true\n   var printPartition = false\n-  var keySeparator = \"\\t\".getBytes(StandardCharsets.UTF_8)\n-  var lineSeparator = \"\\n\".getBytes(StandardCharsets.UTF_8)\n+  var printOffset = false\n+  var printHeaders = false\n+  var keySeparator = utfBytes(\"\\t\")\n+  var lineSeparator = utfBytes(\"\\n\")\n+  var headersSeparator = utfBytes(\",\")\n+  var nullLiteral = utfBytes(\"null\")\n \n   var keyDeserializer: Option[Deserializer[_]] = None\n   var valueDeserializer: Option[Deserializer[_]] = None\n-\n-  override def configure(configs: Map[String, _]): Unit = {\n-    val props = new java.util.Properties()\n-    configs.asScala.foreach { case (key, value) => props.put(key, value.toString) }\n-    if (props.containsKey(\"print.timestamp\"))\n-      printTimestamp = props.getProperty(\"print.timestamp\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"print.key\"))\n-      printKey = props.getProperty(\"print.key\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"print.value\"))\n-      printValue = props.getProperty(\"print.value\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"print.partition\"))\n-      printPartition = props.getProperty(\"print.partition\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"key.separator\"))\n-      keySeparator = props.getProperty(\"key.separator\").getBytes(StandardCharsets.UTF_8)\n-    if (props.containsKey(\"line.separator\"))\n-      lineSeparator = props.getProperty(\"line.separator\").getBytes(StandardCharsets.UTF_8)\n-    // Note that `toString` will be called on the instance returned by `Deserializer.deserialize`\n-    if (props.containsKey(\"key.deserializer\")) {\n-      keyDeserializer = Some(Class.forName(props.getProperty(\"key.deserializer\")).getDeclaredConstructor()\n-        .newInstance().asInstanceOf[Deserializer[_]])\n-      keyDeserializer.get.configure(propertiesWithKeyPrefixStripped(\"key.deserializer.\", props).asScala.asJava, true)\n-    }\n-    // Note that `toString` will be called on the instance returned by `Deserializer.deserialize`\n-    if (props.containsKey(\"value.deserializer\")) {\n-      valueDeserializer = Some(Class.forName(props.getProperty(\"value.deserializer\")).getDeclaredConstructor()\n-        .newInstance().asInstanceOf[Deserializer[_]])\n-      valueDeserializer.get.configure(propertiesWithKeyPrefixStripped(\"value.deserializer.\", props).asScala.asJava, false)\n-    }\n-  }\n-\n-  private def propertiesWithKeyPrefixStripped(prefix: String, props: Properties): Properties = {\n-    val newProps = new Properties()\n-    props.asScala.foreach { case (key, value) =>\n-      if (key.startsWith(prefix) && key.length > prefix.length)\n-        newProps.put(key.substring(prefix.length), value)\n-    }\n-    newProps\n+  var headersDeserializer: Option[Deserializer[_]] = None\n+\n+  override def init(props: Properties): Unit = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMwNjU0MQ=="}, "originalCommit": null, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NjMzMDY5OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/kafka/tools/DefaultMessageFormatterTest.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMzo0NzozMVrOG45Qeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNDo0NToyOFrOG7jz6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMxMTU0Ng==", "bodyText": "nit: Move print.key to next line to remain consistent with the formatting of the other Maps.", "url": "https://github.com/apache/kafka/pull/9099#discussion_r462311546", "createdAt": "2020-07-29T13:47:31Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/kafka/tools/DefaultMessageFormatterTest.scala", "diffHunk": "@@ -0,0 +1,235 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  * http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package unit.kafka.tools\n+\n+import java.io.{ByteArrayOutputStream, Closeable, PrintStream}\n+import java.nio.charset.StandardCharsets\n+import java.util\n+import java.util.Properties\n+\n+import kafka.tools.DefaultMessageFormatter\n+import org.apache.kafka.clients.consumer.ConsumerRecord\n+import org.apache.kafka.common.header.Header\n+import org.apache.kafka.common.header.internals.{RecordHeader, RecordHeaders}\n+import org.apache.kafka.common.record.TimestampType\n+import org.apache.kafka.common.serialization.Deserializer\n+import org.junit.Assert._\n+import org.junit.Test\n+import org.junit.runner.RunWith\n+import org.junit.runners.Parameterized\n+import org.junit.runners.Parameterized.Parameters\n+\n+import scala.jdk.CollectionConverters._\n+\n+@RunWith(value = classOf[Parameterized])\n+class DefaultMessageFormatterTest(name: String, record: ConsumerRecord[Array[Byte], Array[Byte]], properties: Map[String, String], expected: String) {\n+  import DefaultMessageFormatterTest._\n+\n+  @Test\n+  def testWriteRecord()= {\n+    withResource(new ByteArrayOutputStream()) { baos =>\n+      withResource(new PrintStream(baos)) { ps =>\n+        val formatter = buildFormatter(properties)\n+        formatter.writeTo(record, ps)\n+        val actual = new String(baos.toByteArray(), StandardCharsets.UTF_8)\n+        assertEquals(expected, actual)\n+\n+      }\n+    }\n+  }\n+}\n+\n+object DefaultMessageFormatterTest {\n+  @Parameters(name = \"Test {index} - {0}\")\n+  def parameters: java.util.Collection[Array[Object]] = {\n+    Seq(\n+      Array(\n+        \"print nothing\",\n+        consumerRecord(),\n+        Map(\"print.value\" -> \"false\"),\n+        \"\"),\n+      Array(\n+        \"print key\",\n+        consumerRecord(),\n+        Map(\"print.key\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"someKey\\n\"),\n+      Array(\n+        \"print value\",\n+        consumerRecord(),\n+        Map(),\n+        \"someValue\\n\"),\n+      Array(\n+        \"print empty timestamp\",\n+        consumerRecord(timestampType = TimestampType.NO_TIMESTAMP_TYPE),\n+        Map(\"print.timestamp\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"NO_TIMESTAMP\\n\"),\n+      Array(\n+        \"print log append time timestamp\",\n+        consumerRecord(timestampType = TimestampType.LOG_APPEND_TIME),\n+        Map(\"print.timestamp\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"LogAppendTime:1234\\n\"),\n+      Array(\n+        \"print create time timestamp\",\n+        consumerRecord(timestampType = TimestampType.CREATE_TIME),\n+        Map(\"print.timestamp\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"CreateTime:1234\\n\"),\n+      Array(\n+        \"print partition\",\n+        consumerRecord(),\n+        Map(\"print.partition\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"Partition:9\\n\"),\n+      Array(\n+        \"print offset\",\n+        consumerRecord(),\n+        Map(\"print.offset\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"Offset:9876\\n\"),\n+      Array(\n+        \"print headers\",\n+        consumerRecord(),\n+        Map(\"print.headers\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"h1:v1,h2:v2\\n\"),\n+      Array(\n+        \"print empty headers\",\n+        consumerRecord(headers = Nil),\n+        Map(\"print.headers\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"NO_HEADERS\\n\"),\n+      Array(\n+        \"print all possible fields with default delimiters\",\n+        consumerRecord(),\n+        Map(\"print.key\" -> \"true\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTEwNTg5Nw==", "bodyText": "@dajac\nI've re-indent these as well.", "url": "https://github.com/apache/kafka/pull/9099#discussion_r465105897", "createdAt": "2020-08-04T14:45:28Z", "author": {"login": "badaiaqrandista"}, "path": "core/src/test/scala/kafka/tools/DefaultMessageFormatterTest.scala", "diffHunk": "@@ -0,0 +1,235 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  * http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package unit.kafka.tools\n+\n+import java.io.{ByteArrayOutputStream, Closeable, PrintStream}\n+import java.nio.charset.StandardCharsets\n+import java.util\n+import java.util.Properties\n+\n+import kafka.tools.DefaultMessageFormatter\n+import org.apache.kafka.clients.consumer.ConsumerRecord\n+import org.apache.kafka.common.header.Header\n+import org.apache.kafka.common.header.internals.{RecordHeader, RecordHeaders}\n+import org.apache.kafka.common.record.TimestampType\n+import org.apache.kafka.common.serialization.Deserializer\n+import org.junit.Assert._\n+import org.junit.Test\n+import org.junit.runner.RunWith\n+import org.junit.runners.Parameterized\n+import org.junit.runners.Parameterized.Parameters\n+\n+import scala.jdk.CollectionConverters._\n+\n+@RunWith(value = classOf[Parameterized])\n+class DefaultMessageFormatterTest(name: String, record: ConsumerRecord[Array[Byte], Array[Byte]], properties: Map[String, String], expected: String) {\n+  import DefaultMessageFormatterTest._\n+\n+  @Test\n+  def testWriteRecord()= {\n+    withResource(new ByteArrayOutputStream()) { baos =>\n+      withResource(new PrintStream(baos)) { ps =>\n+        val formatter = buildFormatter(properties)\n+        formatter.writeTo(record, ps)\n+        val actual = new String(baos.toByteArray(), StandardCharsets.UTF_8)\n+        assertEquals(expected, actual)\n+\n+      }\n+    }\n+  }\n+}\n+\n+object DefaultMessageFormatterTest {\n+  @Parameters(name = \"Test {index} - {0}\")\n+  def parameters: java.util.Collection[Array[Object]] = {\n+    Seq(\n+      Array(\n+        \"print nothing\",\n+        consumerRecord(),\n+        Map(\"print.value\" -> \"false\"),\n+        \"\"),\n+      Array(\n+        \"print key\",\n+        consumerRecord(),\n+        Map(\"print.key\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"someKey\\n\"),\n+      Array(\n+        \"print value\",\n+        consumerRecord(),\n+        Map(),\n+        \"someValue\\n\"),\n+      Array(\n+        \"print empty timestamp\",\n+        consumerRecord(timestampType = TimestampType.NO_TIMESTAMP_TYPE),\n+        Map(\"print.timestamp\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"NO_TIMESTAMP\\n\"),\n+      Array(\n+        \"print log append time timestamp\",\n+        consumerRecord(timestampType = TimestampType.LOG_APPEND_TIME),\n+        Map(\"print.timestamp\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"LogAppendTime:1234\\n\"),\n+      Array(\n+        \"print create time timestamp\",\n+        consumerRecord(timestampType = TimestampType.CREATE_TIME),\n+        Map(\"print.timestamp\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"CreateTime:1234\\n\"),\n+      Array(\n+        \"print partition\",\n+        consumerRecord(),\n+        Map(\"print.partition\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"Partition:9\\n\"),\n+      Array(\n+        \"print offset\",\n+        consumerRecord(),\n+        Map(\"print.offset\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"Offset:9876\\n\"),\n+      Array(\n+        \"print headers\",\n+        consumerRecord(),\n+        Map(\"print.headers\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"h1:v1,h2:v2\\n\"),\n+      Array(\n+        \"print empty headers\",\n+        consumerRecord(headers = Nil),\n+        Map(\"print.headers\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"NO_HEADERS\\n\"),\n+      Array(\n+        \"print all possible fields with default delimiters\",\n+        consumerRecord(),\n+        Map(\"print.key\" -> \"true\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMxMTU0Ng=="}, "originalCommit": null, "originalPosition": 114}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2040, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}