{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyNTQ0MDY3", "number": 8060, "title": "KAFKA-9274: Gracefully handle timeout exception", "bodyText": "Delay the initialization (producer.initTxn) from construction to maybeInitialize; if it times out we just swallow and retry in the next iteration.\n\n\nIf completeRestoration (consumer.committed) times out, just swallow and retry in the next iteration.\n\n\nFor other calls (producer.partitionsFor, producer.commitTxn, consumer.commit), treat the timeout exception as fatal.\n\n\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-02-07T18:32:39Z", "url": "https://github.com/apache/kafka/pull/8060", "merged": true, "mergeCommit": {"oid": "d8756e81c57040130ec163e63798663d62298589"}, "closed": true, "closedAt": "2020-02-15T01:28:15Z", "author": {"login": "guozhangwang"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcCzaQVAFqTM1NTY1NzEwMw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcEXlNHAFqTM1OTI2MjI1MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NjU3MTAz", "url": "https://github.com/apache/kafka/pull/8060#pullrequestreview-355657103", "createdAt": "2020-02-10T01:39:49Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQwMTozOTo0OVrOFnYcVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQwMjowNjowNlrOFnYrIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjgzOTI1Mg==", "bodyText": "If we change the semantic, we should update the class JavaDocs accordingly -- also, do we need to state that \"It means all tasks belonging to this thread have been migrated\" ?", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376839252", "createdAt": "2020-02-10T01:39:49Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/errors/TaskMigratedException.java", "diffHunk": "@@ -32,43 +29,7 @@\n \n     private final static long serialVersionUID = 1L;\n \n-    private final TaskId taskId;\n-\n-    public TaskMigratedException(final TaskId taskId,\n-                                 final TopicPartition topicPartition,\n-                                 final long endOffset,\n-                                 final long pos) {\n-        this(taskId, String.format(\"Log end offset of %s should not change while restoring: old end offset %d, current offset %d\",\n-            topicPartition,\n-            endOffset,\n-            pos), null);\n-    }\n-\n-    public TaskMigratedException(final TaskId taskId) {\n-        this(taskId, String.format(\"Task %s is unexpectedly closed during processing\", taskId), null);\n-    }\n-\n-    public TaskMigratedException(final TaskId taskId,\n-                                 final Throwable throwable) {\n-        this(taskId, String.format(\"Client request for task %s has been fenced due to a rebalance\", taskId), throwable);\n-    }\n-\n-    public TaskMigratedException(final TaskId taskId,\n-                                 final String message,\n-                                 final Throwable throwable) {\n-        super(message, throwable);\n-        this.taskId = taskId;\n-    }\n-\n     public TaskMigratedException(final String message, final Throwable throwable) {\n-        this(null, message + \" It means all tasks belonging to this thread have been migrated\", throwable);\n-    }\n-\n-    public TaskId migratedTaskId() {\n-        return taskId;\n-    }\n-\n-    public TaskMigratedException() {\n-        this(null, \"A task has been migrated unexpectedly\", null);\n+        super(message + \"; It means all tasks belonging to this thread have been migrated\", throwable);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjgzOTQ0NQ==", "bodyText": "Why do we need to clear the store now but not before?", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376839445", "createdAt": "2020-02-10T01:41:24Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -415,6 +415,8 @@ public void close() throws ProcessorStateException {\n                     log.error(\"Failed to close state store {}: \", store.name(), exception);\n                 }\n             }\n+\n+            stores.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg0MDE3OQ==", "bodyText": "Well -- we could also \"buffer\" the record and try to send it later? In the mean time we would need to pause the corresponding task though to not process more input records (or course, we would need to let the task finish processing the current input record what might lead to more output records that we would need to buffer, too). -- This is just a wild thought and we could also handle this case later if required.", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376840179", "createdAt": "2020-02-10T01:47:14Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordCollectorImpl.java", "diffHunk": "@@ -244,9 +252,16 @@ private void recordSendError(final String topic, final Exception exception, fina\n                             final StreamPartitioner<? super K, ? super V> partitioner) {\n         final Integer partition;\n \n-        // TODO K9113: we need to decide how to handle exceptions from partitionsFor\n         if (partitioner != null) {\n-            final List<PartitionInfo> partitions = producer.partitionsFor(topic);\n+            final List<PartitionInfo> partitions;\n+            try {\n+                partitions = producer.partitionsFor(topic);\n+            } catch (final KafkaException e) {\n+                // here we cannot drop the message on the floor even if it is a transient timeout exception,\n+                // so we treat everything the same as a fatal exception", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg0MDQ5OA==", "bodyText": "Does the consumer not log this already within assign(...) ?", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376840498", "createdAt": "2020-02-10T01:49:23Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java", "diffHunk": "@@ -679,6 +691,8 @@ private void addChangelogsToRestoreConsumer(final Set<TopicPartition> partitions\n         }\n         assignment.addAll(partitions);\n         restoreConsumer.assign(assignment);\n+\n+        log.debug(\"Added partitions {} to the restore consumer, current assignment is {}\", partitions, assignment);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg0MDUxOQ==", "bodyText": "Same question as above (this question comes up for more log statements below -- don't add a comment each time)", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376840519", "createdAt": "2020-02-10T01:49:35Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java", "diffHunk": "@@ -690,18 +704,18 @@ private void pauseChangelogsFromRestoreConsumer(final Collection<TopicPartition>\n                 \"does not contain some of the partitions \" + partitions + \" for pausing.\");\n         }\n         restoreConsumer.pause(partitions);\n+\n+        log.debug(\"Paused partitions {} from the restore consumer\", partitions);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg0MTUyMw==", "bodyText": "nit: we should use ConsumerConfig.DEFAULT_API_TIMEOUT_MS_CONFIG instead of a hard-coded string -- in case we ever deprecate the config we would figure out that we might want to update this log statement", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376841523", "createdAt": "2020-02-10T01:55:44Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -597,6 +600,11 @@ private void initializeMetadata() {\n                 .filter(e -> e.getValue() != null)\n                 .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n             initializeTaskTime(offsetsAndMetadata);\n+        } catch (final TimeoutException e) {\n+            log.warn(\"Encountered {} while trying to fetch committed offsets, will retry initializing the metadata in the next loop.\" +\n+                \"\\nConsider overwriting consumer config `default.api.timeout.ms` to a larger value to avoid timeout errors\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg0MTY1OA==", "bodyText": "Why do we throw TimeoutException directly but not wrap it?", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376841658", "createdAt": "2020-02-10T01:56:41Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -597,6 +600,11 @@ private void initializeMetadata() {\n                 .filter(e -> e.getValue() != null)\n                 .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n             initializeTaskTime(offsetsAndMetadata);\n+        } catch (final TimeoutException e) {\n+            log.warn(\"Encountered {} while trying to fetch committed offsets, will retry initializing the metadata in the next loop.\" +\n+                \"\\nConsider overwriting consumer config `default.api.timeout.ms` to a larger value to avoid timeout errors\");\n+\n+            throw e;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg0MTg1Mw==", "bodyText": "To what extent do we skip? Seems the method just executes as always?", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376841853", "createdAt": "2020-02-10T01:58:04Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -692,9 +700,10 @@ private void closeRecordCollector(final boolean clean) {\n     @Override\n     public void addRecords(final TopicPartition partition, final Iterable<ConsumerRecord<byte[], byte[]>> records) {\n         if (state() == State.CLOSED || state() == State.CLOSING) {\n-            log.info(\"Stream task {} is already closed, probably because it got unexpectedly migrated to another thread already. \" +\n-                         \"Notifying the thread to trigger a new rebalance immediately.\", id());\n-            throw new TaskMigratedException(id());\n+            // a task is only closing / closed when 1) task manager is closing, 2) a rebalance is undergoing;\n+            // in either case we can just log it and move on without notifying the thread since the consumer\n+            // would soon be updated to not return any records for this task anymore.\n+            log.info(\"Stream task {} is already in {} state, skip adding records to it.\", id(), state());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg0MjA0Mg==", "bodyText": "Do we need to distinguish StreamsException and KafkaException (StreamsException is a KafkaException and both are fatal)`?\nActually similar question about KafkaException and Exception? The different error messages don't seems to provide much value?", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376842042", "createdAt": "2020-02-10T01:59:17Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -718,14 +719,20 @@ public void run() {\n         try {\n             runLoop();\n             cleanRun = true;\n+        } catch (final StreamsException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg0MjQ3MQ==", "bodyText": "Should we keep this check and add final else that throws an IllegalStateException instead?", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376842471", "createdAt": "2020-02-10T02:01:38Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -936,7 +950,7 @@ private void resetInvalidOffsets(final InvalidOffsetException e) {\n \n                 if (originalReset.equals(\"earliest\")) {\n                     addToResetList(partition, seekToBeginning, \"No custom setting defined for topic '{}' using original config '{}' for offset reset\", \"earliest\", loggedTopics);\n-                } else if (originalReset.equals(\"latest\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg0MzA0MA==", "bodyText": "Why do we only remove the task if it was active now?", "url": "https://github.com/apache/kafka/pull/8060#discussion_r376843040", "createdAt": "2020-02-10T02:06:06Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -285,18 +306,13 @@ void handleLostAll() {\n         final Iterator<Task> iterator = tasks.values().iterator();\n         while (iterator.hasNext()) {\n             final Task task = iterator.next();\n-            final Set<TopicPartition> inputPartitions = task.inputPartitions();\n             // Even though we've apparently dropped out of the group, we can continue safely to maintain our\n             // standby tasks while we rejoin.\n             if (task.isActive()) {\n+                cleanupTask(task);\n                 task.closeDirty();\n-                changelogReader.remove(task.changelogPartitions());\n-            }\n-\n-            for (final TopicPartition inputPartition : inputPartitions) {\n-                partitionToTask.remove(inputPartition);\n+                iterator.remove();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 165}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74cfbf1a779b7dd3fb3a1ee9f4277338cd9a66d3", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/74cfbf1a779b7dd3fb3a1ee9f4277338cd9a66d3", "committedDate": "2020-02-14T21:30:16Z", "message": "timeout for committed and initTxn"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "74cfbf1a779b7dd3fb3a1ee9f4277338cd9a66d3", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/74cfbf1a779b7dd3fb3a1ee9f4277338cd9a66d3", "committedDate": "2020-02-14T21:30:16Z", "message": "timeout for committed and initTxn"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "19332579cacd46146a8309938215845c16448a8d", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/19332579cacd46146a8309938215845c16448a8d", "committedDate": "2020-02-14T22:46:30Z", "message": "improve producer unit test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU5MjYxOTY5", "url": "https://github.com/apache/kafka/pull/8060#pullrequestreview-359261969", "createdAt": "2020-02-14T22:49:14Z", "commit": {"oid": "19332579cacd46146a8309938215845c16448a8d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQyMjo0OToxNFrOFqFxwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQyMjo0OToxNFrOFqFxwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY3OTE2OQ==", "bodyText": "This is just to verify that initTransactions can indeed be retried. cc @hachikuji", "url": "https://github.com/apache/kafka/pull/8060#discussion_r379679169", "createdAt": "2020-02-14T22:49:14Z", "author": {"login": "guozhangwang"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -761,7 +762,18 @@ public void testInitTransactionTimeout() {\n \n         try (Producer<String, String> producer = new KafkaProducer<>(configs, new StringSerializer(),\n                 new StringSerializer(), metadata, client, null, time)) {\n+            client.prepareResponse(\n+                request -> request instanceof FindCoordinatorRequest &&\n+                    ((FindCoordinatorRequest) request).data().keyType() == FindCoordinatorRequest.CoordinatorType.TRANSACTION.id(),\n+                FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n+\n             assertThrows(TimeoutException.class, producer::initTransactions);\n+\n+            client.respond(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n+            client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n+\n+            // retry initialization should work\n+            producer.initTransactions();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19332579cacd46146a8309938215845c16448a8d"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU5MjYyMjUx", "url": "https://github.com/apache/kafka/pull/8060#pullrequestreview-359262251", "createdAt": "2020-02-14T22:50:14Z", "commit": {"oid": "19332579cacd46146a8309938215845c16448a8d"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1794, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}