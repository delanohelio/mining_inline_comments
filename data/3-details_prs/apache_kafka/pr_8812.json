{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI4NTU0NDYw", "number": 8812, "title": "KAFKA-10101: Fix edge cases in Log.recoverLog and LogManager.loadLogs", "bodyText": "Don't advance recovery point in recoverLog unless there was a clean\nshutdown.\nEnsure the recovery point is not ahead of the log end offset.\nClean and flush leader epoch cache and truncate produce state manager\nif deleting segments due to log end offset being smaller than log start\noffset.\nIf we are unable to delete clean shutdown file that exists, mark the\ndirectory as offline (this was the intent, but the code was wrong).\n\nUpdated one test that was failing after this change to verify the new behavior.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-06-05T16:13:16Z", "url": "https://github.com/apache/kafka/pull/8812", "merged": true, "mergeCommit": {"oid": "068d8fedcb34dcb2d07a6375bd267d3323c7e06c"}, "closed": true, "closedAt": "2021-02-26T22:40:46Z", "author": {"login": "ijuma"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcoVD_UgFqTQyNTQ0MDUwNw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABd-A_dJgFqTU5OTk1NTQxNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDQwNTA3", "url": "https://github.com/apache/kafka/pull/8812#pullrequestreview-425440507", "createdAt": "2020-06-05T16:15:25Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoxNToyNVrOGf01Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNjoxNToyNVrOGf01Hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyNDYwNw==", "bodyText": "@junrao does this seem right? If we don't have any segments, we should be able to completely truncate the producer state manager, right?", "url": "https://github.com/apache/kafka/pull/8812#discussion_r436024607", "createdAt": "2020-06-05T16:15:25Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -806,14 +806,20 @@ class Log(@volatile private var _dir: File,\n       }\n     }\n \n-    if (logSegments.nonEmpty) {\n-      val logEndOffset = activeSegment.readNextOffset\n-      if (logEndOffset < logStartOffset) {\n-        warn(s\"Deleting all segments because logEndOffset ($logEndOffset) is smaller than logStartOffset ($logStartOffset). \" +\n-          \"This could happen if segment files were deleted from the file system.\")\n-        removeAndDeleteSegments(logSegments, asyncDelete = true)\n-      }\n-    }\n+    val logEndOffsetOption: Option[Long] =\n+      if (logSegments.nonEmpty) {\n+        val logEndOffset = activeSegment.readNextOffset\n+        if (logEndOffset >= logStartOffset)\n+          Some(logEndOffset)\n+        else {\n+          warn(s\"Deleting all segments because logEndOffset ($logEndOffset) is smaller than logStartOffset ($logStartOffset). \" +\n+            \"This could happen if segment files were deleted from the file system.\")\n+          removeAndDeleteSegments(logSegments, asyncDelete = false)\n+          leaderEpochCache.foreach(_.clearAndFlush())\n+          producerStateManager.truncate()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDY2OTQy", "url": "https://github.com/apache/kafka/pull/8812#pullrequestreview-425466942", "createdAt": "2020-06-05T16:54:27Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3", "author": {"user": {"login": "ijuma", "name": "Ismael Juma"}}, "url": "https://github.com/apache/kafka/commit/0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3", "committedDate": "2020-06-05T17:21:24Z", "message": "KAFKA-10101: Fix edge cases in Log.recoverLog and LogManager.loadLogs\n\n1. Don't advance recovery point in `recoverLog` unless there was a clean\nshutdown.\n2. Ensure the recovery point is not ahead of the log end offset.\n3. Clean and flush leader epoch cache and truncate produce state manager\nif deleting segments due to log end offset being smaller than log start\noffset.\n4. If we are unable to delete clean shutdown file that exists, mark the\ndirectory as offline (this was the intent, but the code was wrong)."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NjI3NTI0", "url": "https://github.com/apache/kafka/pull/8812#pullrequestreview-425627524", "createdAt": "2020-06-05T21:10:41Z", "commit": {"oid": "0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQyMToxMDo0MVrOGf9c1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQyMTo0Mjo1OFrOGf-I8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE2NTg0Nw==", "bodyText": "nit: this is a big initializer. Are there parts we could move to a method?", "url": "https://github.com/apache/kafka/pull/8812#discussion_r436165847", "createdAt": "2020-06-05T21:10:41Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -806,14 +806,20 @@ class Log(@volatile private var _dir: File,\n       }\n     }\n \n-    if (logSegments.nonEmpty) {\n-      val logEndOffset = activeSegment.readNextOffset\n-      if (logEndOffset < logStartOffset) {\n-        warn(s\"Deleting all segments because logEndOffset ($logEndOffset) is smaller than logStartOffset ($logStartOffset). \" +\n-          \"This could happen if segment files were deleted from the file system.\")\n-        removeAndDeleteSegments(logSegments, asyncDelete = true)\n-      }\n-    }\n+    val logEndOffsetOption: Option[Long] =\n+      if (logSegments.nonEmpty) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE2Njc0Mw==", "bodyText": "Hmm, not sure about this. After KIP-360, we try to retain producer state as long as possible even when the corresponding entries have been removed from the log. However, we're in a strange state given that some of the later segments were apparently removed. Perhaps it is safer to treat this more like a new replica which is starting from scratch.", "url": "https://github.com/apache/kafka/pull/8812#discussion_r436166743", "createdAt": "2020-06-05T21:13:05Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -806,14 +806,20 @@ class Log(@volatile private var _dir: File,\n       }\n     }\n \n-    if (logSegments.nonEmpty) {\n-      val logEndOffset = activeSegment.readNextOffset\n-      if (logEndOffset < logStartOffset) {\n-        warn(s\"Deleting all segments because logEndOffset ($logEndOffset) is smaller than logStartOffset ($logStartOffset). \" +\n-          \"This could happen if segment files were deleted from the file system.\")\n-        removeAndDeleteSegments(logSegments, asyncDelete = true)\n-      }\n-    }\n+    val logEndOffsetOption: Option[Long] =\n+      if (logSegments.nonEmpty) {\n+        val logEndOffset = activeSegment.readNextOffset\n+        if (logEndOffset >= logStartOffset)\n+          Some(logEndOffset)\n+        else {\n+          warn(s\"Deleting all segments because logEndOffset ($logEndOffset) is smaller than logStartOffset ($logStartOffset). \" +\n+            \"This could happen if segment files were deleted from the file system.\")\n+          removeAndDeleteSegments(logSegments, asyncDelete = false)\n+          leaderEpochCache.foreach(_.clearAndFlush())\n+          producerStateManager.truncate()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyNDYwNw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE2OTIyMw==", "bodyText": "I guess it is because of the semantics of DeleteRecords that we trust the checkpoint over the segment data. Might be worth a comment about that since it is a bit surprising.", "url": "https://github.com/apache/kafka/pull/8812#discussion_r436169223", "createdAt": "2020-06-05T21:20:00Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -806,14 +806,20 @@ class Log(@volatile private var _dir: File,\n       }\n     }\n \n-    if (logSegments.nonEmpty) {\n-      val logEndOffset = activeSegment.readNextOffset\n-      if (logEndOffset < logStartOffset) {\n-        warn(s\"Deleting all segments because logEndOffset ($logEndOffset) is smaller than logStartOffset ($logStartOffset). \" +\n-          \"This could happen if segment files were deleted from the file system.\")\n-        removeAndDeleteSegments(logSegments, asyncDelete = true)\n-      }\n-    }\n+    val logEndOffsetOption: Option[Long] =\n+      if (logSegments.nonEmpty) {\n+        val logEndOffset = activeSegment.readNextOffset\n+        if (logEndOffset >= logStartOffset)\n+          Some(logEndOffset)\n+        else {\n+          warn(s\"Deleting all segments because logEndOffset ($logEndOffset) is smaller than logStartOffset ($logStartOffset). \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE3MjY5NA==", "bodyText": "Just checking, but the issue here is that we might mistakenly mark the directory is offline if the clean shutdown file did not exist?", "url": "https://github.com/apache/kafka/pull/8812#discussion_r436172694", "createdAt": "2020-06-05T21:29:58Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -360,7 +360,7 @@ class LogManager(logDirs: Seq[File],\n       for ((cleanShutdownFile, dirJobs) <- jobs) {\n         dirJobs.foreach(_.get)\n         try {\n-          cleanShutdownFile.delete()\n+          Files.deleteIfExists(cleanShutdownFile.toPath)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE3NjQ0NQ==", "bodyText": "Hmm, logEndOffset is defined by nextOffsetMetadata, which is initialized after loadSegments returns. But recoverLog is called within loadSegments. So does this check work as expected or am I missing something?", "url": "https://github.com/apache/kafka/pull/8812#discussion_r436176445", "createdAt": "2020-06-05T21:40:55Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -826,8 +832,16 @@ class Log(@volatile private var _dir: File,\n         preallocate = config.preallocate))\n     }\n \n-    recoveryPoint = activeSegment.readNextOffset\n-    recoveryPoint\n+    // Update the recovery point if there was a clean shutdown and did not perform any changes to\n+    // the segment. Otherwise, we just ensure that the recovery point is not ahead of the log end\n+    // offset. To ensure correctness and to make it easier to reason about, it's best to only advance\n+    // the recovery point in flush(Long).\n+    if (hasCleanShutdownFile)\n+      logEndOffsetOption.foreach(recoveryPoint = _)\n+    else\n+      recoveryPoint = Math.min(recoveryPoint, logEndOffset)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE3NzEzOA==", "bodyText": "Can you help me understand what was wrong with this?", "url": "https://github.com/apache/kafka/pull/8812#discussion_r436177138", "createdAt": "2020-06-05T21:42:58Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -826,8 +832,16 @@ class Log(@volatile private var _dir: File,\n         preallocate = config.preallocate))\n     }\n \n-    recoveryPoint = activeSegment.readNextOffset", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3"}, "originalPosition": 44}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91de172c89fa89b41ec77400dc83946e03c90dfa", "author": {"user": {"login": "ijuma", "name": "Ismael Juma"}}, "url": "https://github.com/apache/kafka/commit/91de172c89fa89b41ec77400dc83946e03c90dfa", "committedDate": "2021-02-25T18:09:01Z", "message": "KAFKA-10101: Fix edge cases in Log.recoverLog and LogManager.loadLogs\n\n1. Don't advance recovery point in `recoverLog` unless there was a clean\nshutdown.\n2. Ensure the recovery point is not ahead of the log end offset.\n3. Clean and flush leader epoch cache and truncate produce state manager\nif deleting segments due to log end offset being smaller than log start\noffset.\n4. If we are unable to delete clean shutdown file that exists, mark the\ndirectory as offline (this was the intent, but the code was wrong)."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3", "author": {"user": {"login": "ijuma", "name": "Ismael Juma"}}, "url": "https://github.com/apache/kafka/commit/0b2f2711f6bf0d0b397b81ebdf8d640a3f8fd6b3", "committedDate": "2020-06-05T17:21:24Z", "message": "KAFKA-10101: Fix edge cases in Log.recoverLog and LogManager.loadLogs\n\n1. Don't advance recovery point in `recoverLog` unless there was a clean\nshutdown.\n2. Ensure the recovery point is not ahead of the log end offset.\n3. Clean and flush leader epoch cache and truncate produce state manager\nif deleting segments due to log end offset being smaller than log start\noffset.\n4. If we are unable to delete clean shutdown file that exists, mark the\ndirectory as offline (this was the intent, but the code was wrong)."}, "afterCommit": {"oid": "91de172c89fa89b41ec77400dc83946e03c90dfa", "author": {"user": {"login": "ijuma", "name": "Ismael Juma"}}, "url": "https://github.com/apache/kafka/commit/91de172c89fa89b41ec77400dc83946e03c90dfa", "committedDate": "2021-02-25T18:09:01Z", "message": "KAFKA-10101: Fix edge cases in Log.recoverLog and LogManager.loadLogs\n\n1. Don't advance recovery point in `recoverLog` unless there was a clean\nshutdown.\n2. Ensure the recovery point is not ahead of the log end offset.\n3. Clean and flush leader epoch cache and truncate produce state manager\nif deleting segments due to log end offset being smaller than log start\noffset.\n4. If we are unable to delete clean shutdown file that exists, mark the\ndirectory as offline (this was the intent, but the code was wrong)."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7b6abd68b61e9013707633fb903542a9ad4d947e", "author": {"user": {"login": "ijuma", "name": "Ismael Juma"}}, "url": "https://github.com/apache/kafka/commit/7b6abd68b61e9013707633fb903542a9ad4d947e", "committedDate": "2021-02-25T18:42:13Z", "message": "Address feedback and resolve FIXME"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "796dd8be722f026a4d3cccf01ab86edf82e62348", "author": {"user": {"login": "ijuma", "name": "Ismael Juma"}}, "url": "https://github.com/apache/kafka/commit/796dd8be722f026a4d3cccf01ab86edf82e62348", "committedDate": "2021-02-25T19:00:24Z", "message": "Tweak logic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46d5cefa5fd62584875f7cc021f7317b105c084d", "author": {"user": {"login": "ijuma", "name": "Ismael Juma"}}, "url": "https://github.com/apache/kafka/commit/46d5cefa5fd62584875f7cc021f7317b105c084d", "committedDate": "2021-02-25T21:56:34Z", "message": "Fix failing test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c02bc3ceb233a880bb256de75262de6b381ed0c5", "author": {"user": {"login": "ijuma", "name": "Ismael Juma"}}, "url": "https://github.com/apache/kafka/commit/c02bc3ceb233a880bb256de75262de6b381ed0c5", "committedDate": "2021-02-25T21:54:55Z", "message": "Fix failing test"}, "afterCommit": {"oid": "46d5cefa5fd62584875f7cc021f7317b105c084d", "author": {"user": {"login": "ijuma", "name": "Ismael Juma"}}, "url": "https://github.com/apache/kafka/commit/46d5cefa5fd62584875f7cc021f7317b105c084d", "committedDate": "2021-02-25T21:56:34Z", "message": "Fix failing test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5OTU1NDE1", "url": "https://github.com/apache/kafka/pull/8812#pullrequestreview-599955415", "createdAt": "2021-02-26T21:29:51Z", "commit": {"oid": "46d5cefa5fd62584875f7cc021f7317b105c084d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 880, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}