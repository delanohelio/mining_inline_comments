{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5Nzk2NjIx", "number": 8691, "title": "KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter", "bodyText": "Implement KIP-606, add metadata context to MetricsReporter:\n\nAdded a new api to MetricsReporter to allow client to expose additional metadata fields to reporter plugin. Added an interface MetricsContext to encapsulate metadata.\nDeprecated JmexReporter(String prefix) constructor. The prefix will be passed to the reporter via MetricsContext.\nReplaced existing usage of JmxReporter with the default ImxReporter and pass JMX prefix to MetricsContext using _namespace as key.\nFrom Kafka broker, populate MetricsContext with: kafka.cluster.id and kafka.nroker.id\nFrom Connect, populate MetricsContext with: connect.kafka.cluster.id, connect.group.id\n\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-05-18T23:42:39Z", "url": "https://github.com/apache/kafka/pull/8691", "merged": true, "mergeCommit": {"oid": "9c833f665f349e5c292228f75188f5521282835d"}, "closed": true, "closedAt": "2020-05-28T01:18:36Z", "author": {"login": "xiaodongdu"}, "timelineItems": {"totalCount": 48, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcgui1-gH2gAyNDE5Nzk2NjIxOjUyMzI0MzMxM2M0NDQzOGE5YjhmMGVjNDQ3NTdhYmYwMDY2ZTQ5YzA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABclisfhgFqTQxOTY5ODc0NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "523243313c44438a9b8f0ec44757abf0066e49c0", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/523243313c44438a9b8f0ec44757abf0066e49c0", "committedDate": "2020-05-13T01:25:21Z", "message": "KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82c0a0d1cc5e627f7c03e6d56e82697f9424a0a6", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/82c0a0d1cc5e627f7c03e6d56e82697f9424a0a6", "committedDate": "2020-05-13T16:21:33Z", "message": "add changes to connect as part of KIP 606 implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d388cf2244a9877a0bca1c3d843b27a092d99a3", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/5d388cf2244a9877a0bca1c3d843b27a092d99a3", "committedDate": "2020-05-13T19:09:45Z", "message": "fix string constant"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "92d6389b97652d81ba6d74f5044462ee0172adea", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/92d6389b97652d81ba6d74f5044462ee0172adea", "committedDate": "2020-05-13T23:50:27Z", "message": "Changes to address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8938501520273a42353cddcb30b5a7acb2a0f27", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/e8938501520273a42353cddcb30b5a7acb2a0f27", "committedDate": "2020-05-14T02:09:10Z", "message": "Fix a issue when setting group id"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b36bc6d901f04e4820974ab019a0fa73b8eaf7f", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/2b36bc6d901f04e4820974ab019a0fa73b8eaf7f", "committedDate": "2020-05-14T19:14:52Z", "message": "use group.id from original config when pass connect.group.id to client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24bc78ed7c859ac603884c7bdffb7438f1b96034", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/24bc78ed7c859ac603884c7bdffb7438f1b96034", "committedDate": "2020-05-14T21:23:11Z", "message": "remove redundant call, add more unit test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65195e1592281054bcf8a9e9c4068e9082e58ad6", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/65195e1592281054bcf8a9e9c4068e9082e58ad6", "committedDate": "2020-05-15T22:05:08Z", "message": "More changes to address code review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9511de85dddfd619ebb2a65156674c7aca399bba", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/9511de85dddfd619ebb2a65156674c7aca399bba", "committedDate": "2020-05-15T22:22:40Z", "message": "More changes to address code review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4964aef267adf0406f4a8982bc95c202b61bc8f4", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/4964aef267adf0406f4a8982bc95c202b61bc8f4", "committedDate": "2020-05-16T02:09:30Z", "message": "More changes to address code review coments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fd4ef53240a561ec4cbdc5dbd69cb3fc988fe28", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/8fd4ef53240a561ec4cbdc5dbd69cb3fc988fe28", "committedDate": "2020-05-16T02:12:09Z", "message": "More changes to address code review coments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "69e4b7c938cae4771a3532d5ed397935f6978665", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/69e4b7c938cae4771a3532d5ed397935f6978665", "committedDate": "2020-05-18T04:01:10Z", "message": "add an integration test, strip off metrics.context from metrics context"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e1a5b6ba37fedf5a5e48256d6a8fb713b888c43", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/0e1a5b6ba37fedf5a5e48256d6a8fb713b888c43", "committedDate": "2020-05-18T19:49:56Z", "message": "More changes to address PR review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/386a5da2dad688648ec7843722e8cf683d01fee6", "committedDate": "2020-05-18T21:30:09Z", "message": "Remove support of reading metric context properties for broker"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6005c9acb6c6803e41af9cc4bf9a69cfa66b0768", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/6005c9acb6c6803e41af9cc4bf9a69cfa66b0768", "committedDate": "2020-05-19T16:31:56Z", "message": "KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter\n\nadd changes to connect as part of KIP 606 implementation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/386a5da2dad688648ec7843722e8cf683d01fee6", "committedDate": "2020-05-18T21:30:09Z", "message": "Remove support of reading metric context properties for broker"}, "afterCommit": {"oid": "6005c9acb6c6803e41af9cc4bf9a69cfa66b0768", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/6005c9acb6c6803e41af9cc4bf9a69cfa66b0768", "committedDate": "2020-05-19T16:31:56Z", "message": "KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter\n\nadd changes to connect as part of KIP 606 implementation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE0MDMyMjA5", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-414032209", "createdAt": "2020-05-19T01:00:50Z", "commit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMTowMDo1MFrOGXMQog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMToxMjo0NlrOGXMdZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MTI5OA==", "bodyText": "I don't think the KIP mentioned this kafka.connect.mirror metrics context. It's probably worthwhile to update the KIP and then notify the vote thread of the minor change noticed during implementation.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426971298", "createdAt": "2020-05-19T01:00:50Z", "author": {"login": "rhauch"}, "path": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorConnectorConfig.java", "diffHunk": "@@ -270,9 +272,15 @@ Duration adminTimeout() {\n     List<MetricsReporter> metricsReporters() {\n         List<MetricsReporter> reporters = getConfiguredInstances(\n                 CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MetricsReporter.class);\n-        JmxReporter jmxReporter = new JmxReporter(\"kafka.connect.mirror\");\n+        JmxReporter jmxReporter = new JmxReporter();\n         jmxReporter.configure(this.originals());\n         reporters.add(jmxReporter);\n+        MetricsContext metricsContext = new KafkaMetricsContext(\"kafka.connect.mirror\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MjUzOA==", "bodyText": "Do we need to modify the KafkaOffsetBackingStore() constructor? The ConnectUtils.lookupKafkaClusterId(...) can be called with the WorkerConfig (which is the parent class of DistributedConfig) passed to it via the configure(...) method, so couldn't the configure(...) method call the lookup method?\nThis may seem minor, but it follows the existing pattern for this class.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426972538", "createdAt": "2020-05-19T01:05:19Z", "author": {"login": "rhauch"}, "path": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMaker.java", "diffHunk": "@@ -233,17 +233,18 @@ private void addHerder(SourceAndTarget sourceAndTarget) {\n         plugins.compareAndSwapWithDelegatingLoader();\n         DistributedConfig distributedConfig = new DistributedConfig(workerProps);\n         String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(distributedConfig);\n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(distributedConfig);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3Mjg5OQ==", "bodyText": "Could the KafkaConfigBackingStore(...) get the cluster ID from the distributedConfig? One of the reasons why we pass the whole worker config to the constructor is so that we don't have to always modify the constructor to pass in additional information that can be derived from the worker config.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426972899", "createdAt": "2020-05-19T01:06:35Z", "author": {"login": "rhauch"}, "path": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMaker.java", "diffHunk": "@@ -233,17 +233,18 @@ private void addHerder(SourceAndTarget sourceAndTarget) {\n         plugins.compareAndSwapWithDelegatingLoader();\n         DistributedConfig distributedConfig = new DistributedConfig(workerProps);\n         String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(distributedConfig);\n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(distributedConfig);\n-        Worker worker = new Worker(workerId, time, plugins, distributedConfig, offsetBackingStore, CLIENT_CONFIG_OVERRIDE_POLICY);\n+        Worker worker = new Worker(workerId, time, plugins, distributedConfig, offsetBackingStore, CLIENT_CONFIG_OVERRIDE_POLICY, kafkaClusterId);\n         WorkerConfigTransformer configTransformer = worker.configTransformer();\n         Converter internalValueConverter = worker.getInternalValueConverter();\n-        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n+        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter, kafkaClusterId);\n         statusBackingStore.configure(distributedConfig);\n         ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(\n                 internalValueConverter,\n                 distributedConfig,\n-                configTransformer);\n+                configTransformer,\n+                kafkaClusterId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzE5Ng==", "bodyText": "Could the KafkaStatusBackingStore(...) get the cluster ID from the distributedConfig passed into the configure(...) method, similar to the KafkaOffsetBackingStore?", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973196", "createdAt": "2020-05-19T01:07:45Z", "author": {"login": "rhauch"}, "path": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMaker.java", "diffHunk": "@@ -233,17 +233,18 @@ private void addHerder(SourceAndTarget sourceAndTarget) {\n         plugins.compareAndSwapWithDelegatingLoader();\n         DistributedConfig distributedConfig = new DistributedConfig(workerProps);\n         String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(distributedConfig);\n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(distributedConfig);\n-        Worker worker = new Worker(workerId, time, plugins, distributedConfig, offsetBackingStore, CLIENT_CONFIG_OVERRIDE_POLICY);\n+        Worker worker = new Worker(workerId, time, plugins, distributedConfig, offsetBackingStore, CLIENT_CONFIG_OVERRIDE_POLICY, kafkaClusterId);\n         WorkerConfigTransformer configTransformer = worker.configTransformer();\n         Converter internalValueConverter = worker.getInternalValueConverter();\n-        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n+        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter, kafkaClusterId);\n         statusBackingStore.configure(distributedConfig);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzQwNQ==", "bodyText": "Same comment here as in MirrorMaker: the backing store's configure(...) method could get the Kafka cluster ID directly from the worker config.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973405", "createdAt": "2020-05-19T01:08:37Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java", "diffHunk": "@@ -101,24 +101,25 @@ public Connect startConnect(Map<String, String> workerProps) {\n         URI advertisedUrl = rest.advertisedUrl();\n         String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n \n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzUzOQ==", "bodyText": "Same comment here as in MirrorMaker: the worker's constructor could get the Kafka cluster ID directly from the worker config.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973539", "createdAt": "2020-05-19T01:09:06Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java", "diffHunk": "@@ -101,24 +101,25 @@ public Connect startConnect(Map<String, String> workerProps) {\n         URI advertisedUrl = rest.advertisedUrl();\n         String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n \n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(config);\n \n         ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                 config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                 config, ConnectorClientConfigOverridePolicy.class);\n \n-        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy);\n+        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy, kafkaClusterId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzYwNQ==", "bodyText": "Same comment here as in MirrorMaker: the backing store's constructor could get the Kafka cluster ID directly from the worker config.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973605", "createdAt": "2020-05-19T01:09:19Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java", "diffHunk": "@@ -101,24 +101,25 @@ public Connect startConnect(Map<String, String> workerProps) {\n         URI advertisedUrl = rest.advertisedUrl();\n         String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n \n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(config);\n \n         ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                 config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                 config, ConnectorClientConfigOverridePolicy.class);\n \n-        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy);\n+        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy, kafkaClusterId);\n         WorkerConfigTransformer configTransformer = worker.configTransformer();\n \n         Converter internalValueConverter = worker.getInternalValueConverter();\n-        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n+        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter, kafkaClusterId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzY4Ng==", "bodyText": "Same comment here as in MirrorMaker: the backing store's constructor could get the Kafka cluster ID directly from the worker config.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973686", "createdAt": "2020-05-19T01:09:38Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java", "diffHunk": "@@ -101,24 +101,25 @@ public Connect startConnect(Map<String, String> workerProps) {\n         URI advertisedUrl = rest.advertisedUrl();\n         String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n \n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(config);\n \n         ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                 config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                 config, ConnectorClientConfigOverridePolicy.class);\n \n-        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy);\n+        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy, kafkaClusterId);\n         WorkerConfigTransformer configTransformer = worker.configTransformer();\n \n         Converter internalValueConverter = worker.getInternalValueConverter();\n-        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n+        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter, kafkaClusterId);\n         statusBackingStore.configure(config);\n \n         ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(\n                 internalValueConverter,\n                 config,\n-                configTransformer);\n+                configTransformer,\n+                kafkaClusterId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzczOA==", "bodyText": "Same comment here as in MirrorMaker: the worker's constructor could get the Kafka cluster ID directly from the worker config.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973738", "createdAt": "2020-05-19T01:09:54Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java", "diffHunk": "@@ -93,7 +93,7 @@ public static void main(String[] args) {\n                 config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                 config, ConnectorClientConfigOverridePolicy.class);\n             Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore(),\n-                                       connectorClientConfigOverridePolicy);\n+                                       connectorClientConfigOverridePolicy, kafkaClusterId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU2NA==", "bodyText": "The Kafka cluster ID is passed into the constructor, but is this supposed to represent the Connect cluster ID or the Kafka cluster ID? Since this is in Connect code, without a context we'd assume it was the Connect cluster ID.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426974564", "createdAt": "2020-05-19T01:12:46Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -92,6 +93,7 @@\n     private final ExecutorService executor;\n     private final Time time;\n     private final String workerId;\n+    private final String clusterId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 12}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d78a1e0e6085353e345e9198058a308a6925bd1d", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/d78a1e0e6085353e345e9198058a308a6925bd1d", "committedDate": "2020-05-20T15:51:05Z", "message": "Remove cluster id from a few constructors and use utility method to get cluster id"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2484d7123701499a8abb94d40a6dae8187859718", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/2484d7123701499a8abb94d40a6dae8187859718", "committedDate": "2020-05-20T17:50:02Z", "message": "Merge branch 'kafka-9960-kip-606' of github.com:xiaodongdu/kafka into kafka-9960-kip-606"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "committedDate": "2020-05-20T19:22:15Z", "message": "remove clusterId from WorkGroupMember constructor"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2MjkzMTM5", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-416293139", "createdAt": "2020-05-21T16:16:23Z", "commit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNjoxNjoyM1rOGY5d6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNjoxNjoyM1rOGY5d6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2MDU1NQ==", "bodyText": "Use putIfAbsent to avoid silently overwriting over labels set upstream.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428760555", "createdAt": "2020-05-21T16:16:23Z", "author": {"login": "rnpridgeon"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/KafkaMetricsContext.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A implementation of MetricsContext, it encapsulates required metrics context properties for Kafka services and clients\n+ */\n+public class KafkaMetricsContext implements MetricsContext {\n+    /**\n+     * Client or Service's metadata map.\n+     */\n+    private Map<String, String> metadata = new HashMap<>();\n+\n+    /**\n+     * Create a MetricsContext with namespace, no service or client properties\n+     * @param namespace value for _namespace key\n+     */\n+    public KafkaMetricsContext(String namespace) {\n+        this(namespace, new HashMap<>());\n+    }\n+\n+    /**\n+     * Create a MetricsContext with namespace, service or client properties\n+     * @param namespace value for _namespace key\n+     * @param metadata  metadata additional entries to add to the context.\n+     *                  values will be converted to string using Object.toString()\n+     */\n+    public KafkaMetricsContext(String namespace, Map<String, ?> metadata) {\n+        this.metadata.put(MetricsContext.NAMESPACE, namespace);\n+        metadata.forEach((key, value) -> this.metadata.put(key, value.toString()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b"}, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2ODcxMDk1", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-416871095", "createdAt": "2020-05-22T12:27:59Z", "commit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxMjoyNzo1OVrOGZVULQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxMjoyNzo1OVrOGZVULQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTIxNjgxMw==", "bodyText": "Maybe it would be helpful to add CONNECT_VERSION as well.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429216813", "createdAt": "2020-05-22T12:27:59Z", "author": {"login": "rnpridgeon"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/ConnectUtils.java", "diffHunk": "@@ -16,19 +16,24 @@\n  */\n package org.apache.kafka.connect.util;\n \n+import org.apache.kafka.clients.CommonClientConfigs;\n import org.apache.kafka.clients.admin.Admin;\n import org.apache.kafka.common.KafkaFuture;\n import org.apache.kafka.common.InvalidRecordException;\n import org.apache.kafka.common.record.RecordBatch;\n import org.apache.kafka.connect.errors.ConnectException;\n import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.runtime.distributed.DistributedConfig;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.util.Map;\n import java.util.concurrent.ExecutionException;\n \n public final class ConnectUtils {\n     private static final Logger log = LoggerFactory.getLogger(ConnectUtils.class);\n+    public static final String CONNECT_KAFKA_CLUSTER_ID = \"connect.kafka.cluster.id\";\n+    public static final String CONNECT_GROUP_ID = \"connect.group.id\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b"}, "originalPosition": 21}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b", "committedDate": "2020-05-22T18:34:43Z", "message": "Merge remote-tracking branch 'origin/trunk' into kafka-9960-kip-606"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MDk2ODM3", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-417096837", "createdAt": "2020-05-22T18:05:54Z", "commit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxODowNTo1NVrOGZfqiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQyMDoxNzo0NlrOGZivMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM4NjM3Nw==", "bodyText": "Can be final", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429386377", "createdAt": "2020-05-22T18:05:55Z", "author": {"login": "mumrah"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/KafkaMetricsContext.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A implementation of MetricsContext, it encapsulates required metrics context properties for Kafka services and clients\n+ */\n+public class KafkaMetricsContext implements MetricsContext {\n+    /**\n+     * Client or Service's metadata map.\n+     */\n+    private Map<String, String> metadata = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM4NzQ5OA==", "bodyText": "nit: just read the value from the Map once", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429387498", "createdAt": "2020-05-22T18:08:30Z", "author": {"login": "mumrah"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/JmxReporter.java", "diffHunk": "@@ -318,4 +324,15 @@ public AttributeList setAttributes(AttributeList list) {\n                                       + \".(whitelist/blacklist) is not a valid regular expression\");\n         }\n     }\n+\n+    @Override\n+    public void contextChange(MetricsContext metricsContext) {\n+        Objects.requireNonNull(metricsContext.metadata().get(MetricsContext.NAMESPACE));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM4Nzc3Mg==", "bodyText": "Should we throw an exception here, or just replace the null value with an empty string?", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429387772", "createdAt": "2020-05-22T18:09:12Z", "author": {"login": "mumrah"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/JmxReporter.java", "diffHunk": "@@ -71,8 +72,13 @@ public JmxReporter() {\n \n     /**\n      * Create a JMX reporter that prefixes all metrics with the given string.\n+     *  @deprecated Since 2.6.0. Use {@link JmxReporter#JmxReporter()}\n+     *  Initialize JmxReporter with {@link JmxReporter#contextChange(MetricsContext)}\n+     *  Populate prefix by adding _namespace/prefix key value pair to {@link MetricsContext}\n      */\n+    @Deprecated\n     public JmxReporter(String prefix) {\n+        Objects.requireNonNull(prefix);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM5MTU3Nw==", "bodyText": "Metadata is very overloaded, can we think of a different name here?", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429391577", "createdAt": "2020-05-22T18:18:58Z", "author": {"login": "mumrah"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsContext.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+\n+/**\n+ * MetricsContext encapsulates additional metadata about metrics exposed via a\n+ * {@link org.apache.kafka.common.metrics.MetricsReporter}\n+ *\n+ * The metadata map provides following information:\n+ * - a <code>_namespace</node> field indicating the component exposing metrics\n+ *   e.g. kafka.server, kafka.consumer\n+ *   {@link JmxReporter} uses this as prefix for mbean names\n+ *\n+ * - for clients and streams libraries: any freeform fields passed in via\n+ *   client properties in the form of `metrics.context.<key>=<value>\n+ *\n+ * - for kafka brokers: kafka.broker.id, kafka.cluster.id\n+ * - for connect workers: connect.kafka.cluster.id, connect.group.id\n+ */\n+@InterfaceStability.Evolving\n+public interface MetricsContext {\n+    /* predefined fields */\n+    String NAMESPACE = \"_namespace\"; // metrics namespace, formerly jmx prefix\n+\n+    /**\n+     * Returns metadata fields\n+     */\n+    Map<String, String> metadata();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjcwOQ==", "bodyText": "Looking through the PR, it seems that MetricsContext is a short lived object used to pass values to the MetricReporters as they are constructed. Since the usage appears to be write-once, it might be better to expose a subset of Map rather than the full thing. E.g., String get(String field) and Iterator<String> fields or something.\nIf we think this might evolve into a mutable long-lived object, then a Map is probably better. Just a thought.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429422709", "createdAt": "2020-05-22T19:34:20Z", "author": {"login": "mumrah"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsContext.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+\n+/**\n+ * MetricsContext encapsulates additional metadata about metrics exposed via a\n+ * {@link org.apache.kafka.common.metrics.MetricsReporter}\n+ *\n+ * The metadata map provides following information:\n+ * - a <code>_namespace</node> field indicating the component exposing metrics\n+ *   e.g. kafka.server, kafka.consumer\n+ *   {@link JmxReporter} uses this as prefix for mbean names\n+ *\n+ * - for clients and streams libraries: any freeform fields passed in via\n+ *   client properties in the form of `metrics.context.<key>=<value>\n+ *\n+ * - for kafka brokers: kafka.broker.id, kafka.cluster.id\n+ * - for connect workers: connect.kafka.cluster.id, connect.group.id\n+ */\n+@InterfaceStability.Evolving\n+public interface MetricsContext {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjgzNA==", "bodyText": "Should we define this as a field on the interface?", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429422834", "createdAt": "2020-05-22T19:34:41Z", "author": {"login": "mumrah"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsContext.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+\n+/**\n+ * MetricsContext encapsulates additional metadata about metrics exposed via a\n+ * {@link org.apache.kafka.common.metrics.MetricsReporter}\n+ *\n+ * The metadata map provides following information:\n+ * - a <code>_namespace</node> field indicating the component exposing metrics\n+ *   e.g. kafka.server, kafka.consumer\n+ *   {@link JmxReporter} uses this as prefix for mbean names\n+ *\n+ * - for clients and streams libraries: any freeform fields passed in via\n+ *   client properties in the form of `metrics.context.<key>=<value>\n+ *\n+ * - for kafka brokers: kafka.broker.id, kafka.cluster.id\n+ * - for connect workers: connect.kafka.cluster.id, connect.group.id\n+ */\n+@InterfaceStability.Evolving\n+public interface MetricsContext {\n+    /* predefined fields */\n+    String NAMESPACE = \"_namespace\"; // metrics namespace, formerly jmx prefix", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ==", "bodyText": "Should we rename jmxPrefix to metricsPrefix?", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429426401", "createdAt": "2020-05-22T19:44:30Z", "author": {"login": "mumrah"}, "path": "core/src/main/scala/kafka/server/KafkaServer.scala", "diffHunk": "@@ -129,7 +129,10 @@ class KafkaServer(val config: KafkaConfig, time: Time = Time.SYSTEM, threadNameP\n \n   private var shutdownLatch = new CountDownLatch(1)\n \n+  //properties for MetricsContext", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQzMjE1NA==", "bodyText": "Not really a \"callback\" in the conventional sense. Maybe just \"Provides context metadata for the ...\"", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429432154", "createdAt": "2020-05-22T20:03:50Z", "author": {"login": "mumrah"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsReporter.java", "diffHunk": "@@ -65,4 +66,13 @@ default void validateReconfiguration(Map<String, ?> configs) throws ConfigExcept\n     default void reconfigure(Map<String, ?> configs) {\n     }\n \n+    /**\n+     * Callback method providing context metadata for the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQzNjcyMQ==", "bodyText": "@xvrl can we remove the explicit construction of JmxReporter and rely on the plugin loading mechanism after we remove this non-zero-arg constructor? Maybe something for 3.0?", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429436721", "createdAt": "2020-05-22T20:17:46Z", "author": {"login": "mumrah"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/JmxReporter.java", "diffHunk": "@@ -71,8 +72,13 @@ public JmxReporter() {\n \n     /**\n      * Create a JMX reporter that prefixes all metrics with the given string.\n+     *  @deprecated Since 2.6.0. Use {@link JmxReporter#JmxReporter()}\n+     *  Initialize JmxReporter with {@link JmxReporter#contextChange(MetricsContext)}\n+     *  Populate prefix by adding _namespace/prefix key value pair to {@link MetricsContext}\n      */\n+    @Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b"}, "originalPosition": 16}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f30c8f090a518e9ff0d97298ec8ad15d77054386", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/f30c8f090a518e9ff0d97298ec8ad15d77054386", "committedDate": "2020-05-23T00:21:23Z", "message": "move string constants to config class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "committedDate": "2020-05-23T04:02:54Z", "message": "revert changes for KafkaConfig"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MzY2NDgz", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-417366483", "createdAt": "2020-05-24T15:02:30Z", "commit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNFQxNTowMjozMFrOGZvfSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNFQxNToyNTo1M1rOGZvnjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTY0MA==", "bodyText": "Standalone does not have a group.id property, since each standalone worker is its own single-node cluster. That means that this line can result in a null value for the metrics.context.connect.group.id entry in the props map.\nUnfortunately, there is no identifier for standalone workers. Is the metrics.context.connect.group.id property really required if the Standalone worker doesn't use any kind of coordination? It seems from other changes in ConnectMetrics that it is not required, in which case we should update the KIP to reflect that this property is only added in Connect distributed mode and we should correct the logic above to only add this property if it is non-null similar to the changes in ConnectMetrics.\nIf it is required, then we'll have to figure out something else.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429645640", "createdAt": "2020-05-24T15:02:30Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/ConnectUtils.java", "diffHunk": "@@ -65,4 +68,12 @@ static String lookupKafkaClusterId(Admin adminClient) {\n                                        + \"Check worker's broker connection and security properties.\", e);\n         }\n     }\n+\n+    public static void addMetricsContextProperties(Map<String, Object> prop, WorkerConfig config, String clusterId) {\n+        //add all properties predefined with \"metrics.context.\"\n+        prop.putAll(config.originalsWithPrefix(CommonClientConfigs.METRICS_CONTEXT_PREFIX, false));\n+        //add connect properties\n+        prop.put(CommonClientConfigs.METRICS_CONTEXT_PREFIX + WorkerConfig.CONNECT_KAFKA_CLUSTER_ID, clusterId);\n+        prop.put(CommonClientConfigs.METRICS_CONTEXT_PREFIX + WorkerConfig.CONNECT_GROUP_ID, config.originals().get(DistributedConfig.GROUP_ID_CONFIG));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTc0NA==", "bodyText": "Speaking of this, it'd probably be worth adding unit tests for this method with both StandaloneConfig and DistributedConfig objects to verify this method adds the right properties to the supplied map.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429645744", "createdAt": "2020-05-24T15:03:41Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/ConnectUtils.java", "diffHunk": "@@ -65,4 +68,12 @@ static String lookupKafkaClusterId(Admin adminClient) {\n                                        + \"Check worker's broker connection and security properties.\", e);\n         }\n     }\n+\n+    public static void addMetricsContextProperties(Map<String, Object> prop, WorkerConfig config, String clusterId) {\n+        //add all properties predefined with \"metrics.context.\"\n+        prop.putAll(config.originalsWithPrefix(CommonClientConfigs.METRICS_CONTEXT_PREFIX, false));\n+        //add connect properties\n+        prop.put(CommonClientConfigs.METRICS_CONTEXT_PREFIX + WorkerConfig.CONNECT_KAFKA_CLUSTER_ID, clusterId);\n+        prop.put(CommonClientConfigs.METRICS_CONTEXT_PREFIX + WorkerConfig.CONNECT_GROUP_ID, config.originals().get(DistributedConfig.GROUP_ID_CONFIG));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTY0MA=="}, "originalCommit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTk2Mw==", "bodyText": "This group.id property is not defined in StandaloneConfig. See my earlier comment.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429645963", "createdAt": "2020-05-24T15:06:08Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerTest.java", "diffHunk": "@@ -153,6 +164,7 @@ public void setup() {\n         workerProps.put(\"config.providers.file.class\", MockFileConfigProvider.class.getName());\n         mockFileProviderTestId = UUID.randomUUID().toString();\n         workerProps.put(\"config.providers.file.param.testId\", mockFileProviderTestId);\n+        workerProps.put(\"group.id\", GROUP_ID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzE1NQ==", "bodyText": "This is unused.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647155", "createdAt": "2020-05-24T15:19:21Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaStatusBackingStoreFormatTest.java", "diffHunk": "@@ -59,6 +59,7 @@\n     private static final String FOO_TOPIC = \"foo-topic\";\n     private static final String FOO_CONNECTOR = \"foo-source\";\n     private static final String BAR_TOPIC = \"bar-topic\";\n+    private static final String CLUSTER_ID = \"cluster-1\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzE2Mw==", "bodyText": "This is unused.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647163", "createdAt": "2020-05-24T15:19:30Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaStatusBackingStoreTest.java", "diffHunk": "@@ -63,6 +63,7 @@\n \n     private static final String STATUS_TOPIC = \"status-topic\";\n     private static final String WORKER_ID = \"localhost:8083\";\n+    private static final String CLUSTER_ID = \"cluster-1\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzYyMg==", "bodyText": "Nit: this doesn't follow our conventions: we don't use the get* style getters, and if this is only used in unit tests we should make this package protected instead this should be:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * Method for unit tests\n          \n          \n            \n                 * @return\n          \n          \n            \n                 */\n          \n          \n            \n                public Metrics getMetrics() {\n          \n          \n            \n                    return this.metrics;\n          \n          \n            \n                }\n          \n          \n            \n                // Visible for testing\n          \n          \n            \n                Metrics metrics() {\n          \n          \n            \n                    return this.metrics;\n          \n          \n            \n                }\n          \n      \n    \n    \n  \n\nYou'll have to change the WorkerGroupMemberTest accordingly.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647622", "createdAt": "2020-05-24T15:24:30Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMember.java", "diffHunk": "@@ -223,4 +235,12 @@ private void stop(boolean swallowException) {\n         else\n             log.debug(\"The Connect group member has stopped.\");\n     }\n+\n+    /**\n+     * Method for unit tests\n+     * @return\n+     */\n+    public Metrics getMetrics() {\n+        return this.metrics;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzY4MQ==", "bodyText": "Per a previous suggestion:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    MetricName name = member.getMetrics().metricName(\"test.avg\", \"grp1\");\n          \n          \n            \n                    MetricName name = member.metrics().metricName(\"test.avg\", \"grp1\");", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647681", "createdAt": "2020-05-24T15:25:10Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"offset.storage.file.filename\", \"/tmp/connect.offsets\");\n+        workerProps.put(\"group.id\", \"group-1\");\n+        workerProps.put(\"offset.storage.topic\", \"topic-1\");\n+        workerProps.put(\"config.storage.topic\", \"topic-1\");\n+        workerProps.put(\"status.storage.topic\", \"topic-1\");\n+        workerProps.put(CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MockConnectMetrics.MockMetricsReporter.class.getName());\n+        DistributedConfig config = new DistributedConfig(workerProps);\n+\n+\n+        LogContext logContext = new LogContext(\"[Worker clientId=client-1 + groupId= group-1]\");\n+\n+        expectClusterId();\n+\n+        member = new WorkerGroupMember(config, \"\", configBackingStore,\n+        null, Time.SYSTEM, \"client-1\", logContext);\n+\n+        for (MetricsReporter reporter : member.getMetrics().reporters()) {\n+            if (reporter instanceof MockConnectMetrics.MockMetricsReporter) {\n+                MockConnectMetrics.MockMetricsReporter mockMetricsReporter = (MockConnectMetrics.MockMetricsReporter) reporter;\n+                assertEquals(\"cluster-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_KAFKA_CLUSTER_ID));\n+                assertEquals(\"group-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_GROUP_ID));\n+            }\n+        }\n+\n+        MetricName name = member.getMetrics().metricName(\"test.avg\", \"grp1\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzcxMw==", "bodyText": "Per a previous suggestion:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    for (MetricsReporter reporter : member.getMetrics().reporters()) {\n          \n          \n            \n                    for (MetricsReporter reporter : member.metrics().reporters()) {", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647713", "createdAt": "2020-05-24T15:25:28Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"offset.storage.file.filename\", \"/tmp/connect.offsets\");\n+        workerProps.put(\"group.id\", \"group-1\");\n+        workerProps.put(\"offset.storage.topic\", \"topic-1\");\n+        workerProps.put(\"config.storage.topic\", \"topic-1\");\n+        workerProps.put(\"status.storage.topic\", \"topic-1\");\n+        workerProps.put(CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MockConnectMetrics.MockMetricsReporter.class.getName());\n+        DistributedConfig config = new DistributedConfig(workerProps);\n+\n+\n+        LogContext logContext = new LogContext(\"[Worker clientId=client-1 + groupId= group-1]\");\n+\n+        expectClusterId();\n+\n+        member = new WorkerGroupMember(config, \"\", configBackingStore,\n+        null, Time.SYSTEM, \"client-1\", logContext);\n+\n+        for (MetricsReporter reporter : member.getMetrics().reporters()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0Nzc1OA==", "bodyText": "Per a previous suggestion:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    member.getMetrics().addMetric(name, new Avg());\n          \n          \n            \n                    member.metrics().addMetric(name, new Avg());", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647758", "createdAt": "2020-05-24T15:25:53Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"offset.storage.file.filename\", \"/tmp/connect.offsets\");\n+        workerProps.put(\"group.id\", \"group-1\");\n+        workerProps.put(\"offset.storage.topic\", \"topic-1\");\n+        workerProps.put(\"config.storage.topic\", \"topic-1\");\n+        workerProps.put(\"status.storage.topic\", \"topic-1\");\n+        workerProps.put(CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MockConnectMetrics.MockMetricsReporter.class.getName());\n+        DistributedConfig config = new DistributedConfig(workerProps);\n+\n+\n+        LogContext logContext = new LogContext(\"[Worker clientId=client-1 + groupId= group-1]\");\n+\n+        expectClusterId();\n+\n+        member = new WorkerGroupMember(config, \"\", configBackingStore,\n+        null, Time.SYSTEM, \"client-1\", logContext);\n+\n+        for (MetricsReporter reporter : member.getMetrics().reporters()) {\n+            if (reporter instanceof MockConnectMetrics.MockMetricsReporter) {\n+                MockConnectMetrics.MockMetricsReporter mockMetricsReporter = (MockConnectMetrics.MockMetricsReporter) reporter;\n+                assertEquals(\"cluster-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_KAFKA_CLUSTER_ID));\n+                assertEquals(\"group-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_GROUP_ID));\n+            }\n+        }\n+\n+        MetricName name = member.getMetrics().metricName(\"test.avg\", \"grp1\");\n+        member.getMetrics().addMetric(name, new Avg());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6"}, "originalPosition": 92}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26a2a761102e05f13449bfa6897cb30b70bf7ee1", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/26a2a761102e05f13449bfa6897cb30b70bf7ee1", "committedDate": "2020-05-24T20:15:02Z", "message": "Merge remote-tracking branch 'origin/trunk' into kafka-9960-kip-606"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a40908570dad698874464fe2f1ff3f5520489b0c", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/a40908570dad698874464fe2f1ff3f5520489b0c", "committedDate": "2020-05-24T22:56:24Z", "message": "Address code review comments: rename method name, remove unused variable, unit tests for ConnectUtils, add group id only for distributed conenct"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d8c5d2aee1d42260eb5f7567b6328ca475810124", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/d8c5d2aee1d42260eb5f7567b6328ca475810124", "committedDate": "2020-05-24T23:01:56Z", "message": "update comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4NjI3NDEz", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-418627413", "createdAt": "2020-05-26T19:47:41Z", "commit": {"oid": "d8c5d2aee1d42260eb5f7567b6328ca475810124"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxOTo0Nzo0MVrOGat1VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMDowMToxOFrOGauTDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY2NzA5Mw==", "bodyText": "Need to add the parameter to the JavaDoc:\n@param clusterId  the Kafka cluster ID", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430667093", "createdAt": "2020-05-26T19:47:41Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/ConnectMetrics.java", "diffHunk": "@@ -63,7 +67,7 @@\n      * @param config   the worker configuration; may not be null\n      * @param time     the time; may not be null\n      */\n-    public ConnectMetrics(String workerId, WorkerConfig config, Time time) {\n+    public ConnectMetrics(String workerId, WorkerConfig config, Time time, String clusterId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8c5d2aee1d42260eb5f7567b6328ca475810124"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY2ODIyNA==", "bodyText": "@xiaodongdu, I was not suggesting getting rid of the field. It's fine to have a new field, but we should call the field kafkaClusterId rather than clusterId since the latter could be misinterpreted to mean the Connect cluster ID.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430668224", "createdAt": "2020-05-26T19:49:41Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -92,6 +93,7 @@\n     private final ExecutorService executor;\n     private final Time time;\n     private final String workerId;\n+    private final String clusterId;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU2NA=="}, "originalCommit": {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3MTMyNA==", "bodyText": "Should we use ConnectUtils.addMetricsContextProperties(adminProps, config, clusterId) a few lines below this? (See the similar changes you made in KafkaStatusBackingStore and KafkaConfigBackingStore.)", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430671324", "createdAt": "2020-05-26T19:55:04Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaOffsetBackingStore.java", "diffHunk": "@@ -66,20 +67,22 @@ public void configure(final WorkerConfig config) {\n         if (topic == null || topic.trim().length() == 0)\n             throw new ConfigException(\"Offset storage topic must be specified\");\n \n+        String clusterId = ConnectUtils.lookupKafkaClusterId(config);\n         data = new HashMap<>();\n \n         Map<String, Object> originals = config.originals();\n         Map<String, Object> producerProps = new HashMap<>(originals);\n         producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n         producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n         producerProps.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, Integer.MAX_VALUE);\n+        ConnectUtils.addMetricsContextProperties(producerProps, config, clusterId);\n \n         Map<String, Object> consumerProps = new HashMap<>(originals);\n         consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName());\n         consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName());\n+        ConnectUtils.addMetricsContextProperties(consumerProps, config, clusterId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8c5d2aee1d42260eb5f7567b6328ca475810124"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3MzY1Mw==", "bodyText": "Let's remove these deprecated configs.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n          \n          \n            \n                    workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n          \n          \n            \n                    workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n          \n          \n            \n                    workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430673653", "createdAt": "2020-05-26T19:59:17Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8c5d2aee1d42260eb5f7567b6328ca475810124"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3NDcwMw==", "bodyText": "It might be good to verify that we entered the if (reporter instance Mock...) block at least once. Otherwise, we might have a bug elsewhere that failed to instantiate the MockMetricsReporter class, and this portion of the test would still pass.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430674703", "createdAt": "2020-05-26T20:01:18Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"offset.storage.file.filename\", \"/tmp/connect.offsets\");\n+        workerProps.put(\"group.id\", \"group-1\");\n+        workerProps.put(\"offset.storage.topic\", \"topic-1\");\n+        workerProps.put(\"config.storage.topic\", \"topic-1\");\n+        workerProps.put(\"status.storage.topic\", \"topic-1\");\n+        workerProps.put(CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MockConnectMetrics.MockMetricsReporter.class.getName());\n+        DistributedConfig config = new DistributedConfig(workerProps);\n+\n+\n+        LogContext logContext = new LogContext(\"[Worker clientId=client-1 + groupId= group-1]\");\n+\n+        expectClusterId();\n+\n+        member = new WorkerGroupMember(config, \"\", configBackingStore,\n+        null, Time.SYSTEM, \"client-1\", logContext);\n+\n+        for (MetricsReporter reporter : member.metrics().reporters()) {\n+            if (reporter instanceof MockConnectMetrics.MockMetricsReporter) {\n+                MockConnectMetrics.MockMetricsReporter mockMetricsReporter = (MockConnectMetrics.MockMetricsReporter) reporter;\n+                assertEquals(\"cluster-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_KAFKA_CLUSTER_ID));\n+                assertEquals(\"group-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_GROUP_ID));\n+            }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8c5d2aee1d42260eb5f7567b6328ca475810124"}, "originalPosition": 89}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a1cf89d14e7631467eae5bb88273653d27fbe9d", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/1a1cf89d14e7631467eae5bb88273653d27fbe9d", "committedDate": "2020-05-26T20:49:03Z", "message": "Update MetricsContext based on KIP changes, address more code review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "15bdb8d7091f5dc9c4e13dcd9029211893506d9e", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/15bdb8d7091f5dc9c4e13dcd9029211893506d9e", "committedDate": "2020-05-26T20:59:01Z", "message": "Update MetricsContext based on KIP changes, address more code review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4Njc1OTkw", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-418675990", "createdAt": "2020-05-26T21:01:10Z", "commit": {"oid": "1a1cf89d14e7631467eae5bb88273653d27fbe9d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowMToxMFrOGawLBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowMToxMFrOGawLBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNTQxNQ==", "bodyText": "the prefix should be stripped before adding the fields to the context.", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430705415", "createdAt": "2020-05-26T21:01:10Z", "author": {"login": "xvrl"}, "path": "core/src/main/scala/kafka/server/KafkaServer.scala", "diffHunk": "@@ -384,6 +390,23 @@ class KafkaServer(val config: KafkaConfig, time: Time = Time.SYSTEM, threadNameP\n     clusterResourceListeners.onUpdate(new ClusterResource(clusterId))\n   }\n \n+  private[server] def notifyMetricsReporters(metricsReporters: Seq[AnyRef]): Unit = {\n+    val metricsContext = createKafkaMetricsContext()\n+    metricsReporters.foreach {\n+      case x: MetricsReporter => x.contextChange(metricsContext)\n+      case _ => //do nothing\n+    }\n+  }\n+\n+  private[server] def createKafkaMetricsContext() : KafkaMetricsContext = {\n+    val contextLabels = new util.HashMap[String, Object]\n+    contextLabels.put(KAFKA_CLUSTER_ID, clusterId)\n+    contextLabels.put(KAFKA_BROKER_ID, config.brokerId.toString)\n+    contextLabels.putAll(config.originalsWithPrefix(CommonClientConfigs.METRICS_CONTEXT_PREFIX, false))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a1cf89d14e7631467eae5bb88273653d27fbe9d"}, "originalPosition": 78}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f5c69a1ff07588355fec4a9019febed85054217", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/7f5c69a1ff07588355fec4a9019febed85054217", "committedDate": "2020-05-26T21:10:15Z", "message": "More fix regarding code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4NjgyNjAz", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-418682603", "createdAt": "2020-05-26T21:11:58Z", "commit": {"oid": "1a1cf89d14e7631467eae5bb88273653d27fbe9d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMToxMTo1OFrOGaweyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMToxMTo1OFrOGaweyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMDQ3NA==", "bodyText": "someone on the ML commented that we might want to name this contextChanged (past tense). I don't have a strong feeling either way. Do you have any thoughts @mumrah @rhauch?", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430710474", "createdAt": "2020-05-26T21:11:58Z", "author": {"login": "xvrl"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsReporter.java", "diffHunk": "@@ -65,4 +66,12 @@ default void validateReconfiguration(Map<String, ?> configs) throws ConfigExcept\n     default void reconfigure(Map<String, ?> configs) {\n     }\n \n+    /**\n+     * Provides context labels for the service or library exposing metrics\n+     *\n+     * @param metricsContext the metric context\n+     */\n+    @InterfaceStability.Evolving\n+    default void contextChange(MetricsContext metricsContext) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a1cf89d14e7631467eae5bb88273653d27fbe9d"}, "originalPosition": 18}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5598fa191d445120baaf92cd988ba198f87e5e3b", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/5598fa191d445120baaf92cd988ba198f87e5e3b", "committedDate": "2020-05-26T21:12:08Z", "message": "Merge branch 'kafka-9960-kip-606' of github.com:xiaodongdu/kafka into kafka-9960-kip-606"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "98371e4c69307da9d627fec97d2bd3361d83b372", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/98371e4c69307da9d627fec97d2bd3361d83b372", "committedDate": "2020-05-26T21:39:10Z", "message": "Minor changes for KafkaServer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c42644b660fb99daa3018f21b5b98d85b653704", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/1c42644b660fb99daa3018f21b5b98d85b653704", "committedDate": "2020-05-26T22:14:52Z", "message": "update variable name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6f934729fe4db47f609e59d20399707c0a2d2190", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/6f934729fe4db47f609e59d20399707c0a2d2190", "committedDate": "2020-05-26T22:33:14Z", "message": "Remove unused variable"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4NzUwMjYz", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-418750263", "createdAt": "2020-05-26T23:41:38Z", "commit": {"oid": "6f934729fe4db47f609e59d20399707c0a2d2190"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMzo0MTozOVrOGaz3Fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMzo0NjozOFrOGaz85Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2NTg0Ng==", "bodyText": "Need an override annotation here:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public Map<String, String> contextLabels() {\n          \n          \n            \n                @Override\n          \n          \n            \n                public Map<String, String> contextLabels() {", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430765846", "createdAt": "2020-05-26T23:41:39Z", "author": {"login": "rhauch"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/KafkaMetricsContext.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A implementation of MetricsContext, it encapsulates required metrics context properties for Kafka services and clients\n+ */\n+public class KafkaMetricsContext implements MetricsContext {\n+    /**\n+     * Client or Service's contextLabels map.\n+     */\n+    private final Map<String, String> contextLabels = new HashMap<>();\n+\n+    /**\n+     * Create a MetricsContext with namespace, no service or client properties\n+     * @param namespace value for _namespace key\n+     */\n+    public KafkaMetricsContext(String namespace) {\n+        this(namespace, new HashMap<>());\n+    }\n+\n+    /**\n+     * Create a MetricsContext with namespace, service or client properties\n+     * @param namespace value for _namespace key\n+     * @param contextLabels  contextLabels additional entries to add to the context.\n+     *                  values will be converted to string using Object.toString()\n+     */\n+    public KafkaMetricsContext(String namespace, Map<String, ?> contextLabels) {\n+        this.contextLabels.put(MetricsContext.NAMESPACE, namespace);\n+        contextLabels.forEach((key, value) -> this.contextLabels.put(key, value.toString()));\n+    }\n+\n+    public Map<String, String> contextLabels() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f934729fe4db47f609e59d20399707c0a2d2190"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2NjQyNg==", "bodyText": "This JavaDoc is incomplete. Perhaps something like:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /**\n          \n          \n            \n                 * Returns contextLabels fields\n          \n          \n            \n                 */\n          \n          \n            \n                Map<String, String> contextLabels();\n          \n          \n            \n                /**\n          \n          \n            \n                 * Returns the labels for this metrics context.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @return the map of label keys and values; never null but possibly empty\n          \n          \n            \n                 */\n          \n          \n            \n                Map<String, String> contextLabels();", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430766426", "createdAt": "2020-05-26T23:43:40Z", "author": {"login": "rhauch"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsContext.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+\n+/**\n+ * MetricsContext encapsulates additional contextLabels about metrics exposed via a\n+ * {@link org.apache.kafka.common.metrics.MetricsReporter}\n+ *\n+ * The contextLabels map provides following information:\n+ * - a <code>_namespace</node> field indicating the component exposing metrics\n+ *   e.g. kafka.server, kafka.consumer\n+ *   {@link JmxReporter} uses this as prefix for mbean names\n+ *\n+ * - for clients and streams libraries: any freeform fields passed in via\n+ *   client properties in the form of `metrics.context.<key>=<value>\n+ *\n+ * - for kafka brokers: kafka.broker.id, kafka.cluster.id\n+ * - for connect workers: connect.kafka.cluster.id, connect.group.id\n+ */\n+@InterfaceStability.Evolving\n+public interface MetricsContext {\n+    /* predefined fields */\n+    String NAMESPACE = \"_namespace\"; // metrics namespace, formerly jmx prefix\n+\n+    /**\n+     * Returns contextLabels fields\n+     */\n+    Map<String, String> contextLabels();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f934729fe4db47f609e59d20399707c0a2d2190"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2NzMzMw==", "bodyText": "It would also be good to identify when this is called relative to other methods. For example, it is always called before init(...) is called. But can it be called again, or is that the only time this method is called?", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430767333", "createdAt": "2020-05-26T23:46:38Z", "author": {"login": "rhauch"}, "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsReporter.java", "diffHunk": "@@ -65,4 +66,12 @@ default void validateReconfiguration(Map<String, ?> configs) throws ConfigExcept\n     default void reconfigure(Map<String, ?> configs) {\n     }\n \n+    /**\n+     * Provides context labels for the service or library exposing metrics\n+     *\n+     * @param metricsContext the metric context\n+     */\n+    @InterfaceStability.Evolving\n+    default void contextChange(MetricsContext metricsContext) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMDQ3NA=="}, "originalCommit": {"oid": "1a1cf89d14e7631467eae5bb88273653d27fbe9d"}, "originalPosition": 18}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "071872fae4a7c1473b1bd29c68fcf5d8b5f94676", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/071872fae4a7c1473b1bd29c68fcf5d8b5f94676", "committedDate": "2020-05-27T00:40:25Z", "message": "Update javadoc and add annotation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5MzExMDM3", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-419311037", "createdAt": "2020-05-27T14:59:15Z", "commit": {"oid": "071872fae4a7c1473b1bd29c68fcf5d8b5f94676"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7bcd0577ffe84a18579fb931e7d81e033717d681", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/7bcd0577ffe84a18579fb931e7d81e033717d681", "committedDate": "2020-05-27T16:11:06Z", "message": "Update javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "319f5c556715d6733e82b41d7289ab71513ae27b", "author": {"user": {"login": "xiaodongdu", "name": null}}, "url": "https://github.com/apache/kafka/commit/319f5c556715d6733e82b41d7289ab71513ae27b", "committedDate": "2020-05-27T17:48:06Z", "message": "Merge remote-tracking branch 'origin/trunk' into kafka-9960-kip-606"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5NDc2NjE3", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-419476617", "createdAt": "2020-05-27T17:57:42Z", "commit": {"oid": "319f5c556715d6733e82b41d7289ab71513ae27b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5NTY1MDA2", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-419565006", "createdAt": "2020-05-27T19:59:50Z", "commit": {"oid": "319f5c556715d6733e82b41d7289ab71513ae27b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5Njk4NzQ1", "url": "https://github.com/apache/kafka/pull/8691#pullrequestreview-419698745", "createdAt": "2020-05-28T00:26:39Z", "commit": {"oid": "319f5c556715d6733e82b41d7289ab71513ae27b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1089, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}