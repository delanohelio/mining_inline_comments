{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgzMzMxODEz", "number": 8220, "title": "KAFKA-9645: Fallback to unsubscribe during Task Migrated", "bodyText": "After #7312, we could still return data during the rebalance phase, which means it could be possible to find records without corresponding tasks. We have to fallback to the unsubscribe mode during task migrated as the assignment should be cleared out to keep sync with task manager state.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-03-04T04:24:45Z", "url": "https://github.com/apache/kafka/pull/8220", "merged": true, "mergeCommit": {"oid": "fe0b704285ebc916ce5080a5248d91b4dc3c60e0"}, "closed": true, "closedAt": "2020-03-07T16:08:24Z", "author": {"login": "abbccdda"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcLDMUOgBqjMxMDYxMzk5Mjk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcLJUvdgFqTM3MDY5NDkwMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNTA1MjM0", "url": "https://github.com/apache/kafka/pull/8220#pullrequestreview-370505234", "createdAt": "2020-03-06T17:38:45Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12f23493778f6f40c630332b29a3c1f99065c478", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/12f23493778f6f40c630332b29a3c1f99065c478", "committedDate": "2020-03-06T23:45:02Z", "message": "bring back unsubscribe"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84ccecbac8fb619977fce3f6789cb5f864178d20", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/84ccecbac8fb619977fce3f6789cb5f864178d20", "committedDate": "2020-03-06T23:45:02Z", "message": "unit test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4c44254016f6c41f3429ab6a66dd7c203e0d482", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/d4c44254016f6c41f3429ab6a66dd7c203e0d482", "committedDate": "2020-03-06T23:58:03Z", "message": "rebase"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "d4c44254016f6c41f3429ab6a66dd7c203e0d482", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/d4c44254016f6c41f3429ab6a66dd7c203e0d482", "committedDate": "2020-03-06T23:58:03Z", "message": "rebase"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNjk0OTAx", "url": "https://github.com/apache/kafka/pull/8220#pullrequestreview-370694901", "createdAt": "2020-03-07T00:04:47Z", "commit": {"oid": "d4c44254016f6c41f3429ab6a66dd7c203e0d482"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wN1QwMDowNDo0N1rOFzK4Gw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wN1QwMDoxMDo0NFrOFzK83w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5OTg5OQ==", "bodyText": "Nice.", "url": "https://github.com/apache/kafka/pull/8220#discussion_r389199899", "createdAt": "2020-03-07T00:04:47Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java", "diffHunk": "@@ -356,21 +358,10 @@ public synchronized void seekToEnd(Collection<TopicPartition> partitions) {\n         subscriptions.requestOffsetReset(partitions, OffsetResetStrategy.LATEST);\n     }\n \n-    // needed for cases where you make a second call to endOffsets\n-    public synchronized void addEndOffsets(final Map<TopicPartition, Long> newOffsets) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4c44254016f6c41f3429ab6a66dd7c203e0d482"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMTExOQ==", "bodyText": "Hmm :) it reminds me that the mock consumer's behavior is not exactly the same as the actual consumer (the later would filter, the former would throw), but perhaps this worth a different PR to cleanup. @abbccdda could you file a JIRA for it?", "url": "https://github.com/apache/kafka/pull/8220#discussion_r389201119", "createdAt": "2020-03-07T00:10:44Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -807,6 +808,66 @@ public void shouldShutdownTaskManagerOnClose() {\n         EasyMock.verify(taskManager);\n     }\n \n+    @Test\n+    public void shouldNotReturnDataAfterTaskMigrated() {\n+        final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n+\n+        internalTopologyBuilder = EasyMock.createNiceMock(InternalTopologyBuilder.class);\n+\n+        EasyMock.expect(internalTopologyBuilder.sourceTopicCollection()).andReturn(Collections.singletonList(topic1)).times(2);\n+\n+        final MockConsumer<byte[], byte[]> consumer = new MockConsumer<>(OffsetResetStrategy.LATEST);\n+\n+        consumer.subscribe(Collections.singletonList(topic1), new MockRebalanceListener());\n+        consumer.rebalance(Collections.singletonList(t1p1));\n+        consumer.updateEndOffsets(Collections.singletonMap(t1p1, 10L));\n+        consumer.seekToEnd(Collections.singletonList(t1p1));\n+\n+        final ChangelogReader changelogReader = new MockChangelogReader() {\n+\n+            @Override\n+            public void restore() {\n+                consumer.addRecord(new ConsumerRecord<>(topic1, 1, 11, new byte[0], new byte[0]));\n+                consumer.addRecord(new ConsumerRecord<>(topic1, 1, 12, new byte[1], new byte[0]));\n+\n+                throw new TaskMigratedException(\n+                    \"Changelog restore found task migrated\", new RuntimeException(\"restore task migrated\"));\n+            }\n+        };\n+\n+        taskManager.handleLostAll();\n+\n+        EasyMock.replay(taskManager, internalTopologyBuilder);\n+\n+        final StreamsMetricsImpl streamsMetrics =\n+            new StreamsMetricsImpl(metrics, CLIENT_ID, StreamsConfig.METRICS_LATEST);\n+\n+        final StreamThread thread = new StreamThread(\n+            mockTime,\n+            config,\n+            null,\n+            consumer,\n+            consumer,\n+            changelogReader,\n+            null,\n+            taskManager,\n+            streamsMetrics,\n+            internalTopologyBuilder,\n+            CLIENT_ID,\n+            new LogContext(\"\"),\n+            new AtomicInteger()\n+        ).updateThreadMetadata(getSharedAdminClientId(CLIENT_ID));\n+\n+        final IllegalStateException thrown = assertThrows(\n+            IllegalStateException.class, thread::run);\n+\n+        EasyMock.verify(taskManager);\n+\n+        // The Mock consumer shall throw as the assignment has been wiped out, but records are assigned.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4c44254016f6c41f3429ab6a66dd7c203e0d482"}, "originalPosition": 67}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 376, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}