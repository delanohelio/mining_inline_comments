{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2NzY0OTg4", "number": 8897, "title": "MINOR; Use the automated protocol for the Consumer Protocol's subscriptions and assignments", "bodyText": "This PR moves the consumer protocol to using the automated protocol instead of using plain old structs.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-06-18T21:11:10Z", "url": "https://github.com/apache/kafka/pull/8897", "merged": true, "mergeCommit": {"oid": "466f8fd21c6651ea5daa50154239e85fa629dbb4"}, "closed": true, "closedAt": "2020-09-25T16:21:23Z", "author": {"login": "dajac"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcwGiTqgBqjM0OTQyNjg0MTg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdMYO4RAFqTQ5NjU2NTEwNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxNjE2MjMy", "url": "https://github.com/apache/kafka/pull/8897#pullrequestreview-491616232", "createdAt": "2020-09-18T16:31:24Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxNjozMToyNVrOHUUHcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxNzoyMzo1MFrOHUVt3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA2MzE1Mg==", "bodyText": "nit: could we remove the \"Data\" suffix? I think we only use it for the request/response classes to avoid naming conflicts.", "url": "https://github.com/apache/kafka/pull/8897#discussion_r491063152", "createdAt": "2020-09-18T16:31:25Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/resources/common/message/ConsumerProtocolSubscriptionData.json", "diffHunk": "@@ -0,0 +1,36 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"type\": \"data\",\n+  \"name\": \"ConsumerProtocolSubscriptionData\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA4ODc4OA==", "bodyText": "I think we can use the \"zero-copy\" flag and avoid the array conversions.", "url": "https://github.com/apache/kafka/pull/8897#discussion_r491088788", "createdAt": "2020-09-18T17:22:42Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/resources/common/message/ConsumerProtocolAssignmentData.json", "diffHunk": "@@ -0,0 +1,35 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"type\": \"data\",\n+  \"name\": \"ConsumerProtocolAssignmentData\",\n+  // Assignment part of the Consumer Protocol.\n+  //\n+  // The current implementation assumes that future versions will not break compatibility. When\n+  // it encounters a newer version, it parses it using the current format. This basically means\n+  // that new versions cannot remove or reorder any of the existing fields.\n+  \"validVersions\": \"0-1\",\n+  \"fields\": [\n+    { \"name\": \"AssignedPartitions\", \"type\": \"[]TopicPartition\", \"versions\": \"0+\",\n+      \"fields\": [\n+        { \"name\": \"Topic\", \"type\": \"string\", \"versions\": \"0+\" },\n+        { \"name\": \"Partitions\", \"type\": \"[]int32\", \"versions\": \"0+\" }\n+      ]\n+    },\n+    { \"name\": \"UserData\", \"type\": \"bytes\", \"versions\": \"0+\", \"nullableVersions\": \"0+\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA4OTM3Mg==", "bodyText": "This might not be safe. If we use the \"zero-copy\" flag as suggested below, we can just duplicate the ByteBuffer instead.", "url": "https://github.com/apache/kafka/pull/8897#discussion_r491089372", "createdAt": "2020-09-18T17:23:50Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerProtocol.java", "diffHunk": "@@ -35,287 +35,160 @@\n \n /**\n  * ConsumerProtocol contains the schemas for consumer subscriptions and assignments for use with\n- * Kafka's generalized group management protocol. Below is the version 1 format:\n- *\n- * <pre>\n- * Subscription => Version Topics\n- *   Version    => Int16\n- *   Topics     => [String]\n- *   UserData   => Bytes\n- *   OwnedPartitions    => [Topic Partitions]\n- *     Topic            => String\n- *     Partitions       => [int32]\n- *\n- * Assignment => Version TopicPartitions\n- *   Version            => int16\n- *   AssignedPartitions => [Topic Partitions]\n- *     Topic            => String\n- *     Partitions       => [int32]\n- *   UserData           => Bytes\n- * </pre>\n- *\n- * Version 0 format:\n- *\n- * <pre>\n- * Subscription => Version Topics\n- *   Version    => Int16\n- *   Topics     => [String]\n- *   UserData   => Bytes\n- *\n- * Assignment => Version TopicPartitions\n- *   Version            => int16\n- *   AssignedPartitions => [Topic Partitions]\n- *     Topic            => String\n- *     Partitions       => [int32]\n- *   UserData           => Bytes\n- * </pre>\n- *\n+ * Kafka's generalized group management protocol.\n  *\n  * The current implementation assumes that future versions will not break compatibility. When\n  * it encounters a newer version, it parses it using the current format. This basically means\n  * that new versions cannot remove or reorder any of the existing fields.\n  */\n public class ConsumerProtocol {\n-\n     public static final String PROTOCOL_TYPE = \"consumer\";\n \n-    public static final String VERSION_KEY_NAME = \"version\";\n-    public static final String TOPICS_KEY_NAME = \"topics\";\n-    public static final String TOPIC_KEY_NAME = \"topic\";\n-    public static final String PARTITIONS_KEY_NAME = \"partitions\";\n-    public static final String OWNED_PARTITIONS_KEY_NAME = \"owned_partitions\";\n-    public static final String TOPIC_PARTITIONS_KEY_NAME = \"topic_partitions\";\n-    public static final String USER_DATA_KEY_NAME = \"user_data\";\n-\n-    public static final short CONSUMER_PROTOCOL_V0 = 0;\n-    public static final short CONSUMER_PROTOCOL_V1 = 1;\n-\n-    public static final short CONSUMER_PROTOCOL_LATEST_VERSION = CONSUMER_PROTOCOL_V1;\n-\n-    public static final Schema CONSUMER_PROTOCOL_HEADER_SCHEMA = new Schema(\n-            new Field(VERSION_KEY_NAME, Type.INT16));\n-    private static final Struct CONSUMER_PROTOCOL_HEADER_V0 = new Struct(CONSUMER_PROTOCOL_HEADER_SCHEMA)\n-            .set(VERSION_KEY_NAME, CONSUMER_PROTOCOL_V0);\n-    private static final Struct CONSUMER_PROTOCOL_HEADER_V1 = new Struct(CONSUMER_PROTOCOL_HEADER_SCHEMA)\n-            .set(VERSION_KEY_NAME, CONSUMER_PROTOCOL_V1);\n-\n-    public static final Schema TOPIC_ASSIGNMENT_V0 = new Schema(\n-        new Field(TOPIC_KEY_NAME, Type.STRING),\n-        new Field(PARTITIONS_KEY_NAME, new ArrayOf(Type.INT32)));\n-\n-    public static final Schema SUBSCRIPTION_V0 = new Schema(\n-            new Field(TOPICS_KEY_NAME, new ArrayOf(Type.STRING)),\n-            new Field(USER_DATA_KEY_NAME, Type.NULLABLE_BYTES));\n-\n-    public static final Schema SUBSCRIPTION_V1 = new Schema(\n-        new Field(TOPICS_KEY_NAME, new ArrayOf(Type.STRING)),\n-        new Field(USER_DATA_KEY_NAME, Type.NULLABLE_BYTES),\n-        new Field(OWNED_PARTITIONS_KEY_NAME, new ArrayOf(TOPIC_ASSIGNMENT_V0)));\n-\n-    public static final Schema ASSIGNMENT_V0 = new Schema(\n-            new Field(TOPIC_PARTITIONS_KEY_NAME, new ArrayOf(TOPIC_ASSIGNMENT_V0)),\n-            new Field(USER_DATA_KEY_NAME, Type.NULLABLE_BYTES));\n-\n-    public static final Schema ASSIGNMENT_V1 = new Schema(\n-        new Field(TOPIC_PARTITIONS_KEY_NAME, new ArrayOf(TOPIC_ASSIGNMENT_V0)),\n-        new Field(USER_DATA_KEY_NAME, Type.NULLABLE_BYTES));\n-\n-    public static Short deserializeVersion(ByteBuffer buffer) {\n-        Struct header = CONSUMER_PROTOCOL_HEADER_SCHEMA.read(buffer);\n-        return header.getShort(VERSION_KEY_NAME);\n+    static {\n+        // Safety check to ensure that both parts of the consumer protocol remain in sync.\n+        if (ConsumerProtocolSubscriptionData.LOWEST_SUPPORTED_VERSION\n+                != ConsumerProtocolAssignmentData.LOWEST_SUPPORTED_VERSION)\n+            throw new IllegalStateException(\"Subscription and Assignment schemas must have the \" +\n+                \"same lowest version\");\n+\n+        if (ConsumerProtocolSubscriptionData.HIGHEST_SUPPORTED_VERSION\n+                != ConsumerProtocolAssignmentData.HIGHEST_SUPPORTED_VERSION)\n+            throw new IllegalStateException(\"Subscription and Assignment schemas must have the \" +\n+                \"same highest version\");\n     }\n \n-    public static ByteBuffer serializeSubscriptionV0(Subscription subscription) {\n-        Struct struct = new Struct(SUBSCRIPTION_V0);\n-        struct.set(USER_DATA_KEY_NAME, subscription.userData());\n-        struct.set(TOPICS_KEY_NAME, subscription.topics().toArray());\n+    public static short deserializeVersion(final ByteBuffer buffer) {\n+        try {\n+            return buffer.getShort();\n+        } catch (BufferUnderflowException e) {\n+            throw new SchemaException(\"Buffer underflow while parsing consumer protocol's header\", e);\n+        }\n+    }\n \n-        ByteBuffer buffer = ByteBuffer.allocate(CONSUMER_PROTOCOL_HEADER_V0.sizeOf() + SUBSCRIPTION_V0.sizeOf(struct));\n-        CONSUMER_PROTOCOL_HEADER_V0.writeTo(buffer);\n-        SUBSCRIPTION_V0.write(buffer, struct);\n-        buffer.flip();\n-        return buffer;\n+    public static ByteBuffer serializeSubscription(final Subscription subscription) {\n+        return serializeSubscription(subscription, ConsumerProtocolSubscriptionData.HIGHEST_SUPPORTED_VERSION);\n     }\n \n-    public static ByteBuffer serializeSubscriptionV1(Subscription subscription) {\n-        Struct struct = new Struct(SUBSCRIPTION_V1);\n-        struct.set(USER_DATA_KEY_NAME, subscription.userData());\n-        struct.set(TOPICS_KEY_NAME, subscription.topics().toArray());\n-        List<Struct> topicAssignments = new ArrayList<>();\n+    public static ByteBuffer serializeSubscription(final Subscription subscription, short version) {\n+        version = checkSubscriptionVersion(version);\n+\n+        ConsumerProtocolSubscriptionData data = new ConsumerProtocolSubscriptionData();\n+        data.setTopics(subscription.topics());\n+        if (subscription.userData() != null)\n+            data.setUserData(subscription.userData().array());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 161}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "75faa3758618153a5bc4bf7ed0f90d0ccb9dc5de", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/75faa3758618153a5bc4bf7ed0f90d0ccb9dc5de", "committedDate": "2020-09-25T08:20:33Z", "message": "MINOR; Use the automated protocol for the Consumer Protocol's subscriptions and assignments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2cfcd5f37670fb0741c5707ef092556994013a3b", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/2cfcd5f37670fb0741c5707ef092556994013a3b", "committedDate": "2020-09-25T08:20:33Z", "message": "update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c64881db6c01ab42d152221c4b5674a72dee2027", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/c64881db6c01ab42d152221c4b5674a72dee2027", "committedDate": "2020-09-25T08:56:11Z", "message": "address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "c64881db6c01ab42d152221c4b5674a72dee2027", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/c64881db6c01ab42d152221c4b5674a72dee2027", "committedDate": "2020-09-25T08:56:11Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2NTY1MTA2", "url": "https://github.com/apache/kafka/pull/8897#pullrequestreview-496565106", "createdAt": "2020-09-25T16:18:18Z", "commit": {"oid": "c64881db6c01ab42d152221c4b5674a72dee2027"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 671, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}