{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQyOTE0ODg1", "number": 8970, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoxMToxNlrOEKuq_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODoxOTo1NlrOELAnhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5Njg1ODg3OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogManager.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoxMToxN1rOGr77tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoxMToxN1rOGr77tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcyMzg5NQ==", "bodyText": "Have we checked that the dir.toString does what we want? If the path is relative, I think it will only print that.", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448723895", "createdAt": "2020-07-02T03:11:17Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -308,11 +312,11 @@ class LogManager(logDirs: Seq[File],\n         threadPools.append(pool)\n \n         val cleanShutdownFile = new File(dir, Log.CleanShutdownFile)\n-\n         if (cleanShutdownFile.exists) {\n-          debug(s\"Found clean shutdown file. Skipping recovery for all logs in data directory: ${dir.getAbsolutePath}\")\n+          info(s\"Skipping recovery for all logs in $dir since clean shutdown file was found\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5Njg3MzYwOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogManager.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoyMDo0MVrOGr8ERw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoyMDo0MVrOGr8ERw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcyNjA4Nw==", "bodyText": "We should fix this and related code to use hiResClockMs since it's monotonic.", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448726087", "createdAt": "2020-07-02T03:20:41Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -321,25 +325,32 @@ class LogManager(logDirs: Seq[File],\n           recoveryPoints = this.recoveryPointCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir\", e)\n-            warn(\"Resetting the recovery checkpoint to 0\")\n+            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir, \" +\n+              \"resetting the recovery checkpoint to 0\", e)\n         }\n \n         var logStartOffsets = Map[TopicPartition, Long]()\n         try {\n           logStartOffsets = this.logStartOffsetCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir\", e)\n+            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir, \" +\n+              \"resetting to the base offset of the first segment\", e)\n         }\n \n-        val jobsForDir = for {\n-          dirContent <- Option(dir.listFiles).toList\n-          logDir <- dirContent if logDir.isDirectory\n-        } yield {\n+        val logsToLoad = Option(dir.listFiles).getOrElse(Array.empty).filter(_.isDirectory)\n+        val numRemainingLogsToLoad = new AtomicInteger(logsToLoad.length)\n+\n+        val jobsForDir = logsToLoad.map { logDir =>\n           val runnable: Runnable = () => {\n             try {\n-              loadLog(logDir, recoveryPoints, logStartOffsets)\n+              debug(s\"Loading log $logDir\")\n+              val logLoadStartMs = time.milliseconds()\n+              val log = loadLog(logDir, recoveryPoints, logStartOffsets)\n+              numRemainingLogsToLoad.decrementAndGet()\n+              info(s\"Completed load of $log with ${log.numberOfSegments} segments \" +\n+                s\"in ${time.milliseconds() - logLoadStartMs}ms \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5Njg3NjI2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogManager.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoyMjoxOFrOGr8F1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoyMjoxOFrOGr8F1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcyNjQ4NQ==", "bodyText": "Can we keep the variable here and then use it in the log below? Also, should we decrement the value if there's an exception?", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448726485", "createdAt": "2020-07-02T03:22:18Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -321,25 +325,32 @@ class LogManager(logDirs: Seq[File],\n           recoveryPoints = this.recoveryPointCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir\", e)\n-            warn(\"Resetting the recovery checkpoint to 0\")\n+            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir, \" +\n+              \"resetting the recovery checkpoint to 0\", e)\n         }\n \n         var logStartOffsets = Map[TopicPartition, Long]()\n         try {\n           logStartOffsets = this.logStartOffsetCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir\", e)\n+            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir, \" +\n+              \"resetting to the base offset of the first segment\", e)\n         }\n \n-        val jobsForDir = for {\n-          dirContent <- Option(dir.listFiles).toList\n-          logDir <- dirContent if logDir.isDirectory\n-        } yield {\n+        val logsToLoad = Option(dir.listFiles).getOrElse(Array.empty).filter(_.isDirectory)\n+        val numRemainingLogsToLoad = new AtomicInteger(logsToLoad.length)\n+\n+        val jobsForDir = logsToLoad.map { logDir =>\n           val runnable: Runnable = () => {\n             try {\n-              loadLog(logDir, recoveryPoints, logStartOffsets)\n+              debug(s\"Loading log $logDir\")\n+              val logLoadStartMs = time.milliseconds()\n+              val log = loadLog(logDir, recoveryPoints, logStartOffsets)\n+              numRemainingLogsToLoad.decrementAndGet()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5Njg4MDgzOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogManager.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoyNToxNFrOGr8IbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoyNToxNFrOGr8IbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcyNzE0OA==", "bodyText": "Could we maybe say something like Loaded n logs after... where n is the number of logs we loaded?", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448727148", "createdAt": "2020-07-02T03:25:14Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -379,7 +391,7 @@ class LogManager(logDirs: Seq[File],\n       threadPools.foreach(_.shutdown())\n     }\n \n-    info(s\"Logs loading complete in ${time.milliseconds - startMs} ms.\")\n+    info(s\"Log loading completed after ${time.milliseconds - startMs}ms.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5Njk5NDMyOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogManager.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwNDozNzo1N1rOGr9KJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwNDozNzo1N1rOGr9KJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc0Mzk3Mw==", "bodyText": "Nit: an alternative would be to say something like 3 out of 5 logs have been loaded in $dir. It gives a slightly better sense of progression.", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448743973", "createdAt": "2020-07-02T04:37:57Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -321,25 +325,32 @@ class LogManager(logDirs: Seq[File],\n           recoveryPoints = this.recoveryPointCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir\", e)\n-            warn(\"Resetting the recovery checkpoint to 0\")\n+            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir, \" +\n+              \"resetting the recovery checkpoint to 0\", e)\n         }\n \n         var logStartOffsets = Map[TopicPartition, Long]()\n         try {\n           logStartOffsets = this.logStartOffsetCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir\", e)\n+            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir, \" +\n+              \"resetting to the base offset of the first segment\", e)\n         }\n \n-        val jobsForDir = for {\n-          dirContent <- Option(dir.listFiles).toList\n-          logDir <- dirContent if logDir.isDirectory\n-        } yield {\n+        val logsToLoad = Option(dir.listFiles).getOrElse(Array.empty).filter(_.isDirectory)\n+        val numRemainingLogsToLoad = new AtomicInteger(logsToLoad.length)\n+\n+        val jobsForDir = logsToLoad.map { logDir =>\n           val runnable: Runnable = () => {\n             try {\n-              loadLog(logDir, recoveryPoints, logStartOffsets)\n+              debug(s\"Loading log $logDir\")\n+              val logLoadStartMs = time.milliseconds()\n+              val log = loadLog(logDir, recoveryPoints, logStartOffsets)\n+              numRemainingLogsToLoad.decrementAndGet()\n+              info(s\"Completed load of $log with ${log.numberOfSegments} segments \" +\n+                s\"in ${time.milliseconds() - logLoadStartMs}ms \" +\n+                s\"(${numRemainingLogsToLoad.get} logs remaining to load in $dir)\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTc5OTExOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/log/LogManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODoxOTo1NlrOGsYnLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODoxOTo1NlrOGsYnLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE5Mzc3NQ==", "bodyText": "Did you mean to include the word logs somewhere in this sentence?", "url": "https://github.com/apache/kafka/pull/8970#discussion_r449193775", "createdAt": "2020-07-02T18:19:56Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -379,7 +396,7 @@ class LogManager(logDirs: Seq[File],\n       threadPools.foreach(_.shutdown())\n     }\n \n-    info(s\"Logs loading complete in ${time.milliseconds - startMs} ms.\")\n+    info(s\"Loaded $numTotalLogs in ${time.hiResClockMs() - startMs}ms.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77bc7335122ead4ee67c5a2c53d24ebffb63336b"}, "originalPosition": 125}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2164, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}