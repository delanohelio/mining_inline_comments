{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyNjcwNTk4", "number": 8069, "title": "KAFKA-9374: Make connector interactions asynchronous", "bodyText": "Jira ticket\nThese changes allow herders to continue to function even when a connector they are running hangs in its start, stop, initialize, validate, and/or config methods.\nThe main idea is to make these connector interactions asynchronous and accept a callback that can be invoked upon the completion (successful or otherwise) of these interactions. The distributed herder handles any follow-up logic by adding a new herder request to its queue in that callback, which helps preserve some synchronization and ordering guarantees provided by the current tick model.\nIf any connector refuses to shut down within a graceful timeout period, the framework will abandon it and potentially start a new connector in its place (in cases such as connector restart or reconfiguration).\nExisting unit tests for the distributed herder and worker have been modified to reflect these changes, and a new integration test named BlockingConnectorTest has been added to ensure that they work in practice.", "createdAt": "2020-02-08T02:36:53Z", "url": "https://github.com/apache/kafka/pull/8069", "merged": true, "mergeCommit": {"oid": "7f4fc76e968a6b2cf4a73364c93bfdea03f81af3"}, "closed": true, "closedAt": "2020-06-11T08:29:24Z", "author": {"login": "C0urante"}, "timelineItems": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcCbgOdABqjMwMjAxOTQ3NDk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcqGw69AH2gAyMzcyNjcwNTk4OmJmYjFiYzA0ODMyYjM0MmU2MTRlODkxZDZkYTVhZjFmOGViZTMwYTU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU2MjkxOTk0", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-356291994", "createdAt": "2020-02-10T21:53:26Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQyMTo1MzoyNlrOFn274g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQyMTo1NDo1NlrOFn2-mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzMzODg1MA==", "bodyText": "It looks like you are reusing the executor that currently is used to run the WorkerTask. Since operations are async now, would it be possible to have startTask called on a different thread while connector is still being initialized or is transitioning to started state here?", "url": "https://github.com/apache/kafka/pull/8069#discussion_r377338850", "createdAt": "2020-02-10T21:53:26Z", "author": {"login": "ncliang"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -270,6 +273,8 @@ public boolean startConnector(\n             if (existing != null)\n                 throw new ConnectException(\"Connector with name \" + connName + \" already exists\");\n \n+            executor.submit(workerConnector);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzMzOTU0Ng==", "bodyText": "Probably a good idea to have timeout to not block indefinitely.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r377339546", "createdAt": "2020-02-10T21:54:56Z", "author": {"login": "ncliang"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/resources/ConnectorPluginsResource.java", "diffHunk": "@@ -78,7 +79,11 @@ public ConfigInfos validateConfigs(\n             );\n         }\n \n-        return herder.validateConnectorConfig(connectorConfig);\n+        FutureCallback<ConfigInfos> validationCallback = new FutureCallback<>();\n+        herder.validateConnectorConfig(connectorConfig, validationCallback);\n+\n+        // TODO: Timeout?\n+        return validationCallback.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU3MDA3Nzkw", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-357007790", "createdAt": "2020-02-11T21:26:54Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMToyNjo1NFrOFoZuPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMToyNjo1NFrOFoZuPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzkwODc5OA==", "bodyText": "It'd be great to minimize the number of changes lines, so maybe put the runnable logic as a separate method to eliminate the indentation-only changes.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r377908798", "createdAt": "2020-02-11T21:26:54Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/AbstractHerder.java", "diffHunk": "@@ -299,103 +304,115 @@ public StatusBackingStore statusBackingStore() {\n     }\n \n     @Override\n-    public ConfigInfos validateConnectorConfig(Map<String, String> connectorProps) {\n-        if (worker.configTransformer() != null) {\n-            connectorProps = worker.configTransformer().transform(connectorProps);\n-        }\n-        String connType = connectorProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n-        if (connType == null)\n-            throw new BadRequestException(\"Connector config \" + connectorProps + \" contains no connector type\");\n-\n-        Connector connector = getConnector(connType);\n-        org.apache.kafka.connect.health.ConnectorType connectorType;\n-        ClassLoader savedLoader = plugins().compareAndSwapLoaders(connector);\n-        try {\n-            ConfigDef baseConfigDef;\n-            if (connector instanceof SourceConnector) {\n-                baseConfigDef = SourceConnectorConfig.configDef();\n-                connectorType = org.apache.kafka.connect.health.ConnectorType.SOURCE;\n-            } else {\n-                baseConfigDef = SinkConnectorConfig.configDef();\n-                SinkConnectorConfig.validate(connectorProps);\n-                connectorType = org.apache.kafka.connect.health.ConnectorType.SINK;\n-            }\n-            ConfigDef enrichedConfigDef = ConnectorConfig.enrich(plugins(), baseConfigDef, connectorProps, false);\n-            Map<String, ConfigValue> validatedConnectorConfig = validateBasicConnectorConfig(\n-                    connector,\n-                    enrichedConfigDef,\n-                    connectorProps\n-            );\n-            List<ConfigValue> configValues = new ArrayList<>(validatedConnectorConfig.values());\n-            Map<String, ConfigKey> configKeys = new LinkedHashMap<>(enrichedConfigDef.configKeys());\n-            Set<String> allGroups = new LinkedHashSet<>(enrichedConfigDef.groups());\n-\n-            // do custom connector-specific validation\n-            Config config = connector.validate(connectorProps);\n-            if (null == config) {\n-                throw new BadRequestException(\n-                    String.format(\n-                        \"%s.validate() must return a Config that is not null.\",\n-                        connector.getClass().getName()\n-                    )\n-                );\n-            }\n-            ConfigDef configDef = connector.config();\n-            if (null == configDef) {\n-                throw new BadRequestException(\n-                    String.format(\n-                        \"%s.config() must return a ConfigDef that is not null.\",\n-                        connector.getClass().getName()\n-                    )\n-                );\n-            }\n-            configKeys.putAll(configDef.configKeys());\n-            allGroups.addAll(configDef.groups());\n-            configValues.addAll(config.configValues());\n-            ConfigInfos configInfos =  generateResult(connType, configKeys, configValues, new ArrayList<>(allGroups));\n-\n-            AbstractConfig connectorConfig = new AbstractConfig(new ConfigDef(), connectorProps);\n-            String connName = connectorProps.get(ConnectorConfig.NAME_CONFIG);\n-            ConfigInfos producerConfigInfos = null;\n-            ConfigInfos consumerConfigInfos = null;\n-            ConfigInfos adminConfigInfos = null;\n-            if (connectorType.equals(org.apache.kafka.connect.health.ConnectorType.SOURCE)) {\n-                producerConfigInfos = validateClientOverrides(connName,\n-                                                              ConnectorConfig.CONNECTOR_CLIENT_PRODUCER_OVERRIDES_PREFIX,\n-                                                              connectorConfig,\n-                                                              ProducerConfig.configDef(),\n-                                                              connector.getClass(),\n-                                                              connectorType,\n-                                                              ConnectorClientConfigRequest.ClientType.PRODUCER,\n-                                                              connectorClientConfigOverridePolicy);\n-                return mergeConfigInfos(connType, configInfos, producerConfigInfos);\n-            } else {\n-                consumerConfigInfos = validateClientOverrides(connName,\n-                                                              ConnectorConfig.CONNECTOR_CLIENT_CONSUMER_OVERRIDES_PREFIX,\n-                                                              connectorConfig,\n-                                                              ProducerConfig.configDef(),\n-                                                              connector.getClass(),\n-                                                              connectorType,\n-                                                              ConnectorClientConfigRequest.ClientType.CONSUMER,\n-                                                              connectorClientConfigOverridePolicy);\n-                // check if topic for dead letter queue exists\n-                String topic = connectorProps.get(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG);\n-                if (topic != null && !topic.isEmpty()) {\n-                    adminConfigInfos = validateClientOverrides(connName,\n-                                                               ConnectorConfig.CONNECTOR_CLIENT_ADMIN_OVERRIDES_PREFIX,\n-                                                               connectorConfig,\n-                                                               ProducerConfig.configDef(),\n-                                                               connector.getClass(),\n-                                                               connectorType,\n-                                                               ConnectorClientConfigRequest.ClientType.ADMIN,\n-                                                               connectorClientConfigOverridePolicy);\n+    public void validateConnectorConfig(Map<String, String> connectorProps, Callback<ConfigInfos> callback) {\n+        connectorExecutor.submit(new Runnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 128}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk4NzUwNjU4", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-398750658", "createdAt": "2020-04-23T04:28:16Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwNDoyODoxNlrOGKWBRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwNDoyODoxNlrOGKWBRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ5OTcxOA==", "bodyText": "This part still needs some work; it's in an inconsistent state because I modified Worker::startConnector to have no return value and instead communicate all success or failure of the connector startup through the callback, but haven't taken care of issues like possibly invoking the callback twice (once in this method, and once in the WorkerConnector instance), making sure to swap plugin classloaders at the right times, and preventing a possible race with the check to see if the connector already exists based on whether its name is present as a key in the connectors map.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r413499718", "createdAt": "2020-04-23T04:28:16Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -263,17 +267,20 @@ public boolean startConnector(\n                 Plugins.compareAndSwapLoaders(savedLoader);\n                 workerMetricsGroup.recordConnectorStartupFailure();\n                 statusListener.onFailure(connName, t);\n-                return false;\n+                onConnectorStateChange.onCompletion(t, null);\n+                return;\n             }\n+            workerConnector.transitionTo(initialState, onConnectorStateChange);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU3MDA5OTIx", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-357009921", "createdAt": "2020-02-11T21:30:08Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwNTo0NToxM1rOGNDi2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMDoyMjoxN1rOGOVmAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0Mjc0NA==", "bodyText": "why use locking if the variable is volatile and can change only to true during the lifetime of this object?", "url": "https://github.com/apache/kafka/pull/8069#discussion_r416342744", "createdAt": "2020-04-28T05:45:13Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/HerderConnectorContext.java", "diffHunk": "@@ -16,30 +16,64 @@\n  */\n package org.apache.kafka.connect.runtime;\n \n-import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n /**\n  * ConnectorContext for use with a Herder\n  */\n-public class HerderConnectorContext implements ConnectorContext {\n+public class HerderConnectorContext implements CloseableConnectorContext {\n+\n+    private static final Logger log = LoggerFactory.getLogger(HerderConnectorContext.class);\n \n     private final AbstractHerder herder;\n     private final String connectorName;\n+    private volatile boolean closed;\n \n     public HerderConnectorContext(AbstractHerder herder, String connectorName) {\n         this.herder = herder;\n         this.connectorName = connectorName;\n+        this.closed = false;\n     }\n \n     @Override\n     public void requestTaskReconfiguration() {\n+        synchronized (this) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw==", "bodyText": "same question here and below about locking around a volatile variable. Is this the only reason to lock here? One would think so based on previous usage.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r416345143", "createdAt": "2020-04-28T05:51:25Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerConnector.java", "diffHunk": "@@ -266,31 +422,51 @@ public void close() {\n         @Override\n         public void onStartup(String connector) {\n             state = AbstractStatus.State.RUNNING;\n-            delegate.onStartup(connector);\n+            synchronized (this) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4NzA0MA==", "bodyText": "I don't think this is worth backporting before AK 2.0, and maybe not even as far back. Given that, I'd suggest using lambda notation whenever a new Runnable is needed to avoid the Runnable declaration boilerplate.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r417687040", "createdAt": "2020-04-30T00:22:17Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -191,32 +192,71 @@ public synchronized void putConnectorConfig(String connName,\n                                                 boolean allowReplace,\n                                                 final Callback<Created<ConnectorInfo>> callback) {\n         try {\n-            if (maybeAddConfigErrors(validateConnectorConfig(config), callback)) {\n+            validateConnectorConfig(config, new Callback<ConfigInfos>() {\n+                @Override\n+                public void onCompletion(Throwable error, ConfigInfos configInfos) {\n+                    if (error != null) {\n+                        callback.onCompletion(error, null);\n+                        return;\n+                    }\n+\n+                    requestExecutorService.submit(\n+                        () -> putConnectorConfig(connName, config, allowReplace, callback, configInfos)\n+                    );\n+                }\n+            });\n+        } catch (Throwable t) {\n+            callback.onCompletion(t, null);\n+        }\n+    }\n+\n+    private synchronized void putConnectorConfig(String connName,\n+                                                 final Map<String, String> config,\n+                                                 boolean allowReplace,\n+                                                 final Callback<Created<ConnectorInfo>> callback,\n+                                                 ConfigInfos configInfos) {\n+        try {\n+            if (maybeAddConfigErrors(configInfos, callback)) {\n                 return;\n             }\n \n-            boolean created = false;\n+            final boolean created;\n             if (configState.contains(connName)) {\n                 if (!allowReplace) {\n                     callback.onCompletion(new AlreadyExistsException(\"Connector \" + connName + \" already exists\"), null);\n                     return;\n                 }\n-                worker.stopConnector(connName);\n+                worker.stopAndAwaitConnector(connName);\n+                created = false;\n             } else {\n                 created = true;\n             }\n \n             configBackingStore.putConnectorConfig(connName, config);\n \n-            if (!startConnector(connName)) {\n-                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connName), null);\n-                return;\n-            }\n+            Callback<TargetState> onStart = new Callback<TargetState>() {\n+                @Override\n+                public void onCompletion(Throwable error, TargetState result) {\n+                    if (error != null) {\n+                        callback.onCompletion(error, null);\n+                        return;\n+                    }\n+\n+                    requestExecutorService.submit(new Runnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 105}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2MzAwMjU4", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-406300258", "createdAt": "2020-05-06T04:42:20Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwNDo0MjoyMFrOGRD1jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwNTo0NzozNVrOGREyQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU0MTgzNg==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420541836", "createdAt": "2020-05-06T04:42:20Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -246,15 +251,16 @@ public boolean startConnector(\n             final WorkerConnector workerConnector;\n             ClassLoader savedLoader = plugins.currentThreadLoader();\n             try {\n+                final String connClass = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1MDc0OA==", "bodyText": "nit: seems unnecessary?\nsimilar for State.FAILED below.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420550748", "createdAt": "2020-05-06T05:21:04Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerConnector.java", "diffHunk": "@@ -166,27 +244,105 @@ private void pause() {\n         }\n     }\n \n+    /**\n+     * Stop this connector. This method does not block, it only triggers shutdown. Use\n+     * #{@link #awaitShutdown} to block until completion.\n+     */\n     public void shutdown() {\n+        synchronized (this) {\n+            log.info(\"Scheduled shutdown for {}\", this);\n+            stopping = true;\n+            notify();\n+        }\n+    }\n+\n+    void doShutdown() {\n         try {\n             if (state == State.STARTED)\n                 connector.stop();\n-            this.state = State.STOPPED;\n+            WorkerConnector.this.state = State.STOPPED;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 195}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NTQzNg==", "bodyText": "Is it possible to trigger this log statement now?\nShould this be moved into the callback?", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420555436", "createdAt": "2020-05-06T05:40:10Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -1182,28 +1251,47 @@ public Void call() throws Exception {\n \n     // Helper for starting a connector with the given name, which will extract & parse the config, generate connector\n     // context and add to the worker. This needs to be called from within the main worker thread for this herder.\n-    private boolean startConnector(String connectorName) {\n+    // The callback is invoked after the connector has finished startup and generated task configs, or failed in the process.\n+    private void startConnector(String connectorName, Callback<Void> callback) {\n         log.info(\"Starting connector {}\", connectorName);\n         final Map<String, String> configProps = configState.connectorConfig(connectorName);\n-        final ConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n+        final CloseableConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n         final TargetState initialState = configState.targetState(connectorName);\n-        boolean started = worker.startConnector(connectorName, configProps, ctx, this, initialState);\n-\n-        // Immediately request configuration since this could be a brand new connector. However, also only update those\n-        // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n-        // just restoring an existing connector.\n-        if (started && initialState == TargetState.STARTED)\n-            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+        final Callback<TargetState> onInitialStateChange = (error, newState) -> {\n+            if (error != null) {\n+                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connectorName), null);\n+                return;\n+            }\n \n-        return started;\n+            // newState should be equal to initialState, but use it just in case\n+            if (newState == TargetState.STARTED) {\n+                addRequest(\n+                    new Callable<Void>() {\n+                        @Override\n+                        public Void call() {\n+                            // Request configuration since this could be a brand new connector. However, also only update those\n+                            // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n+                            // just restoring an existing connector.\n+                            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+                            callback.onCompletion(null, null);\n+                            return null;\n+                        }\n+                    },\n+                    forwardErrorCallback(callback)\n+                );\n+            } else {\n+                callback.onCompletion(null, null);\n+            }\n+        };\n+        worker.startConnector(connectorName, configProps, ctx, this, initialState, onInitialStateChange);\n     }\n \n     private Callable<Void> getConnectorStartingCallable(final String connectorName) {\n         return new Callable<Void>() {\n             @Override\n             public Void call() throws Exception {\n                 try {\n-                    startConnector(connectorName);\n+                    startConnector(connectorName, (error, result) -> { });\n                 } catch (Throwable t) {\n                     log.error(\"Couldn't instantiate connector \" + connectorName + \" because it has an invalid connector \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 336}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NjY0OQ==", "bodyText": "If only time was mocked.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420556649", "createdAt": "2020-05-06T05:44:42Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/resources/ConnectorsResource.java", "diffHunk": "@@ -82,6 +82,9 @@\n     // we need to consider all possible scenarios this could fail. It might be ok to fail with a timeout in rare cases,\n     // but currently a worker simply leaving the group can take this long as well.\n     public static final long REQUEST_TIMEOUT_MS = 90 * 1000;\n+    // Mutable for integration testing; otherwise, some tests would take at least REQUEST_TIMEOUT_MS", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1Njc0Nw==", "bodyText": "Can this be knocked down to protected / package-private?", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420556747", "createdAt": "2020-05-06T05:45:06Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/resources/ConnectorsResource.java", "diffHunk": "@@ -97,6 +100,15 @@ public ConnectorsResource(Herder herder, WorkerConfig config) {\n         isTopicTrackingResetDisabled = !config.getBoolean(TOPIC_TRACKING_ALLOW_RESET_CONFIG);\n     }\n \n+    // For testing purposes only\n+    public static void setRequestTimeout(long requestTimeoutMs) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NzM3Ng==", "bodyText": "All of the call sites for this function have synchronization blocks, can you just add the synchronized keyword to the method instead?", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420557376", "createdAt": "2020-05-06T05:47:35Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -191,32 +192,61 @@ public synchronized void putConnectorConfig(String connName,\n                                                 boolean allowReplace,\n                                                 final Callback<Created<ConnectorInfo>> callback) {\n         try {\n-            if (maybeAddConfigErrors(validateConnectorConfig(config), callback)) {\n+            validateConnectorConfig(config, (error, configInfos) -> {\n+                if (error != null) {\n+                    callback.onCompletion(error, null);\n+                    return;\n+                }\n+\n+                requestExecutorService.submit(\n+                    () -> putConnectorConfig(connName, config, allowReplace, callback, configInfos)\n+                );\n+            });\n+        } catch (Throwable t) {\n+            callback.onCompletion(t, null);\n+        }\n+    }\n+\n+    private synchronized void putConnectorConfig(String connName,\n+                                                 final Map<String, String> config,\n+                                                 boolean allowReplace,\n+                                                 final Callback<Created<ConnectorInfo>> callback,\n+                                                 ConfigInfos configInfos) {\n+        try {\n+            if (maybeAddConfigErrors(configInfos, callback)) {\n                 return;\n             }\n \n-            boolean created = false;\n+            final boolean created;\n             if (configState.contains(connName)) {\n                 if (!allowReplace) {\n                     callback.onCompletion(new AlreadyExistsException(\"Connector \" + connName + \" already exists\"), null);\n                     return;\n                 }\n-                worker.stopConnector(connName);\n+                worker.stopAndAwaitConnector(connName);\n+                created = false;\n             } else {\n                 created = true;\n             }\n \n             configBackingStore.putConnectorConfig(connName, config);\n \n-            if (!startConnector(connName)) {\n-                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connName), null);\n-                return;\n-            }\n+            // startConnector(connName, onStart);\n+            startConnector(connName, (error, result) -> {\n+                if (error != null) {\n+                    callback.onCompletion(error, null);\n+                    return;\n+                }\n \n-            updateConnectorTasks(connName);\n-            callback.onCompletion(null, new Created<>(created, createConnectorInfo(connName)));\n-        } catch (ConnectException e) {\n-            callback.onCompletion(e, null);\n+                requestExecutorService.submit(() -> {\n+                    synchronized (this) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 106}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2Nzc2MzE5", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-406776319", "createdAt": "2020-05-06T16:19:07Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQxNjoxOTowN1rOGRa5ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQxNjoxOTowN1rOGRa5ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkxOTcxMA==", "bodyText": "I don't think locking buys you anything w/r/t to that. The producer#send in the status backing store is asynchronous. So what would describe above can happen anyways, regardless of whether you lock this object.\nOf course, if it wasn't asynchronous things would be much worse. A bottleneck would be created by the lock, waiting for the send to finish in every locked block, so that's not an option. Wdyt?\nThat's what I see at the high level without spending to much time on it, but see if you can check this assumption and we can return to this question.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420919710", "createdAt": "2020-05-06T16:19:07Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerConnector.java", "diffHunk": "@@ -266,31 +422,51 @@ public void close() {\n         @Override\n         public void onStartup(String connector) {\n             state = AbstractStatus.State.RUNNING;\n-            delegate.onStartup(connector);\n+            synchronized (this) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw=="}, "originalCommit": null, "originalPosition": 289}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2OTcxOTM2", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-406971936", "createdAt": "2020-05-06T20:43:49Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQyMDo0Mzo0OVrOGRkrUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQyMDo1MzoxOFrOGRk_Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA3OTg4OQ==", "bodyText": "nit: leftover comments", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421079889", "createdAt": "2020-05-06T20:43:49Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -239,9 +236,10 @@ private synchronized void putConnectorConfig(String connName,\n                 }\n \n                 requestExecutorService.submit(() -> {\n-                    synchronized (this) {\n-                        updateConnectorTasks(connName);\n-                    }\n+                    updateConnectorTasks(connName);\n+                    // synchronized (this) {\n+                    //     updateConnectorTasks(connName);\n+                    // }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4MDE0NQ==", "bodyText": "nit: leftover comments", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421080145", "createdAt": "2020-05-06T20:44:18Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -412,9 +407,10 @@ public void onConnectorTargetStateChange(String connector) {\n \n                     if (newState == TargetState.STARTED) {\n                         requestExecutorService.submit(() -> {\n-                            synchronized (StandaloneHerder.this) {\n-                                updateConnectorTasks(connector);\n-                            }\n+                            updateConnectorTasks(connector);\n+                            // synchronized (StandaloneHerder.this) {\n+                            //     updateConnectorTasks(connector);\n+                            // }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4MzE2NQ==", "bodyText": "The caller of this function doesn't need to block on starting the connector, but I think it should log errors inside of the callback. Otherwise they're going to get swallowed.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421083165", "createdAt": "2020-05-06T20:49:50Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -536,20 +561,37 @@ private void processConnectorConfigUpdates(Set<String> connectorConfigUpdates) {\n         // If we only have connector config updates, we can just bounce the updated connectors that are\n         // currently assigned to this worker.\n         Set<String> localConnectors = assignment == null ? Collections.<String>emptySet() : new HashSet<>(assignment.connectors());\n+        log.trace(\n+            \"Processing connector config updates; \"\n+                + \"currently-owned connectors are {}, and to-be-updated connectors are {}\",\n+            localConnectors,\n+            connectorConfigUpdates\n+        );\n         for (String connectorName : connectorConfigUpdates) {\n-            if (!localConnectors.contains(connectorName))\n+            if (!localConnectors.contains(connectorName)) {\n+                log.trace(\n+                    \"Skipping config update for connector {} as it is not owned by this worker\",\n+                    connectorName\n+                );\n                 continue;\n+            }\n             boolean remains = configState.contains(connectorName);\n             log.info(\"Handling connector-only config update by {} connector {}\",\n                     remains ? \"restarting\" : \"stopping\", connectorName);\n-            worker.stopConnector(connectorName);\n+            worker.stopAndAwaitConnector(connectorName);\n             // The update may be a deletion, so verify we actually need to restart the connector\n             if (remains)\n-                startConnector(connectorName);\n+                startConnector(connectorName, (error, result) -> { });", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4MzQzMg==", "bodyText": "This needs a log statement to avoid swallowing the exception silently.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421083432", "createdAt": "2020-05-06T20:50:22Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -1182,31 +1245,49 @@ public Void call() throws Exception {\n \n     // Helper for starting a connector with the given name, which will extract & parse the config, generate connector\n     // context and add to the worker. This needs to be called from within the main worker thread for this herder.\n-    private boolean startConnector(String connectorName) {\n+    // The callback is invoked after the connector has finished startup and generated task configs, or failed in the process.\n+    private void startConnector(String connectorName, Callback<Void> callback) {\n         log.info(\"Starting connector {}\", connectorName);\n         final Map<String, String> configProps = configState.connectorConfig(connectorName);\n-        final ConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n+        final CloseableConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n         final TargetState initialState = configState.targetState(connectorName);\n-        boolean started = worker.startConnector(connectorName, configProps, ctx, this, initialState);\n-\n-        // Immediately request configuration since this could be a brand new connector. However, also only update those\n-        // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n-        // just restoring an existing connector.\n-        if (started && initialState == TargetState.STARTED)\n-            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+        final Callback<TargetState> onInitialStateChange = (error, newState) -> {\n+            if (error != null) {\n+                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connectorName), null);\n+                return;\n+            }\n \n-        return started;\n+            // Use newState here in case the connector has been paused right after being created\n+            if (newState == TargetState.STARTED) {\n+                addRequest(\n+                    new Callable<Void>() {\n+                        @Override\n+                        public Void call() {\n+                            // Request configuration since this could be a brand new connector. However, also only update those\n+                            // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n+                            // just restoring an existing connector.\n+                            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+                            callback.onCompletion(null, null);\n+                            return null;\n+                        }\n+                    },\n+                    forwardErrorCallback(callback)\n+                );\n+            } else {\n+                callback.onCompletion(null, null);\n+            }\n+        };\n+        worker.startConnector(connectorName, configProps, ctx, this, initialState, onInitialStateChange);\n     }\n \n     private Callable<Void> getConnectorStartingCallable(final String connectorName) {\n         return new Callable<Void>() {\n             @Override\n             public Void call() throws Exception {\n                 try {\n-                    startConnector(connectorName);\n+                    startConnector(connectorName, (error, result) -> { });", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 372}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4NTAwMw==", "bodyText": "Yeah, I don't think that it's worth changing everything just to mock time, especially if requires us to change the functionality.\nSGTM.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421085003", "createdAt": "2020-05-06T20:53:18Z", "author": {"login": "gharris1727"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/resources/ConnectorsResource.java", "diffHunk": "@@ -82,6 +82,9 @@\n     // we need to consider all possible scenarios this could fail. It might be ok to fail with a timeout in rare cases,\n     // but currently a worker simply leaving the group can take this long as well.\n     public static final long REQUEST_TIMEOUT_MS = 90 * 1000;\n+    // Mutable for integration testing; otherwise, some tests would take at least REQUEST_TIMEOUT_MS", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NjY0OQ=="}, "originalCommit": null, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4MzgxMTAx", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-408381101", "createdAt": "2020-05-08T17:01:48Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2ODk1NzE0", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-426895714", "createdAt": "2020-06-09T08:18:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwODoxODoxNVrOGg96Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMDo0NDo0OFrOGhhGpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyMTkxMQ==", "bodyText": "Any reason not to use AutoCloseable instead?", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437221911", "createdAt": "2020-06-09T08:18:15Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/CloseableConnectorContext.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.errors.ConnectException;\n+\n+import java.io.Closeable;\n+\n+public interface CloseableConnectorContext extends ConnectorContext, Closeable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyOTQ3Nw==", "bodyText": "not sure what's the advantage of bringing this log message further down here. Searching the logs for Stopping connector will miss the cases of \"unowned\" connectors, making debugging potentially more challenging.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437229477", "createdAt": "2020-06-09T08:30:24Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -356,40 +390,96 @@ public boolean isSinkConnector(String connName) {\n         return result;\n     }\n \n-    private void stopConnectors() {\n-        // Herder is responsible for stopping connectors. This is an internal method to sequentially\n-        // stop connectors that have not explicitly been stopped.\n-        for (String connector: connectors.keySet())\n-            stopConnector(connector);\n-    }\n-\n     /**\n      * Stop a connector managed by this worker.\n      *\n      * @param connName the connector name.\n-     * @return true if the connector belonged to this worker and was successfully stopped.\n      */\n-    public boolean stopConnector(String connName) {\n+    private void stopConnector(String connName) {\n         try (LoggingContext loggingContext = LoggingContext.forConnector(connName)) {\n-            log.info(\"Stopping connector {}\", connName);\n-\n-            WorkerConnector workerConnector = connectors.remove(connName);\n+            WorkerConnector workerConnector = connectors.get(connName);\n             if (workerConnector == null) {\n                 log.warn(\"Ignoring stop request for unowned connector {}\", connName);\n-                return false;\n+                return;\n             }\n \n+            log.info(\"Stopping connector {}\", connName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5ODU2NA==", "bodyText": "Thanks for checking the underlying implementation @C0urante .\nThat takes us to my earlier concern about this operation potentially blocking for too long to be in a synchronized block. And the potential of blocking does not have to do with acknowledging that the record was written only. The producer call has a metadata update call too.\nGoing over the uses of KafkaBasedLog in Connect, I didn't find an example where we have KafkaBasedLog#send running  in mutual exclusion. Contrary, similar concerns are probably the reason why we call OffsetStorageWriter#doFlush outside the synchronized block in WorkerSourceTask.\nI think we might be able to live with a rare race condition as the one you described, in order to avoid introducing unintended side-effects due to locking.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437798564", "createdAt": "2020-06-10T00:44:48Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerConnector.java", "diffHunk": "@@ -266,31 +422,51 @@ public void close() {\n         @Override\n         public void onStartup(String connector) {\n             state = AbstractStatus.State.RUNNING;\n-            delegate.onStartup(connector);\n+            synchronized (this) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw=="}, "originalCommit": null, "originalPosition": 289}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3Nzc2MTAz", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-427776103", "createdAt": "2020-06-10T07:24:11Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwNzoyNDoxMVrOGhoBaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwODowNTozNlrOGhpjkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxMTkxNQ==", "bodyText": "I think I've noticed that you tab size when lines are wrapped is not what we've been using. As you see below, this indentation corresponds to two tabs (8 characters). Only exception I've found that is enforced by checkstyle is when a lambda is wrapped. But other than than we've been using 2 tabs for multiline statements.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437911915", "createdAt": "2020-06-10T07:24:11Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -239,38 +243,59 @@ public void stop() {\n      * @param ctx the connector runtime context.\n      * @param statusListener a listener for the runtime status transitions of the connector.\n      * @param initialState the initial state of the connector.\n-     * @return true if the connector started successfully.\n+     * @param onConnectorStateChange invoked when the initial state change of the connector is completed\n      */\n-    public boolean startConnector(\n+    public void startConnector(\n             String connName,\n             Map<String, String> connProps,\n-            ConnectorContext ctx,\n+            CloseableConnectorContext ctx,\n             ConnectorStatus.Listener statusListener,\n-            TargetState initialState\n+            TargetState initialState,\n+            Callback<TargetState> onConnectorStateChange\n     ) {\n         try (LoggingContext loggingContext = LoggingContext.forConnector(connName)) {\n-            if (connectors.containsKey(connName))\n-                throw new ConnectException(\"Connector with name \" + connName + \" already exists\");\n+            if (connectors.containsKey(connName)) {\n+                onConnectorStateChange.onCompletion(\n+                    new ConnectException(\"Connector with name \" + connName + \" already exists\"),\n+                    null\n+                );\n+                return;\n+            }\n \n             final WorkerConnector workerConnector;\n             ClassLoader savedLoader = plugins.currentThreadLoader();\n             try {\n                 // By the time we arrive here, CONNECTOR_CLASS_CONFIG has been validated already\n                 // Getting this value from the unparsed map will allow us to instantiate the\n                 // right config (source or sink)\n-                final String connClassProp = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n-                log.info(\"Creating connector {} of type {}\", connName, connClassProp);\n-                final Connector connector = plugins.newConnector(connClassProp);\n+                final String connClass = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n+                ClassLoader connectorLoader = plugins.delegatingLoader().connectorLoader(connClass);\n+                savedLoader = Plugins.compareAndSwapLoaders(connectorLoader);\n+\n+                log.info(\"Creating connector {} of type {}\", connName, connClass);\n+                final Connector connector = plugins.newConnector(connClass);\n+                final ConnectorConfig connConfig = ConnectUtils.isSinkConnector(connector)\n+                    ? new SinkConnectorConfig(plugins, connProps)\n+                    : new SourceConnectorConfig(plugins, connProps, config.topicCreationEnable());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxMjkzOA==", "bodyText": "nit: keeping the previous format of grouping arguments in a few lines matches what we have in other versions. This change was brought in when the OffsetStorageReader PR was merged but from the diff you can see that it was changed back.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437912938", "createdAt": "2020-06-10T07:26:05Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -239,38 +243,59 @@ public void stop() {\n      * @param ctx the connector runtime context.\n      * @param statusListener a listener for the runtime status transitions of the connector.\n      * @param initialState the initial state of the connector.\n-     * @return true if the connector started successfully.\n+     * @param onConnectorStateChange invoked when the initial state change of the connector is completed\n      */\n-    public boolean startConnector(\n+    public void startConnector(\n             String connName,\n             Map<String, String> connProps,\n-            ConnectorContext ctx,\n+            CloseableConnectorContext ctx,\n             ConnectorStatus.Listener statusListener,\n-            TargetState initialState\n+            TargetState initialState,\n+            Callback<TargetState> onConnectorStateChange\n     ) {\n         try (LoggingContext loggingContext = LoggingContext.forConnector(connName)) {\n-            if (connectors.containsKey(connName))\n-                throw new ConnectException(\"Connector with name \" + connName + \" already exists\");\n+            if (connectors.containsKey(connName)) {\n+                onConnectorStateChange.onCompletion(\n+                    new ConnectException(\"Connector with name \" + connName + \" already exists\"),\n+                    null\n+                );\n+                return;\n+            }\n \n             final WorkerConnector workerConnector;\n             ClassLoader savedLoader = plugins.currentThreadLoader();\n             try {\n                 // By the time we arrive here, CONNECTOR_CLASS_CONFIG has been validated already\n                 // Getting this value from the unparsed map will allow us to instantiate the\n                 // right config (source or sink)\n-                final String connClassProp = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n-                log.info(\"Creating connector {} of type {}\", connName, connClassProp);\n-                final Connector connector = plugins.newConnector(connClassProp);\n+                final String connClass = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n+                ClassLoader connectorLoader = plugins.delegatingLoader().connectorLoader(connClass);\n+                savedLoader = Plugins.compareAndSwapLoaders(connectorLoader);\n+\n+                log.info(\"Creating connector {} of type {}\", connName, connClass);\n+                final Connector connector = plugins.newConnector(connClass);\n+                final ConnectorConfig connConfig = ConnectUtils.isSinkConnector(connector)\n+                    ? new SinkConnectorConfig(plugins, connProps)\n+                    : new SourceConnectorConfig(plugins, connProps, config.topicCreationEnable());\n+\n                 final OffsetStorageReader offsetReader = new OffsetStorageReaderImpl(\n-                        offsetBackingStore, connName, internalKeyConverter, internalValueConverter);\n-                workerConnector = new WorkerConnector(connName, connector, ctx, metrics, statusListener, offsetReader);\n-                final ConnectorConfig connConfig = workerConnector.isSinkConnector()\n-                        ? new SinkConnectorConfig(plugins, connProps)\n-                        : new SourceConnectorConfig(plugins, connProps, config.topicCreationEnable());\n+                    offsetBackingStore,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyMDYzNg==", "bodyText": "if you endup locking the whole method, there's no reason to use a block, you can use synchronized on the method. Applies here and any similar method.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437920636", "createdAt": "2020-06-10T07:39:02Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerConnector.java", "diffHunk": "@@ -165,27 +241,115 @@ private void pause() {\n         }\n     }\n \n+    /**\n+     * Stop this connector. This method does not block, it only triggers shutdown. Use\n+     * #{@link #awaitShutdown} to block until completion.\n+     */\n     public void shutdown() {\n+        synchronized (this) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyNTI1Mw==", "bodyText": "I wonder if we should create a jira issue instead", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437925253", "createdAt": "2020-06-10T07:45:10Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -337,6 +340,12 @@ public void tick() {\n         }\n \n         // Process any external requests\n+        // TODO: Some of these can be performed concurrently or even optimized away entirely.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyNjAzNQ==", "bodyText": "nit: our style allows the first line to be with the log statement (see your other trace call below)", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437926035", "createdAt": "2020-06-10T07:46:32Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -414,31 +423,44 @@ public void tick() {\n \n         // Let the group take any actions it needs to\n         try {\n+            log.trace(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyODE1OA==", "bodyText": "do we know how often this message or the one below would be printed?", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437928158", "createdAt": "2020-06-10T07:50:06Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -486,6 +509,10 @@ private synchronized boolean updateConfigsWithEager(AtomicReference<Set<String>>\n                     connectorTargetStateChanges = new HashSet<>();\n                 }\n             }\n+        } else {\n+            log.trace(\"Skipping config updates with eager rebalancing \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyOTg5MQ==", "bodyText": "nit; multiline splitting is a bit unusual", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437929891", "createdAt": "2020-06-10T07:53:02Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -540,20 +572,45 @@ private void processConnectorConfigUpdates(Set<String> connectorConfigUpdates) {\n         // If we only have connector config updates, we can just bounce the updated connectors that are\n         // currently assigned to this worker.\n         Set<String> localConnectors = assignment == null ? Collections.<String>emptySet() : new HashSet<>(assignment.connectors());\n+        log.trace(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzMDcwNA==", "bodyText": "probably the style followed in worker.setTargetState is preferable", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437930704", "createdAt": "2020-06-10T07:54:29Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -540,20 +572,45 @@ private void processConnectorConfigUpdates(Set<String> connectorConfigUpdates) {\n         // If we only have connector config updates, we can just bounce the updated connectors that are\n         // currently assigned to this worker.\n         Set<String> localConnectors = assignment == null ? Collections.<String>emptySet() : new HashSet<>(assignment.connectors());\n+        log.trace(\n+            \"Processing connector config updates; \"\n+                + \"currently-owned connectors are {}, and to-be-updated connectors are {}\",\n+            localConnectors,\n+            connectorConfigUpdates\n+        );\n         for (String connectorName : connectorConfigUpdates) {\n-            if (!localConnectors.contains(connectorName))\n+            if (!localConnectors.contains(connectorName)) {\n+                log.trace(\n+                    \"Skipping config update for connector {} as it is not owned by this worker\",\n+                    connectorName\n+                );\n                 continue;\n+            }\n             boolean remains = configState.contains(connectorName);\n             log.info(\"Handling connector-only config update by {} connector {}\",\n                     remains ? \"restarting\" : \"stopping\", connectorName);\n-            worker.stopConnector(connectorName);\n+            worker.stopAndAwaitConnector(connectorName);\n             // The update may be a deletion, so verify we actually need to restart the connector\n-            if (remains)\n-                startConnector(connectorName);\n+            if (remains) {\n+                startConnector(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzNzA0MA==", "bodyText": "this can also be written in a less verbose way (see also comment above)", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437937040", "createdAt": "2020-06-10T08:05:36Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -1221,31 +1297,56 @@ public Void call() throws Exception {\n \n     // Helper for starting a connector with the given name, which will extract & parse the config, generate connector\n     // context and add to the worker. This needs to be called from within the main worker thread for this herder.\n-    private boolean startConnector(String connectorName) {\n+    // The callback is invoked after the connector has finished startup and generated task configs, or failed in the process.\n+    private void startConnector(String connectorName, Callback<Void> callback) {\n         log.info(\"Starting connector {}\", connectorName);\n         final Map<String, String> configProps = configState.connectorConfig(connectorName);\n-        final ConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n+        final CloseableConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n         final TargetState initialState = configState.targetState(connectorName);\n-        boolean started = worker.startConnector(connectorName, configProps, ctx, this, initialState);\n-\n-        // Immediately request configuration since this could be a brand new connector. However, also only update those\n-        // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n-        // just restoring an existing connector.\n-        if (started && initialState == TargetState.STARTED)\n-            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+        final Callback<TargetState> onInitialStateChange = (error, newState) -> {\n+            if (error != null) {\n+                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connectorName), null);\n+                return;\n+            }\n \n-        return started;\n+            // Use newState here in case the connector has been paused right after being created\n+            if (newState == TargetState.STARTED) {\n+                addRequest(\n+                    new Callable<Void>() {\n+                        @Override\n+                        public Void call() {\n+                            // Request configuration since this could be a brand new connector. However, also only update those\n+                            // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n+                            // just restoring an existing connector.\n+                            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+                            callback.onCompletion(null, null);\n+                            return null;\n+                        }\n+                    },\n+                    forwardErrorCallback(callback)\n+                );\n+            } else {\n+                callback.onCompletion(null, null);\n+            }\n+        };\n+        worker.startConnector(connectorName, configProps, ctx, this, initialState, onInitialStateChange);\n     }\n \n     private Callable<Void> getConnectorStartingCallable(final String connectorName) {\n         return new Callable<Void>() {\n             @Override\n             public Void call() throws Exception {\n                 try {\n-                    startConnector(connectorName);\n+                    startConnector(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 460}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Mjk5NzA3", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-428299707", "createdAt": "2020-06-10T17:57:26Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo1NzoyNlrOGiASxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTozMDoyNlrOGiDWZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwOTU3Mw==", "bodyText": "this seems to refer to member.wakeup. Best to follow that method.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438309573", "createdAt": "2020-06-10T17:57:26Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/DistributedHerderTest.java", "diffHunk": "@@ -240,11 +243,19 @@ public void testJoinAssignment() throws Exception {\n         EasyMock.expect(worker.getPlugins()).andReturn(plugins);\n         expectRebalance(1, Arrays.asList(CONN1), Arrays.asList(TASK1));\n         expectPostRebalanceCatchup(SNAPSHOT);\n-        worker.startConnector(EasyMock.eq(CONN1), EasyMock.<Map<String, String>>anyObject(), EasyMock.<ConnectorContext>anyObject(),\n-                EasyMock.eq(herder), EasyMock.eq(TargetState.STARTED));\n-        PowerMock.expectLastCall().andReturn(true);\n+        Capture<Callback<TargetState>> onStart = newCapture();\n+        worker.startConnector(EasyMock.eq(CONN1), EasyMock.<Map<String, String>>anyObject(), EasyMock.<CloseableConnectorContext>anyObject(),\n+                EasyMock.eq(herder), EasyMock.eq(TargetState.STARTED), capture(onStart));\n+        PowerMock.expectLastCall().andAnswer(new IAnswer<Boolean>() {\n+            @Override\n+            public Boolean answer() throws Throwable {\n+                onStart.getValue().onCompletion(null, TargetState.STARTED);\n+                return true;\n+            }\n+        });\n+        member.wakeup();\n         EasyMock.expect(worker.isRunning(CONN1)).andReturn(true);\n-\n+        PowerMock.expectLastCall();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxOTM3NQ==", "bodyText": "This call is missing an expectLastCall. Here an in a couple other places.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438319375", "createdAt": "2020-06-10T18:14:30Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/DistributedHerderTest.java", "diffHunk": "@@ -269,9 +280,17 @@ public void testRebalance() throws Exception {\n         EasyMock.expect(worker.getPlugins()).andReturn(plugins);\n         expectRebalance(1, Arrays.asList(CONN1), Arrays.asList(TASK1));\n         expectPostRebalanceCatchup(SNAPSHOT);\n-        worker.startConnector(EasyMock.eq(CONN1), EasyMock.<Map<String, String>>anyObject(), EasyMock.<ConnectorContext>anyObject(),\n-                EasyMock.eq(herder), EasyMock.eq(TargetState.STARTED));\n-        PowerMock.expectLastCall().andReturn(true);\n+        Capture<Callback<TargetState>> onFirstStart = newCapture();\n+        worker.startConnector(EasyMock.eq(CONN1), EasyMock.<Map<String, String>>anyObject(), EasyMock.<CloseableConnectorContext>anyObject(),\n+                EasyMock.eq(herder), EasyMock.eq(TargetState.STARTED), capture(onFirstStart));\n+        PowerMock.expectLastCall().andAnswer(new IAnswer<Boolean>() {\n+            @Override\n+            public Boolean answer() throws Throwable {\n+                onFirstStart.getValue().onCompletion(null, TargetState.STARTED);\n+                return true;\n+            }\n+        });\n+        member.wakeup();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMzMzk5NQ==", "bodyText": "don't we need to verify the expectations ?", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438333995", "createdAt": "2020-06-10T18:41:05Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/DistributedHerderTest.java", "diffHunk": "@@ -582,86 +658,41 @@ public void testCreateConnectorFailedBasicValidation() throws Exception {\n         member.wakeup();\n         PowerMock.expectLastCall();\n \n-        // config validation\n-        Connector connectorMock = PowerMock.createMock(SourceConnector.class);\n-        EasyMock.expect(worker.configTransformer()).andReturn(transformer).times(2);\n-        final Capture<Map<String, String>> configCapture = newCapture();\n-        EasyMock.expect(transformer.transform(EasyMock.capture(configCapture))).andAnswer(configCapture::getValue);\n-        EasyMock.expect(worker.getPlugins()).andReturn(plugins).times(3);\n-        EasyMock.expect(plugins.compareAndSwapLoaders(connectorMock)).andReturn(delegatingLoader);\n-        EasyMock.expect(plugins.newConnector(EasyMock.anyString())).andReturn(connectorMock);\n-\n-        EasyMock.expect(connectorMock.config()).andStubReturn(new ConfigDef());\n-        ConfigValue validatedValue = new ConfigValue(\"foo.bar\");\n-        EasyMock.expect(connectorMock.validate(config)).andReturn(new Config(singletonList(validatedValue)));\n-\n-        EasyMock.expect(Plugins.compareAndSwapLoaders(delegatingLoader)).andReturn(pluginLoader);\n-\n-        // CONN2 creation should fail\n+        // mock the actual validation since its asynchronous nature is difficult to test and should\n+        // be covered sufficiently by the unit tests for the AbstractHerder class\n+        Capture<Callback<ConfigInfos>> validateCallback = newCapture();\n+        herder.validateConnectorConfig(EasyMock.eq(config), capture(validateCallback));\n+        PowerMock.expectLastCall().andAnswer(new IAnswer<Void>() {\n+            @Override\n+            public Void answer() throws Throwable {\n+                // CONN2 creation should fail\n+                validateCallback.getValue().onCompletion(null, CONN2_INVALID_CONFIG_INFOS);\n+                return null;\n+            }\n+        });\n \n         Capture<Throwable> error = newCapture();\n-        putConnectorCallback.onCompletion(EasyMock.capture(error), EasyMock.<Herder.Created<ConnectorInfo>>isNull());\n+        putConnectorCallback.onCompletion(capture(error), EasyMock.<Herder.Created<ConnectorInfo>>isNull());\n         PowerMock.expectLastCall();\n \n         member.poll(EasyMock.anyInt());\n         PowerMock.expectLastCall();\n-        // No immediate action besides this -- change will be picked up via the config log\n-\n-        PowerMock.replayAll();\n-\n-        herder.putConnectorConfig(CONN2, config, false, putConnectorCallback);\n-        herder.tick();\n-\n-        assertTrue(error.hasCaptured());\n-        assertTrue(error.getValue() instanceof BadRequestException);\n-\n-        time.sleep(1000L);\n-        assertStatistics(3, 1, 100, 1000L);\n-\n-        PowerMock.verifyAll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 367}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMzNDcwMw==", "bodyText": "same question. Not sure if there are not mocks used here.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438334703", "createdAt": "2020-06-10T18:42:31Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/DistributedHerderTest.java", "diffHunk": "@@ -676,63 +707,38 @@ public void testCreateConnectorFailedCustomValidation() throws Exception {\n     @SuppressWarnings(\"unchecked\")\n     @Test\n     public void testConnectorNameConflictsWithWorkerGroupId() throws Exception {\n-        EasyMock.expect(member.memberId()).andStubReturn(\"leader\");\n-        EasyMock.expect(member.currentProtocolVersion()).andStubReturn(CONNECT_PROTOCOL_V0);\n-        expectRebalance(1, Collections.<String>emptyList(), Collections.<ConnectorTaskId>emptyList());\n-        expectPostRebalanceCatchup(SNAPSHOT);\n-\n-        member.wakeup();\n-        PowerMock.expectLastCall();\n-\n         Map<String, String> config = new HashMap<>(CONN2_CONFIG);\n         config.put(ConnectorConfig.NAME_CONFIG, \"test-group\");\n \n-        // config validation\n         Connector connectorMock = PowerMock.createMock(SinkConnector.class);\n-        EasyMock.expect(worker.configTransformer()).andReturn(transformer).times(2);\n-        final Capture<Map<String, String>> configCapture = newCapture();\n-        EasyMock.expect(transformer.transform(EasyMock.capture(configCapture))).andAnswer(configCapture::getValue);\n-        EasyMock.expect(worker.getPlugins()).andReturn(plugins).times(3);\n-        EasyMock.expect(plugins.compareAndSwapLoaders(connectorMock)).andReturn(delegatingLoader);\n-        EasyMock.expect(plugins.newConnector(EasyMock.anyString())).andReturn(connectorMock);\n-        EasyMock.expect(connectorMock.config()).andReturn(new ConfigDef());\n-        EasyMock.expect(connectorMock.validate(config)).andReturn(new Config(Collections.<ConfigValue>emptyList()));\n-        EasyMock.expect(Plugins.compareAndSwapLoaders(delegatingLoader)).andReturn(pluginLoader);\n \n         // CONN2 creation should fail because the worker group id (connect-test-group) conflicts with\n         // the consumer group id we would use for this sink\n+        Map<String, ConfigValue> validatedConfigs =\n+            herder.validateBasicConnectorConfig(connectorMock, ConnectorConfig.configDef(), config);\n \n-        Capture<Throwable> error = newCapture();\n-        putConnectorCallback.onCompletion(EasyMock.capture(error), EasyMock.isNull(Herder.Created.class));\n-        PowerMock.expectLastCall();\n-\n-        member.poll(EasyMock.anyInt());\n-        PowerMock.expectLastCall();\n-        // No immediate action besides this -- change will be picked up via the config log\n-\n-        PowerMock.replayAll();\n-\n-        herder.putConnectorConfig(CONN2, config, false, putConnectorCallback);\n-        herder.tick();\n-\n-        assertTrue(error.hasCaptured());\n-        assertTrue(error.getValue() instanceof BadRequestException);\n-\n-        time.sleep(1000L);\n-        assertStatistics(3, 1, 100, 1000L);\n-\n-        PowerMock.verifyAll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 470}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1ODcxOA==", "bodyText": "I think it's not great to introduce tests that will be ignored by default. As we wouldn't add unused code, maybe we want to skip adding these test cases for now.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438358718", "createdAt": "2020-06-10T19:28:33Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/BlockingConnectorTest.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.integration;\n+\n+import org.apache.kafka.common.config.AbstractConfig;\n+import org.apache.kafka.common.config.Config;\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.connector.Task;\n+import org.apache.kafka.connect.runtime.Worker;\n+import org.apache.kafka.connect.runtime.rest.errors.ConnectRestException;\n+import org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource;\n+import org.apache.kafka.connect.source.SourceConnector;\n+import org.apache.kafka.connect.source.SourceRecord;\n+import org.apache.kafka.connect.source.SourceTask;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.CONNECTOR_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TASKS_MAX_CONFIG;\n+import static org.apache.kafka.connect.runtime.SinkConnectorConfig.TOPICS_CONFIG;\n+import static org.junit.Assert.assertThrows;\n+\n+public class BlockingConnectorTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(BlockingConnectorTest.class);\n+\n+    private static final int NUM_WORKERS = 1;\n+    private static final String BLOCKING_CONNECTOR_NAME = \"blocking-connector\";\n+    private static final String NORMAL_CONNECTOR_NAME = \"normal-connector\";\n+    private static final long REST_REQUEST_TIMEOUT = Worker.CONNECTOR_GRACEFUL_SHUTDOWN_TIMEOUT_MS * 2;\n+\n+    private EmbeddedConnectCluster connect;\n+\n+    @Before\n+    public void setup() {\n+        // Artificially reduce the REST request timeout so that these don't take forever\n+        ConnectorsResource.setRequestTimeout(REST_REQUEST_TIMEOUT);\n+        // build a Connect cluster backed by Kafka and Zk\n+        connect = new EmbeddedConnectCluster.Builder()\n+                .name(\"connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .workerProps(new HashMap<>())\n+                .brokerProps(new Properties())\n+                .build();\n+\n+        // start the clusters\n+        connect.start();\n+    }\n+\n+    @After\n+    public void close() {\n+        // stop all Connect, Kafka and Zk threads.\n+        connect.stop();\n+        ConnectorsResource.resetRequestTimeout();\n+        BlockingConnector.resetBlockLatch();\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorValidate() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorValidate\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ValidateBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorConfig() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorConfig\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ConfigBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorInitialize() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorInitialize\");\n+        createConnectorWithBlock(InitializeBlockingConnector.class);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStart\");\n+        createConnectorWithBlock(BlockingConnector.START);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStop\");\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.deleteConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStart\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.START);\n+        // First instance of the connector should block on startup\n+        BlockingConnector.waitForBlock();\n+        connect.removeWorker();\n+\n+        connect.addWorker();\n+        // After stopping the only worker and restarting it, a new instance of the blocking\n+        // connector should be created and we can ensure that it blocks again\n+        BlockingConnector.waitForBlock();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStop\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.removeWorker();\n+        BlockingConnector.waitForBlock();\n+\n+        connect.addWorker();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1OTEzMQ==", "bodyText": "Should we create source connectors that actually produce data? Doesn't seem to be any flow of records to this connector.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438359131", "createdAt": "2020-06-10T19:29:23Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/BlockingConnectorTest.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.integration;\n+\n+import org.apache.kafka.common.config.AbstractConfig;\n+import org.apache.kafka.common.config.Config;\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.connector.Task;\n+import org.apache.kafka.connect.runtime.Worker;\n+import org.apache.kafka.connect.runtime.rest.errors.ConnectRestException;\n+import org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource;\n+import org.apache.kafka.connect.source.SourceConnector;\n+import org.apache.kafka.connect.source.SourceRecord;\n+import org.apache.kafka.connect.source.SourceTask;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.CONNECTOR_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TASKS_MAX_CONFIG;\n+import static org.apache.kafka.connect.runtime.SinkConnectorConfig.TOPICS_CONFIG;\n+import static org.junit.Assert.assertThrows;\n+\n+public class BlockingConnectorTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(BlockingConnectorTest.class);\n+\n+    private static final int NUM_WORKERS = 1;\n+    private static final String BLOCKING_CONNECTOR_NAME = \"blocking-connector\";\n+    private static final String NORMAL_CONNECTOR_NAME = \"normal-connector\";\n+    private static final long REST_REQUEST_TIMEOUT = Worker.CONNECTOR_GRACEFUL_SHUTDOWN_TIMEOUT_MS * 2;\n+\n+    private EmbeddedConnectCluster connect;\n+\n+    @Before\n+    public void setup() {\n+        // Artificially reduce the REST request timeout so that these don't take forever\n+        ConnectorsResource.setRequestTimeout(REST_REQUEST_TIMEOUT);\n+        // build a Connect cluster backed by Kafka and Zk\n+        connect = new EmbeddedConnectCluster.Builder()\n+                .name(\"connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .workerProps(new HashMap<>())\n+                .brokerProps(new Properties())\n+                .build();\n+\n+        // start the clusters\n+        connect.start();\n+    }\n+\n+    @After\n+    public void close() {\n+        // stop all Connect, Kafka and Zk threads.\n+        connect.stop();\n+        ConnectorsResource.resetRequestTimeout();\n+        BlockingConnector.resetBlockLatch();\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorValidate() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorValidate\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ValidateBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorConfig() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorConfig\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ConfigBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorInitialize() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorInitialize\");\n+        createConnectorWithBlock(InitializeBlockingConnector.class);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStart\");\n+        createConnectorWithBlock(BlockingConnector.START);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStop\");\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.deleteConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStart\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.START);\n+        // First instance of the connector should block on startup\n+        BlockingConnector.waitForBlock();\n+        connect.removeWorker();\n+\n+        connect.addWorker();\n+        // After stopping the only worker and restarting it, a new instance of the blocking\n+        // connector should be created and we can ensure that it blocks again\n+        BlockingConnector.waitForBlock();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStop\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.removeWorker();\n+        BlockingConnector.waitForBlock();\n+\n+        connect.addWorker();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testBlockInConnectorTaskClass() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CLASS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testBlockInConnectorTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CONFIGS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testConnectorRestartWithBlockInConnectorTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CONFIGS);\n+        // Test both explicit restart and implicit (pause then resume) restart\n+        connect.restartConnector(BLOCKING_CONNECTOR_NAME);\n+        connect.pauseConnector(BLOCKING_CONNECTOR_NAME);\n+        connect.resumeConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    // TODO: Consider patching plugin scanning to handle connectors that block in their version methods\n+    // @Test\n+    // public void testBlockInConnectorVersion() throws Exception {\n+    //     createConnectorWithBlock(VersionBlockingConnector.class);\n+    //     createNormalConnector();\n+    //     waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    // }\n+\n+    @Test\n+    @Ignore(\"This connector method is never invoked by the framework\")\n+    public void testBlockInConnectorInitializeWithTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.INITIALIZE_WITH_TASK_CONFIGS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"This connector method is never invoked by the framework\")\n+    public void testBlockInConnectorReconfigure() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.RECONFIGURE);\n+        Map<String, String> newProps = baseBlockingConnectorProps();\n+        newProps.put(\"foo\", \"bar\");\n+\n+        connect.configureConnector(BLOCKING_CONNECTOR_NAME, newProps);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    private void createConnectorWithBlock(String block) {\n+        Map<String, String> props = baseBlockingConnectorProps();\n+        props.put(BlockingConnector.BLOCK_CONFIG, block);\n+        log.info(\"Creating connector with block during {}\", block);\n+        try {\n+            connect.configureConnector(BLOCKING_CONNECTOR_NAME, props);\n+        } catch (RuntimeException e) {\n+            log.info(\"Failed to create connector\", e);\n+            throw e;\n+        }\n+    }\n+\n+    private void createConnectorWithBlock(Class<? extends BlockingConnector> connectorClass) {\n+        Map<String, String> props = baseBlockingConnectorProps();\n+        props.put(CONNECTOR_CLASS_CONFIG, connectorClass.getName());\n+        log.info(\"Creating blocking connector of type {}\", connectorClass.getSimpleName());\n+        try {\n+            connect.configureConnector(BLOCKING_CONNECTOR_NAME, props);\n+        } catch (RuntimeException e) {\n+            log.info(\"Failed to create connector\", e);\n+            throw e;\n+        }\n+    }\n+\n+    private Map<String, String> baseBlockingConnectorProps() {\n+        Map<String, String> result = new HashMap<>();\n+        result.put(CONNECTOR_CLASS_CONFIG, BlockingConnector.class.getName());\n+        result.put(TASKS_MAX_CONFIG, \"1\");\n+        return result;\n+    }\n+\n+    private void createNormalConnector() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSinkConnector.class.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 276}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1OTY1NA==", "bodyText": "Code might not be the best way to document this, and it might get stale with time.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438359654", "createdAt": "2020-06-10T19:30:26Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/BlockingConnectorTest.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.integration;\n+\n+import org.apache.kafka.common.config.AbstractConfig;\n+import org.apache.kafka.common.config.Config;\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.connector.Task;\n+import org.apache.kafka.connect.runtime.Worker;\n+import org.apache.kafka.connect.runtime.rest.errors.ConnectRestException;\n+import org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource;\n+import org.apache.kafka.connect.source.SourceConnector;\n+import org.apache.kafka.connect.source.SourceRecord;\n+import org.apache.kafka.connect.source.SourceTask;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.CONNECTOR_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TASKS_MAX_CONFIG;\n+import static org.apache.kafka.connect.runtime.SinkConnectorConfig.TOPICS_CONFIG;\n+import static org.junit.Assert.assertThrows;\n+\n+public class BlockingConnectorTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(BlockingConnectorTest.class);\n+\n+    private static final int NUM_WORKERS = 1;\n+    private static final String BLOCKING_CONNECTOR_NAME = \"blocking-connector\";\n+    private static final String NORMAL_CONNECTOR_NAME = \"normal-connector\";\n+    private static final long REST_REQUEST_TIMEOUT = Worker.CONNECTOR_GRACEFUL_SHUTDOWN_TIMEOUT_MS * 2;\n+\n+    private EmbeddedConnectCluster connect;\n+\n+    @Before\n+    public void setup() {\n+        // Artificially reduce the REST request timeout so that these don't take forever\n+        ConnectorsResource.setRequestTimeout(REST_REQUEST_TIMEOUT);\n+        // build a Connect cluster backed by Kafka and Zk\n+        connect = new EmbeddedConnectCluster.Builder()\n+                .name(\"connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .workerProps(new HashMap<>())\n+                .brokerProps(new Properties())\n+                .build();\n+\n+        // start the clusters\n+        connect.start();\n+    }\n+\n+    @After\n+    public void close() {\n+        // stop all Connect, Kafka and Zk threads.\n+        connect.stop();\n+        ConnectorsResource.resetRequestTimeout();\n+        BlockingConnector.resetBlockLatch();\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorValidate() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorValidate\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ValidateBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorConfig() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorConfig\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ConfigBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorInitialize() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorInitialize\");\n+        createConnectorWithBlock(InitializeBlockingConnector.class);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStart\");\n+        createConnectorWithBlock(BlockingConnector.START);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStop\");\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.deleteConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStart\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.START);\n+        // First instance of the connector should block on startup\n+        BlockingConnector.waitForBlock();\n+        connect.removeWorker();\n+\n+        connect.addWorker();\n+        // After stopping the only worker and restarting it, a new instance of the blocking\n+        // connector should be created and we can ensure that it blocks again\n+        BlockingConnector.waitForBlock();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStop\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.removeWorker();\n+        BlockingConnector.waitForBlock();\n+\n+        connect.addWorker();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testBlockInConnectorTaskClass() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CLASS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testBlockInConnectorTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CONFIGS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testConnectorRestartWithBlockInConnectorTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CONFIGS);\n+        // Test both explicit restart and implicit (pause then resume) restart\n+        connect.restartConnector(BLOCKING_CONNECTOR_NAME);\n+        connect.pauseConnector(BLOCKING_CONNECTOR_NAME);\n+        connect.resumeConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    // TODO: Consider patching plugin scanning to handle connectors that block in their version methods", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 211}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NDUzODE5", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-428453819", "createdAt": "2020-06-10T21:51:12Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMTo1MToxMlrOGiHixg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMjo0ODozN1rOGiIzZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQyODM1OA==", "bodyText": "nit: leftover?", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438428358", "createdAt": "2020-06-10T21:51:12Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -191,32 +189,59 @@ public synchronized void putConnectorConfig(String connName,\n                                                 boolean allowReplace,\n                                                 final Callback<Created<ConnectorInfo>> callback) {\n         try {\n-            if (maybeAddConfigErrors(validateConnectorConfig(config), callback)) {\n+            validateConnectorConfig(config, (error, configInfos) -> {\n+                if (error != null) {\n+                    callback.onCompletion(error, null);\n+                    return;\n+                }\n+\n+                requestExecutorService.submit(\n+                    () -> putConnectorConfig(connName, config, allowReplace, callback, configInfos)\n+                );\n+            });\n+        } catch (Throwable t) {\n+            callback.onCompletion(t, null);\n+        }\n+    }\n+\n+    private synchronized void putConnectorConfig(String connName,\n+                                                 final Map<String, String> config,\n+                                                 boolean allowReplace,\n+                                                 final Callback<Created<ConnectorInfo>> callback,\n+                                                 ConfigInfos configInfos) {\n+        try {\n+            if (maybeAddConfigErrors(configInfos, callback)) {\n                 return;\n             }\n \n-            boolean created = false;\n+            final boolean created;\n             if (configState.contains(connName)) {\n                 if (!allowReplace) {\n                     callback.onCompletion(new AlreadyExistsException(\"Connector \" + connName + \" already exists\"), null);\n                     return;\n                 }\n-                worker.stopConnector(connName);\n+                worker.stopAndAwaitConnector(connName);\n+                created = false;\n             } else {\n                 created = true;\n             }\n \n             configBackingStore.putConnectorConfig(connName, config);\n \n-            if (!startConnector(connName)) {\n-                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connName), null);\n-                return;\n-            }\n+            // startConnector(connName, onStart);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ0ODk5Nw==", "bodyText": "I'm referring to how the lambda was written there as the second argument. I'd be nice to keep a consistent style at least in the changes included in a single commit.", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438448997", "createdAt": "2020-06-10T22:48:37Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -1221,31 +1297,56 @@ public Void call() throws Exception {\n \n     // Helper for starting a connector with the given name, which will extract & parse the config, generate connector\n     // context and add to the worker. This needs to be called from within the main worker thread for this herder.\n-    private boolean startConnector(String connectorName) {\n+    // The callback is invoked after the connector has finished startup and generated task configs, or failed in the process.\n+    private void startConnector(String connectorName, Callback<Void> callback) {\n         log.info(\"Starting connector {}\", connectorName);\n         final Map<String, String> configProps = configState.connectorConfig(connectorName);\n-        final ConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n+        final CloseableConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n         final TargetState initialState = configState.targetState(connectorName);\n-        boolean started = worker.startConnector(connectorName, configProps, ctx, this, initialState);\n-\n-        // Immediately request configuration since this could be a brand new connector. However, also only update those\n-        // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n-        // just restoring an existing connector.\n-        if (started && initialState == TargetState.STARTED)\n-            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+        final Callback<TargetState> onInitialStateChange = (error, newState) -> {\n+            if (error != null) {\n+                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connectorName), null);\n+                return;\n+            }\n \n-        return started;\n+            // Use newState here in case the connector has been paused right after being created\n+            if (newState == TargetState.STARTED) {\n+                addRequest(\n+                    new Callable<Void>() {\n+                        @Override\n+                        public Void call() {\n+                            // Request configuration since this could be a brand new connector. However, also only update those\n+                            // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n+                            // just restoring an existing connector.\n+                            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+                            callback.onCompletion(null, null);\n+                            return null;\n+                        }\n+                    },\n+                    forwardErrorCallback(callback)\n+                );\n+            } else {\n+                callback.onCompletion(null, null);\n+            }\n+        };\n+        worker.startConnector(connectorName, configProps, ctx, this, initialState, onInitialStateChange);\n     }\n \n     private Callable<Void> getConnectorStartingCallable(final String connectorName) {\n         return new Callable<Void>() {\n             @Override\n             public Void call() throws Exception {\n                 try {\n-                    startConnector(connectorName);\n+                    startConnector(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzNzA0MA=="}, "originalCommit": null, "originalPosition": 460}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NTAxNDY0", "url": "https://github.com/apache/kafka/pull/8069#pullrequestreview-428501464", "createdAt": "2020-06-10T23:46:40Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMzo0Njo0MFrOGiJ4Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMzo0Njo0MFrOGiJ4Hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2NjU5MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                startConnector(\n          \n          \n            \n                                        connectorName,\n          \n          \n            \n                                        (error, result) -> {\n          \n          \n            \n                                            if (error != null) {\n          \n          \n            \n                                                log.error(\"Failed to start connector '\" + connectorName + \"'\", error);\n          \n          \n            \n                                            }\n          \n          \n            \n                                        }\n          \n          \n            \n                                );\n          \n          \n            \n                                startConnector(connectorName, (error, result) -> {\n          \n          \n            \n                                    if (error != null) {\n          \n          \n            \n                                        log.error(\"Failed to start connector '\" + connectorName + \"'\", error);\n          \n          \n            \n                                    }\n          \n          \n            \n                                });", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438466591", "createdAt": "2020-06-10T23:46:40Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -1221,31 +1284,56 @@ public Void call() throws Exception {\n \n     // Helper for starting a connector with the given name, which will extract & parse the config, generate connector\n     // context and add to the worker. This needs to be called from within the main worker thread for this herder.\n-    private boolean startConnector(String connectorName) {\n+    // The callback is invoked after the connector has finished startup and generated task configs, or failed in the process.\n+    private void startConnector(String connectorName, Callback<Void> callback) {\n         log.info(\"Starting connector {}\", connectorName);\n         final Map<String, String> configProps = configState.connectorConfig(connectorName);\n-        final ConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n+        final CloseableConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n         final TargetState initialState = configState.targetState(connectorName);\n-        boolean started = worker.startConnector(connectorName, configProps, ctx, this, initialState);\n-\n-        // Immediately request configuration since this could be a brand new connector. However, also only update those\n-        // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n-        // just restoring an existing connector.\n-        if (started && initialState == TargetState.STARTED)\n-            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+        final Callback<TargetState> onInitialStateChange = (error, newState) -> {\n+            if (error != null) {\n+                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connectorName), null);\n+                return;\n+            }\n \n-        return started;\n+            // Use newState here in case the connector has been paused right after being created\n+            if (newState == TargetState.STARTED) {\n+                addRequest(\n+                        new Callable<Void>() {\n+                            @Override\n+                            public Void call() {\n+                                // Request configuration since this could be a brand new connector. However, also only update those\n+                                // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n+                                // just restoring an existing connector.\n+                                reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+                                callback.onCompletion(null, null);\n+                                return null;\n+                            }\n+                        },\n+                        forwardErrorCallback(callback)\n+                );\n+            } else {\n+                callback.onCompletion(null, null);\n+            }\n+        };\n+        worker.startConnector(connectorName, configProps, ctx, this, initialState, onInitialStateChange);\n     }\n \n     private Callable<Void> getConnectorStartingCallable(final String connectorName) {\n         return new Callable<Void>() {\n             @Override\n             public Void call() throws Exception {\n                 try {\n-                    startConnector(connectorName);\n+                    startConnector(\n+                            connectorName,\n+                            (error, result) -> {\n+                                if (error != null) {\n+                                    log.error(\"Failed to start connector '\" + connectorName + \"'\", error);\n+                                }\n+                            }\n+                    );", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 454}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ba080d7624e9cedadbf4279fff89c041d2ca811d", "author": {"user": {"login": "C0urante", "name": "Chris Egerton"}}, "url": "https://github.com/apache/kafka/commit/ba080d7624e9cedadbf4279fff89c041d2ca811d", "committedDate": "2020-06-11T03:51:31Z", "message": "KAFKA-9374: Make connector interactions asynchronous\n\nThese changes allow herders to continue to function even when a connector they\nare running hangs in its start, stop, initialize, validate, and/or config\nmethods."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "491cd4036c611ab657a06cf134b78d67c6b6d6d2", "author": {"user": {"login": "C0urante", "name": "Chris Egerton"}}, "url": "https://github.com/apache/kafka/commit/491cd4036c611ab657a06cf134b78d67c6b6d6d2", "committedDate": "2020-06-11T03:51:32Z", "message": "KAFKA-9374: Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "48e501adc02a685d9ae35a30ad013784f4c4f1f1", "author": {"user": {"login": "C0urante", "name": "Chris Egerton"}}, "url": "https://github.com/apache/kafka/commit/48e501adc02a685d9ae35a30ad013784f4c4f1f1", "committedDate": "2020-06-11T03:51:33Z", "message": "KAFKA-9374: Address review comments on tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "55acd7c4166004c140429b95d05401511ee52a55", "author": {"user": {"login": "C0urante", "name": "Chris Egerton"}}, "url": "https://github.com/apache/kafka/commit/55acd7c4166004c140429b95d05401511ee52a55", "committedDate": "2020-06-11T03:51:33Z", "message": "KAFKA-9374: Remove commented-out code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "045a5f72f78840bb59a1393af5cd8cd6c7c1a02f", "author": {"user": {"login": "C0urante", "name": "Chris Egerton"}}, "url": "https://github.com/apache/kafka/commit/045a5f72f78840bb59a1393af5cd8cd6c7c1a02f", "committedDate": "2020-06-11T03:51:33Z", "message": "KAFKA-9374: Style improvement"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3adcc1f0551255f20174ca8a107f0fdb3d5401cf", "author": {"user": {"login": "C0urante", "name": "Chris Egerton"}}, "url": "https://github.com/apache/kafka/commit/3adcc1f0551255f20174ca8a107f0fdb3d5401cf", "committedDate": "2020-06-11T03:51:34Z", "message": "KAFKA-9374: Further style improvements"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "3adcc1f0551255f20174ca8a107f0fdb3d5401cf", "author": {"user": {"login": "C0urante", "name": "Chris Egerton"}}, "url": "https://github.com/apache/kafka/commit/3adcc1f0551255f20174ca8a107f0fdb3d5401cf", "committedDate": "2020-06-11T03:51:34Z", "message": "KAFKA-9374: Further style improvements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bfb1bc04832b342e614e891d6da5af1f8ebe30a5", "author": {"user": {"login": "C0urante", "name": "Chris Egerton"}}, "url": "https://github.com/apache/kafka/commit/bfb1bc04832b342e614e891d6da5af1f8ebe30a5", "committedDate": "2020-06-11T04:43:46Z", "message": "KAFKA-9374: Fix race condition in failing unit test"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1815, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}