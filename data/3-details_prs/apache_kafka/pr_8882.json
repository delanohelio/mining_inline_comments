{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM1NDQzMjA5", "number": 8882, "title": "KAFKA-10165: Remove Percentiles from e2e metrics", "bodyText": "Remove problematic Percentiles measurements until the implementation is fixed\nFix leaking e2e metrics when task is closed\nFix leaking metrics when tasks are recycled\n\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-06-16T20:14:37Z", "url": "https://github.com/apache/kafka/pull/8882", "merged": true, "mergeCommit": {"oid": "147ffb9a968d62ef78ac6b330a20023ed49ddbb8"}, "closed": true, "closedAt": "2020-06-17T14:24:08Z", "author": {"login": "vvcephei"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcr7OyzgFqTQzMTg1NzY4NA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcsO-RHAFqTQzMjcwNzQyOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxODU3Njg0", "url": "https://github.com/apache/kafka/pull/8882#pullrequestreview-431857684", "createdAt": "2020-06-16T20:15:44Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMDoxNTo0NFrOGkrjRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMDoyNDo0N1rOGkr1XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNTQ2Mw==", "bodyText": "This previously relied on a lookup of the actual current system time. I thought we decided to use the cached system time. Can you set me straight, @ableegoldman ?", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441115463", "createdAt": "2020-06-16T20:15:44Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextImpl.java", "diffHunk": "@@ -235,7 +235,7 @@ public StateStore getStateStore(final String name) {\n         setCurrentNode(child);\n         child.process(key, value);\n         if (child.isTerminalNode()) {\n-            streamTask.maybeRecordE2ELatency(timestamp(), child.name());\n+            streamTask.maybeRecordE2ELatency(timestamp(), currentSystemTimeMs(), child.name());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNjA1Mg==", "bodyText": "Standby tasks don't currently register any sensors, but I personally rather to be defensive and idempotently ensure we remove any sensors while closing.", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441116052", "createdAt": "2020-06-16T20:16:53Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -160,18 +162,21 @@ public void postCommit() {\n \n     @Override\n     public void closeClean() {\n+        streamsMetrics.removeAllTaskLevelSensors(Thread.currentThread().getName(), id.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNjk3OA==", "bodyText": "We previously relied on the task manager to remove these sensors before calling close, but forgot to do it before recycling. In retrospect, it's better to do it within the same class that creates the sensors to begin with.", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441116978", "createdAt": "2020-06-16T20:18:43Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -456,12 +457,14 @@ public void postCommit() {\n \n     @Override\n     public void closeClean() {\n+        streamsMetrics.removeAllTaskLevelSensors(Thread.currentThread().getName(), id.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNzQyOA==", "bodyText": "Fixes the sensor leak by simply registering these as task-level sensors. Note the node name is still provided to scope the sensors themselves.", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441117428", "createdAt": "2020-06-16T20:19:35Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -150,18 +151,18 @@ public StreamTask(final TaskId id,\n         punctuateLatencySensor = TaskMetrics.punctuateSensor(threadId, taskId, streamsMetrics);\n         bufferedRecordsSensor = TaskMetrics.activeBufferedRecordsSensor(threadId, taskId, streamsMetrics);\n \n-        for (final String terminalNode : topology.terminalNodes()) {\n+        for (final String terminalNodeName : topology.terminalNodes()) {\n             e2eLatencySensors.put(\n-                terminalNode,\n-                ProcessorNodeMetrics.recordE2ELatencySensor(threadId, taskId, terminalNode, RecordingLevel.INFO, streamsMetrics)\n+                terminalNodeName,\n+                TaskMetrics.e2ELatencySensor(threadId, taskId, terminalNodeName, RecordingLevel.INFO, streamsMetrics)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExODI0MQ==", "bodyText": "We erroneously ignored the provided recordingLevel and set them to debug. It didn't manifest because this method happens to always be called with a recordingLevel of debug anyway.", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441118241", "createdAt": "2020-06-16T20:21:10Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/ProcessorNodeMetrics.java", "diffHunk": "@@ -337,7 +307,7 @@ private static Sensor throughputAndLatencySensorWithParent(final String threadId\n             descriptionOfCount,\n             descriptionOfAvgLatency,\n             descriptionOfMaxLatency,\n-            RecordingLevel.DEBUG,\n+            recordingLevel,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExODUzNQ==", "bodyText": "Dropped the percentiles metric.", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441118535", "createdAt": "2020-06-16T20:21:43Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -675,27 +670,6 @@ public static void addMinAndMaxAndP99AndP90ToSensor(final Sensor sensor,\n                 tags),\n             new Max()\n         );\n-\n-        sensor.add(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExOTE2Ng==", "bodyText": "Just cleaning up some oddball literals.", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441119166", "createdAt": "2020-06-16T20:22:52Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -400,20 +402,20 @@ public void shouldRecordBufferedRecords() {\n \n         final KafkaMetric metric = getMetric(\"active-buffer\", \"%s-count\", task.id().toString(), StreamsConfig.METRICS_LATEST);\n \n-        assertThat(metric.metricValue(), equalTo(0.0d));\n+        assertThat(metric.metricValue(), equalTo(0.0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExOTc2OA==", "bodyText": "This test wasn't really testing the \"terminal node\" code path in ProcessorContextImpl, just that this overload actually fetches the current system time. Since I removed the overload, we don't need the test.", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441119768", "createdAt": "2020-06-16T20:24:06Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -454,24 +456,7 @@ public void shouldRecordE2ELatencyOnProcessForSourceNodes() {\n         task.addRecords(partition1, singletonList(getConsumerRecord(partition1, 0L)));\n         task.process(100L);\n \n-        assertThat(maxMetric.metricValue(), equalTo(100d));\n-    }\n-\n-    @Test\n-    public void shouldRecordE2ELatencyOnProcessForTerminalNodes() {\n-        time = new MockTime(0L, 0L, 0L);\n-        metrics = new Metrics(new MetricConfig().recordLevel(Sensor.RecordingLevel.INFO), time);\n-        task = createStatelessTask(createConfig(false, \"0\"), StreamsConfig.METRICS_LATEST);\n-\n-        final String terminalNode = processorStreamTime.name();\n-\n-        final Metric maxMetric = getProcessorMetric(\"record-e2e-latency\", \"%s-max\", task.id().toString(), terminalNode, StreamsConfig.METRICS_LATEST);\n-\n-        // e2e latency = 100\n-        time.setCurrentTimeMs(100L);\n-        task.maybeRecordE2ELatency(0L, terminalNode);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEyMDA5Mg==", "bodyText": "Verified this fails on trunk.", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441120092", "createdAt": "2020-06-16T20:24:47Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -1806,11 +1793,19 @@ public void shouldRecycleTask() {\n         task.initializeIfNeeded();\n         task.completeRestoration();\n \n+        assertThat(getTaskMetrics(), not(empty()));\n+\n         task.closeAndRecycleState();\n \n+        assertThat(getTaskMetrics(), empty());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 184}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxOTMzMzIx", "url": "https://github.com/apache/kafka/pull/8882#pullrequestreview-431933321", "createdAt": "2020-06-16T22:22:11Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMjoyMjoxMVrOGkvM4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMjoyMjoxMVrOGkvM4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE3NTI2Ng==", "bodyText": "\ud83d\ude4f", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441175266", "createdAt": "2020-06-16T22:22:11Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java", "diffHunk": "@@ -366,6 +369,37 @@ public void shouldThrowOnCloseCleanCheckpointError() {\n         EasyMock.replay(stateManager);\n     }\n \n+    @Test\n+    public void shouldUnregisterMetricsInCloseClean() {\n+        EasyMock.expect(stateManager.changelogPartitions()).andReturn(Collections.emptySet()).anyTimes();\n+        EasyMock.replay(stateManager);\n+\n+        task = createStandbyTask();\n+        task.initializeIfNeeded();\n+\n+        task.suspend();\n+        task.closeClean();\n+        // Currently, there are no metrics registered for standby tasks.\n+        // This is a regression test so that, if we add some, we will be sure to deregister them.\n+        assertThat(getTaskMetrics(), empty());\n+    }\n+\n+    @Test\n+    public void shouldUnregisterMetricsInCloseDirty() {\n+        EasyMock.expect(stateManager.changelogPartitions()).andReturn(Collections.emptySet()).anyTimes();\n+        EasyMock.replay(stateManager);\n+\n+        task = createStandbyTask();\n+        task.initializeIfNeeded();\n+\n+        task.suspend();\n+        task.closeDirty();\n+\n+        // Currently, there are no metrics registered for standby tasks.\n+        // This is a regression test so that, if we add some, we will be sure to deregister them.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxOTM0NDI5", "url": "https://github.com/apache/kafka/pull/8882#pullrequestreview-431934429", "createdAt": "2020-06-16T22:24:43Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c3c51ffcb65b50c344ab05733874964e1d1064c", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/7c3c51ffcb65b50c344ab05733874964e1d1064c", "committedDate": "2020-06-17T03:35:02Z", "message": "KAFKA-10165: Remove Percentiles from e2e metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ae1a3908bcaad82e30ad35a0e4462d7a4b7978b5", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/ae1a3908bcaad82e30ad35a0e4462d7a4b7978b5", "committedDate": "2020-06-17T03:42:47Z", "message": "separate test case for closeAndRecycle metrics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyNzA3NDI4", "url": "https://github.com/apache/kafka/pull/8882#pullrequestreview-432707428", "createdAt": "2020-06-17T19:25:25Z", "commit": {"oid": "ae1a3908bcaad82e30ad35a0e4462d7a4b7978b5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxOToyNToyNVrOGlUM-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxOToyNToyNVrOGlUM-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc4MTQ5OA==", "bodyText": "@vvcephei I'm not familiar enough with the metrics classification to know if this will be an issue or just an oddity, but we now have allegedly task-level metrics but with the processor-node-level tags/grouping. It's kind of a \"task metric in implementation, processor node metric in interface\" -- might be confusing for us but should be alright for users, yeah?", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441781498", "createdAt": "2020-06-17T19:25:25Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/TaskMetrics.java", "diffHunk": "@@ -133,6 +142,25 @@ public static Sensor activeBufferedRecordsSensor(final String threadId,\n         return sensor;\n     }\n \n+    public static Sensor e2ELatencySensor(final String threadId,\n+                                          final String taskId,\n+                                          final String processorNodeId,\n+                                          final RecordingLevel recordingLevel,\n+                                          final StreamsMetricsImpl streamsMetrics) {\n+        final String sensorName = processorNodeId + \"-\" + RECORD_E2E_LATENCY;\n+        final Sensor sensor = streamsMetrics.taskLevelSensor(threadId, taskId, sensorName, recordingLevel);\n+        final Map<String, String> tagMap = streamsMetrics.nodeLevelTagMap(threadId, taskId, processorNodeId);\n+        addMinAndMaxToSensor(\n+            sensor,\n+            PROCESSOR_NODE_LEVEL_GROUP,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae1a3908bcaad82e30ad35a0e4462d7a4b7978b5"}, "originalPosition": 42}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 637, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}