{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMwMDkwNTY2", "number": 8826, "title": "KAFKA-10090 Misleading warnings: The configuration was supplied but i\u2026", "bodyText": "https://issues.apache.org/jira/browse/KAFKA-10090\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-06-07T14:02:27Z", "url": "https://github.com/apache/kafka/pull/8826", "merged": true, "mergeCommit": {"oid": "e63f591ec4d4664608286072c31127323371cb96"}, "closed": true, "closedAt": "2020-12-03T02:34:28Z", "author": {"login": "chia7712"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcvaoHIAFqTQzODcwOTY2OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdiQk_sgBqjQwNjMwNjY2MDU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NzA5NjY5", "url": "https://github.com/apache/kafka/pull/8826#pullrequestreview-438709669", "createdAt": "2020-06-27T16:39:57Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxNjozOTo1N1rOGp23Rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxNjozOTo1N1rOGp23Rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU0MzY4Ng==", "bodyText": "I'm confused, why does convert the type of config will change the way we interpret the config value?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r446543686", "createdAt": "2020-06-27T16:39:57Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,23 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n+    @SuppressWarnings(\"unchecked\")\n     protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+        Map<String, Object> parsedConfigs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI2NzgyNTE0", "url": "https://github.com/apache/kafka/pull/8826#pullrequestreview-526782514", "createdAt": "2020-11-10T01:21:34Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwMToyMTozNFrOHwIDSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwMToyNToyN1rOHwIINw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNTYxMQ==", "bodyText": "Does this cover the case when listenerName is not null? I guess that can only happen on the server side and since we don't log unused configs on the server, so maybe this is ok for now?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r520225611", "createdAt": "2020-11-10T01:21:34Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,25 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n-    protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+    @SuppressWarnings(\"unchecked\")\n+    static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n+        Map<String, Object> parsedConfigs;\n         if (listenerName == null)\n-            parsedConfigs = config.values();\n+            parsedConfigs = (Map<String, Object>) config.values();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNjMzNQ==", "bodyText": "(1) \"so we should not wrap it to a immutable map\": It's kind of weird to have a comment on what we don't do.\n(2) to return map  => to returned map", "url": "https://github.com/apache/kafka/pull/8826#discussion_r520226335", "createdAt": "2020-11-10T01:23:55Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,25 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n-    protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+    @SuppressWarnings(\"unchecked\")\n+    static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n+        Map<String, Object> parsedConfigs;\n         if (listenerName == null)\n-            parsedConfigs = config.values();\n+            parsedConfigs = (Map<String, Object>) config.values();\n         else\n             parsedConfigs = config.valuesWithPrefixOverride(listenerName.configPrefix());\n \n-        // include any custom configs from original configs\n-        Map<String, Object> configs = new HashMap<>(parsedConfigs);\n         config.originals().entrySet().stream()\n             .filter(e -> !parsedConfigs.containsKey(e.getKey())) // exclude already parsed configs\n             // exclude already parsed listener prefix configs\n             .filter(e -> !(listenerName != null && e.getKey().startsWith(listenerName.configPrefix()) &&\n                 parsedConfigs.containsKey(e.getKey().substring(listenerName.configPrefix().length()))))\n             // exclude keys like `{mechanism}.some.prop` if \"listener.name.\" prefix is present and key `some.prop` exists in parsed configs.\n             .filter(e -> !(listenerName != null && parsedConfigs.containsKey(e.getKey().substring(e.getKey().indexOf('.') + 1))))\n-            .forEach(e -> configs.put(e.getKey(), e.getValue()));\n-        return configs;\n+            .forEach(e -> parsedConfigs.put(e.getKey(), e.getValue()));\n+        // The callers may add new elements to return map so we should not wrap it to a immutable map. Otherwise,\n+        // the callers have to create a new map to carry more elements and then following Get ops are not recorded.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNjg3MQ==", "bodyText": "common/config/* is part of the public interface. This method seems internal. So, could we not expose it publicly to the end user?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r520226871", "createdAt": "2020-11-10T01:25:27Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -582,6 +582,13 @@ public int hashCode() {\n         return originals.hashCode();\n     }\n \n+    /**\n+     * @return true if the input map is a recording map. otherwise, false\n+     */\n+    public static boolean isRecording(Map<String, ?> map) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI2ODYyMDQ4", "url": "https://github.com/apache/kafka/pull/8826#pullrequestreview-526862048", "createdAt": "2020-11-10T05:24:57Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNToyNDo1N1rOHwMOJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNToyNDo1N1rOHwMOJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg==", "bodyText": "I tried running console-producer with/without this PR. It doesn't seem to WARN any unused SSL configs in either test. Do you know why?\n\n@junrao this is the root cause.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r520293926", "createdAt": "2020-11-10T05:24:57Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzOTI4NTE4", "url": "https://github.com/apache/kafka/pull/8826#pullrequestreview-533928518", "createdAt": "2020-11-18T22:19:33Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQyMjoxOTozM1rOH2Eo5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxODoxMzoyOVrOH2rfFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ2MTE1OQ==", "bodyText": "Hmm, why is this necessary since we reset used to empty in the next line?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r526461159", "createdAt": "2020-11-18T22:19:33Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg=="}, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ3NzA1MA==", "bodyText": "This comment is still not very clear to me. Are you saying if the caller needs to add more elements, it needs to create a new RecordingMap for the additional elements to be recorded?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r526477050", "createdAt": "2020-11-18T22:52:44Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/network/ChannelBuilders.java", "diffHunk": "@@ -159,24 +159,25 @@ private static ChannelBuilder create(SecurityProtocol securityProtocol,\n     }\n \n     // Visibility for testing\n-    protected static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n-        Map<String, ?> parsedConfigs;\n+    @SuppressWarnings(\"unchecked\")\n+    static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n+        Map<String, Object> parsedConfigs;\n         if (listenerName == null)\n-            parsedConfigs = config.values();\n+            parsedConfigs = (Map<String, Object>) config.values();\n         else\n             parsedConfigs = config.valuesWithPrefixOverride(listenerName.configPrefix());\n \n-        // include any custom configs from original configs\n-        Map<String, Object> configs = new HashMap<>(parsedConfigs);\n         config.originals().entrySet().stream()\n             .filter(e -> !parsedConfigs.containsKey(e.getKey())) // exclude already parsed configs\n             // exclude already parsed listener prefix configs\n             .filter(e -> !(listenerName != null && e.getKey().startsWith(listenerName.configPrefix()) &&\n                 parsedConfigs.containsKey(e.getKey().substring(listenerName.configPrefix().length()))))\n             // exclude keys like `{mechanism}.some.prop` if \"listener.name.\" prefix is present and key `some.prop` exists in parsed configs.\n             .filter(e -> !(listenerName != null && parsedConfigs.containsKey(e.getKey().substring(e.getKey().indexOf('.') + 1))))\n-            .forEach(e -> configs.put(e.getKey(), e.getValue()));\n-        return configs;\n+            .forEach(e -> parsedConfigs.put(e.getKey(), e.getValue()));\n+        // The callers may add new elements to return map so we should not wrap it to a immutable map. Otherwise,\n+        // the callers have to create a new map to carry more elements and then following Get ops are not recorded.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyNjMzNQ=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA4Njc4MQ==", "bodyText": "When will the input configs not be recording?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527086781", "createdAt": "2020-11-19T17:56:33Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/security/ssl/SslFactory.java", "diffHunk": "@@ -79,14 +79,29 @@ public SslFactory(Mode mode,\n         this.keystoreVerifiableUsingTruststore = keystoreVerifiableUsingTruststore;\n     }\n \n+    /**\n+     * @return true if the input map is a recording map. otherwise, false\n+     */\n+    static boolean isRecording(Map<String, ?> map) {\n+        // AbstractConfig is a public APIs and RecordingMap is a internal class\n+        // In order to avoid touching public interface, we just compare the class name here.\n+        return map.getClass().getSimpleName().equals(\"RecordingMap\");\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n     @Override\n     public void configure(Map<String, ?> configs) throws KafkaException {\n         if (sslEngineFactory != null) {\n             throw new IllegalStateException(\"SslFactory was already configured.\");\n         }\n         this.endpointIdentification = (String) configs.get(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG);\n \n-        Map<String, Object> nextConfigs = new HashMap<>(configs);\n+        // it should keep using the input map if it is recording.\n+        // Otherwise, the used configs are not recorded and then AbstractConfig can produce misleading warnings:\n+        // \"The configuration 'xxx' was supplied but isn't a known config.\"\n+        Map<String, Object> nextConfigs = isRecording(configs)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MjAzOA==", "bodyText": "consumer is unused.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527092038", "createdAt": "2020-11-19T18:04:48Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -2588,6 +2589,21 @@ public void deserializerShouldSeeGeneratedClientId() {\n         consumer.close();\n     }\n \n+    @Test\n+    public void testUnusedConfigs() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n+        props.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLS\");\n+        ConsumerConfig config = new ConsumerConfig(ConsumerConfig.appendDeserializerToConfig(props, new StringDeserializer(), new StringDeserializer()));\n+\n+        assertTrue(new ConsumerConfig(config.originals(), false).unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+        assertTrue(config.unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        try (KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(config, null, null)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5NjYwNw==", "bodyText": "Should we use the private static constructor in this class? Ditto below.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527096607", "createdAt": "2020-11-19T18:11:56Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -366,8 +379,9 @@ public void testMetadataFetch() throws InterruptedException {\n         // Return empty cluster 4 times and cluster from then on\n         when(metadata.fetch()).thenReturn(emptyCluster, emptyCluster, emptyCluster, emptyCluster, onePartitionCluster);\n \n-        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(configs, new StringSerializer(),\n-                new StringSerializer(), metadata, new MockClient(Time.SYSTEM, metadata), null, Time.SYSTEM) {\n+        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5NzYyMg==", "bodyText": "producer is unused.", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527097622", "createdAt": "2020-11-19T18:13:29Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -1290,6 +1308,23 @@ public void serializerShouldSeeGeneratedClientId() {\n         producer.close();\n     }\n \n+    @Test\n+    public void testUnusedConfigs() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n+        props.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLS\");\n+        ProducerConfig config = new ProducerConfig(ProducerConfig.appendSerializerToConfig(props,\n+                new StringSerializer(), new StringSerializer()));\n+\n+        assertTrue(new ProducerConfig(config.originals(), false).unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+        assertTrue(config.unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        try (KafkaProducer<byte[], byte[]> producer = new KafkaProducer<>(config, null, null,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 275}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1Nzc5ODIy", "url": "https://github.com/apache/kafka/pull/8826#pullrequestreview-535779822", "createdAt": "2020-11-20T21:13:25Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMToxMzoyNVrOH3g4yA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMToxMzoyNVrOH3g4yA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk3MjU1Mg==", "bodyText": "Ok. I guess the issue is in the following, where we pass in a RecordingMap to construct ProducerConfig.\nhttps://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L384\nHowever, that code seems no longer necessary since we are now setting clientId in ProducerConfig.postProcessParsedConfig(). Could we just avoid constructing ProducerConfig there?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r527972552", "createdAt": "2020-11-20T21:13:25Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg=="}, "originalCommit": null, "originalPosition": 7}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxNDA4MDEy", "url": "https://github.com/apache/kafka/pull/8826#pullrequestreview-541408012", "createdAt": "2020-12-01T00:48:34Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMDo0ODozNFrOH8Tt5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo0NjoxNFrOH8U32g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk5OTY1Mw==", "bodyText": "Hmm, I am still a bit confused. My understanding is that with the latest change, ProducerConfig will only be instantiated once and thus the passed in originals will never be a RecordingMap. But it seems this is still needed? Could you explain a bit more why this is the case?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r532999653", "createdAt": "2020-12-01T00:48:34Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java", "diffHunk": "@@ -105,7 +105,9 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals,  Map<String, ?>\n                 throw new ConfigException(entry.getKey().toString(), entry.getValue(), \"Key must be a string.\");\n \n         this.originals = resolveConfigVariables(configProviderProps, (Map<String, Object>) originals);\n-        this.values = definition.parse(this.originals);\n+        // pass a copy to definition.parse. Otherwise, the definition.parse adds all keys of definitions to \"used\" group\n+        // since definition.parse needs to call \"RecordingMap#get\" when checking all definitions.\n+        this.values = definition.parse(new HashMap<>(this.originals));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDI5MzkyNg=="}, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwMjI3Mg==", "bodyText": "Could we just do config.get(ProducerConfig.TRANSACTIONAL_ID_CONFIG) here?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533002272", "createdAt": "2020-12-01T00:56:12Z", "author": {"login": "junrao"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -314,27 +315,23 @@ public KafkaProducer(Properties properties) {\n      *                         be called in the producer when the serializer is passed in directly.\n      */\n     public KafkaProducer(Properties properties, Serializer<K> keySerializer, Serializer<V> valueSerializer) {\n-        this(Utils.propsToMap(properties), keySerializer, valueSerializer, null, null, null,\n-                Time.SYSTEM);\n+        this(Utils.propsToMap(properties), keySerializer, valueSerializer);\n     }\n \n     // visible for testing\n     @SuppressWarnings(\"unchecked\")\n-    KafkaProducer(Map<String, Object> configs,\n+    KafkaProducer(ProducerConfig config,\n                   Serializer<K> keySerializer,\n                   Serializer<V> valueSerializer,\n                   ProducerMetadata metadata,\n                   KafkaClient kafkaClient,\n                   ProducerInterceptors<K, V> interceptors,\n                   Time time) {\n-        ProducerConfig config = new ProducerConfig(ProducerConfig.appendSerializerToConfig(configs, keySerializer,\n-                valueSerializer));\n         try {\n-            Map<String, Object> userProvidedConfigs = config.originals();\n             this.producerConfig = config;\n             this.time = time;\n \n-            String transactionalId = (String) userProvidedConfigs.get(ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n+            String transactionalId = (String) config.originals().get(ProducerConfig.TRANSACTIONAL_ID_CONFIG);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxMzMzMw==", "bodyText": "Should gssapi.sasl.kerberos.service.name be sasl.kerberos.service.name?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533013333", "createdAt": "2020-12-01T01:29:47Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/common/network/ChannelBuildersTest.java", "diffHunk": "@@ -79,25 +80,52 @@ public void testChannelBuilderConfigs() {\n \n         // test configs with listener prefix\n         Map<String, Object> configs = ChannelBuilders.channelBuilderConfigs(securityConfig, new ListenerName(\"listener1\"));\n+\n         assertNull(configs.get(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"gssapi.sasl.kerberos.service.name\"), \"testkafka\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"sasl.kerberos.service.name\"), \"testkafkaglobal\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxMzk2Mg==", "bodyText": "Do we need to instantiate again?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533013962", "createdAt": "2020-12-01T01:31:39Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/common/network/ChannelBuildersTest.java", "diffHunk": "@@ -79,25 +80,52 @@ public void testChannelBuilderConfigs() {\n \n         // test configs with listener prefix\n         Map<String, Object> configs = ChannelBuilders.channelBuilderConfigs(securityConfig, new ListenerName(\"listener1\"));\n+\n         assertNull(configs.get(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"gssapi.sasl.kerberos.service.name\"), \"testkafka\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));\n+\n         assertEquals(configs.get(\"sasl.kerberos.service.name\"), \"testkafkaglobal\");\n+        assertFalse(securityConfig.unused().contains(\"gssapi.sasl.kerberos.service.name\"));\n+\n         assertNull(configs.get(\"listener.name.listener1.sasl.kerberos.service.name\"));\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.sasl.kerberos.service.name\"));\n \n         assertNull(configs.get(\"plain.sasl.server.callback.handler.class\"));\n+        assertFalse(securityConfig.unused().contains(\"plain.sasl.server.callback.handler.class\"));\n+\n         assertEquals(configs.get(\"listener.name.listener1.gssapi.config1.key\"), \"custom.config1\");\n+        assertFalse(securityConfig.unused().contains(\"listener.name.listener1.gssapi.config1.key\"));\n+\n         assertEquals(configs.get(\"custom.config2.key\"), \"custom.config2\");\n+        assertFalse(securityConfig.unused().contains(\"custom.config2.key\"));\n \n         // test configs without listener prefix\n+        securityConfig = new TestSecurityConfig(props);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxODU4Ng==", "bodyText": "Is this test necessary? Do we still have a case where we pass in a RecordingMap to  ProducerConfig?", "url": "https://github.com/apache/kafka/pull/8826#discussion_r533018586", "createdAt": "2020-12-01T01:46:14Z", "author": {"login": "junrao"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -1271,27 +1270,48 @@ public void testProducerJmxPrefix() throws  Exception {\n         producer.close();\n     }\n \n-    private ProducerMetadata newMetadata(long refreshBackoffMs, long expirationMs) {\n-        return new ProducerMetadata(refreshBackoffMs, expirationMs, defaultMetadataIdleMs,\n+    private static ProducerMetadata newMetadata(long refreshBackoffMs, long expirationMs) {\n+        return new ProducerMetadata(refreshBackoffMs, expirationMs, DEFAULT_METADATA_IDLE_MS,\n                 new LogContext(), new ClusterResourceListeners(), Time.SYSTEM);\n     }\n \n     @Test\n-    public void serializerShouldSeeGeneratedClientId() {\n+    public void configurableObjectsShouldSeeGeneratedClientId() {\n         Properties props = new Properties();\n         props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n         props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, SerializerForClientId.class.getName());\n         props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, SerializerForClientId.class.getName());\n+        props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, PartitionerForClientId.class.getName());\n+        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ProducerInterceptorForClientId.class.getName());\n \n         KafkaProducer<byte[], byte[]> producer = new KafkaProducer<>(props);\n-        assertEquals(2, SerializerForClientId.CLIENT_IDS.size());\n-        assertEquals(SerializerForClientId.CLIENT_IDS.get(0), producer.getClientId());\n-        assertEquals(SerializerForClientId.CLIENT_IDS.get(1), producer.getClientId());\n+        assertNotNull(producer.getClientId());\n+        assertNotEquals(0, producer.getClientId().length());\n+        assertEquals(4, CLIENT_IDS.size());\n+        CLIENT_IDS.forEach(id -> assertEquals(id, producer.getClientId()));\n         producer.close();\n     }\n \n+    @Test\n+    public void testUnusedConfigs() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9999\");\n+        props.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLS\");\n+        ProducerConfig config = new ProducerConfig(ProducerConfig.appendSerializerToConfig(props,\n+                new StringSerializer(), new StringSerializer()));\n+\n+        assertTrue(new ProducerConfig(config.originals(), false).unused().contains(SslConfigs.SSL_PROTOCOL_CONFIG));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 387}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTg1OTc1", "url": "https://github.com/apache/kafka/pull/8826#pullrequestreview-542185975", "createdAt": "2020-12-01T18:34:07Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyOTcwOTg4", "url": "https://github.com/apache/kafka/pull/8826#pullrequestreview-542970988", "createdAt": "2020-12-02T15:45:32Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b994ee1ff848057103c0c73b009a54abf74f9285", "author": {"user": {"login": "chia7712", "name": "Chia-Ping Tsai"}}, "url": "https://github.com/apache/kafka/commit/b994ee1ff848057103c0c73b009a54abf74f9285", "committedDate": "2020-12-02T15:49:06Z", "message": "KAFKA-10090 Misleading warnings: The configuration was supplied but isn't a known config"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7298cfa9da20cb5a5b18add1d77420dc3c67da83", "author": {"user": {"login": "chia7712", "name": "Chia-Ping Tsai"}}, "url": "https://github.com/apache/kafka/commit/7298cfa9da20cb5a5b18add1d77420dc3c67da83", "committedDate": "2020-12-02T15:49:06Z", "message": "fix SslFactory configs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df3780776e98a4ca97e6f80e7471ab07bed32219", "author": {"user": {"login": "chia7712", "name": "Chia-Ping Tsai"}}, "url": "https://github.com/apache/kafka/commit/df3780776e98a4ca97e6f80e7471ab07bed32219", "committedDate": "2020-12-02T15:49:06Z", "message": "channelBuilderConfigs should return RecordedMap"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93465cccb9096761819c57c17006a12ca34d1b63", "author": {"user": {"login": "chia7712", "name": "Chia-Ping Tsai"}}, "url": "https://github.com/apache/kafka/commit/93465cccb9096761819c57c17006a12ca34d1b63", "committedDate": "2020-12-02T15:49:06Z", "message": "address review comments; fix another bug"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "29e36ae7d5c5bc27fe932d3c507b33b77661909c", "author": {"user": {"login": "chia7712", "name": "Chia-Ping Tsai"}}, "url": "https://github.com/apache/kafka/commit/29e36ae7d5c5bc27fe932d3c507b33b77661909c", "committedDate": "2020-12-02T15:49:06Z", "message": "refactor KafkaProducerTest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2b52fd78c50f49ca60c5ffba44361e9dd88e098", "author": {"user": {"login": "chia7712", "name": "Chia-Ping Tsai"}}, "url": "https://github.com/apache/kafka/commit/a2b52fd78c50f49ca60c5ffba44361e9dd88e098", "committedDate": "2020-12-02T15:49:07Z", "message": "apply generated client id to all configurable objects"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bee0513e40c2eae343456a067d7dce26af55854a", "author": {"user": {"login": "chia7712", "name": "Chia-Ping Tsai"}}, "url": "https://github.com/apache/kafka/commit/bee0513e40c2eae343456a067d7dce26af55854a", "committedDate": "2020-12-02T15:49:07Z", "message": "remove unnecessary tests and changes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "bee0513e40c2eae343456a067d7dce26af55854a", "author": {"user": {"login": "chia7712", "name": "Chia-Ping Tsai"}}, "url": "https://github.com/apache/kafka/commit/bee0513e40c2eae343456a067d7dce26af55854a", "committedDate": "2020-12-02T15:49:07Z", "message": "remove unnecessary tests and changes"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 907, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}