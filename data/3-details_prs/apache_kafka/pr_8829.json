{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMwNDU3Nzk0", "number": 8829, "title": "KAFKA-10115: Incorporate errors.tolerance with the Errant Record Reporter", "bodyText": "Currently, the errant record reporter doesn't take into account the value of errors.tolerance. Added a check if the reporter is within the tolerance limits; if not, then a ConnectException is thrown. This is essentially what is done across other parts of the RetryAndToleranceOperator.", "createdAt": "2020-06-07T22:57:58Z", "url": "https://github.com/apache/kafka/pull/8829", "merged": true, "mergeCommit": {"oid": "c49954c5cf0e5699a6885dd385e40c5b34af7e9c"}, "closed": true, "closedAt": "2020-06-11T03:43:47Z", "author": {"login": "aakashnshah"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcpESphAFqTQyNTg2MTU5NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcqDs89gFqTQyODUyNzA5Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1ODYxNTk1", "url": "https://github.com/apache/kafka/pull/8829#pullrequestreview-425861595", "createdAt": "2020-06-07T23:16:37Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wN1QyMzoxNjozN1rOGgMbYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wN1QyMzoxNjozN1rOGgMbYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQxMTIzNQ==", "bodyText": "This marks the failure when we get a new error but the previous error already put us over the limit. IOW, if this is the first error that is reported, then totalFailures will be 0 when this method is called and thus the withinToleranceLimits() will return true (i.e., we haven't recorded any errors yet) and we will not enter the if block due to the negation.\nSeems like we should actually do this check after we record the error. That would be something like:\n        markAsFailed();\n        context.consumerRecord(consumerRecord);\n        context.currentContext(stage, executingClass);\n        context.error(error);\n        errorHandlingMetrics.recordError();\n        if (!withinToleranceLimits()) {\n            errorHandlingMetrics.recordFailure();\n            throw new ConnectException(\"Tolerance exceeded in error handler\", error);\n        }\n        return context.report();\n\nNote that I added the markAsFailed() call since that's what increments the totalFailures field (and calls errorHandlingMetrics.recordErrorTimestamp()).\nBTW, I'm not sure whether we should call errorHandlingMetrics.recordError() or errorHandlingMetrics.recordFailure() or both.\nIIUC, then when we get to the if-block on the first error being reported, the markAsFailed() method will have incremented the totalFailures (we were not doing that in this method before this PR), and if errors.tolerance=NONE is used we will fail on the first error -- which is what we want.\nI also think that if we add other error tolerance policies in the future, this logic will work correctly, as long as withinToleranceLimits() is implemented to return false when we should fail rather than report.\nAlso, it'd be great to have unit tests that verify this behavior.", "url": "https://github.com/apache/kafka/pull/8829#discussion_r436411235", "createdAt": "2020-06-07T23:16:37Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/RetryWithToleranceOperator.java", "diffHunk": "@@ -87,6 +87,12 @@ public RetryWithToleranceOperator(long errorRetryTimeout, long errorMaxDelayInMi\n     public Future<Void> executeFailed(Stage stage, Class<?> executingClass,\n                                       ConsumerRecord<byte[], byte[]> consumerRecord,\n                                       Throwable error) {\n+        if (!withinToleranceLimits()) {\n+            errorHandlingMetrics.recordFailure();\n+            markAsFailed();\n+            throw new ConnectException(\"Tolerance exceeded in the errant record reporter\", error);\n+        }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NDIxNjIx", "url": "https://github.com/apache/kafka/pull/8829#pullrequestreview-426421621", "createdAt": "2020-06-08T16:41:49Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNjo0MTo0OVrOGgm6Hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNjo0MTo0OVrOGgm6Hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg0NTA4Ng==", "bodyText": "Since this is called from the task(), is it enough to just raise an exception? that may be swallowed by the task, and could continue processing.", "url": "https://github.com/apache/kafka/pull/8829#discussion_r436845086", "createdAt": "2020-06-08T16:41:49Z", "author": {"login": "wicknicks"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/RetryWithToleranceOperator.java", "diffHunk": "@@ -87,6 +87,12 @@ public RetryWithToleranceOperator(long errorRetryTimeout, long errorMaxDelayInMi\n     public Future<Void> executeFailed(Stage stage, Class<?> executingClass,\n                                       ConsumerRecord<byte[], byte[]> consumerRecord,\n                                       Throwable error) {\n+        if (!withinToleranceLimits()) {\n+            errorHandlingMetrics.recordFailure();\n+            markAsFailed();\n+            throw new ConnectException(\"Tolerance exceeded in the errant record reporter\", error);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c2867f70bc491f87329736487aaf68663c50f4a5", "author": {"user": {"login": "aakashnshah", "name": "Aakash Shah"}}, "url": "https://github.com/apache/kafka/commit/c2867f70bc491f87329736487aaf68663c50f4a5", "committedDate": "2020-06-08T21:14:11Z", "message": "KAFKA-10115: Incorporate errors.tolerance with the Errant Record Reporter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "author": {"user": {"login": "aakashnshah", "name": "Aakash Shah"}}, "url": "https://github.com/apache/kafka/commit/0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "committedDate": "2020-06-10T22:21:21Z", "message": "addressed comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "author": {"user": {"login": "aakashnshah", "name": "Aakash Shah"}}, "url": "https://github.com/apache/kafka/commit/0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "committedDate": "2020-06-10T22:21:21Z", "message": "addressed comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NDgzOTMw", "url": "https://github.com/apache/kafka/pull/8829#pullrequestreview-428483930", "createdAt": "2020-06-10T22:58:33Z", "commit": {"oid": "0ce4daf669d95320c9ab096b7dbc207786aaeeb8"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMjo1ODozM1rOGiI_tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMzowMDoxMVrOGiJB2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1MjE1MQ==", "bodyText": "instead, you can just check:\n        if (retryWithToleranceOperator.failed()) {\n            throw retryWithToleranceOperator.error();\n        }\n\nbecause we are already storing the error in the processing context. you can expose that through the operator.", "url": "https://github.com/apache/kafka/pull/8829#discussion_r438452151", "createdAt": "2020-06-10T22:58:33Z", "author": {"login": "wicknicks"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java", "diffHunk": "@@ -556,6 +556,9 @@ private void deliverMessages() {\n             log.trace(\"{} Delivering batch of {} messages to task\", this, messageBatch.size());\n             long start = time.milliseconds();\n             task.put(new ArrayList<>(messageBatch));\n+            if (workerErrantRecordReporter != null && workerErrantRecordReporter.mustThrowException()) {\n+                throw workerErrantRecordReporter.getExceptionToThrow();\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ce4daf669d95320c9ab096b7dbc207786aaeeb8"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1MjY5Ng==", "bodyText": "we don't need these vars, the errors are already stored in the ProcessingContext. look at comment above.", "url": "https://github.com/apache/kafka/pull/8829#discussion_r438452696", "createdAt": "2020-06-10T23:00:11Z", "author": {"login": "wicknicks"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/WorkerErrantRecordReporter.java", "diffHunk": "@@ -99,8 +102,15 @@ public WorkerErrantRecordReporter(\n                 valLength, key, value, headers);\n         }\n \n-        Future<Void> future = retryWithToleranceOperator.executeFailed(Stage.TASK_PUT,\n-            SinkTask.class, consumerRecord, error);\n+        Future<Void> future;\n+        try {\n+            future = retryWithToleranceOperator.executeFailed(Stage.TASK_PUT,\n+                SinkTask.class, consumerRecord, error);\n+        } catch (ConnectException e) {\n+            mustThrowException = true;\n+            exceptionToThrow = e;\n+            throw e;\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ce4daf669d95320c9ab096b7dbc207786aaeeb8"}, "originalPosition": 24}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "603217f1ed0e68295b5a6cfd0bc2fd09ba9f681d", "author": {"user": {"login": "aakashnshah", "name": "Aakash Shah"}}, "url": "https://github.com/apache/kafka/commit/603217f1ed0e68295b5a6cfd0bc2fd09ba9f681d", "committedDate": "2020-06-10T23:55:34Z", "message": "addressed comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aefe73ffc3e6173a2427bd3dfb957d776d4088fd", "author": {"user": {"login": "aakashnshah", "name": "Aakash Shah"}}, "url": "https://github.com/apache/kafka/commit/aefe73ffc3e6173a2427bd3dfb957d776d4088fd", "committedDate": "2020-06-11T00:20:26Z", "message": "moved errant record reporter test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NTExNTI5", "url": "https://github.com/apache/kafka/pull/8829#pullrequestreview-428511529", "createdAt": "2020-06-11T00:17:22Z", "commit": {"oid": "603217f1ed0e68295b5a6cfd0bc2fd09ba9f681d"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQwMDoxNzoyMlrOGiKaWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQwMDoyMjozMlrOGiKfsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3NTM1NQ==", "bodyText": "minor: we should move this test to ErrorHandlingIntegrationTest. this class was meant to be an example of how to do integration tests.", "url": "https://github.com/apache/kafka/pull/8829#discussion_r438475355", "createdAt": "2020-06-11T00:17:22Z", "author": {"login": "wicknicks"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/ExampleConnectIntegrationTest.java", "diffHunk": "@@ -237,6 +239,7 @@ public void testErrantRecordReporter() throws Exception {\n         props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n         props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n         props.put(DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC);\n+        props.put(ERRORS_TOLERANCE_CONFIG, ToleranceType.ALL.value());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "603217f1ed0e68295b5a6cfd0bc2fd09ba9f681d"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3NjcyMg==", "bodyText": "let's add a small comment saying why we need to do this: specifically, that if the errors raised from the operator were swallowed by the task implementation, then here we need to kill the task, and if they were not swallowed, we would not get here.", "url": "https://github.com/apache/kafka/pull/8829#discussion_r438476722", "createdAt": "2020-06-11T00:22:32Z", "author": {"login": "wicknicks"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java", "diffHunk": "@@ -556,6 +556,10 @@ private void deliverMessages() {\n             log.trace(\"{} Delivering batch of {} messages to task\", this, messageBatch.size());\n             long start = time.milliseconds();\n             task.put(new ArrayList<>(messageBatch));\n+            if (retryWithToleranceOperator.failed() && !retryWithToleranceOperator.withinToleranceLimits()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "603217f1ed0e68295b5a6cfd0bc2fd09ba9f681d"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3324cce90f8379c69c8538b594edd29e83f7fe1", "author": {"user": {"login": "aakashnshah", "name": "Aakash Shah"}}, "url": "https://github.com/apache/kafka/commit/c3324cce90f8379c69c8538b594edd29e83f7fe1", "committedDate": "2020-06-11T00:44:15Z", "message": "more comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NTIxNzQz", "url": "https://github.com/apache/kafka/pull/8829#pullrequestreview-428521743", "createdAt": "2020-06-11T00:51:30Z", "commit": {"oid": "c3324cce90f8379c69c8538b594edd29e83f7fe1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NTI3MDk3", "url": "https://github.com/apache/kafka/pull/8829#pullrequestreview-428527097", "createdAt": "2020-06-11T01:09:43Z", "commit": {"oid": "c3324cce90f8379c69c8538b594edd29e83f7fe1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 915, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}