{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3MDEyOTQ2", "number": 8662, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMzowNzoyNFrOD72vmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QyMTo0ODo1NVrOD8P67w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDg5NDk2OnYy", "diffSide": "LEFT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMzowNzoyNFrOGUcBTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxODoyMjozNVrOGVo4dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA4Mzc4OQ==", "bodyText": "Am I crazy or is this entire block not actually doing anything?", "url": "https://github.com/apache/kafka/pull/8662#discussion_r424083789", "createdAt": "2020-05-12T23:07:24Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -1520,38 +1534,6 @@ private static void validateActiveTaskEncoding(final List<TopicPartition> partit\n         }\n     }\n \n-    /**\n-     * Internal helper function that creates a Kafka topic\n-     *\n-     * @param topicPartitions Map that contains the topic names to be created with the number of partitions\n-     */\n-    private void prepareTopic(final Map<String, InternalTopicConfig> topicPartitions) {\n-        log.debug(\"Starting to validate internal topics {} in partition assignor.\", topicPartitions);\n-\n-        // first construct the topics to make ready\n-        final Map<String, InternalTopicConfig> topicsToMakeReady = new HashMap<>();\n-\n-        for (final InternalTopicConfig topic : topicPartitions.values()) {\n-            final Optional<Integer> numPartitions = topic.numberOfPartitions();\n-            if (!numPartitions.isPresent()) {\n-                throw new StreamsException(\n-                    String.format(\"%sTopic [%s] number of partitions not defined\",\n-                                  logPrefix, topic.name())\n-                );\n-            }\n-            if (!topic.hasEnforcedNumberOfPartitions()) {\n-                topic.setNumberOfPartitions(numPartitions.get());\n-            }\n-            topicsToMakeReady.put(topic.name(), topic);\n-        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDEwMzU1OA==", "bodyText": "It should do some sanity checks -- but I agree it's not easy to grok... Maybe we also incrementally refactored the code and this method become useless? All tests passed?", "url": "https://github.com/apache/kafka/pull/8662#discussion_r424103558", "createdAt": "2020-05-13T00:13:38Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -1520,38 +1534,6 @@ private static void validateActiveTaskEncoding(final List<TopicPartition> partit\n         }\n     }\n \n-    /**\n-     * Internal helper function that creates a Kafka topic\n-     *\n-     * @param topicPartitions Map that contains the topic names to be created with the number of partitions\n-     */\n-    private void prepareTopic(final Map<String, InternalTopicConfig> topicPartitions) {\n-        log.debug(\"Starting to validate internal topics {} in partition assignor.\", topicPartitions);\n-\n-        // first construct the topics to make ready\n-        final Map<String, InternalTopicConfig> topicsToMakeReady = new HashMap<>();\n-\n-        for (final InternalTopicConfig topic : topicPartitions.values()) {\n-            final Optional<Integer> numPartitions = topic.numberOfPartitions();\n-            if (!numPartitions.isPresent()) {\n-                throw new StreamsException(\n-                    String.format(\"%sTopic [%s] number of partitions not defined\",\n-                                  logPrefix, topic.name())\n-                );\n-            }\n-            if (!topic.hasEnforcedNumberOfPartitions()) {\n-                topic.setNumberOfPartitions(numPartitions.get());\n-            }\n-            topicsToMakeReady.put(topic.name(), topic);\n-        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA4Mzc4OQ=="}, "originalCommit": null, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDExMDgzMQ==", "bodyText": "I guess to be fair it was still validating that every topic had the numberOfPartitions set, but I thought it might make more sense to do this inside the InternalTopicManager since that checks the partitions anyways", "url": "https://github.com/apache/kafka/pull/8662#discussion_r424110831", "createdAt": "2020-05-13T00:40:51Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -1520,38 +1534,6 @@ private static void validateActiveTaskEncoding(final List<TopicPartition> partit\n         }\n     }\n \n-    /**\n-     * Internal helper function that creates a Kafka topic\n-     *\n-     * @param topicPartitions Map that contains the topic names to be created with the number of partitions\n-     */\n-    private void prepareTopic(final Map<String, InternalTopicConfig> topicPartitions) {\n-        log.debug(\"Starting to validate internal topics {} in partition assignor.\", topicPartitions);\n-\n-        // first construct the topics to make ready\n-        final Map<String, InternalTopicConfig> topicsToMakeReady = new HashMap<>();\n-\n-        for (final InternalTopicConfig topic : topicPartitions.values()) {\n-            final Optional<Integer> numPartitions = topic.numberOfPartitions();\n-            if (!numPartitions.isPresent()) {\n-                throw new StreamsException(\n-                    String.format(\"%sTopic [%s] number of partitions not defined\",\n-                                  logPrefix, topic.name())\n-                );\n-            }\n-            if (!topic.hasEnforcedNumberOfPartitions()) {\n-                topic.setNumberOfPartitions(numPartitions.get());\n-            }\n-            topicsToMakeReady.put(topic.name(), topic);\n-        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA4Mzc4OQ=="}, "originalCommit": null, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTM0MzA5NA==", "bodyText": "The logic indeed seem redundant to me.", "url": "https://github.com/apache/kafka/pull/8662#discussion_r425343094", "createdAt": "2020-05-14T18:22:35Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -1520,38 +1534,6 @@ private static void validateActiveTaskEncoding(final List<TopicPartition> partit\n         }\n     }\n \n-    /**\n-     * Internal helper function that creates a Kafka topic\n-     *\n-     * @param topicPartitions Map that contains the topic names to be created with the number of partitions\n-     */\n-    private void prepareTopic(final Map<String, InternalTopicConfig> topicPartitions) {\n-        log.debug(\"Starting to validate internal topics {} in partition assignor.\", topicPartitions);\n-\n-        // first construct the topics to make ready\n-        final Map<String, InternalTopicConfig> topicsToMakeReady = new HashMap<>();\n-\n-        for (final InternalTopicConfig topic : topicPartitions.values()) {\n-            final Optional<Integer> numPartitions = topic.numberOfPartitions();\n-            if (!numPartitions.isPresent()) {\n-                throw new StreamsException(\n-                    String.format(\"%sTopic [%s] number of partitions not defined\",\n-                                  logPrefix, topic.name())\n-                );\n-            }\n-            if (!topic.hasEnforcedNumberOfPartitions()) {\n-                topic.setNumberOfPartitions(numPartitions.get());\n-            }\n-            topicsToMakeReady.put(topic.name(), topic);\n-        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA4Mzc4OQ=="}, "originalCommit": null, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTAzMjE5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwMDoyMDoyMlrOGUdVfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwMDozNDowMFrOGUdjnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDEwNTM0MQ==", "bodyText": "I like immutability. Should we call this allExpetcedChangelogPartitions and introduce allExistingChangelogPartitions = allExpetcedChangelogPartitions - newlyCreatedChangelogs", "url": "https://github.com/apache/kafka/pull/8662#discussion_r424105341", "createdAt": "2020-05-13T00:20:22Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -755,16 +753,25 @@ private TaskAssignor createTaskAssignor(final boolean lagComputationSuccessful)\n     private boolean populateClientStatesMap(final Map<UUID, ClientState> clientStates,\n                                             final Map<UUID, ClientMetadata> clientMetadataMap,\n                                             final Map<TopicPartition, TaskId> taskForPartition,\n-                                            final Map<TaskId, Set<TopicPartition>> changelogsByStatefulTask) {\n+                                            final Map<TaskId, Set<TopicPartition>> changelogsByStatefulTask,\n+                                            final Set<String> newlyCreatedChangelogs) {\n         boolean fetchEndOffsetsSuccessful;\n         Map<TaskId, Long> allTaskEndOffsetSums;\n         try {\n-            final Collection<TopicPartition> allChangelogPartitions = changelogsByStatefulTask.values().stream()\n-                                                                          .flatMap(Collection::stream)\n-                                                                          .collect(Collectors.toList());\n+            final Collection<TopicPartition> allExistingChangelogPartitions =", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDEwODk1Ng==", "bodyText": "Fair enough", "url": "https://github.com/apache/kafka/pull/8662#discussion_r424108956", "createdAt": "2020-05-13T00:34:00Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -755,16 +753,25 @@ private TaskAssignor createTaskAssignor(final boolean lagComputationSuccessful)\n     private boolean populateClientStatesMap(final Map<UUID, ClientState> clientStates,\n                                             final Map<UUID, ClientMetadata> clientMetadataMap,\n                                             final Map<TopicPartition, TaskId> taskForPartition,\n-                                            final Map<TaskId, Set<TopicPartition>> changelogsByStatefulTask) {\n+                                            final Map<TaskId, Set<TopicPartition>> changelogsByStatefulTask,\n+                                            final Set<String> newlyCreatedChangelogs) {\n         boolean fetchEndOffsetsSuccessful;\n         Map<TaskId, Long> allTaskEndOffsetSums;\n         try {\n-            final Collection<TopicPartition> allChangelogPartitions = changelogsByStatefulTask.values().stream()\n-                                                                          .flatMap(Collection::stream)\n-                                                                          .collect(Collectors.toList());\n+            final Collection<TopicPartition> allExistingChangelogPartitions =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDEwNTM0MQ=="}, "originalCommit": null, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NDc3ODE3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ClientUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QyMDoyOTowNVrOGVCXfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QyMDoyOTowNVrOGVCXfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcxMjA2MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        LOG.warn(\"listOffsets request failed due to \", e);\n          \n          \n            \n                        LOG.warn(\"listOffsets request failed.\", e);\n          \n      \n    \n    \n  \n\nThanks! (minor suggestion to make the log message more typical)", "url": "https://github.com/apache/kafka/pull/8662#discussion_r424712060", "createdAt": "2020-05-13T20:29:05Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ClientUtils.java", "diffHunk": "@@ -105,6 +109,7 @@ public static String getTaskProducerClientId(final String threadClientId, final\n                 endOffsets = future.get(timeout.toMillis(), TimeUnit.MILLISECONDS);\n             }\n         } catch (final TimeoutException | RuntimeException | InterruptedException | ExecutionException e) {\n+            LOG.warn(\"listOffsets request failed due to \", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NDgwNjA4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QyMDozODowOVrOGVCpaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxODowMDo0MVrOGVoIMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcxNjY0OQ==", "bodyText": "It's not what you signed up for, but I'm wondering if we should at least submit a Jira to give some of these AdminClient methods a \"full consistency\" mode. In other words, since the command returns a future anyway, it would be nice to be able to tell it not to return until it can guarantee the topic will appear to be fully created on all brokers.\nI'm mildly concerned that we're just kicking the can down the road a little ways with this PR. I.e., we let the assignment happen, but then some other metadata (or data) operation for that topic will just fail shortly thereafter.\nMore generally, we jump through a lot of hoops in our own tests to try and make sure that the topics are really, actually created (or deleted) before proceeding with the test, and I'm sure that our users also suffer from the same problem in their testing and production code.", "url": "https://github.com/apache/kafka/pull/8662#discussion_r424716649", "createdAt": "2020-05-13T20:38:09Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "diffHunk": "@@ -169,6 +173,9 @@ public void makeReady(final Map<String, InternalTopicConfig> topics) {\n             log.error(timeoutAndRetryError);\n             throw new StreamsException(timeoutAndRetryError);\n         }\n+        log.debug(\"Completed validating internal topics and created {}\", newlyCreatedTopics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTMxNDI2Mw==", "bodyText": "I think this race condition was particularly severe since we do the listOffsets request pretty much immediately after creating the topics, whereas whatever we're doing with that topic next will not be until the rebalance was completed.\nAFAIK we've never had any users report subsequent operations failing after the first rebalance due to not-yet-fully-created topics, but it could have just slipped past us", "url": "https://github.com/apache/kafka/pull/8662#discussion_r425314263", "createdAt": "2020-05-14T17:35:15Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "diffHunk": "@@ -169,6 +173,9 @@ public void makeReady(final Map<String, InternalTopicConfig> topics) {\n             log.error(timeoutAndRetryError);\n             throw new StreamsException(timeoutAndRetryError);\n         }\n+        log.debug(\"Completed validating internal topics and created {}\", newlyCreatedTopics);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcxNjY0OQ=="}, "originalCommit": null, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTMxNDQ3MA==", "bodyText": "I do agree it would be useful though. Feel free to create a ticket :P", "url": "https://github.com/apache/kafka/pull/8662#discussion_r425314470", "createdAt": "2020-05-14T17:35:34Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "diffHunk": "@@ -169,6 +173,9 @@ public void makeReady(final Map<String, InternalTopicConfig> topics) {\n             log.error(timeoutAndRetryError);\n             throw new StreamsException(timeoutAndRetryError);\n         }\n+        log.debug(\"Completed validating internal topics and created {}\", newlyCreatedTopics);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcxNjY0OQ=="}, "originalCommit": null, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTMzMDczNg==", "bodyText": "Thanks! Will do. I just wanted to bounce the idea off you first, in case it was stupid.", "url": "https://github.com/apache/kafka/pull/8662#discussion_r425330736", "createdAt": "2020-05-14T18:00:41Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "diffHunk": "@@ -169,6 +173,9 @@ public void makeReady(final Map<String, InternalTopicConfig> topics) {\n             log.error(timeoutAndRetryError);\n             throw new StreamsException(timeoutAndRetryError);\n         }\n+        log.debug(\"Completed validating internal topics and created {}\", newlyCreatedTopics);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcxNjY0OQ=="}, "originalCommit": null, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NTAxOTk5OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QyMTo0ODo1NVrOGVEvbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QyMTo1MDo1MFrOGVEynA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1MDk1OA==", "bodyText": "Don't we need to reply adminClient, too?", "url": "https://github.com/apache/kafka/pull/8662#discussion_r424750958", "createdAt": "2020-05-13T21:48:55Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java", "diffHunk": "@@ -1862,6 +1866,35 @@ public void shouldThrowIllegalStateExceptionIfAnyTopicsMissingFromChangelogEndOf\n         assertThrows(IllegalStateException.class, () -> partitionAssignor.assign(metadata, new GroupSubscription(subscriptions)));\n     }\n \n+    @Test\n+    public void shouldSkipListOffsetsRequestForNewlyCreatedChangelogTopics() {\n+        adminClient = EasyMock.createMock(AdminClient.class);\n+        final ListOffsetsResult result = EasyMock.createNiceMock(ListOffsetsResult.class);\n+        final KafkaFutureImpl<Map<TopicPartition, ListOffsetsResultInfo>> allFuture = new KafkaFutureImpl<>();\n+        allFuture.complete(emptyMap());\n+\n+        expect(adminClient.listOffsets(emptyMap())).andStubReturn(result);\n+        expect(result.all()).andReturn(allFuture);\n+\n+        builder.addSource(null, \"source1\", null, null, null, \"topic1\");\n+        builder.addProcessor(\"processor1\", new MockProcessorSupplier(), \"source1\");\n+        builder.addStateStore(new MockKeyValueStoreBuilder(\"store1\", false), \"processor1\");\n+\n+        subscriptions.put(\"consumer10\",\n+                          new Subscription(\n+                              singletonList(\"topic1\"),\n+                              defaultSubscriptionInfo.encode()\n+                          ));\n+\n+        EasyMock.replay(result);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1MTc3Mg==", "bodyText": "It gets replayed during configuration (at the end of configureDefault below)", "url": "https://github.com/apache/kafka/pull/8662#discussion_r424751772", "createdAt": "2020-05-13T21:50:50Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java", "diffHunk": "@@ -1862,6 +1866,35 @@ public void shouldThrowIllegalStateExceptionIfAnyTopicsMissingFromChangelogEndOf\n         assertThrows(IllegalStateException.class, () -> partitionAssignor.assign(metadata, new GroupSubscription(subscriptions)));\n     }\n \n+    @Test\n+    public void shouldSkipListOffsetsRequestForNewlyCreatedChangelogTopics() {\n+        adminClient = EasyMock.createMock(AdminClient.class);\n+        final ListOffsetsResult result = EasyMock.createNiceMock(ListOffsetsResult.class);\n+        final KafkaFutureImpl<Map<TopicPartition, ListOffsetsResultInfo>> allFuture = new KafkaFutureImpl<>();\n+        allFuture.complete(emptyMap());\n+\n+        expect(adminClient.listOffsets(emptyMap())).andStubReturn(result);\n+        expect(result.all()).andReturn(allFuture);\n+\n+        builder.addSource(null, \"source1\", null, null, null, \"topic1\");\n+        builder.addProcessor(\"processor1\", new MockProcessorSupplier(), \"source1\");\n+        builder.addStateStore(new MockKeyValueStoreBuilder(\"store1\", false), \"processor1\");\n+\n+        subscriptions.put(\"consumer10\",\n+                          new Subscription(\n+                              singletonList(\"topic1\"),\n+                              defaultSubscriptionInfo.encode()\n+                          ));\n+\n+        EasyMock.replay(result);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1MDk1OA=="}, "originalCommit": null, "originalPosition": 50}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2594, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}