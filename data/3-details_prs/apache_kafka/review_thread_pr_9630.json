{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI0Nzg1MjQx", "number": 9630, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwODo1MjowMVrOE8HmCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxODoxMzoxOFrOE_v1XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNDc0NDQxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwODo1MjowMVrOH4D3NA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxNjoxNzo1MFrOH6hkAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NTU4OA==", "bodyText": "Could we avoid duplicate conversion between scala and java? It can be rewrite by java stream APIs so the  asScala  can be avoid.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r528545588", "createdAt": "2020-11-23T08:52:01Z", "author": {"login": "chia7712"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1862,23 +1864,51 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n   }\n \n-  def lastOffsetForLeaderEpoch(requestedEpochInfo: Map[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData]): Map[TopicPartition, EpochEndOffset] = {\n-    requestedEpochInfo.map { case (tp, partitionData) =>\n-      val epochEndOffset = getPartition(tp) match {\n-        case HostedPartition.Online(partition) =>\n-          partition.lastOffsetForLeaderEpoch(partitionData.currentLeaderEpoch, partitionData.leaderEpoch,\n-            fetchOnlyFromLeader = true)\n-\n-        case HostedPartition.Offline =>\n-          new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None if metadataCache.contains(tp) =>\n-          new EpochEndOffset(Errors.NOT_LEADER_OR_FOLLOWER, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None =>\n-          new EpochEndOffset(Errors.UNKNOWN_TOPIC_OR_PARTITION, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n+  def lastOffsetForLeaderEpoch(\n+    requestedEpochInfo: Seq[OffsetForLeaderTopic]\n+  ): Seq[OffsetForLeaderTopicResult] = {\n+    requestedEpochInfo.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEyMzM2MA==", "bodyText": "asScala and asJava just wrap the collections to make it accessible from respectively Scala and Java. In that regards, I am not sure that we would gain much by using the stream API here as it also creates a Stream. It seems more natural to keep using Scala here. If you look in the API layer, we do this everywhere.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r531123360", "createdAt": "2020-11-26T16:06:13Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1862,23 +1864,51 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n   }\n \n-  def lastOffsetForLeaderEpoch(requestedEpochInfo: Map[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData]): Map[TopicPartition, EpochEndOffset] = {\n-    requestedEpochInfo.map { case (tp, partitionData) =>\n-      val epochEndOffset = getPartition(tp) match {\n-        case HostedPartition.Online(partition) =>\n-          partition.lastOffsetForLeaderEpoch(partitionData.currentLeaderEpoch, partitionData.leaderEpoch,\n-            fetchOnlyFromLeader = true)\n-\n-        case HostedPartition.Offline =>\n-          new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None if metadataCache.contains(tp) =>\n-          new EpochEndOffset(Errors.NOT_LEADER_OR_FOLLOWER, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None =>\n-          new EpochEndOffset(Errors.UNKNOWN_TOPIC_OR_PARTITION, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n+  def lastOffsetForLeaderEpoch(\n+    requestedEpochInfo: Seq[OffsetForLeaderTopic]\n+  ): Seq[OffsetForLeaderTopicResult] = {\n+    requestedEpochInfo.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NTU4OA=="}, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEyOTM0NA==", "bodyText": "Make sense to me :)", "url": "https://github.com/apache/kafka/pull/9630#discussion_r531129344", "createdAt": "2020-11-26T16:17:50Z", "author": {"login": "chia7712"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1862,23 +1864,51 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n   }\n \n-  def lastOffsetForLeaderEpoch(requestedEpochInfo: Map[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData]): Map[TopicPartition, EpochEndOffset] = {\n-    requestedEpochInfo.map { case (tp, partitionData) =>\n-      val epochEndOffset = getPartition(tp) match {\n-        case HostedPartition.Online(partition) =>\n-          partition.lastOffsetForLeaderEpoch(partitionData.currentLeaderEpoch, partitionData.leaderEpoch,\n-            fetchOnlyFromLeader = true)\n-\n-        case HostedPartition.Offline =>\n-          new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None if metadataCache.contains(tp) =>\n-          new EpochEndOffset(Errors.NOT_LEADER_OR_FOLLOWER, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None =>\n-          new EpochEndOffset(Errors.UNKNOWN_TOPIC_OR_PARTITION, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n+  def lastOffsetForLeaderEpoch(\n+    requestedEpochInfo: Seq[OffsetForLeaderTopic]\n+  ): Seq[OffsetForLeaderTopicResult] = {\n+    requestedEpochInfo.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NTU4OA=="}, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNDc0Nzc2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwODo1Mjo1NlrOH4D5Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwODo1Mjo1NlrOH4D5Ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NjA4Mg==", "bodyText": "ditto", "url": "https://github.com/apache/kafka/pull/9630#discussion_r528546082", "createdAt": "2020-11-23T08:52:56Z", "author": {"login": "chia7712"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -2592,25 +2596,39 @@ class KafkaApis(val requestChannel: RequestChannel,\n \n   def handleOffsetForLeaderEpochRequest(request: RequestChannel.Request): Unit = {\n     val offsetForLeaderEpoch = request.body[OffsetsForLeaderEpochRequest]\n-    val requestInfo = offsetForLeaderEpoch.epochsByTopicPartition.asScala\n+    val topics = offsetForLeaderEpoch.data.topics.asScala.toSeq\n \n     // The OffsetsForLeaderEpoch API was initially only used for inter-broker communication and required\n     // cluster permission. With KIP-320, the consumer now also uses this API to check for log truncation\n     // following a leader change, so we also allow topic describe permission.\n-    val (authorizedPartitions, unauthorizedPartitions) =\n+    val (authorizedTopics, unauthorizedTopics) =\n       if (authorize(request.context, CLUSTER_ACTION, CLUSTER, CLUSTER_NAME, logIfDenied = false))\n-        (requestInfo, Map.empty[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData])\n-      else partitionMapByAuthorized(request.context, DESCRIBE, TOPIC, requestInfo)(_.topic)\n+        (topics, Seq.empty[OffsetForLeaderTopic])\n+      else partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, topics)(_.topic)\n+\n+    val endOffsetsForAuthorizedPartitions = replicaManager.lastOffsetForLeaderEpoch(authorizedTopics)\n+    val endOffsetsForUnauthorizedPartitions = unauthorizedTopics.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNDc4OTIyOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwOTowNTowMlrOH4ESGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQwOToxMzo0OFrOH7x1BQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU1MjQ3Mw==", "bodyText": "Should it be topic.partitions.add(offsetForLeaderPartition.duplicate())?", "url": "https://github.com/apache/kafka/pull/9630#discussion_r528552473", "createdAt": "2020-11-23T09:05:02Z", "author": {"login": "chia7712"}, "path": "core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala", "diffHunk": "@@ -78,7 +80,19 @@ class ReplicaFetcherMockBlockingSend(offsets: java.util.Map[TopicPartition, Epoc\n         callback.foreach(_.apply())\n         epochFetchCount += 1\n         lastUsedOffsetForLeaderEpochVersion = requestBuilder.latestAllowedVersion()\n-        new OffsetsForLeaderEpochResponse(currentOffsets)\n+\n+        val data = new OffsetForLeaderEpochResponseData()\n+        currentOffsets.forEach((tp, offsetForLeaderPartition) => {\n+          var topic = data.topics.find(tp.topic)\n+          if (topic == null) {\n+            topic = new OffsetForLeaderTopicResult()\n+              .setTopic(tp.topic)\n+            data.topics.add(topic)\n+          }\n+          topic.partitions.add(offsetForLeaderPartition.setPartition(tp.partition))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEyMzc4MA==", "bodyText": "Hum.. I am not sure to understand the duplicate suggestion here. Could you elaborate?", "url": "https://github.com/apache/kafka/pull/9630#discussion_r531123780", "createdAt": "2020-11-26T16:07:01Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala", "diffHunk": "@@ -78,7 +80,19 @@ class ReplicaFetcherMockBlockingSend(offsets: java.util.Map[TopicPartition, Epoc\n         callback.foreach(_.apply())\n         epochFetchCount += 1\n         lastUsedOffsetForLeaderEpochVersion = requestBuilder.latestAllowedVersion()\n-        new OffsetsForLeaderEpochResponse(currentOffsets)\n+\n+        val data = new OffsetForLeaderEpochResponseData()\n+        currentOffsets.forEach((tp, offsetForLeaderPartition) => {\n+          var topic = data.topics.find(tp.topic)\n+          if (topic == null) {\n+            topic = new OffsetForLeaderTopicResult()\n+              .setTopic(tp.topic)\n+            data.topics.add(topic)\n+          }\n+          topic.partitions.add(offsetForLeaderPartition.setPartition(tp.partition))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU1MjQ3Mw=="}, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEzNzM5Nw==", "bodyText": "oh, it is just personal taste. the code topic.partitions.add(offsetForLeaderPartition.setPartition(tp.partition)) adds inner mutable object (offsetForLeaderPartition) to returned response. I prefer to add a copy of offsetForLeaderPartition.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r531137397", "createdAt": "2020-11-26T16:33:21Z", "author": {"login": "chia7712"}, "path": "core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala", "diffHunk": "@@ -78,7 +80,19 @@ class ReplicaFetcherMockBlockingSend(offsets: java.util.Map[TopicPartition, Epoc\n         callback.foreach(_.apply())\n         epochFetchCount += 1\n         lastUsedOffsetForLeaderEpochVersion = requestBuilder.latestAllowedVersion()\n-        new OffsetsForLeaderEpochResponse(currentOffsets)\n+\n+        val data = new OffsetForLeaderEpochResponseData()\n+        currentOffsets.forEach((tp, offsetForLeaderPartition) => {\n+          var topic = data.topics.find(tp.topic)\n+          if (topic == null) {\n+            topic = new OffsetForLeaderTopicResult()\n+              .setTopic(tp.topic)\n+            data.topics.add(topic)\n+          }\n+          topic.partitions.add(offsetForLeaderPartition.setPartition(tp.partition))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU1MjQ3Mw=="}, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjQ0NDQyMQ==", "bodyText": "Good point. Actually, setPartition(tp.partition) is not needed. Let me remove it.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r532444421", "createdAt": "2020-11-30T09:13:48Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala", "diffHunk": "@@ -78,7 +80,19 @@ class ReplicaFetcherMockBlockingSend(offsets: java.util.Map[TopicPartition, Epoc\n         callback.foreach(_.apply())\n         epochFetchCount += 1\n         lastUsedOffsetForLeaderEpochVersion = requestBuilder.latestAllowedVersion()\n-        new OffsetsForLeaderEpochResponse(currentOffsets)\n+\n+        val data = new OffsetForLeaderEpochResponseData()\n+        currentOffsets.forEach((tp, offsetForLeaderPartition) => {\n+          var topic = data.topics.find(tp.topic)\n+          if (topic == null) {\n+            topic = new OffsetForLeaderTopicResult()\n+              .setTopic(tp.topic)\n+            data.topics.add(topic)\n+          }\n+          topic.partitions.add(offsetForLeaderPartition.setPartition(tp.partition))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU1MjQ3Mw=="}, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NzM2NzcyOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNjoxNjoyN1rOH80r5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwODoyMzo1N1rOH9PTIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUzOTgxMg==", "bodyText": "I'm wondering if it is reasonable to rely on defaults for some of these. I guess there's value in being explicit, but it is a tad vexing to see the same code repeated for a few of these cases.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533539812", "createdAt": "2020-12-01T16:16:27Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1862,23 +1864,51 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n   }\n \n-  def lastOffsetForLeaderEpoch(requestedEpochInfo: Map[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData]): Map[TopicPartition, EpochEndOffset] = {\n-    requestedEpochInfo.map { case (tp, partitionData) =>\n-      val epochEndOffset = getPartition(tp) match {\n-        case HostedPartition.Online(partition) =>\n-          partition.lastOffsetForLeaderEpoch(partitionData.currentLeaderEpoch, partitionData.leaderEpoch,\n-            fetchOnlyFromLeader = true)\n-\n-        case HostedPartition.Offline =>\n-          new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None if metadataCache.contains(tp) =>\n-          new EpochEndOffset(Errors.NOT_LEADER_OR_FOLLOWER, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None =>\n-          new EpochEndOffset(Errors.UNKNOWN_TOPIC_OR_PARTITION, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n+  def lastOffsetForLeaderEpoch(\n+    requestedEpochInfo: Seq[OffsetForLeaderTopic]\n+  ): Seq[OffsetForLeaderTopicResult] = {\n+    requestedEpochInfo.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>\n+        val tp = new TopicPartition(offsetForLeaderTopic.topic, offsetForLeaderPartition.partition)\n+        getPartition(tp) match {\n+          case HostedPartition.Online(partition) =>\n+            val currentLeaderEpochOpt =\n+              if (offsetForLeaderPartition.currentLeaderEpoch == RecordBatch.NO_PARTITION_LEADER_EPOCH)\n+                Optional.empty[Integer]\n+              else\n+                Optional.of[Integer](offsetForLeaderPartition.currentLeaderEpoch)\n+\n+            partition.lastOffsetForLeaderEpoch(\n+              currentLeaderEpochOpt,\n+              offsetForLeaderPartition.leaderEpoch,\n+              fetchOnlyFromLeader = true)\n+\n+          case HostedPartition.Offline =>\n+            new OffsetForLeaderPartitionResult()\n+              .setPartition(offsetForLeaderPartition.partition)\n+              .setErrorCode(Errors.KAFKA_STORAGE_ERROR.code)\n+              .setLeaderEpoch(UNDEFINED_EPOCH)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk3NTg0Mg==", "bodyText": "That makes sense. Let me use them where ever possible. I will also add a default value (-1) for EndOffset in the schema.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533975842", "createdAt": "2020-12-02T08:23:57Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1862,23 +1864,51 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n   }\n \n-  def lastOffsetForLeaderEpoch(requestedEpochInfo: Map[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData]): Map[TopicPartition, EpochEndOffset] = {\n-    requestedEpochInfo.map { case (tp, partitionData) =>\n-      val epochEndOffset = getPartition(tp) match {\n-        case HostedPartition.Online(partition) =>\n-          partition.lastOffsetForLeaderEpoch(partitionData.currentLeaderEpoch, partitionData.leaderEpoch,\n-            fetchOnlyFromLeader = true)\n-\n-        case HostedPartition.Offline =>\n-          new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None if metadataCache.contains(tp) =>\n-          new EpochEndOffset(Errors.NOT_LEADER_OR_FOLLOWER, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None =>\n-          new EpochEndOffset(Errors.UNKNOWN_TOPIC_OR_PARTITION, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n+  def lastOffsetForLeaderEpoch(\n+    requestedEpochInfo: Seq[OffsetForLeaderTopic]\n+  ): Seq[OffsetForLeaderTopicResult] = {\n+    requestedEpochInfo.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>\n+        val tp = new TopicPartition(offsetForLeaderTopic.topic, offsetForLeaderPartition.partition)\n+        getPartition(tp) match {\n+          case HostedPartition.Online(partition) =>\n+            val currentLeaderEpochOpt =\n+              if (offsetForLeaderPartition.currentLeaderEpoch == RecordBatch.NO_PARTITION_LEADER_EPOCH)\n+                Optional.empty[Integer]\n+              else\n+                Optional.of[Integer](offsetForLeaderPartition.currentLeaderEpoch)\n+\n+            partition.lastOffsetForLeaderEpoch(\n+              currentLeaderEpochOpt,\n+              offsetForLeaderPartition.leaderEpoch,\n+              fetchOnlyFromLeader = true)\n+\n+          case HostedPartition.Offline =>\n+            new OffsetForLeaderPartitionResult()\n+              .setPartition(offsetForLeaderPartition.partition)\n+              .setErrorCode(Errors.KAFKA_STORAGE_ERROR.code)\n+              .setLeaderEpoch(UNDEFINED_EPOCH)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUzOTgxMg=="}, "originalCommit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NzM3OTUyOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNjoxODo1OVrOH80zaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwODozMjoyOVrOH9PnDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0MTczOQ==", "bodyText": "Maybe just me, but OffsetForLeaderPartitionResult seems more cumbersome and less descriptive than EpochEndOffset. Would it be worth changing the name in the generated schema?", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533541739", "createdAt": "2020-12-01T16:18:59Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3727,15 +3733,24 @@ public void testOffsetValidationRequestGrouping() {\n             assertTrue(expectedPartitions.size() > 0);\n             allRequestedPartitions.addAll(expectedPartitions);\n \n-            Map<TopicPartition, EpochEndOffset> endOffsets = expectedPartitions.stream().collect(Collectors.toMap(\n-                Function.identity(),\n-                tp -> new EpochEndOffset(Errors.NONE, 4, 0)\n-            ));\n+            OffsetForLeaderEpochResponseData data = new OffsetForLeaderEpochResponseData();\n+            expectedPartitions.forEach(tp -> {\n+                OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+                if (topic == null) {\n+                    topic = new OffsetForLeaderTopicResult().setTopic(tp.topic());\n+                    data.topics().add(topic);\n+                }\n+                topic.partitions().add(new OffsetForLeaderPartitionResult()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk4MDk0Mg==", "bodyText": "I do agree with you. Using EpochEndOffset sounds much better.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533980942", "createdAt": "2020-12-02T08:32:29Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3727,15 +3733,24 @@ public void testOffsetValidationRequestGrouping() {\n             assertTrue(expectedPartitions.size() > 0);\n             allRequestedPartitions.addAll(expectedPartitions);\n \n-            Map<TopicPartition, EpochEndOffset> endOffsets = expectedPartitions.stream().collect(Collectors.toMap(\n-                Function.identity(),\n-                tp -> new EpochEndOffset(Errors.NONE, 4, 0)\n-            ));\n+            OffsetForLeaderEpochResponseData data = new OffsetForLeaderEpochResponseData();\n+            expectedPartitions.forEach(tp -> {\n+                OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+                if (topic == null) {\n+                    topic = new OffsetForLeaderTopicResult().setTopic(tp.topic());\n+                    data.topics().add(topic);\n+                }\n+                topic.partitions().add(new OffsetForLeaderPartitionResult()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0MTczOQ=="}, "originalCommit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NzQyMDkxOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNjoyNzoyMlrOH81MpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwOTowMzoyMVrOH9QwYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0ODE5Ng==", "bodyText": "Not for this patch, but all of this boilerplate we need to build the topic groupings gets annoying. It is such a common case that it might be worth writing a special type that lets the parser construct Map<TopicPartition, Data> directly since that is really what the code wants. Alternatively, maybe we could flatten the schemas and introduce compression.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533548196", "createdAt": "2020-12-01T16:27:22Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3727,15 +3733,24 @@ public void testOffsetValidationRequestGrouping() {\n             assertTrue(expectedPartitions.size() > 0);\n             allRequestedPartitions.addAll(expectedPartitions);\n \n-            Map<TopicPartition, EpochEndOffset> endOffsets = expectedPartitions.stream().collect(Collectors.toMap(\n-                Function.identity(),\n-                tp -> new EpochEndOffset(Errors.NONE, 4, 0)\n-            ));\n+            OffsetForLeaderEpochResponseData data = new OffsetForLeaderEpochResponseData();\n+            expectedPartitions.forEach(tp -> {\n+                OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+                if (topic == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk5OTcxNQ==", "bodyText": "That would be nice, indeed! I have been thinking about this as well but did not have the time to tackle this yet. I have opened a JIRA to track this: https://issues.apache.org/jira/browse/KAFKA-10795.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533999715", "createdAt": "2020-12-02T09:03:21Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3727,15 +3733,24 @@ public void testOffsetValidationRequestGrouping() {\n             assertTrue(expectedPartitions.size() > 0);\n             allRequestedPartitions.addAll(expectedPartitions);\n \n-            Map<TopicPartition, EpochEndOffset> endOffsets = expectedPartitions.stream().collect(Collectors.toMap(\n-                Function.identity(),\n-                tp -> new EpochEndOffset(Errors.NONE, 4, 0)\n-            ));\n+            OffsetForLeaderEpochResponseData data = new OffsetForLeaderEpochResponseData();\n+            expectedPartitions.forEach(tp -> {\n+                OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+                if (topic == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0ODE5Ng=="}, "originalCommit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1Mjc5NDUyOnYy", "diffSide": "LEFT", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxODoxMzoxOFrOH9n7VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwODoyMzoxMFrOH-HwiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM3OTM0OQ==", "bodyText": "In the case of the error code, I think it might be better to be explicit.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r534379349", "createdAt": "2020-12-02T18:13:18Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1839,20 +1839,17 @@ private OffsetsForLeaderEpochResponse createLeaderEpochResponse() {\n             .setPartitions(Arrays.asList(\n                 new OffsetForLeaderPartitionResult()\n                     .setPartition(0)\n-                    .setErrorCode(Errors.NONE.code())\n                     .setLeaderEpoch(1)\n                     .setEndOffset(0),\n                 new OffsetForLeaderPartitionResult()\n                     .setPartition(1)\n-                    .setErrorCode(Errors.NONE.code())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d192b83e0993500cd0345d3aea48a21cdc9ab190"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkwMDg3Mg==", "bodyText": "I don't feel strong either ways so I will follow your suggestion.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r534900872", "createdAt": "2020-12-03T08:23:10Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1839,20 +1839,17 @@ private OffsetsForLeaderEpochResponse createLeaderEpochResponse() {\n             .setPartitions(Arrays.asList(\n                 new OffsetForLeaderPartitionResult()\n                     .setPartition(0)\n-                    .setErrorCode(Errors.NONE.code())\n                     .setLeaderEpoch(1)\n                     .setEndOffset(0),\n                 new OffsetForLeaderPartitionResult()\n                     .setPartition(1)\n-                    .setErrorCode(Errors.NONE.code())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM3OTM0OQ=="}, "originalCommit": {"oid": "d192b83e0993500cd0345d3aea48a21cdc9ab190"}, "originalPosition": 9}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3597, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}