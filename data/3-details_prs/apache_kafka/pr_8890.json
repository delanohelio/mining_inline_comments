{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2MTIwODYw", "number": 8890, "title": "KAFKA-9891: add integration tests for EOS and StandbyTask", "bodyText": "Ports the test from #8886 to trunk -- this should be merged to 2.6 branch.\nOne open question. In 2.6 and trunk we rely on the active tasks to wipe out the store if it crashes. However, assume there is a hard JVM crash and we don't call closeDirty() the store would not be wiped out. Thus, I am wondering, if we would need to fix this (for both active and standby tasks) and do a check on startup if a local store must be wiped out?\nThe current test passes, as we do a proper cleanup after the exception is thrown.\nCall for review @guozhangwang @abbccdda", "createdAt": "2020-06-17T22:06:36Z", "url": "https://github.com/apache/kafka/pull/8890", "merged": true, "mergeCommit": {"oid": "3c43adff1d4562c6b33732f399691c9e2f887903"}, "closed": true, "closedAt": "2020-06-19T16:05:55Z", "author": {"login": "mjsax"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcsodIHAH2gAyNDM2MTIwODYwOjM4NmM0Mjg2OWQyMzEwODg1NmNjNDI2ZWZmYzdlNjM0MzgwNDNkODY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcs3xRmgFqTQzNDI4MjExMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "386c42869d23108856cc426effc7e63438043d86", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/386c42869d23108856cc426effc7e63438043d86", "committedDate": "2020-06-19T01:06:46Z", "message": "KAFKA-9891: add integration tests for EOS and StandbyTask"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "386c42869d23108856cc426effc7e63438043d86", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/386c42869d23108856cc426effc7e63438043d86", "committedDate": "2020-06-19T01:06:46Z", "message": "KAFKA-9891: add integration tests for EOS and StandbyTask"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM0MjgyMTEx", "url": "https://github.com/apache/kafka/pull/8890#pullrequestreview-434282111", "createdAt": "2020-06-19T18:52:23Z", "commit": {"oid": "386c42869d23108856cc426effc7e63438043d86"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxODo1NDo1N1rOGmeduQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxODo1NzowNFrOGmehIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk5ODIwMQ==", "bodyText": "Did you mean \"stale\"?", "url": "https://github.com/apache/kafka/pull/8890#discussion_r442998201", "createdAt": "2020-06-19T18:54:57Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StandbyTaskEOSIntegrationTest.java", "diffHunk": "@@ -151,6 +173,198 @@ private KafkaStreams buildStreamWithDirtyStateDir(final String stateDirPath,\n         return new KafkaStreams(builder.build(), props);\n     }\n \n+    @Test\n+    public void shouldWipeOutStandbyStateDirectoryIfCheckpointIsMissing() throws Exception {\n+        final String base = TestUtils.tempDirectory(appId).getPath();\n+\n+        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+            inputTopic,\n+            Collections.singletonList(\n+                new KeyValue<>(KEY_0, 0)\n+            ),\n+            TestUtils.producerConfig(\n+                CLUSTER.bootstrapServers(),\n+                IntegerSerializer.class,\n+                IntegerSerializer.class,\n+                new Properties()\n+            ),\n+            10L\n+        );\n+\n+        try (\n+            final KafkaStreams streamInstanceOne = buildWithDeduplicationTopology(base + \"-1\");\n+            final KafkaStreams streamInstanceTwo = buildWithDeduplicationTopology(base + \"-2\");\n+            final KafkaStreams streamInstanceOneRecovery = buildWithDeduplicationTopology(base + \"-1\")\n+        ) {\n+            // start first instance and wait for processing\n+            startApplicationAndWaitUntilRunning(Collections.singletonList(streamInstanceOne), Duration.ofSeconds(30));\n+            IntegrationTestUtils.waitUntilMinRecordsReceived(\n+                TestUtils.consumerConfig(\n+                    CLUSTER.bootstrapServers(),\n+                    IntegerDeserializer.class,\n+                    IntegerDeserializer.class\n+                ),\n+                outputTopic,\n+                1\n+            );\n+\n+            // start second instance and wait for standby replication\n+            startApplicationAndWaitUntilRunning(Collections.singletonList(streamInstanceTwo), Duration.ofSeconds(30));\n+            waitForCondition(\n+                () -> streamInstanceTwo.store(\n+                    StoreQueryParameters.fromNameAndType(\n+                        storeName,\n+                        QueryableStoreTypes.<Integer, Integer>keyValueStore()\n+                    ).enableStaleStores()\n+                ).get(KEY_0) != null,\n+                REBALANCE_TIMEOUT,\n+                \"Could not get key from standby store\"\n+            );\n+            // sanity check that first instance is still active\n+            waitForCondition(\n+                () -> streamInstanceOne.store(\n+                    StoreQueryParameters.fromNameAndType(\n+                        storeName,\n+                        QueryableStoreTypes.<Integer, Integer>keyValueStore()\n+                    )\n+                ).get(KEY_0) != null,\n+                \"Could not get key from main store\"\n+            );\n+\n+            // inject poison pill and wait for crash of first instance and recovery on second instance\n+            IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+                inputTopic,\n+                Collections.singletonList(\n+                    new KeyValue<>(KEY_1, 0)\n+                ),\n+                TestUtils.producerConfig(\n+                    CLUSTER.bootstrapServers(),\n+                    IntegerSerializer.class,\n+                    IntegerSerializer.class,\n+                    new Properties()\n+                ),\n+                10L\n+            );\n+            waitForCondition(\n+                () -> streamInstanceOne.state() == KafkaStreams.State.ERROR,\n+                \"Stream instance 1 did not go into error state\"\n+            );\n+            streamInstanceOne.close();\n+\n+            IntegrationTestUtils.waitUntilMinRecordsReceived(\n+                TestUtils.consumerConfig(\n+                    CLUSTER.bootstrapServers(),\n+                    IntegerDeserializer.class,\n+                    IntegerDeserializer.class\n+                ),\n+                outputTopic,\n+                2\n+            );\n+\n+            // \"restart\" first client and wait for standby recovery\n+            // (could actually also be active, but it does not matter as long as we enable \"state stores\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386c42869d23108856cc426effc7e63438043d86"}, "originalPosition": 214}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk5OTA3Mw==", "bodyText": "Do we really need this? It seems like the only thing that depends on knowing which instance would get the active is just waiting for the crash after the poison pill. Could we instead just wait for once of the instances to crash, but not worry about which?", "url": "https://github.com/apache/kafka/pull/8890#discussion_r442999073", "createdAt": "2020-06-19T18:57:04Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StandbyTaskEOSIntegrationTest.java", "diffHunk": "@@ -162,6 +376,8 @@ private Properties props(final String stateDirPath) {\n         streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n         streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n         streamsConfiguration.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 1000);\n+        // need to set to zero to get predictable active/standby task assignments\n+        streamsConfiguration.put(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "386c42869d23108856cc426effc7e63438043d86"}, "originalPosition": 325}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 653, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}