{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQyOTE0ODg1", "number": 8970, "title": "MINOR: Improve logging around initial log loading", "bodyText": "Users often get confused after an unclean shutdown when log recovery takes a long time. This patch attempts to make the logging clearer and provide a simple indication of loading progress.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-07-01T19:13:11Z", "url": "https://github.com/apache/kafka/pull/8970", "merged": true, "mergeCommit": {"oid": "2a4d938ef00edfdde7279cd16ff2e01f06416596"}, "closed": true, "closedAt": "2020-07-06T17:30:17Z", "author": {"login": "hachikuji"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcwvJ3vAH2gAyNDQyOTE0ODg1Ojc0MjYxODMxYjQ2MGZjNjIwZTA2MjllODFiZGJiMzgxMjgyNjMwYmI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcxd9K9AH2gAyNDQyOTE0ODg1OjJmOWUyYmVhZWM4NzBkNjdhMWU4Y2JhMDA1MDM4YzA4MjA2MDJjNTQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/74261831b460fc620e0629e81bdbb381282630bb", "committedDate": "2020-07-01T19:10:46Z", "message": "MINOR: Improve logging around initial log loading"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxMzIwOTc3", "url": "https://github.com/apache/kafka/pull/8970#pullrequestreview-441320977", "createdAt": "2020-07-02T03:11:16Z", "commit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoxMToxN1rOGr77tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMzoyNToxNFrOGr8IbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcyMzg5NQ==", "bodyText": "Have we checked that the dir.toString does what we want? If the path is relative, I think it will only print that.", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448723895", "createdAt": "2020-07-02T03:11:17Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -308,11 +312,11 @@ class LogManager(logDirs: Seq[File],\n         threadPools.append(pool)\n \n         val cleanShutdownFile = new File(dir, Log.CleanShutdownFile)\n-\n         if (cleanShutdownFile.exists) {\n-          debug(s\"Found clean shutdown file. Skipping recovery for all logs in data directory: ${dir.getAbsolutePath}\")\n+          info(s\"Skipping recovery for all logs in $dir since clean shutdown file was found\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcyNjA4Nw==", "bodyText": "We should fix this and related code to use hiResClockMs since it's monotonic.", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448726087", "createdAt": "2020-07-02T03:20:41Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -321,25 +325,32 @@ class LogManager(logDirs: Seq[File],\n           recoveryPoints = this.recoveryPointCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir\", e)\n-            warn(\"Resetting the recovery checkpoint to 0\")\n+            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir, \" +\n+              \"resetting the recovery checkpoint to 0\", e)\n         }\n \n         var logStartOffsets = Map[TopicPartition, Long]()\n         try {\n           logStartOffsets = this.logStartOffsetCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir\", e)\n+            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir, \" +\n+              \"resetting to the base offset of the first segment\", e)\n         }\n \n-        val jobsForDir = for {\n-          dirContent <- Option(dir.listFiles).toList\n-          logDir <- dirContent if logDir.isDirectory\n-        } yield {\n+        val logsToLoad = Option(dir.listFiles).getOrElse(Array.empty).filter(_.isDirectory)\n+        val numRemainingLogsToLoad = new AtomicInteger(logsToLoad.length)\n+\n+        val jobsForDir = logsToLoad.map { logDir =>\n           val runnable: Runnable = () => {\n             try {\n-              loadLog(logDir, recoveryPoints, logStartOffsets)\n+              debug(s\"Loading log $logDir\")\n+              val logLoadStartMs = time.milliseconds()\n+              val log = loadLog(logDir, recoveryPoints, logStartOffsets)\n+              numRemainingLogsToLoad.decrementAndGet()\n+              info(s\"Completed load of $log with ${log.numberOfSegments} segments \" +\n+                s\"in ${time.milliseconds() - logLoadStartMs}ms \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcyNjQ4NQ==", "bodyText": "Can we keep the variable here and then use it in the log below? Also, should we decrement the value if there's an exception?", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448726485", "createdAt": "2020-07-02T03:22:18Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -321,25 +325,32 @@ class LogManager(logDirs: Seq[File],\n           recoveryPoints = this.recoveryPointCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir\", e)\n-            warn(\"Resetting the recovery checkpoint to 0\")\n+            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir, \" +\n+              \"resetting the recovery checkpoint to 0\", e)\n         }\n \n         var logStartOffsets = Map[TopicPartition, Long]()\n         try {\n           logStartOffsets = this.logStartOffsetCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir\", e)\n+            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir, \" +\n+              \"resetting to the base offset of the first segment\", e)\n         }\n \n-        val jobsForDir = for {\n-          dirContent <- Option(dir.listFiles).toList\n-          logDir <- dirContent if logDir.isDirectory\n-        } yield {\n+        val logsToLoad = Option(dir.listFiles).getOrElse(Array.empty).filter(_.isDirectory)\n+        val numRemainingLogsToLoad = new AtomicInteger(logsToLoad.length)\n+\n+        val jobsForDir = logsToLoad.map { logDir =>\n           val runnable: Runnable = () => {\n             try {\n-              loadLog(logDir, recoveryPoints, logStartOffsets)\n+              debug(s\"Loading log $logDir\")\n+              val logLoadStartMs = time.milliseconds()\n+              val log = loadLog(logDir, recoveryPoints, logStartOffsets)\n+              numRemainingLogsToLoad.decrementAndGet()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcyNzE0OA==", "bodyText": "Could we maybe say something like Loaded n logs after... where n is the number of logs we loaded?", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448727148", "createdAt": "2020-07-02T03:25:14Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -379,7 +391,7 @@ class LogManager(logDirs: Seq[File],\n       threadPools.foreach(_.shutdown())\n     }\n \n-    info(s\"Logs loading complete in ${time.milliseconds - startMs} ms.\")\n+    info(s\"Log loading completed after ${time.milliseconds - startMs}ms.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 105}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxMzQ0NjI0", "url": "https://github.com/apache/kafka/pull/8970#pullrequestreview-441344624", "createdAt": "2020-07-02T04:37:57Z", "commit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwNDozNzo1N1rOGr9KJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwNDozNzo1N1rOGr9KJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc0Mzk3Mw==", "bodyText": "Nit: an alternative would be to say something like 3 out of 5 logs have been loaded in $dir. It gives a slightly better sense of progression.", "url": "https://github.com/apache/kafka/pull/8970#discussion_r448743973", "createdAt": "2020-07-02T04:37:57Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -321,25 +325,32 @@ class LogManager(logDirs: Seq[File],\n           recoveryPoints = this.recoveryPointCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir\", e)\n-            warn(\"Resetting the recovery checkpoint to 0\")\n+            warn(s\"Error occurred while reading recovery-point-offset-checkpoint file of directory $dir, \" +\n+              \"resetting the recovery checkpoint to 0\", e)\n         }\n \n         var logStartOffsets = Map[TopicPartition, Long]()\n         try {\n           logStartOffsets = this.logStartOffsetCheckpoints(dir).read()\n         } catch {\n           case e: Exception =>\n-            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir\", e)\n+            warn(s\"Error occurred while reading log-start-offset-checkpoint file of directory $dir, \" +\n+              \"resetting to the base offset of the first segment\", e)\n         }\n \n-        val jobsForDir = for {\n-          dirContent <- Option(dir.listFiles).toList\n-          logDir <- dirContent if logDir.isDirectory\n-        } yield {\n+        val logsToLoad = Option(dir.listFiles).getOrElse(Array.empty).filter(_.isDirectory)\n+        val numRemainingLogsToLoad = new AtomicInteger(logsToLoad.length)\n+\n+        val jobsForDir = logsToLoad.map { logDir =>\n           val runnable: Runnable = () => {\n             try {\n-              loadLog(logDir, recoveryPoints, logStartOffsets)\n+              debug(s\"Loading log $logDir\")\n+              val logLoadStartMs = time.milliseconds()\n+              val log = loadLog(logDir, recoveryPoints, logStartOffsets)\n+              numRemainingLogsToLoad.decrementAndGet()\n+              info(s\"Completed load of $log with ${log.numberOfSegments} segments \" +\n+                s\"in ${time.milliseconds() - logLoadStartMs}ms \" +\n+                s\"(${numRemainingLogsToLoad.get} logs remaining to load in $dir)\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74261831b460fc620e0629e81bdbb381282630bb"}, "originalPosition": 88}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77bc7335122ead4ee67c5a2c53d24ebffb63336b", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/77bc7335122ead4ee67c5a2c53d24ebffb63336b", "committedDate": "2020-07-02T18:10:27Z", "message": "Review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxOTI2MTYz", "url": "https://github.com/apache/kafka/pull/8970#pullrequestreview-441926163", "createdAt": "2020-07-02T18:19:56Z", "commit": {"oid": "77bc7335122ead4ee67c5a2c53d24ebffb63336b"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODoxOTo1NlrOGsYnLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODoxOTo1NlrOGsYnLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE5Mzc3NQ==", "bodyText": "Did you mean to include the word logs somewhere in this sentence?", "url": "https://github.com/apache/kafka/pull/8970#discussion_r449193775", "createdAt": "2020-07-02T18:19:56Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -379,7 +396,7 @@ class LogManager(logDirs: Seq[File],\n       threadPools.foreach(_.shutdown())\n     }\n \n-    info(s\"Logs loading complete in ${time.milliseconds - startMs} ms.\")\n+    info(s\"Loaded $numTotalLogs in ${time.hiResClockMs() - startMs}ms.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77bc7335122ead4ee67c5a2c53d24ebffb63336b"}, "originalPosition": 125}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2f9e2beaec870d67a1e8cba005038c0820602c54", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/2f9e2beaec870d67a1e8cba005038c0820602c54", "committedDate": "2020-07-04T01:42:26Z", "message": "Add missing 'logs' to clarify what was loaded"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1133, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}