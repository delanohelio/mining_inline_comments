{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE4MTgyMzI3", "number": 8668, "title": "KAFKA-9987: optimize sticky assignment algorithm for same-subscription case", "bodyText": "Motivation and pseudo code algorithm in the ticket.\nAdded a scale test with large number of topic partitions and consumers and 30s timeout.\nWith these changes, assignment with 2,000 consumers and 200 topics with 2,000 each completes within a few seconds.\nPorting the same test to trunk, it took 2 minutes even with a 100x reduction in the number of topics (ie, 2 minutes for 2,000 consumers and 2 topics with 2,000 partitions)\nShould be cherry-picked to 2.6, 2.5, and 2.4", "createdAt": "2020-05-14T18:46:15Z", "url": "https://github.com/apache/kafka/pull/8668", "merged": true, "mergeCommit": {"oid": "c6633a157eec1712116d294eb3785a96cba4e331"}, "closed": true, "closedAt": "2020-06-01T22:57:16Z", "author": {"login": "ableegoldman"}, "timelineItems": {"totalCount": 34, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcl3oJzgFqTQyMDU4NTI0OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcnXp_ygFqTQyMjg2NTQ4OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNTg1MjQ5", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-420585249", "createdAt": "2020-05-29T00:49:54Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMDo0OTo1NVrOGcLZnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMDo0OTo1NVrOGcLZnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIwMDA5Mg==", "bodyText": "We can remove all this since we checked for identical subscriptions at the start, so we know that they are not", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432200092", "createdAt": "2020-05-29T00:49:55Z", "author": {"login": "ableegoldman"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignor.java", "diffHunk": "@@ -303,79 +469,17 @@ private int getBalanceScore(Map<String, List<TopicPartition>> assignment) {\n                                                 Map<String, List<TopicPartition>> consumer2AllPotentialPartitions) {\n         List<TopicPartition> sortedPartitions = new ArrayList<>();\n \n-        if (!isFreshAssignment && areSubscriptionsIdentical(partition2AllPotentialConsumers, consumer2AllPotentialPartitions)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 200}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dbac63dde4ce596ed26e422ec4449ece4113f15e", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/dbac63dde4ce596ed26e422ec4449ece4113f15e", "committedDate": "2020-05-29T01:00:48Z", "message": "refactor AbstractStickyAssignor and implement optimized algorithm"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b2a0113c37e8b4959d2c33af25b67250f0b9938", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/2b2a0113c37e8b4959d2c33af25b67250f0b9938", "committedDate": "2020-05-29T01:00:48Z", "message": "rough benchmarks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a812d348b8b735a941a515ac4d7ea49a2e3e8c63", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/a812d348b8b735a941a515ac4d7ea49a2e3e8c63", "committedDate": "2020-05-29T01:00:48Z", "message": "remove areSubscriptionsIdentical when we know they are not"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "50486af2af1ae608adb295224f0aff4cb95511f5", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/50486af2af1ae608adb295224f0aff4cb95511f5", "committedDate": "2020-05-29T01:00:48Z", "message": "simplify"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "afbed930a925cff1b11ec4192b5415334ea5e0b9", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/afbed930a925cff1b11ec4192b5415334ea5e0b9", "committedDate": "2020-05-29T01:00:48Z", "message": "renaming"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "afbed930a925cff1b11ec4192b5415334ea5e0b9", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/afbed930a925cff1b11ec4192b5415334ea5e0b9", "committedDate": "2020-05-29T01:00:48Z", "message": "renaming"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "52c328578c71945dd708ceb7974b99c1e6f7255f", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/52c328578c71945dd708ceb7974b99c1e6f7255f", "committedDate": "2020-05-29T01:07:03Z", "message": "initialize movements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7a6fa4fdd9cfc2e72a0f5ee43dc68544c60a8d7", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f7a6fa4fdd9cfc2e72a0f5ee43dc68544c60a8d7", "committedDate": "2020-05-29T02:21:58Z", "message": "trim by subscription"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f3a074fbd7083af008fcc3115f450e169473eec6", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f3a074fbd7083af008fcc3115f450e169473eec6", "committedDate": "2020-05-29T02:58:57Z", "message": "fixing tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNjIyMjQ4", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-420622248", "createdAt": "2020-05-29T03:01:16Z", "commit": {"oid": "f3a074fbd7083af008fcc3115f450e169473eec6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMzowMToxNlrOGcNQoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMzowMToxNlrOGcNQoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIzMDU2MA==", "bodyText": "This test was testing an illegal state to begin with: you should never have two consumers in the same generation claim to own the same partition. That fact is the entire reason for the generation field to be added to the StickyAssignor's subscription userdata to begin with.", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432230560", "createdAt": "2020-05-29T03:01:16Z", "author": {"login": "ableegoldman"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/StickyAssignorTest.java", "diffHunk": "@@ -169,10 +169,10 @@ public void testAssignmentWithConflictingPreviousGenerations() {\n         TopicPartition tp5 = new TopicPartition(topic, 5);\n \n         List<TopicPartition> c1partitions0 = partitions(tp0, tp1, tp4);\n-        List<TopicPartition> c2partitions0 = partitions(tp0, tp2, tp3);\n+        List<TopicPartition> c2partitions0 = partitions(tp0, tp1, tp2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3a074fbd7083af008fcc3115f450e169473eec6"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNjIyOTEz", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-420622913", "createdAt": "2020-05-29T03:03:51Z", "commit": {"oid": "f3a074fbd7083af008fcc3115f450e169473eec6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMzowMzo1MVrOGcNS4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMzowMzo1MVrOGcNS4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIzMTEzNw==", "bodyText": "See comment above: this test was starting from an illegal state. Also, it doesn't make sense to place this in the AbstractStickyAssignorTest as the cooperative assignor can't have conflicting previous assignments. If a member thinks it still owns a partition that now belongs to another member, it will have to invoke onPartitionsLost before rejoining the group", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432231137", "createdAt": "2020-05-29T03:03:51Z", "author": {"login": "ableegoldman"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignorTest.java", "diffHunk": "@@ -582,35 +578,6 @@ public void testNoExceptionThrownWhenOnlySubscribedTopicDeleted() {\n         assertTrue(assignment.get(consumerId).isEmpty());\n     }\n \n-    @Test\n-    public void testConflictingPreviousAssignments() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3a074fbd7083af008fcc3115f450e169473eec6"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff28badb115e61e2d08268d89b0db406c78426a8", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/ff28badb115e61e2d08268d89b0db406c78426a8", "committedDate": "2020-05-29T03:04:55Z", "message": "remove unused imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a119767f8773b88a20c33d125c1b09845ff906f", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/9a119767f8773b88a20c33d125c1b09845ff906f", "committedDate": "2020-05-29T03:17:56Z", "message": "improve data parallelism"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "63e797ff3951489c731daa7a846af75458490bc4", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/63e797ff3951489c731daa7a846af75458490bc4", "committedDate": "2020-05-29T03:23:20Z", "message": "use Optional.empty"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e3975653d19f97d6eb61cb24e4cb25b7965e16c1", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/e3975653d19f97d6eb61cb24e4cb25b7965e16c1", "committedDate": "2020-05-29T04:08:02Z", "message": "apply timeout and increase number of topics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNjQwNzY0", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-420640764", "createdAt": "2020-05-29T04:13:12Z", "commit": {"oid": "e3975653d19f97d6eb61cb24e4cb25b7965e16c1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwNDoxMzoxMlrOGcONDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwNDoxMzoxMlrOGcONDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI0NjAyOA==", "bodyText": "On trunk, this test fails (hits the 30s timeout) even when you reduce the number of topics to just 1", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432246028", "createdAt": "2020-05-29T04:13:12Z", "author": {"login": "ableegoldman"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignorTest.java", "diffHunk": "@@ -425,8 +422,36 @@ public void testSameSubscriptions() {\n         assertTrue(assignor.isSticky());\n     }\n \n+    @Test(timeout = 30 * 1000)\n+    public void testLargeAssignmentAndGroupWithUniformSubscription() {\n+        int topicCount = 200;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3975653d19f97d6eb61cb24e4cb25b7965e16c1"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMjE3ODIw", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-421217820", "createdAt": "2020-05-29T19:12:44Z", "commit": {"oid": "e3975653d19f97d6eb61cb24e4cb25b7965e16c1"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxOToxMjo0NFrOGco7QA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxOTozMTowNVrOGcpZwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY4Mzg0MA==", "bodyText": "nit: to be consistent, we can just add consumer to membersWithOldGeneration and then let them to be cleared at the end.", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432683840", "createdAt": "2020-05-29T19:12:44Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignor.java", "diffHunk": "@@ -65,9 +69,182 @@ public MemberData(List<TopicPartition> partitions, Optional<Integer> generation)\n     @Override\n     public Map<String, List<TopicPartition>> assign(Map<String, Integer> partitionsPerTopic,\n                                                     Map<String, Subscription> subscriptions) {\n+        Map<String, List<TopicPartition>> consumerToOwnedPartitions = new HashMap<>();\n+        Set<String> subscribedTopics = new HashSet<>();\n+        if (allSubscriptionsEqual(subscriptions, consumerToOwnedPartitions, subscribedTopics)) {\n+            log.debug(\"Detected that all consumers were subscribed to same set of topics, invoking the \"\n+                          + \"optimized assignment algorithm\");\n+            return constrainedAssign(partitionsPerTopic, subscribedTopics, consumerToOwnedPartitions);\n+        } else {\n+            log.debug(\"Detected that all not consumers were subscribed to same set of topics, falling back to the \"\n+                          + \"general case assignment algorithm\");\n+            return generalAssign(partitionsPerTopic, subscriptions);\n+        }\n+    }\n+\n+    private boolean allSubscriptionsEqual(Map<String, Subscription> subscriptions,\n+                                          Map<String, List<TopicPartition>> consumerToOwnedPartitions,\n+                                          Set<String> subscribedTopics) {\n+        Set<String> membersWithOldGeneration = new HashSet<>();\n+        Set<String> membersOfCurrentHighestGeneration = new HashSet<>();\n+        int maxGeneration = -1;\n+\n+        for (Map.Entry<String, Subscription> subscriptionEntry : subscriptions.entrySet()) {\n+            String consumer = subscriptionEntry.getKey();\n+            Subscription subscription = subscriptionEntry.getValue();\n+\n+            // initialize the subscribed topics set if this is the first subscription\n+            if (subscribedTopics.isEmpty()) {\n+                subscribedTopics.addAll(subscription.topics());\n+            } else if (!(subscription.topics().size() == subscribedTopics.size()\n+                && subscribedTopics.containsAll(subscription.topics()))) {\n+                return false;\n+            }\n+\n+            MemberData memberData = memberData(subscription);\n+\n+            // If this member's generation is lower than the current max, or it is not present while\n+            // other generations are, consider it as having lost its owned partition\n+            if (!memberData.generation.isPresent() && maxGeneration > 0\n+                    || memberData.generation.isPresent() && memberData.generation.get() < maxGeneration) {\n+                consumerToOwnedPartitions.put(consumer, new ArrayList<>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3975653d19f97d6eb61cb24e4cb25b7965e16c1"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MDIyMA==", "bodyText": "Is it possible that this unfilled consumer has N+1 remaining capacity, while there's only N max consumer only?", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432690220", "createdAt": "2020-05-29T19:27:51Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignor.java", "diffHunk": "@@ -65,9 +69,182 @@ public MemberData(List<TopicPartition> partitions, Optional<Integer> generation)\n     @Override\n     public Map<String, List<TopicPartition>> assign(Map<String, Integer> partitionsPerTopic,\n                                                     Map<String, Subscription> subscriptions) {\n+        Map<String, List<TopicPartition>> consumerToOwnedPartitions = new HashMap<>();\n+        Set<String> subscribedTopics = new HashSet<>();\n+        if (allSubscriptionsEqual(subscriptions, consumerToOwnedPartitions, subscribedTopics)) {\n+            log.debug(\"Detected that all consumers were subscribed to same set of topics, invoking the \"\n+                          + \"optimized assignment algorithm\");\n+            return constrainedAssign(partitionsPerTopic, subscribedTopics, consumerToOwnedPartitions);\n+        } else {\n+            log.debug(\"Detected that all not consumers were subscribed to same set of topics, falling back to the \"\n+                          + \"general case assignment algorithm\");\n+            return generalAssign(partitionsPerTopic, subscriptions);\n+        }\n+    }\n+\n+    private boolean allSubscriptionsEqual(Map<String, Subscription> subscriptions,\n+                                          Map<String, List<TopicPartition>> consumerToOwnedPartitions,\n+                                          Set<String> subscribedTopics) {\n+        Set<String> membersWithOldGeneration = new HashSet<>();\n+        Set<String> membersOfCurrentHighestGeneration = new HashSet<>();\n+        int maxGeneration = -1;\n+\n+        for (Map.Entry<String, Subscription> subscriptionEntry : subscriptions.entrySet()) {\n+            String consumer = subscriptionEntry.getKey();\n+            Subscription subscription = subscriptionEntry.getValue();\n+\n+            // initialize the subscribed topics set if this is the first subscription\n+            if (subscribedTopics.isEmpty()) {\n+                subscribedTopics.addAll(subscription.topics());\n+            } else if (!(subscription.topics().size() == subscribedTopics.size()\n+                && subscribedTopics.containsAll(subscription.topics()))) {\n+                return false;\n+            }\n+\n+            MemberData memberData = memberData(subscription);\n+\n+            // If this member's generation is lower than the current max, or it is not present while\n+            // other generations are, consider it as having lost its owned partition\n+            if (!memberData.generation.isPresent() && maxGeneration > 0\n+                    || memberData.generation.isPresent() && memberData.generation.get() < maxGeneration) {\n+                consumerToOwnedPartitions.put(consumer, new ArrayList<>());\n+            } else {\n+                // If the current member's generation is higher, all the previous owned partitions are invalid\n+                if (memberData.generation.isPresent() && memberData.generation.get() > maxGeneration) {\n+                    membersWithOldGeneration.addAll(membersOfCurrentHighestGeneration);\n+                    membersOfCurrentHighestGeneration.clear();\n+                    maxGeneration = memberData.generation.get();\n+                }\n+                membersOfCurrentHighestGeneration.add(consumer);\n+                List<TopicPartition> ownedPartitions = memberData.partitions.stream()\n+                    .filter(tp -> subscribedTopics.contains(tp.topic()))\n+                    .collect(Collectors.toList());\n+                consumerToOwnedPartitions.put(consumer, ownedPartitions);\n+            }\n+        }\n+\n+        for (String consumer : membersWithOldGeneration) {\n+            consumerToOwnedPartitions.get(consumer).clear();\n+        }\n+        return true;\n+    }\n+\n+    private Map<String, List<TopicPartition>> constrainedAssign(Map<String, Integer> partitionsPerTopic,\n+                                                                Set<String> subscribedTopics,\n+                                                                Map<String, List<TopicPartition>> consumerToOwnedPartitions) {\n+        SortedSet<TopicPartition> unassignedPartitions = getTopicPartitions(partitionsPerTopic, subscribedTopics);\n+\n+        // Each consumer should end up in exactly one of the below\n+        List<String> unfilledMembers = new LinkedList<>();\n+        Queue<String> maxCapacityMembers = new LinkedList<>();\n+        Queue<String> minCapacityMembers = new LinkedList<>();\n+\n+        int numberOfConsumers = consumerToOwnedPartitions.size();\n+        int minQuota = (int) Math.floor(((double)unassignedPartitions.size()) / numberOfConsumers);\n+        int maxQuota = (int) Math.ceil(((double)unassignedPartitions.size()) / numberOfConsumers);\n+\n+        // initialize the assignment map with an empty array of size minQuota for all members\n+        Map<String, List<TopicPartition>> assignment = new HashMap<>(\n+            consumerToOwnedPartitions.keySet().stream().collect(Collectors.toMap(c -> c, c -> new ArrayList<>(minQuota))));\n+\n+        for (Map.Entry<String, List<TopicPartition>> consumerEntry : consumerToOwnedPartitions.entrySet()) {\n+            String consumer = consumerEntry.getKey();\n+            List<TopicPartition> ownedPartitions = consumerEntry.getValue();\n+\n+            if (ownedPartitions.size() < minQuota) {\n+                assignment.get(consumer).addAll(ownedPartitions);\n+                unassignedPartitions.removeAll(ownedPartitions);\n+                unfilledMembers.add(consumer);\n+            } else if (ownedPartitions.size() == minQuota) {\n+                assignment.get(consumer).addAll(ownedPartitions);\n+                unassignedPartitions.removeAll(ownedPartitions);\n+                minCapacityMembers.add(consumer);\n+            } else {\n+                List<TopicPartition> assignmentPartitions = assignment.get(consumer);\n+                Iterator<TopicPartition> ownedPartitionsIter = ownedPartitions.iterator();\n+                for (int i = 0; i < maxQuota; ++i) {\n+                    TopicPartition tp = ownedPartitionsIter.next();\n+                    assignmentPartitions.add(tp);\n+                    unassignedPartitions.remove(tp);\n+                }\n+                maxCapacityMembers.add(consumer);\n+            }\n+        }\n+\n+        Collections.sort(unfilledMembers);\n+        Iterator<TopicPartition> unassignedPartitionsIter = unassignedPartitions.iterator();\n+\n+        while (!unfilledMembers.isEmpty() && !unassignedPartitions.isEmpty()) {\n+            Iterator<String> unfilledConsumerIter = unfilledMembers.iterator();\n+\n+            while (unfilledConsumerIter.hasNext()) {\n+                String consumer = unfilledConsumerIter.next();\n+                List<TopicPartition> consumerAssignment = assignment.get(consumer);\n+\n+                if (unassignedPartitionsIter.hasNext()) {\n+                    consumerAssignment.add(unassignedPartitionsIter.next());\n+                    unassignedPartitionsIter.remove();\n+                } else {\n+                    break;\n+                }\n+\n+                if (consumerAssignment.size() == minQuota) {\n+                    minCapacityMembers.add(consumer);\n+                    unfilledConsumerIter.remove();\n+                }\n+            }\n+        }\n+\n+        // If we ran out of unassigned partitions before filling all consumers, we need to start stealing partitions\n+        // from the over-full consumers at max capacity\n+        for (String consumer : unfilledMembers) {\n+            List<TopicPartition> consumerAssignment = assignment.get(consumer);\n+            int remainingCapacity = minQuota - consumerAssignment.size();\n+            while (remainingCapacity > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3975653d19f97d6eb61cb24e4cb25b7965e16c1"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MTY0OQ==", "bodyText": "NVM, I realized it should never happen.", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432691649", "createdAt": "2020-05-29T19:31:05Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignor.java", "diffHunk": "@@ -65,9 +69,182 @@ public MemberData(List<TopicPartition> partitions, Optional<Integer> generation)\n     @Override\n     public Map<String, List<TopicPartition>> assign(Map<String, Integer> partitionsPerTopic,\n                                                     Map<String, Subscription> subscriptions) {\n+        Map<String, List<TopicPartition>> consumerToOwnedPartitions = new HashMap<>();\n+        Set<String> subscribedTopics = new HashSet<>();\n+        if (allSubscriptionsEqual(subscriptions, consumerToOwnedPartitions, subscribedTopics)) {\n+            log.debug(\"Detected that all consumers were subscribed to same set of topics, invoking the \"\n+                          + \"optimized assignment algorithm\");\n+            return constrainedAssign(partitionsPerTopic, subscribedTopics, consumerToOwnedPartitions);\n+        } else {\n+            log.debug(\"Detected that all not consumers were subscribed to same set of topics, falling back to the \"\n+                          + \"general case assignment algorithm\");\n+            return generalAssign(partitionsPerTopic, subscriptions);\n+        }\n+    }\n+\n+    private boolean allSubscriptionsEqual(Map<String, Subscription> subscriptions,\n+                                          Map<String, List<TopicPartition>> consumerToOwnedPartitions,\n+                                          Set<String> subscribedTopics) {\n+        Set<String> membersWithOldGeneration = new HashSet<>();\n+        Set<String> membersOfCurrentHighestGeneration = new HashSet<>();\n+        int maxGeneration = -1;\n+\n+        for (Map.Entry<String, Subscription> subscriptionEntry : subscriptions.entrySet()) {\n+            String consumer = subscriptionEntry.getKey();\n+            Subscription subscription = subscriptionEntry.getValue();\n+\n+            // initialize the subscribed topics set if this is the first subscription\n+            if (subscribedTopics.isEmpty()) {\n+                subscribedTopics.addAll(subscription.topics());\n+            } else if (!(subscription.topics().size() == subscribedTopics.size()\n+                && subscribedTopics.containsAll(subscription.topics()))) {\n+                return false;\n+            }\n+\n+            MemberData memberData = memberData(subscription);\n+\n+            // If this member's generation is lower than the current max, or it is not present while\n+            // other generations are, consider it as having lost its owned partition\n+            if (!memberData.generation.isPresent() && maxGeneration > 0\n+                    || memberData.generation.isPresent() && memberData.generation.get() < maxGeneration) {\n+                consumerToOwnedPartitions.put(consumer, new ArrayList<>());\n+            } else {\n+                // If the current member's generation is higher, all the previous owned partitions are invalid\n+                if (memberData.generation.isPresent() && memberData.generation.get() > maxGeneration) {\n+                    membersWithOldGeneration.addAll(membersOfCurrentHighestGeneration);\n+                    membersOfCurrentHighestGeneration.clear();\n+                    maxGeneration = memberData.generation.get();\n+                }\n+                membersOfCurrentHighestGeneration.add(consumer);\n+                List<TopicPartition> ownedPartitions = memberData.partitions.stream()\n+                    .filter(tp -> subscribedTopics.contains(tp.topic()))\n+                    .collect(Collectors.toList());\n+                consumerToOwnedPartitions.put(consumer, ownedPartitions);\n+            }\n+        }\n+\n+        for (String consumer : membersWithOldGeneration) {\n+            consumerToOwnedPartitions.get(consumer).clear();\n+        }\n+        return true;\n+    }\n+\n+    private Map<String, List<TopicPartition>> constrainedAssign(Map<String, Integer> partitionsPerTopic,\n+                                                                Set<String> subscribedTopics,\n+                                                                Map<String, List<TopicPartition>> consumerToOwnedPartitions) {\n+        SortedSet<TopicPartition> unassignedPartitions = getTopicPartitions(partitionsPerTopic, subscribedTopics);\n+\n+        // Each consumer should end up in exactly one of the below\n+        List<String> unfilledMembers = new LinkedList<>();\n+        Queue<String> maxCapacityMembers = new LinkedList<>();\n+        Queue<String> minCapacityMembers = new LinkedList<>();\n+\n+        int numberOfConsumers = consumerToOwnedPartitions.size();\n+        int minQuota = (int) Math.floor(((double)unassignedPartitions.size()) / numberOfConsumers);\n+        int maxQuota = (int) Math.ceil(((double)unassignedPartitions.size()) / numberOfConsumers);\n+\n+        // initialize the assignment map with an empty array of size minQuota for all members\n+        Map<String, List<TopicPartition>> assignment = new HashMap<>(\n+            consumerToOwnedPartitions.keySet().stream().collect(Collectors.toMap(c -> c, c -> new ArrayList<>(minQuota))));\n+\n+        for (Map.Entry<String, List<TopicPartition>> consumerEntry : consumerToOwnedPartitions.entrySet()) {\n+            String consumer = consumerEntry.getKey();\n+            List<TopicPartition> ownedPartitions = consumerEntry.getValue();\n+\n+            if (ownedPartitions.size() < minQuota) {\n+                assignment.get(consumer).addAll(ownedPartitions);\n+                unassignedPartitions.removeAll(ownedPartitions);\n+                unfilledMembers.add(consumer);\n+            } else if (ownedPartitions.size() == minQuota) {\n+                assignment.get(consumer).addAll(ownedPartitions);\n+                unassignedPartitions.removeAll(ownedPartitions);\n+                minCapacityMembers.add(consumer);\n+            } else {\n+                List<TopicPartition> assignmentPartitions = assignment.get(consumer);\n+                Iterator<TopicPartition> ownedPartitionsIter = ownedPartitions.iterator();\n+                for (int i = 0; i < maxQuota; ++i) {\n+                    TopicPartition tp = ownedPartitionsIter.next();\n+                    assignmentPartitions.add(tp);\n+                    unassignedPartitions.remove(tp);\n+                }\n+                maxCapacityMembers.add(consumer);\n+            }\n+        }\n+\n+        Collections.sort(unfilledMembers);\n+        Iterator<TopicPartition> unassignedPartitionsIter = unassignedPartitions.iterator();\n+\n+        while (!unfilledMembers.isEmpty() && !unassignedPartitions.isEmpty()) {\n+            Iterator<String> unfilledConsumerIter = unfilledMembers.iterator();\n+\n+            while (unfilledConsumerIter.hasNext()) {\n+                String consumer = unfilledConsumerIter.next();\n+                List<TopicPartition> consumerAssignment = assignment.get(consumer);\n+\n+                if (unassignedPartitionsIter.hasNext()) {\n+                    consumerAssignment.add(unassignedPartitionsIter.next());\n+                    unassignedPartitionsIter.remove();\n+                } else {\n+                    break;\n+                }\n+\n+                if (consumerAssignment.size() == minQuota) {\n+                    minCapacityMembers.add(consumer);\n+                    unfilledConsumerIter.remove();\n+                }\n+            }\n+        }\n+\n+        // If we ran out of unassigned partitions before filling all consumers, we need to start stealing partitions\n+        // from the over-full consumers at max capacity\n+        for (String consumer : unfilledMembers) {\n+            List<TopicPartition> consumerAssignment = assignment.get(consumer);\n+            int remainingCapacity = minQuota - consumerAssignment.size();\n+            while (remainingCapacity > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MDIyMA=="}, "originalCommit": {"oid": "e3975653d19f97d6eb61cb24e4cb25b7965e16c1"}, "originalPosition": 162}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e5eeb7d577df00d89825131c1e097ea5bb5a096e", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/e5eeb7d577df00d89825131c1e097ea5bb5a096e", "committedDate": "2020-05-29T20:55:48Z", "message": "add comment and fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "18b13cb1039865660f5bb807e4771694b42894fa", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/18b13cb1039865660f5bb807e4771694b42894fa", "committedDate": "2020-05-29T21:04:31Z", "message": "remove more unused code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "07267a24afb09deb5077a5e06ab6fee9d8dc1946", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/07267a24afb09deb5077a5e06ab6fee9d8dc1946", "committedDate": "2020-05-29T21:31:20Z", "message": "simplify  a bit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f6ce366c69d1565cc0be552218e019238a0d4988", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f6ce366c69d1565cc0be552218e019238a0d4988", "committedDate": "2020-05-29T21:47:10Z", "message": "remove unnecessary check and  fix test to verify valid state"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9c93d0191c554f468845d1a592b27400be40007", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/d9c93d0191c554f468845d1a592b27400be40007", "committedDate": "2020-05-29T22:00:14Z", "message": "filter by cluster topics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9b243a793c243b5580bf4075c451766ebb49aef", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/e9b243a793c243b5580bf4075c451766ebb49aef", "committedDate": "2020-05-29T22:16:34Z", "message": "simplify owned partition aassignemnt"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad1f63d0ce6c53a1392fd4b1613bb713a5a10791", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/ad1f63d0ce6c53a1392fd4b1613bb713a5a10791", "committedDate": "2020-05-29T22:20:14Z", "message": "can reduce further"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "28d13ba8d382a41018790ca9ba92083bc418ffe4", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/28d13ba8d382a41018790ca9ba92083bc418ffe4", "committedDate": "2020-05-29T22:21:21Z", "message": "condition can be tighter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ec6131486215032cc4fec290b9fac80a463316a", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/7ec6131486215032cc4fec290b9fac80a463316a", "committedDate": "2020-05-29T22:56:08Z", "message": "optimize by tracking reassigned partitions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6210a757738f9886fad4676cd22eeee5227bb863", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/6210a757738f9886fad4676cd22eeee5227bb863", "committedDate": "2020-05-30T00:51:33Z", "message": "sclae to 1million"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMzcwNDc2", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-421370476", "createdAt": "2020-05-30T02:29:09Z", "commit": {"oid": "6210a757738f9886fad4676cd22eeee5227bb863"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjoyOTowOVrOGcwJOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjoyOTowOVrOGcwJOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMjEwNg==", "bodyText": "This is just an optimization for the cooperative case: I found that the assignment time for the eager and cooperative assignor began to diverge once you reached partition counts in the millions. At 10 million partitions for example, the eager assignor hovered around 30s but the cooperative assignor was upwards of 5-6 minutes.\nThe discrepancy was entirely due to the adjustAssignment method needing to compute the set of partitions transferring ownership  in the completed assignment. But we can build up this map during assignment much more efficiently, by taking advantage of the additional context we have at various steps in the algorithm. Tracking and exposing this set to the cooperative assignor cut the assignment time for large partition numbers pretty drastically, putting the cooperative assignor  on par with the eager assignor.", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432802106", "createdAt": "2020-05-30T02:29:09Z", "author": {"login": "ableegoldman"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignor.java", "diffHunk": "@@ -40,7 +43,11 @@\n \n     public static final int DEFAULT_GENERATION = -1;\n \n-    private PartitionMovements partitionMovements;\n+    private PartitionMovements partitionMovements = new PartitionMovements();\n+\n+    // Keep track of the partitions being migrated from one consumer to another during assignment\n+    // so the cooperative assignor can adjust the assignment\n+    protected Map<TopicPartition, String> partitionsTransferringOwnership = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6210a757738f9886fad4676cd22eeee5227bb863"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMzcwNTcw", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-421370570", "createdAt": "2020-05-30T02:30:31Z", "commit": {"oid": "6210a757738f9886fad4676cd22eeee5227bb863"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjozMDozMVrOGcwJng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjozMDozMVrOGcwJng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMjIwNg==", "bodyText": "I didn't bother to include this optimization for the general case. We know that the assignment algorithm itself becomes a bottleneck at only 2,000 partitions, so there's no point optimizing something that only becomes a bottleneck in the millions of partitions", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432802206", "createdAt": "2020-05-30T02:30:31Z", "author": {"login": "ableegoldman"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignor.java", "diffHunk": "@@ -65,9 +72,206 @@ public MemberData(List<TopicPartition> partitions, Optional<Integer> generation)\n     @Override\n     public Map<String, List<TopicPartition>> assign(Map<String, Integer> partitionsPerTopic,\n                                                     Map<String, Subscription> subscriptions) {\n+        Map<String, List<TopicPartition>> consumerToOwnedPartitions = new HashMap<>();\n+        if (allSubscriptionsEqual(partitionsPerTopic.keySet(), subscriptions, consumerToOwnedPartitions)) {\n+            log.debug(\"Detected that all consumers were subscribed to same set of topics, invoking the \"\n+                          + \"optimized assignment algorithm\");\n+            partitionsTransferringOwnership = new HashMap<>();\n+            return constrainedAssign(partitionsPerTopic, consumerToOwnedPartitions);\n+        } else {\n+            log.debug(\"Detected that all not consumers were subscribed to same set of topics, falling back to the \"\n+                          + \"general case assignment algorithm\");\n+            partitionsTransferringOwnership = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6210a757738f9886fad4676cd22eeee5227bb863"}, "originalPosition": 50}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e25a323d7e21aa5a554e43d811ac6eb3e3894055", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/e25a323d7e21aa5a554e43d811ac6eb3e3894055", "committedDate": "2020-05-30T02:34:12Z", "message": "checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMzcxMDEy", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-421371012", "createdAt": "2020-05-30T02:37:57Z", "commit": {"oid": "6210a757738f9886fad4676cd22eeee5227bb863"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjozNzo1N1rOGcwLbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0zMFQwMjozNzo1N1rOGcwLbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgwMjY2OQ==", "bodyText": "This test was also starting with an illegal state -- partitionsPerTopic only contains metadata for topics included in the subscription. I noticed that we don't seem to be testing the actual valid case, where some consumers have ownedPartitions which are no longer in the subscription, so I just adapted this test for the related purpose", "url": "https://github.com/apache/kafka/pull/8668#discussion_r432802669", "createdAt": "2020-05-30T02:37:57Z", "author": {"login": "ableegoldman"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignorTest.java", "diffHunk": "@@ -105,12 +106,16 @@ public void testOnlyAssignsPartitionsFromSubscribedTopics() {\n         String otherTopic = \"other\";\n \n         Map<String, Integer> partitionsPerTopic = new HashMap<>();\n-        partitionsPerTopic.put(topic, 3);\n-        partitionsPerTopic.put(otherTopic, 3);\n-        subscriptions = Collections.singletonMap(consumerId, new Subscription(topics(topic)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6210a757738f9886fad4676cd22eeee5227bb863"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyMTI3MzAw", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-422127300", "createdAt": "2020-06-01T19:40:34Z", "commit": {"oid": "e25a323d7e21aa5a554e43d811ac6eb3e3894055"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyODY1NDg4", "url": "https://github.com/apache/kafka/pull/8668#pullrequestreview-422865488", "createdAt": "2020-06-02T16:42:49Z", "commit": {"oid": "e25a323d7e21aa5a554e43d811ac6eb3e3894055"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjo0Mjo0OVrOGd6lSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjo0Mjo0OVrOGd6lSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAyMTcwNA==", "bodyText": "Just FYI, I introduced this bug right before merging. Luckily the tests caught it -- fix is #8777", "url": "https://github.com/apache/kafka/pull/8668#discussion_r434021704", "createdAt": "2020-06-02T16:42:49Z", "author": {"login": "ableegoldman"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractStickyAssignor.java", "diffHunk": "@@ -65,9 +72,206 @@ public MemberData(List<TopicPartition> partitions, Optional<Integer> generation)\n     @Override\n     public Map<String, List<TopicPartition>> assign(Map<String, Integer> partitionsPerTopic,\n                                                     Map<String, Subscription> subscriptions) {\n+        Map<String, List<TopicPartition>> consumerToOwnedPartitions = new HashMap<>();\n+        if (allSubscriptionsEqual(partitionsPerTopic.keySet(), subscriptions, consumerToOwnedPartitions)) {\n+            log.debug(\"Detected that all consumers were subscribed to same set of topics, invoking the \"\n+                          + \"optimized assignment algorithm\");\n+            partitionsTransferringOwnership = new HashMap<>();\n+            return constrainedAssign(partitionsPerTopic, consumerToOwnedPartitions);\n+        } else {\n+            log.debug(\"Detected that all not consumers were subscribed to same set of topics, falling back to the \"\n+                          + \"general case assignment algorithm\");\n+            partitionsTransferringOwnership = null;\n+            return generalAssign(partitionsPerTopic, subscriptions);\n+        }\n+    }\n+\n+    /**\n+     * Returns true iff all consumers have an identical subscription. Also fills out the passed in\n+     * {@code consumerToOwnedPartitions} with each consumer's previously owned and still-subscribed partitions\n+     */\n+    private boolean allSubscriptionsEqual(Set<String> allTopics,\n+                                          Map<String, Subscription> subscriptions,\n+                                          Map<String, List<TopicPartition>> consumerToOwnedPartitions) {\n+        Set<String> membersWithOldGeneration = new HashSet<>();\n+        Set<String> membersOfCurrentHighestGeneration = new HashSet<>();\n+        int maxGeneration = DEFAULT_GENERATION;\n+\n+        Set<String> subscribedTopics = new HashSet<>();\n+\n+        for (Map.Entry<String, Subscription> subscriptionEntry : subscriptions.entrySet()) {\n+            String consumer = subscriptionEntry.getKey();\n+            Subscription subscription = subscriptionEntry.getValue();\n+\n+            // initialize the subscribed topics set if this is the first subscription\n+            if (subscribedTopics.isEmpty()) {\n+                subscribedTopics.addAll(subscription.topics());\n+            } else if (!(subscription.topics().size() == subscribedTopics.size()\n+                && subscribedTopics.containsAll(subscription.topics()))) {\n+                return false;\n+            }\n+\n+            MemberData memberData = memberData(subscription);\n+\n+            List<TopicPartition> ownedPartitions = new ArrayList<>();\n+            consumerToOwnedPartitions.put(consumer, ownedPartitions);\n+\n+            // Only consider this consumer's owned partitions as valid if it is a member of the current highest\n+            // generation, or it's generation is not present but we have not seen any known generation so far\n+            if (memberData.generation.isPresent() && memberData.generation.get() >= maxGeneration\n+                || !memberData.generation.isPresent() && maxGeneration == DEFAULT_GENERATION) {\n+\n+                membersOfCurrentHighestGeneration.add(consumer);\n+                for (final TopicPartition tp : memberData.partitions) {\n+                    // filter out any topics that no longer exist or aren't part of the current subscription\n+                    if (allTopics.contains(tp.topic())) {\n+                        ownedPartitions.add(tp);\n+                    }\n+                }\n+\n+                // If the current member's generation is higher, all the previous owned partitions are invalid\n+                if (memberData.generation.isPresent() && memberData.generation.get() > maxGeneration) {\n+                    membersWithOldGeneration.addAll(membersOfCurrentHighestGeneration);\n+                    membersOfCurrentHighestGeneration.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e25a323d7e21aa5a554e43d811ac6eb3e3894055"}, "originalPosition": 101}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1001, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}