{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI0MzExMDQ1", "number": 9626, "title": "KAFKA-10545: Create topic IDs and propagate to brokers", "bodyText": "This change takes the topic IDs created in #9473 and propagates them to brokers using LeaderAndIsr Request. It also removes the topic name from the LeaderAndIsr Response, reorganizes the response to be sorted by topic, and includes the topic ID.\nIn addition, the topic ID is persisted to each replica in Log as well as in a file on disk. This file is read on startup and if the topic ID exists, it will be reloaded.\nThis PR bumps the IBP and is expected to be merged at the same time as #9622 as to not bump the protocol twice\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-11-19T23:48:46Z", "url": "https://github.com/apache/kafka/pull/9626", "merged": true, "mergeCommit": {"oid": "1dd1e7f945d7a8c1dc177223cd88800680f1ff46"}, "closed": true, "closedAt": "2020-12-18T22:19:51Z", "author": {"login": "jolshan"}, "timelineItems": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdeWJf7gFqTUzNTM2Mjg3OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdnfI2GAH2gAyNTI0MzExMDQ1OjVmZjc4NDBhNTkyNDY0Y2IxODkzMWIyN2Q0ZmYxZDYxNTdhODZiOTM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1MzYyODc4", "url": "https://github.com/apache/kafka/pull/9626#pullrequestreview-535362878", "createdAt": "2020-11-20T11:53:14Z", "commit": {"oid": "5999b004f0f3931a4cd004f45a1887067d61dab3"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMTo1MzoxNFrOH3MsPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMTo1NjozNlrOH3My9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY0MTY2MA==", "bodyText": "can be changed into topics.contains()", "url": "https://github.com/apache/kafka/pull/9626#discussion_r527641660", "createdAt": "2020-11-20T11:53:14Z", "author": {"login": "dengziming"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1445,15 +1483,38 @@ class ReplicaManager(val config: KafkaConfig,\n           replicaFetcherManager.shutdownIdleFetcherThreads()\n           replicaAlterLogDirsManager.shutdownIdleFetcherThreads()\n           onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)\n-          val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n-            new LeaderAndIsrPartitionError()\n-              .setTopicName(tp.topic)\n-              .setPartitionIndex(tp.partition)\n-              .setErrorCode(error.code)\n-          }.toBuffer\n-          new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n-            .setErrorCode(Errors.NONE.code)\n-            .setPartitionErrors(responsePartitions.asJava))\n+          if (leaderAndIsrRequest.version() < 4) {\n+            val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n+              new LeaderAndIsrPartitionError()\n+                .setTopicName(tp.topic)\n+                .setPartitionIndex(tp.partition)\n+                .setErrorCode(error.code)\n+            }.toBuffer\n+            new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n+              .setErrorCode(Errors.NONE.code)\n+              .setPartitionErrors(responsePartitions.asJava))\n+          } else {\n+            val topics = new mutable.HashMap[String, List[LeaderAndIsrPartitionError]]\n+            responseMap.asJava.forEach { case (tp, error) =>\n+              if (topics.get(tp.topic) == None) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5999b004f0f3931a4cd004f45a1887067d61dab3"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY0MzM4MA==", "bodyText": "Should here be version() < 5 ?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r527643380", "createdAt": "2020-11-20T11:56:36Z", "author": {"login": "dengziming"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1445,15 +1483,38 @@ class ReplicaManager(val config: KafkaConfig,\n           replicaFetcherManager.shutdownIdleFetcherThreads()\n           replicaAlterLogDirsManager.shutdownIdleFetcherThreads()\n           onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)\n-          val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n-            new LeaderAndIsrPartitionError()\n-              .setTopicName(tp.topic)\n-              .setPartitionIndex(tp.partition)\n-              .setErrorCode(error.code)\n-          }.toBuffer\n-          new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n-            .setErrorCode(Errors.NONE.code)\n-            .setPartitionErrors(responsePartitions.asJava))\n+          if (leaderAndIsrRequest.version() < 4) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5999b004f0f3931a4cd004f45a1887067d61dab3"}, "originalPosition": 92}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef2c75b123de53fe64a8fac43a22565824320c92", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/ef2c75b123de53fe64a8fac43a22565824320c92", "committedDate": "2020-11-20T16:39:20Z", "message": "First implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e0a304f464146f2197b91a83cce37bfb3ae7d16", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/0e0a304f464146f2197b91a83cce37bfb3ae7d16", "committedDate": "2020-11-20T16:39:38Z", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12e440b89f4939af6c54fd82fdf1e28db1feeee6", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/12e440b89f4939af6c54fd82fdf1e28db1feeee6", "committedDate": "2020-11-20T16:40:19Z", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b6b0796b0539549b2ed20d44d319bb56b777ac8d", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/b6b0796b0539549b2ed20d44d319bb56b777ac8d", "committedDate": "2020-11-20T16:40:31Z", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0279e2c1d2fd7a2aca494c710f41621b12db2057", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/0279e2c1d2fd7a2aca494c710f41621b12db2057", "committedDate": "2020-11-20T16:40:38Z", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0f0e3272266ccee981e73c7a654677a24fe6ec2f", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/0f0e3272266ccee981e73c7a654677a24fe6ec2f", "committedDate": "2020-11-20T16:40:44Z", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fa1e332e3a983ed96331f75963368aa8199a5d3", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/7fa1e332e3a983ed96331f75963368aa8199a5d3", "committedDate": "2020-11-20T16:40:54Z", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516LeaderAndIsr"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37cdd626a41f92725e18098c286735d839e442e6", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/37cdd626a41f92725e18098c286735d839e442e6", "committedDate": "2020-11-20T16:40:55Z", "message": "Fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/1926bf43e6c1b2f293fa6401847794edde5396b8", "committedDate": "2020-11-20T19:08:49Z", "message": "Cleaned up Uuid, merge processes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5999b004f0f3931a4cd004f45a1887067d61dab3", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/5999b004f0f3931a4cd004f45a1887067d61dab3", "committedDate": "2020-11-19T22:25:31Z", "message": "Fixes"}, "afterCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/1926bf43e6c1b2f293fa6401847794edde5396b8", "committedDate": "2020-11-20T19:08:49Z", "message": "Cleaned up Uuid, merge processes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4ODkyNzY0", "url": "https://github.com/apache/kafka/pull/9626#pullrequestreview-548892764", "createdAt": "2020-12-10T06:41:23Z", "commit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNjo0MToyM1rOIC44eA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNjo0MToyM1rOIC44eA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTkwMDAyNA==", "bodyText": "nit: is the else statement needed all it has is return?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r539900024", "createdAt": "2020-12-10T06:41:23Z", "author": {"login": "rite2nikhil"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -58,8 +68,17 @@ public Errors error() {\n         Errors error = error();\n         if (error != Errors.NONE)\n             // Minor optimization since the top-level error applies to all partitions\n-            return Collections.singletonMap(error, data.partitionErrors().size());\n-        return errorCounts(data.partitionErrors().stream().map(l -> Errors.forCode(l.errorCode())));\n+            if (data.topics().isEmpty()) {\n+                return Collections.singletonMap(error, data.partitionErrors().size());\n+            } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4ODk0Njg1", "url": "https://github.com/apache/kafka/pull/9626#pullrequestreview-548894685", "createdAt": "2020-12-10T06:45:59Z", "commit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNjo0NTo1OVrOIC5G6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNjo0NTo1OVrOIC5G6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTkwMzcyMQ==", "bodyText": "may be i missed is there a test checking correctness of versioning ?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r539903721", "createdAt": "2020-12-10T06:45:59Z", "author": {"login": "rite2nikhil"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrRequest.java", "diffHunk": "@@ -138,14 +145,32 @@ public LeaderAndIsrResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n         Errors error = Errors.forException(e);\n         responseData.setErrorCode(error.code());\n \n-        List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n-        for (LeaderAndIsrPartitionState partition : partitionStates()) {\n-            partitions.add(new LeaderAndIsrPartitionError()\n-                .setTopicName(partition.topicName())\n-                .setPartitionIndex(partition.partitionIndex())\n-                .setErrorCode(error.code()));\n+        if (version() < 5) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 76}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4ODk1MDUy", "url": "https://github.com/apache/kafka/pull/9626#pullrequestreview-548895052", "createdAt": "2020-12-10T06:46:54Z", "commit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5MjU4NjQy", "url": "https://github.com/apache/kafka/pull/9626#pullrequestreview-549258642", "createdAt": "2020-12-10T14:37:11Z", "commit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "state": "COMMENTED", "comments": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNDozNzoxMVrOIDMWSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNTo0NDoxN1rOIDPwDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIxODk1Mg==", "bodyText": "Type field is also added. I would also mention the KIP for reference.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540218952", "createdAt": "2020-12-10T14:37:11Z", "author": {"login": "dajac"}, "path": "clients/src/main/resources/common/message/LeaderAndIsrRequest.json", "diffHunk": "@@ -21,8 +21,12 @@\n   //\n   // Version 2 adds broker epoch and reorganizes the partitions by topic.\n   //\n-  // Version 3 adds AddingReplicas and RemovingReplicas\n-  \"validVersions\": \"0-4\",\n+  // Version 3 adds AddingReplicas and RemovingReplicas.\n+  //\n+  // Version 4 is the first flexible version.\n+  //\n+  // Version 5 adds Topic ID to the TopicStates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIxOTQxNg==", "bodyText": "nit: There are two spaces before Type and int8.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540219416", "createdAt": "2020-12-10T14:37:46Z", "author": {"login": "dajac"}, "path": "clients/src/main/resources/common/message/LeaderAndIsrRequest.json", "diffHunk": "@@ -31,6 +35,8 @@\n       \"about\": \"The current controller epoch.\" },\n     { \"name\": \"BrokerEpoch\", \"type\": \"int64\", \"versions\": \"2+\", \"ignorable\": true, \"default\": \"-1\",\n       \"about\": \"The current broker epoch.\" },\n+    { \"name\":  \"Type\", \"type\":  \"int8\", \"versions\": \"5+\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIxOTc3OA==", "bodyText": "nit: There are two consecutive and.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540219778", "createdAt": "2020-12-10T14:38:16Z", "author": {"login": "dajac"}, "path": "clients/src/main/resources/common/message/LeaderAndIsrResponse.json", "diffHunk": "@@ -22,15 +22,28 @@\n   // Version 2 is the same as version 1.\n   //\n   // Version 3 is the same as version 2.\n-  \"validVersions\": \"0-4\",\n+  //\n+  // Version 4 is the first flexible version.\n+  //\n+  // Version 5 removes TopicName and replaces it with TopicId and and reorganizes the partitions by topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyMDg3NQ==", "bodyText": "nit: There are two spaces before Topics and []LeaderAndIsrTopicError. We could also add a space before name to remain consistent with the other fields.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540220875", "createdAt": "2020-12-10T14:39:42Z", "author": {"login": "dajac"}, "path": "clients/src/main/resources/common/message/LeaderAndIsrResponse.json", "diffHunk": "@@ -22,15 +22,28 @@\n   // Version 2 is the same as version 1.\n   //\n   // Version 3 is the same as version 2.\n-  \"validVersions\": \"0-4\",\n+  //\n+  // Version 4 is the first flexible version.\n+  //\n+  // Version 5 removes TopicName and replaces it with TopicId and and reorganizes the partitions by topic.\n+  \"validVersions\": \"0-5\",\n   \"flexibleVersions\": \"4+\",\n   \"fields\": [\n     { \"name\": \"ErrorCode\", \"type\": \"int16\", \"versions\": \"0+\",\n       \"about\": \"The error code, or 0 if there was no error.\" },\n-    { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0+\",\n-      \"about\": \"Each partition.\", \"fields\": [\n-      { \"name\": \"TopicName\", \"type\": \"string\", \"versions\": \"0+\", \"entityType\": \"topicName\",\n-        \"about\": \"The topic name.\" },\n+    { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0-4\",\n+      \"about\": \"Each partition in v0 to v4 message.\"},\n+    {\"name\":  \"Topics\", \"type\":  \"[]LeaderAndIsrTopicError\", \"versions\": \"5+\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyMTk3MA==", "bodyText": "Should the version of PartitionErrors be 5+?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540221970", "createdAt": "2020-12-10T14:41:02Z", "author": {"login": "dajac"}, "path": "clients/src/main/resources/common/message/LeaderAndIsrResponse.json", "diffHunk": "@@ -22,15 +22,28 @@\n   // Version 2 is the same as version 1.\n   //\n   // Version 3 is the same as version 2.\n-  \"validVersions\": \"0-4\",\n+  //\n+  // Version 4 is the first flexible version.\n+  //\n+  // Version 5 removes TopicName and replaces it with TopicId and and reorganizes the partitions by topic.\n+  \"validVersions\": \"0-5\",\n   \"flexibleVersions\": \"4+\",\n   \"fields\": [\n     { \"name\": \"ErrorCode\", \"type\": \"int16\", \"versions\": \"0+\",\n       \"about\": \"The error code, or 0 if there was no error.\" },\n-    { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0+\",\n-      \"about\": \"Each partition.\", \"fields\": [\n-      { \"name\": \"TopicName\", \"type\": \"string\", \"versions\": \"0+\", \"entityType\": \"topicName\",\n-        \"about\": \"The topic name.\" },\n+    { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0-4\",\n+      \"about\": \"Each partition in v0 to v4 message.\"},\n+    {\"name\":  \"Topics\", \"type\":  \"[]LeaderAndIsrTopicError\", \"versions\": \"5+\",\n+      \"about\": \"Each topic\", \"fields\": [\n+      { \"name\": \"TopicId\", \"type\": \"uuid\", \"versions\": \"5+\", \"about\": \"The unique topic ID\" },\n+      { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0+\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNDY5MA==", "bodyText": "topicIds() recomputes the Map so it would be better to keep a local reference to it.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540224690", "createdAt": "2020-12-10T14:44:27Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrRequest.java", "diffHunk": "@@ -138,14 +145,32 @@ public LeaderAndIsrResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n         Errors error = Errors.forException(e);\n         responseData.setErrorCode(error.code());\n \n-        List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n-        for (LeaderAndIsrPartitionState partition : partitionStates()) {\n-            partitions.add(new LeaderAndIsrPartitionError()\n-                .setTopicName(partition.topicName())\n-                .setPartitionIndex(partition.partitionIndex())\n-                .setErrorCode(error.code()));\n+        if (version() < 5) {\n+            List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n+            for (LeaderAndIsrPartitionState partition : partitionStates()) {\n+                partitions.add(new LeaderAndIsrPartitionError()\n+                        .setTopicName(partition.topicName())\n+                        .setPartitionIndex(partition.partitionIndex())\n+                        .setErrorCode(error.code()));\n+            }\n+            responseData.setPartitionErrors(partitions);\n+            return new LeaderAndIsrResponse(responseData);\n+        }\n+\n+        List<LeaderAndIsrTopicError> topics = new ArrayList<>();\n+        for (LeaderAndIsrTopicState topicState : data.topicStates()) {\n+            LeaderAndIsrTopicError topicError = new LeaderAndIsrTopicError();\n+            topicError.setTopicId(topicIds().get(topicState.topicName()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNjAyNQ==", "bodyText": "nit: Could we directly allocate the ArrayList with the correct capacity? The same for partitions above and below.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540226025", "createdAt": "2020-12-10T14:46:04Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrRequest.java", "diffHunk": "@@ -138,14 +145,32 @@ public LeaderAndIsrResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n         Errors error = Errors.forException(e);\n         responseData.setErrorCode(error.code());\n \n-        List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n-        for (LeaderAndIsrPartitionState partition : partitionStates()) {\n-            partitions.add(new LeaderAndIsrPartitionError()\n-                .setTopicName(partition.topicName())\n-                .setPartitionIndex(partition.partitionIndex())\n-                .setErrorCode(error.code()));\n+        if (version() < 5) {\n+            List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n+            for (LeaderAndIsrPartitionState partition : partitionStates()) {\n+                partitions.add(new LeaderAndIsrPartitionError()\n+                        .setTopicName(partition.topicName())\n+                        .setPartitionIndex(partition.partitionIndex())\n+                        .setErrorCode(error.code()));\n+            }\n+            responseData.setPartitionErrors(partitions);\n+            return new LeaderAndIsrResponse(responseData);\n+        }\n+\n+        List<LeaderAndIsrTopicError> topics = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzMDEzMQ==", "bodyText": "It would be better to explicitly handle the version here instead of relying on topics() to be empty or not. It is easier to reason about for the reader and it also makes the handling very explicit instead of being implicit.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540230131", "createdAt": "2020-12-10T14:51:02Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -45,8 +47,16 @@ public LeaderAndIsrResponse(Struct struct, short version) {\n         this.data = new LeaderAndIsrResponseData(struct, version);\n     }\n \n-    public List<LeaderAndIsrPartitionError> partitions() {\n-        return data.partitionErrors();\n+    public List<LeaderAndIsrTopicError> topics() {\n+        return this.data.topics();\n+    }\n+\n+    public Iterable<LeaderAndIsrPartitionError> partitions() {\n+        if (data.topics().isEmpty()) {\n+            return data.partitionErrors();\n+        }\n+        return () -> new FlattenedIterator<>(data.topics().iterator(),\n+            topic -> topic.partitionErrors().iterator());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzMzU5MA==", "bodyText": "ditto here. It would be better to be explicit wrt. the handling of the version.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540233590", "createdAt": "2020-12-10T14:55:05Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -58,8 +68,17 @@ public Errors error() {\n         Errors error = error();\n         if (error != Errors.NONE)\n             // Minor optimization since the top-level error applies to all partitions\n-            return Collections.singletonMap(error, data.partitionErrors().size());\n-        return errorCounts(data.partitionErrors().stream().map(l -> Errors.forCode(l.errorCode())));\n+            if (data.topics().isEmpty()) {\n+                return Collections.singletonMap(error, data.partitionErrors().size());\n+            } else {\n+                return Collections.singletonMap(error,\n+                        data.topics().stream().mapToInt(t -> t.partitionErrors().size()).sum());\n+            }\n+        if (data.topics().isEmpty()) {\n+            return errorCounts(data.partitionErrors().stream().map(l -> Errors.forCode(l.errorCode())));\n+        }\n+        return errorCounts(data.topics().stream().flatMap(t -> t.partitionErrors().stream()).map(l ->\n+                Errors.forCode(l.errorCode())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzNzA0Mg==", "bodyText": "Shouldn't we verify that topic ids are correctly set in the generated response as well?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540237042", "createdAt": "2020-12-10T14:59:15Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/LeaderAndIsrRequestTest.java", "diffHunk": "@@ -51,15 +53,15 @@\n     public void testUnsupportedVersion() {\n         LeaderAndIsrRequest.Builder builder = new LeaderAndIsrRequest.Builder(\n                 (short) (LEADER_AND_ISR.latestVersion() + 1), 0, 0, 0,\n-                Collections.emptyList(), Collections.emptySet());\n+                Collections.emptyList(), Collections.emptyMap(), Collections.emptySet());\n         assertThrows(UnsupportedVersionException.class, builder::build);\n     }\n \n     @Test\n     public void testGetErrorResponse() {\n         for (short version = LEADER_AND_ISR.oldestVersion(); version < LEADER_AND_ISR.latestVersion(); version++) {\n             LeaderAndIsrRequest.Builder builder = new LeaderAndIsrRequest.Builder(version, 0, 0, 0,\n-                    Collections.emptyList(), Collections.emptySet());\n+                    Collections.emptyList(), Collections.emptyMap(), Collections.emptySet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzNzc2OA==", "bodyText": "nit: HashMap<String, Uuid> to Map<String, Uuid>. I have seen this in a couple of places.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540237768", "createdAt": "2020-12-10T15:00:05Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/LeaderAndIsrRequestTest.java", "diffHunk": "@@ -116,8 +118,13 @@ public void testVersionLogic() {\n                 new Node(0, \"host0\", 9090),\n                 new Node(1, \"host1\", 9091)\n             );\n+\n+            HashMap<String, Uuid> topicIds = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI0Mzk0MA==", "bodyText": "nit: You could use Collections.singletonMap here.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540243940", "createdAt": "2020-12-10T15:07:33Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/LeaderAndIsrResponseTest.java", "diffHunk": "@@ -57,29 +60,32 @@ public void testErrorCountsFromGetErrorResponse() {\n             .setZkVersion(20)\n             .setReplicas(Collections.singletonList(10))\n             .setIsNew(false));\n+        HashMap<String, Uuid> topicIds = new HashMap<>();\n+        topicIds.put(\"foo\", Uuid.randomUuid());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI0NjQ0MA==", "bodyText": "Should we keep testing the older version as well? Tests assume the newest version only now.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540246440", "createdAt": "2020-12-10T15:10:46Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/LeaderAndIsrResponseTest.java", "diffHunk": "@@ -57,29 +60,32 @@ public void testErrorCountsFromGetErrorResponse() {\n             .setZkVersion(20)\n             .setReplicas(Collections.singletonList(10))\n             .setIsNew(false));\n+        HashMap<String, Uuid> topicIds = new HashMap<>();\n+        topicIds.put(\"foo\", Uuid.randomUuid());\n+\n         LeaderAndIsrRequest request = new LeaderAndIsrRequest.Builder(ApiKeys.LEADER_AND_ISR.latestVersion(),\n-                15, 20, 0, partitionStates, Collections.emptySet()).build();\n+                15, 20, 0, partitionStates, topicIds, Collections.emptySet()).build();\n         LeaderAndIsrResponse response = request.getErrorResponse(0, Errors.CLUSTER_AUTHORIZATION_FAILED.exception());\n         assertEquals(Collections.singletonMap(Errors.CLUSTER_AUTHORIZATION_FAILED, 2), response.errorCounts());\n     }\n \n     @Test\n     public void testErrorCountsWithTopLevelError() {\n-        List<LeaderAndIsrPartitionError> partitions = createPartitions(\"foo\",\n-            asList(Errors.NONE, Errors.NOT_LEADER_OR_FOLLOWER));\n+        Uuid id = Uuid.randomUuid();\n+        List<LeaderAndIsrTopicError> topics = createTopic(id, asList(Errors.NONE, Errors.NOT_LEADER_OR_FOLLOWER));\n         LeaderAndIsrResponse response = new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n             .setErrorCode(Errors.UNKNOWN_SERVER_ERROR.code())\n-            .setPartitionErrors(partitions));\n+            .setTopics(topics));\n         assertEquals(Collections.singletonMap(Errors.UNKNOWN_SERVER_ERROR, 2), response.errorCounts());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI0NzY2Mg==", "bodyText": "It would be good to verify that all versions are tested in testSerialization.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540247662", "createdAt": "2020-12-10T15:12:09Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -21,6 +21,7 @@\n import org.apache.kafka.common.IsolationLevel;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI1MjM1MA==", "bodyText": "nit: (topic: String) -> topic. We rarely specify the type in lambdas.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540252350", "createdAt": "2020-12-10T15:17:38Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -482,8 +483,13 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n           _.node(config.interBrokerListenerName)\n         }\n         val brokerEpoch = controllerContext.liveBrokerIdAndEpochs(broker)\n+        val topicIds = leaderAndIsrPartitionStates.keys\n+          .map(_.topic)\n+          .toSet\n+          .map((topic: String) => (topic, controllerContext.topicIds(topic)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI1OTEzMQ==", "bodyText": "nit: We usually put a space before { and } when we use curly braces inline. We could also add a space after the coma.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540259131", "createdAt": "2020-12-10T15:25:48Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/controller/ControllerChannelManagerTest.scala", "diffHunk": "@@ -72,6 +73,8 @@ class ControllerChannelManagerTest {\n     assertEquals(1, updateMetadataRequests.size)\n \n     val leaderAndIsrRequest = leaderAndIsrRequests.head\n+    val topicIds = leaderAndIsrRequest.topicIds();\n+    val topicNames = topicIds.asScala.map{ case (k,v) => (v, k)}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI2Mjc1OA==", "bodyText": "topicNames.get(t.topicId).get -> topicNames(t.topicId). It is a bit more concise when you know that the Map contains what you are looking up.\nflatMap(f => f) looks weird. I suppose that we could use flatMap instead of the first map.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540262758", "createdAt": "2020-12-10T15:30:01Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/controller/ControllerChannelManagerTest.scala", "diffHunk": "@@ -87,7 +90,10 @@ class ControllerChannelManagerTest {\n     val LeaderAndIsrResponseReceived(leaderAndIsrResponse, brokerId) = batch.sentEvents.head\n     assertEquals(2, brokerId)\n     assertEquals(partitions.keySet,\n-      leaderAndIsrResponse.partitions.asScala.map(p => new TopicPartition(p.topicName, p.partitionIndex)).toSet)\n+      leaderAndIsrResponse.topics.asScala.map(t => t.partitionErrors.asScala.map(p =>\n+        new TopicPartition(topicNames.get(t.topicId).get, p.partitionIndex))).flatMap(f => f).toSet)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI2NTU2MQ==", "bodyText": "nit: The parenthesis after topicStates, partitionStates, and partitionIndex are not mandatory. We tend to not put it when they are not.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540265561", "createdAt": "2020-12-10T15:33:17Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/controller/ControllerChannelManagerTest.scala", "diffHunk": "@@ -818,15 +825,18 @@ class ControllerChannelManagerTest {\n   private def applyLeaderAndIsrResponseCallbacks(error: Errors, sentRequests: List[SentRequest]): Unit = {\n     sentRequests.filter(_.request.apiKey == ApiKeys.LEADER_AND_ISR).filter(_.responseCallback != null).foreach { sentRequest =>\n       val leaderAndIsrRequest = sentRequest.request.build().asInstanceOf[LeaderAndIsrRequest]\n-      val partitionErrors = leaderAndIsrRequest.partitionStates.asScala.map(p =>\n-        new LeaderAndIsrPartitionError()\n-          .setTopicName(p.topicName)\n-          .setPartitionIndex(p.partitionIndex)\n-          .setErrorCode(error.code))\n+      val topicIds = leaderAndIsrRequest.topicIds()\n+      val topicErrors = leaderAndIsrRequest.data.topicStates().asScala.map(t =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI2Nzc2MQ==", "bodyText": "I wonder if we should extend testLeaderAndIsrRequestFollowsInterBrokerProtocolVersion to verifies the topic ids based on the different supported versions. What do you think?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540267761", "createdAt": "2020-12-10T15:35:57Z", "author": {"login": "dajac"}, "path": "core/src/test/scala/unit/kafka/controller/ControllerChannelManagerTest.scala", "diffHunk": "@@ -157,7 +163,8 @@ class ControllerChannelManagerTest {\n \n     for (apiVersion <- ApiVersion.allVersions) {\n       val leaderAndIsrRequestVersion: Short =\n-        if (apiVersion >= KAFKA_2_4_IV1) 4\n+        if (apiVersion >= KAFKA_2_8_IV0) 5", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI3MzU2Mw==", "bodyText": "It may be better to also have an explicit handling of the version here. Alternatively, we could push this into the LeaderAndIsrResponse and provides a method Map<TopicPartition, ...> partitions() which handles the version.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540273563", "createdAt": "2020-12-10T15:42:52Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1378,12 +1378,26 @@ class KafkaController(val config: KafkaConfig,\n     val offlineReplicas = new ArrayBuffer[TopicPartition]()\n     val onlineReplicas = new ArrayBuffer[TopicPartition]()\n \n-    leaderAndIsrResponse.partitions.forEach { partition =>\n-      val tp = new TopicPartition(partition.topicName, partition.partitionIndex)\n-      if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n-        offlineReplicas += tp\n-      else if (partition.errorCode == Errors.NONE.code)\n-        onlineReplicas += tp\n+    if (leaderAndIsrResponse.topics().isEmpty) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI3NDcwMw==", "bodyText": "Do we need to handle the case when the topic may not be there anymore when the response is received? If not, we could use controllerContext.topicNames(topic.topicId).", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540274703", "createdAt": "2020-12-10T15:44:17Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1378,12 +1378,26 @@ class KafkaController(val config: KafkaConfig,\n     val offlineReplicas = new ArrayBuffer[TopicPartition]()\n     val onlineReplicas = new ArrayBuffer[TopicPartition]()\n \n-    leaderAndIsrResponse.partitions.forEach { partition =>\n-      val tp = new TopicPartition(partition.topicName, partition.partitionIndex)\n-      if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n-        offlineReplicas += tp\n-      else if (partition.errorCode == Errors.NONE.code)\n-        onlineReplicas += tp\n+    if (leaderAndIsrResponse.topics().isEmpty) {\n+      leaderAndIsrResponse.partitions.forEach { partition =>\n+        val topicName = partition.topicName\n+        val tp = new TopicPartition(topicName, partition.partitionIndex)\n+        if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n+          offlineReplicas += tp\n+        else if (partition.errorCode == Errors.NONE.code)\n+          onlineReplicas += tp\n+      }\n+    }\n+\n+    leaderAndIsrResponse.topics.forEach { topic =>\n+      val topicName = controllerContext.topicNames.get(topic.topicId).get", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMzMxNTQ4", "url": "https://github.com/apache/kafka/pull/9626#pullrequestreview-552331548", "createdAt": "2020-12-15T10:55:47Z", "commit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQxMDo1NTo0N1rOIGE-jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQxMTo0ODoyN1rOIGG-Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI0MzkxNg==", "bodyText": "Should be able to replace this with something like:\nreturn data.topicStates().stream()\n  .collect(Collectors.toMap(LeaderAndIsrTopicState::topicName, LeaderAndIsrTopicState::topicId));", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543243916", "createdAt": "2020-12-15T10:55:47Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrRequest.java", "diffHunk": "@@ -171,6 +196,14 @@ public long brokerEpoch() {\n         return data.ungroupedPartitionStates();\n     }\n \n+    public Map<String, Uuid> topicIds() {\n+        Map<String, Uuid> topicIds = new HashMap<>();\n+        for (LeaderAndIsrTopicState ts : data.topicStates()) {\n+            topicIds.put(ts.topicName(), ts.topicId());\n+        }\n+        return topicIds;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI0NzMzNQ==", "bodyText": "nit: We should add braces here since there are multiple lines inside the if statement", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543247335", "createdAt": "2020-12-15T11:01:05Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -58,8 +68,17 @@ public Errors error() {\n         Errors error = error();\n         if (error != Errors.NONE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI0NzM0Ng==", "bodyText": "nit: We should add braces here since there are multiple lines inside the if statement", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543247346", "createdAt": "2020-12-15T11:01:06Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -58,8 +68,17 @@ public Errors error() {\n         Errors error = error();\n         if (error != Errors.NONE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI1NjMwNg==", "bodyText": "Should we do controllerContext.topicNames.get(topic.topicId).foreach instead of get to avoid throwing exception if topic is not in the context?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543256306", "createdAt": "2020-12-15T11:14:59Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1378,12 +1378,26 @@ class KafkaController(val config: KafkaConfig,\n     val offlineReplicas = new ArrayBuffer[TopicPartition]()\n     val onlineReplicas = new ArrayBuffer[TopicPartition]()\n \n-    leaderAndIsrResponse.partitions.forEach { partition =>\n-      val tp = new TopicPartition(partition.topicName, partition.partitionIndex)\n-      if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n-        offlineReplicas += tp\n-      else if (partition.errorCode == Errors.NONE.code)\n-        onlineReplicas += tp\n+    if (leaderAndIsrResponse.topics().isEmpty) {\n+      leaderAndIsrResponse.partitions.forEach { partition =>\n+        val topicName = partition.topicName\n+        val tp = new TopicPartition(topicName, partition.partitionIndex)\n+        if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n+          offlineReplicas += tp\n+        else if (partition.errorCode == Errors.NONE.code)\n+          onlineReplicas += tp\n+      }\n+    }\n+\n+    leaderAndIsrResponse.topics.forEach { topic =>\n+      val topicName = controllerContext.topicNames.get(topic.topicId).get", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI1NzM3Mg==", "bodyText": "We can make an inner method within this method with the common logic.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543257372", "createdAt": "2020-12-15T11:16:42Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1378,12 +1378,26 @@ class KafkaController(val config: KafkaConfig,\n     val offlineReplicas = new ArrayBuffer[TopicPartition]()\n     val onlineReplicas = new ArrayBuffer[TopicPartition]()\n \n-    leaderAndIsrResponse.partitions.forEach { partition =>\n-      val tp = new TopicPartition(partition.topicName, partition.partitionIndex)\n-      if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n-        offlineReplicas += tp\n-      else if (partition.errorCode == Errors.NONE.code)\n-        onlineReplicas += tp\n+    if (leaderAndIsrResponse.topics().isEmpty) {\n+      leaderAndIsrResponse.partitions.forEach { partition =>\n+        val topicName = partition.topicName\n+        val tp = new TopicPartition(topicName, partition.partitionIndex)\n+        if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n+          offlineReplicas += tp\n+        else if (partition.errorCode == Errors.NONE.code)\n+          onlineReplicas += tp\n+      }\n+    }\n+\n+    leaderAndIsrResponse.topics.forEach { topic =>\n+      val topicName = controllerContext.topicNames.get(topic.topicId).get\n+      topic.partitionErrors().forEach { partition =>\n+        val tp = new TopicPartition(topicName, partition.partitionIndex)\n+        if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n+          offlineReplicas += tp\n+        else if (partition.errorCode == Errors.NONE.code)\n+          onlineReplicas += tp", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI1OTY1Mg==", "bodyText": "Seems neater to use partitionMetadataFile.foreach instead of using .get twice.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543259652", "createdAt": "2020-12-15T11:20:42Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -322,6 +327,11 @@ class Log(@volatile private var _dir: File,\n     // deletion.\n     producerStateManager.removeStraySnapshots(segments.values().asScala.map(_.baseOffset).toSeq)\n     loadProducerState(logEndOffset, reloadFromCleanShutdown = hadCleanShutdown)\n+\n+    // Recover topic ID if present\n+    if (!partitionMetadataFile.get.isEmpty()) {\n+      topicId = partitionMetadataFile.get.read().topicId\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NDA5OA==", "bodyText": "Why are we reading and writing again?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543264098", "createdAt": "2020-12-15T11:28:07Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1021,6 +1036,13 @@ class Log(@volatile private var _dir: File,\n           // re-initialize leader epoch cache so that LeaderEpochCheckpointFile.checkpoint can correctly reference\n           // the checkpoint file in renamed log directory\n           initializeLeaderEpochCache()\n+          if (!partitionMetadataFile.isEmpty && !partitionMetadataFile.get.isEmpty()) {\n+            val partitionMetadata = partitionMetadataFile.get.read()\n+            initializePartitionMetadata()\n+            partitionMetadataFile.get.write(partitionMetadata.topicId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NDY2Mg==", "bodyText": "LeaderEpochCheckpointFilename => PartitionMetadataFilename?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543264662", "createdAt": "2020-12-15T11:29:05Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/PartitionMetadataFile.scala", "diffHunk": "@@ -0,0 +1,141 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.io.{BufferedReader, BufferedWriter, File, FileOutputStream, IOException, OutputStreamWriter}\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{FileAlreadyExistsException, Files, Paths}\n+import java.util.regex.Pattern\n+\n+import kafka.utils.Logging\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.errors.KafkaStorageException\n+import org.apache.kafka.common.utils.Utils\n+\n+\n+\n+object PartitionMetadataFile {\n+  private val LeaderEpochCheckpointFilename = \"partition.metadata\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NTkzNA==", "bodyText": ".foreach may be better than lots of .gets", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543265934", "createdAt": "2020-12-15T11:31:12Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1021,6 +1036,13 @@ class Log(@volatile private var _dir: File,\n           // re-initialize leader epoch cache so that LeaderEpochCheckpointFile.checkpoint can correctly reference\n           // the checkpoint file in renamed log directory\n           initializeLeaderEpochCache()\n+          if (!partitionMetadataFile.isEmpty && !partitionMetadataFile.get.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NzU4Nw==", "bodyText": "update error message?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543267587", "createdAt": "2020-12-15T11:33:57Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/PartitionMetadataFile.scala", "diffHunk": "@@ -0,0 +1,141 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.io.{BufferedReader, BufferedWriter, File, FileOutputStream, IOException, OutputStreamWriter}\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{FileAlreadyExistsException, Files, Paths}\n+import java.util.regex.Pattern\n+\n+import kafka.utils.Logging\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.errors.KafkaStorageException\n+import org.apache.kafka.common.utils.Utils\n+\n+\n+\n+object PartitionMetadataFile {\n+  private val LeaderEpochCheckpointFilename = \"partition.metadata\"\n+  private val WhiteSpacesPattern = Pattern.compile(\":\\\\s+\")\n+  private val CurrentVersion = 0\n+\n+  def newFile(dir: File): File = new File(dir, LeaderEpochCheckpointFilename)\n+\n+  object PartitionMetadataFileFormatter {\n+    def toFile(data: PartitionMetadata): String = {\n+      s\"version: ${data.version}\\ntopic_id: ${data.topicId}\"\n+    }\n+\n+  }\n+\n+  class PartitionMetadataReadBuffer[T](location: String,\n+                                       reader: BufferedReader,\n+                                       version: Int) extends Logging {\n+    def read(): PartitionMetadata = {\n+      def malformedLineException(line: String) =\n+        new IOException(s\"Malformed line in checkpoint file ($location): '$line'\")\n+\n+      var line: String = null\n+      var metadataTopicId: Uuid = null\n+      try {\n+        line = reader.readLine()\n+        WhiteSpacesPattern.split(line) match {\n+          case Array(_, version) =>\n+            if (version.toInt == CurrentVersion) {\n+              line = reader.readLine()\n+              WhiteSpacesPattern.split(line) match {\n+                case Array(_, topicId) => metadataTopicId = Uuid.fromString(topicId)\n+                case _ => throw malformedLineException(line)\n+              }\n+              new PartitionMetadata(CurrentVersion, metadataTopicId)\n+            } else {\n+              throw new IOException(s\"Unrecognized version of the checkpoint file ($location): \" + version)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MjU3Mw==", "bodyText": "why is this a warning?", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543272573", "createdAt": "2020-12-15T11:42:04Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1434,6 +1447,31 @@ class ReplicaManager(val config: KafkaConfig,\n            */\n             if (localLog(topicPartition).isEmpty)\n               markPartitionOffline(topicPartition)\n+            else {\n+              val id = topicIds.get(topicPartition.topic())\n+              // Ensure we have not received a request from an older protocol\n+              if (id != null && !id.equals(Uuid.ZERO_UUID)) {\n+                val log = localLog(topicPartition).get\n+                // Check if the topic ID is in memory, if not, it must be new to the broker.\n+                // If the broker previously wrote it to file, it would be recovered on restart after failure.\n+                // If the topic ID is not the default (ZERO_UUID), a topic ID is being used for the given topic.\n+                // If the topic ID in the log does not match the one in the request, the broker's topic must be stale.\n+                if (!log.topicId.equals(Uuid.ZERO_UUID) && !log.topicId.equals(topicIds.get(topicPartition.topic))) {\n+                  stateChangeLogger.warn(s\"Topic Id in memory: ${log.topicId.toString} does not\" +\n+                    s\" match the topic Id provided in the request: \" +\n+                    s\"${topicIds.get(topicPartition.topic).toString}.\")\n+                } else {\n+                  // There is not yet a topic ID stored in the log.\n+                  // Write the partition metadata file if it is empty.\n+                  if (log.partitionMetadataFile.get.isEmpty()) {\n+                    log.partitionMetadataFile.get.write(topicIds.get(topicPartition.topic))\n+                    log.topicId = topicIds.get(topicPartition.topic)\n+                  } else {\n+                    stateChangeLogger.warn(\"Partition metadata file already contains content.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MzI0NQ==", "bodyText": "we already have the topic id in id.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543273245", "createdAt": "2020-12-15T11:43:01Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1434,6 +1447,31 @@ class ReplicaManager(val config: KafkaConfig,\n            */\n             if (localLog(topicPartition).isEmpty)\n               markPartitionOffline(topicPartition)\n+            else {\n+              val id = topicIds.get(topicPartition.topic())\n+              // Ensure we have not received a request from an older protocol\n+              if (id != null && !id.equals(Uuid.ZERO_UUID)) {\n+                val log = localLog(topicPartition).get\n+                // Check if the topic ID is in memory, if not, it must be new to the broker.\n+                // If the broker previously wrote it to file, it would be recovered on restart after failure.\n+                // If the topic ID is not the default (ZERO_UUID), a topic ID is being used for the given topic.\n+                // If the topic ID in the log does not match the one in the request, the broker's topic must be stale.\n+                if (!log.topicId.equals(Uuid.ZERO_UUID) && !log.topicId.equals(topicIds.get(topicPartition.topic))) {\n+                  stateChangeLogger.warn(s\"Topic Id in memory: ${log.topicId.toString} does not\" +\n+                    s\" match the topic Id provided in the request: \" +\n+                    s\"${topicIds.get(topicPartition.topic).toString}.\")\n+                } else {\n+                  // There is not yet a topic ID stored in the log.\n+                  // Write the partition metadata file if it is empty.\n+                  if (log.partitionMetadataFile.get.isEmpty()) {\n+                    log.partitionMetadataFile.get.write(topicIds.get(topicPartition.topic))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MzU0MQ==", "bodyText": "As above, we can use id", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543273541", "createdAt": "2020-12-15T11:43:29Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1434,6 +1447,31 @@ class ReplicaManager(val config: KafkaConfig,\n            */\n             if (localLog(topicPartition).isEmpty)\n               markPartitionOffline(topicPartition)\n+            else {\n+              val id = topicIds.get(topicPartition.topic())\n+              // Ensure we have not received a request from an older protocol\n+              if (id != null && !id.equals(Uuid.ZERO_UUID)) {\n+                val log = localLog(topicPartition).get\n+                // Check if the topic ID is in memory, if not, it must be new to the broker.\n+                // If the broker previously wrote it to file, it would be recovered on restart after failure.\n+                // If the topic ID is not the default (ZERO_UUID), a topic ID is being used for the given topic.\n+                // If the topic ID in the log does not match the one in the request, the broker's topic must be stale.\n+                if (!log.topicId.equals(Uuid.ZERO_UUID) && !log.topicId.equals(topicIds.get(topicPartition.topic))) {\n+                  stateChangeLogger.warn(s\"Topic Id in memory: ${log.topicId.toString} does not\" +\n+                    s\" match the topic Id provided in the request: \" +\n+                    s\"${topicIds.get(topicPartition.topic).toString}.\")\n+                } else {\n+                  // There is not yet a topic ID stored in the log.\n+                  // Write the partition metadata file if it is empty.\n+                  if (log.partitionMetadataFile.get.isEmpty()) {\n+                    log.partitionMetadataFile.get.write(topicIds.get(topicPartition.topic))\n+                    log.topicId = topicIds.get(topicPartition.topic)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3NjYxNQ==", "bodyText": "Replace topics.get(tp.topic).get with topics(tp.topic)", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543276615", "createdAt": "2020-12-15T11:48:27Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1445,15 +1483,38 @@ class ReplicaManager(val config: KafkaConfig,\n           replicaFetcherManager.shutdownIdleFetcherThreads()\n           replicaAlterLogDirsManager.shutdownIdleFetcherThreads()\n           onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)\n-          val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n-            new LeaderAndIsrPartitionError()\n-              .setTopicName(tp.topic)\n-              .setPartitionIndex(tp.partition)\n-              .setErrorCode(error.code)\n-          }.toBuffer\n-          new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n-            .setErrorCode(Errors.NONE.code)\n-            .setPartitionErrors(responsePartitions.asJava))\n+          if (leaderAndIsrRequest.version() < 5) {\n+            val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n+              new LeaderAndIsrPartitionError()\n+                .setTopicName(tp.topic)\n+                .setPartitionIndex(tp.partition)\n+                .setErrorCode(error.code)\n+            }.toBuffer\n+            new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n+              .setErrorCode(Errors.NONE.code)\n+              .setPartitionErrors(responsePartitions.asJava))\n+          } else {\n+            val topics = new mutable.HashMap[String, List[LeaderAndIsrPartitionError]]\n+            responseMap.asJava.forEach { case (tp, error) =>\n+              if (!topics.contains(tp.topic)) {\n+                topics.put(tp.topic, List(new LeaderAndIsrPartitionError()\n+                                                                .setPartitionIndex(tp.partition)\n+                                                                .setErrorCode(error.code)))\n+              } else {\n+                topics.put(tp.topic, new LeaderAndIsrPartitionError()\n+                  .setPartitionIndex(tp.partition)\n+                  .setErrorCode(error.code)::topics.get(tp.topic).get)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 112}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5424a1a026649a5270d4593fb2ba920e8abc091a", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/5424a1a026649a5270d4593fb2ba920e8abc091a", "committedDate": "2020-12-16T00:57:57Z", "message": "Addressed comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzNTc0MTUz", "url": "https://github.com/apache/kafka/pull/9626#pullrequestreview-553574153", "createdAt": "2020-12-16T10:59:33Z", "commit": {"oid": "5424a1a026649a5270d4593fb2ba920e8abc091a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxMDo1OTozM1rOIG_myg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxMDo1OTozM1rOIG_myg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDIwNDQ5MA==", "bodyText": "Hmm, looking at the conditional statements here, it looks like we would write the file the first time we get here because log.partitionMetadataFile.get.isEmpty() and the second time we would print a warning even if the id in the file matches the expected id. Unless I missed something.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r544204490", "createdAt": "2020-12-16T10:59:33Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1434,6 +1447,31 @@ class ReplicaManager(val config: KafkaConfig,\n            */\n             if (localLog(topicPartition).isEmpty)\n               markPartitionOffline(topicPartition)\n+            else {\n+              val id = topicIds.get(topicPartition.topic())\n+              // Ensure we have not received a request from an older protocol\n+              if (id != null && !id.equals(Uuid.ZERO_UUID)) {\n+                val log = localLog(topicPartition).get\n+                // Check if the topic ID is in memory, if not, it must be new to the broker.\n+                // If the broker previously wrote it to file, it would be recovered on restart after failure.\n+                // If the topic ID is not the default (ZERO_UUID), a topic ID is being used for the given topic.\n+                // If the topic ID in the log does not match the one in the request, the broker's topic must be stale.\n+                if (!log.topicId.equals(Uuid.ZERO_UUID) && !log.topicId.equals(topicIds.get(topicPartition.topic))) {\n+                  stateChangeLogger.warn(s\"Topic Id in memory: ${log.topicId.toString} does not\" +\n+                    s\" match the topic Id provided in the request: \" +\n+                    s\"${topicIds.get(topicPartition.topic).toString}.\")\n+                } else {\n+                  // There is not yet a topic ID stored in the log.\n+                  // Write the partition metadata file if it is empty.\n+                  if (log.partitionMetadataFile.get.isEmpty()) {\n+                    log.partitionMetadataFile.get.write(topicIds.get(topicPartition.topic))\n+                    log.topicId = topicIds.get(topicPartition.topic)\n+                  } else {\n+                    stateChangeLogger.warn(\"Partition metadata file already contains content.\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MjU3Mw=="}, "originalCommit": {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8"}, "originalPosition": 71}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6dbdbb80b3c6774e9dc3870976d709d7fe3c217b", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/6dbdbb80b3c6774e9dc3870976d709d7fe3c217b", "committedDate": "2020-12-17T01:20:24Z", "message": "Made replicaManager code less complicated."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53ea8430a75b6e8e81f216ebae1ba27b32ca44b2", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/53ea8430a75b6e8e81f216ebae1ba27b32ca44b2", "committedDate": "2020-12-17T03:49:41Z", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516LeaderAndIsr"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0NTA2NjEz", "url": "https://github.com/apache/kafka/pull/9626#pullrequestreview-554506613", "createdAt": "2020-12-17T11:16:13Z", "commit": {"oid": "53ea8430a75b6e8e81f216ebae1ba27b32ca44b2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxMToxNjoxM1rOIHwwlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxMToxNjoxM1rOIHwwlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTAwOTgxMw==", "bodyText": "nit: assertFalse instead of assertTrue(!...). There are a few of these below as well.", "url": "https://github.com/apache/kafka/pull/9626#discussion_r545009813", "createdAt": "2020-12-17T11:16:13Z", "author": {"login": "rajinisivaram"}, "path": "core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala", "diffHunk": "@@ -2176,4 +2212,84 @@ class ReplicaManagerTest {\n       replicaManager.shutdown(false)\n     }\n   }\n+\n+  @Test\n+  def testPartitionMetadataFile() = {\n+    val replicaManager = setupReplicaManagerWithMockedPurgatories(new MockTimer(time))\n+    try {\n+      val brokerList = Seq[Integer](0, 1).asJava\n+      val topicPartition = new TopicPartition(topic, 0)\n+      replicaManager.createPartition(topicPartition)\n+        .createLogIfNotExists(isNew = false, isFutureReplica = false,\n+          new LazyOffsetCheckpoints(replicaManager.highWatermarkCheckpoints))\n+      val topicIds = Collections.singletonMap(topic, Uuid.randomUuid())\n+\n+      def leaderAndIsrRequest(epoch: Int): LeaderAndIsrRequest = new LeaderAndIsrRequest.Builder(ApiKeys.LEADER_AND_ISR.latestVersion, 0, 0, brokerEpoch,\n+        Seq(new LeaderAndIsrPartitionState()\n+          .setTopicName(topic)\n+          .setPartitionIndex(0)\n+          .setControllerEpoch(0)\n+          .setLeader(0)\n+          .setLeaderEpoch(epoch)\n+          .setIsr(brokerList)\n+          .setZkVersion(0)\n+          .setReplicas(brokerList)\n+          .setIsNew(true)).asJava,\n+        topicIds,\n+        Set(new Node(0, \"host1\", 0), new Node(1, \"host2\", 1)).asJava).build()\n+\n+      replicaManager.becomeLeaderOrFollower(0, leaderAndIsrRequest(0), (_, _) => ())\n+      assertTrue(!replicaManager.localLog(topicPartition).isEmpty)\n+      val id = topicIds.get(topicPartition.topic())\n+      val log = replicaManager.localLog(topicPartition).get\n+      assertTrue(!log.partitionMetadataFile.isEmpty)\n+      assertTrue(!log.partitionMetadataFile.get.isEmpty())\n+      val partitionMetadata = log.partitionMetadataFile.get.read()\n+\n+      // Current version of PartitionMetadataFile is 0.\n+      assertEquals(0, partitionMetadata.version)\n+      assertEquals(id, partitionMetadata.topicId)\n+    } finally replicaManager.shutdown(checkpointHW = false)\n+  }\n+\n+  @Test\n+  def testPartitionMetadataFileNotCreated() = {\n+    val replicaManager = setupReplicaManagerWithMockedPurgatories(new MockTimer(time))\n+    try {\n+      val brokerList = Seq[Integer](0, 1).asJava\n+      val topicPartition = new TopicPartition(topic, 0)\n+      replicaManager.createPartition(topicPartition)\n+        .createLogIfNotExists(isNew = false, isFutureReplica = false,\n+          new LazyOffsetCheckpoints(replicaManager.highWatermarkCheckpoints))\n+      val topicIds = Collections.singletonMap(topic, Uuid.ZERO_UUID)\n+\n+      def leaderAndIsrRequest(epoch: Int, name: String): LeaderAndIsrRequest = new LeaderAndIsrRequest.Builder(ApiKeys.LEADER_AND_ISR.latestVersion, 0, 0, brokerEpoch,\n+        Seq(new LeaderAndIsrPartitionState()\n+          .setTopicName(name)\n+          .setPartitionIndex(0)\n+          .setControllerEpoch(0)\n+          .setLeader(0)\n+          .setLeaderEpoch(epoch)\n+          .setIsr(brokerList)\n+          .setZkVersion(0)\n+          .setReplicas(brokerList)\n+          .setIsNew(true)).asJava,\n+        topicIds,\n+        Set(new Node(0, \"host1\", 0), new Node(1, \"host2\", 1)).asJava).build()\n+\n+      // The file has no contents if the topic does not have an associated topic ID.\n+      replicaManager.becomeLeaderOrFollower(0, leaderAndIsrRequest(0, \"fakeTopic\"), (_, _) => ())\n+      assertTrue(!replicaManager.localLog(topicPartition).isEmpty)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "53ea8430a75b6e8e81f216ebae1ba27b32ca44b2"}, "originalPosition": 377}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "919f0ed74008a43deeb39b088d7c63ee56ae6d44", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/919f0ed74008a43deeb39b088d7c63ee56ae6d44", "committedDate": "2020-12-17T23:00:00Z", "message": "Fix some issues with propagating partition state"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fcd80938b9c17b46d2395623cca80e12d2b4f6c9", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/fcd80938b9c17b46d2395623cca80e12d2b4f6c9", "committedDate": "2020-12-18T15:56:40Z", "message": "Remove extra code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "213143d98480f92cc308e7c082b1a123ff03e821", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/213143d98480f92cc308e7c082b1a123ff03e821", "committedDate": "2020-12-18T18:55:32Z", "message": "Merge branch 'trunk' into KIP516LeaderAndIsr"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ff7840a592464cb18931b27d4ff1d6157a86b93", "author": {"user": {"login": "jolshan", "name": "Justine Olshan"}}, "url": "https://github.com/apache/kafka/commit/5ff7840a592464cb18931b27d4ff1d6157a86b93", "committedDate": "2020-12-18T21:37:00Z", "message": "Merge branch 'trunk' into KIP516LeaderAndIsr"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2418, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}