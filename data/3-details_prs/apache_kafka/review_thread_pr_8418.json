{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4Mjk1MTEy", "number": 8418, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0MDowN1rODufMrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0MTowN1rODufPFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMDcyMjM5OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0MDowN1rOGAgT-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0MDowN1rOGAgT-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4MjU4Ng==", "bodyText": "Should we use lambdas for Runnable and Callable?", "url": "https://github.com/apache/kafka/pull/8418#discussion_r403182586", "createdAt": "2020-04-03T17:40:07Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -3649,6 +3650,61 @@ class LogTest {\n     assertEquals(None, log.firstUnstableOffset)\n   }\n \n+  @Test\n+  def testReadCommittedWithConcurrentHighWatermarkUpdates(): Unit = {\n+    val logConfig = LogTest.createLogConfig(segmentBytes = 1024 * 1024 * 5)\n+    val log = createLog(logDir, logConfig)\n+    val lastOffset = 50L\n+\n+    val producerEpoch = 0.toShort\n+    val producerId = 15L\n+    val appendProducer = appendTransactionalAsLeader(log, producerId, producerEpoch)\n+\n+    // Thread 1 writes single-record transactions and attempts to read them\n+    // before they have been aborted, and then aborts them\n+    val txnVerifier = new Callable[Int]() {\n+      override def call(): Int = {\n+        var nonEmptyReads = 0\n+        while (log.logEndOffset < lastOffset) {\n+          val currentLogEndOffset = log.logEndOffset\n+\n+          appendProducer(1)\n+\n+          val readInfo = log.read(\n+            startOffset = currentLogEndOffset,\n+            maxLength = Int.MaxValue,\n+            isolation = FetchTxnCommitted,\n+            minOneMessage = false)\n+\n+          if (readInfo.records.sizeInBytes() > 0)\n+            nonEmptyReads += 1\n+\n+          appendEndTxnMarkerAsLeader(log, producerId, producerEpoch, ControlRecordType.ABORT)\n+        }\n+        nonEmptyReads\n+      }\n+    }\n+\n+    // Thread 2 watches the log and updates the high watermark\n+    val hwUpdater = new Runnable() {\n+      override def run(): Unit = {\n+        while (log.logEndOffset < lastOffset) {\n+          log.updateHighWatermark(log.logEndOffset)\n+        }\n+      }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d162c26242a1fa25479b9067e8238dbdaaf4c75a"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMDcyODU1OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0MTowN1rOGAgXgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0MTowN1rOGAgXgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4MzQ5MA==", "bodyText": "Shall we do this within a try/finally?", "url": "https://github.com/apache/kafka/pull/8418#discussion_r403183490", "createdAt": "2020-04-03T17:41:07Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -3649,6 +3650,61 @@ class LogTest {\n     assertEquals(None, log.firstUnstableOffset)\n   }\n \n+  @Test\n+  def testReadCommittedWithConcurrentHighWatermarkUpdates(): Unit = {\n+    val logConfig = LogTest.createLogConfig(segmentBytes = 1024 * 1024 * 5)\n+    val log = createLog(logDir, logConfig)\n+    val lastOffset = 50L\n+\n+    val producerEpoch = 0.toShort\n+    val producerId = 15L\n+    val appendProducer = appendTransactionalAsLeader(log, producerId, producerEpoch)\n+\n+    // Thread 1 writes single-record transactions and attempts to read them\n+    // before they have been aborted, and then aborts them\n+    val txnVerifier = new Callable[Int]() {\n+      override def call(): Int = {\n+        var nonEmptyReads = 0\n+        while (log.logEndOffset < lastOffset) {\n+          val currentLogEndOffset = log.logEndOffset\n+\n+          appendProducer(1)\n+\n+          val readInfo = log.read(\n+            startOffset = currentLogEndOffset,\n+            maxLength = Int.MaxValue,\n+            isolation = FetchTxnCommitted,\n+            minOneMessage = false)\n+\n+          if (readInfo.records.sizeInBytes() > 0)\n+            nonEmptyReads += 1\n+\n+          appendEndTxnMarkerAsLeader(log, producerId, producerEpoch, ControlRecordType.ABORT)\n+        }\n+        nonEmptyReads\n+      }\n+    }\n+\n+    // Thread 2 watches the log and updates the high watermark\n+    val hwUpdater = new Runnable() {\n+      override def run(): Unit = {\n+        while (log.logEndOffset < lastOffset) {\n+          log.updateHighWatermark(log.logEndOffset)\n+        }\n+      }\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(2)\n+    executor.submit(hwUpdater)\n+\n+    val future = executor.submit(txnVerifier)\n+    val nonEmptyReads = future.get()\n+\n+    assertEquals(0, nonEmptyReads)\n+\n+    executor.shutdownNow()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d162c26242a1fa25479b9067e8238dbdaaf4c75a"}, "originalPosition": 64}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3202, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}