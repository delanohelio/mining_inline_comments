{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY5ODYxNzIw", "number": 8029, "title": "KAFKA-8147: Add changelog topic configuration to KTable suppress", "bodyText": "Committer Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-02-01T05:54:32Z", "url": "https://github.com/apache/kafka/pull/8029", "merged": true, "mergeCommit": {"oid": "90640266393b530107db8256d38ec5aeba4805e1"}, "closed": true, "closedAt": "2020-02-25T19:23:26Z", "author": {"login": "highluck"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcFRLi5AFqTM1OTg4ODA2MQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcH3F1NAFqTM2NDM3ODI1Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU5ODg4MDYx", "url": "https://github.com/apache/kafka/pull/8029#pullrequestreview-359888061", "createdAt": "2020-02-17T17:28:28Z", "commit": {"oid": "08d14a6b742b9f52d642d74bc716c7e96e8e0033"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QxNzoyODoyOVrOFqr2OA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QxNzoyOToyMVrOFqr3bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDMwMjkwNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                     * Disable the changelog for store built by this {@link StoreBuilder}.\n          \n          \n            \n                     * Disable the changelog for this suppression's internal buffer.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r380302904", "createdAt": "2020-02-17T17:28:29Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/Suppressed.java", "diffHunk": "@@ -118,6 +119,25 @@ static StrictBufferConfig unbounded() {\n          * duplicate results downstream, but does not promise to eliminate them.\n          */\n         EagerBufferConfig emitEarlyWhenFull();\n+\n+        /**\n+         * Disable the changelog for store built by this {@link StoreBuilder}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08d14a6b742b9f52d642d74bc716c7e96e8e0033"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDMwMzIxNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                     * This will turn off fault-tolerance for your store.\n          \n          \n            \n                     * This will turn off fault-tolerance for the suppression, and will result in data loss in the event of a rebalance.\n          \n      \n    \n    \n  \n\nThis isn't a \"store\", but rather a buffer internally used for suppression. Also, it seems appropriate to be a little more dire in our warning here because the internal nature of the buffer may make it less obvious to people what the downside of disabling this changelog is.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r380303214", "createdAt": "2020-02-17T17:29:21Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/kstream/Suppressed.java", "diffHunk": "@@ -118,6 +119,25 @@ static StrictBufferConfig unbounded() {\n          * duplicate results downstream, but does not promise to eliminate them.\n          */\n         EagerBufferConfig emitEarlyWhenFull();\n+\n+        /**\n+         * Disable the changelog for store built by this {@link StoreBuilder}.\n+         * This will turn off fault-tolerance for your store.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08d14a6b742b9f52d642d74bc716c7e96e8e0033"}, "originalPosition": 15}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "08d14a6b742b9f52d642d74bc716c7e96e8e0033", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/08d14a6b742b9f52d642d74bc716c7e96e8e0033", "committedDate": "2020-02-01T05:50:31Z", "message": "KAFKA-8147: Add changelog topic configuration to KTable suppress"}, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwNTY3NTMz", "url": "https://github.com/apache/kafka/pull/8029#pullrequestreview-360567533", "createdAt": "2020-02-18T18:22:27Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxMzAyMTc5", "url": "https://github.com/apache/kafka/pull/8029#pullrequestreview-361302179", "createdAt": "2020-02-19T17:46:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo0NjoxNlrOFrxK0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNzo1NDowNlrOFrxcJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzODY3Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n          \n          \n            \n                        assertThat(CLUSTER.getAllTopicsInCluster(), contains(changeLog));\n          \n      \n    \n    \n  \n\nEquivalent, but gives a better error message when it fails.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381438672", "createdAt": "2020-02-19T17:46:16Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzOTQ3NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void shouldWithLoggingEnable() {\n          \n          \n            \n                public void shouldAllowOverridingChangelogConfig() {\n          \n      \n    \n    \n  \n\nNot a big deal, but it's a little nicer when the test methods explain exactly what they are testing.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381439475", "createdAt": "2020-02-19T17:47:36Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzOTY2Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void shouldWithLoggingDisable() {\n          \n          \n            \n                public void should createChangelogByDefault() {", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381439666", "createdAt": "2020-02-19T17:47:56Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQ0MDM1Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            .withLoggingEnabled(Collections.emptyMap())))", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381440353", "createdAt": "2020-02-19T17:49:06Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {\n+        final String testId = \"-shouldWithLoggingDisable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingDisable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(Collections.emptyMap())))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQ0MDk4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        assertThat(config.getProperty(\"retention.ms\"), Matchers.is(nullValue()));\n          \n          \n            \n                        assertThat(CLUSTER.getAllTopicsInCluster(), contains(changeLog));\n          \n      \n    \n    \n  \n\nAnd we can remove line 426, final Properties config = CLUSTER.getLogConfig(changeLog);, since it would be unused.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381440981", "createdAt": "2020-02-19T17:50:21Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {\n+        final String testId = \"-shouldWithLoggingDisable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingDisable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(Collections.emptyMap())))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), Matchers.is(nullValue()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQ0MzExMA==", "bodyText": "It seems like this test would be more useful just as an assertion of the default behavior.", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381443110", "createdAt": "2020-02-19T17:54:06Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzOTY2Ng=="}, "originalCommit": null, "originalPosition": 84}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYyODUyNzYz", "url": "https://github.com/apache/kafka/pull/8029#pullrequestreview-362852763", "createdAt": "2020-02-21T19:09:37Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "81ce750f9f9beb835d5026f4a0dd6885c0398b3f", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/81ce750f9f9beb835d5026f4a0dd6885c0398b3f", "committedDate": "2020-02-22T00:28:27Z", "message": "KAFKA-8147: Add changelog topic configuration to KTable suppress"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "81ce750f9f9beb835d5026f4a0dd6885c0398b3f", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/81ce750f9f9beb835d5026f4a0dd6885c0398b3f", "committedDate": "2020-02-22T00:28:27Z", "message": "KAFKA-8147: Add changelog topic configuration to KTable suppress"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY0Mzc4MjUy", "url": "https://github.com/apache/kafka/pull/8029#pullrequestreview-364378252", "createdAt": "2020-02-25T19:14:42Z", "commit": {"oid": "81ce750f9f9beb835d5026f4a0dd6885c0398b3f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1697, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}