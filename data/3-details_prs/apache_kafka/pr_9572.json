{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE2OTE5NDQw", "number": 9572, "title": "KAFKA-10500: Thread Cache Resizes", "bodyText": "The thread cache can now be resized. This will go towards being able to scale the number of threads\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-11-06T18:48:33Z", "url": "https://github.com/apache/kafka/pull/9572", "merged": true, "mergeCommit": {"oid": "d12fbb7c0077fba23282adb84ff87635d6e44e5e"}, "closed": true, "closedAt": "2020-11-18T23:45:41Z", "author": {"login": "wcarlson5"}, "timelineItems": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdZ_SvjAFqTUyNTU0ODY4OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABddxnvuAH2gAyNTE2OTE5NDQwOmI2OWI2YjI1NmY3NzQ0ODA5N2ExNDRmNWY5ZWYwZTE0ZmVkMTQ0NWY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1NTQ4Njg4", "url": "https://github.com/apache/kafka/pull/9572#pullrequestreview-525548688", "createdAt": "2020-11-06T23:09:50Z", "commit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQyMzowOTo1MFrOHvAQZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQyMzowOTo1MFrOHvAQZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw==", "bodyText": "I am not sure if I should just expose cache or pass it along. It is about 4 levels deep", "url": "https://github.com/apache/kafka/pull/9572#discussion_r519049317", "createdAt": "2020-11-06T23:09:50Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3MDQ5MzY4", "url": "https://github.com/apache/kafka/pull/9572#pullrequestreview-527049368", "createdAt": "2020-11-10T10:14:03Z", "commit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMDoxNDowM1rOHwVaBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMTo1MjozN1rOHwZFmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NDQyMA==", "bodyText": "I see that this check was there before, but I actually think it is not needed because the configs are validated and there CACHE_MAX_BYTES_BUFFERING_CONFIG is specified as at least 0.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520444420", "createdAt": "2020-11-10T10:14:03Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,21 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        if (totalCacheSize < 0) {\n+            totalCacheSize = 0L;\n+            log.warn(\"Negative cache size passed in. Reverting to cache size of 0 bytes.\");\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NTc4Nw==", "bodyText": "I think this can be a final long if we remove the check as I proposed below.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520445787", "createdAt": "2020-11-10T10:16:03Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -155,6 +155,7 @@\n     private final StreamsMetricsImpl streamsMetrics;\n     private final ProcessorTopology taskTopology;\n     private final ProcessorTopology globalTaskTopology;\n+    private Long totalCacheSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ5ODU2NA==", "bodyText": "I am in favour of keeping a reference to the thread cache in the StreamThread and do the re-sizing here. I think it makes the code a bit easier to follow.\nYou will need synchronization, because the thread that will add the new stream thread will also resize the thread caches.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520498564", "createdAt": "2020-11-10T11:41:05Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUwNDcyOQ==", "bodyText": "This loop has the disadvantage that it first evict entries of one named cache, if all entries are evicted and we still need to free space, it starts to evict entries of the next named cache etc. I guess it would be better to avoid such a skewed emission of records to downstream by continuously iterating over the named caches and evict one entry at a time from each named cache until enough space is freed.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520504729", "createdAt": "2020-11-10T11:52:37Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +71,16 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            for (final NamedCache cache : caches.values()) {\n+                maybeEvict(cache.name());\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4MDMwMTUw", "url": "https://github.com/apache/kafka/pull/9572#pullrequestreview-528030150", "createdAt": "2020-11-11T10:04:46Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxMDowNDo0NlrOHxGcog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxMDoxMDoyNVrOHxGp6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0NzkwNg==", "bodyText": "Why does this need to be a Long instead of a long? The numerical value of the variable is only immutable if we use a long here.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521247906", "createdAt": "2020-11-11T10:04:46Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -155,6 +155,7 @@\n     private final StreamsMetricsImpl streamsMetrics;\n     private final ProcessorTopology taskTopology;\n     private final ProcessorTopology globalTaskTopology;\n+    private final Long totalCacheSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0OTA3NA==", "bodyText": "IMO, the code would be easier navigable if you inline this method. Without the removed check, there is not really a reason to have a method here.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521249074", "createdAt": "2020-11-11T10:06:42Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,17 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI1MTMwNA==", "bodyText": "I was not planning on having the new thread resize the cache but the calling thread do so\n\nThat is what I am saying \"the thread that will add the new stream thread\" is the calling thread. The new stream thread cannot resize the caches of the other stream threads because it is not aware of the other stream threads. Still we need synchronization because the calling thread will access and modify the thread caches of all stream threads and all stream threads will access and modify their own thread cache during normal processing.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521251304", "createdAt": "2020-11-11T10:10:25Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyNjc5MjA5", "url": "https://github.com/apache/kafka/pull/9572#pullrequestreview-532679209", "createdAt": "2020-11-17T18:41:19Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODo0MToxOVrOH1Dz_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODo1NTowMFrOH1EVvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTAzOA==", "bodyText": "Why do we remove this guard?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525399038", "createdAt": "2020-11-17T18:41:19Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -728,12 +729,8 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 \"must subscribe to at least one source topic or global table.\");\n         }\n \n-        long totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n-        if (totalCacheSize < 0) {\n-            totalCacheSize = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTM5Ng==", "bodyText": "Why move off using hasGlobalTopology?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525399396", "createdAt": "2020-11-17T18:41:53Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -728,12 +729,8 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 \"must subscribe to at least one source topic or global table.\");\n         }\n \n-        long totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n-        if (totalCacheSize < 0) {\n-            totalCacheSize = 0;\n-            log.warn(\"Negative cache size passed in. Reverting to cache size of 0 bytes.\");\n-        }\n-        final long cacheSizePerThread = totalCacheSize / (numStreamThreads + (hasGlobalTopology ? 1 : 0));\n+        totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n+        final long cacheSizePerThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng==", "bodyText": "Seems this duplicates L733. Might be good to extract into a small helper method.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525404296", "createdAt": "2020-11-17T18:49:40Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,13 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private void resizeThreadCache(final int numStreamThreads) {\n+        final long cacheSizePreThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNTYxNQ==", "bodyText": "Why do we need the cacheResizer? Can't we just call cache.resize(size) here?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525405615", "createdAt": "2020-11-17T18:51:45Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +593,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        cacheResizer.accept(size);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNjUxNQ==", "bodyText": "nit: newCachSizeBytes ? (To avoid the \"clash\" with this.maxCachSizeBytes.)", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525406515", "createdAt": "2020-11-17T18:53:12Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNzY3Nw==", "bodyText": "Could this ever happen? If we the max cache size is smaller than a single entry, would we not evict the entry and the used cache size would always shrink to zero?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525407677", "createdAt": "2020-11-17T18:55:00Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            final CircularIterator<NamedCache> circularIterator = new CircularIterator<>(caches.values());\n+            while (sizeBytes() > maxCacheSizeBytes) {\n+                if (!circularIterator.hasNext()) {\n+                    log.error(\"Unable to remove any more entries as all caches are empty\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyODI0MDYz", "url": "https://github.com/apache/kafka/pull/9572#pullrequestreview-532824063", "createdAt": "2020-11-17T21:23:53Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMToyMzo1NFrOH1MBmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMToyMzo1NFrOH1MBmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw==", "bodyText": "Can it be smaller than 0 ? Should the test be <= 0 or < 1 instead?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525533593", "createdAt": "2020-11-17T21:23:54Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,20 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }\n+\n+    private void resizeThreadCache(final int numStreamThreads) {\n+        if (numStreamThreads < 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyODI0Njkw", "url": "https://github.com/apache/kafka/pull/9572#pullrequestreview-532824690", "createdAt": "2020-11-17T21:24:49Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMToyNDo0OVrOH1MD1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMToyNDo0OVrOH1MD1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzNDE2Nw==", "bodyText": "nit: we can remove this. now (same next line)", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525534167", "createdAt": "2020-11-17T21:24:49Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,22 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long newCacheSizeBytes) {\n+        final boolean shrink = newCacheSizeBytes < this.maxCacheSizeBytes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ecb17f434fc6c08e5810e14ff668d9ef0c67f9f5", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/ecb17f434fc6c08e5810e14ff668d9ef0c67f9f5", "committedDate": "2020-11-18T17:12:30Z", "message": "ThreadCache Resizes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41c9dca704b5541b267692dac07c033ba119dfa4", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/41c9dca704b5541b267692dac07c033ba119dfa4", "committedDate": "2020-11-18T17:12:30Z", "message": "fix typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2d3b0fb2f30ba66b13955c80bbc83ce255336bc", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/a2d3b0fb2f30ba66b13955c80bbc83ce255336bc", "committedDate": "2020-11-18T17:12:30Z", "message": "address comments and evenly clear cache"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eade1c7ece7a7cc92349a95d69e90ad56696402d", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/eade1c7ece7a7cc92349a95d69e90ad56696402d", "committedDate": "2020-11-18T17:12:30Z", "message": "make final"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb8078f5a018d0d2b49b7282afea9c508f72ae94", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/cb8078f5a018d0d2b49b7282afea9c508f72ae94", "committedDate": "2020-11-18T17:12:30Z", "message": "comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1ed3914fc618d769fd01d4996b2c2af5e915ca55", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/1ed3914fc618d769fd01d4996b2c2af5e915ca55", "committedDate": "2020-11-18T17:27:57Z", "message": "make maxCacheSize volatile and wrapped thread cache"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7a3edb35789bcd28867a3312bbd2e3656d9a175", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/d7a3edb35789bcd28867a3312bbd2e3656d9a175", "committedDate": "2020-11-18T17:27:57Z", "message": "change to consumer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53d92c5a7faed35d9771434d8d71777a3ceccf31", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/53d92c5a7faed35d9771434d8d71777a3ceccf31", "committedDate": "2020-11-18T17:27:57Z", "message": "improved names and checks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c4b78e59ba44c1f0f84ffa4d5f484e8a07cf4081", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/c4b78e59ba44c1f0f84ffa4d5f484e8a07cf4081", "committedDate": "2020-11-18T17:29:47Z", "message": "couple of comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2698000507c8e675b247dc7dbbd3a60cbe39bbdf", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/2698000507c8e675b247dc7dbbd3a60cbe39bbdf", "committedDate": "2020-11-18T17:29:47Z", "message": "make helper for cache size"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26fb2a9c206178db3a248807c5f8fb114deb844f", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/26fb2a9c206178db3a248807c5f8fb114deb844f", "committedDate": "2020-11-18T17:29:47Z", "message": "remove this"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b69b6b256f77448097a144f5f9ef0e14fed1445f", "author": {"user": {"login": "wcarlson5", "name": "Walker Carlson"}}, "url": "https://github.com/apache/kafka/commit/b69b6b256f77448097a144f5f9ef0e14fed1445f", "committedDate": "2020-11-18T17:29:48Z", "message": "remove redundant check"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2728, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}