{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTExNzE0MDc0", "number": 9521, "title": "KAFKA-10638: Fix QueryableStateIntegrationTest", "bodyText": "This test has been observed to have flaky failures.\nApparently, in the failed runs, Streams had entered a rebalance\nbefore some of the assertions were made. We recently made\nIQ a little stricter on whether it would return errors instead of\nnull responses in such cases:\nKAFKA-10598: Improve IQ name and type checks (#9408)\nAs a result, we have started seeing failures now instead of\nsilently executing an invalid test (I.e., it was asserting the\nreturn to be null, but the result was null for the wrong\nreason).\nNow, if the test discovers that Streams is no longer running,\nit will repeat the verification until it actually gets a valid\npositive or negative result.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-10-28T17:22:10Z", "url": "https://github.com/apache/kafka/pull/9521", "merged": true, "mergeCommit": {"oid": "933a813950b1ae06e19ead23734fa6bdf1f32e3f"}, "closed": true, "closedAt": "2020-10-29T16:57:31Z", "author": {"login": "vvcephei"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdXA0BfgH2gAyNTExNzE0MDc0OjUwMGNkYWVlOGE1M2Q2MTBkNmY5ZGIyZDc5ZjhhZGQxNTU0ODkzZGI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdXKGK4gFqTUxOTMxNzA4MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/500cdaee8a53d610d6f9db2d79f8add1554893db", "committedDate": "2020-10-28T17:14:19Z", "message": "KAFKA-10638: Fix QueryableStateIntegrationTest"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE4OTExMzc5", "url": "https://github.com/apache/kafka/pull/9521#pullrequestreview-518911379", "createdAt": "2020-10-28T17:23:07Z", "commit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNzoyMzowN1rOHp1W9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNzoyOTo1MFrOHp1prQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYyNzg5Mg==", "bodyText": "I went ahead and fixed the whitespace also, since this PR is relatively small.", "url": "https://github.com/apache/kafka/pull/9521#discussion_r513627892", "createdAt": "2020-10-28T17:23:07Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -102,10 +111,10 @@ public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n \n         final StreamsBuilder builder = new StreamsBuilder();\n         builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n-                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n-                                .withCachingDisabled())\n-                .toStream()\n-                .peek((k, v) -> semaphore.release());\n+                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n+                          .withCachingDisabled())\n+               .toStream()\n+               .peek((k, v) -> semaphore.release());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYyODE3Nw==", "bodyText": "This class is in the same package, so the fully-qualified name is not necessary.", "url": "https://github.com/apache/kafka/pull/9521#discussion_r513628177", "createdAt": "2020-10-28T17:23:33Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/QueryableStoreType.java", "diffHunk": "@@ -44,7 +44,7 @@\n      * @param storeProvider     provides access to all the underlying StateStore instances\n      * @param storeName         The name of the Store\n      * @return a read-only interface over a {@code StateStore}\n-     *        (cf. {@link org.apache.kafka.streams.state.QueryableStoreTypes.KeyValueStoreType})\n+     *        (cf. {@link QueryableStoreTypes.KeyValueStoreType})", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYyOTI0MA==", "bodyText": "This is the meat of this change. If we do get an exception, we can still verify the exception is the one we expected to get, and then we return false to indicate we should try again later to get a successful verification.", "url": "https://github.com/apache/kafka/pull/9521#discussion_r513629240", "createdAt": "2020-10-28T17:25:03Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -117,17 +126,34 @@ public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n \n         // Assert that all messages in the first batch were processed in a timely manner\n         assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n-        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n-\n-        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n-        final ReadOnlyKeyValueStore<Integer, Integer> store1 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n-        final ReadOnlyKeyValueStore<Integer, Integer> store2 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n-\n-        final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n-\n-        // Assert that only active is able to query for a key by default\n-        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n-        assertThat(kafkaStreams1IsActive ? store2.get(key) : store1.get(key), is(nullValue()));\n+        until(() -> {\n+\n+            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n+\n+            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n+            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n+            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n+\n+            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n+\n+            // Assert that only active is able to query for a key by default\n+            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n+            try {\n+                if (kafkaStreams1IsActive) {\n+                    assertThat(store2.get(key), is(nullValue()));\n+                } else {\n+                    assertThat(store1.get(key), is(nullValue()));\n+                }\n+                return true;\n+            } catch (final InvalidStateStoreException exception) {\n+                assertThat(\n+                    exception.getMessage(),\n+                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n+                );\n+                LOG.info(\"Streams wasn't running. Will try again.\");\n+                return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYzMTA4NQ==", "bodyText": "Also, here, if we find that Streams is rebalancing, we'll try the whole verification again, including to re-discover the stores in case the stores have swapped ownership.", "url": "https://github.com/apache/kafka/pull/9521#discussion_r513631085", "createdAt": "2020-10-28T17:27:30Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -153,51 +179,75 @@ public void shouldQuerySpecificActivePartitionStores() throws Exception {\n \n         // Assert that all messages in the first batch were processed in a timely manner\n         assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n-        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n-\n-        //key belongs to this partition\n-        final int keyPartition = keyQueryMetadata.partition();\n-\n-        //key doesn't belongs to this partition\n-        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n-        final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n-\n-        StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n-            StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n-                .withPartition(keyPartition);\n-        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n-        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n-        if (kafkaStreams1IsActive) {\n-            store1 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n-        } else {\n-            store2 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n-        }\n-\n-        if (kafkaStreams1IsActive) {\n-            assertThat(store1, is(notNullValue()));\n-            assertThat(store2, is(nullValue()));\n-        } else {\n-            assertThat(store2, is(notNullValue()));\n-            assertThat(store1, is(nullValue()));\n-        }\n+        until(() -> {\n+            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n+\n+            //key belongs to this partition\n+            final int keyPartition = keyQueryMetadata.partition();\n+\n+            //key doesn't belongs to this partition\n+            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n+            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n+\n+            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n+                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n+                    .withPartition(keyPartition);\n+            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n+            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n+            if (kafkaStreams1IsActive) {\n+                store1 = getStore(kafkaStreams1, storeQueryParam);\n+            } else {\n+                store2 = getStore(kafkaStreams2, storeQueryParam);\n+            }\n+\n+            if (kafkaStreams1IsActive) {\n+                assertThat(store1, is(notNullValue()));\n+                assertThat(store2, is(nullValue()));\n+            } else {\n+                assertThat(store2, is(notNullValue()));\n+                assertThat(store1, is(nullValue()));\n+            }\n+\n+            // Assert that only active for a specific requested partition serves key if stale stores and not enabled\n+            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n+\n+            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n+                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n+                .withPartition(keyDontBelongPartition);\n \n-        // Assert that only active for a specific requested partition serves key if stale stores and not enabled\n-        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n \n-        storeQueryParam = StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n-            .withPartition(keyDontBelongPartition);\n-        ReadOnlyKeyValueStore<Integer, Integer> store3 = null;\n-        ReadOnlyKeyValueStore<Integer, Integer> store4 = null;\n-        if (!kafkaStreams1IsActive) {\n-            store3 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n-        } else {\n-            store4 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n-        }\n \n-        // Assert that key is not served when wrong specific partition is requested\n-        // If kafkaStreams1 is active for keyPartition, kafkaStreams2 would be active for keyDontBelongPartition\n-        // So, in that case, store3 would be null and the store4 would not return the value for key as wrong partition was requested\n-        assertThat(kafkaStreams1IsActive ? store4.get(key) : store3.get(key), is(nullValue()));\n+            try {\n+                // Assert that key is not served when wrong specific partition is requested\n+                // If kafkaStreams1 is active for keyPartition, kafkaStreams2 would be active for keyDontBelongPartition\n+                // So, in that case, store3 would be null and the store4 would not return the value for key as wrong partition was requested\n+                if (kafkaStreams1IsActive) {\n+                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n+                    final InvalidStateStoreException exception =\n+                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n+                    assertThat(\n+                        exception.getMessage(),\n+                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n+                    );\n+                } else {\n+                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n+                    final InvalidStateStoreException exception =\n+                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n+                    assertThat(\n+                        exception.getMessage(),\n+                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n+                    );\n+                }\n+                return true;\n+            } catch (final InvalidStateStoreException exception) {\n+                assertThat(\n+                    exception.getMessage(),\n+                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n+                );\n+                LOG.info(\"Streams wasn't running. Will try again.\");\n+                return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYzMjY4NQ==", "bodyText": "Note, this is different than TestUtils.waitForCondition, which does the inverse thing. That one will retry on exceptions and otherwise verify that the return is true. We need to fail on exceptions and retry as long as the return is false.\nI opted to keep this method here, since it might be confusing next to the other util method.", "url": "https://github.com/apache/kafka/pull/9521#discussion_r513632685", "createdAt": "2020-10-28T17:29:50Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -337,34 +385,49 @@ public void shouldQuerySpecificStalePartitionStoresMultiStreamThreads() throws E\n \n         //key doesn't belongs to this partition\n         final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n-        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n+        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n \n         // Assert that both active and standby are able to query for a key\n         final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> param = StoreQueryParameters\n-                .fromNameAndType(TABLE_NAME, queryableStoreType)\n-                .enableStaleStores()\n-                .withPartition(keyPartition);\n+            .fromNameAndType(TABLE_NAME, queryableStoreType)\n+            .enableStaleStores()\n+            .withPartition(keyPartition);\n         TestUtils.waitForCondition(() -> {\n-            final ReadOnlyKeyValueStore<Integer, Integer> store1 = IntegrationTestUtils.getStore(kafkaStreams1, param);\n+            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(kafkaStreams1, param);\n             return store1.get(key) != null;\n         }, \"store1 cannot find results for key\");\n         TestUtils.waitForCondition(() -> {\n-            final ReadOnlyKeyValueStore<Integer, Integer> store2 = IntegrationTestUtils.getStore(kafkaStreams2, param);\n+            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(kafkaStreams2, param);\n             return store2.get(key) != null;\n         }, \"store2 cannot find results for key\");\n \n         final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> otherParam = StoreQueryParameters\n-                .fromNameAndType(TABLE_NAME, queryableStoreType)\n-                .enableStaleStores()\n-                .withPartition(keyDontBelongPartition);\n-        final ReadOnlyKeyValueStore<Integer, Integer> store3 = IntegrationTestUtils.getStore(kafkaStreams1, otherParam);\n-        final ReadOnlyKeyValueStore<Integer, Integer> store4 = IntegrationTestUtils.getStore(kafkaStreams2, otherParam);\n+            .fromNameAndType(TABLE_NAME, queryableStoreType)\n+            .enableStaleStores()\n+            .withPartition(keyDontBelongPartition);\n+        final ReadOnlyKeyValueStore<Integer, Integer> store3 = getStore(kafkaStreams1, otherParam);\n+        final ReadOnlyKeyValueStore<Integer, Integer> store4 = getStore(kafkaStreams2, otherParam);\n \n         // Assert that\n         assertThat(store3.get(key), is(nullValue()));\n         assertThat(store4.get(key), is(nullValue()));\n     }\n \n+    private static void until(final TestCondition condition) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db"}, "originalPosition": 390}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE5MzE3MDgx", "url": "https://github.com/apache/kafka/pull/9521#pullrequestreview-519317081", "createdAt": "2020-10-29T04:00:05Z", "commit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQwNDowMDowNVrOHqIZwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQwNDowMTo0OVrOHqIeDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzkzOTkwNg==", "bodyText": "Why not handling the InvalidStateStoreException in the helper method until", "url": "https://github.com/apache/kafka/pull/9521#discussion_r513939906", "createdAt": "2020-10-29T04:00:05Z", "author": {"login": "chia7712"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -117,17 +126,34 @@ public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n \n         // Assert that all messages in the first batch were processed in a timely manner\n         assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n-        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n-\n-        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n-        final ReadOnlyKeyValueStore<Integer, Integer> store1 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n-        final ReadOnlyKeyValueStore<Integer, Integer> store2 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n-\n-        final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n-\n-        // Assert that only active is able to query for a key by default\n-        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n-        assertThat(kafkaStreams1IsActive ? store2.get(key) : store1.get(key), is(nullValue()));\n+        until(() -> {\n+\n+            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n+\n+            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n+            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n+            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n+\n+            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n+\n+            // Assert that only active is able to query for a key by default\n+            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n+            try {\n+                if (kafkaStreams1IsActive) {\n+                    assertThat(store2.get(key), is(nullValue()));\n+                } else {\n+                    assertThat(store1.get(key), is(nullValue()));\n+                }\n+                return true;\n+            } catch (final InvalidStateStoreException exception) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk0MTAwNg==", "bodyText": "which method can throw InvalidStateStoreException in this case? It seems to me the potential methods are caught by assertThrows", "url": "https://github.com/apache/kafka/pull/9521#discussion_r513941006", "createdAt": "2020-10-29T04:01:49Z", "author": {"login": "chia7712"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -153,51 +179,75 @@ public void shouldQuerySpecificActivePartitionStores() throws Exception {\n \n         // Assert that all messages in the first batch were processed in a timely manner\n         assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n-        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n-\n-        //key belongs to this partition\n-        final int keyPartition = keyQueryMetadata.partition();\n-\n-        //key doesn't belongs to this partition\n-        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n-        final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n-\n-        StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n-            StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n-                .withPartition(keyPartition);\n-        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n-        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n-        if (kafkaStreams1IsActive) {\n-            store1 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n-        } else {\n-            store2 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n-        }\n-\n-        if (kafkaStreams1IsActive) {\n-            assertThat(store1, is(notNullValue()));\n-            assertThat(store2, is(nullValue()));\n-        } else {\n-            assertThat(store2, is(notNullValue()));\n-            assertThat(store1, is(nullValue()));\n-        }\n+        until(() -> {\n+            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n+\n+            //key belongs to this partition\n+            final int keyPartition = keyQueryMetadata.partition();\n+\n+            //key doesn't belongs to this partition\n+            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n+            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n+\n+            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n+                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n+                    .withPartition(keyPartition);\n+            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n+            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n+            if (kafkaStreams1IsActive) {\n+                store1 = getStore(kafkaStreams1, storeQueryParam);\n+            } else {\n+                store2 = getStore(kafkaStreams2, storeQueryParam);\n+            }\n+\n+            if (kafkaStreams1IsActive) {\n+                assertThat(store1, is(notNullValue()));\n+                assertThat(store2, is(nullValue()));\n+            } else {\n+                assertThat(store2, is(notNullValue()));\n+                assertThat(store1, is(nullValue()));\n+            }\n+\n+            // Assert that only active for a specific requested partition serves key if stale stores and not enabled\n+            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n+\n+            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n+                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n+                .withPartition(keyDontBelongPartition);\n \n-        // Assert that only active for a specific requested partition serves key if stale stores and not enabled\n-        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n \n-        storeQueryParam = StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n-            .withPartition(keyDontBelongPartition);\n-        ReadOnlyKeyValueStore<Integer, Integer> store3 = null;\n-        ReadOnlyKeyValueStore<Integer, Integer> store4 = null;\n-        if (!kafkaStreams1IsActive) {\n-            store3 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n-        } else {\n-            store4 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n-        }\n \n-        // Assert that key is not served when wrong specific partition is requested\n-        // If kafkaStreams1 is active for keyPartition, kafkaStreams2 would be active for keyDontBelongPartition\n-        // So, in that case, store3 would be null and the store4 would not return the value for key as wrong partition was requested\n-        assertThat(kafkaStreams1IsActive ? store4.get(key) : store3.get(key), is(nullValue()));\n+            try {\n+                // Assert that key is not served when wrong specific partition is requested\n+                // If kafkaStreams1 is active for keyPartition, kafkaStreams2 would be active for keyDontBelongPartition\n+                // So, in that case, store3 would be null and the store4 would not return the value for key as wrong partition was requested\n+                if (kafkaStreams1IsActive) {\n+                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n+                    final InvalidStateStoreException exception =\n+                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n+                    assertThat(\n+                        exception.getMessage(),\n+                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n+                    );\n+                } else {\n+                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n+                    final InvalidStateStoreException exception =\n+                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n+                    assertThat(\n+                        exception.getMessage(),\n+                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n+                    );\n+                }\n+                return true;\n+            } catch (final InvalidStateStoreException exception) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "500cdaee8a53d610d6f9db2d79f8add1554893db"}, "originalPosition": 235}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2911, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}