{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxMjgxNTky", "number": 8833, "reviewThreads": {"totalCount": 37, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxMzo1MFrOEDi9yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMzozMzowOVrOEEfhyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMTU0MDU3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxMzo1MFrOGgoGMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxMzo1MFrOGgoGMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2NDU2MQ==", "bodyText": "When we suspend, we always want to commit.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436864561", "createdAt": "2020-06-08T17:13:50Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {\n+            transitionTo(State.SUSPENDED);\n+        }\n     }\n \n     @Override\n-    public void suspend() {\n-        log.trace(\"No-op suspend with state {}\", state());\n+    public void suspendCleanAndPrepareCommit() {\n+        log.trace(\"No-op suspend clean with state {}\", state());\n+        if (state() == State.RUNNING) {\n+            transitionTo(State.SUSPENDED);\n+        }\n+        prepareCommit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMTU0NjI1OnYy", "diffSide": "LEFT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxNTowNVrOGgoJgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxNTowNVrOGgoJgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2NTQxMA==", "bodyText": "This logic is now followed in suspendCleanAndPrepareCommit() that must be called before a task can be closed.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436865410", "createdAt": "2020-06-08T17:15:05Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -151,69 +157,23 @@ public void postCommit() {\n         }\n     }\n \n-    @Override\n-    public void prepareCloseClean() {\n-        prepareClose(true);\n-\n-        log.info(\"Prepared clean close\");\n-    }\n-\n-    @Override\n-    public void prepareCloseDirty() {\n-        prepareClose(false);\n-\n-        log.info(\"Prepared dirty close\");\n-    }\n-\n-    /**\n-     * 1. commit if we are running and clean close;\n-     * 2. close the state manager.\n-     *\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    private void prepareClose(final boolean clean) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMTU0OTQ5OnYy", "diffSide": "LEFT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxNTo1MVrOGgoLeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxNTo1MVrOGgoLeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2NTkxMw==", "bodyText": "This is now done via suspendAndPrepareCommit()", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436865913", "createdAt": "2020-06-08T17:15:51Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -246,82 +245,39 @@ public void completeRestoration() {\n         }\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     *  4. then commit the record collector -- for EOS this is the synchronization barrier\n-     *  5. then checkpoint the state manager -- even if we crash before this step, EOS is still guaranteed\n-     * </pre>\n-     *\n-     * @throws TaskMigratedException if committing offsets failed (non-EOS)\n-     *                               or if the task producer got fenced (EOS)\n-     */\n     @Override\n-    public void prepareSuspend() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMTU1NzMzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxNzo0M1rOGgoQFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxNzo0M1rOGgoQFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2NzA5Mg==", "bodyText": "The \"old\" suspend() was called after committing, the \"new\" suspend() is now called before committing!\nThe old suspend logic is now handled via postCommit and close", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436867092", "createdAt": "2020-06-08T17:17:43Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -246,82 +245,39 @@ public void completeRestoration() {\n         }\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     *  4. then commit the record collector -- for EOS this is the synchronization barrier\n-     *  5. then checkpoint the state manager -- even if we crash before this step, EOS is still guaranteed\n-     * </pre>\n-     *\n-     * @throws TaskMigratedException if committing offsets failed (non-EOS)\n-     *                               or if the task producer got fenced (EOS)\n-     */\n     @Override\n-    public void prepareSuspend() {\n-        switch (state()) {\n-            case CREATED:\n-            case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip prepare suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RESTORING:\n-                stateMgr.flush();\n-                log.info(\"Prepare suspending restoring\");\n-\n-                break;\n-\n-            case RUNNING:\n-                closeTopology(true);\n-\n-                stateMgr.flush();\n-                recordCollector.flush();\n-\n-                log.info(\"Prepare suspending running\");\n-\n-                break;\n-\n-            case CLOSED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while suspending active task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while suspending active task \" + id);\n-        }\n+    public void suspendDirty() {\n+        log.info(\"Suspending dirty\");\n+        suspend(false);\n     }\n \n     @Override\n-    public void suspend() {\n+    public void suspendCleanAndPrepareCommit() {\n+        log.info(\"Suspending clean\");\n+        suspend(true);\n+    }\n+\n+    @SuppressWarnings(\"fallthrough\")\n+    private void suspend(final boolean clean) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMTU2MzIwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxOTowN1rOGgoTbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoxOTowN1rOGgoTbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2Nzk0OQ==", "bodyText": "Instead of \"blindly\" writing a checkpoint in postCommit(), we only do it if a checkpoint get's scheduled.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436867949", "createdAt": "2020-06-08T17:19:07Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -369,6 +325,8 @@ public void prepareCommit() {\n         switch (state()) {\n             case RUNNING:\n             case RESTORING:\n+            case SUSPENDED:\n+                maybeScheduleCheckpoint();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 114}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMTU2ODU2OnYy", "diffSide": "LEFT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoyMDoyNFrOGgoWlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzoyMDoyNFrOGgoWlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2ODc1OQ==", "bodyText": "Mainly rewrite to use switch now -- however, we return a proper non-empty checkpoint on SUSPEND now.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436868759", "createdAt": "2020-06-08T17:20:24Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -423,39 +377,51 @@ public void postCommit() {\n \n     @Override\n     public Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n-        if (state() == State.CLOSED) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjMwMTM5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMDozOTowMFrOGgvj6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMDozOTowMFrOGgvj6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjk4Njg1OQ==", "bodyText": "Should update the exception text like while scheduling checkpoint", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436986859", "createdAt": "2020-06-08T20:39:00Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -534,62 +482,38 @@ public void closeAndRecycleState() {\n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = Collections.emptyMap();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing active task \" + id);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 360}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjMwMjYyOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMDozOToyOFrOGgvkyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMDozOToyOFrOGgvkyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjk4NzA4MQ==", "bodyText": "similar here", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436987081", "createdAt": "2020-06-08T20:39:28Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -534,62 +482,38 @@ public void closeAndRecycleState() {\n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = Collections.emptyMap();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing active task \" + id);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 364}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjMwNDM3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMDo0MDowNlrOGgvl4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToyNjowMFrOGg1pIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjk4NzM2Mw==", "bodyText": "if commit is needed", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436987363", "createdAt": "2020-06-08T20:40:06Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -534,62 +482,38 @@ public void closeAndRecycleState() {\n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = Collections.emptyMap();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {\n+            throw new IllegalStateException(\"A checkpoint should only be written if now commit is needed.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 374}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NjQ5OA==", "bodyText": "Should be if no commit is needed (ie, if we need to commit, we need to commit first! -- writing a checkpoint as long as a commit is needed implies we write the checkpoint too early).", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437086498", "createdAt": "2020-06-09T01:26:00Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -534,62 +482,38 @@ public void closeAndRecycleState() {\n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = Collections.emptyMap();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {\n+            throw new IllegalStateException(\"A checkpoint should only be written if now commit is needed.\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjk4NzM2Mw=="}, "originalCommit": null, "originalPosition": 374}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjMwODc4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMDo0MToyM1rOGgvoew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToxOTowMlrOGg1iHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjk4ODAyNw==", "bodyText": "Seems applied to both RUNNING and SUSPENDED?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r436988027", "createdAt": "2020-06-08T20:41:23Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -389,30 +346,27 @@ public void prepareCommit() {\n     @Override\n     public void postCommit() {\n         switch (state()) {\n+            case RESTORING:\n             case RUNNING:\n-                commitNeeded = false;\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.RESTORING) {\n+                    writeCheckpointIfNeed();\n+                } else if (!eosEnabled) { // if RUNNING, checkpoint only for non-eos", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDcwMA==", "bodyText": "For SUSPENDING, we should always write the checkpoint. Fixing.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437084700", "createdAt": "2020-06-09T01:19:02Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -389,30 +346,27 @@ public void prepareCommit() {\n     @Override\n     public void postCommit() {\n         switch (state()) {\n+            case RESTORING:\n             case RUNNING:\n-                commitNeeded = false;\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.RESTORING) {\n+                    writeCheckpointIfNeed();\n+                } else if (!eosEnabled) { // if RUNNING, checkpoint only for non-eos", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjk4ODAyNw=="}, "originalCommit": null, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjQwMjg0OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMToxMTowN1rOGgwkIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMToxMTowN1rOGgwkIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAwMzI5Ng==", "bodyText": "This comment could be removed IMHO.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437003296", "createdAt": "2020-06-08T21:11:07Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -246,82 +245,39 @@ public void completeRestoration() {\n         }\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     *  4. then commit the record collector -- for EOS this is the synchronization barrier\n-     *  5. then checkpoint the state manager -- even if we crash before this step, EOS is still guaranteed\n-     * </pre>\n-     *\n-     * @throws TaskMigratedException if committing offsets failed (non-EOS)\n-     *                               or if the task producer got fenced (EOS)\n-     */\n     @Override\n-    public void prepareSuspend() {\n-        switch (state()) {\n-            case CREATED:\n-            case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip prepare suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RESTORING:\n-                stateMgr.flush();\n-                log.info(\"Prepare suspending restoring\");\n-\n-                break;\n-\n-            case RUNNING:\n-                closeTopology(true);\n-\n-                stateMgr.flush();\n-                recordCollector.flush();\n-\n-                log.info(\"Prepare suspending running\");\n-\n-                break;\n-\n-            case CLOSED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while suspending active task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while suspending active task \" + id);\n-        }\n+    public void suspendDirty() {\n+        log.info(\"Suspending dirty\");\n+        suspend(false);\n     }\n \n     @Override\n-    public void suspend() {\n+    public void suspendCleanAndPrepareCommit() {\n+        log.info(\"Suspending clean\");\n+        suspend(true);\n+    }\n+\n+    @SuppressWarnings(\"fallthrough\")\n+    private void suspend(final boolean clean) {\n         switch (state()) {\n             case CREATED:\n             case SUSPENDED:\n                 // do nothing", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjQxNDk5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMToxNTowMlrOGgwruQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMToxNTowMlrOGgwruQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAwNTI0MQ==", "bodyText": "a standby task is never in", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437005241", "createdAt": "2020-06-08T21:15:02Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -260,8 +220,8 @@ private void close(final boolean clean) {\n                 log.trace(\"Skip closing since state is {}\", state());\n                 return;\n \n-            case RESTORING:\n-            case SUSPENDED:\n+            case RESTORING: // a StandbyTask in never in RESTORING state", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 129}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjQyMTAyOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMToxNjozOVrOGgwvRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDo1MjozNVrOGg1HnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAwNjE0OA==", "bodyText": "Seems like we could use a separate illegal state exception here for RESTORING as we should never hit it.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437006148", "createdAt": "2020-06-08T21:16:39Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -260,8 +220,8 @@ private void close(final boolean clean) {\n                 log.trace(\"Skip closing since state is {}\", state());\n                 return;\n \n-            case RESTORING:\n-            case SUSPENDED:\n+            case RESTORING: // a StandbyTask in never in RESTORING state", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA3NzkxNw==", "bodyText": "We can, but does it help much?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437077917", "createdAt": "2020-06-09T00:52:35Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -260,8 +220,8 @@ private void close(final boolean clean) {\n                 log.trace(\"Skip closing since state is {}\", state());\n                 return;\n \n-            case RESTORING:\n-            case SUSPENDED:\n+            case RESTORING: // a StandbyTask in never in RESTORING state", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAwNjE0OA=="}, "originalCommit": null, "originalPosition": 129}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjQ0OTAwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMToyNTo0N1rOGgxAcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToxNToxM1rOGg1ekQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAxMDU0NA==", "bodyText": "Although this holds true for now, I'm thinking whether in long term a commit will always follow suspendClean, what's the downside of having these two logics separate?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437010544", "createdAt": "2020-06-08T21:25:47Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -246,82 +245,39 @@ public void completeRestoration() {\n         }\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     *  4. then commit the record collector -- for EOS this is the synchronization barrier\n-     *  5. then checkpoint the state manager -- even if we crash before this step, EOS is still guaranteed\n-     * </pre>\n-     *\n-     * @throws TaskMigratedException if committing offsets failed (non-EOS)\n-     *                               or if the task producer got fenced (EOS)\n-     */\n     @Override\n-    public void prepareSuspend() {\n-        switch (state()) {\n-            case CREATED:\n-            case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip prepare suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RESTORING:\n-                stateMgr.flush();\n-                log.info(\"Prepare suspending restoring\");\n-\n-                break;\n-\n-            case RUNNING:\n-                closeTopology(true);\n-\n-                stateMgr.flush();\n-                recordCollector.flush();\n-\n-                log.info(\"Prepare suspending running\");\n-\n-                break;\n-\n-            case CLOSED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while suspending active task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while suspending active task \" + id);\n-        }\n+    public void suspendDirty() {\n+        log.info(\"Suspending dirty\");\n+        suspend(false);\n     }\n \n     @Override\n-    public void suspend() {\n+    public void suspendCleanAndPrepareCommit() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4Mzc5Mw==", "bodyText": "The downside is, that the caller must make sure to call both methods. (In 3 places in the code atm) -- We can also decouple them later if required. -- Don't have a very strong opinion about it, the idea was just to make it simpler for the caller.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437083793", "createdAt": "2020-06-09T01:15:13Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -246,82 +245,39 @@ public void completeRestoration() {\n         }\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     *  4. then commit the record collector -- for EOS this is the synchronization barrier\n-     *  5. then checkpoint the state manager -- even if we crash before this step, EOS is still guaranteed\n-     * </pre>\n-     *\n-     * @throws TaskMigratedException if committing offsets failed (non-EOS)\n-     *                               or if the task producer got fenced (EOS)\n-     */\n     @Override\n-    public void prepareSuspend() {\n-        switch (state()) {\n-            case CREATED:\n-            case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip prepare suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RESTORING:\n-                stateMgr.flush();\n-                log.info(\"Prepare suspending restoring\");\n-\n-                break;\n-\n-            case RUNNING:\n-                closeTopology(true);\n-\n-                stateMgr.flush();\n-                recordCollector.flush();\n-\n-                log.info(\"Prepare suspending running\");\n-\n-                break;\n-\n-            case CLOSED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while suspending active task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while suspending active task \" + id);\n-        }\n+    public void suspendDirty() {\n+        log.info(\"Suspending dirty\");\n+        suspend(false);\n     }\n \n     @Override\n-    public void suspend() {\n+    public void suspendCleanAndPrepareCommit() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAxMDU0NA=="}, "originalCommit": null, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjQ2MjUwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMTozMDo0NFrOGgxI8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToxNjo1NlrOGg1gEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAxMjcyMg==", "bodyText": "Could we merge the two if-else here?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437012722", "createdAt": "2020-06-08T21:30:44Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -389,30 +346,27 @@ public void prepareCommit() {\n     @Override\n     public void postCommit() {\n         switch (state()) {\n+            case RESTORING:\n             case RUNNING:\n-                commitNeeded = false;\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.RESTORING) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDE3OA==", "bodyText": "We could. I thought it's easier to read right now compared to if (state() == State.RESTORING || !eosEnabled) -- I don't care too much.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437084178", "createdAt": "2020-06-09T01:16:56Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -389,30 +346,27 @@ public void prepareCommit() {\n     @Override\n     public void postCommit() {\n         switch (state()) {\n+            case RESTORING:\n             case RUNNING:\n-                commitNeeded = false;\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.RESTORING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAxMjcyMg=="}, "originalCommit": null, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjU1MDEyOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "isResolved": false, "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMjowMzo1M1rOGgx_lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMzozMTozMFrOGiJnUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA==", "bodyText": "Do we want to throw here if the current state is CLOSED?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437026710", "createdAt": "2020-06-08T22:03:53Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA3NzEzOQ==", "bodyText": "My proposal is, to keep the methods idempotent.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437077139", "createdAt": "2020-06-09T00:49:59Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1OTMwOQ==", "bodyText": "nit: we can throw illegal-state if the state() == RESTORING since it should never happen.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437759309", "createdAt": "2020-06-09T22:34:11Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQyNzc4MA==", "bodyText": "Why not just make suspend a no-op if the task is RESTORING? That seems more in line with how we handle things elsewhere", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438427780", "createdAt": "2020-06-10T21:49:52Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQzMDc2NQ==", "bodyText": "For StandbyTasks, we never restore. When we do the state transition, we away make two transitions directly after each other from CREATE -> RESTORING -> RUNNING -- thus, state RESTORING is an invalid state for standby tasks.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438430765", "createdAt": "2020-06-10T21:57:11Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQzMjE2Nw==", "bodyText": "Oh duh, I thought this was StreamTask. In that case, why would we check for RESTORING at all? We don't check for RESTORING state anywhere else in StandbyTask AFAICT (maybe Guozhang thought this was StreamTask like I did? \ud83d\ude1b )", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438432167", "createdAt": "2020-06-10T22:00:48Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQzNDA1OQ==", "bodyText": "why would we check for RESTORING at all?\n\nWell, we don't. (and if we do, only to raise an exception)", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438434059", "createdAt": "2020-06-10T22:05:47Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQzNDM0NA==", "bodyText": "Before this PR, we did not throw if state was RESTORING for this case. Now we do.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438434344", "createdAt": "2020-06-10T22:06:32Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQzODgyNw==", "bodyText": "Right, by \"check for RESTORING\" I meant \"throw an exception if state is restoring\". It seems odd to check for RESTORING during suspend but not in any other StandbyTask method. Either it can never be in RESTORING and we are completely sure of that, and shouldn't check for RESTORING, or we should always check whether it's RESTORING and not just during suspend (eg also in postCommit)", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438438827", "createdAt": "2020-06-10T22:18:52Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQzOTIzNA==", "bodyText": "Just to clarify, I would support doing the former, ie don't check whether it's RESTORING here at all. But we should at least be consistent", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438439234", "createdAt": "2020-06-10T22:19:59Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ0MDYyMQ==", "bodyText": "Ah, I see. I guess we check it in almost all method though. (we just missed initializeIfNeeded and resume() -- will add it there).", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438440621", "createdAt": "2020-06-10T22:23:54Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ0NDg3OQ==", "bodyText": "We do this check implicitly for some case already, ie:\nif (RUNNING) {\n} else {\n  throw\n}\n\nie, only RUNNING is a valid state, and all others are invalid. Thus, it seems to be consistent if we add those checks elsewhere (or, what would be odd, exclude RESTORING from those implicit checks).", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438444879", "createdAt": "2020-06-10T22:36:11Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjI4OA==", "bodyText": "Cool \ud83d\udc4d", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438462288", "createdAt": "2020-06-10T23:31:30Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNjcxMA=="}, "originalCommit": null, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjU1NDA2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMjowNToxOFrOGgyCAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMjowNToxOFrOGgyCAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyNzMzMA==", "bodyText": "Similar here, maybe we could leverage transitionTo to help throw the exception.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437027330", "createdAt": "2020-06-08T22:05:18Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -108,13 +107,20 @@ public void completeRestoration() {\n     }\n \n     @Override\n-    public void prepareSuspend() {\n-        log.trace(\"No-op prepareSuspend with state {}\", state());\n+    public void suspendDirty() {\n+        log.trace(\"No-op suspend dirty with state {}\", state());\n+        if (state() == State.RUNNING) {\n+            transitionTo(State.SUSPENDED);\n+        }\n     }\n \n     @Override\n-    public void suspend() {\n-        log.trace(\"No-op suspend with state {}\", state());\n+    public void suspendCleanAndPrepareCommit() {\n+        log.trace(\"No-op suspend clean with state {}\", state());\n+        if (state() == State.RUNNING) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjU2MDQ3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMjowNzo0NlrOGgyFzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToyMjo0MVrOGg1l2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyODMwMw==", "bodyText": "The partitionGroup.clear and partitionGroup.close are interchangeable right now, should we just consolidate both?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437028303", "createdAt": "2020-06-08T22:07:46Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -389,30 +346,27 @@ public void prepareCommit() {\n     @Override\n     public void postCommit() {\n         switch (state()) {\n+            case RESTORING:\n             case RUNNING:\n-                commitNeeded = false;\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.RESTORING) {\n+                    writeCheckpointIfNeed();\n+                } else if (!eosEnabled) { // if RUNNING, checkpoint only for non-eos\n+                    writeCheckpointIfNeed();\n                 }\n \n-                log.debug(\"Committed\");\n-\n-                break;\n-\n-            case RESTORING:\n-                commitNeeded = false;\n-                commitRequested = false;\n-\n-                stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.SUSPENDED) {\n+                    partitionGroup.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NTY1Nw==", "bodyText": "Good call.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437085657", "createdAt": "2020-06-09T01:22:41Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -389,30 +346,27 @@ public void prepareCommit() {\n     @Override\n     public void postCommit() {\n         switch (state()) {\n+            case RESTORING:\n             case RUNNING:\n-                commitNeeded = false;\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.RESTORING) {\n+                    writeCheckpointIfNeed();\n+                } else if (!eosEnabled) { // if RUNNING, checkpoint only for non-eos\n+                    writeCheckpointIfNeed();\n                 }\n \n-                log.debug(\"Committed\");\n-\n-                break;\n-\n-            case RESTORING:\n-                commitNeeded = false;\n-                commitRequested = false;\n-\n-                stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.SUSPENDED) {\n+                    partitionGroup.clear();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyODMwMw=="}, "originalCommit": null, "originalPosition": 155}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjU2Nzc5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMjoxMDo0NlrOGgyKWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMDo0ODoxOFrOGiFxmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyOTQ2NA==", "bodyText": "Prefer to throw different illegal state exception here than making comments", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437029464", "createdAt": "2020-06-08T22:10:46Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -506,19 +455,18 @@ public void update(final Set<TopicPartition> topicPartitions, final ProcessorTop\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspendCleanAndPrepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RUNNING:\n-            case RESTORING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n                 break;\n \n+            case RESTORING: // we should have transitioned to `SUSPENDED` already", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 297}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NTgyOA==", "bodyText": "What does it improve?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437085828", "createdAt": "2020-06-09T01:23:17Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -506,19 +455,18 @@ public void update(final Set<TopicPartition> topicPartitions, final ProcessorTop\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspendCleanAndPrepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RUNNING:\n-            case RESTORING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n                 break;\n \n+            case RESTORING: // we should have transitioned to `SUSPENDED` already", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyOTQ2NA=="}, "originalCommit": null, "originalPosition": 297}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI0ODg4Nw==", "bodyText": "Maybe not necessary after a second thought. However, one more question: why not making closeAndRecycleState idempotent as well?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438248887", "createdAt": "2020-06-10T16:16:56Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -506,19 +455,18 @@ public void update(final Set<TopicPartition> topicPartitions, final ProcessorTop\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspendCleanAndPrepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RUNNING:\n-            case RESTORING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n                 break;\n \n+            case RESTORING: // we should have transitioned to `SUSPENDED` already", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyOTQ2NA=="}, "originalCommit": null, "originalPosition": 297}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2NDI2Mw==", "bodyText": "I see your point, but for this case, I would prefer to introduce a new state -- atm, closeAndRecycleState transits to CLOSED state what is the same as when we actually close a task -- however, the stateMgr would be closed for a proper CLOSED state, while for recycling the stateMgr is not closed -- so in general, the CLOSED state is not a \"safe\" state to provide idempotence. Thoughts?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438364263", "createdAt": "2020-06-10T19:39:22Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -506,19 +455,18 @@ public void update(final Set<TopicPartition> topicPartitions, final ProcessorTop\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspendCleanAndPrepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RUNNING:\n-            case RESTORING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n                 break;\n \n+            case RESTORING: // we should have transitioned to `SUSPENDED` already", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyOTQ2NA=="}, "originalCommit": null, "originalPosition": 297}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM5OTM4NA==", "bodyText": "That makes sense", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438399384", "createdAt": "2020-06-10T20:48:18Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -506,19 +455,18 @@ public void update(final Set<TopicPartition> topicPartitions, final ProcessorTop\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspendCleanAndPrepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RUNNING:\n-            case RESTORING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n                 break;\n \n+            case RESTORING: // we should have transitioned to `SUSPENDED` already", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyOTQ2NA=="}, "originalCommit": null, "originalPosition": 297}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjU4MDg2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMjoxNjowOVrOGgySOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjo1NDo1OVrOGhfIgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAzMTQ4Mg==", "bodyText": "I could see we are trying to maintain the same behavior, but still why a restoring task won't need to close topology?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437031482", "createdAt": "2020-06-08T22:16:09Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -891,6 +821,9 @@ private void initializeTopology() {\n     }\n \n     private void closeTopology(final boolean clean) {\n+        if (state() != State.RUNNING) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 412}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NzA5Ng==", "bodyText": "Because the topology is only initialized when restoring is finished.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437087096", "createdAt": "2020-06-09T01:28:10Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -891,6 +821,9 @@ private void initializeTopology() {\n     }\n \n     private void closeTopology(final boolean clean) {\n+        if (state() != State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAzMTQ4Mg=="}, "originalCommit": null, "originalPosition": 412}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MDY4MA==", "bodyText": "Sg, should we move the log on L811 inside the if statement?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437690680", "createdAt": "2020-06-09T20:13:36Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -891,6 +821,9 @@ private void initializeTopology() {\n     }\n \n     private void closeTopology(final boolean clean) {\n+        if (state() != State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAzMTQ4Mg=="}, "originalCommit": null, "originalPosition": 412}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NjI3Mw==", "bodyText": "nit: since this is a private function only called by suspend, we can modify the caller such that we only call this in RUNNING not in RESTORING, and then inside this function we do not need this check anymore.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437766273", "createdAt": "2020-06-09T22:54:59Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -891,6 +821,9 @@ private void initializeTopology() {\n     }\n \n     private void closeTopology(final boolean clean) {\n+        if (state() != State.RUNNING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAzMTQ4Mg=="}, "originalCommit": null, "originalPosition": 412}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjkyMDkzOnYy", "diffSide": "LEFT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToxNzo1OFrOGg1hJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMTo1MDo1NlrOGg2B5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDQ1Mw==", "bodyText": "I'm wondering if we could merge committableOffsetsAndMetadata with prepareCommit as well, letting the latter to return the map? See my other comment aside.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437084453", "createdAt": "2020-06-09T01:17:58Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "diffHunk": "@@ -125,40 +126,21 @@ public boolean isValidTransition(final State newState) {\n \n     void postCommit();\n \n-    /**", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MjgzOA==", "bodyText": "That is certainly possible. Good catch!", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437092838", "createdAt": "2020-06-09T01:50:56Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "diffHunk": "@@ -125,40 +126,21 @@ public boolean isValidTransition(final State newState) {\n \n     void postCommit();\n \n-    /**", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDQ1Mw=="}, "originalCommit": null, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjk1ODI0OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMTo0MTowOVrOGg14SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMjowNjoyNFrOGg2Rww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MDM3Ng==", "bodyText": "It seems to me that the reason we want to have two suspends and also merging the suspendClean with prepareCommit is that for StreamTask, if state SUSPENDED we want to skip prepareCommit. I feel it is a tad cleaner to separate them further into one suspend which does not try to call prepareCommit, and rely on whether prepareCommit should do anything or not based on both state (i.e. only running/restoring/suspended need to commit) and commitNeeded flag.\nWith that we can convert the callers as follows:\n\nsuspendDirty(): just call suspend(), do not call prepareCommit().\nsuspendCleanAndPrepareCommit():\n2.a) from task.closeAndRecycleState: call suspend(), and then call prepareCommit(); the second would check commitNeeded and if it was false, we would not try to flush / commit. Hence if the task just transited from other states to suspended, then commitNeeded should still be true.\n2.b) from taskManager directly: same as above, but for this call we always follow with a committableOffsetsAndMetadata getting the map of offsets, so I'm thinking we can merge prepareCommit with committableOffsetsAndMetadata as well: if the state is right and commitNeeded is set, execute the prepare committing procedure, and accumulate the offsets, otherwise returning null indicating no offsets needed to be committed.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437090376", "createdAt": "2020-06-09T01:41:09Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "diffHunk": "@@ -125,40 +126,21 @@ public boolean isValidTransition(final State newState) {\n \n     void postCommit();\n \n-    /**\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    void prepareSuspend();\n+    void suspendDirty();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5Njg5OQ==", "bodyText": "We also want to swallow exceptions in closeTopology() but we can work around this.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437096899", "createdAt": "2020-06-09T02:06:24Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "diffHunk": "@@ -125,40 +126,21 @@ public boolean isValidTransition(final State newState) {\n \n     void postCommit();\n \n-    /**\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    void prepareSuspend();\n+    void suspendDirty();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MDM3Ng=="}, "originalCommit": null, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY3OTM4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowOToxNVrOGhaYWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjo1NzoyMFrOGhfLkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4ODQwOQ==", "bodyText": "Could we merge RESTORING and SUSPENDED?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437688409", "createdAt": "2020-06-09T20:09:15Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 364}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzA1Nw==", "bodyText": "+1, IDEA also suggests it :)", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437767057", "createdAt": "2020-06-09T22:57:20Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4ODQwOQ=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 364}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY5NzY5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxNTowNlrOGhakJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxNTowNlrOGhakJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MTQyOA==", "bodyText": "add a @return comment for the struct", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437691428", "createdAt": "2020-06-09T20:15:06Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "diffHunk": "@@ -122,44 +123,23 @@ public boolean isValidTransition(final State newState) {\n     /**\n      * @throws StreamsException fatal error, should close the thread\n      */\n-    void prepareCommit();\n+    Map<TopicPartition, OffsetAndMetadata> prepareCommit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjczNjgwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyNjo1OFrOGha8gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNjoyMzo1OFrOGh836g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NzY2NQ==", "bodyText": "I could get a follow-up newbie ticket, but it seems that we have a couple of catch and swallow cases in the task manager with clean flag, does it make sense to extract the executeAndMaybeSwallow to TaskManager class and share between cases?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437697665", "createdAt": "2020-06-09T20:26:58Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -623,7 +618,11 @@ private long sumOfChangelogOffsets(final TaskId id, final Map<TopicPartition, Lo\n     }\n \n     private void closeTaskDirty(final Task task) {\n-        task.prepareCloseDirty();\n+        try {\n+            task.suspend();\n+        } catch (final RuntimeException swallow) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NTMzNA==", "bodyText": "SGTM. Can you create a ticket?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437775334", "createdAt": "2020-06-09T23:22:18Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -623,7 +618,11 @@ private long sumOfChangelogOffsets(final TaskId id, final Map<TopicPartition, Lo\n     }\n \n     private void closeTaskDirty(final Task task) {\n-        task.prepareCloseDirty();\n+        try {\n+            task.suspend();\n+        } catch (final RuntimeException swallow) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NzY2NQ=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI1MzU0Ng==", "bodyText": "Done", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438253546", "createdAt": "2020-06-10T16:23:58Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -623,7 +618,11 @@ private long sumOfChangelogOffsets(final TaskId id, final Map<TopicPartition, Lo\n     }\n \n     private void closeTaskDirty(final Task task) {\n-        task.prepareCloseDirty();\n+        try {\n+            task.suspend();\n+        } catch (final RuntimeException swallow) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NzY2NQ=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc0MjQ1OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyODo0NVrOGha__g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzoyMjozNFrOGhfsPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5ODU1OA==", "bodyText": "What does this lastCall suggest?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437698558", "createdAt": "2020-06-09T20:28:45Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java", "diffHunk": "@@ -476,6 +445,26 @@ public void shouldDeleteStateDirOnTaskCreatedAndEosBetaUncleanClose() {\n         assertEquals(Task.State.CLOSED, task.state());\n     }\n \n+    @Test\n+    public void shouldRecycleTask() {\n+        EasyMock.expectLastCall();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NTQyMg==", "bodyText": "Ups.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437775422", "createdAt": "2020-06-09T23:22:34Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java", "diffHunk": "@@ -476,6 +445,26 @@ public void shouldDeleteStateDirOnTaskCreatedAndEosBetaUncleanClose() {\n         assertEquals(Task.State.CLOSED, task.state());\n     }\n \n+    @Test\n+    public void shouldRecycleTask() {\n+        EasyMock.expectLastCall();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5ODU1OA=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzEzNTQ2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjozOTowNlrOGhez_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjozOTowNlrOGhez_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2MTAyMg==", "bodyText": "The comment below is not accurate anymore: we do not write checkpoint during recycle actually.\nEDIT: actually, the updated offsetSnapshotSinceLastCommit seems not used since after this function we would create a new StreamTask and in between we do not check if commitNeeded at all. Could we remove line 175 then?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437761022", "createdAt": "2020-06-09T22:39:06Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -151,69 +151,24 @@ public void postCommit() {\n         }\n     }\n \n-    @Override\n-    public void prepareCloseClean() {\n-        prepareClose(true);\n-\n-        log.info(\"Prepared clean close\");\n-    }\n-\n-    @Override\n-    public void prepareCloseDirty() {\n-        prepareClose(false);\n-\n-        log.info(\"Prepared dirty close\");\n-    }\n-\n-    /**\n-     * 1. commit if we are running and clean close;\n-     * 2. close the state manager.\n-     *\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    private void prepareClose(final boolean clean) {\n-        switch (state()) {\n-            case CREATED:\n-            case CLOSED:\n-                log.trace(\"Skip prepare closing since state is {}\", state());\n-                return;\n-\n-            case RUNNING:\n-                if (clean) {\n-                    stateMgr.flush();\n-                }\n-\n-                break;\n-\n-            case RESTORING:\n-            case SUSPENDED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing standby task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing standby task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void closeClean() {\n         close(true);\n-\n         log.info(\"Closed clean\");\n     }\n \n     @Override\n     public void closeDirty() {\n         close(false);\n-\n         log.info(\"Closed dirty\");\n     }\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n+        suspend();\n+        prepareCommit();\n \n-        if (state() == State.CREATED || state() == State.RUNNING) {\n+        if (state() == State.CREATED || state() == State.SUSPENDED) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 120}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzE0NDQwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjo0MzoyMlrOGhe5pQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjo0MzoyMlrOGhe5pQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2MjQ2OQ==", "bodyText": "Ditto for line 195: we do not need to update the snapshot since we are closing the task already.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437762469", "createdAt": "2020-06-09T22:43:22Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -232,7 +187,7 @@ public void closeAndRecycleState() {\n     private void close(final boolean clean) {\n         switch (state()) {\n             case CREATED:\n-            case RUNNING:\n+            case SUSPENDED:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 129}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzE3MTIzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjo1NjoxNFrOGhfKPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTozMzoxNVrOGiDb-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NjcxNg==", "bodyText": "Maybe we can skip calling this if we are in RESTORING; I have another comment below.\nAlso could we add javadoc on top explaining what exception can be thrown?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437766716", "createdAt": "2020-06-09T22:56:14Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -247,82 +246,23 @@ public void completeRestoration() {\n         }\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     *  4. then commit the record collector -- for EOS this is the synchronization barrier\n-     *  5. then checkpoint the state manager -- even if we crash before this step, EOS is still guaranteed\n-     * </pre>\n-     *\n-     * @throws TaskMigratedException if committing offsets failed (non-EOS)\n-     *                               or if the task producer got fenced (EOS)\n-     */\n-    @Override\n-    public void prepareSuspend() {\n-        switch (state()) {\n-            case CREATED:\n-            case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip prepare suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RESTORING:\n-                stateMgr.flush();\n-                log.info(\"Prepare suspending restoring\");\n-\n-                break;\n-\n-            case RUNNING:\n-                closeTopology(true);\n-\n-                stateMgr.flush();\n-                recordCollector.flush();\n-\n-                log.info(\"Prepare suspending running\");\n-\n-                break;\n-\n-            case CLOSED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while suspending active task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while suspending active task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void suspend() {\n         switch (state()) {\n             case CREATED:\n             case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RUNNING:\n-                stateMgr.checkpoint(checkpointableOffsets());\n-                partitionGroup.clear();\n-\n-                transitionTo(State.SUSPENDED);\n-                log.info(\"Suspended running\");\n+                log.info(\"Skip suspending since state is {}\", state());\n \n                 break;\n \n             case RESTORING:\n-                // we just checkpoint the position that we've restored up to without\n-                // going through the commit process\n-                stateMgr.checkpoint(emptyMap());\n-\n-                // we should also clear any buffered records of a task when suspending it\n-                partitionGroup.clear();\n-\n-                transitionTo(State.SUSPENDED);\n-                log.info(\"Suspended restoring\");\n+            case RUNNING:\n+                try {\n+                    closeTopology();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgyOTU1NQ==", "bodyText": "Is this addressed?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437829555", "createdAt": "2020-06-10T02:46:16Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -247,82 +246,23 @@ public void completeRestoration() {\n         }\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     *  4. then commit the record collector -- for EOS this is the synchronization barrier\n-     *  5. then checkpoint the state manager -- even if we crash before this step, EOS is still guaranteed\n-     * </pre>\n-     *\n-     * @throws TaskMigratedException if committing offsets failed (non-EOS)\n-     *                               or if the task producer got fenced (EOS)\n-     */\n-    @Override\n-    public void prepareSuspend() {\n-        switch (state()) {\n-            case CREATED:\n-            case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip prepare suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RESTORING:\n-                stateMgr.flush();\n-                log.info(\"Prepare suspending restoring\");\n-\n-                break;\n-\n-            case RUNNING:\n-                closeTopology(true);\n-\n-                stateMgr.flush();\n-                recordCollector.flush();\n-\n-                log.info(\"Prepare suspending running\");\n-\n-                break;\n-\n-            case CLOSED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while suspending active task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while suspending active task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void suspend() {\n         switch (state()) {\n             case CREATED:\n             case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RUNNING:\n-                stateMgr.checkpoint(checkpointableOffsets());\n-                partitionGroup.clear();\n-\n-                transitionTo(State.SUSPENDED);\n-                log.info(\"Suspended running\");\n+                log.info(\"Skip suspending since state is {}\", state());\n \n                 break;\n \n             case RESTORING:\n-                // we just checkpoint the position that we've restored up to without\n-                // going through the commit process\n-                stateMgr.checkpoint(emptyMap());\n-\n-                // we should also clear any buffered records of a task when suspending it\n-                partitionGroup.clear();\n-\n-                transitionTo(State.SUSPENDED);\n-                log.info(\"Suspended restoring\");\n+            case RUNNING:\n+                try {\n+                    closeTopology();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NjcxNg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2MTA4Mw==", "bodyText": "Yes. RESTORING above is it's own \"case\" branch now (before RUNNING and RESTORING was shared the code).", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438361083", "createdAt": "2020-06-10T19:33:15Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -247,82 +246,23 @@ public void completeRestoration() {\n         }\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     *  4. then commit the record collector -- for EOS this is the synchronization barrier\n-     *  5. then checkpoint the state manager -- even if we crash before this step, EOS is still guaranteed\n-     * </pre>\n-     *\n-     * @throws TaskMigratedException if committing offsets failed (non-EOS)\n-     *                               or if the task producer got fenced (EOS)\n-     */\n-    @Override\n-    public void prepareSuspend() {\n-        switch (state()) {\n-            case CREATED:\n-            case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip prepare suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RESTORING:\n-                stateMgr.flush();\n-                log.info(\"Prepare suspending restoring\");\n-\n-                break;\n-\n-            case RUNNING:\n-                closeTopology(true);\n-\n-                stateMgr.flush();\n-                recordCollector.flush();\n-\n-                log.info(\"Prepare suspending running\");\n-\n-                break;\n-\n-            case CLOSED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while suspending active task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while suspending active task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void suspend() {\n         switch (state()) {\n             case CREATED:\n             case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RUNNING:\n-                stateMgr.checkpoint(checkpointableOffsets());\n-                partitionGroup.clear();\n-\n-                transitionTo(State.SUSPENDED);\n-                log.info(\"Suspended running\");\n+                log.info(\"Skip suspending since state is {}\", state());\n \n                 break;\n \n             case RESTORING:\n-                // we just checkpoint the position that we've restored up to without\n-                // going through the commit process\n-                stateMgr.checkpoint(emptyMap());\n-\n-                // we should also clear any buffered records of a task when suspending it\n-                partitionGroup.clear();\n-\n-                transitionTo(State.SUSPENDED);\n-                log.info(\"Suspended restoring\");\n+            case RUNNING:\n+                try {\n+                    closeTopology();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NjcxNg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzE3ODkwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjo1OTo0M1rOGhfO5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzowNTo0NVrOGh-asw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzkxMA==", "bodyText": "Maybe we can make an optimization by remembering the committableOffsets, and then if the value (both offset and time) does not change we do not need to give it out to consumer to commit.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437767910", "createdAt": "2020-06-09T22:59:43Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5Njg4MA==", "bodyText": "Well, what is the probability that it did not change? Feel free to file a ticket if you think it's worth it, but I would like to not piggy-back other things into the PR>", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437796880", "createdAt": "2020-06-10T00:38:06Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzkxMA=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI0Mzc5Nw==", "bodyText": "+1, this seems not really necessary atm.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438243797", "createdAt": "2020-06-10T16:10:18Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzkxMA=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI3ODgzNQ==", "bodyText": "Sounds fair, we can do that in another PR.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438278835", "createdAt": "2020-06-10T17:05:45Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzkxMA=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 165}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzE4NTA5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzowMjoyNVrOGhfSwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQyMToxODoxNFrOGivDzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw==", "bodyText": "Why we need this check?\nAlso nit: how about maybeWriteCheckpoint to align with maybeScheduleCheckpoint.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437768897", "createdAt": "2020-06-09T23:02:25Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5NzQ1Ng==", "bodyText": "Why do we need any check? To avoid bugs :)\nIf like the different names, because \"maybe\" indicated that the method makes a decision, while \"ifNeeded\" implies that the methods executed a decision that was already made? At least my personal interpretation?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437797456", "createdAt": "2020-06-10T00:40:18Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4MjAwMw==", "bodyText": "okay, fair enough :)\n\n\nactually I think we use maybeXXX and YYYIfNeeded across the repo for both semantics :) my very paranoid nit intention is to just make the private function names more aligned. Your call.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438282003", "createdAt": "2020-06-10T17:11:07Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2OTUxNw==", "bodyText": "If we want to align them, I would recommend to go a single PR to align all of them at once :)", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438369517", "createdAt": "2020-06-10T19:49:21Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk1Mzc2Ng==", "bodyText": "@mjsax  By should only be written if no commit is needed do you mean ...if a commit was just completed?\nDoesn't this break closeAndRecycleState (I thought iI saw in another comment that we don't write checkpoints during recycle anymore?)", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438953766", "createdAt": "2020-06-11T17:33:47Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk1NzYyMQ==", "bodyText": "Maybe I'm thinking of standby tasks (ie we only skip checkpointing for recycled standbys). For active tasks, we should probably commit them before recycling right? Or is it ok to skip committing altogether \ud83e\udd14", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438957621", "createdAt": "2020-06-11T17:40:49Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTAwNDk4Mg==", "bodyText": "@guozhangwang  Just saw this in the SmokeTestDriverIntegrationTest#shouldWorkWithRebalance -- not sure if it merits a separate ticket or can just be fixed together with https://issues.apache.org/jira/browse/KAFKA-10150 ?\nCaused by: java.lang.IllegalStateException: A checkpoint should only be written if no commit is needed.\n\tat org.apache.kafka.streams.processor.internals.StreamTask.writeCheckpointIfNeed(StreamTask.java:534)\n\tat org.apache.kafka.streams.processor.internals.StreamTask.closeAndRecycleState(StreamTask.java:482)\n\tat org.apache.kafka.streams.processor.internals.StandbyTaskCreator.createStandbyTaskFromActive(StandbyTaskCreator.java:115)\n\tat org.apache.kafka.streams.processor.internals.TaskManager.handleAssignment(TaskManager.java:288)", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439004982", "createdAt": "2020-06-11T18:59:41Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA3NDg2OQ==", "bodyText": "Nice catch. Let's just fix it along with 10150?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439074869", "createdAt": "2020-06-11T21:16:08Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA3NTc4OQ==", "bodyText": "Too late, I already created a ticket for it \ud83d\ude42 But after starting to work on it, I agree, they should be addressed in one PR", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439075789", "createdAt": "2020-06-11T21:18:14Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 410}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzE5MDIxOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzowNDo0M1rOGhfVwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzowNDo0M1rOGhfVwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2OTY2NA==", "bodyText": "What about 1) move the line 387/388 out of the switch, also line 400 after the switch block, 2) and then make these three states separate branches, so that we can avoid a mix of switch / if-else.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437769664", "createdAt": "2020-06-09T23:04:43Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());\n+                for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n+                    final TopicPartition partition = entry.getKey();\n+                    Long offset = partitionGroup.headRecordOffset(partition);\n+                    if (offset == null) {\n+                        try {\n+                            offset = mainConsumer.position(partition);\n+                        } catch (final TimeoutException error) {\n+                            // the `consumer.position()` call should never block, because we know that we did process data\n+                            // for the requested partition and thus the consumer should have a valid local position\n+                            // that it can return immediately\n+\n+                            // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                            throw new IllegalStateException(error);\n+                        } catch (final KafkaException fatal) {\n+                            throw new StreamsException(fatal);\n+                        }\n+                    }\n+                    final long partitionTime = partitionTimes.get(partition);\n+                    committableOffsets.put(partition, new OffsetAndMetadata(offset, encodeTimestamp(partitionTime)));\n+                }\n \n                 break;\n \n+            case CLOSED:\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while getting commitable offsets for active task \" + id);\n+\n+            default:\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while post committing active task \" + id);\n+        }\n+\n+        return committableOffsets;\n+    }\n+\n+    @Override\n+    public void postCommit() {\n+        switch (state()) {\n             case RESTORING:\n-                commitNeeded = false;\n+            case RUNNING:\n+            case SUSPENDED:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 205}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzE5OTEwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzowODo1OFrOGhfbIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTo1MDoyMVrOGiD_KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTA0Mg==", "bodyText": "Hmm... this reads a bit weird to me. Can we call this in suspend instead? Also in that case we do not need to call this in close and closeAndRecycle.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437771042", "createdAt": "2020-06-09T23:08:58Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());\n+                for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n+                    final TopicPartition partition = entry.getKey();\n+                    Long offset = partitionGroup.headRecordOffset(partition);\n+                    if (offset == null) {\n+                        try {\n+                            offset = mainConsumer.position(partition);\n+                        } catch (final TimeoutException error) {\n+                            // the `consumer.position()` call should never block, because we know that we did process data\n+                            // for the requested partition and thus the consumer should have a valid local position\n+                            // that it can return immediately\n+\n+                            // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                            throw new IllegalStateException(error);\n+                        } catch (final KafkaException fatal) {\n+                            throw new StreamsException(fatal);\n+                        }\n+                    }\n+                    final long partitionTime = partitionTimes.get(partition);\n+                    committableOffsets.put(partition, new OffsetAndMetadata(offset, encodeTimestamp(partitionTime)));\n+                }\n \n                 break;\n \n+            case CLOSED:\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while getting commitable offsets for active task \" + id);\n+\n+            default:\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while post committing active task \" + id);\n+        }\n+\n+        return committableOffsets;\n+    }\n+\n+    @Override\n+    public void postCommit() {\n+        switch (state()) {\n             case RESTORING:\n-                commitNeeded = false;\n+            case RUNNING:\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n+\n+                if (state() == State.RESTORING || state() == State.SUSPENDED) {\n+                    writeCheckpointIfNeed();\n+                } else if (!eosEnabled) { // if RUNNING, checkpoint only for non-eos\n+                    writeCheckpointIfNeed();\n+                }\n \n-                stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.SUSPENDED) {\n+                    partitionGroup.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgwMDA4Mg==", "bodyText": "We cannot call it in suspend, because we would loose the partition-time information that we need in prepareCommit() (that is called after suspend()).", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437800082", "createdAt": "2020-06-10T00:50:42Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());\n+                for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n+                    final TopicPartition partition = entry.getKey();\n+                    Long offset = partitionGroup.headRecordOffset(partition);\n+                    if (offset == null) {\n+                        try {\n+                            offset = mainConsumer.position(partition);\n+                        } catch (final TimeoutException error) {\n+                            // the `consumer.position()` call should never block, because we know that we did process data\n+                            // for the requested partition and thus the consumer should have a valid local position\n+                            // that it can return immediately\n+\n+                            // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                            throw new IllegalStateException(error);\n+                        } catch (final KafkaException fatal) {\n+                            throw new StreamsException(fatal);\n+                        }\n+                    }\n+                    final long partitionTime = partitionTimes.get(partition);\n+                    committableOffsets.put(partition, new OffsetAndMetadata(offset, encodeTimestamp(partitionTime)));\n+                }\n \n                 break;\n \n+            case CLOSED:\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while getting commitable offsets for active task \" + id);\n+\n+            default:\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while post committing active task \" + id);\n+        }\n+\n+        return committableOffsets;\n+    }\n+\n+    @Override\n+    public void postCommit() {\n+        switch (state()) {\n             case RESTORING:\n-                commitNeeded = false;\n+            case RUNNING:\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n+\n+                if (state() == State.RESTORING || state() == State.SUSPENDED) {\n+                    writeCheckpointIfNeed();\n+                } else if (!eosEnabled) { // if RUNNING, checkpoint only for non-eos\n+                    writeCheckpointIfNeed();\n+                }\n \n-                stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.SUSPENDED) {\n+                    partitionGroup.clear();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTA0Mg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4Mjc1Mg==", "bodyText": "Got it, makes sense.\nCould you copy-paste the above as comment to remind other readers?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438282752", "createdAt": "2020-06-10T17:12:23Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());\n+                for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n+                    final TopicPartition partition = entry.getKey();\n+                    Long offset = partitionGroup.headRecordOffset(partition);\n+                    if (offset == null) {\n+                        try {\n+                            offset = mainConsumer.position(partition);\n+                        } catch (final TimeoutException error) {\n+                            // the `consumer.position()` call should never block, because we know that we did process data\n+                            // for the requested partition and thus the consumer should have a valid local position\n+                            // that it can return immediately\n+\n+                            // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                            throw new IllegalStateException(error);\n+                        } catch (final KafkaException fatal) {\n+                            throw new StreamsException(fatal);\n+                        }\n+                    }\n+                    final long partitionTime = partitionTimes.get(partition);\n+                    committableOffsets.put(partition, new OffsetAndMetadata(offset, encodeTimestamp(partitionTime)));\n+                }\n \n                 break;\n \n+            case CLOSED:\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while getting commitable offsets for active task \" + id);\n+\n+            default:\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while post committing active task \" + id);\n+        }\n+\n+        return committableOffsets;\n+    }\n+\n+    @Override\n+    public void postCommit() {\n+        switch (state()) {\n             case RESTORING:\n-                commitNeeded = false;\n+            case RUNNING:\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n+\n+                if (state() == State.RESTORING || state() == State.SUSPENDED) {\n+                    writeCheckpointIfNeed();\n+                } else if (!eosEnabled) { // if RUNNING, checkpoint only for non-eos\n+                    writeCheckpointIfNeed();\n+                }\n \n-                stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.SUSPENDED) {\n+                    partitionGroup.clear();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTA0Mg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM3MDA4OQ==", "bodyText": "Sure -- but if they change it (I also did the change originally) a unit test fails anyway :)", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438370089", "createdAt": "2020-06-10T19:50:21Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());\n+                for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n+                    final TopicPartition partition = entry.getKey();\n+                    Long offset = partitionGroup.headRecordOffset(partition);\n+                    if (offset == null) {\n+                        try {\n+                            offset = mainConsumer.position(partition);\n+                        } catch (final TimeoutException error) {\n+                            // the `consumer.position()` call should never block, because we know that we did process data\n+                            // for the requested partition and thus the consumer should have a valid local position\n+                            // that it can return immediately\n+\n+                            // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                            throw new IllegalStateException(error);\n+                        } catch (final KafkaException fatal) {\n+                            throw new StreamsException(fatal);\n+                        }\n+                    }\n+                    final long partitionTime = partitionTimes.get(partition);\n+                    committableOffsets.put(partition, new OffsetAndMetadata(offset, encodeTimestamp(partitionTime)));\n+                }\n \n                 break;\n \n+            case CLOSED:\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while getting commitable offsets for active task \" + id);\n+\n+            default:\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while post committing active task \" + id);\n+        }\n+\n+        return committableOffsets;\n+    }\n+\n+    @Override\n+    public void postCommit() {\n+        switch (state()) {\n             case RESTORING:\n-                commitNeeded = false;\n+            case RUNNING:\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n+\n+                if (state() == State.RESTORING || state() == State.SUSPENDED) {\n+                    writeCheckpointIfNeed();\n+                } else if (!eosEnabled) { // if RUNNING, checkpoint only for non-eos\n+                    writeCheckpointIfNeed();\n+                }\n \n-                stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.SUSPENDED) {\n+                    partitionGroup.clear();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTA0Mg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 217}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzIxMzMxOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzoxNToxNVrOGhfjYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMDo1MjozMVrOGhhOZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzE1Mw==", "bodyText": "I think we actually do not need to commit (including write-checkpoint) when closeAndRecycle actually, and only need to suspend the task before recycle it. But this is out of the scope and we can discuss about this in another PR (cc @ableegoldman ).", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437773153", "createdAt": "2020-06-09T23:15:15Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 313}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgwMDU1MQ==", "bodyText": "Assuming rebalancing does not happen often (in a stable deployment) it might be re-mature optimization?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437800551", "createdAt": "2020-06-10T00:52:31Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzE1Mw=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 313}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzIxNjE3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzoxNjoyOFrOGhflDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTo0NjoyNVrOGiD3Gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzU4Mg==", "bodyText": "Should we return emptyMap if we are SUSPENDED as well?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437773582", "createdAt": "2020-06-09T23:16:28Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -813,6 +727,10 @@ private void updateProcessorContext(final StampedRecord record, final ProcessorN\n      * Currently only changelog topic offsets need to be checkpointed.\n      */\n     private Map<TopicPartition, Long> checkpointableOffsets() {\n+        if (state() == State.RESTORING) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 444}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NDYwNg==", "bodyText": "EDIT: actually, I think we need to accumulate the consumed offsets when we just transited to suspend and then called prepareCommit, but if we are already in suspended then it is actually okay to return an emptyMap. However since we do not know if we have just transited to suspended and the below code should not be a big overhead, we can just keep it as-is.\nSo please ignore my previous comment :)", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437774606", "createdAt": "2020-06-09T23:20:01Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -813,6 +727,10 @@ private void updateProcessorContext(final StampedRecord record, final ProcessorN\n      * Currently only changelog topic offsets need to be checkpointed.\n      */\n     private Map<TopicPartition, Long> checkpointableOffsets() {\n+        if (state() == State.RESTORING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzU4Mg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 444}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI1MjA5Nw==", "bodyText": "Is this logic necessary? I don't think we would populate data in record collector or consumed offsets until we start processing?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438252097", "createdAt": "2020-06-10T16:21:45Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -813,6 +727,10 @@ private void updateProcessorContext(final StampedRecord record, final ProcessorN\n      * Currently only changelog topic offsets need to be checkpointed.\n      */\n     private Map<TopicPartition, Long> checkpointableOffsets() {\n+        if (state() == State.RESTORING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzU4Mg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 444}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2ODAyNw==", "bodyText": "Good point!", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438368027", "createdAt": "2020-06-10T19:46:25Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -813,6 +727,10 @@ private void updateProcessorContext(final StampedRecord record, final ProcessorN\n      * Currently only changelog topic offsets need to be checkpointed.\n      */\n     private Map<TopicPartition, Long> checkpointableOffsets() {\n+        if (state() == State.RESTORING) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzU4Mg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 444}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzIzNTYzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzoyNjozNFrOGhfxQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQyMTo1NTowN1rOGiwIfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg==", "bodyText": "question: I cannot remember why we need to commit those still owned tasks during handle-assignment, is that necessary? Or is that just an optimization: since we are going to commit anyways, let's just commit everyone.\nIf that's the case, we can refresh the last-commit timestamp as well.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437776706", "createdAt": "2020-06-09T23:26:34Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -210,9 +214,8 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 tasksToRecycle.add(task);\n             } else {\n                 try {\n-                    task.prepareCloseClean();\n-                    final Map<TopicPartition, OffsetAndMetadata> committableOffsets = task\n-                        .committableOffsetsAndMetadata();\n+                    task.suspend();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NzI0NQ==", "bodyText": "Even in that case, in line 205 we could check task.commitNeeded() && task.isActive right?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437777245", "createdAt": "2020-06-09T23:28:23Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -210,9 +214,8 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 tasksToRecycle.add(task);\n             } else {\n                 try {\n-                    task.prepareCloseClean();\n-                    final Map<TopicPartition, OffsetAndMetadata> committableOffsets = task\n-                        .committableOffsetsAndMetadata();\n+                    task.suspend();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgwMjMyOQ==", "bodyText": "For eoa-beta, if we commit, we alway need to commit all tasks. And to not distinguish between non-eos/eos-alpha vs eos-beta, be decided to just commit all tasks for all cases.\nAnd we don't own StreamThread#lastCommitMs so we cannot update it.\nFor L205: the outter if checks already if task.isActive", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437802329", "createdAt": "2020-06-10T00:59:23Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -210,9 +214,8 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 tasksToRecycle.add(task);\n             } else {\n                 try {\n-                    task.prepareCloseClean();\n-                    final Map<TopicPartition, OffsetAndMetadata> committableOffsets = task\n-                        .committableOffsetsAndMetadata();\n+                    task.suspend();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA4NjQxNg==", "bodyText": "@mjsax @guozhangwang why do we need to commit at all during handleAssignment? Shouldn't we have already committed all tasks that need to be committed during handleRevocation?\nThat's not exactly a bug, I'm just wondering if it's necessary?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439086416", "createdAt": "2020-06-11T21:44:09Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -210,9 +214,8 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 tasksToRecycle.add(task);\n             } else {\n                 try {\n-                    task.prepareCloseClean();\n-                    final Map<TopicPartition, OffsetAndMetadata> committableOffsets = task\n-                        .committableOffsetsAndMetadata();\n+                    task.suspend();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA5MzM3Mg==", "bodyText": "We may not call handleRevocation before calling handleAssignment so the task to close may not be in SUSPENDED state yet, and hence do close them we need to commit their states. For other tasks, they are not necessarily committing but I think the point was, that since we are going to send one commit request anyways so just commit for everyone --- note that flushing can indeed be skipped, which is what KAFKA-9450 covers", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439093372", "createdAt": "2020-06-11T21:55:07Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -210,9 +214,8 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 tasksToRecycle.add(task);\n             } else {\n                 try {\n-                    task.prepareCloseClean();\n-                    final Map<TopicPartition, OffsetAndMetadata> committableOffsets = task\n-                        .committableOffsetsAndMetadata();\n+                    task.suspend();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg=="}, "originalCommit": {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMTQ2MzEzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMzozMzowOVrOGiJpAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQwMDoxOToyMVrOGiKcTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjcyMQ==", "bodyText": "Why call prepareCommit (or suspend for that matter)?", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438462721", "createdAt": "2020-06-10T23:33:09Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -151,73 +158,24 @@ public void postCommit() {\n         }\n     }\n \n-    @Override\n-    public void prepareCloseClean() {\n-        prepareClose(true);\n-\n-        log.info(\"Prepared clean close\");\n-    }\n-\n-    @Override\n-    public void prepareCloseDirty() {\n-        prepareClose(false);\n-\n-        log.info(\"Prepared dirty close\");\n-    }\n-\n-    /**\n-     * 1. commit if we are running and clean close;\n-     * 2. close the state manager.\n-     *\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    private void prepareClose(final boolean clean) {\n-        switch (state()) {\n-            case CREATED:\n-            case CLOSED:\n-                log.trace(\"Skip prepare closing since state is {}\", state());\n-                return;\n-\n-            case RUNNING:\n-                if (clean) {\n-                    stateMgr.flush();\n-                }\n-\n-                break;\n-\n-            case RESTORING:\n-            case SUSPENDED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing standby task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing standby task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void closeClean() {\n         close(true);\n-\n         log.info(\"Closed clean\");\n     }\n \n     @Override\n     public void closeDirty() {\n         close(false);\n-\n         log.info(\"Closed dirty\");\n     }\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n+        suspend();\n+        prepareCommit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329e187a9187c4ea532ce88e0202402cb6f78b86"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3MTI1OA==", "bodyText": "Both now do what prepareClose() did before.", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438471258", "createdAt": "2020-06-11T00:02:28Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -151,73 +158,24 @@ public void postCommit() {\n         }\n     }\n \n-    @Override\n-    public void prepareCloseClean() {\n-        prepareClose(true);\n-\n-        log.info(\"Prepared clean close\");\n-    }\n-\n-    @Override\n-    public void prepareCloseDirty() {\n-        prepareClose(false);\n-\n-        log.info(\"Prepared dirty close\");\n-    }\n-\n-    /**\n-     * 1. commit if we are running and clean close;\n-     * 2. close the state manager.\n-     *\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    private void prepareClose(final boolean clean) {\n-        switch (state()) {\n-            case CREATED:\n-            case CLOSED:\n-                log.trace(\"Skip prepare closing since state is {}\", state());\n-                return;\n-\n-            case RUNNING:\n-                if (clean) {\n-                    stateMgr.flush();\n-                }\n-\n-                break;\n-\n-            case RESTORING:\n-            case SUSPENDED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing standby task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing standby task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void closeClean() {\n         close(true);\n-\n         log.info(\"Closed clean\");\n     }\n \n     @Override\n     public void closeDirty() {\n         close(false);\n-\n         log.info(\"Closed dirty\");\n     }\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n+        suspend();\n+        prepareCommit();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjcyMQ=="}, "originalCommit": {"oid": "329e187a9187c4ea532ce88e0202402cb6f78b86"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3MjM3Mw==", "bodyText": "I just mean, why not inline that? I'm just imagining coming back to this code in a few months and wondering why we need to suspend a task before recycling, or why we call prepareCommit but don't then actually commit, etc", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438472373", "createdAt": "2020-06-11T00:06:31Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -151,73 +158,24 @@ public void postCommit() {\n         }\n     }\n \n-    @Override\n-    public void prepareCloseClean() {\n-        prepareClose(true);\n-\n-        log.info(\"Prepared clean close\");\n-    }\n-\n-    @Override\n-    public void prepareCloseDirty() {\n-        prepareClose(false);\n-\n-        log.info(\"Prepared dirty close\");\n-    }\n-\n-    /**\n-     * 1. commit if we are running and clean close;\n-     * 2. close the state manager.\n-     *\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    private void prepareClose(final boolean clean) {\n-        switch (state()) {\n-            case CREATED:\n-            case CLOSED:\n-                log.trace(\"Skip prepare closing since state is {}\", state());\n-                return;\n-\n-            case RUNNING:\n-                if (clean) {\n-                    stateMgr.flush();\n-                }\n-\n-                break;\n-\n-            case RESTORING:\n-            case SUSPENDED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing standby task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing standby task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void closeClean() {\n         close(true);\n-\n         log.info(\"Closed clean\");\n     }\n \n     @Override\n     public void closeDirty() {\n         close(false);\n-\n         log.info(\"Closed dirty\");\n     }\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n+        suspend();\n+        prepareCommit();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjcyMQ=="}, "originalCommit": {"oid": "329e187a9187c4ea532ce88e0202402cb6f78b86"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3NTg1Mw==", "bodyText": "Nevermind, I see that's the pattern we follow everywhere else", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438475853", "createdAt": "2020-06-11T00:19:21Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -151,73 +158,24 @@ public void postCommit() {\n         }\n     }\n \n-    @Override\n-    public void prepareCloseClean() {\n-        prepareClose(true);\n-\n-        log.info(\"Prepared clean close\");\n-    }\n-\n-    @Override\n-    public void prepareCloseDirty() {\n-        prepareClose(false);\n-\n-        log.info(\"Prepared dirty close\");\n-    }\n-\n-    /**\n-     * 1. commit if we are running and clean close;\n-     * 2. close the state manager.\n-     *\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    private void prepareClose(final boolean clean) {\n-        switch (state()) {\n-            case CREATED:\n-            case CLOSED:\n-                log.trace(\"Skip prepare closing since state is {}\", state());\n-                return;\n-\n-            case RUNNING:\n-                if (clean) {\n-                    stateMgr.flush();\n-                }\n-\n-                break;\n-\n-            case RESTORING:\n-            case SUSPENDED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing standby task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing standby task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void closeClean() {\n         close(true);\n-\n         log.info(\"Closed clean\");\n     }\n \n     @Override\n     public void closeDirty() {\n         close(false);\n-\n         log.info(\"Closed dirty\");\n     }\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n+        suspend();\n+        prepareCommit();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjcyMQ=="}, "originalCommit": {"oid": "329e187a9187c4ea532ce88e0202402cb6f78b86"}, "originalPosition": 141}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2556, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}