{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc2OTUzMzk1", "number": 9237, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxOTo1ODo1NFrOEh1k3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQyMjozNDo0NlrOEqgRTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzOTE2MjU1OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxOTo1ODo1NFrOHPYHyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxOTo1ODo1NFrOHPYHyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTg4NTg5OA==", "bodyText": "I'm not really sure what the threading model is when building the topology, but chose to be safe and made all the accessors synchronized.", "url": "https://github.com/apache/kafka/pull/9237#discussion_r485885898", "createdAt": "2020-09-09T19:58:54Z", "author": {"login": "lkokhreidze"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -632,8 +632,18 @@ public final void addInternalTopic(final String topicName,\n         internalTopicNamesWithProperties.put(topicName, internalTopicProperties);\n     }\n \n-    public final void copartitionSources(final Collection<String> sourceNodes) {\n-        copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n+    public final synchronized void copartitionSources(final Collection<String> sourceNodes) {\n+        copartitionSourceGroups.add(new HashSet<>(sourceNodes));\n+    }\n+\n+    public final synchronized void maybeUpdateCopartitionSourceGroups(final String replacedNodeName,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac26e58942ddeeed9e66fea3c7b5b53bb6aab143"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzOTE2NjAwOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamTableJoinTopologyOptimizationIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxOTo1OTozOFrOHPYJ1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxOTo1OTozOFrOHPYJ1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTg4NjQyMw==", "bodyText": "There's already another StreamTableIntegrationTest present, but it works with TopologyTestDriver so I thought it would be better and easier to keep them separate.", "url": "https://github.com/apache/kafka/pull/9237#discussion_r485886423", "createdAt": "2020-09-09T19:59:38Z", "author": {"login": "lkokhreidze"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamTableJoinTopologyOptimizationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.TopicDescription;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.IntegerDeserializer;\n+import org.apache.kafka.common.serialization.IntegerSerializer;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(value = Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class StreamTableJoinTopologyOptimizationIntegrationTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac26e58942ddeeed9e66fea3c7b5b53bb6aab143"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNjcxMzg2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQyMjo1ODoyMFrOHayIaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQxNjo0Nzo1M1rOHbS7UA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg0NjM3OQ==", "bodyText": "building a topology is done on the main thread when calling StreamBuilder.build() so I think it's safe to remove synchronized.", "url": "https://github.com/apache/kafka/pull/9237#discussion_r497846379", "createdAt": "2020-09-30T22:58:20Z", "author": {"login": "bbejeck"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -632,11 +632,21 @@ public final void addInternalTopic(final String topicName,\n         internalTopicNamesWithProperties.put(topicName, internalTopicProperties);\n     }\n \n-    public final void copartitionSources(final Collection<String> sourceNodes) {\n-        copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n+    public final synchronized void copartitionSources(final Collection<String> sourceNodes) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36ec38bd292d8b0b139c15c69392542eef3e438b"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODM4MzY5Ng==", "bodyText": "Thanks for confirming, removed synchronized.", "url": "https://github.com/apache/kafka/pull/9237#discussion_r498383696", "createdAt": "2020-10-01T16:47:53Z", "author": {"login": "lkokhreidze"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -632,11 +632,21 @@ public final void addInternalTopic(final String topicName,\n         internalTopicNamesWithProperties.put(topicName, internalTopicProperties);\n     }\n \n-    public final void copartitionSources(final Collection<String> sourceNodes) {\n-        copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n+    public final synchronized void copartitionSources(final Collection<String> sourceNodes) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg0NjM3OQ=="}, "originalCommit": {"oid": "36ec38bd292d8b0b139c15c69392542eef3e438b"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODU0OTYyOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNTowODozN1rOHchfDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNTozODoyMFrOHciyMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY3MDc5OQ==", "bodyText": "nit: I think we can remove synchronized here as well", "url": "https://github.com/apache/kafka/pull/9237#discussion_r499670799", "createdAt": "2020-10-05T15:08:37Z", "author": {"login": "bbejeck"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,10 +633,20 @@ public final void addInternalTopic(final String topicName,\n     }\n \n     public final void copartitionSources(final Collection<String> sourceNodes) {\n-        copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n+        copartitionSourceGroups.add(new HashSet<>(sourceNodes));\n     }\n \n-    public void validateCopartition() {\n+    public final void maybeUpdateCopartitionSourceGroups(final String replacedNodeName,\n+                                                         final String optimizedNodeName) {\n+        for (final Set<String> copartitionSourceGroup : copartitionSourceGroups) {\n+            if (copartitionSourceGroup.contains(replacedNodeName)) {\n+                copartitionSourceGroup.remove(replacedNodeName);\n+                copartitionSourceGroup.add(optimizedNodeName);\n+            }\n+        }\n+    }\n+\n+    public synchronized void validateCopartition() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6eb3686facb4acc705ca7932f8eb5fc28548619"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY5MTExMg==", "bodyText": "Sorry, somehow missed this one. On it.", "url": "https://github.com/apache/kafka/pull/9237#discussion_r499691112", "createdAt": "2020-10-05T15:37:00Z", "author": {"login": "lkokhreidze"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,10 +633,20 @@ public final void addInternalTopic(final String topicName,\n     }\n \n     public final void copartitionSources(final Collection<String> sourceNodes) {\n-        copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n+        copartitionSourceGroups.add(new HashSet<>(sourceNodes));\n     }\n \n-    public void validateCopartition() {\n+    public final void maybeUpdateCopartitionSourceGroups(final String replacedNodeName,\n+                                                         final String optimizedNodeName) {\n+        for (final Set<String> copartitionSourceGroup : copartitionSourceGroups) {\n+            if (copartitionSourceGroup.contains(replacedNodeName)) {\n+                copartitionSourceGroup.remove(replacedNodeName);\n+                copartitionSourceGroup.add(optimizedNodeName);\n+            }\n+        }\n+    }\n+\n+    public synchronized void validateCopartition() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY3MDc5OQ=="}, "originalCommit": {"oid": "a6eb3686facb4acc705ca7932f8eb5fc28548619"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY5MjA4Mw==", "bodyText": "Done.", "url": "https://github.com/apache/kafka/pull/9237#discussion_r499692083", "createdAt": "2020-10-05T15:38:20Z", "author": {"login": "lkokhreidze"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,10 +633,20 @@ public final void addInternalTopic(final String topicName,\n     }\n \n     public final void copartitionSources(final Collection<String> sourceNodes) {\n-        copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n+        copartitionSourceGroups.add(new HashSet<>(sourceNodes));\n     }\n \n-    public void validateCopartition() {\n+    public final void maybeUpdateCopartitionSourceGroups(final String replacedNodeName,\n+                                                         final String optimizedNodeName) {\n+        for (final Set<String> copartitionSourceGroup : copartitionSourceGroups) {\n+            if (copartitionSourceGroup.contains(replacedNodeName)) {\n+                copartitionSourceGroup.remove(replacedNodeName);\n+                copartitionSourceGroup.add(optimizedNodeName);\n+            }\n+        }\n+    }\n+\n+    public synchronized void validateCopartition() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY3MDc5OQ=="}, "originalCommit": {"oid": "a6eb3686facb4acc705ca7932f8eb5fc28548619"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDA0MzY2OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamTableJoinTopologyOptimizationIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQyMjozNDo0NlrOHcwAkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjowMjoxN1rOHc3CJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwODc1Mw==", "bodyText": "super nit: I missed this before, but the last statement could be an else", "url": "https://github.com/apache/kafka/pull/9237#discussion_r499908753", "createdAt": "2020-10-05T22:34:46Z", "author": {"login": "bbejeck"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamTableJoinTopologyOptimizationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.TopicDescription;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.IntegerDeserializer;\n+import org.apache.kafka.common.serialization.IntegerSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(value = Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class StreamTableJoinTopologyOptimizationIntegrationTest {\n+    private static final int NUM_BROKERS = 1;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(NUM_BROKERS);\n+\n+    private String tableTopic;\n+    private String inputTopic;\n+    private String outputTopic;\n+    private String applicationId;\n+\n+    private Properties streamsConfiguration;\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    @Parameterized.Parameter\n+    public String topologyOptimization;\n+\n+    @Parameterized.Parameters(name = \"Optimization = {0}\")\n+    public static Collection<?> topologyOptimization() {\n+        return Arrays.asList(new String[][]{\n+            {StreamsConfig.OPTIMIZE},\n+            {StreamsConfig.NO_OPTIMIZATION}\n+        });\n+    }\n+\n+    @Before\n+    public void before() throws InterruptedException {\n+        streamsConfiguration = new Properties();\n+\n+        final String safeTestName = safeUniqueTestName(getClass(), testName);\n+\n+        tableTopic = \"table-topic\" + safeTestName;\n+        inputTopic = \"stream-topic-\" + safeTestName;\n+        outputTopic = \"output-topic-\" + safeTestName;\n+        applicationId = \"app-\" + safeTestName;\n+\n+        CLUSTER.createTopic(inputTopic, 4, 1);\n+        CLUSTER.createTopic(tableTopic, 2, 1);\n+        CLUSTER.createTopic(outputTopic, 4, 1);\n+\n+        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, applicationId);\n+        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers());\n+        streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        streamsConfiguration.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n+        streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n+        streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());\n+        streamsConfiguration.put(StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG, topologyOptimization);\n+    }\n+\n+    @After\n+    public void whenShuttingDown() throws IOException {\n+        IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n+    }\n+\n+    @Test\n+    public void shouldDoStreamTableJoinWithDifferentNumberOfPartitions() throws Exception {\n+        final String storeName = \"store\";\n+        final String selectKeyName = \"selectKey\";\n+\n+        final StreamsBuilder streamsBuilder = new StreamsBuilder();\n+\n+        final KStream<Integer, String> stream = streamsBuilder.stream(inputTopic);\n+        final KTable<Integer, String> table = streamsBuilder.table(tableTopic, Materialized.as(storeName));\n+\n+        stream\n+            .selectKey((key, value) -> key, Named.as(selectKeyName))\n+            .join(table, (value1, value2) -> value2)\n+            .to(outputTopic);\n+\n+        startStreams(streamsBuilder);\n+\n+        final long timestamp = System.currentTimeMillis();\n+\n+        final List<KeyValue<Integer, String>> expectedRecords = Arrays.asList(\n+            new KeyValue<>(1, \"A\"),\n+            new KeyValue<>(2, \"B\")\n+        );\n+\n+        sendEvents(inputTopic, timestamp, expectedRecords);\n+        sendEvents(outputTopic, timestamp, expectedRecords);\n+\n+        startStreams(streamsBuilder);\n+\n+        validateReceivedMessages(\n+            outputTopic,\n+            new IntegerDeserializer(),\n+            new StringDeserializer(),\n+            expectedRecords\n+        );\n+\n+        final Set<String> allTopicsInCluster = CLUSTER.getAllTopicsInCluster();\n+\n+        final String repartitionTopicName = applicationId + \"-\" + selectKeyName + \"-repartition\";\n+        final String tableChangelogStoreName = applicationId + \"-\" + storeName + \"-changelog\";\n+\n+        assertTrue(topicExists(repartitionTopicName));\n+        assertEquals(2, getNumberOfPartitionsForTopic(repartitionTopicName));\n+\n+        if (StreamsConfig.OPTIMIZE.equals(topologyOptimization)) {\n+            assertFalse(allTopicsInCluster.contains(tableChangelogStoreName));\n+        } else if (StreamsConfig.NO_OPTIMIZATION.equals(topologyOptimization)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "66366e4b98b60dabf4e477a32aae8ca88a33f508"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAyMzg0NA==", "bodyText": "I did it on purpose. Potentially there can be some changes regarding those values and felt like being explicit on what is being tested would be better.", "url": "https://github.com/apache/kafka/pull/9237#discussion_r500023844", "createdAt": "2020-10-06T06:02:17Z", "author": {"login": "lkokhreidze"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamTableJoinTopologyOptimizationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.TopicDescription;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.IntegerDeserializer;\n+import org.apache.kafka.common.serialization.IntegerSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(value = Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class StreamTableJoinTopologyOptimizationIntegrationTest {\n+    private static final int NUM_BROKERS = 1;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(NUM_BROKERS);\n+\n+    private String tableTopic;\n+    private String inputTopic;\n+    private String outputTopic;\n+    private String applicationId;\n+\n+    private Properties streamsConfiguration;\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    @Parameterized.Parameter\n+    public String topologyOptimization;\n+\n+    @Parameterized.Parameters(name = \"Optimization = {0}\")\n+    public static Collection<?> topologyOptimization() {\n+        return Arrays.asList(new String[][]{\n+            {StreamsConfig.OPTIMIZE},\n+            {StreamsConfig.NO_OPTIMIZATION}\n+        });\n+    }\n+\n+    @Before\n+    public void before() throws InterruptedException {\n+        streamsConfiguration = new Properties();\n+\n+        final String safeTestName = safeUniqueTestName(getClass(), testName);\n+\n+        tableTopic = \"table-topic\" + safeTestName;\n+        inputTopic = \"stream-topic-\" + safeTestName;\n+        outputTopic = \"output-topic-\" + safeTestName;\n+        applicationId = \"app-\" + safeTestName;\n+\n+        CLUSTER.createTopic(inputTopic, 4, 1);\n+        CLUSTER.createTopic(tableTopic, 2, 1);\n+        CLUSTER.createTopic(outputTopic, 4, 1);\n+\n+        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, applicationId);\n+        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers());\n+        streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        streamsConfiguration.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n+        streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n+        streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());\n+        streamsConfiguration.put(StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG, topologyOptimization);\n+    }\n+\n+    @After\n+    public void whenShuttingDown() throws IOException {\n+        IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n+    }\n+\n+    @Test\n+    public void shouldDoStreamTableJoinWithDifferentNumberOfPartitions() throws Exception {\n+        final String storeName = \"store\";\n+        final String selectKeyName = \"selectKey\";\n+\n+        final StreamsBuilder streamsBuilder = new StreamsBuilder();\n+\n+        final KStream<Integer, String> stream = streamsBuilder.stream(inputTopic);\n+        final KTable<Integer, String> table = streamsBuilder.table(tableTopic, Materialized.as(storeName));\n+\n+        stream\n+            .selectKey((key, value) -> key, Named.as(selectKeyName))\n+            .join(table, (value1, value2) -> value2)\n+            .to(outputTopic);\n+\n+        startStreams(streamsBuilder);\n+\n+        final long timestamp = System.currentTimeMillis();\n+\n+        final List<KeyValue<Integer, String>> expectedRecords = Arrays.asList(\n+            new KeyValue<>(1, \"A\"),\n+            new KeyValue<>(2, \"B\")\n+        );\n+\n+        sendEvents(inputTopic, timestamp, expectedRecords);\n+        sendEvents(outputTopic, timestamp, expectedRecords);\n+\n+        startStreams(streamsBuilder);\n+\n+        validateReceivedMessages(\n+            outputTopic,\n+            new IntegerDeserializer(),\n+            new StringDeserializer(),\n+            expectedRecords\n+        );\n+\n+        final Set<String> allTopicsInCluster = CLUSTER.getAllTopicsInCluster();\n+\n+        final String repartitionTopicName = applicationId + \"-\" + selectKeyName + \"-repartition\";\n+        final String tableChangelogStoreName = applicationId + \"-\" + storeName + \"-changelog\";\n+\n+        assertTrue(topicExists(repartitionTopicName));\n+        assertEquals(2, getNumberOfPartitionsForTopic(repartitionTopicName));\n+\n+        if (StreamsConfig.OPTIMIZE.equals(topologyOptimization)) {\n+            assertFalse(allTopicsInCluster.contains(tableChangelogStoreName));\n+        } else if (StreamsConfig.NO_OPTIMIZATION.equals(topologyOptimization)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwODc1Mw=="}, "originalCommit": {"oid": "66366e4b98b60dabf4e477a32aae8ca88a33f508"}, "originalPosition": 171}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1978, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}