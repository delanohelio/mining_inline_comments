{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEwOTIyNjA0", "number": 9512, "title": "KAFKA-10394: generate snapshot", "bodyText": "This PR adds support for generating snapshot for KIP-630.\n\n\nAdds the interfaces RawSnapshotWriter and RawSnapshotReader and the implementations FileRawSnapshotWriter and FileRawSnapshotReader respectively. These interfaces and implementations are low level API for writing and reading snapshots. They are internal to the Raft implementation and are not exposed to the users of RaftClient. They operation at the Record level. These types are exposed to the RaftClient through the ReplicatedLog interface.\n\n\nAdds a buffered snapshot writer: SnapshotWriter<T>. This type is a higher-level type and it is exposed through the RaftClient interface. A future PR will add the related SnapshotReader<T>, which will be used by the state machine to load a snapshot.\n\n\nMore detailed description of your change,\nif necessary. The PR title and PR message become\nthe squashed commit message, so use a separate\ncomment to ping reviewers.\nSummary of testing strategy (including rationale)\nfor the feature or bug fix. Unit and/or integration\ntests are expected for any behaviour change and\nsystem tests should be considered for larger changes.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-10-27T17:12:43Z", "url": "https://github.com/apache/kafka/pull/9512", "merged": true, "mergeCommit": {"oid": "ab0807dd858887d934d2be520608d20bf765b609"}, "closed": true, "closedAt": "2020-12-07T22:06:26Z", "author": {"login": "jsancio"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdXAuIigH2gAyNTEwOTIyNjA0OjkxYmNlN2U4OTY0ZDBmNWE4MGE1MjFmZmViNjdjMTAzMzQxN2E0ZDE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdj6q1gAFqTU0NjQ1MTEwNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "91bce7e8964d0f5a80a521ffeb67c1033417a4d1", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/91bce7e8964d0f5a80a521ffeb67c1033417a4d1", "committedDate": "2020-10-28T17:07:53Z", "message": "KAFKA-10394: Generate Kafka Snapshots"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "455e36221edb91f90b0ad7c05042e44b0754f512", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/455e36221edb91f90b0ad7c05042e44b0754f512", "committedDate": "2020-10-29T17:40:36Z", "message": "Implement a buffered snapshot writer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "455e36221edb91f90b0ad7c05042e44b0754f512", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/455e36221edb91f90b0ad7c05042e44b0754f512", "committedDate": "2020-10-29T17:40:36Z", "message": "Implement a buffered snapshot writer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00ea9fdd864efb45bd6987c874662a51641d6487", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/00ea9fdd864efb45bd6987c874662a51641d6487", "committedDate": "2020-10-29T18:36:32Z", "message": "Simplify some tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ac347d0733cad6ef0454249cf1f8835f8d4fb9c", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/5ac347d0733cad6ef0454249cf1f8835f8d4fb9c", "committedDate": "2020-10-31T20:52:52Z", "message": "Support appending bytes directly to the snapshot"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "5ac347d0733cad6ef0454249cf1f8835f8d4fb9c", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/5ac347d0733cad6ef0454249cf1f8835f8d4fb9c", "committedDate": "2020-10-31T20:52:52Z", "message": "Support appending bytes directly to the snapshot"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3cc586bd56e28686b54a5f719956ca271e9dc9e", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/a3cc586bd56e28686b54a5f719956ca271e9dc9e", "committedDate": "2020-10-31T21:01:29Z", "message": "Rename snapshot writing to BatchedSnapshotWriter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "288b19f4ec11f9ced3327ac1c371927245e06882", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/288b19f4ec11f9ced3327ac1c371927245e06882", "committedDate": "2020-11-03T18:34:09Z", "message": "Merge remote-tracking branch 'upstream/trunk' into kafka-10394-generate-snapshot"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyOTE1ODgx", "url": "https://github.com/apache/kafka/pull/9512#pullrequestreview-522915881", "createdAt": "2020-11-03T22:19:26Z", "commit": {"oid": "288b19f4ec11f9ced3327ac1c371927245e06882"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMjoxOToyNlrOHtCfhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMjozMzozMFrOHtC21g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk4ODgwNg==", "bodyText": "It would be nice if we can figure out how to consolidate this and BatchReader. It seems like it should be doable.", "url": "https://github.com/apache/kafka/pull/9512#discussion_r516988806", "createdAt": "2020-11-03T22:19:26Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/SnapshotReader.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Iterator;\n+import org.apache.kafka.common.record.RecordBatch;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+// TODO: Write documentation for this type and all of the methods\n+public interface SnapshotReader extends Closeable, Iterable<RecordBatch> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "288b19f4ec11f9ced3327ac1c371927245e06882"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk4OTM4MA==", "bodyText": "So I guess we need this in order to be able to serve FetchSnapshot requests. I am wondering if it would be better to pull it into a separate object. Maybe we can have something like this:\nclass SnapshotReader extends BatchReader;\n\nclass Snapshot extends Iterable<Batch> {\n  public SnapshotReader iterator();\n  public int read(ByteBuffer buffer, long position) throws IOException;\n}", "url": "https://github.com/apache/kafka/pull/9512#discussion_r516989380", "createdAt": "2020-11-03T22:20:48Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/SnapshotReader.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Iterator;\n+import org.apache.kafka.common.record.RecordBatch;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+// TODO: Write documentation for this type and all of the methods\n+public interface SnapshotReader extends Closeable, Iterable<RecordBatch> {\n+\n+    public OffsetAndEpoch snapshotId();\n+\n+    public long sizeInBytes();\n+\n+    public Iterator<RecordBatch> iterator();\n+\n+    public int read(ByteBuffer buffer, long position) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "288b19f4ec11f9ced3327ac1c371927245e06882"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5MzA5OA==", "bodyText": "So far we have preferred to keep implementations in the raft package except in cases where we depended on something that was in the server code (such as Log). Is there any reason to do snapshots differently? I think we would still be able to use the snapshot code from raft for other internal use cases (like __consumer_offsets).", "url": "https://github.com/apache/kafka/pull/9512#discussion_r516993098", "createdAt": "2020-11-03T22:29:27Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/snapshot/KafkaSnapshotReader.scala", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package kafka.snapshot\n+\n+import java.nio.ByteBuffer\n+import java.nio.file.Path\n+import java.util.{Iterator => JIterator}\n+import org.apache.kafka.common.record.RecordBatch\n+import org.apache.kafka.common.record.FileRecords\n+import org.apache.kafka.raft.OffsetAndEpoch\n+import org.apache.kafka.snapshot.SnapshotReader\n+\n+final class KafkaSnapshotReader private (fileRecords: FileRecords, snapshotId: OffsetAndEpoch) extends SnapshotReader {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "288b19f4ec11f9ced3327ac1c371927245e06882"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5NDc3NA==", "bodyText": "The types surprised me a bit. I would have expected this to extend SnapshotWriter. I'm wondering why we don't push the type <T> up to SnapshotWriter and try to keep Records out of the interfaces?", "url": "https://github.com/apache/kafka/pull/9512#discussion_r516994774", "createdAt": "2020-11-03T22:33:30Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/BatchedSnapshotWriter.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.snapshot;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.List;\n+import org.apache.kafka.common.memory.MemoryPool;\n+import org.apache.kafka.common.record.CompressionType;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+import org.apache.kafka.raft.RecordSerde;\n+import org.apache.kafka.raft.internals.BatchAccumulator.CompletedBatch;\n+import org.apache.kafka.raft.internals.BatchAccumulator;\n+\n+// TODO: Write documentation for this type and all of the methods\n+final public class BatchedSnapshotWriter<T> implements Closeable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "288b19f4ec11f9ced3327ac1c371927245e06882"}, "originalPosition": 32}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b05419777b17bff90e9a0c3bef8c373cab38e7ee", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/b05419777b17bff90e9a0c3bef8c373cab38e7ee", "committedDate": "2020-11-05T21:58:07Z", "message": "Move snapshot implementations to raft project"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c85536b893e65609bb2433749852f1cdc3779b4", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/5c85536b893e65609bb2433749852f1cdc3779b4", "committedDate": "2020-11-06T21:37:55Z", "message": "Rename the snapshot classes and interfaces"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "303c300a3761bce08ae4605158c2a65414b7923f", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/303c300a3761bce08ae4605158c2a65414b7923f", "committedDate": "2020-11-07T19:41:41Z", "message": "Improve documentation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1Njc2ODI0", "url": "https://github.com/apache/kafka/pull/9512#pullrequestreview-525676824", "createdAt": "2020-11-07T19:44:17Z", "commit": {"oid": "303c300a3761bce08ae4605158c2a65414b7923f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxOTo0NDoxN1rOHvKJfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxOTo0NDoxN1rOHvKJfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIxMTM5MA==", "bodyText": "Changes to this file are unrelated to this PR. Made them here so that docsJar would succeed.", "url": "https://github.com/apache/kafka/pull/9512#discussion_r519211390", "createdAt": "2020-11-07T19:44:17Z", "author": {"login": "jsancio"}, "path": "raft/src/main/java/org/apache/kafka/raft/QuorumState.java", "diffHunk": "@@ -32,25 +32,25 @@\n  * This class is responsible for managing the current state of this node and ensuring only\n  * valid state transitions.\n  *\n- * Unattached =>\n+ * Unattached transitions to:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "303c300a3761bce08ae4605158c2a65414b7923f"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1Njc2OTY0", "url": "https://github.com/apache/kafka/pull/9512#pullrequestreview-525676964", "createdAt": "2020-11-07T19:46:11Z", "commit": {"oid": "303c300a3761bce08ae4605158c2a65414b7923f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxOTo0NjoxMVrOHvKKQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxOTo0NjoxMVrOHvKKQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIxMTU4Ng==", "bodyText": "As @hachikuji and I discussed offline, it is very like that this method will change to:\npublic void append(MemoryRecords records) throws IOException;\nAfter we implement https://issues.apache.org/jira/browse/KAFKA-10694", "url": "https://github.com/apache/kafka/pull/9512#discussion_r519211586", "createdAt": "2020-11-07T19:46:11Z", "author": {"login": "jsancio"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/RawSnapshotWriter.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.snapshot;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+/**\n+ * Interface for writing snapshot as a sequence of records.\n+ */\n+public interface RawSnapshotWriter extends Closeable {\n+    /**\n+     * Returns the end offset and epoch for the snapshot.\n+     */\n+    public OffsetAndEpoch snapshotId();\n+\n+    /**\n+     * Returns the number of bytes for the snapshot.\n+     *\n+     * @throws IOException for any IO error while reading the size\n+     */\n+    public long sizeInBytes() throws IOException;\n+\n+    /**\n+     * Fully appends the buffer to the snapshot.\n+     *\n+     * If the method returns without an exception the given buffer was fully writing the\n+     * snapshot.\n+     *\n+     * @param buffer the buffer to append\n+     * @throws IOException for any IO error during append\n+     */\n+    public void append(ByteBuffer buffer) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "303c300a3761bce08ae4605158c2a65414b7923f"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1Njc3MDc0", "url": "https://github.com/apache/kafka/pull/9512#pullrequestreview-525677074", "createdAt": "2020-11-07T19:47:45Z", "commit": {"oid": "303c300a3761bce08ae4605158c2a65414b7923f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxOTo0Nzo0NVrOHvKKyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxOTo0Nzo0NVrOHvKKyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIxMTcyMQ==", "bodyText": "As @hachikuji and I discussed offline, it is very like that this method will change to:\npublic BaseRecords slice(long position) throws IOException;\nAfter we implement https://issues.apache.org/jira/browse/KAFKA-10694", "url": "https://github.com/apache/kafka/pull/9512#discussion_r519211721", "createdAt": "2020-11-07T19:47:45Z", "author": {"login": "jsancio"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/RawSnapshotReader.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import org.apache.kafka.common.record.RecordBatch;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+/**\n+ * Interface for reading snapshots as a sequence of records.\n+ */\n+public interface RawSnapshotReader extends Closeable, Iterable<RecordBatch> {\n+    /**\n+     * Returns the end offset and epoch for the snapshot.\n+     */\n+    public OffsetAndEpoch snapshotId();\n+\n+    /**\n+     * Returns the number of bytes for the snapshot.\n+     *\n+     * @throws IOException for any IO error while reading the size\n+     */\n+    public long sizeInBytes() throws IOException;\n+\n+    /**\n+     * Reads bytes from position into the given buffer.\n+     *\n+     * It is not guarantee that the given buffer will be filled.\n+     *\n+     * @param buffer byte buffer to put the read files\n+     * @param position the starting position in the snapshot to read\n+     * @return the number of bytes read\n+     * @throws IOException for any IO error while reading the snapshot\n+     */\n+    public int read(ByteBuffer buffer, long position) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "303c300a3761bce08ae4605158c2a65414b7923f"}, "originalPosition": 51}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db591686f308776d5d7d515df89f5a12c3d6d841", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/db591686f308776d5d7d515df89f5a12c3d6d841", "committedDate": "2020-11-07T19:59:17Z", "message": "Change the epoch formatter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "408d0b7968f79100834058034721573335ba0f21", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/408d0b7968f79100834058034721573335ba0f21", "committedDate": "2020-11-07T20:32:21Z", "message": "Merge remote-tracking branch 'upstream/trunk' into kafka-10394-generate-snapshot"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/9c7b8e45679eab960fb634a91eafe0b0f5d28e9e", "committedDate": "2020-11-23T17:46:07Z", "message": "Merge remote-tracking branch 'upstream/trunk' into kafka-10394-generate-snapshot"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMzA2NjY2", "url": "https://github.com/apache/kafka/pull/9512#pullrequestreview-542306666", "createdAt": "2020-12-01T21:22:34Z", "commit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMToyMjozNVrOH9ARuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMjoxNDoxMlrOH9B68w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcyOTcyMw==", "bodyText": "Do we assume the offset is below the high watermark?", "url": "https://github.com/apache/kafka/pull/9512#discussion_r533729723", "createdAt": "2020-12-01T21:22:35Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/raft/RaftClient.java", "diffHunk": "@@ -100,4 +102,15 @@ default void handleResign() {}\n      */\n     CompletableFuture<Void> shutdown(int timeoutMs);\n \n+    /**\n+     * Create a writable snapshot file for a given offset and epoch.\n+     *\n+     * The RaftClient assumes that the snapshot return will contain the records up to but\n+     * not including the end offset in the snapshot id. See {@link SnapshotWriter} for\n+     * details on how to use this object.\n+     *\n+     * @param snapshotId the end offset and epoch that identifies the snapshot", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzczMjc4OQ==", "bodyText": "This suffix is used for producer state snapshots already. Maybe we could use .snap or something like that.", "url": "https://github.com/apache/kafka/pull/9512#discussion_r533732789", "createdAt": "2020-12-01T21:28:37Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/Snapshots.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.text.NumberFormat;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+final class Snapshots {\n+    private static final String SNAPSHOT_DIR = \"snapshots\";\n+    private static final String SUFFIX =  \".snapshot\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc0MDk1MA==", "bodyText": "Do we also need an api to list snapshots?", "url": "https://github.com/apache/kafka/pull/9512#discussion_r533740950", "createdAt": "2020-12-01T21:44:15Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/raft/ReplicatedLog.java", "diffHunk": "@@ -149,6 +152,29 @@ default OptionalLong truncateToEndOffset(OffsetAndEpoch endOffset) {\n         return OptionalLong.of(truncationOffset);\n     }\n \n+    /**\n+     * Create a writable snapshot for the given snapshot id.\n+     *\n+     * See {@link RawSnapshotWriter} for details on how to use this object.\n+     *\n+     * @param snapshotId the end offset and epoch that identifies the snapshot\n+     * @return a writable snapshot\n+     */\n+    RawSnapshotWriter createSnapshot(OffsetAndEpoch snapshotId) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc0MjU4MA==", "bodyText": "Is there a tangible benefit to separating snapshots into a new directory? Currently the log directory is a flat structure. I'm wondering if we should stick with convention.", "url": "https://github.com/apache/kafka/pull/9512#discussion_r533742580", "createdAt": "2020-12-01T21:47:21Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/Snapshots.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.text.NumberFormat;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+final class Snapshots {\n+    private static final String SNAPSHOT_DIR = \"snapshots\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc0NjQ3NQ==", "bodyText": "Maybe we can just a better name for path since it makes this code look suspicious.", "url": "https://github.com/apache/kafka/pull/9512#discussion_r533746475", "createdAt": "2020-12-01T21:54:44Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/FileRawSnapshotWriter.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardCopyOption;\n+import java.nio.file.StandardOpenOption;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+public final class FileRawSnapshotWriter implements RawSnapshotWriter {\n+    private final Path path;\n+    private final FileChannel channel;\n+    private final OffsetAndEpoch snapshotId;\n+    private boolean frozen = false;\n+\n+    private FileRawSnapshotWriter(\n+        Path path,\n+        FileChannel channel,\n+        OffsetAndEpoch snapshotId\n+    ) {\n+        this.path = path;\n+        this.channel = channel;\n+        this.snapshotId = snapshotId;\n+    }\n+\n+    @Override\n+    public OffsetAndEpoch snapshotId() {\n+        return snapshotId;\n+    }\n+\n+    @Override\n+    public long sizeInBytes() throws IOException {\n+        return channel.size();\n+    }\n+\n+    @Override\n+    public void append(ByteBuffer buffer) throws IOException {\n+        if (frozen) {\n+            throw new IllegalStateException(\n+                String.format(\"Append not supported. Snapshot is already frozen: id = %s; path = %s\", snapshotId, path)\n+            );\n+        }\n+\n+        Utils.writeFully(channel, buffer);\n+    }\n+\n+    @Override\n+    public boolean isFrozen() {\n+        return frozen;\n+    }\n+\n+    @Override\n+    public void freeze() throws IOException {\n+        channel.close();\n+        frozen = true;\n+\n+        // Set readonly and ignore the result\n+        if (!path.toFile().setReadOnly()) {\n+            throw new IOException(String.format(\"Unable to set file %s as read-only\", path));\n+        }\n+\n+        Path destination = Snapshots.moveRename(path, snapshotId);\n+        Files.move(path, destination, StandardCopyOption.ATOMIC_MOVE);\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        channel.close();\n+        Files.deleteIfExists(path);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc1MDA4OA==", "bodyText": "nit: I think this would be more natural:\nif (accumulator.needsDrain(time.milliseconds())) {\n  appendBatches(accumulator.drain());\n}", "url": "https://github.com/apache/kafka/pull/9512#discussion_r533750088", "createdAt": "2020-12-01T22:01:27Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/SnapshotWriter.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.snapshot;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.List;\n+import org.apache.kafka.common.memory.MemoryPool;\n+import org.apache.kafka.common.record.CompressionType;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+import org.apache.kafka.raft.RecordSerde;\n+import org.apache.kafka.raft.internals.BatchAccumulator.CompletedBatch;\n+import org.apache.kafka.raft.internals.BatchAccumulator;\n+\n+/**\n+ * A type for writing a snapshot fora given end offset and epoch.\n+ *\n+ * A snapshot writer can be used to append objects until freeze is called. When freeze is\n+ * called the snapshot is validated and marked as immutable. After freeze is called any\n+ * append will fail with an exception.\n+ *\n+ * It is assumed that the content of the snapshot represents all of the records for the\n+ * topic partition from offset 0 up to but not including the end offset in the snapshot\n+ * id.\n+ *\n+ * @see org.apache.kafka.raft.RaftClient#createSnapshot(OffsetAndEpoch)\n+ */\n+final public class SnapshotWriter<T> implements Closeable {\n+    final private RawSnapshotWriter snapshot;\n+    final private BatchAccumulator<T> accumulator;\n+    final private Time time;\n+\n+    /**\n+     * Initializes a new instance of the class.\n+     *\n+     * @param snapshot the low level snapshot writer\n+     * @param maxBatchSize the maximum size in byte for a batch\n+     * @param memoryPool the memory pool for buffer allocation\n+     * @param time the clock implementation\n+     * @param compressionType the compression algorithm to use\n+     * @param serde the record serialization and deserialization implementation\n+     */\n+    public SnapshotWriter(\n+        RawSnapshotWriter snapshot,\n+        int maxBatchSize,\n+        MemoryPool memoryPool,\n+        Time time,\n+        CompressionType compressionType,\n+        RecordSerde<T> serde\n+    ) {\n+        this.snapshot = snapshot;\n+        this.time = time;\n+\n+        this.accumulator = new BatchAccumulator<>(\n+            snapshot.snapshotId().epoch,\n+            0,\n+            Integer.MAX_VALUE,\n+            maxBatchSize,\n+            memoryPool,\n+            time,\n+            compressionType,\n+            serde\n+        );\n+    }\n+\n+    /**\n+     * Returns the end offset and epoch for the snapshot.\n+     */\n+    public OffsetAndEpoch snapshotId() {\n+        return snapshot.snapshotId();\n+    }\n+\n+    /**\n+     * Returns true if the snapshot has been frozen, otherwise false is returned.\n+     *\n+     * Modification to the snapshot are not allowed once it is frozen.\n+     */\n+    public boolean isFrozen() {\n+        return snapshot.isFrozen();\n+    }\n+\n+    /**\n+     * Appends a list of values to the snapshot.\n+     *\n+     * The list of record passed are guaranteed to get written together.\n+     *\n+     * @param records the list of records to append to the snapshot\n+     * @throws IOException for any IO error while appending\n+     * @throws IllegalStateException if append is called when isFrozen is true\n+     */\n+    public void append(List<T> records) throws IOException {\n+        if (snapshot.isFrozen()) {\n+            String message = String.format(\n+                \"Append not supported. Snapshot is already frozen: id = {}.\",\n+                snapshot.snapshotId()\n+            );\n+\n+            throw new IllegalStateException(message);\n+        }\n+\n+        accumulator.append(snapshot.snapshotId().epoch, records);\n+\n+        if (!accumulator.needsDrain(time.milliseconds())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc1MjAxOA==", "bodyText": "nit: kind of annoying to wrap the iterator just to avoid the generic warning. An alternative might be to use <? extends RecordBatch> in the interface.", "url": "https://github.com/apache/kafka/pull/9512#discussion_r533752018", "createdAt": "2020-12-01T22:05:08Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/FileRawSnapshotReader.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Path;\n+import java.util.Iterator;\n+import org.apache.kafka.common.record.FileLogInputStream.FileChannelRecordBatch;\n+import org.apache.kafka.common.record.FileRecords;\n+import org.apache.kafka.common.record.RecordBatch;\n+import org.apache.kafka.common.utils.AbstractIterator;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+public final class FileRawSnapshotReader implements RawSnapshotReader {\n+    private final FileRecords fileRecords;\n+    private final OffsetAndEpoch snapshotId;\n+\n+    private FileRawSnapshotReader(FileRecords fileRecords, OffsetAndEpoch snapshotId) {\n+        this.fileRecords = fileRecords;\n+        this.snapshotId = snapshotId;\n+    }\n+\n+    @Override\n+    public OffsetAndEpoch snapshotId() {\n+        return snapshotId;\n+    }\n+\n+    @Override\n+    public long sizeInBytes() {\n+        return fileRecords.sizeInBytes();\n+    }\n+\n+    @Override\n+    public Iterator<RecordBatch> iterator() {\n+        return new Iterator<RecordBatch>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc1NDEwNg==", "bodyText": "Wonder if we should consider using Utils.atomicMoveWithFallback?", "url": "https://github.com/apache/kafka/pull/9512#discussion_r533754106", "createdAt": "2020-12-01T22:09:13Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/FileRawSnapshotWriter.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardCopyOption;\n+import java.nio.file.StandardOpenOption;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+public final class FileRawSnapshotWriter implements RawSnapshotWriter {\n+    private final Path path;\n+    private final FileChannel channel;\n+    private final OffsetAndEpoch snapshotId;\n+    private boolean frozen = false;\n+\n+    private FileRawSnapshotWriter(\n+        Path path,\n+        FileChannel channel,\n+        OffsetAndEpoch snapshotId\n+    ) {\n+        this.path = path;\n+        this.channel = channel;\n+        this.snapshotId = snapshotId;\n+    }\n+\n+    @Override\n+    public OffsetAndEpoch snapshotId() {\n+        return snapshotId;\n+    }\n+\n+    @Override\n+    public long sizeInBytes() throws IOException {\n+        return channel.size();\n+    }\n+\n+    @Override\n+    public void append(ByteBuffer buffer) throws IOException {\n+        if (frozen) {\n+            throw new IllegalStateException(\n+                String.format(\"Append not supported. Snapshot is already frozen: id = %s; path = %s\", snapshotId, path)\n+            );\n+        }\n+\n+        Utils.writeFully(channel, buffer);\n+    }\n+\n+    @Override\n+    public boolean isFrozen() {\n+        return frozen;\n+    }\n+\n+    @Override\n+    public void freeze() throws IOException {\n+        channel.close();\n+        frozen = true;\n+\n+        // Set readonly and ignore the result\n+        if (!path.toFile().setReadOnly()) {\n+            throw new IOException(String.format(\"Unable to set file %s as read-only\", path));\n+        }\n+\n+        Path destination = Snapshots.moveRename(path, snapshotId);\n+        Files.move(path, destination, StandardCopyOption.ATOMIC_MOVE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc1NjY1OQ==", "bodyText": "We could probably use ByteBufferOutputStream which already handles expansion.", "url": "https://github.com/apache/kafka/pull/9512#discussion_r533756659", "createdAt": "2020-12-01T22:14:12Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/raft/MockLog.java", "diffHunk": "@@ -472,4 +489,110 @@ private EpochStartOffset(int epoch, long startOffset) {\n         }\n     }\n \n+    final class MockRawSnapshotWriter implements RawSnapshotWriter {\n+        private final OffsetAndEpoch snapshotId;\n+        private ByteBuffer data;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 54}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "10f1d5cea71910398979c368842b34ac964646bb", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/10f1d5cea71910398979c368842b34ac964646bb", "committedDate": "2020-12-03T00:58:46Z", "message": "Store snapshots directly in the partition directory"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzMzcyODA3", "url": "https://github.com/apache/kafka/pull/9512#pullrequestreview-543372807", "createdAt": "2020-12-03T01:31:17Z", "commit": {"oid": "10f1d5cea71910398979c368842b34ac964646bb"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwMTozMToxOFrOH91Vrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwMTo1ODozMlrOH919GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDU5OTA4Nw==", "bodyText": "Would it be useful to call this in a finally?", "url": "https://github.com/apache/kafka/pull/9512#discussion_r534599087", "createdAt": "2020-12-03T01:31:18Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/FileRawSnapshotWriter.java", "diffHunk": "@@ -74,18 +74,19 @@ public void freeze() throws IOException {\n         frozen = true;\n \n         // Set readonly and ignore the result\n-        if (!path.toFile().setReadOnly()) {\n-            throw new IOException(String.format(\"Unable to set file %s as read-only\", path));\n+        if (!tempSnapshotPath.toFile().setReadOnly()) {\n+            throw new IOException(String.format(\"Unable to set file (%s) as read-only\", tempSnapshotPath));\n         }\n \n-        Path destination = Snapshots.moveRename(path, snapshotId);\n-        Files.move(path, destination, StandardCopyOption.ATOMIC_MOVE);\n+        Path destination = Snapshots.moveRename(tempSnapshotPath, snapshotId);\n+        Files.move(tempSnapshotPath, destination, StandardCopyOption.ATOMIC_MOVE);\n     }\n \n     @Override\n     public void close() throws IOException {\n         channel.close();\n-        Files.deleteIfExists(path);\n+        // This is a noop if freeze was called before calling close\n+        Files.deleteIfExists(tempSnapshotPath);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10f1d5cea71910398979c368842b34ac964646bb"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYwNjgxNw==", "bodyText": "In that case, I would probably just do the cast to avoid the useless wrapper. Maybe we could create a helper like this in Utils:\n    @SuppressWarnings(\"unchecked\")\n    private <S, T extends S> Iterator<S> covariantCast(Iterator<T> iterator) {\n        return (Iterator<S>) iterator;\n    }", "url": "https://github.com/apache/kafka/pull/9512#discussion_r534606817", "createdAt": "2020-12-03T01:52:09Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/FileRawSnapshotReader.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Path;\n+import java.util.Iterator;\n+import org.apache.kafka.common.record.FileLogInputStream.FileChannelRecordBatch;\n+import org.apache.kafka.common.record.FileRecords;\n+import org.apache.kafka.common.record.RecordBatch;\n+import org.apache.kafka.common.utils.AbstractIterator;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+public final class FileRawSnapshotReader implements RawSnapshotReader {\n+    private final FileRecords fileRecords;\n+    private final OffsetAndEpoch snapshotId;\n+\n+    private FileRawSnapshotReader(FileRecords fileRecords, OffsetAndEpoch snapshotId) {\n+        this.fileRecords = fileRecords;\n+        this.snapshotId = snapshotId;\n+    }\n+\n+    @Override\n+    public OffsetAndEpoch snapshotId() {\n+        return snapshotId;\n+    }\n+\n+    @Override\n+    public long sizeInBytes() {\n+        return fileRecords.sizeInBytes();\n+    }\n+\n+    @Override\n+    public Iterator<RecordBatch> iterator() {\n+        return new Iterator<RecordBatch>() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc1MjAxOA=="}, "originalCommit": {"oid": "9c7b8e45679eab960fb634a91eafe0b0f5d28e9e"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYwNzI2NA==", "bodyText": "nit: can just do buildRecords(ByteBuffer.wrap(randomBytes(bufferSize)))", "url": "https://github.com/apache/kafka/pull/9512#discussion_r534607264", "createdAt": "2020-12-03T01:53:20Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/snapshot/FileRawSnapshotTest.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.stream.IntStream;\n+import org.apache.kafka.common.record.BufferSupplier.GrowableBufferSupplier;\n+import org.apache.kafka.common.record.CompressionType;\n+import org.apache.kafka.common.record.MemoryRecords;\n+import org.apache.kafka.common.record.RecordBatch;\n+import org.apache.kafka.common.record.SimpleRecord;\n+import org.apache.kafka.common.record.Record;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.jupiter.api.Test;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+public final class FileRawSnapshotTest {\n+    @Test\n+    public void testWritingSnapshot() throws IOException {\n+        Path tempDir = TestUtils.tempDirectory().toPath();\n+        OffsetAndEpoch offsetAndEpoch = new OffsetAndEpoch(10L, 3);\n+        int bufferSize = 256;\n+        int batches = 10;\n+        int expectedSize = 0;\n+\n+        try (FileRawSnapshotWriter snapshot = FileRawSnapshotWriter.create(tempDir, offsetAndEpoch)) {\n+            assertEquals(0, snapshot.sizeInBytes());\n+\n+            MemoryRecords records = buildRecords(new ByteBuffer[] {ByteBuffer.wrap(randomBytes(bufferSize))});", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10f1d5cea71910398979c368842b34ac964646bb"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYwOTE3Nw==", "bodyText": "It might be useful to review the history behind Utils.atomicMoveWithFallback. It's not clear to me why this case is different from some of the other situations that it is used.", "url": "https://github.com/apache/kafka/pull/9512#discussion_r534609177", "createdAt": "2020-12-03T01:58:32Z", "author": {"login": "hachikuji"}, "path": "raft/src/main/java/org/apache/kafka/snapshot/FileRawSnapshotWriter.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.snapshot;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardCopyOption;\n+import java.nio.file.StandardOpenOption;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.raft.OffsetAndEpoch;\n+\n+public final class FileRawSnapshotWriter implements RawSnapshotWriter {\n+    private final Path tempSnapshotPath;\n+    private final FileChannel channel;\n+    private final OffsetAndEpoch snapshotId;\n+    private boolean frozen = false;\n+\n+    private FileRawSnapshotWriter(\n+        Path tempSnapshotPath,\n+        FileChannel channel,\n+        OffsetAndEpoch snapshotId\n+    ) {\n+        this.tempSnapshotPath = tempSnapshotPath;\n+        this.channel = channel;\n+        this.snapshotId = snapshotId;\n+    }\n+\n+    @Override\n+    public OffsetAndEpoch snapshotId() {\n+        return snapshotId;\n+    }\n+\n+    @Override\n+    public long sizeInBytes() throws IOException {\n+        return channel.size();\n+    }\n+\n+    @Override\n+    public void append(ByteBuffer buffer) throws IOException {\n+        if (frozen) {\n+            throw new IllegalStateException(\n+                String.format(\"Append not supported. Snapshot is already frozen: id = %s; temp path = %s\", snapshotId, tempSnapshotPath)\n+            );\n+        }\n+\n+        Utils.writeFully(channel, buffer);\n+    }\n+\n+    @Override\n+    public boolean isFrozen() {\n+        return frozen;\n+    }\n+\n+    @Override\n+    public void freeze() throws IOException {\n+        channel.close();\n+        frozen = true;\n+\n+        // Set readonly and ignore the result\n+        if (!tempSnapshotPath.toFile().setReadOnly()) {\n+            throw new IOException(String.format(\"Unable to set file (%s) as read-only\", tempSnapshotPath));\n+        }\n+\n+        Path destination = Snapshots.moveRename(tempSnapshotPath, snapshotId);\n+        Files.move(tempSnapshotPath, destination, StandardCopyOption.ATOMIC_MOVE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10f1d5cea71910398979c368842b34ac964646bb"}, "originalPosition": 82}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa500b9839322903770011696849e44064292bd1", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/aa500b9839322903770011696849e44064292bd1", "committedDate": "2020-12-03T18:31:10Z", "message": "Always attempt to delete the temporary snapshot file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f853c50e61e179daf239a46fd8b77bbae6eeefca", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/f853c50e61e179daf239a46fd8b77bbae6eeefca", "committedDate": "2020-12-07T19:19:59Z", "message": "Use `atomicMoveWithFallback`"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2NDUxMTA0", "url": "https://github.com/apache/kafka/pull/9512#pullrequestreview-546451104", "createdAt": "2020-12-07T19:08:19Z", "commit": {"oid": "aa500b9839322903770011696849e44064292bd1"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxOTowODoxOVrOIA2HLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxOTowODoxOVrOIA2HLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc1NzQ4Nw==", "bodyText": "nit: we cab use covariantCast?", "url": "https://github.com/apache/kafka/pull/9512#discussion_r537757487", "createdAt": "2020-12-07T19:08:19Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/raft/MockLog.java", "diffHunk": "@@ -472,4 +490,106 @@ private EpochStartOffset(int epoch, long startOffset) {\n         }\n     }\n \n+    final class MockRawSnapshotWriter implements RawSnapshotWriter {\n+        private final OffsetAndEpoch snapshotId;\n+        private ByteBufferOutputStream data;\n+        private boolean frozen;\n+\n+        public MockRawSnapshotWriter(OffsetAndEpoch snapshotId) {\n+            this.snapshotId = snapshotId;\n+            this.data = new ByteBufferOutputStream(0);\n+            this.frozen = false;\n+        }\n+\n+        @Override\n+        public OffsetAndEpoch snapshotId() {\n+            return snapshotId;\n+        }\n+\n+        @Override\n+        public long sizeInBytes() {\n+            return data.position();\n+        }\n+\n+        @Override\n+        public void append(ByteBuffer buffer) {\n+            if (frozen) {\n+                throw new RuntimeException(\"Snapshot is already frozen \" + snapshotId);\n+            }\n+\n+            data.write(buffer);\n+        }\n+\n+        @Override\n+        public boolean isFrozen() {\n+            return frozen;\n+        }\n+\n+        @Override\n+        public void freeze() {\n+            if (frozen) {\n+                throw new RuntimeException(\"Snapshot is already frozen \" + snapshotId);\n+            }\n+\n+            frozen = true;\n+            ByteBuffer buffer = data.buffer();\n+            buffer.flip();\n+\n+            snapshots.putIfAbsent(snapshotId, new MockRawSnapshotReader(snapshotId, buffer));\n+        }\n+\n+        @Override\n+        public void close() {}\n+    }\n+\n+    final static class MockRawSnapshotReader implements RawSnapshotReader {\n+        private final OffsetAndEpoch snapshotId;\n+        private final MemoryRecords data;\n+\n+        MockRawSnapshotReader(OffsetAndEpoch snapshotId, ByteBuffer data) {\n+            this.snapshotId = snapshotId;\n+            this.data = MemoryRecords.readableRecords(data);\n+        }\n+\n+        @Override\n+        public OffsetAndEpoch snapshotId() {\n+            return snapshotId;\n+        }\n+\n+        @Override\n+        public long sizeInBytes() {\n+            return data.sizeInBytes();\n+        }\n+\n+        @Override\n+        public Iterator<RecordBatch> iterator() {\n+            return new Iterator<RecordBatch>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa500b9839322903770011696849e44064292bd1"}, "originalPosition": 128}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2893, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}