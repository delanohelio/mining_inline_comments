{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU0MjE2MTgx", "number": 9047, "title": "KAFKA-9274: Remove `retries` for global task", "bodyText": "part of KIP-572\nremoved the usage of retries in GlobalStateManger\ninstead of retries the new task.timeout.ms config is used\n\nSecond PR for KIP-572 (cf. #8864)\nCall for review @vvcephei\nDocs Screenshots:\nMain upgrade guide:\n\nStreams upgrade guide:\n\nSnippet from StreamConfig:", "createdAt": "2020-07-21T07:21:50Z", "url": "https://github.com/apache/kafka/pull/9047", "merged": true, "mergeCommit": {"oid": "b351493543b7e26aa345df3b568d0dc08a8c8d91"}, "closed": true, "closedAt": "2020-08-05T21:14:19Z", "author": {"login": "mjsax"}, "timelineItems": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc3BAd-AFqTQ1MjE5MDAzMQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc8A12_AFqTQ2MTkyMjAwMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyMTkwMDMx", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452190031", "createdAt": "2020-07-21T07:22:19Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwNzoyMjoxOVrOG0rV2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwNzoyMjoxOVrOG0rV2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg4OTI0Mg==", "bodyText": "This is just added until the first PR is merged to unblock the work on this PR.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r457889242", "createdAt": "2020-07-21T07:22:19Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -523,6 +524,8 @@\n     public static final String STATE_DIR_CONFIG = \"state.dir\";\n     private static final String STATE_DIR_DOC = \"Directory location for state store. This path must be unique for each streams instance sharing the same underlying filesystem.\";\n \n+    public static final String TASK_TIMEOUT_MS_CONFIG = \"task.timeout.ms\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyNTU3MzA4", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452557308", "createdAt": "2020-07-21T15:09:50Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTowOTo1MFrOG08qPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNToxNDo0OFrOG084OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE3Mjk5MA==", "bodyText": "Minor note: it's confusing to track down exceptions when they are re-thrown like this, because the stacktrace would only reference L223. Even though there is a small performance penalty, it's better for maintainability to always throw a new exception like new RetryableException(timeoutException).\nIn this particular case, it may be more appropriate just to remove the try-catch and add a throws declaration. There are two things that make me think this:\n\nThe log message here says, \"will retry\", but this method can have no idea whether or not it'll be retried\nThe calling method has a comment that says this method logs the error, which is also an assumption that may not survive refactoring\n\nIt seems like we can resolve all three of these maintenence problems by just moving the log message to the caller.\nThis feedback also applies elsewhere.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458172990", "createdAt": "2020-07-21T15:09:50Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -184,32 +217,21 @@ public void registerStore(final StateStore store, final StateRestoreCallback sta\n \n         log.info(\"Restoring state for global store {}\", store.name());\n         final List<TopicPartition> topicPartitions = topicPartitionsForStore(store);\n-        Map<TopicPartition, Long> highWatermarks = null;\n \n-        int attempts = 0;\n-        while (highWatermarks == null) {\n-            try {\n-                highWatermarks = globalConsumer.endOffsets(topicPartitions);\n-            } catch (final TimeoutException retryableException) {\n-                if (++attempts > retries) {\n-                    log.error(\"Failed to get end offsets for topic partitions of global store {} after {} retry attempts. \" +\n-                        \"You can increase the number of retries via configuration parameter `retries`.\",\n-                        store.name(),\n-                        retries,\n-                        retryableException);\n-                    throw new StreamsException(String.format(\"Failed to get end offsets for topic partitions of global store %s after %d retry attempts. \" +\n-                            \"You can increase the number of retries via configuration parameter `retries`.\", store.name(), retries),\n-                        retryableException);\n-                }\n-                log.debug(\"Failed to get end offsets for partitions {}, backing off for {} ms to retry (attempt {} of {})\",\n-                    topicPartitions,\n-                    retryBackoffMs,\n-                    attempts,\n-                    retries,\n-                    retryableException);\n-                Utils.sleep(retryBackoffMs);\n-            }\n+        final Map<TopicPartition, Long> highWatermarks;\n+        try {\n+            highWatermarks = globalConsumer.endOffsets(topicPartitions);\n+        } catch (final TimeoutException retryableException) {\n+            log.debug(\n+                \"Failed to get end offsets for partitions {}. The broker may be transiently unavailable at the moment. Will retry.\",\n+                topicPartitions,\n+                retryableException\n+            );\n+\n+            // handled in `GlobalStateMangerImpl#initialize()`\n+            throw retryableException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE3MzY1MQ==", "bodyText": "The varargs version of debug does not take a cause at the end. This exception will not be logged. You have to use the version that only takes (String, Exception).", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458173651", "createdAt": "2020-07-21T15:10:42Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -184,32 +217,21 @@ public void registerStore(final StateStore store, final StateRestoreCallback sta\n \n         log.info(\"Restoring state for global store {}\", store.name());\n         final List<TopicPartition> topicPartitions = topicPartitionsForStore(store);\n-        Map<TopicPartition, Long> highWatermarks = null;\n \n-        int attempts = 0;\n-        while (highWatermarks == null) {\n-            try {\n-                highWatermarks = globalConsumer.endOffsets(topicPartitions);\n-            } catch (final TimeoutException retryableException) {\n-                if (++attempts > retries) {\n-                    log.error(\"Failed to get end offsets for topic partitions of global store {} after {} retry attempts. \" +\n-                        \"You can increase the number of retries via configuration parameter `retries`.\",\n-                        store.name(),\n-                        retries,\n-                        retryableException);\n-                    throw new StreamsException(String.format(\"Failed to get end offsets for topic partitions of global store %s after %d retry attempts. \" +\n-                            \"You can increase the number of retries via configuration parameter `retries`.\", store.name(), retries),\n-                        retryableException);\n-                }\n-                log.debug(\"Failed to get end offsets for partitions {}, backing off for {} ms to retry (attempt {} of {})\",\n-                    topicPartitions,\n-                    retryBackoffMs,\n-                    attempts,\n-                    retries,\n-                    retryableException);\n-                Utils.sleep(retryBackoffMs);\n-            }\n+        final Map<TopicPartition, Long> highWatermarks;\n+        try {\n+            highWatermarks = globalConsumer.endOffsets(topicPartitions);\n+        } catch (final TimeoutException retryableException) {\n+            log.debug(\n+                \"Failed to get end offsets for partitions {}. The broker may be transiently unavailable at the moment. Will retry.\",\n+                topicPartitions,\n+                retryableException", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE3NjU2OA==", "bodyText": "Double-brace initialization is an anti-pattern. It would be preferable to use mkProperties.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458176568", "createdAt": "2020-07-21T15:14:48Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -613,69 +617,262 @@ public boolean lockGlobalState() throws IOException {\n     }\n \n     @Test\n-    public void shouldRetryWhenEndOffsetsThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldNotRetryWhenEndOffsetsThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<org.apache.kafka.common.TopicPartition> partitions) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        consumer.updatePartitions(t1.topic(), Collections.singletonList(new PartitionInfo(t1.topic(), t1.partition(), null, null, null)));\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n     }\n \n     @Test\n-    public void shouldRetryWhenPartitionsForThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldRetryAtLeastOnceWhenEndOffsetsThrowsTimeoutException() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized List<PartitionInfo> partitionsFor(final String topic) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        consumer.updatePartitions(t1.topic(), Collections.singletonList(new PartitionInfo(t1.topic(), t1.partition(), null, null, null)));\n+        consumer.updatePartitions(t2.topic(), Collections.singletonList(new PartitionInfo(t2.topic(), t2.partition(), null, null, null)));\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 2);\n+    }\n+\n+    @Test\n+    public void shouldRetryWhenEndOffsetsThrowsTimeoutExceptionUntilTaskTimeoutExpired() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        consumer.updatePartitions(t1.topic(), Collections.singletonList(new PartitionInfo(t1.topic(), t1.partition(), null, null, null)));\n+        consumer.updatePartitions(t2.topic(), Collections.singletonList(new PartitionInfo(t2.topic(), t2.partition(), null, null, null)));\n+        consumer.updatePartitions(t3.topic(), Collections.singletonList(new PartitionInfo(t3.topic(), t3.partition(), null, null, null)));\n+        consumer.updatePartitions(t4.topic(), Collections.singletonList(new PartitionInfo(t4.topic(), t4.partition(), null, null, null)));\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 207}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM1MDY5", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452935069", "createdAt": "2020-07-22T01:31:08Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMTowOVrOG1PeTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMTowOVrOG1PeTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTIzMQ==", "bodyText": "Added a couple of side fixed for the docs.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481231", "createdAt": "2020-07-22T01:31:09Z", "author": {"login": "mjsax"}, "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -203,7 +203,7 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n           </tr>\n           <tr class=\"row-even\"><td>commit.interval.ms</td>\n             <td>Low</td>\n-            <td colspan=\"2\">The frequency with which to save the position (offsets in source topics) of tasks.</td>\n+            <td colspan=\"2\">The frequency in milliseconds with which to save the position (offsets in source topics) of tasks.</td>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM1MTU0", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452935154", "createdAt": "2020-07-22T01:31:28Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMToyOFrOG1Peow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMToyOFrOG1Peow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTMxNQ==", "bodyText": "Forgot to remove retries in the first PR.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481315", "createdAt": "2020-07-22T01:31:28Z", "author": {"login": "mjsax"}, "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -308,15 +308,10 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n             <td colspan=\"2\">The replication factor for changelog topics and repartition topics created by the application.</td>\n             <td>1</td>\n           </tr>\n-          <tr class=\"row-odd\"><td>retries</td>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM1MjA2", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452935206", "createdAt": "2020-07-22T01:31:40Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMTo0MFrOG1Pe5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMTo0MFrOG1Pe5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTM4MQ==", "bodyText": "Forgot to add the new config in the first PR", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481381", "createdAt": "2020-07-22T01:31:40Z", "author": {"login": "mjsax"}, "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -326,13 +321,18 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n           <tr class=\"row-even\"><td>state.cleanup.delay.ms</td>\n             <td>Low</td>\n             <td colspan=\"2\">The amount of time in milliseconds to wait before deleting state when a partition has migrated.</td>\n-            <td>600000 milliseconds</td>\n+            <td>600000 milliseconds (10 minutes)</td>\n           </tr>\n           <tr class=\"row-odd\"><td>state.dir</td>\n             <td>High</td>\n             <td colspan=\"2\">Directory location for state stores.</td>\n             <td><code class=\"docutils literal\"><span class=\"pre\">/tmp/kafka-streams</span></code></td>\n           </tr>\n+          <tr class=\"row-odd\"><td>task.timeout.ms</td>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 69}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM1MzQ3", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452935347", "createdAt": "2020-07-22T01:32:11Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMjoxMVrOG1PfcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMjoxMVrOG1PfcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTUyMQ==", "bodyText": "Fixed some typos. And added reference to max.block.ms config", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481521", "createdAt": "2020-07-22T01:32:11Z", "author": {"login": "mjsax"}, "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -95,11 +95,12 @@ <h3><a id=\"streams_api_changes_270\" href=\"#streams_api_changes_270\">Streams API\n     </p>\n \n     <p>\n-        The configuration parameter <code>retries</code> is deprecated in favor of a the new parameter <code>task.timeout.ms</code>.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM1NDg5", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452935489", "createdAt": "2020-07-22T01:32:36Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMjozNlrOG1Pf2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMjozNlrOG1Pf2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTYyNg==", "bodyText": "As above.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481626", "createdAt": "2020-07-22T01:32:36Z", "author": {"login": "mjsax"}, "path": "docs/upgrade.html", "diffHunk": "@@ -23,8 +23,8 @@ <h5><a id=\"upgrade_270_notable\" href=\"#upgrade_270_notable\">Notable changes in 2\n <ul>\n     <li>The configuration parameter <code>retries</code> is deprecated for the producer, admin, and Kafka Streams clients\n         via <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-572%3A+Improve+timeouts+and+retries+in+Kafka+Streams\">KIP-572</a>.\n-        You should use the producer's <code>delivery.timeout.ms</code>, admin's <code>default.api.timeout.ms</code>, and\n-        Kafka Streams' new <code>task.timeout.ms</code> parameters instead.\n+        You should use the producer's <code>delivery.timeout.ms</code> and <code>max.block.ms</code>, admin's", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM1NTMw", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452935530", "createdAt": "2020-07-22T01:32:47Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMjo0N1rOG1PgAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMjo0N1rOG1PgAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTY2NQ==", "bodyText": "Same fixes as in the docs.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481665", "createdAt": "2020-07-22T01:32:47Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -357,7 +357,7 @@\n     /** {@code commit.interval.ms} */\n     @SuppressWarnings(\"WeakerAccess\")\n     public static final String COMMIT_INTERVAL_MS_CONFIG = \"commit.interval.ms\";\n-    private static final String COMMIT_INTERVAL_MS_DOC = \"The frequency with which to save the position of the processor.\" +\n+    private static final String COMMIT_INTERVAL_MS_DOC = \"The frequency in milliseconds with which to save the position of the processor.\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM1NjQ2", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452935646", "createdAt": "2020-07-22T01:33:12Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMzoxMlrOG1Pggg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozMzoxMlrOG1Pggg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTc5NA==", "bodyText": "Added new exception type as requested.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481794", "createdAt": "2020-07-22T01:33:12Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/errors/RetryableErrorException.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.errors;\n+\n+public class RetryableErrorException extends StreamsException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM1OTY4", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452935968", "createdAt": "2020-07-22T01:34:16Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNDoxNlrOG1PhfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNDoxNlrOG1PhfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MjA0NQ==", "bodyText": "This PR fixed 3 TODOs form the first PR. (The other two are in the test -- also added a comment to the original PR that links to this PR as reference.)", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458482045", "createdAt": "2020-07-22T01:34:16Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -58,30 +60,33 @@\n  * of Global State Stores. There is only ever 1 instance of this class per Application Instance.\n  */\n public class GlobalStateManagerImpl implements GlobalStateManager {\n+    private final static long NO_DEADLINE = -1L;\n+\n     private final Logger log;\n+    private final Time time;\n     private final Consumer<byte[], byte[]> globalConsumer;\n     private final File baseDir;\n     private final StateDirectory stateDirectory;\n     private final Set<String> globalStoreNames = new HashSet<>();\n     private final FixedOrderMap<String, Optional<StateStore>> globalStores = new FixedOrderMap<>();\n     private final StateRestoreListener stateRestoreListener;\n     private InternalProcessorContext globalProcessorContext;\n-    private final int retries;\n-    private final long retryBackoffMs;\n     private final Duration pollTime;\n+    private final long taskTimeoutMs;\n     private final Set<String> globalNonPersistentStoresTopics = new HashSet<>();\n     private final OffsetCheckpoint checkpointFile;\n     private final Map<TopicPartition, Long> checkpointFileCache;\n     private final Map<String, String> storeToChangelogTopic;\n     private final List<StateStore> globalStateStores;\n \n-    @SuppressWarnings(\"deprecation\") // TODO: remove in follow up PR when `RETRIES` is removed", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM2MzI3", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452936327", "createdAt": "2020-07-22T01:35:21Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNToyMVrOG1Pi6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNToyMVrOG1Pi6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MjQwOA==", "bodyText": "Second TODO", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458482408", "createdAt": "2020-07-22T01:35:21Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -612,72 +617,521 @@ public boolean lockGlobalState() throws IOException {\n         }\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM2Nzk4", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452936798", "createdAt": "2020-07-22T01:36:54Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNjo1NFrOG1Pkcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNjo1NFrOG1Pkcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MjgwMw==", "bodyText": "If we rethrow, we get rid of the RetryableErrorException and pass in the original root cause, ie, the TimeoutException.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458482803", "createdAt": "2020-07-22T01:36:54Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -131,11 +135,40 @@ public void setGlobalProcessorContext(final InternalProcessorContext globalProce\n         }\n \n         final Set<String> changelogTopics = new HashSet<>();\n-        for (final StateStore stateStore : globalStateStores) {\n+\n+        long deadlineMs = NO_DEADLINE;\n+        final List<StateStore> storesToInitialize = new LinkedList<>(globalStateStores);\n+\n+        while (!storesToInitialize.isEmpty()) {\n+            // we remove and add back on failure to round-robin through all stores\n+            final StateStore stateStore = storesToInitialize.remove(0);\n             globalStoreNames.add(stateStore.name());\n             final String sourceTopic = storeToChangelogTopic.get(stateStore.name());\n             changelogTopics.add(sourceTopic);\n-            stateStore.init(globalProcessorContext, stateStore);\n+\n+            try {\n+                stateStore.init(globalProcessorContext, stateStore);\n+                deadlineMs = NO_DEADLINE;\n+            } catch (final RetryableErrorException retryableException) {\n+                if (taskTimeoutMs == 0L) {\n+                    throw new StreamsException(retryableException.getCause());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 91}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM2ODU2", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452936856", "createdAt": "2020-07-22T01:37:05Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNzowNVrOG1Pkng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNzowNVrOG1Pkng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4Mjg0Ng==", "bodyText": "Third TODO", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458482846", "createdAt": "2020-07-22T01:37:05Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -612,72 +617,521 @@ public boolean lockGlobalState() throws IOException {\n         }\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenEndOffsetsThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldNotRetryWhenEndOffsetsThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<org.apache.kafka.common.TopicPartition> partitions) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 104}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM3MDU4", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452937058", "createdAt": "2020-07-22T01:37:46Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNzo0NlrOG1PlTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozNzo0NlrOG1PlTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MzAyMw==", "bodyText": "This test is new (also added it for partitionFor() case).", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458483023", "createdAt": "2020-07-22T01:37:46Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -612,72 +617,521 @@ public boolean lockGlobalState() throws IOException {\n         }\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenEndOffsetsThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldNotRetryWhenEndOffsetsThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<org.apache.kafka.common.TopicPartition> partitions) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenPartitionsForThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldRetryAtLeastOnceWhenEndOffsetsThrowsTimeoutException() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized List<PartitionInfo> partitionsFor(final String topic) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 2);\n+    }\n+\n+    @Test\n+    public void shouldRetryWhenEndOffsetsThrowsTimeoutExceptionUntilTaskTimeoutExpired() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1000L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 1100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 12);\n+    }\n+\n+    @Test\n+    public void shouldNotFailOnSlowProgressWhenEndOffsetsThrowsTimeoutException() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 208}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyOTM3MzY1", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-452937365", "createdAt": "2020-07-22T01:38:42Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozODo0MlrOG1PmOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMTozODo0MlrOG1PmOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MzI1OQ==", "bodyText": "Replicated the tests from above (endOffset and partitionFor) for the position call.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458483259", "createdAt": "2020-07-22T01:38:42Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -612,72 +617,521 @@ public boolean lockGlobalState() throws IOException {\n         }\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenEndOffsetsThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldNotRetryWhenEndOffsetsThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<org.apache.kafka.common.TopicPartition> partitions) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenPartitionsForThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldRetryAtLeastOnceWhenEndOffsetsThrowsTimeoutException() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized List<PartitionInfo> partitionsFor(final String topic) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 2);\n+    }\n+\n+    @Test\n+    public void shouldRetryWhenEndOffsetsThrowsTimeoutExceptionUntilTaskTimeoutExpired() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1000L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 1100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 12);\n+    }\n+\n+    @Test\n+    public void shouldNotFailOnSlowProgressWhenEndOffsetsThrowsTimeoutException() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(1L);\n+                if (numberOfCalls.incrementAndGet() % 3 == 0) {\n+                    return super.endOffsets(partitions);\n+                }\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+\n+            @Override\n+            public synchronized long position(final TopicPartition partition) {\n+                return numberOfCalls.incrementAndGet();\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        stateManager.initialize();\n+    }\n+\n+    @Test\n+    public void shouldNotRetryWhenPartitionsForThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public List<PartitionInfo> partitionsFor(final String topic) {\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n+    }\n+\n+    @Test\n+    public void shouldRetryAtLeastOnceWhenPartitionsForThrowsTimeoutException() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public List<PartitionInfo> partitionsFor(final String topic) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 2);\n+    }\n+\n+    @Test\n+    public void shouldRetryWhenPartitionsForThrowsTimeoutExceptionUntilTaskTimeoutExpires() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public List<PartitionInfo> partitionsFor(final String topic) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1000L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 1100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 12);\n+    }\n+\n+    @Test\n+    public void shouldNotFailOnSlowProgressWhenPartitionForThrowsTimeoutException() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public List<PartitionInfo> partitionsFor(final String topic) {\n+                time.sleep(1L);\n+                if (numberOfCalls.incrementAndGet() % 3 == 0) {\n+                    return super.partitionsFor(topic);\n+                }\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+\n+            @Override\n+            public synchronized long position(final TopicPartition partition) {\n+                return numberOfCalls.incrementAndGet();\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        stateManager.initialize();\n+    }\n+\n+    @Test\n+    public void shouldNotRetryWhenPositionThrowsTimeoutExceptionAndTaskTimeoutIsZero() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 426}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNTM4Nzk2", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-453538796", "createdAt": "2020-07-22T17:35:21Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNzozNToyMVrOG1tDJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNzozNToyMVrOG1tDJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk2NTc5OQ==", "bodyText": "@vvcephei I actually had a follow up thought: given that we fetch data for a single partition only, should we trigger a timeout within this loop if records is empty (ie, poll() did not return anything)? Otherwise, this restore loop might \"hang\" forever if we lose the connection to the broker -- IMHO, task.timeout.msshould cover this case? Otherwise, we block on startup as the initial global store loading would never finish and we don't even start the actualStreamThreads`.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458965799", "createdAt": "2020-07-22T17:35:21Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately\n+\n+                        // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                        throw new IllegalStateException(error);\n+                    }\n+\n                     stateRestoreAdapter.restoreBatch(restoreRecords);\n                     stateRestoreListener.onBatchRestored(topicPartition, storeName, offset, restoreRecords.size());\n                     restoreCount += restoreRecords.size();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 245}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0NDg5OTMw", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-454489930", "createdAt": "2020-07-23T20:57:45Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QyMDo1Nzo0NVrOG2bUUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QyMjoyOTowNlrOG2duYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTcyMzg1OQ==", "bodyText": "Why not just preserve the whole story of what happened, like throw new StreamsException(\"Couldn't retry because timeout is set to zero\", retryableException)?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459723859", "createdAt": "2020-07-23T20:57:45Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -131,11 +135,40 @@ public void setGlobalProcessorContext(final InternalProcessorContext globalProce\n         }\n \n         final Set<String> changelogTopics = new HashSet<>();\n-        for (final StateStore stateStore : globalStateStores) {\n+\n+        long deadlineMs = NO_DEADLINE;\n+        final List<StateStore> storesToInitialize = new LinkedList<>(globalStateStores);\n+\n+        while (!storesToInitialize.isEmpty()) {\n+            // we remove and add back on failure to round-robin through all stores\n+            final StateStore stateStore = storesToInitialize.remove(0);\n             globalStoreNames.add(stateStore.name());\n             final String sourceTopic = storeToChangelogTopic.get(stateStore.name());\n             changelogTopics.add(sourceTopic);\n-            stateStore.init(globalProcessorContext, stateStore);\n+\n+            try {\n+                stateStore.init(globalProcessorContext, stateStore);\n+                deadlineMs = NO_DEADLINE;\n+            } catch (final RetryableErrorException retryableException) {\n+                if (taskTimeoutMs == 0L) {\n+                    throw new StreamsException(retryableException.getCause());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MjgwMw=="}, "originalCommit": null, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1ODA5MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            log.debug(retryableException.getMessage() + \" Will retry. Remaining time in milliseconds: {}\", deadlineMs - currentWallClockMs);\n          \n          \n            \n                            log.debug(String.format(\"Got an exception in store.init(). Will retry. Remaining time in milliseconds: %d\",  deadlineMs - currentWallClockMs), retryableException);\n          \n      \n    \n    \n  \n\nSorry, my prior feedback was ambiguous. This is what I meant.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459758091", "createdAt": "2020-07-23T22:15:01Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -131,11 +135,40 @@ public void setGlobalProcessorContext(final InternalProcessorContext globalProce\n         }\n \n         final Set<String> changelogTopics = new HashSet<>();\n-        for (final StateStore stateStore : globalStateStores) {\n+\n+        long deadlineMs = NO_DEADLINE;\n+        final List<StateStore> storesToInitialize = new LinkedList<>(globalStateStores);\n+\n+        while (!storesToInitialize.isEmpty()) {\n+            // we remove and add back on failure to round-robin through all stores\n+            final StateStore stateStore = storesToInitialize.remove(0);\n             globalStoreNames.add(stateStore.name());\n             final String sourceTopic = storeToChangelogTopic.get(stateStore.name());\n             changelogTopics.add(sourceTopic);\n-            stateStore.init(globalProcessorContext, stateStore);\n+\n+            try {\n+                stateStore.init(globalProcessorContext, stateStore);\n+                deadlineMs = NO_DEADLINE;\n+            } catch (final RetryableErrorException retryableException) {\n+                if (taskTimeoutMs == 0L) {\n+                    throw new StreamsException(retryableException.getCause());\n+                }\n+\n+                storesToInitialize.add(stateStore);\n+\n+                final long currentWallClockMs = time.milliseconds();\n+                if (deadlineMs == NO_DEADLINE) {\n+                    final long newDeadlineMs = currentWallClockMs + taskTimeoutMs;\n+                    deadlineMs = newDeadlineMs < 0L ? Long.MAX_VALUE : newDeadlineMs;\n+                } else if (currentWallClockMs > deadlineMs) {\n+                    throw new TimeoutException(String.format(\n+                        \"Global task did not make progress to restore state within %d ms. Adjust `task.timeout.ms` if needed.\",\n+                        currentWallClockMs - deadlineMs + taskTimeoutMs\n+                    ));\n+                }\n+\n+                log.debug(retryableException.getMessage() + \" Will retry. Remaining time in milliseconds: {}\", deadlineMs - currentWallClockMs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg==", "bodyText": "I think this makes sense, but it seems to make some assumptions about the internal implementation of the consumer that doesn't seem necessary here. Is it important to assert that the consumer can't possibly get a timeout exception here?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459762036", "createdAt": "2020-07-23T22:25:39Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 237}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjI3OQ==", "bodyText": "I can't comment above, but can the poll call itself throw a timeout exception? Or does it always just return no results in that case?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459762279", "createdAt": "2020-07-23T22:26:14Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MzI5Ng==", "bodyText": "Huh, interesting thought. Just to be clear, it looks like it would already block forever in this case today, right?\nYeah, it does seem like we should implement a similar non-progress timeout for this loop in that case.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459763296", "createdAt": "2020-07-23T22:29:06Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately\n+\n+                        // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                        throw new IllegalStateException(error);\n+                    }\n+\n                     stateRestoreAdapter.restoreBatch(restoreRecords);\n                     stateRestoreListener.onBatchRestored(topicPartition, storeName, offset, restoreRecords.size());\n                     restoreCount += restoreRecords.size();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk2NTc5OQ=="}, "originalCommit": null, "originalPosition": 245}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0Njc5NDE2", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-454679416", "createdAt": "2020-07-24T07:22:23Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwNzoyMjoyNFrOG2lfqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwNzoyMjoyNFrOG2lfqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MDYwMg==", "bodyText": "Moved this class into ClientUtils.java", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459890602", "createdAt": "2020-07-24T07:22:24Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/internals/QuietStreamsConfig.java", "diffHunk": "@@ -1,33 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License. You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.kafka.streams.internals;\n-\n-import org.apache.kafka.streams.StreamsConfig;\n-\n-import java.util.Map;\n-\n-/**\n- * A {@link StreamsConfig} that does not log its configuration on construction.\n- *\n- * This producer cleaner output for unit tests using the {@code test-utils},\n- * since logging the config is not really valuable in this context.\n- */\n-public class QuietStreamsConfig extends StreamsConfig {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0NjgwODUy", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-454680852", "createdAt": "2020-07-24T07:25:18Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwNzoyNToxOFrOG2lkMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwNzoyNToxOFrOG2lkMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MTc2Mg==", "bodyText": "Some side improvement: if we seek base on the checkpoint, there is no reason to call position() because we know what our offset is. -- Only if we seekToBeginning() we need to get the current offset from the consumer itself (instead of position() we could also call beginningOffsets but position it the easer to use API.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459891762", "createdAt": "2020-07-24T07:25:18Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -275,31 +259,70 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 199}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0NjgxODM1", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-454681835", "createdAt": "2020-07-24T07:27:22Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwNzoyNzoyMlrOG2lnQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwNzoyNzoyMlrOG2lnQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA==", "bodyText": "For poll(), even if retrying is disabled, we need to retry to give a fetch request (with default request timeout of 30 seconds but only a default pollTime of 100ms) a fair change to actually return.\nAt least I believe this makes sense. Also \\cc @guozhangwang", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459892544", "createdAt": "2020-07-24T07:27:22Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -275,31 +259,70 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;\n             } else {\n                 globalConsumer.seekToBeginning(Collections.singletonList(topicPartition));\n+                final AtomicLong position = new AtomicLong();\n+                retryUntilSuccessOrThrowOnTaskTimeout(\n+                    () -> position.set(globalConsumer.position(topicPartition)),\n+                    String.format(\n+                        \"Failed to get position for partition %s. The broker may be transiently unavailable at the moment.\",\n+                        topicPartition\n+                    )\n+                );\n+                offset = position.get();\n             }\n \n-            long offset = globalConsumer.position(topicPartition);\n             final Long highWatermark = highWatermarks.get(topicPartition);\n             final RecordBatchingStateRestoreCallback stateRestoreAdapter =\n                 StateRestoreCallbackAdapter.adapt(stateRestoreCallback);\n \n             stateRestoreListener.onRestoreStart(topicPartition, storeName, offset, highWatermark);\n             long restoreCount = 0L;\n \n+            long deadlineMs = NO_DEADLINE;\n             while (offset < highWatermark) {\n                 try {\n                     final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(pollTime);\n+                    if (records.isEmpty()) {\n+                        if (taskTimeoutMs == 0L) {\n+                            deadlineMs = maybeUpdateDeadlineOrThrow(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 227}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1MDMxNjY3", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-455031667", "createdAt": "2020-07-24T16:39:43Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNjozOTo0M1rOG22R4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxOToxMDo1OFrOG26xwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2NTYwMQ==", "bodyText": "nit: for a doc clean-up, it is helpful to include a screenshot of updated paragraph. The changes starting at L331 should be suffice.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460165601", "createdAt": "2020-07-24T16:39:43Z", "author": {"login": "abbccdda"}, "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -326,13 +321,18 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n           <tr class=\"row-even\"><td>state.cleanup.delay.ms</td>\n             <td>Low</td>\n             <td colspan=\"2\">The amount of time in milliseconds to wait before deleting state when a partition has migrated.</td>\n-            <td>600000 milliseconds</td>\n+            <td>600000 milliseconds (10 minutes)</td>\n           </tr>\n           <tr class=\"row-odd\"><td>state.dir</td>\n             <td>High</td>\n             <td colspan=\"2\">Directory location for state stores.</td>\n             <td><code class=\"docutils literal\"><span class=\"pre\">/tmp/kafka-streams</span></code></td>\n           </tr>\n+          <tr class=\"row-odd\"><td>task.timeout.ms</td>\n+            <td>Medium</td>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2NzkzNA==", "bodyText": "What's the purpose for this move?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460167934", "createdAt": "2020-07-24T16:43:51Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/internals/QuietStreamsConfig.java", "diffHunk": "@@ -1,33 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License. You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.kafka.streams.internals;\n-\n-import org.apache.kafka.streams.StreamsConfig;\n-\n-import java.util.Map;\n-\n-/**\n- * A {@link StreamsConfig} that does not log its configuration on construction.\n- *\n- * This producer cleaner output for unit tests using the {@code test-utils},\n- * since logging the config is not really valuable in this context.\n- */\n-public class QuietStreamsConfig extends StreamsConfig {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MDYwMg=="}, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2OTcxNg==", "bodyText": "retriableException to be consistent with the defined exception type in AK.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460169716", "createdAt": "2020-07-24T16:47:07Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -318,6 +341,72 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n         }\n     }\n \n+    private void retryUntilSuccessOrThrowOnTaskTimeout(final Runnable runnable,\n+                                                       final String errorMessage) {\n+        long deadlineMs = NO_DEADLINE;\n+\n+        do {\n+            try {\n+                runnable.run();\n+                return;\n+            } catch (final TimeoutException retryableException) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 276}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE3MDg2OA==", "bodyText": "Should we log warning here instead? At least this is a timeout.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460170868", "createdAt": "2020-07-24T16:49:15Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -318,6 +341,72 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n         }\n     }\n \n+    private void retryUntilSuccessOrThrowOnTaskTimeout(final Runnable runnable,\n+                                                       final String errorMessage) {\n+        long deadlineMs = NO_DEADLINE;\n+\n+        do {\n+            try {\n+                runnable.run();\n+                return;\n+            } catch (final TimeoutException retryableException) {\n+                if (taskTimeoutMs == 0L) {\n+                    throw new StreamsException(\n+                        String.format(\n+                            \"Retrying is disabled. You can enable it by setting `%s` to a value larger than zero.\",\n+                            StreamsConfig.TASK_TIMEOUT_MS_CONFIG\n+                        ),\n+                        retryableException\n+                    );\n+                }\n+\n+                deadlineMs = maybeUpdateDeadlineOrThrow(deadlineMs);\n+\n+                log.debug(errorMessage, retryableException);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzMTYxNw==", "bodyText": "If we do have a valid position from previous position call, do we still need to update the position here again?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460231617", "createdAt": "2020-07-24T18:54:11Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, "originalCommit": null, "originalPosition": 237}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzMTg1MQ==", "bodyText": "We should add some explanation in the illegal state exception for why such timeout is fatal", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460231851", "createdAt": "2020-07-24T18:54:44Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -275,31 +259,70 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;\n             } else {\n                 globalConsumer.seekToBeginning(Collections.singletonList(topicPartition));\n+                final AtomicLong position = new AtomicLong();\n+                retryUntilSuccessOrThrowOnTaskTimeout(\n+                    () -> position.set(globalConsumer.position(topicPartition)),\n+                    String.format(\n+                        \"Failed to get position for partition %s. The broker may be transiently unavailable at the moment.\",\n+                        topicPartition\n+                    )\n+                );\n+                offset = position.get();\n             }\n \n-            long offset = globalConsumer.position(topicPartition);\n             final Long highWatermark = highWatermarks.get(topicPartition);\n             final RecordBatchingStateRestoreCallback stateRestoreAdapter =\n                 StateRestoreCallbackAdapter.adapt(stateRestoreCallback);\n \n             stateRestoreListener.onRestoreStart(topicPartition, storeName, offset, highWatermark);\n             long restoreCount = 0L;\n \n+            long deadlineMs = NO_DEADLINE;\n             while (offset < highWatermark) {\n                 try {\n                     final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(pollTime);\n+                    if (records.isEmpty()) {\n+                        if (taskTimeoutMs == 0L) {\n+                            deadlineMs = maybeUpdateDeadlineOrThrow(\n+                                deadlineMs,\n+                                requestTimeoutMs,\n+                                new StreamsException(String.format(\n+                                    \"Global task did not make progress to restore state. Retrying is disabled. You can enable it by setting `%s` to a value larger than zero.\",\n+                                    StreamsConfig.TASK_TIMEOUT_MS_CONFIG\n+                                ))\n+                            );\n+                        } else {\n+                            deadlineMs = maybeUpdateDeadlineOrThrow(deadlineMs);\n+                        }\n+\n+                        continue;\n+                    }\n+                    deadlineMs = NO_DEADLINE;\n+\n                     final List<ConsumerRecord<byte[], byte[]>> restoreRecords = new ArrayList<>();\n                     for (final ConsumerRecord<byte[], byte[]> record : records.records(topicPartition)) {\n                         if (record.key() != null) {\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately\n+\n+                        // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                        throw new IllegalStateException(error);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 258}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzNTI0Mw==", "bodyText": "Why do we need this?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460235243", "createdAt": "2020-07-24T19:01:56Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/test/NoOpReadOnlyStore.java", "diffHunk": "@@ -78,6 +78,7 @@ public void init(final ProcessorContext context, final StateStore root) {\n             new File(context.stateDir() + File.separator + name).mkdir();\n         }\n         this.initialized = true;\n+        context.register(root, (k, v) -> { });", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzOTI5OA==", "bodyText": "For the above call, was curious why we couldn't seek for all the topic partitions that are missing positions here, instead of doing one by one look-up?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460239298", "createdAt": "2020-07-24T19:10:58Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -275,31 +259,70 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;\n             } else {\n                 globalConsumer.seekToBeginning(Collections.singletonList(topicPartition));\n+                final AtomicLong position = new AtomicLong();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 202}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1MTg1NDUx", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-455185451", "createdAt": "2020-07-24T21:05:55Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMTowNTo1NVrOG29v9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMTo1MDoxN1rOG2-rYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI4Nzk5MQ==", "bodyText": "Man, this is confusing. I think I see what you're getting at, but it seems pretty strange to have to go to all that trouble to extract the consumer config so that we can apply a shorter timeout on each poll, but then loop around until the originally configured client timeout passes.\nCan you explain how the outcome is different than just calling globalConsumer.poll(requestTimeoutMs)?\nIt also seems strange to extract a consumer timeout configuration that specifically does not apply to poll and apply it to poll. This seems like it would violate users' expectations when they set that configuration value.\nWhy wouldn't we instead apply the non-progress timeout (taskTimeoutMs), since it seems like that's exactly what it's for? I.e., it seems like globalConsumer.poll(pollTime + taskTimeoutMs) might be the most appropriate choice here?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460287991", "createdAt": "2020-07-24T21:05:55Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -275,31 +259,70 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;\n             } else {\n                 globalConsumer.seekToBeginning(Collections.singletonList(topicPartition));\n+                final AtomicLong position = new AtomicLong();\n+                retryUntilSuccessOrThrowOnTaskTimeout(\n+                    () -> position.set(globalConsumer.position(topicPartition)),\n+                    String.format(\n+                        \"Failed to get position for partition %s. The broker may be transiently unavailable at the moment.\",\n+                        topicPartition\n+                    )\n+                );\n+                offset = position.get();\n             }\n \n-            long offset = globalConsumer.position(topicPartition);\n             final Long highWatermark = highWatermarks.get(topicPartition);\n             final RecordBatchingStateRestoreCallback stateRestoreAdapter =\n                 StateRestoreCallbackAdapter.adapt(stateRestoreCallback);\n \n             stateRestoreListener.onRestoreStart(topicPartition, storeName, offset, highWatermark);\n             long restoreCount = 0L;\n \n+            long deadlineMs = NO_DEADLINE;\n             while (offset < highWatermark) {\n                 try {\n                     final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(pollTime);\n+                    if (records.isEmpty()) {\n+                        if (taskTimeoutMs == 0L) {\n+                            deadlineMs = maybeUpdateDeadlineOrThrow(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, "originalCommit": null, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5MDU0OA==", "bodyText": "It seems like what we're doing here is syncing our offset variable with the internal position cursor of the client. Although @mjsax is claiming the client never needs to update its position from the consumer group, the position would advance as a consequence of polling records earlier in this loop. Right?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460290548", "createdAt": "2020-07-24T21:12:47Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, "originalCommit": null, "originalPosition": 237}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5MTQ5NQ==", "bodyText": "Hey @mjsax , it sounds like you have an opinion about what would be unexpected internal behavior of the client, based on your knowledge of how it is currently implemented. There doesn't seem to be anything in the contract of the client that says we should rely on this implementation detail, so it seems inappropriate to build in a fatal exception for this case.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460291495", "createdAt": "2020-07-24T21:15:24Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, "originalCommit": null, "originalPosition": 237}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwMDA0MQ==", "bodyText": "No need to change anything, just a note: It's mildly concerning to see side-effecting operations inside a retry loop, since there's no guarantee that failed attempts won't leave any garbage in the system, for example leaving a couple of things in highWatermarks on each attempt. I've read through the code, and I don't think this could actually happen right now, but it could after refactoring.\nSince we're really just retrying simple API calls, something like this would be safer:\n    private <R> R retryUntilSuccessOrThrowOnTaskTimeout(final Supplier<R> supplier,\n                                                        final String errorMessage) {\n        long deadlineMs = NO_DEADLINE;\n\n        do {\n            try {\n                return supplier.get();\n            } catch (final TimeoutException retryableException) {\n                if (taskTimeoutMs == 0L) {\n                    throw new StreamsException(\n                        String.format(\n                            \"Retrying is disabled. You can enable it by setting `%s` to a value larger than zero.\",\n                            StreamsConfig.TASK_TIMEOUT_MS_CONFIG\n                        ),\n                        retryableException\n                    );\n                }\n\n                deadlineMs = maybeUpdateDeadlineOrThrow(deadlineMs);\n\n                log.debug(errorMessage, retryableException);\n            }\n        } while (true);\n    }\nWhich would support:\n        final Map<TopicPartition, Long> highWatermarks = new HashMap<>(\n            retryUntilSuccessOrThrowOnTaskTimeout(\n                () -> globalConsumer.endOffsets(topicPartitions),\n                String.format(\n                    \"Failed to get offsets for partitions %s. The broker may be transiently unavailable at the moment.\",\n                    topicPartitions\n                )\n            )\n        );\nIncidentally, this seems to be exactly the same as:\n        final Map<TopicPartition, Long> highWatermarks = new HashMap<>(\n            globalConsumer.endOffsets(topicPartitions, Duration.ofMillis(taskTimeoutMs))\n        );\nright? That might be preferable because we're not implementing any backoff, whereas retrying internally in the client, it can do exponential backoff, etc. (I think).", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460300041", "createdAt": "2020-07-24T21:40:14Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -185,32 +200,16 @@ public void registerStore(final StateStore store, final StateRestoreCallback sta\n \n         log.info(\"Restoring state for global store {}\", store.name());\n         final List<TopicPartition> topicPartitions = topicPartitionsForStore(store);\n-        Map<TopicPartition, Long> highWatermarks = null;\n \n-        int attempts = 0;\n-        while (highWatermarks == null) {\n-            try {\n-                highWatermarks = globalConsumer.endOffsets(topicPartitions);\n-            } catch (final TimeoutException retryableException) {\n-                if (++attempts > retries) {\n-                    log.error(\"Failed to get end offsets for topic partitions of global store {} after {} retry attempts. \" +\n-                        \"You can increase the number of retries via configuration parameter `retries`.\",\n-                        store.name(),\n-                        retries,\n-                        retryableException);\n-                    throw new StreamsException(String.format(\"Failed to get end offsets for topic partitions of global store %s after %d retry attempts. \" +\n-                            \"You can increase the number of retries via configuration parameter `retries`.\", store.name(), retries),\n-                        retryableException);\n-                }\n-                log.debug(\"Failed to get end offsets for partitions {}, backing off for {} ms to retry (attempt {} of {})\",\n-                    topicPartitions,\n-                    retryBackoffMs,\n-                    attempts,\n-                    retries,\n-                    retryableException);\n-                Utils.sleep(retryBackoffMs);\n-            }\n-        }\n+        final Map<TopicPartition, Long> highWatermarks = new HashMap<>();\n+        retryUntilSuccessOrThrowOnTaskTimeout(\n+            () -> highWatermarks.putAll(globalConsumer.endOffsets(topicPartitions)),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwMzIwMw==", "bodyText": "I guessing because there are other \"quiet\" configs there. On the other hand, the \"quiet Streams config\" isn't really a \"client util\"...", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460303203", "createdAt": "2020-07-24T21:50:17Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/internals/QuietStreamsConfig.java", "diffHunk": "@@ -1,33 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License. You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.kafka.streams.internals;\n-\n-import org.apache.kafka.streams.StreamsConfig;\n-\n-import java.util.Map;\n-\n-/**\n- * A {@link StreamsConfig} that does not log its configuration on construction.\n- *\n- * This producer cleaner output for unit tests using the {@code test-utils},\n- * since logging the config is not really valuable in this context.\n- */\n-public class QuietStreamsConfig extends StreamsConfig {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MDYwMg=="}, "originalCommit": null, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2MDY3MjQz", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-456067243", "createdAt": "2020-07-27T19:21:45Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxOToyMTo0NVrOG3wOQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxOToyMTo0NVrOG3wOQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNDk0NQ==", "bodyText": "It does seem a bit weird here to add in the request timeout. Not sure I follow the reasoning behind that...", "url": "https://github.com/apache/kafka/pull/9047#discussion_r461114945", "createdAt": "2020-07-27T19:21:45Z", "author": {"login": "hachikuji"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -292,21 +278,36 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n \n             while (offset < highWatermark) {\n                 try {\n-                    final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(pollTime);\n+                    final ConsumerRecords<byte[], byte[]> records =\n+                        globalConsumer.poll(pollTimePlusRequestTimeoutPlusTaskTimeout);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 218}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89ae568004fdc04b3d216cec53585fadf55641cc", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/89ae568004fdc04b3d216cec53585fadf55641cc", "committedDate": "2020-07-28T04:05:45Z", "message": "KAFKA-9274: remove `retries` for global tasks\n - part of KIP-572\n - removed the usage of `retries` in `GlobalStateManger`\n - instead of retries the new `task.timeout.ms` config is used"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7cecee3b990da57dd0a57ec5e497d1c8c2550955", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/7cecee3b990da57dd0a57ec5e497d1c8c2550955", "committedDate": "2020-07-28T04:39:47Z", "message": "Rebased\n\nUpdated poll timeout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "7cecee3b990da57dd0a57ec5e497d1c8c2550955", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/7cecee3b990da57dd0a57ec5e497d1c8c2550955", "committedDate": "2020-07-28T04:39:47Z", "message": "Rebased\n\nUpdated poll timeout"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2ODk5MDk2", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-456899096", "createdAt": "2020-07-28T18:28:56Z", "commit": {"oid": "7cecee3b990da57dd0a57ec5e497d1c8c2550955"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxODoyODo1NlrOG4ZNEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwNTozNTowNFrOG4pObw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc4NjM4Ng==", "bodyText": "@mjsax could we do a screenshot to make sure it looks good on the web-page?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r461786386", "createdAt": "2020-07-28T18:28:56Z", "author": {"login": "abbccdda"}, "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -326,13 +321,18 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n           <tr class=\"row-even\"><td>state.cleanup.delay.ms</td>\n             <td>Low</td>\n             <td colspan=\"2\">The amount of time in milliseconds to wait before deleting state when a partition has migrated.</td>\n-            <td>600000 milliseconds</td>\n+            <td>600000 milliseconds (10 minutes)</td>\n           </tr>\n           <tr class=\"row-odd\"><td>state.dir</td>\n             <td>High</td>\n             <td colspan=\"2\">Directory location for state stores.</td>\n             <td><code class=\"docutils literal\"><span class=\"pre\">/tmp/kafka-streams</span></code></td>\n           </tr>\n+          <tr class=\"row-odd\"><td>task.timeout.ms</td>\n+            <td>Medium</td>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2NTYwMQ=="}, "originalCommit": null, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA0NzA2OA==", "bodyText": "Could we just throw here?", "url": "https://github.com/apache/kafka/pull/9047#discussion_r462047068", "createdAt": "2020-07-29T05:28:49Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -274,30 +252,74 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;\n             } else {\n                 globalConsumer.seekToBeginning(Collections.singletonList(topicPartition));\n+                offset = retryUntilSuccessOrThrowOnTaskTimeout(\n+                    () -> globalConsumer.position(topicPartition),\n+                    String.format(\n+                        \"Failed to get position for partition %s. The broker may be transiently unavailable at the moment.\",\n+                        topicPartition\n+                    )\n+                );\n             }\n \n-            long offset = globalConsumer.position(topicPartition);\n             final Long highWatermark = highWatermarks.get(topicPartition);\n             final RecordBatchingStateRestoreCallback stateRestoreAdapter =\n                 StateRestoreCallbackAdapter.adapt(stateRestoreCallback);\n \n             stateRestoreListener.onRestoreStart(topicPartition, storeName, offset, highWatermark);\n             long restoreCount = 0L;\n \n-            while (offset < highWatermark) {\n-                final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(pollTime);\n+            while (offset < highWatermark) { // when we \"fix\" this loop (KAFKA-7380 / KAFKA-10317)\n+                                             // we should update the `poll()` timeout below\n+\n+                // we ignore `poll.ms` config during bootstrapping phase and\n+                // apply `request.timeout.ms` plus `task.timeout.ms` instead\n+                //\n+                // the reason is, that `poll.ms` might be too short to give a fetch request a fair chance\n+                // to actually complete and we don't want to start `task.timeout.ms` too early\n+                //\n+                // we also pass `task.timeout.ms` into `poll()` directly right now as it simplifies our own code:\n+                // if we don't pass it in, we would just track the timeout ourselves and call `poll()` again\n+                // in our own retry loop; by passing the timeout we can reuse the consumer's internal retry loop instead\n+                //\n+                // note that using `request.timeout.ms` provides a conservative upper bound for the timeout;\n+                // this implies that we might start `task.timeout.ms` \"delayed\" -- however, starting the timeout\n+                // delayed is preferable (as it's more robust) than starting it too early\n+                //\n+                // TODO https://issues.apache.org/jira/browse/KAFKA-10315\n+                //   -> do a more precise timeout handling if `poll` would throw an exception if a fetch request fails\n+                //      (instead of letting the consumer retry fetch requests silently)\n+                //\n+                // TODO https://issues.apache.org/jira/browse/KAFKA-10317 and\n+                //      https://issues.apache.org/jira/browse/KAFKA-7380\n+                //  -> don't pass in `task.timeout.ms` to stay responsive if `KafkaStreams#close` gets called\n+                final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(requestTimeoutPlusTaskTimeout);\n+                if (records.isEmpty()) {\n+                    // this will always throw\n+                    maybeUpdateDeadlineOrThrow(time.milliseconds());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cecee3b990da57dd0a57ec5e497d1c8c2550955"}, "originalPosition": 244}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA0ODg3OQ==", "bodyText": "nit: we could just use Map for startOffsets and endOffsets", "url": "https://github.com/apache/kafka/pull/9047#discussion_r462048879", "createdAt": "2020-07-29T05:35:04Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -671,19 +1211,21 @@ private void writeCorruptCheckpoint() throws IOException {\n         }\n     }\n \n-    private void initializeConsumer(final long numRecords, final long startOffset, final TopicPartition topicPartition) {\n+    private void initializeConsumer(final long numRecords, final long startOffset, final TopicPartition... topicPartitions) {\n+        consumer.assign(Arrays.asList(topicPartitions));\n+\n         final HashMap<TopicPartition, Long> startOffsets = new HashMap<>();\n-        startOffsets.put(topicPartition, startOffset);\n         final HashMap<TopicPartition, Long> endOffsets = new HashMap<>();\n-        endOffsets.put(topicPartition, startOffset + numRecords);\n-        consumer.updatePartitions(topicPartition.topic(), Collections.singletonList(new PartitionInfo(topicPartition.topic(), topicPartition.partition(), null, null, null)));\n-        consumer.assign(Collections.singletonList(topicPartition));\n+        for (final TopicPartition topicPartition : topicPartitions) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cecee3b990da57dd0a57ec5e497d1c8c2550955"}, "originalPosition": 729}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf6ee1e774a3a635cb8ac9c134ff3269edaa7357", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/cf6ee1e774a3a635cb8ac9c134ff3269edaa7357", "committedDate": "2020-08-04T02:12:18Z", "message": "Github comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxMDc3MTU1", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-461077155", "createdAt": "2020-08-04T18:47:39Z", "commit": {"oid": "cf6ee1e774a3a635cb8ac9c134ff3269edaa7357"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxOTIyMDAz", "url": "https://github.com/apache/kafka/pull/9047#pullrequestreview-461922003", "createdAt": "2020-08-05T18:32:38Z", "commit": {"oid": "cf6ee1e774a3a635cb8ac9c134ff3269edaa7357"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxODozMjozOVrOG8VuuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxODozMjozOVrOG8VuuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTkyMzc2OQ==", "bodyText": "\"medium\" looks fine to me. But I'm not feeling strong against it either.", "url": "https://github.com/apache/kafka/pull/9047#discussion_r465923769", "createdAt": "2020-08-05T18:32:39Z", "author": {"login": "guozhangwang"}, "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -326,13 +321,18 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n           <tr class=\"row-even\"><td>state.cleanup.delay.ms</td>\n             <td>Low</td>\n             <td colspan=\"2\">The amount of time in milliseconds to wait before deleting state when a partition has migrated.</td>\n-            <td>600000 milliseconds</td>\n+            <td>600000 milliseconds (10 minutes)</td>\n           </tr>\n           <tr class=\"row-odd\"><td>state.dir</td>\n             <td>High</td>\n             <td colspan=\"2\">Directory location for state stores.</td>\n             <td><code class=\"docutils literal\"><span class=\"pre\">/tmp/kafka-streams</span></code></td>\n           </tr>\n+          <tr class=\"row-odd\"><td>task.timeout.ms</td>\n+            <td>Medium</td>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2NTYwMQ=="}, "originalCommit": null, "originalPosition": 70}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1338, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}