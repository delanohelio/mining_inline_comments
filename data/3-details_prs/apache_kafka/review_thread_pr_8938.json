{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQwOTQzNzYw", "number": 8938, "reviewThreads": {"totalCount": 41, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxMDoxNFrOEJXoig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxOToyNTozMVrOEKolDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjU5ODUwOnYy", "diffSide": "LEFT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SmokeTestDriverIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxMDoxNFrOGp3XUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxMDoxNFrOGp3XUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MTg4OQ==", "bodyText": "This isn't needed anymore, as SmokeTestClient#start now blocks until the instance goes to running the first time.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446551889", "createdAt": "2020-06-27T18:10:14Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SmokeTestDriverIntegrationTest.java", "diffHunk": "@@ -104,10 +104,6 @@ public void shouldWorkWithRebalance() throws InterruptedException {\n             clients.add(smokeTestClient);\n             smokeTestClient.start(props);\n \n-            while (!clients.get(clients.size() - 1).started()) {\n-                Thread.sleep(100);\n-            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjU5OTIwOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxMToxNVrOGp3XqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxOToyMzoxOVrOGryhTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MTk3Nw==", "bodyText": "I inlined these utilities to make this class \"portable\". I.e., we can copy and paste it into the \"upgrade test\" modules without also dragging in a dependency on the client utils.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446551977", "createdAt": "2020-06-27T18:11:15Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU2OTY3OQ==", "bodyText": "Sounds good.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448569679", "createdAt": "2020-07-01T19:23:19Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MTk3Nw=="}, "originalCommit": null, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwMDA4OnYy", "diffSide": "LEFT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxMjoyNVrOGp3YFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxMjoyNVrOGp3YFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MjA4Nw==", "bodyText": "Inlining this function actually fixed a bug in which the next line was setting a handler that actually replaced the handler registered in createKafkaStreams.\nThe function was only used from right here anyway, so it was needless complexity.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446552087", "createdAt": "2020-06-27T18:12:25Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwMTcxOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxMzo1NFrOGp3Y1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxMzo1NFrOGp3Y1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MjI3Ng==", "bodyText": "This is logic from the inlined function that had gotten lost when we set the handler again.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446552276", "createdAt": "2020-06-27T18:13:54Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n         streams.setUncaughtExceptionHandler((t, e) -> {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n             uncaughtException = true;\n-            e.printStackTrace();\n+            streams.close(Duration.ofSeconds(30));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwMjI3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxNDo0M1rOGp3ZGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxNDo0M1rOGp3ZGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MjM0Ng==", "bodyText": "Blocking and then printing this gives the system tests the ability to explicitly wait until the instances are joined.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446552346", "createdAt": "2020-06-27T18:14:43Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n         streams.setUncaughtExceptionHandler((t, e) -> {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n             uncaughtException = true;\n-            e.printStackTrace();\n+            streams.close(Duration.ofSeconds(30));\n         });\n \n-        Exit.addShutdownHook(\"streams-shutdown-hook\", () -> close());\n+        addShutdownHook(\"streams-shutdown-hook\", this::close);\n \n-        thread = new Thread(() -> streams.start());\n-        thread.start();\n+        streams.start();\n+        try {\n+            if (!countDownLatch.await(1, TimeUnit.MINUTES)) {\n+                System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't start in one minute\");\n+            }\n+        } catch (final InterruptedException e) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: \" + e);\n+            e.printStackTrace(System.out);\n+        }\n+        System.out.println(name + \": SMOKE-TEST-CLIENT-STARTED\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwMzU3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxNTo1N1rOGp3ZsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxNTo1N1rOGp3ZsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MjQ5Ng==", "bodyText": "I just happened to notice that we weren't previously checking that Streams actually finished closing. It looks like we were expecting some kind of exception to get thrown during the join() below, but that's not the way it works.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446552496", "createdAt": "2020-06-27T18:15:57Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n         streams.setUncaughtExceptionHandler((t, e) -> {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n             uncaughtException = true;\n-            e.printStackTrace();\n+            streams.close(Duration.ofSeconds(30));\n         });\n \n-        Exit.addShutdownHook(\"streams-shutdown-hook\", () -> close());\n+        addShutdownHook(\"streams-shutdown-hook\", this::close);\n \n-        thread = new Thread(() -> streams.start());\n-        thread.start();\n+        streams.start();\n+        try {\n+            if (!countDownLatch.await(1, TimeUnit.MINUTES)) {\n+                System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't start in one minute\");\n+            }\n+        } catch (final InterruptedException e) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: \" + e);\n+            e.printStackTrace(System.out);\n+        }\n+        System.out.println(name + \": SMOKE-TEST-CLIENT-STARTED\");\n+        System.out.println(name + \" started at \" + Instant.now());\n     }\n \n     public void closeAsync() {\n         streams.close(Duration.ZERO);\n     }\n \n     public void close() {\n-        streams.close(Duration.ofSeconds(5));\n-        // do not remove these printouts since they are needed for health scripts\n-        if (!uncaughtException) {\n+        final boolean wasClosed = streams.close(Duration.ofMinutes(1));\n+\n+        if (wasClosed && !uncaughtException) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwNDE4OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxNjo0NlrOGp3Z-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxOTo0OTozN1rOGrzP5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MjU3MQ==", "bodyText": "So here's what we print if there was no uncaught exception, but we also didn't close in time.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446552571", "createdAt": "2020-06-27T18:16:46Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n         streams.setUncaughtExceptionHandler((t, e) -> {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n             uncaughtException = true;\n-            e.printStackTrace();\n+            streams.close(Duration.ofSeconds(30));\n         });\n \n-        Exit.addShutdownHook(\"streams-shutdown-hook\", () -> close());\n+        addShutdownHook(\"streams-shutdown-hook\", this::close);\n \n-        thread = new Thread(() -> streams.start());\n-        thread.start();\n+        streams.start();\n+        try {\n+            if (!countDownLatch.await(1, TimeUnit.MINUTES)) {\n+                System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't start in one minute\");\n+            }\n+        } catch (final InterruptedException e) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: \" + e);\n+            e.printStackTrace(System.out);\n+        }\n+        System.out.println(name + \": SMOKE-TEST-CLIENT-STARTED\");\n+        System.out.println(name + \" started at \" + Instant.now());\n     }\n \n     public void closeAsync() {\n         streams.close(Duration.ZERO);\n     }\n \n     public void close() {\n-        streams.close(Duration.ofSeconds(5));\n-        // do not remove these printouts since they are needed for health scripts\n-        if (!uncaughtException) {\n+        final boolean wasClosed = streams.close(Duration.ofMinutes(1));\n+\n+        if (wasClosed && !uncaughtException) {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-CLOSED\");\n-        }\n-        try {\n-            thread.join();\n-        } catch (final Exception ex) {\n-            // do not remove these printouts since they are needed for health scripts\n+        } else if (wasClosed) {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n-            // ignore\n+        } else {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't close\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU3MjE5MA==", "bodyText": "nit: Didn't close in time?", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448572190", "createdAt": "2020-07-01T19:28:53Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n         streams.setUncaughtExceptionHandler((t, e) -> {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n             uncaughtException = true;\n-            e.printStackTrace();\n+            streams.close(Duration.ofSeconds(30));\n         });\n \n-        Exit.addShutdownHook(\"streams-shutdown-hook\", () -> close());\n+        addShutdownHook(\"streams-shutdown-hook\", this::close);\n \n-        thread = new Thread(() -> streams.start());\n-        thread.start();\n+        streams.start();\n+        try {\n+            if (!countDownLatch.await(1, TimeUnit.MINUTES)) {\n+                System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't start in one minute\");\n+            }\n+        } catch (final InterruptedException e) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: \" + e);\n+            e.printStackTrace(System.out);\n+        }\n+        System.out.println(name + \": SMOKE-TEST-CLIENT-STARTED\");\n+        System.out.println(name + \" started at \" + Instant.now());\n     }\n \n     public void closeAsync() {\n         streams.close(Duration.ZERO);\n     }\n \n     public void close() {\n-        streams.close(Duration.ofSeconds(5));\n-        // do not remove these printouts since they are needed for health scripts\n-        if (!uncaughtException) {\n+        final boolean wasClosed = streams.close(Duration.ofMinutes(1));\n+\n+        if (wasClosed && !uncaughtException) {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-CLOSED\");\n-        }\n-        try {\n-            thread.join();\n-        } catch (final Exception ex) {\n-            // do not remove these printouts since they are needed for health scripts\n+        } else if (wasClosed) {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n-            // ignore\n+        } else {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't close\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MjU3MQ=="}, "originalCommit": null, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU4MTYwNw==", "bodyText": "Sounds good.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't close\");\n          \n          \n            \n                        System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't close in time.\");", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448581607", "createdAt": "2020-07-01T19:49:37Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n         streams.setUncaughtExceptionHandler((t, e) -> {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n             uncaughtException = true;\n-            e.printStackTrace();\n+            streams.close(Duration.ofSeconds(30));\n         });\n \n-        Exit.addShutdownHook(\"streams-shutdown-hook\", () -> close());\n+        addShutdownHook(\"streams-shutdown-hook\", this::close);\n \n-        thread = new Thread(() -> streams.start());\n-        thread.start();\n+        streams.start();\n+        try {\n+            if (!countDownLatch.await(1, TimeUnit.MINUTES)) {\n+                System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't start in one minute\");\n+            }\n+        } catch (final InterruptedException e) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: \" + e);\n+            e.printStackTrace(System.out);\n+        }\n+        System.out.println(name + \": SMOKE-TEST-CLIENT-STARTED\");\n+        System.out.println(name + \" started at \" + Instant.now());\n     }\n \n     public void closeAsync() {\n         streams.close(Duration.ZERO);\n     }\n \n     public void close() {\n-        streams.close(Duration.ofSeconds(5));\n-        // do not remove these printouts since they are needed for health scripts\n-        if (!uncaughtException) {\n+        final boolean wasClosed = streams.close(Duration.ofMinutes(1));\n+\n+        if (wasClosed && !uncaughtException) {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-CLOSED\");\n-        }\n-        try {\n-            thread.join();\n-        } catch (final Exception ex) {\n-            // do not remove these printouts since they are needed for health scripts\n+        } else if (wasClosed) {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n-            // ignore\n+        } else {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't close\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MjU3MQ=="}, "originalCommit": null, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwNDc3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxNzo1MFrOGp3aSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxOToyODowN1rOGryp6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MjY0OQ==", "bodyText": "5 seconds seems a bit stingy :) . Note that we were previously ignoring the case where we didn't close within the timeout, so we have no idea if 5 seconds was ever long enough. I figured a minute is more reasonable.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446552649", "createdAt": "2020-06-27T18:17:50Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n         streams.setUncaughtExceptionHandler((t, e) -> {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n             uncaughtException = true;\n-            e.printStackTrace();\n+            streams.close(Duration.ofSeconds(30));\n         });\n \n-        Exit.addShutdownHook(\"streams-shutdown-hook\", () -> close());\n+        addShutdownHook(\"streams-shutdown-hook\", this::close);\n \n-        thread = new Thread(() -> streams.start());\n-        thread.start();\n+        streams.start();\n+        try {\n+            if (!countDownLatch.await(1, TimeUnit.MINUTES)) {\n+                System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't start in one minute\");\n+            }\n+        } catch (final InterruptedException e) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: \" + e);\n+            e.printStackTrace(System.out);\n+        }\n+        System.out.println(name + \": SMOKE-TEST-CLIENT-STARTED\");\n+        System.out.println(name + \" started at \" + Instant.now());\n     }\n \n     public void closeAsync() {\n         streams.close(Duration.ZERO);\n     }\n \n     public void close() {\n-        streams.close(Duration.ofSeconds(5));\n-        // do not remove these printouts since they are needed for health scripts\n-        if (!uncaughtException) {\n+        final boolean wasClosed = streams.close(Duration.ofMinutes(1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU3MTg4Mg==", "bodyText": "+1", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448571882", "createdAt": "2020-07-01T19:28:07Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n         streams.setUncaughtExceptionHandler((t, e) -> {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n             uncaughtException = true;\n-            e.printStackTrace();\n+            streams.close(Duration.ofSeconds(30));\n         });\n \n-        Exit.addShutdownHook(\"streams-shutdown-hook\", () -> close());\n+        addShutdownHook(\"streams-shutdown-hook\", this::close);\n \n-        thread = new Thread(() -> streams.start());\n-        thread.start();\n+        streams.start();\n+        try {\n+            if (!countDownLatch.await(1, TimeUnit.MINUTES)) {\n+                System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't start in one minute\");\n+            }\n+        } catch (final InterruptedException e) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: \" + e);\n+            e.printStackTrace(System.out);\n+        }\n+        System.out.println(name + \": SMOKE-TEST-CLIENT-STARTED\");\n+        System.out.println(name + \" started at \" + Instant.now());\n     }\n \n     public void closeAsync() {\n         streams.close(Duration.ZERO);\n     }\n \n     public void close() {\n-        streams.close(Duration.ofSeconds(5));\n-        // do not remove these printouts since they are needed for health scripts\n-        if (!uncaughtException) {\n+        final boolean wasClosed = streams.close(Duration.ofMinutes(1));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MjY0OQ=="}, "originalCommit": null, "originalPosition": 137}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwNTY1OnYy", "diffSide": "LEFT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxODo1NlrOGp3asw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxODo1NlrOGp3asw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1Mjc1NQ==", "bodyText": "Moved these to the python code, where the \"properties file\" itself is built. I left only the properties that are better off dynamically generated in the java code.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446552755", "createdAt": "2020-06-27T18:18:56Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n     }\n \n     public boolean closed() {\n         return closed;\n     }\n \n     public void start(final Properties streamsProperties) {\n-        streams = createKafkaStreams(streamsProperties);\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n         streams.setUncaughtExceptionHandler((t, e) -> {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n             uncaughtException = true;\n-            e.printStackTrace();\n+            streams.close(Duration.ofSeconds(30));\n         });\n \n-        Exit.addShutdownHook(\"streams-shutdown-hook\", () -> close());\n+        addShutdownHook(\"streams-shutdown-hook\", this::close);\n \n-        thread = new Thread(() -> streams.start());\n-        thread.start();\n+        streams.start();\n+        try {\n+            if (!countDownLatch.await(1, TimeUnit.MINUTES)) {\n+                System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't start in one minute\");\n+            }\n+        } catch (final InterruptedException e) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: \" + e);\n+            e.printStackTrace(System.out);\n+        }\n+        System.out.println(name + \": SMOKE-TEST-CLIENT-STARTED\");\n+        System.out.println(name + \" started at \" + Instant.now());\n     }\n \n     public void closeAsync() {\n         streams.close(Duration.ZERO);\n     }\n \n     public void close() {\n-        streams.close(Duration.ofSeconds(5));\n-        // do not remove these printouts since they are needed for health scripts\n-        if (!uncaughtException) {\n+        final boolean wasClosed = streams.close(Duration.ofMinutes(1));\n+\n+        if (wasClosed && !uncaughtException) {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-CLOSED\");\n-        }\n-        try {\n-            thread.join();\n-        } catch (final Exception ex) {\n-            // do not remove these printouts since they are needed for health scripts\n+        } else if (wasClosed) {\n             System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n-            // ignore\n+        } else {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't close\");\n         }\n     }\n \n     private Properties getStreamsConfig(final Properties props) {\n         final Properties fullProps = new Properties(props);\n         fullProps.put(StreamsConfig.APPLICATION_ID_CONFIG, \"SmokeTest\");\n         fullProps.put(StreamsConfig.CLIENT_ID_CONFIG, \"SmokeTest-\" + name);\n-        fullProps.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 3);\n-        fullProps.put(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, 2);\n-        fullProps.put(StreamsConfig.BUFFERED_RECORDS_PER_PARTITION_CONFIG, 100);\n-        fullProps.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 1000);\n-        fullProps.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 3);\n-        fullProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-        fullProps.put(ProducerConfig.ACKS_CONFIG, \"all\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwNjc3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxOTozNlrOGp3bMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoxOTozNlrOGp3bMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1Mjg4MA==", "bodyText": "I just happened to notice that the newline was missing when I looked at the stdout. It didn't affect the tests' ability to grep.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446552880", "createdAt": "2020-06-27T18:19:36Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "diffHunk": "@@ -75,7 +75,7 @@ public void process(final Object key, final Object value) {\n \n                     @Override\n                     public void close() {\n-                        System.out.printf(\"Close processor for task %s\", context().taskId());\n+                        System.out.printf(\"Close processor for task %s%n\", context().taskId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwNzM3OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-22/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDoxMlrOGp3bdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDoxMlrOGp3bdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1Mjk0OQ==", "bodyText": "Everything in the upgrade-system-tests... directories is just copy/pasted from the main SmokeTest implementations.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446552949", "createdAt": "2020-06-27T18:20:12Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-22/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.common.utils.KafkaThread;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.Grouped;\n+import org.apache.kafka.streams.kstream.KGroupedStream;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Produced;\n+import org.apache.kafka.streams.kstream.Suppressed.BufferConfig;\n+import org.apache.kafka.streams.kstream.TimeWindows;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.streams.state.WindowStore;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n+\n+public class SmokeTestClient extends SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwNzg5OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-22/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDozOVrOGp3bsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDozOVrOGp3bsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzAwOQ==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553009", "createdAt": "2020-06-27T18:20:39Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-22/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java", "diffHunk": "@@ -0,0 +1,632 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.producer.Callback;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.clients.producer.RecordMetadata;\n+import org.apache.kafka.common.PartitionInfo;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.utils.Utils;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.PrintStream;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.Collections.emptyMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+\n+public class SmokeTestDriver extends SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwNzk5OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-22/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDo0NlrOGp3buw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDo0NlrOGp3buw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzAxOQ==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553019", "createdAt": "2020-06-27T18:20:46Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-22/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.kstream.Aggregator;\n+import org.apache.kafka.streams.kstream.Initializer;\n+import org.apache.kafka.streams.kstream.KeyValueMapper;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.streams.processor.Processor;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.ProcessorSupplier;\n+\n+import java.time.Instant;\n+\n+public class SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODAwOnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-22/src/test/java/org/apache/kafka/streams/tests/StreamsSmokeTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDo1MVrOGp3bvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDo1MVrOGp3bvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzAyMQ==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553021", "createdAt": "2020-06-27T18:20:51Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-22/src/test/java/org/apache/kafka/streams/tests/StreamsSmokeTest.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.StreamsConfig;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import static org.apache.kafka.streams.tests.SmokeTestDriver.generate;\n+import static org.apache.kafka.streams.tests.SmokeTestDriver.generatePerpetually;\n+\n+public class StreamsSmokeTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODA1OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-23/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDo1N1rOGp3bwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMDo1N1rOGp3bwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzAyNg==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553026", "createdAt": "2020-06-27T18:20:57Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-23/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.common.utils.KafkaThread;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.Grouped;\n+import org.apache.kafka.streams.kstream.KGroupedStream;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Produced;\n+import org.apache.kafka.streams.kstream.Suppressed.BufferConfig;\n+import org.apache.kafka.streams.kstream.TimeWindows;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.streams.state.WindowStore;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n+\n+public class SmokeTestClient extends SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODA5OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-23/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTowNlrOGp3bzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTowNlrOGp3bzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzAzNg==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553036", "createdAt": "2020-06-27T18:21:06Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-23/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java", "diffHunk": "@@ -0,0 +1,622 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.producer.Callback;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.clients.producer.RecordMetadata;\n+import org.apache.kafka.common.PartitionInfo;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.utils.Utils;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.PrintStream;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.Collections.emptyMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+\n+public class SmokeTestDriver extends SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODE0OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-23/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMToxNVrOGp3b0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMToxNVrOGp3b0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzA0Mw==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553043", "createdAt": "2020-06-27T18:21:15Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-23/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.kstream.Aggregator;\n+import org.apache.kafka.streams.kstream.Initializer;\n+import org.apache.kafka.streams.kstream.KeyValueMapper;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.streams.processor.Processor;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.ProcessorSupplier;\n+\n+import java.time.Instant;\n+\n+public class SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODI5OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-23/src/test/java/org/apache/kafka/streams/tests/StreamsSmokeTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMToyMVrOGp3b4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMToyMVrOGp3b4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzA1OQ==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553059", "createdAt": "2020-06-27T18:21:21Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-23/src/test/java/org/apache/kafka/streams/tests/StreamsSmokeTest.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.StreamsConfig;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import static org.apache.kafka.streams.tests.SmokeTestDriver.generate;\n+import static org.apache.kafka.streams.tests.SmokeTestDriver.generatePerpetually;\n+\n+public class StreamsSmokeTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODM5OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-24/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMToyNlrOGp3b7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMToyNlrOGp3b7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzA3MA==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553070", "createdAt": "2020-06-27T18:21:26Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-24/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.common.utils.KafkaThread;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.Grouped;\n+import org.apache.kafka.streams.kstream.KGroupedStream;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Produced;\n+import org.apache.kafka.streams.kstream.Suppressed.BufferConfig;\n+import org.apache.kafka.streams.kstream.TimeWindows;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.streams.state.WindowStore;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n+\n+public class SmokeTestClient extends SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODQ4OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-24/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTozNVrOGp3b_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTozNVrOGp3b_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzA4NA==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553084", "createdAt": "2020-06-27T18:21:35Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-24/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java", "diffHunk": "@@ -0,0 +1,622 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.producer.Callback;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.clients.producer.RecordMetadata;\n+import org.apache.kafka.common.PartitionInfo;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.utils.Utils;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.PrintStream;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.Collections.emptyMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+\n+public class SmokeTestDriver extends SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODUzOnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-24/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTo0MVrOGp3cAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTo0MVrOGp3cAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzA5MA==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553090", "createdAt": "2020-06-27T18:21:41Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-24/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.kstream.Aggregator;\n+import org.apache.kafka.streams.kstream.Initializer;\n+import org.apache.kafka.streams.kstream.KeyValueMapper;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.streams.processor.Processor;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.ProcessorSupplier;\n+\n+import java.time.Instant;\n+\n+public class SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODY5OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-24/src/test/java/org/apache/kafka/streams/tests/StreamsSmokeTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTo0NlrOGp3cEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTo0NlrOGp3cEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzEwNg==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553106", "createdAt": "2020-06-27T18:21:46Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-24/src/test/java/org/apache/kafka/streams/tests/StreamsSmokeTest.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.StreamsConfig;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import static org.apache.kafka.streams.tests.SmokeTestDriver.generate;\n+import static org.apache.kafka.streams.tests.SmokeTestDriver.generatePerpetually;\n+\n+public class StreamsSmokeTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODgyOnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-25/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTo1MlrOGp3cHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMTo1MlrOGp3cHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzExOQ==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553119", "createdAt": "2020-06-27T18:21:52Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-25/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.common.utils.KafkaThread;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.Grouped;\n+import org.apache.kafka.streams.kstream.KGroupedStream;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Produced;\n+import org.apache.kafka.streams.kstream.Suppressed.BufferConfig;\n+import org.apache.kafka.streams.kstream.TimeWindows;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.streams.state.WindowStore;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n+\n+public class SmokeTestClient extends SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODg4OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-25/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjowMFrOGp3cJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjowMFrOGp3cJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzEyNQ==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553125", "createdAt": "2020-06-27T18:22:00Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-25/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java", "diffHunk": "@@ -0,0 +1,622 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.producer.Callback;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.clients.producer.RecordMetadata;\n+import org.apache.kafka.common.PartitionInfo;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.utils.Utils;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.PrintStream;\n+import java.nio.charset.StandardCharsets;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.Collections.emptyMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+\n+public class SmokeTestDriver extends SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODkyOnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-25/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjowNlrOGp3cKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjowNlrOGp3cKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzEzMA==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553130", "createdAt": "2020-06-27T18:22:06Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-25/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.kstream.Aggregator;\n+import org.apache.kafka.streams.kstream.Initializer;\n+import org.apache.kafka.streams.kstream.KeyValueMapper;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.streams.processor.Processor;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.ProcessorSupplier;\n+\n+import java.time.Instant;\n+\n+public class SmokeTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwODk2OnYy", "diffSide": "RIGHT", "path": "streams/upgrade-system-tests-25/src/test/java/org/apache/kafka/streams/tests/StreamsSmokeTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjoxMlrOGp3cLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjoxMlrOGp3cLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzEzNQ==", "bodyText": "copy/pasted", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553135", "createdAt": "2020-06-27T18:22:12Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-25/src/test/java/org/apache/kafka/streams/tests/StreamsSmokeTest.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.StreamsConfig;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import static org.apache.kafka.streams.tests.SmokeTestDriver.generate;\n+import static org.apache.kafka.streams.tests.SmokeTestDriver.generatePerpetually;\n+\n+public class StreamsSmokeTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwOTMzOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/streams.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjozNlrOGp3cWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjozNlrOGp3cWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzE3Nw==", "bodyText": "Added the ability to set this, so that we can just run one broker from the upgrade tests.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553177", "createdAt": "2020-06-27T18:22:36Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/services/streams.py", "diffHunk": "@@ -305,23 +305,62 @@ def start_node(self, node):\n class StreamsSmokeTestBaseService(StreamsTestBaseService):\n     \"\"\"Base class for Streams Smoke Test services providing some common settings and functionality\"\"\"\n \n-    def __init__(self, test_context, kafka, command, processing_guarantee = 'at_least_once', num_threads = 3):\n+    def __init__(self, test_context, kafka, command, processing_guarantee = 'at_least_once', num_threads = 3, replication_factor = 3):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwOTUwOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/streams.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjo1MVrOGp3cbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMjo1MVrOGp3cbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzE5OQ==", "bodyText": "some other stuff for the upgrade tests.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553199", "createdAt": "2020-06-27T18:22:51Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/services/streams.py", "diffHunk": "@@ -305,23 +305,62 @@ def start_node(self, node):\n class StreamsSmokeTestBaseService(StreamsTestBaseService):\n     \"\"\"Base class for Streams Smoke Test services providing some common settings and functionality\"\"\"\n \n-    def __init__(self, test_context, kafka, command, processing_guarantee = 'at_least_once', num_threads = 3):\n+    def __init__(self, test_context, kafka, command, processing_guarantee = 'at_least_once', num_threads = 3, replication_factor = 3):\n         super(StreamsSmokeTestBaseService, self).__init__(test_context,\n                                                           kafka,\n                                                           \"org.apache.kafka.streams.tests.StreamsSmokeTest\",\n                                                           command)\n         self.NUM_THREADS = num_threads\n         self.PROCESSING_GUARANTEE = processing_guarantee\n+        self.KAFKA_STREAMS_VERSION = \"\"\n+        self.UPGRADE_FROM = None\n+        self.REPLICATION_FACTOR = replication_factor\n+\n+    def set_version(self, kafka_streams_version):\n+        self.KAFKA_STREAMS_VERSION = kafka_streams_version\n+\n+    def set_upgrade_from(self, upgrade_from):\n+        self.UPGRADE_FROM = upgrade_from", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYwOTY1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/streams.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMzowNlrOGp3cgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyMzowNlrOGp3cgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzIxOA==", "bodyText": "moved from Java", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553218", "createdAt": "2020-06-27T18:23:06Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/services/streams.py", "diffHunk": "@@ -305,23 +305,62 @@ def start_node(self, node):\n class StreamsSmokeTestBaseService(StreamsTestBaseService):\n     \"\"\"Base class for Streams Smoke Test services providing some common settings and functionality\"\"\"\n \n-    def __init__(self, test_context, kafka, command, processing_guarantee = 'at_least_once', num_threads = 3):\n+    def __init__(self, test_context, kafka, command, processing_guarantee = 'at_least_once', num_threads = 3, replication_factor = 3):\n         super(StreamsSmokeTestBaseService, self).__init__(test_context,\n                                                           kafka,\n                                                           \"org.apache.kafka.streams.tests.StreamsSmokeTest\",\n                                                           command)\n         self.NUM_THREADS = num_threads\n         self.PROCESSING_GUARANTEE = processing_guarantee\n+        self.KAFKA_STREAMS_VERSION = \"\"\n+        self.UPGRADE_FROM = None\n+        self.REPLICATION_FACTOR = replication_factor\n+\n+    def set_version(self, kafka_streams_version):\n+        self.KAFKA_STREAMS_VERSION = kafka_streams_version\n+\n+    def set_upgrade_from(self, upgrade_from):\n+        self.UPGRADE_FROM = upgrade_from\n \n     def prop_file(self):\n         properties = {streams_property.STATE_DIR: self.PERSISTENT_ROOT,\n                       streams_property.KAFKA_SERVERS: self.kafka.bootstrap_servers(),\n                       streams_property.PROCESSING_GUARANTEE: self.PROCESSING_GUARANTEE,\n-                      streams_property.NUM_THREADS: self.NUM_THREADS}\n+                      streams_property.NUM_THREADS: self.NUM_THREADS,\n+                      \"replication.factor\": self.REPLICATION_FACTOR,\n+                      \"num.standby.replicas\": 2,\n+                      \"buffered.records.per.partition\": 100,\n+                      \"commit.interval.ms\": 1000,\n+                      \"auto.offset.reset\": \"earliest\",\n+                      \"acks\": \"all\"}", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYxMDMzOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNDowM1rOGp3c0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNDowM1rOGp3c0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzI5Nw==", "bodyText": "Unfortunately, 2.1 doesn't work. See https://issues.apache.org/jira/browse/KAFKA-10203", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553297", "createdAt": "2020-06-27T18:24:03Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "diffHunk": "@@ -37,6 +37,9 @@\n # can be replaced with metadata_2_versions\n backward_compatible_metadata_2_versions = [str(LATEST_0_10_2), str(LATEST_0_11_0), str(LATEST_1_0), str(LATEST_1_1)]\n metadata_3_or_higher_versions = [str(LATEST_2_0), str(LATEST_2_1), str(LATEST_2_2), str(LATEST_2_3), str(LATEST_2_4), str(LATEST_2_5), str(DEV_VERSION)]\n+smoke_test_versions = [str(LATEST_2_2), str(LATEST_2_3), str(LATEST_2_4), str(LATEST_2_5)]", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYxMDYwOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNDo0NFrOGp3c9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNDo0NFrOGp3c9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzMzNA==", "bodyText": "Changed the name to reflect that we're just testing upgrades now.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553334", "createdAt": "2020-06-27T18:24:44Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "diffHunk": "@@ -189,8 +192,8 @@ def test_upgrade_downgrade_brokers(self, from_version, to_version):\n         processor.stop()\n         processor.node.account.ssh_capture(\"grep SMOKE-TEST-CLIENT-CLOSED %s\" % processor.STDOUT_FILE, allow_fail=False)\n \n-    @matrix(from_version=metadata_2_versions, to_version=metadata_2_versions)\n-    def test_simple_upgrade_downgrade(self, from_version, to_version):\n+    @matrix(from_version=smoke_test_versions, to_version=dev_version)\n+    def test_app_upgrade(self, from_version, to_version):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYxMTA2OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNTowMVrOGp3dJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNTowMVrOGp3dJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzM4Mg==", "bodyText": "required setup for the smoke test app", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553382", "createdAt": "2020-06-27T18:25:01Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "diffHunk": "@@ -201,14 +204,29 @@ def test_simple_upgrade_downgrade(self, from_version, to_version):\n         self.zk = ZookeeperService(self.test_context, num_nodes=1)\n         self.zk.start()\n \n-        self.kafka = KafkaService(self.test_context, num_nodes=1, zk=self.zk, topics=self.topics)\n+        self.kafka = KafkaService(self.test_context, num_nodes=1, zk=self.zk, topics={\n+            'echo' : { 'partitions': 5, 'replication-factor': 1 },\n+            'data' : { 'partitions': 5, 'replication-factor': 1 },\n+            'min' : { 'partitions': 5, 'replication-factor': 1 },\n+            'min-suppressed' : { 'partitions': 5, 'replication-factor': 1 },\n+            'min-raw' : { 'partitions': 5, 'replication-factor': 1 },\n+            'max' : { 'partitions': 5, 'replication-factor': 1 },\n+            'sum' : { 'partitions': 5, 'replication-factor': 1 },\n+            'sws-raw' : { 'partitions': 5, 'replication-factor': 1 },\n+            'sws-suppressed' : { 'partitions': 5, 'replication-factor': 1 },\n+            'dif' : { 'partitions': 5, 'replication-factor': 1 },\n+            'cnt' : { 'partitions': 5, 'replication-factor': 1 },\n+            'avg' : { 'partitions': 5, 'replication-factor': 1 },\n+            'wcnt' : { 'partitions': 5, 'replication-factor': 1 },\n+            'tagg' : { 'partitions': 5, 'replication-factor': 1 }\n+        })", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYxMjI0OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNjoyMFrOGp3dsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNjoyMFrOGp3dsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzUyMA==", "bodyText": "I changed the \"first time startup\" method to just start all the instances at the same time, rather than waiting for them to start up and process one at a time.\nFor the upgrade part of the test, we still do rolling upgrades.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553520", "createdAt": "2020-06-27T18:26:20Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "diffHunk": "@@ -349,56 +370,42 @@ def get_version_string(self, version):\n     def start_all_nodes_with(self, version):\n         kafka_version_str = self.get_version_string(version)\n \n-        # start first with <version>\n         self.prepare_for(self.processor1, version)\n-        node1 = self.processor1.node\n-        with node1.account.monitor_log(self.processor1.STDOUT_FILE) as monitor:\n-            with node1.account.monitor_log(self.processor1.LOG_FILE) as log_monitor:\n-                self.processor1.start()\n-                log_monitor.wait_until(kafka_version_str,\n-                                       timeout_sec=60,\n-                                       err_msg=\"Could not detect Kafka Streams version \" + version + \" \" + str(node1.account))\n-                monitor.wait_until(self.processed_msg,\n-                                   timeout_sec=60,\n-                                   err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node1.account))\n-\n-        # start second with <version>\n         self.prepare_for(self.processor2, version)\n-        node2 = self.processor2.node\n-        with node1.account.monitor_log(self.processor1.STDOUT_FILE) as first_monitor:\n-            with node2.account.monitor_log(self.processor2.STDOUT_FILE) as second_monitor:\n-                with node2.account.monitor_log(self.processor2.LOG_FILE) as log_monitor:\n-                    self.processor2.start()\n-                    log_monitor.wait_until(kafka_version_str,\n-                                           timeout_sec=60,\n-                                           err_msg=\"Could not detect Kafka Streams version \" + version + \" on \" + str(node2.account))\n-                    first_monitor.wait_until(self.processed_msg,\n-                                             timeout_sec=60,\n-                                             err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node1.account))\n-                    second_monitor.wait_until(self.processed_msg,\n-                                              timeout_sec=60,\n-                                              err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node2.account))\n-\n-        # start third with <version>\n         self.prepare_for(self.processor3, version)\n-        node3 = self.processor3.node\n-        with node1.account.monitor_log(self.processor1.STDOUT_FILE) as first_monitor:\n-            with node2.account.monitor_log(self.processor2.STDOUT_FILE) as second_monitor:\n-                with node3.account.monitor_log(self.processor3.STDOUT_FILE) as third_monitor:\n-                    with node3.account.monitor_log(self.processor3.LOG_FILE) as log_monitor:\n-                        self.processor3.start()\n-                        log_monitor.wait_until(kafka_version_str,\n-                                               timeout_sec=60,\n-                                               err_msg=\"Could not detect Kafka Streams version \" + version + \" on \" + str(node3.account))\n-                        first_monitor.wait_until(self.processed_msg,\n-                                                 timeout_sec=60,\n-                                                 err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node1.account))\n-                        second_monitor.wait_until(self.processed_msg,\n-                                                  timeout_sec=60,\n-                                                  err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node2.account))\n-                        third_monitor.wait_until(self.processed_msg,\n-                                                 timeout_sec=60,\n-                                                 err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node3.account))\n+\n+        self.processor1.start()\n+        self.processor2.start()\n+        self.processor3.start()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYxMjY1OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNzowMlrOGp3d4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNzowMlrOGp3d4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzU3MQ==", "bodyText": "Here's where we use that new output line after synchronously waiting to join the group in start()", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553571", "createdAt": "2020-06-27T18:27:02Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "diffHunk": "@@ -349,56 +370,42 @@ def get_version_string(self, version):\n     def start_all_nodes_with(self, version):\n         kafka_version_str = self.get_version_string(version)\n \n-        # start first with <version>\n         self.prepare_for(self.processor1, version)\n-        node1 = self.processor1.node\n-        with node1.account.monitor_log(self.processor1.STDOUT_FILE) as monitor:\n-            with node1.account.monitor_log(self.processor1.LOG_FILE) as log_monitor:\n-                self.processor1.start()\n-                log_monitor.wait_until(kafka_version_str,\n-                                       timeout_sec=60,\n-                                       err_msg=\"Could not detect Kafka Streams version \" + version + \" \" + str(node1.account))\n-                monitor.wait_until(self.processed_msg,\n-                                   timeout_sec=60,\n-                                   err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node1.account))\n-\n-        # start second with <version>\n         self.prepare_for(self.processor2, version)\n-        node2 = self.processor2.node\n-        with node1.account.monitor_log(self.processor1.STDOUT_FILE) as first_monitor:\n-            with node2.account.monitor_log(self.processor2.STDOUT_FILE) as second_monitor:\n-                with node2.account.monitor_log(self.processor2.LOG_FILE) as log_monitor:\n-                    self.processor2.start()\n-                    log_monitor.wait_until(kafka_version_str,\n-                                           timeout_sec=60,\n-                                           err_msg=\"Could not detect Kafka Streams version \" + version + \" on \" + str(node2.account))\n-                    first_monitor.wait_until(self.processed_msg,\n-                                             timeout_sec=60,\n-                                             err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node1.account))\n-                    second_monitor.wait_until(self.processed_msg,\n-                                              timeout_sec=60,\n-                                              err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node2.account))\n-\n-        # start third with <version>\n         self.prepare_for(self.processor3, version)\n-        node3 = self.processor3.node\n-        with node1.account.monitor_log(self.processor1.STDOUT_FILE) as first_monitor:\n-            with node2.account.monitor_log(self.processor2.STDOUT_FILE) as second_monitor:\n-                with node3.account.monitor_log(self.processor3.STDOUT_FILE) as third_monitor:\n-                    with node3.account.monitor_log(self.processor3.LOG_FILE) as log_monitor:\n-                        self.processor3.start()\n-                        log_monitor.wait_until(kafka_version_str,\n-                                               timeout_sec=60,\n-                                               err_msg=\"Could not detect Kafka Streams version \" + version + \" on \" + str(node3.account))\n-                        first_monitor.wait_until(self.processed_msg,\n-                                                 timeout_sec=60,\n-                                                 err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node1.account))\n-                        second_monitor.wait_until(self.processed_msg,\n-                                                  timeout_sec=60,\n-                                                  err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node2.account))\n-                        third_monitor.wait_until(self.processed_msg,\n-                                                 timeout_sec=60,\n-                                                 err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node3.account))\n+\n+        self.processor1.start()\n+        self.processor2.start()\n+        self.processor3.start()\n+\n+        # double-check the version\n+        self.wait_for_verification(self.processor1, kafka_version_str, self.processor1.LOG_FILE)\n+        self.wait_for_verification(self.processor2, kafka_version_str, self.processor2.LOG_FILE)\n+        self.wait_for_verification(self.processor3, kafka_version_str, self.processor3.LOG_FILE)\n+\n+        # wait for the members to join", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYxMzAxOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNzozOFrOGp3eDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyNzozOFrOGp3eDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzYxNA==", "bodyText": "Copied this over here so that we don't have to mess with monitors if we just want to search from the beginning of the files.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553614", "createdAt": "2020-06-27T18:27:38Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "diffHunk": "@@ -349,56 +370,42 @@ def get_version_string(self, version):\n     def start_all_nodes_with(self, version):\n         kafka_version_str = self.get_version_string(version)\n \n-        # start first with <version>\n         self.prepare_for(self.processor1, version)\n-        node1 = self.processor1.node\n-        with node1.account.monitor_log(self.processor1.STDOUT_FILE) as monitor:\n-            with node1.account.monitor_log(self.processor1.LOG_FILE) as log_monitor:\n-                self.processor1.start()\n-                log_monitor.wait_until(kafka_version_str,\n-                                       timeout_sec=60,\n-                                       err_msg=\"Could not detect Kafka Streams version \" + version + \" \" + str(node1.account))\n-                monitor.wait_until(self.processed_msg,\n-                                   timeout_sec=60,\n-                                   err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node1.account))\n-\n-        # start second with <version>\n         self.prepare_for(self.processor2, version)\n-        node2 = self.processor2.node\n-        with node1.account.monitor_log(self.processor1.STDOUT_FILE) as first_monitor:\n-            with node2.account.monitor_log(self.processor2.STDOUT_FILE) as second_monitor:\n-                with node2.account.monitor_log(self.processor2.LOG_FILE) as log_monitor:\n-                    self.processor2.start()\n-                    log_monitor.wait_until(kafka_version_str,\n-                                           timeout_sec=60,\n-                                           err_msg=\"Could not detect Kafka Streams version \" + version + \" on \" + str(node2.account))\n-                    first_monitor.wait_until(self.processed_msg,\n-                                             timeout_sec=60,\n-                                             err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node1.account))\n-                    second_monitor.wait_until(self.processed_msg,\n-                                              timeout_sec=60,\n-                                              err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node2.account))\n-\n-        # start third with <version>\n         self.prepare_for(self.processor3, version)\n-        node3 = self.processor3.node\n-        with node1.account.monitor_log(self.processor1.STDOUT_FILE) as first_monitor:\n-            with node2.account.monitor_log(self.processor2.STDOUT_FILE) as second_monitor:\n-                with node3.account.monitor_log(self.processor3.STDOUT_FILE) as third_monitor:\n-                    with node3.account.monitor_log(self.processor3.LOG_FILE) as log_monitor:\n-                        self.processor3.start()\n-                        log_monitor.wait_until(kafka_version_str,\n-                                               timeout_sec=60,\n-                                               err_msg=\"Could not detect Kafka Streams version \" + version + \" on \" + str(node3.account))\n-                        first_monitor.wait_until(self.processed_msg,\n-                                                 timeout_sec=60,\n-                                                 err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node1.account))\n-                        second_monitor.wait_until(self.processed_msg,\n-                                                  timeout_sec=60,\n-                                                  err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node2.account))\n-                        third_monitor.wait_until(self.processed_msg,\n-                                                 timeout_sec=60,\n-                                                 err_msg=\"Never saw output '%s' on \" % self.processed_msg + str(node3.account))\n+\n+        self.processor1.start()\n+        self.processor2.start()\n+        self.processor3.start()\n+\n+        # double-check the version\n+        self.wait_for_verification(self.processor1, kafka_version_str, self.processor1.LOG_FILE)\n+        self.wait_for_verification(self.processor2, kafka_version_str, self.processor2.LOG_FILE)\n+        self.wait_for_verification(self.processor3, kafka_version_str, self.processor3.LOG_FILE)\n+\n+        # wait for the members to join\n+        self.wait_for_verification(self.processor1, \"SMOKE-TEST-CLIENT-STARTED\", self.processor1.STDOUT_FILE)\n+        self.wait_for_verification(self.processor2, \"SMOKE-TEST-CLIENT-STARTED\", self.processor2.STDOUT_FILE)\n+        self.wait_for_verification(self.processor3, \"SMOKE-TEST-CLIENT-STARTED\", self.processor3.STDOUT_FILE)\n+\n+        # make sure they've processed something\n+        self.wait_for_verification(self.processor1, self.processed_msg, self.processor1.STDOUT_FILE)\n+        self.wait_for_verification(self.processor2, self.processed_msg, self.processor2.STDOUT_FILE)\n+        self.wait_for_verification(self.processor3, self.processed_msg, self.processor3.STDOUT_FILE)\n+\n+    def wait_for_verification(self, processor, message, file, num_lines=1):\n+        wait_until(lambda: self.verify_from_file(processor, message, file) >= num_lines,\n+                   timeout_sec=60,\n+                   err_msg=\"Did expect to read '%s' from %s\" % (message, processor.node.account))\n+\n+    @staticmethod\n+    def verify_from_file(processor, message, file):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 155}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYxMzQ0OnYy", "diffSide": "LEFT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyODoxMFrOGp3eQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyODoxMFrOGp3eQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzY2NA==", "bodyText": "no longer needed, since start() is now blocking", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553664", "createdAt": "2020-06-27T18:28:10Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MjYxNDUzOnYy", "diffSide": "LEFT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyOTo1MFrOGp3eyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QxODoyOTo1MFrOGp3eyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU1MzgwMg==", "bodyText": "This thread was actually pointless, since StreamThreads are already user (not daemon) threads.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r446553802", "createdAt": "2020-06-27T18:29:50Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTYxMzM3OnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/services/streams.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxODowMzoxNlrOGrwKWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxOTo1MzoxMFrOGrzWig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzMTAzMw==", "bodyText": "Rotating the config file as well as the logs gives us better visibility for debugging.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448531033", "createdAt": "2020-07-01T18:03:16Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/services/streams.py", "diffHunk": "@@ -48,6 +48,15 @@ class StreamsTestBaseService(KafkaPathResolverMixin, JmxMixin, Service):\n         \"streams_config\": {\n             \"path\": CONFIG_FILE,\n             \"collect_default\": True},\n+        \"streams_config.1\": {\n+            \"path\": CONFIG_FILE + \".1\",\n+            \"collect_default\": True},\n+        \"streams_config.0-1\": {\n+            \"path\": CONFIG_FILE + \".0-1\",\n+            \"collect_default\": True},\n+        \"streams_config.1-1\": {\n+            \"path\": CONFIG_FILE + \".1-1\",\n+            \"collect_default\": True},", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU3MzgwOA==", "bodyText": "Why only .1 / 0-1/ 1-1? There are more rotated log files below?", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448573808", "createdAt": "2020-07-01T19:32:33Z", "author": {"login": "guozhangwang"}, "path": "tests/kafkatest/services/streams.py", "diffHunk": "@@ -48,6 +48,15 @@ class StreamsTestBaseService(KafkaPathResolverMixin, JmxMixin, Service):\n         \"streams_config\": {\n             \"path\": CONFIG_FILE,\n             \"collect_default\": True},\n+        \"streams_config.1\": {\n+            \"path\": CONFIG_FILE + \".1\",\n+            \"collect_default\": True},\n+        \"streams_config.0-1\": {\n+            \"path\": CONFIG_FILE + \".0-1\",\n+            \"collect_default\": True},\n+        \"streams_config.1-1\": {\n+            \"path\": CONFIG_FILE + \".1-1\",\n+            \"collect_default\": True},", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzMTAzMw=="}, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU4MzMwNg==", "bodyText": "Yep, but those are for other tests. The upgrade tests only roll one time. I wanted to try and avoid touching any other tests in this PR, so I only implemented config file rotation for the new test.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448583306", "createdAt": "2020-07-01T19:53:10Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/services/streams.py", "diffHunk": "@@ -48,6 +48,15 @@ class StreamsTestBaseService(KafkaPathResolverMixin, JmxMixin, Service):\n         \"streams_config\": {\n             \"path\": CONFIG_FILE,\n             \"collect_default\": True},\n+        \"streams_config.1\": {\n+            \"path\": CONFIG_FILE + \".1\",\n+            \"collect_default\": True},\n+        \"streams_config.0-1\": {\n+            \"path\": CONFIG_FILE + \".0-1\",\n+            \"collect_default\": True},\n+        \"streams_config.1-1\": {\n+            \"path\": CONFIG_FILE + \".1-1\",\n+            \"collect_default\": True},", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzMTAzMw=="}, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTYxNjEwOnYy", "diffSide": "LEFT", "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxODowNDoxNlrOGrwMIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxOTo1NjoyOFrOGrzcOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzMTQ4OA==", "bodyText": "Moved this case to the new test file, streams_application_upgrade_test.py to avoid messing too much with the other tests here.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448531488", "createdAt": "2020-07-01T18:04:16Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "diffHunk": "@@ -189,54 +189,6 @@ def test_upgrade_downgrade_brokers(self, from_version, to_version):\n         processor.stop()\n         processor.node.account.ssh_capture(\"grep SMOKE-TEST-CLIENT-CLOSED %s\" % processor.STDOUT_FILE, allow_fail=False)\n \n-    @matrix(from_version=metadata_2_versions, to_version=metadata_2_versions)\n-    def test_simple_upgrade_downgrade(self, from_version, to_version):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU3NTQyOQ==", "bodyText": "Should we merge the test_metadata_upgrade below to the new file? I think with the new principle it is less meaningful to test the upgrade path from an old v1 to another old v2, since, the test of v2 should already cover that.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448575429", "createdAt": "2020-07-01T19:36:05Z", "author": {"login": "guozhangwang"}, "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "diffHunk": "@@ -189,54 +189,6 @@ def test_upgrade_downgrade_brokers(self, from_version, to_version):\n         processor.stop()\n         processor.node.account.ssh_capture(\"grep SMOKE-TEST-CLIENT-CLOSED %s\" % processor.STDOUT_FILE, allow_fail=False)\n \n-    @matrix(from_version=metadata_2_versions, to_version=metadata_2_versions)\n-    def test_simple_upgrade_downgrade(self, from_version, to_version):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzMTQ4OA=="}, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU4NDc2Mg==", "bodyText": "Aha! For that, I've been preparing a separate PR: #8971", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448584762", "createdAt": "2020-07-01T19:56:28Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_upgrade_test.py", "diffHunk": "@@ -189,54 +189,6 @@ def test_upgrade_downgrade_brokers(self, from_version, to_version):\n         processor.stop()\n         processor.node.account.ssh_capture(\"grep SMOKE-TEST-CLIENT-CLOSED %s\" % processor.STDOUT_FILE, allow_fail=False)\n \n-    @matrix(from_version=metadata_2_versions, to_version=metadata_2_versions)\n-    def test_simple_upgrade_downgrade(self, from_version, to_version):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzMTQ4OA=="}, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTYzMzMyOnYy", "diffSide": "RIGHT", "path": "tests/kafkatest/tests/streams/streams_application_upgrade_test.py", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxODoxMDowMlrOGrwXSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxOTowMzo0NFrOGs2izQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNDM0NQ==", "bodyText": "During a rolling bounce, we might see an old node try to read the changelog records of a new node, which would fail. All you have to do to recover is to continue upgrading, but we can't tolerate the failure in this system test. This is the exact same failure that we would see if we tried to downgrade.\nTo repair the non-downgradability of Streams (and hence allow rolling bounces to work without errors), we need to go back and release forward-compatible versions of older releases. For example, 2.5.1 and 2.4.2 would be such versions. I'll create a ticket to come back here and add the missing matrix coordinates once those versions are released. Additionally, when new versions are released, we should add them to the downgrade matrix and the rolling-bounce matrix to prevent this situation from arising again.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448534345", "createdAt": "2020-07-01T18:10:02Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_application_upgrade_test.py", "diffHunk": "@@ -0,0 +1,297 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import random\n+from ducktape.mark import matrix\n+from ducktape.tests.test import Test\n+from ducktape.utils.util import wait_until\n+from kafkatest.services.kafka import KafkaService\n+from kafkatest.services.streams import StreamsSmokeTestDriverService, StreamsSmokeTestJobRunnerService\n+from kafkatest.services.zookeeper import ZookeeperService\n+from kafkatest.version import LATEST_2_2, LATEST_2_3, LATEST_2_4, LATEST_2_5, DEV_VERSION, KafkaVersion\n+\n+smoke_test_versions = [str(LATEST_2_2), str(LATEST_2_3), str(LATEST_2_4), str(LATEST_2_5)]\n+dev_version = [str(DEV_VERSION)]\n+\n+class StreamsUpgradeTest(Test):\n+    \"\"\"\n+    Test upgrading Kafka Streams (all version combination)\n+    If metadata was changes, upgrade is more difficult\n+    Metadata version was bumped in 0.10.1.0 and\n+    subsequently bumped in 2.0.0\n+    \"\"\"\n+\n+    def __init__(self, test_context):\n+        super(StreamsUpgradeTest, self).__init__(test_context)\n+        self.topics = {\n+            'echo' : { 'partitions': 5 },\n+            'data' : { 'partitions': 5 },\n+        }\n+\n+    processed_msg = \"processed [0-9]* records\"\n+    base_version_number = str(DEV_VERSION).split(\"-\")[0]\n+\n+    def perform_broker_upgrade(self, to_version):\n+        self.logger.info(\"First pass bounce - rolling broker upgrade\")\n+        for node in self.kafka.nodes:\n+            self.kafka.stop_node(node)\n+            node.version = KafkaVersion(to_version)\n+            self.kafka.start_node(node)\n+\n+    @matrix(from_version=smoke_test_versions, to_version=dev_version, bounce_type=[\"full\"])", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU3NDUwMw==", "bodyText": "All you have to do to recover is to continue upgrading, but we can't tolerate the failure in this system test.  how this is handled now?", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448574503", "createdAt": "2020-07-01T19:34:16Z", "author": {"login": "guozhangwang"}, "path": "tests/kafkatest/tests/streams/streams_application_upgrade_test.py", "diffHunk": "@@ -0,0 +1,297 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import random\n+from ducktape.mark import matrix\n+from ducktape.tests.test import Test\n+from ducktape.utils.util import wait_until\n+from kafkatest.services.kafka import KafkaService\n+from kafkatest.services.streams import StreamsSmokeTestDriverService, StreamsSmokeTestJobRunnerService\n+from kafkatest.services.zookeeper import ZookeeperService\n+from kafkatest.version import LATEST_2_2, LATEST_2_3, LATEST_2_4, LATEST_2_5, DEV_VERSION, KafkaVersion\n+\n+smoke_test_versions = [str(LATEST_2_2), str(LATEST_2_3), str(LATEST_2_4), str(LATEST_2_5)]\n+dev_version = [str(DEV_VERSION)]\n+\n+class StreamsUpgradeTest(Test):\n+    \"\"\"\n+    Test upgrading Kafka Streams (all version combination)\n+    If metadata was changes, upgrade is more difficult\n+    Metadata version was bumped in 0.10.1.0 and\n+    subsequently bumped in 2.0.0\n+    \"\"\"\n+\n+    def __init__(self, test_context):\n+        super(StreamsUpgradeTest, self).__init__(test_context)\n+        self.topics = {\n+            'echo' : { 'partitions': 5 },\n+            'data' : { 'partitions': 5 },\n+        }\n+\n+    processed_msg = \"processed [0-9]* records\"\n+    base_version_number = str(DEV_VERSION).split(\"-\")[0]\n+\n+    def perform_broker_upgrade(self, to_version):\n+        self.logger.info(\"First pass bounce - rolling broker upgrade\")\n+        for node in self.kafka.nodes:\n+            self.kafka.stop_node(node)\n+            node.version = KafkaVersion(to_version)\n+            self.kafka.start_node(node)\n+\n+    @matrix(from_version=smoke_test_versions, to_version=dev_version, bounce_type=[\"full\"])", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNDM0NQ=="}, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU4Njc5Ng==", "bodyText": "When you say \"how is this handled\", do you mean in the system tests or in \"real life\"?\nI'm handling it in the system tests by not doing rolling bounces at all. If we do them, we'll see the test fail nondeterministically, when it just so happens that an old-version node tries to read a new-version record. Once we release 2.6.0, we'll be able to add a downgrade test from trunk to 2.6.0, and once we release 2.5.1, we can add a downgrade test from trunk to 2.5.1, and also one in the 2.6 branch from 2.6.x to 2.5.1.\nIn real life, you would see some of the old-versioned threads get exceptions and crash. But it wouldn't be a huge deal, since you can just continue with the rolling bounce until there are no more old-versioned instances, at which point everything is fine. There would be no data corruption or anything.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448586796", "createdAt": "2020-07-01T20:00:56Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_application_upgrade_test.py", "diffHunk": "@@ -0,0 +1,297 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import random\n+from ducktape.mark import matrix\n+from ducktape.tests.test import Test\n+from ducktape.utils.util import wait_until\n+from kafkatest.services.kafka import KafkaService\n+from kafkatest.services.streams import StreamsSmokeTestDriverService, StreamsSmokeTestJobRunnerService\n+from kafkatest.services.zookeeper import ZookeeperService\n+from kafkatest.version import LATEST_2_2, LATEST_2_3, LATEST_2_4, LATEST_2_5, DEV_VERSION, KafkaVersion\n+\n+smoke_test_versions = [str(LATEST_2_2), str(LATEST_2_3), str(LATEST_2_4), str(LATEST_2_5)]\n+dev_version = [str(DEV_VERSION)]\n+\n+class StreamsUpgradeTest(Test):\n+    \"\"\"\n+    Test upgrading Kafka Streams (all version combination)\n+    If metadata was changes, upgrade is more difficult\n+    Metadata version was bumped in 0.10.1.0 and\n+    subsequently bumped in 2.0.0\n+    \"\"\"\n+\n+    def __init__(self, test_context):\n+        super(StreamsUpgradeTest, self).__init__(test_context)\n+        self.topics = {\n+            'echo' : { 'partitions': 5 },\n+            'data' : { 'partitions': 5 },\n+        }\n+\n+    processed_msg = \"processed [0-9]* records\"\n+    base_version_number = str(DEV_VERSION).split(\"-\")[0]\n+\n+    def perform_broker_upgrade(self, to_version):\n+        self.logger.info(\"First pass bounce - rolling broker upgrade\")\n+        for node in self.kafka.nodes:\n+            self.kafka.stop_node(node)\n+            node.version = KafkaVersion(to_version)\n+            self.kafka.start_node(node)\n+\n+    @matrix(from_version=smoke_test_versions, to_version=dev_version, bounce_type=[\"full\"])", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNDM0NQ=="}, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY1MzUwNw==", "bodyText": "I was asking about in system tests :) More specifically I'm wondering if we could separate the upgrade path which are \"rolling bouncible\" from others that are not, e.g. as two separate tests in our python code base. And this can also be used as a cross-reference for our upgrade docs.\nAnyways, sine for trunk / 2.7 we would only be rolling bouncible from 2.6 and not from others this is not a big point. We can leave it to another follow-up PR.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448653507", "createdAt": "2020-07-01T22:44:04Z", "author": {"login": "guozhangwang"}, "path": "tests/kafkatest/tests/streams/streams_application_upgrade_test.py", "diffHunk": "@@ -0,0 +1,297 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import random\n+from ducktape.mark import matrix\n+from ducktape.tests.test import Test\n+from ducktape.utils.util import wait_until\n+from kafkatest.services.kafka import KafkaService\n+from kafkatest.services.streams import StreamsSmokeTestDriverService, StreamsSmokeTestJobRunnerService\n+from kafkatest.services.zookeeper import ZookeeperService\n+from kafkatest.version import LATEST_2_2, LATEST_2_3, LATEST_2_4, LATEST_2_5, DEV_VERSION, KafkaVersion\n+\n+smoke_test_versions = [str(LATEST_2_2), str(LATEST_2_3), str(LATEST_2_4), str(LATEST_2_5)]\n+dev_version = [str(DEV_VERSION)]\n+\n+class StreamsUpgradeTest(Test):\n+    \"\"\"\n+    Test upgrading Kafka Streams (all version combination)\n+    If metadata was changes, upgrade is more difficult\n+    Metadata version was bumped in 0.10.1.0 and\n+    subsequently bumped in 2.0.0\n+    \"\"\"\n+\n+    def __init__(self, test_context):\n+        super(StreamsUpgradeTest, self).__init__(test_context)\n+        self.topics = {\n+            'echo' : { 'partitions': 5 },\n+            'data' : { 'partitions': 5 },\n+        }\n+\n+    processed_msg = \"processed [0-9]* records\"\n+    base_version_number = str(DEV_VERSION).split(\"-\")[0]\n+\n+    def perform_broker_upgrade(self, to_version):\n+        self.logger.info(\"First pass bounce - rolling broker upgrade\")\n+        for node in self.kafka.nodes:\n+            self.kafka.stop_node(node)\n+            node.version = KafkaVersion(to_version)\n+            self.kafka.start_node(node)\n+\n+    @matrix(from_version=smoke_test_versions, to_version=dev_version, bounce_type=[\"full\"])", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNDM0NQ=="}, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcwNDA0Mw==", "bodyText": "Ah, thanks for the clarification. Yes, I was thinking we would just add new matrices for both rolling-bounceable and downgradable versions. E.g., after the two pending releases, we'd also have:\n@matrix(from=[2.5.1, 2.6.0], to=[DEV_VERSION], bounce_type=[full, rolling])\n@matrix(from=[DEV_VERSION], to=[2.5.1, 2.6.0], bounce_type=[full, rolling])\n\n(just for illustrative purposes, we'd probably declare a variable to make it maintainable)", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448704043", "createdAt": "2020-07-02T01:49:43Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_application_upgrade_test.py", "diffHunk": "@@ -0,0 +1,297 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import random\n+from ducktape.mark import matrix\n+from ducktape.tests.test import Test\n+from ducktape.utils.util import wait_until\n+from kafkatest.services.kafka import KafkaService\n+from kafkatest.services.streams import StreamsSmokeTestDriverService, StreamsSmokeTestJobRunnerService\n+from kafkatest.services.zookeeper import ZookeeperService\n+from kafkatest.version import LATEST_2_2, LATEST_2_3, LATEST_2_4, LATEST_2_5, DEV_VERSION, KafkaVersion\n+\n+smoke_test_versions = [str(LATEST_2_2), str(LATEST_2_3), str(LATEST_2_4), str(LATEST_2_5)]\n+dev_version = [str(DEV_VERSION)]\n+\n+class StreamsUpgradeTest(Test):\n+    \"\"\"\n+    Test upgrading Kafka Streams (all version combination)\n+    If metadata was changes, upgrade is more difficult\n+    Metadata version was bumped in 0.10.1.0 and\n+    subsequently bumped in 2.0.0\n+    \"\"\"\n+\n+    def __init__(self, test_context):\n+        super(StreamsUpgradeTest, self).__init__(test_context)\n+        self.topics = {\n+            'echo' : { 'partitions': 5 },\n+            'data' : { 'partitions': 5 },\n+        }\n+\n+    processed_msg = \"processed [0-9]* records\"\n+    base_version_number = str(DEV_VERSION).split(\"-\")[0]\n+\n+    def perform_broker_upgrade(self, to_version):\n+        self.logger.info(\"First pass bounce - rolling broker upgrade\")\n+        for node in self.kafka.nodes:\n+            self.kafka.stop_node(node)\n+            node.version = KafkaVersion(to_version)\n+            self.kafka.start_node(node)\n+\n+    @matrix(from_version=smoke_test_versions, to_version=dev_version, bounce_type=[\"full\"])", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNDM0NQ=="}, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY4NDE3Mw==", "bodyText": "Sounds great, thank you!!", "url": "https://github.com/apache/kafka/pull/8938#discussion_r449684173", "createdAt": "2020-07-03T19:03:44Z", "author": {"login": "guozhangwang"}, "path": "tests/kafkatest/tests/streams/streams_application_upgrade_test.py", "diffHunk": "@@ -0,0 +1,297 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import random\n+from ducktape.mark import matrix\n+from ducktape.tests.test import Test\n+from ducktape.utils.util import wait_until\n+from kafkatest.services.kafka import KafkaService\n+from kafkatest.services.streams import StreamsSmokeTestDriverService, StreamsSmokeTestJobRunnerService\n+from kafkatest.services.zookeeper import ZookeeperService\n+from kafkatest.version import LATEST_2_2, LATEST_2_3, LATEST_2_4, LATEST_2_5, DEV_VERSION, KafkaVersion\n+\n+smoke_test_versions = [str(LATEST_2_2), str(LATEST_2_3), str(LATEST_2_4), str(LATEST_2_5)]\n+dev_version = [str(DEV_VERSION)]\n+\n+class StreamsUpgradeTest(Test):\n+    \"\"\"\n+    Test upgrading Kafka Streams (all version combination)\n+    If metadata was changes, upgrade is more difficult\n+    Metadata version was bumped in 0.10.1.0 and\n+    subsequently bumped in 2.0.0\n+    \"\"\"\n+\n+    def __init__(self, test_context):\n+        super(StreamsUpgradeTest, self).__init__(test_context)\n+        self.topics = {\n+            'echo' : { 'partitions': 5 },\n+            'data' : { 'partitions': 5 },\n+        }\n+\n+    processed_msg = \"processed [0-9]* records\"\n+    base_version_number = str(DEV_VERSION).split(\"-\")[0]\n+\n+    def perform_broker_upgrade(self, to_version):\n+        self.logger.info(\"First pass bounce - rolling broker upgrade\")\n+        for node in self.kafka.nodes:\n+            self.kafka.stop_node(node)\n+            node.version = KafkaVersion(to_version)\n+            self.kafka.start_node(node)\n+\n+    @matrix(from_version=smoke_test_versions, to_version=dev_version, bounce_type=[\"full\"])", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUzNDM0NQ=="}, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTg2MDYzOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxOToyNTozMVrOGryliQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxOToyNTozMVrOGryliQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU3MDc2MQ==", "bodyText": "Do we still need a shutdown hook to delete with file.deleteOnExit();? I think the latter can still be triggered even with abnormal exits.", "url": "https://github.com/apache/kafka/pull/8938#discussion_r448570761", "createdAt": "2020-07-01T19:25:31Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -38,107 +37,128 @@\n import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.test.TestUtils;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.time.Duration;\n import java.time.Instant;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.kafka.streams.kstream.Suppressed.untilWindowCloses;\n \n public class SmokeTestClient extends SmokeTestUtil {\n \n     private final String name;\n \n-    private Thread thread;\n     private KafkaStreams streams;\n     private boolean uncaughtException = false;\n-    private boolean started;\n-    private boolean closed;\n+    private volatile boolean closed;\n \n-    public SmokeTestClient(final String name) {\n-        super();\n-        this.name = name;\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n     }\n \n-    public boolean started() {\n-        return started;\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b1a54f0701be5304fc31ddffa6b1404f1aff9beb"}, "originalPosition": 63}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2316, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}