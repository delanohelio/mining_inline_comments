{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIzMzc5Nzk5", "number": 9614, "title": "KAFKA-10500: Add failed-stream-threads metric for adding + removing stream threads", "bodyText": "Per KIP-663, adding a metric to record the failed streams threads over the life of a client.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-11-18T18:12:29Z", "url": "https://github.com/apache/kafka/pull/9614", "merged": true, "mergeCommit": {"oid": "4cc6d204ec5cb21841a2f8f21e6333bb688cd892"}, "closed": true, "closedAt": "2020-12-04T07:56:12Z", "author": {"login": "lct45"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABddgRcJgH2gAyNTIzMzc5Nzk5OjE3ODQzYmZkMGQ0NzEzNTZlOTFjY2U4MmNiNDY2ODA2YzYzYjg1M2M=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdioK1lAFqTU0NDMwMTQ2OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "17843bfd0d471356e91cce82cb466806c63b853c", "author": {"user": {"login": "lct45", "name": "leah"}}, "url": "https://github.com/apache/kafka/commit/17843bfd0d471356e91cce82cb466806c63b853c", "committedDate": "2020-11-17T21:17:03Z", "message": "adding failed stream metric"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b32c64d8892438dc305ad4c51f455ee4e6347e46", "author": {"user": {"login": "lct45", "name": "leah"}}, "url": "https://github.com/apache/kafka/commit/b32c64d8892438dc305ad4c51f455ee4e6347e46", "committedDate": "2020-11-18T17:22:23Z", "message": "adding testing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db", "author": {"user": {"login": "lct45", "name": "leah"}}, "url": "https://github.com/apache/kafka/commit/845b1750959d4cf69d8ce905d79b6a6c89c6c2db", "committedDate": "2020-11-18T18:14:14Z", "message": "Merge branch 'trunk' into thread_metrics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzNzYyODU5", "url": "https://github.com/apache/kafka/pull/9614#pullrequestreview-533762859", "createdAt": "2020-11-18T18:37:29Z", "commit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxODozNzoyOVrOH18skQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxODozNzoyOVrOH18skQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ==", "bodyText": "We also need to verify that the metric works when there is a failed stream thread. Options are (1) to create a custom processor now and (IIRC) run the test suite twice, once with failing stream threads and once without to confirm that the metric works. I'm not sure if the custom processor will let us just fail one stream thread right before closing the app. Or (2) wait until add/remove stream threads is implemented and remove threads and test the metric after removing some threads before closing the app. WDYT?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526331025", "createdAt": "2020-11-18T18:37:29Z", "author": {"login": "lct45"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java", "diffHunk": "@@ -377,7 +378,7 @@ private void shouldAddMetricsOnAllLevels(final String builtInMetricsVersion) thr\n             builtInMetricsVersion\n         );\n         checkCacheMetrics(builtInMetricsVersion);\n-\n+        verifyFailedStreamThreadsSensor(0.0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzNzgzNDc2", "url": "https://github.com/apache/kafka/pull/9614#pullrequestreview-533783476", "createdAt": "2020-11-18T19:03:38Z", "commit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOTowMzozOFrOH19sXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOTowNTo0NVrOH19xIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM0NzM1OQ==", "bodyText": "This seems wrong. There are a few duplicate calls here", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526347359", "createdAt": "2020-11-18T19:03:38Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -1070,6 +1070,10 @@ private Thread shutdownHelper(final boolean error) {\n             adminClient.close();\n \n             streamsMetrics.removeAllClientLevelMetrics();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM0ODU3OA==", "bodyText": "We probably don't want to skip this log. Can you move the sensor in here?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526348578", "createdAt": "2020-11-18T19:05:45Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -219,6 +220,8 @@ State setState(final State newState) {\n             } else if (!state.isValidTransition(newState)) {\n                 log.error(\"Unexpected state transition from {} to {}\", oldState, newState);\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n+            } else if (newState == State.DEAD) {\n+                failedStreamThreadSensor.record();\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 31}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe", "author": {"user": {"login": "lct45", "name": "leah"}}, "url": "https://github.com/apache/kafka/commit/44db7af16b663dba85e2d126947e239f475f63fe", "committedDate": "2020-11-18T22:38:25Z", "message": "Walker's updates"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0NDQ0ODI2", "url": "https://github.com/apache/kafka/pull/9614#pullrequestreview-534444826", "createdAt": "2020-11-19T13:29:31Z", "commit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzoyOTozMVrOH2eOnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNDozNzowNlrOH2hmIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg4MDQxMg==", "bodyText": "Could you please add a public method to StreamsMetricsImpl named removeAllClientLevelSensorsAndMetrics() that calls removeAllClientLevelMetrics() and removeAllClientLevelSensors() and make the latter two methods private?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526880412", "createdAt": "2020-11-19T13:29:31Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -1070,7 +1070,9 @@ private Thread shutdownHelper(final boolean error) {\n             adminClient.close();\n \n             streamsMetrics.removeAllClientLevelMetrics();\n+            streamsMetrics.removeAllClientLevelSensors();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg4NjM2OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads so far for a given Kafka Streams client\";\n          \n          \n            \n                private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads since the start of the Kafka Streams client\";", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526886369", "createdAt": "2020-11-19T13:33:43Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java", "diffHunk": "@@ -60,6 +65,7 @@ private ClientMetrics() {}\n         \"The description of the topology executed in the Kafka Streams client\";\n     private static final String STATE_DESCRIPTION = \"The state of the Kafka Streams client\";\n     private static final String ALIVE_STREAM_THREADS_DESCRIPTION = \"The current number of alive stream threads that are running or participating in rebalance\";\n+    private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads so far for a given Kafka Streams client\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg5NTQ0Nw==", "bodyText": "nit: I like to insert a blank line after the call to test to visually separate setup, call, and verification.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526895447", "createdAt": "2020-11-19T13:42:11Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java", "diffHunk": "@@ -99,6 +121,27 @@ public void shouldAddAliveStreamThreadsMetric() {\n         );\n     }\n \n+    @Test\n+    public void shouldGetFailedStreamThreadsSensor() {\n+        final String name = \"failed-stream-threads\";\n+        final String description = \"The number of failed stream threads so far for a given Kafka Streams client\";\n+        expect(streamsMetrics.clientLevelSensor(name, RecordingLevel.INFO)).andReturn(expectedSensor);\n+        expect(streamsMetrics.clientLevelTagMap()).andReturn(tagMap);\n+        StreamsMetricsImpl.addSumMetricToSensor(\n+            expectedSensor,\n+            CLIENT_LEVEL_GROUP,\n+            tagMap,\n+            name,\n+            false,\n+            description\n+        );\n+        replay(StreamsMetricsImpl.class, streamsMetrics);\n+\n+        final Sensor sensor = ClientMetrics.failedStreamThreadSensor(streamsMetrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg5NzEzNQ==", "bodyText": "Unit tests for this method are missing.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526897135", "createdAt": "2020-11-19T13:44:38Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg5NzIzNA==", "bodyText": "Unit tests for this method are missing. Please also consider my comment in class KafkaStreams for these unit tests.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526897234", "createdAt": "2020-11-19T13:44:46Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -253,6 +268,16 @@ public final void removeAllClientLevelMetrics() {\n         }\n     }\n \n+    public final void removeAllClientLevelSensors() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkwOTkyNw==", "bodyText": "Here you should just need a queue as for clientLevelMetrics. We need a map for the other levels because there can be multiple objects for each level, e.g., there might be multiple stream thread and each one manages its sensors under a key in the map. However, there is only one client on client level.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526909927", "createdAt": "2020-11-19T14:02:40Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -93,6 +93,7 @@ public int hashCode() {\n \n     private final Version version;\n     private final Deque<MetricName> clientLevelMetrics = new LinkedList<>();\n+    private final Map<String, Deque<String>> clientLevelSensors = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkxNDY2OA==", "bodyText": "Not every dead stream thread is a failed stream thread. You should record this metric where the uncaught exception handler is called because there we now that a stream thread died unexpectedly.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526914668", "createdAt": "2020-11-19T14:09:34Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -221,6 +221,9 @@ State setState(final State newState) {\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);\n+                if (newState == State.DEAD) {\n+                    failedStreamThreadSensor.record();\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkzNTU4Ng==", "bodyText": "I would put the test whether the metric is recorded correctly in StreamThreadTest. An example for such a test is shouldLogAndRecordSkippedRecordsForInvalidTimestamps(). I do not think an integration test is needed. The test regarding the existence of the metric, i.e., checkMetricByName(listMetricThread, FAILED_STREAM_THREADS, 1); should stay here.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526935586", "createdAt": "2020-11-19T14:37:06Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java", "diffHunk": "@@ -377,7 +378,7 @@ private void shouldAddMetricsOnAllLevels(final String builtInMetricsVersion) thr\n             builtInMetricsVersion\n         );\n         checkCacheMetrics(builtInMetricsVersion);\n-\n+        verifyFailedStreamThreadsSensor(0.0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ=="}, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 13}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "author": {"user": {"login": "lct45", "name": "leah"}}, "url": "https://github.com/apache/kafka/commit/f6db8cdd4e9f880bf34baf471212b980f8da7092", "committedDate": "2020-11-23T16:20:23Z", "message": "Updated testing and fixes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "author": {"user": {"login": "lct45", "name": "leah"}}, "url": "https://github.com/apache/kafka/commit/f6db8cdd4e9f880bf34baf471212b980f8da7092", "committedDate": "2020-11-23T16:20:23Z", "message": "Updated testing and fixes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3MjcwNjI0", "url": "https://github.com/apache/kafka/pull/9614#pullrequestreview-537270624", "createdAt": "2020-11-24T09:00:03Z", "commit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTowMDowM1rOH4ydEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMDowMDoxNVrOH43E-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMwODk0Ng==", "bodyText": "You can inline the value of variable key here and remove key.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n          \n          \n            \n                        final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529308946", "createdAt": "2020-11-24T09:00:03Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        final String key = CLIENT_LEVEL_GROUP;\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMxMzAyMg==", "bodyText": "Although, we use this in other methods, I think the following is a bit simpler to read:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        return Optional.ofNullable(metrics.getSensor(fullSensorName))\n          \n          \n            \n                            .orElseGet(() -> {\n          \n          \n            \n                                clientLevelSensors.push(fullSensorName);\n          \n          \n            \n                                return metrics.sensor(fullSensorName, recordingLevel, parents);\n          \n          \n            \n                            });\n          \n          \n            \n                    final Sensor sensor = metrics.getSensor(fullSensorName);\n          \n          \n            \n                    if (sensor == null) {\n          \n          \n            \n                        clientLevelSensors.push(fullSensorName);\n          \n          \n            \n                        return metrics.sensor(fullSensorName, recordingLevel, parents);\n          \n          \n            \n                    }\n          \n          \n            \n                    return sensor;", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529313022", "createdAt": "2020-11-24T09:03:22Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        final String key = CLIENT_LEVEL_GROUP;\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n+            return Optional.ofNullable(metrics.getSensor(fullSensorName))\n+                .orElseGet(() -> {\n+                    clientLevelSensors.push(fullSensorName);\n+                    return metrics.sensor(fullSensorName, recordingLevel, parents);\n+                });", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMxNzM5OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n          \n          \n            \n                        SENSOR_NAME_1,\n          \n          \n            \n                        recordingLevel\n          \n          \n            \n                    );\n          \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(SENSOR_NAME_1, recordingLevel);", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529317398", "createdAt": "2020-11-24T09:07:08Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -577,6 +579,38 @@ public void shouldGetExistingCacheLevelSensor() {\n         assertThat(actualSensor, is(equalToObject(sensor)));\n     }\n \n+    @Test\n+    public void shouldGetNewClientLevelSensor() {\n+        final Metrics metrics = mock(Metrics.class);\n+        final RecordingLevel recordingLevel = RecordingLevel.INFO;\n+        setupGetNewSensorTest(metrics, recordingLevel);\n+        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n+\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n+            SENSOR_NAME_1,\n+            recordingLevel\n+        );\n+\n+        verify(metrics);\n+        assertThat(actualSensor, is(equalToObject(sensor)));\n+    }\n+\n+    @Test\n+    public void shouldGetExistingClientLevelSensor() {\n+        final Metrics metrics = mock(Metrics.class);\n+        final RecordingLevel recordingLevel = RecordingLevel.INFO;\n+        setupGetExistingSensorTest(metrics);\n+        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n+\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n+            SENSOR_NAME_1,\n+            recordingLevel\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMyMjk2Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n          \n          \n            \n                        SENSOR_NAME_1,\n          \n          \n            \n                        recordingLevel\n          \n          \n            \n                    );\n          \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(SENSOR_NAME_1, recordingLevel);", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529322966", "createdAt": "2020-11-24T09:11:37Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -577,6 +579,38 @@ public void shouldGetExistingCacheLevelSensor() {\n         assertThat(actualSensor, is(equalToObject(sensor)));\n     }\n \n+    @Test\n+    public void shouldGetNewClientLevelSensor() {\n+        final Metrics metrics = mock(Metrics.class);\n+        final RecordingLevel recordingLevel = RecordingLevel.INFO;\n+        setupGetNewSensorTest(metrics, recordingLevel);\n+        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n+\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n+            SENSOR_NAME_1,\n+            recordingLevel\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMzOTI3Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(0));\n          \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(1));\n          \n          \n            \n            \n          \n          \n            \n                    expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    replay(metrics);\n          \n          \n            \n            \n          \n          \n            \n                    streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n          \n          \n            \n                    verify(metrics);\n          \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(0));\n          \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(1));\n          \n          \n            \n                    expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    replay(metrics);\n          \n          \n            \n            \n          \n          \n            \n                    streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n          \n          \n            \n            \n          \n          \n            \n                    verify(metrics);", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529339272", "createdAt": "2020-11-24T09:24:34Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,17 +663,20 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n \n-        streamsMetrics.removeAllClientLevelMetrics();\n+        metrics.removeSensor(sensorKeys.getValues().get(0));\n+        metrics.removeSensor(sensorKeys.getValues().get(1));\n+\n+        expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n+        expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n+        replay(metrics);\n \n+        streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n         verify(metrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMzOTU4Mg==", "bodyText": "Please remove this empty line.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529339582", "createdAt": "2020-11-24T09:24:48Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,17 +663,20 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM0MDk3Ng==", "bodyText": "Please remove empty line.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529340976", "createdAt": "2020-11-24T09:25:52Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java", "diffHunk": "@@ -99,6 +121,29 @@ public void shouldAddAliveStreamThreadsMetric() {\n         );\n     }\n \n+    @Test\n+    public void shouldGetFailedStreamThreadsSensor() {\n+        final String name = \"failed-stream-threads\";\n+        final String description = \"The number of failed stream threads since the start of the Kafka Streams client\";\n+        expect(streamsMetrics.clientLevelSensor(name, RecordingLevel.INFO)).andReturn(expectedSensor);\n+        expect(streamsMetrics.clientLevelTagMap()).andReturn(tagMap);\n+        StreamsMetricsImpl.addSumMetricToSensor(\n+            expectedSensor,\n+            CLIENT_LEVEL_GROUP,\n+            tagMap,\n+            name,\n+            false,\n+            description\n+        );\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM2Mzc5Ng==", "bodyText": "You can remove these lines. They are dead code.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529363796", "createdAt": "2020-11-24T09:44:03Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }\n+\n+    public void verifyFailedStreamThread(final boolean shouldFail) {\n+        final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n+        final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n+        final StreamsMetricsImpl streamsMetrics =\n+            new StreamsMetricsImpl(metrics, CLIENT_ID, StreamsConfig.METRICS_LATEST, mockTime);\n+        final StreamThread thread = new StreamThread(\n+            mockTime,\n+            config,\n+            null,\n+            consumer,\n+            consumer,\n+            null,\n+            null,\n+            taskManager,\n+            streamsMetrics,\n+            internalTopologyBuilder,\n+            CLIENT_ID,\n+            new LogContext(\"\"),\n+            new AtomicInteger(),\n+            new AtomicLong(Long.MAX_VALUE),\n+            null,\n+            e -> { }\n+        ) {\n+            @Override\n+            void runOnce() {\n+                setState(StreamThread.State.PENDING_SHUTDOWN);\n+                if (shouldFail) {\n+                    throw new StreamsException(Thread.currentThread().getName());\n+                }\n+            }\n+        };\n+        expect(taskManager.activeTaskMap()).andReturn(Collections.emptyMap());\n+        expect(taskManager.standbyTaskMap()).andReturn(Collections.emptyMap());\n+\n+        taskManager.process(anyInt(), anyObject());\n+        EasyMock.expectLastCall().andThrow(new StreamsException(Thread.currentThread().getName()));\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM2OTMxMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                    EasyMock.replay(taskManager);\n          \n          \n            \n            \n          \n          \n            \n                    thread.updateThreadMetadata(\"metadata\");\n          \n          \n            \n                    thread.setState(StreamThread.State.STARTING);\n          \n          \n            \n                    thread.runLoop();\n          \n          \n            \n            \n          \n          \n            \n                    final Metric failedThreads = StreamsTestUtils.getMetricByName(metrics.metrics(), \"failed-stream-threads\", \"stream-metrics\");\n          \n          \n            \n            \n          \n          \n            \n                    assertEquals(shouldFail ? 1.0 : 0.0, failedThreads.metricValue());\n          \n          \n            \n                    EasyMock.replay(taskManager);\n          \n          \n            \n                    thread.updateThreadMetadata(\"metadata\");\n          \n          \n            \n                    thread.setState(StreamThread.State.STARTING);\n          \n          \n            \n                    \n          \n          \n            \n                    thread.runLoop();\n          \n          \n            \n            \n          \n          \n            \n                    final Metric failedThreads = StreamsTestUtils.getMetricByName(metrics.metrics(), \"failed-stream-threads\", \"stream-metrics\");\n          \n          \n            \n                    assertThat(failedThreads.metricValue(), is(shouldFail ? 1.0 : 0.0));", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529369313", "createdAt": "2020-11-24T09:48:30Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }\n+\n+    public void verifyFailedStreamThread(final boolean shouldFail) {\n+        final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n+        final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n+        final StreamsMetricsImpl streamsMetrics =\n+            new StreamsMetricsImpl(metrics, CLIENT_ID, StreamsConfig.METRICS_LATEST, mockTime);\n+        final StreamThread thread = new StreamThread(\n+            mockTime,\n+            config,\n+            null,\n+            consumer,\n+            consumer,\n+            null,\n+            null,\n+            taskManager,\n+            streamsMetrics,\n+            internalTopologyBuilder,\n+            CLIENT_ID,\n+            new LogContext(\"\"),\n+            new AtomicInteger(),\n+            new AtomicLong(Long.MAX_VALUE),\n+            null,\n+            e -> { }\n+        ) {\n+            @Override\n+            void runOnce() {\n+                setState(StreamThread.State.PENDING_SHUTDOWN);\n+                if (shouldFail) {\n+                    throw new StreamsException(Thread.currentThread().getName());\n+                }\n+            }\n+        };\n+        expect(taskManager.activeTaskMap()).andReturn(Collections.emptyMap());\n+        expect(taskManager.standbyTaskMap()).andReturn(Collections.emptyMap());\n+\n+        taskManager.process(anyInt(), anyObject());\n+        EasyMock.expectLastCall().andThrow(new StreamsException(Thread.currentThread().getName()));\n+\n+        EasyMock.replay(taskManager);\n+\n+        thread.updateThreadMetadata(\"metadata\");\n+        thread.setState(StreamThread.State.STARTING);\n+        thread.runLoop();\n+\n+        final Metric failedThreads = StreamsTestUtils.getMetricByName(metrics.metrics(), \"failed-stream-threads\", \"stream-metrics\");\n+\n+        assertEquals(shouldFail ? 1.0 : 0.0, failedThreads.metricValue());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NDM2Mg==", "bodyText": "I would rename this method to runAndVerifyFailedStreamThreadRecording().", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529384362", "createdAt": "2020-11-24T09:59:55Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }\n+\n+    public void verifyFailedStreamThread(final boolean shouldFail) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NDY5Nw==", "bodyText": "Could you please specify two separate unit tests? One could be named shouldRecordFailedStreamThread() and the other shouldNotRecordFailedStreamThread().", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529384697", "createdAt": "2020-11-24T10:00:15Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 24}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8", "author": {"user": {"login": "lct45", "name": "leah"}}, "url": "https://github.com/apache/kafka/commit/e395ba706e59f13af996c83177e5846878adb3e8", "committedDate": "2020-11-24T15:51:08Z", "message": "Review clean up"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3ODY5NDY3", "url": "https://github.com/apache/kafka/pull/9614#pullrequestreview-537869467", "createdAt": "2020-11-24T20:14:43Z", "commit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxNDI4Mjcz", "url": "https://github.com/apache/kafka/pull/9614#pullrequestreview-541428273", "createdAt": "2020-12-01T01:44:44Z", "commit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo0NDo0NFrOH8U17Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjowMDo0MFrOH8VKfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxODA5Mw==", "bodyText": "nit: missing empty line", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533018093", "createdAt": "2020-12-01T01:44:44Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java", "diffHunk": "@@ -125,4 +131,16 @@ public static void addNumAliveStreamThreadMetric(final StreamsMetricsImpl stream\n             stateProvider\n         );\n     }\n+    public static Sensor failedStreamThreadSensor(final StreamsMetricsImpl streamsMetrics) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ==", "bodyText": "Should we rewrite this the same way threadLevelSensor is written (ie, using orElseGet) for consistency?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533020449", "createdAt": "2020-12-01T01:51:48Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMzM1Nw==", "bodyText": "Why did we change this from andStubReturn(null) to andReturn(mock(KafkaMetric.class))?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533023357", "createdAt": "2020-12-01T02:00:40Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,16 +657,18 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n \n-        streamsMetrics.removeAllClientLevelMetrics();\n+        metrics.removeSensor(sensorKeys.getValues().get(0));\n+        metrics.removeSensor(sensorKeys.getValues().get(1));\n+        expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n+        expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 72}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc6cf529d9e4becb5871913a34711a37dd6916dc", "author": {"user": {"login": "lct45", "name": "leah"}}, "url": "https://github.com/apache/kafka/commit/fc6cf529d9e4becb5871913a34711a37dd6916dc", "committedDate": "2020-12-01T17:17:06Z", "message": "Fixes from Matthias's comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTI2OTY5", "url": "https://github.com/apache/kafka/pull/9614#pullrequestreview-542126969", "createdAt": "2020-12-01T17:20:30Z", "commit": {"oid": "fc6cf529d9e4becb5871913a34711a37dd6916dc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzoyMDozMFrOH83ilg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzoyMDozMFrOH83ilg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU4NjU4Mg==", "bodyText": "This wasn't being used so I went ahead and took it out", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533586582", "createdAt": "2020-12-01T17:20:30Z", "author": {"login": "lct45"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -619,8 +647,7 @@ public void shouldProvideCorrectStrings() {\n     }\n \n     private void setupRemoveSensorsTest(final Metrics metrics,\n-                                        final String level,\n-                                        final RecordingLevel recordingLevel) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc6cf529d9e4becb5871913a34711a37dd6916dc"}, "originalPosition": 58}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c5df6eb31efe029519f633de1cded887306edb29", "author": {"user": {"login": "lct45", "name": "leah"}}, "url": "https://github.com/apache/kafka/commit/c5df6eb31efe029519f633de1cded887306edb29", "committedDate": "2020-12-02T15:27:37Z", "message": "updated consistency"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ0MzAxNDY4", "url": "https://github.com/apache/kafka/pull/9614#pullrequestreview-544301468", "createdAt": "2020-12-03T19:18:42Z", "commit": {"oid": "c5df6eb31efe029519f633de1cded887306edb29"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2808, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}