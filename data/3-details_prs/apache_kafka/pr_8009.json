{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY4MDAzMzgy", "number": 8009, "title": "KAFKA-9308: Reworded the ssl part of the security documentation ", "bodyText": "This is to fix various issues (mainly as noted by this jira, the problem that SAN extension values are not copied to certificates) and add some recommendations.\nBuild the page and reviewed it, used Intellij HTML syntax checker to ensure valid HTML syntax.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-01-28T13:06:24Z", "url": "https://github.com/apache/kafka/pull/8009", "merged": true, "mergeCommit": {"oid": "30ab2297f1697f9aee048283fb2cf307e3f4f4be"}, "closed": true, "closedAt": "2020-02-25T16:24:03Z", "author": {"login": "soenkeliebau"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb-xBMQgH2gAyMzY4MDAzMzgyOjg5OTA0ZTJjMzE3ZTZhMDVjMjViYzNjYTI4NDZhYjZlYTcwNWVjMjU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcH0od6gFqTM2NDI4MDY3Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "89904e2c317e6a05c25bc3ca2846ab6ea705ec25", "author": {"user": {"login": "soenkeliebau", "name": "S\u00f6nke Liebau"}}, "url": "https://github.com/apache/kafka/commit/89904e2c317e6a05c25bc3ca2846ab6ea705ec25", "committedDate": "2020-01-28T13:04:53Z", "message": "KAFKA-9308: Reworded the ssl part of the security documentation to fix various issues (mainly as noted by this jira, the problem that SAN extension values are not copied to certificates) and add some recommendations."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYzMzMwNzI1", "url": "https://github.com/apache/kafka/pull/8009#pullrequestreview-363330725", "createdAt": "2020-02-24T11:43:17Z", "commit": {"oid": "89904e2c317e6a05c25bc3ca2846ab6ea705ec25"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMTo0MzoxN1rOFtd0WA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMTo1ODo1OVrOFteNtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIxODc3Ng==", "bodyText": "Are we missing spaces around -?", "url": "https://github.com/apache/kafka/pull/8009#discussion_r383218776", "createdAt": "2020-02-24T11:43:17Z", "author": {"login": "mimaison"}, "path": "docs/security.html", "diffHunk": "@@ -37,114 +37,291 @@ <h3><a id=\"security_overview\" href=\"#security_overview\">7.1 Security Overview</a\n     The guides below explain how to configure and use the security features in both clients and brokers.\n \n     <h3><a id=\"security_ssl\" href=\"#security_ssl\">7.2 Encryption and Authentication using SSL</a></h3>\n-    Apache Kafka allows clients to connect over SSL. By default, SSL is disabled but can be turned on as needed.\n+    Apache Kafka allows clients to use SSL for encryption of traffic as well as authentication. By default, SSL is disabled but can be turned on if needed.\n+    The following paragraphs explain in detail how to set up your own PKI infrastructure, use it to create certificates and configure Kafka to use these.\n \n     <ol>\n         <li><h4><a id=\"security_ssl_key\" href=\"#security_ssl_key\">Generate SSL key and certificate for each Kafka broker</a></h4>\n-            The first step of deploying one or more brokers with the SSL support is to generate the key and the certificate for each machine in the cluster. You can use Java's keytool utility to accomplish this task.\n-            We will generate the key into a temporary keystore initially so that we can export and sign it later with CA.\n+            The first step of deploying one or more brokers with SSL support is to generate a public/private keypair for every server.\n+            Since Kafka expects all keys and certificates to be stored in keystores we will use Java's keytool command for this task.\n+            The tool supports two different keystore formats, the Java specific jks format which has been deprecated by now, as well as PKCS12.\n+            PKCS12 is the default format as of Java version 9, to ensure this format is being used regardless of the Java version in use all following\n+            commands explicitly specify the PKCS12 format.\n             <pre class=\"brush: bash;\">\n-            keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA</pre>\n-\n+                keytool -keystore {keystorefile} -alias localhost -validity {validity} -genkey -keyalg RSA -storetype pkcs12\n+            </pre>\n             You need to specify two parameters in the above command:\n             <ol>\n-                <li>keystore: the keystore file that stores the certificate. The keystore file contains the private key of the certificate; therefore, it needs to be kept safely.</li>\n-                <li>validity: the valid time of the certificate in days.</li>\n-            </ol>\n-            <br>\n-\n-        <h5><a id=\"security_confighostname\" href=\"#security_confighostname\">Configuring Host Name Verification</a></h5>\n-        From Kafka version 2.0.0 onwards, host name verification of servers is enabled by default for client connections\n-        as well as inter-broker connections to prevent man-in-the-middle attacks. Server host name verification may be disabled\n-        by setting <code>ssl.endpoint.identification.algorithm</code> to an empty string. For example,\n-        <pre class=\"brush: text;\">\tssl.endpoint.identification.algorithm=</pre>\n-        For dynamically configured broker listeners, hostname verification may be disabled using <code>kafka-configs.sh</code>.\n-        For example,\n-        <pre class=\"brush: text;\">\n-        bin/kafka-configs.sh --bootstrap-server localhost:9093 --entity-type brokers --entity-name 0 --alter --add-config \"listener.name.internal.ssl.endpoint.identification.algorithm=\"\n-        </pre>\n+                <li>keystorefile: the keystore file that stores the keys (and later the certificate) for this broker. The keystore file contains the private\n+                    and public keys of this broker, therefore it needs to be kept safe. Ideally this step is run on the Kafka broker that the key will be\n+                    used on, as this key should never be transmitted/leave the server that it is intended for.</li>\n+                <li>validity: the valid time of the key in days. Please note that this differs from the validity period for the certificate, which\n+                    will be determined in <a href =\"#security_ssl_signing\">Signing the certificate</a>. You can use the same key to request multiple\n+                    certificates: if your key has a validity of 10 years, but your CA will only sign certificates that are valid for one year, you\n+                    can use the same key with 10 certificates over time.</li>\n+            </ol><br>\n+            To obtain a certificate that can be used with the private key that was just created a certificate signing request needs to be created. This\n+            signing request, when signed by a trusted CA results in the actual certificate which can then be installed in the keystore and used for\n+            authentication purposes.<br>\n+            To generate certificate signing requests run the following command for all server keystores created so far.\n \n-        For older versions of Kafka, <code>ssl.endpoint.identification.algorithm</code> is not defined by default, so host name\n-        verification is not performed. The property should be set to <code>HTTPS</code> to enable host name verification.\n+            <pre class=\"brush: bash;\">\n+                keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -destkeystoretype pkcs12 -ext SAN=DNS:{FQDN},IP:{IPADDRESS1}\n+            </pre>\n+            This command assumes that you want to add hostname information to the certificate, if this is not the case, you can omit the extension parameter <code>-ext SAN=DNS:{FQDN},IP:{IPADDRESS1}</code>. Please see below for more information on this.\n \n-        <pre class=\"brush: text;\">\tssl.endpoint.identification.algorithm=HTTPS </pre>\n+            <h5>Host Name Verification</h5>\n+            Host name verification, when enabled, is the process of checking attributes from the certificate that is presented by the server you are\n+            connecting to against the actual hostname or ip address of that server to ensure that you are indeed connecting to the correct server.<br>\n+            The main reason for this check is to prevent man-in-the-middle attacks.\n \n-        Host name verification must be enabled to prevent man-in-the-middle attacks if server endpoints are not validated\n-        externally.\n+            For Kafka, this check has been disabled by default for a long time, but as of Kafka 2.0.0 host name verification of servers is enabled by default\n+            for client connections as well as inter-broker connections.<br>\n+            Server host name verification may be disabled by setting <code>ssl.endpoint.identification.algorithm</code> to an empty string.<br>\n+            For dynamically configured broker listeners, hostname verification may be disabled using <code>kafka-configs.sh</code>:<br>\n \n-        <h5><a id=\"security_configcerthostname\" href=\"#security_configcerthstname\">Configuring Host Name In Certificates</a></h5>\n-        If host name verification is enabled, clients will verify the server's fully qualified domain name (FQDN) against one of\n-        the following two fields:\n-        <ol>\n-            <li>Common Name (CN)\n-            <li>Subject Alternative Name (SAN)\n-        </ol>\n-        <br>\n-        Both fields are valid, RFC-2818 recommends the use of SAN however. SAN is also more flexible, allowing for multiple DNS entries to be declared. Another advantage is that the CN can be set to a more meaningful value for authorization purposes. To add a SAN field  append the following argument <code> -ext SAN=DNS:{FQDN} </code> to the keytool command:\n-        <pre class=\"brush: bash;\">\n-        keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -ext SAN=DNS:{FQDN}\n-        </pre>\n-        The following command can be run afterwards to verify the contents of the generated certificate:\n-        <pre class=\"brush: bash;\">\n-        keytool -list -v -keystore server.keystore.jks\n-        </pre>\n+            <pre class=\"brush: text;\">\n+                bin/kafka-configs.sh --bootstrap-server localhost:9093 --entity-type brokers --entity-name 0 --alter --add-config \"listener.name.internal.ssl.endpoint.identification.algorithm=\"\n+            </pre>\n+\n+            <p><b>Note:</b></p>\n+            Normally there is no good reason to disable hostname verification apart from being the quickest way to \"just get it to work\" followed\n+            by the promise to \"fix it later when there is more time\"!<br>\n+            Getting hostname verification right is not that hard when done at the right time, but gets much harder once the cluster is up and\n+            running - do yourself a favor and do it now!\n+\n+\n+            <p>If host name verification is enabled, clients will verify the server's fully qualified domain name (FQDN) or ip address against one of the following two fields:\n+            <ol>\n+                <li>Common Name (CN)</li>\n+                <li><a href=\"https://tools.ietf.org/html/rfc5280#section-4.2.1.6\">Subject Alternative Name (SAN)</a></li>\n+            </ol><br>\n+            While Kafka checks both fields, usage of the common name field for hostname verification has been\n+            <a href=\"https://tools.ietf.org/html/rfc2818#section-3.1\">deprecated</a> since 2000 and should be avoided if possible. In addition the\n+            SAN field is much more flexible, allowing for multiple DNS and IP entries to be declared in a certificate.<br>\n+            Another advantage is that if the SAN field is used for hostname verification the common name can be set to a more meaningful value for\n+            authorization purposes. Since we need the SAN field to be contained in the signed certificate, it will be specified when generating the\n+            signing request. It can also be specified when generating the keypair, but this will not automatically be copied into the signing request.<br>\n+\n+\n+            To add a SAN field append the following argument <code> -ext SAN=DNS:{FQDN},IP:{IPADDRESS} </code> to the keytool command:\n+            <pre class=\"brush: bash;\">\n+                keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -destkeystoretype pkcs12 -ext SAN=DNS:{FQDN},IP:{IPADDRESS1}\n+            </pre>\n         </li>\n+\n         <li><h4><a id=\"security_ssl_ca\" href=\"#security_ssl_ca\">Creating your own CA</a></h4>\n-            After the first step, each machine in the cluster has a public-private key pair, and a certificate to identify the machine. The certificate, however, is unsigned, which means that an attacker can create such a certificate to pretend to be any machine.<p>\n-            Therefore, it is important to prevent forged certificates by signing them for each machine in the cluster. A certificate authority (CA) is responsible for signing certificates. CA works likes a government that issues passports\u2014the government stamps (signs) each passport so that the passport becomes difficult to forge. Other governments verify the stamps to ensure the passport is authentic. Similarly, the CA signs the certificates, and the cryptography guarantees that a signed certificate is computationally difficult to forge. Thus, as long as the CA is a genuine and trusted authority, the clients have high assurance that they are connecting to the authentic machines.\n-            <pre class=\"brush: bash;\">\n-            openssl req -new -x509 -keyout ca-key -out ca-cert -days 365</pre>\n+            After this step each machine in the cluster has a public/private key pair which can already be used to encrypt traffic and a certificate\n+            signing request, which is the basis for creating a certificate. To add authentication capabilities this signing request needs to be signed\n+            by a trusted authority, which will be created in this step.\n+\n+            <p>A certificate authority (CA) is responsible for signing certificates. CAs works likes a government that issues passports\u2014the government", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89904e2c317e6a05c25bc3ca2846ab6ea705ec25"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIxOTUyOQ==", "bodyText": "I feel like breaking this sentence in two would make it easier to read.", "url": "https://github.com/apache/kafka/pull/8009#discussion_r383219529", "createdAt": "2020-02-24T11:45:13Z", "author": {"login": "mimaison"}, "path": "docs/security.html", "diffHunk": "@@ -37,114 +37,291 @@ <h3><a id=\"security_overview\" href=\"#security_overview\">7.1 Security Overview</a\n     The guides below explain how to configure and use the security features in both clients and brokers.\n \n     <h3><a id=\"security_ssl\" href=\"#security_ssl\">7.2 Encryption and Authentication using SSL</a></h3>\n-    Apache Kafka allows clients to connect over SSL. By default, SSL is disabled but can be turned on as needed.\n+    Apache Kafka allows clients to use SSL for encryption of traffic as well as authentication. By default, SSL is disabled but can be turned on if needed.\n+    The following paragraphs explain in detail how to set up your own PKI infrastructure, use it to create certificates and configure Kafka to use these.\n \n     <ol>\n         <li><h4><a id=\"security_ssl_key\" href=\"#security_ssl_key\">Generate SSL key and certificate for each Kafka broker</a></h4>\n-            The first step of deploying one or more brokers with the SSL support is to generate the key and the certificate for each machine in the cluster. You can use Java's keytool utility to accomplish this task.\n-            We will generate the key into a temporary keystore initially so that we can export and sign it later with CA.\n+            The first step of deploying one or more brokers with SSL support is to generate a public/private keypair for every server.\n+            Since Kafka expects all keys and certificates to be stored in keystores we will use Java's keytool command for this task.\n+            The tool supports two different keystore formats, the Java specific jks format which has been deprecated by now, as well as PKCS12.\n+            PKCS12 is the default format as of Java version 9, to ensure this format is being used regardless of the Java version in use all following\n+            commands explicitly specify the PKCS12 format.\n             <pre class=\"brush: bash;\">\n-            keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA</pre>\n-\n+                keytool -keystore {keystorefile} -alias localhost -validity {validity} -genkey -keyalg RSA -storetype pkcs12\n+            </pre>\n             You need to specify two parameters in the above command:\n             <ol>\n-                <li>keystore: the keystore file that stores the certificate. The keystore file contains the private key of the certificate; therefore, it needs to be kept safely.</li>\n-                <li>validity: the valid time of the certificate in days.</li>\n-            </ol>\n-            <br>\n-\n-        <h5><a id=\"security_confighostname\" href=\"#security_confighostname\">Configuring Host Name Verification</a></h5>\n-        From Kafka version 2.0.0 onwards, host name verification of servers is enabled by default for client connections\n-        as well as inter-broker connections to prevent man-in-the-middle attacks. Server host name verification may be disabled\n-        by setting <code>ssl.endpoint.identification.algorithm</code> to an empty string. For example,\n-        <pre class=\"brush: text;\">\tssl.endpoint.identification.algorithm=</pre>\n-        For dynamically configured broker listeners, hostname verification may be disabled using <code>kafka-configs.sh</code>.\n-        For example,\n-        <pre class=\"brush: text;\">\n-        bin/kafka-configs.sh --bootstrap-server localhost:9093 --entity-type brokers --entity-name 0 --alter --add-config \"listener.name.internal.ssl.endpoint.identification.algorithm=\"\n-        </pre>\n+                <li>keystorefile: the keystore file that stores the keys (and later the certificate) for this broker. The keystore file contains the private\n+                    and public keys of this broker, therefore it needs to be kept safe. Ideally this step is run on the Kafka broker that the key will be\n+                    used on, as this key should never be transmitted/leave the server that it is intended for.</li>\n+                <li>validity: the valid time of the key in days. Please note that this differs from the validity period for the certificate, which\n+                    will be determined in <a href =\"#security_ssl_signing\">Signing the certificate</a>. You can use the same key to request multiple\n+                    certificates: if your key has a validity of 10 years, but your CA will only sign certificates that are valid for one year, you\n+                    can use the same key with 10 certificates over time.</li>\n+            </ol><br>\n+            To obtain a certificate that can be used with the private key that was just created a certificate signing request needs to be created. This\n+            signing request, when signed by a trusted CA results in the actual certificate which can then be installed in the keystore and used for\n+            authentication purposes.<br>\n+            To generate certificate signing requests run the following command for all server keystores created so far.\n \n-        For older versions of Kafka, <code>ssl.endpoint.identification.algorithm</code> is not defined by default, so host name\n-        verification is not performed. The property should be set to <code>HTTPS</code> to enable host name verification.\n+            <pre class=\"brush: bash;\">\n+                keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -destkeystoretype pkcs12 -ext SAN=DNS:{FQDN},IP:{IPADDRESS1}\n+            </pre>\n+            This command assumes that you want to add hostname information to the certificate, if this is not the case, you can omit the extension parameter <code>-ext SAN=DNS:{FQDN},IP:{IPADDRESS1}</code>. Please see below for more information on this.\n \n-        <pre class=\"brush: text;\">\tssl.endpoint.identification.algorithm=HTTPS </pre>\n+            <h5>Host Name Verification</h5>\n+            Host name verification, when enabled, is the process of checking attributes from the certificate that is presented by the server you are\n+            connecting to against the actual hostname or ip address of that server to ensure that you are indeed connecting to the correct server.<br>\n+            The main reason for this check is to prevent man-in-the-middle attacks.\n \n-        Host name verification must be enabled to prevent man-in-the-middle attacks if server endpoints are not validated\n-        externally.\n+            For Kafka, this check has been disabled by default for a long time, but as of Kafka 2.0.0 host name verification of servers is enabled by default\n+            for client connections as well as inter-broker connections.<br>\n+            Server host name verification may be disabled by setting <code>ssl.endpoint.identification.algorithm</code> to an empty string.<br>\n+            For dynamically configured broker listeners, hostname verification may be disabled using <code>kafka-configs.sh</code>:<br>\n \n-        <h5><a id=\"security_configcerthostname\" href=\"#security_configcerthstname\">Configuring Host Name In Certificates</a></h5>\n-        If host name verification is enabled, clients will verify the server's fully qualified domain name (FQDN) against one of\n-        the following two fields:\n-        <ol>\n-            <li>Common Name (CN)\n-            <li>Subject Alternative Name (SAN)\n-        </ol>\n-        <br>\n-        Both fields are valid, RFC-2818 recommends the use of SAN however. SAN is also more flexible, allowing for multiple DNS entries to be declared. Another advantage is that the CN can be set to a more meaningful value for authorization purposes. To add a SAN field  append the following argument <code> -ext SAN=DNS:{FQDN} </code> to the keytool command:\n-        <pre class=\"brush: bash;\">\n-        keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -ext SAN=DNS:{FQDN}\n-        </pre>\n-        The following command can be run afterwards to verify the contents of the generated certificate:\n-        <pre class=\"brush: bash;\">\n-        keytool -list -v -keystore server.keystore.jks\n-        </pre>\n+            <pre class=\"brush: text;\">\n+                bin/kafka-configs.sh --bootstrap-server localhost:9093 --entity-type brokers --entity-name 0 --alter --add-config \"listener.name.internal.ssl.endpoint.identification.algorithm=\"\n+            </pre>\n+\n+            <p><b>Note:</b></p>\n+            Normally there is no good reason to disable hostname verification apart from being the quickest way to \"just get it to work\" followed\n+            by the promise to \"fix it later when there is more time\"!<br>\n+            Getting hostname verification right is not that hard when done at the right time, but gets much harder once the cluster is up and\n+            running - do yourself a favor and do it now!\n+\n+\n+            <p>If host name verification is enabled, clients will verify the server's fully qualified domain name (FQDN) or ip address against one of the following two fields:\n+            <ol>\n+                <li>Common Name (CN)</li>\n+                <li><a href=\"https://tools.ietf.org/html/rfc5280#section-4.2.1.6\">Subject Alternative Name (SAN)</a></li>\n+            </ol><br>\n+            While Kafka checks both fields, usage of the common name field for hostname verification has been\n+            <a href=\"https://tools.ietf.org/html/rfc2818#section-3.1\">deprecated</a> since 2000 and should be avoided if possible. In addition the\n+            SAN field is much more flexible, allowing for multiple DNS and IP entries to be declared in a certificate.<br>\n+            Another advantage is that if the SAN field is used for hostname verification the common name can be set to a more meaningful value for\n+            authorization purposes. Since we need the SAN field to be contained in the signed certificate, it will be specified when generating the\n+            signing request. It can also be specified when generating the keypair, but this will not automatically be copied into the signing request.<br>\n+\n+\n+            To add a SAN field append the following argument <code> -ext SAN=DNS:{FQDN},IP:{IPADDRESS} </code> to the keytool command:\n+            <pre class=\"brush: bash;\">\n+                keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -destkeystoretype pkcs12 -ext SAN=DNS:{FQDN},IP:{IPADDRESS1}\n+            </pre>\n         </li>\n+\n         <li><h4><a id=\"security_ssl_ca\" href=\"#security_ssl_ca\">Creating your own CA</a></h4>\n-            After the first step, each machine in the cluster has a public-private key pair, and a certificate to identify the machine. The certificate, however, is unsigned, which means that an attacker can create such a certificate to pretend to be any machine.<p>\n-            Therefore, it is important to prevent forged certificates by signing them for each machine in the cluster. A certificate authority (CA) is responsible for signing certificates. CA works likes a government that issues passports\u2014the government stamps (signs) each passport so that the passport becomes difficult to forge. Other governments verify the stamps to ensure the passport is authentic. Similarly, the CA signs the certificates, and the cryptography guarantees that a signed certificate is computationally difficult to forge. Thus, as long as the CA is a genuine and trusted authority, the clients have high assurance that they are connecting to the authentic machines.\n-            <pre class=\"brush: bash;\">\n-            openssl req -new -x509 -keyout ca-key -out ca-cert -days 365</pre>\n+            After this step each machine in the cluster has a public/private key pair which can already be used to encrypt traffic and a certificate\n+            signing request, which is the basis for creating a certificate. To add authentication capabilities this signing request needs to be signed\n+            by a trusted authority, which will be created in this step.\n+\n+            <p>A certificate authority (CA) is responsible for signing certificates. CAs works likes a government that issues passports\u2014the government\n+            stamps (signs) each passport so that the passport becomes difficult to forge. Other governments verify the stamps to ensure the passport is\n+            authentic. Similarly, the CA signs the certificates, and the cryptography guarantees that a signed certificate is computationally difficult to\n+            forge. Thus, as long as the CA is a genuine and trusted authority, the clients have a strong assurance that they are connecting to the authentic\n+            machines.\n+\n+            <p>For this guide we will be our own Certificate Authority, when setting up a production cluster in a corporate environment these certificates would", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89904e2c317e6a05c25bc3ca2846ab6ea705ec25"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIxOTk3Ng==", "bodyText": "Can we add a comma after OpenSSL?", "url": "https://github.com/apache/kafka/pull/8009#discussion_r383219976", "createdAt": "2020-02-24T11:46:20Z", "author": {"login": "mimaison"}, "path": "docs/security.html", "diffHunk": "@@ -37,114 +37,291 @@ <h3><a id=\"security_overview\" href=\"#security_overview\">7.1 Security Overview</a\n     The guides below explain how to configure and use the security features in both clients and brokers.\n \n     <h3><a id=\"security_ssl\" href=\"#security_ssl\">7.2 Encryption and Authentication using SSL</a></h3>\n-    Apache Kafka allows clients to connect over SSL. By default, SSL is disabled but can be turned on as needed.\n+    Apache Kafka allows clients to use SSL for encryption of traffic as well as authentication. By default, SSL is disabled but can be turned on if needed.\n+    The following paragraphs explain in detail how to set up your own PKI infrastructure, use it to create certificates and configure Kafka to use these.\n \n     <ol>\n         <li><h4><a id=\"security_ssl_key\" href=\"#security_ssl_key\">Generate SSL key and certificate for each Kafka broker</a></h4>\n-            The first step of deploying one or more brokers with the SSL support is to generate the key and the certificate for each machine in the cluster. You can use Java's keytool utility to accomplish this task.\n-            We will generate the key into a temporary keystore initially so that we can export and sign it later with CA.\n+            The first step of deploying one or more brokers with SSL support is to generate a public/private keypair for every server.\n+            Since Kafka expects all keys and certificates to be stored in keystores we will use Java's keytool command for this task.\n+            The tool supports two different keystore formats, the Java specific jks format which has been deprecated by now, as well as PKCS12.\n+            PKCS12 is the default format as of Java version 9, to ensure this format is being used regardless of the Java version in use all following\n+            commands explicitly specify the PKCS12 format.\n             <pre class=\"brush: bash;\">\n-            keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA</pre>\n-\n+                keytool -keystore {keystorefile} -alias localhost -validity {validity} -genkey -keyalg RSA -storetype pkcs12\n+            </pre>\n             You need to specify two parameters in the above command:\n             <ol>\n-                <li>keystore: the keystore file that stores the certificate. The keystore file contains the private key of the certificate; therefore, it needs to be kept safely.</li>\n-                <li>validity: the valid time of the certificate in days.</li>\n-            </ol>\n-            <br>\n-\n-        <h5><a id=\"security_confighostname\" href=\"#security_confighostname\">Configuring Host Name Verification</a></h5>\n-        From Kafka version 2.0.0 onwards, host name verification of servers is enabled by default for client connections\n-        as well as inter-broker connections to prevent man-in-the-middle attacks. Server host name verification may be disabled\n-        by setting <code>ssl.endpoint.identification.algorithm</code> to an empty string. For example,\n-        <pre class=\"brush: text;\">\tssl.endpoint.identification.algorithm=</pre>\n-        For dynamically configured broker listeners, hostname verification may be disabled using <code>kafka-configs.sh</code>.\n-        For example,\n-        <pre class=\"brush: text;\">\n-        bin/kafka-configs.sh --bootstrap-server localhost:9093 --entity-type brokers --entity-name 0 --alter --add-config \"listener.name.internal.ssl.endpoint.identification.algorithm=\"\n-        </pre>\n+                <li>keystorefile: the keystore file that stores the keys (and later the certificate) for this broker. The keystore file contains the private\n+                    and public keys of this broker, therefore it needs to be kept safe. Ideally this step is run on the Kafka broker that the key will be\n+                    used on, as this key should never be transmitted/leave the server that it is intended for.</li>\n+                <li>validity: the valid time of the key in days. Please note that this differs from the validity period for the certificate, which\n+                    will be determined in <a href =\"#security_ssl_signing\">Signing the certificate</a>. You can use the same key to request multiple\n+                    certificates: if your key has a validity of 10 years, but your CA will only sign certificates that are valid for one year, you\n+                    can use the same key with 10 certificates over time.</li>\n+            </ol><br>\n+            To obtain a certificate that can be used with the private key that was just created a certificate signing request needs to be created. This\n+            signing request, when signed by a trusted CA results in the actual certificate which can then be installed in the keystore and used for\n+            authentication purposes.<br>\n+            To generate certificate signing requests run the following command for all server keystores created so far.\n \n-        For older versions of Kafka, <code>ssl.endpoint.identification.algorithm</code> is not defined by default, so host name\n-        verification is not performed. The property should be set to <code>HTTPS</code> to enable host name verification.\n+            <pre class=\"brush: bash;\">\n+                keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -destkeystoretype pkcs12 -ext SAN=DNS:{FQDN},IP:{IPADDRESS1}\n+            </pre>\n+            This command assumes that you want to add hostname information to the certificate, if this is not the case, you can omit the extension parameter <code>-ext SAN=DNS:{FQDN},IP:{IPADDRESS1}</code>. Please see below for more information on this.\n \n-        <pre class=\"brush: text;\">\tssl.endpoint.identification.algorithm=HTTPS </pre>\n+            <h5>Host Name Verification</h5>\n+            Host name verification, when enabled, is the process of checking attributes from the certificate that is presented by the server you are\n+            connecting to against the actual hostname or ip address of that server to ensure that you are indeed connecting to the correct server.<br>\n+            The main reason for this check is to prevent man-in-the-middle attacks.\n \n-        Host name verification must be enabled to prevent man-in-the-middle attacks if server endpoints are not validated\n-        externally.\n+            For Kafka, this check has been disabled by default for a long time, but as of Kafka 2.0.0 host name verification of servers is enabled by default\n+            for client connections as well as inter-broker connections.<br>\n+            Server host name verification may be disabled by setting <code>ssl.endpoint.identification.algorithm</code> to an empty string.<br>\n+            For dynamically configured broker listeners, hostname verification may be disabled using <code>kafka-configs.sh</code>:<br>\n \n-        <h5><a id=\"security_configcerthostname\" href=\"#security_configcerthstname\">Configuring Host Name In Certificates</a></h5>\n-        If host name verification is enabled, clients will verify the server's fully qualified domain name (FQDN) against one of\n-        the following two fields:\n-        <ol>\n-            <li>Common Name (CN)\n-            <li>Subject Alternative Name (SAN)\n-        </ol>\n-        <br>\n-        Both fields are valid, RFC-2818 recommends the use of SAN however. SAN is also more flexible, allowing for multiple DNS entries to be declared. Another advantage is that the CN can be set to a more meaningful value for authorization purposes. To add a SAN field  append the following argument <code> -ext SAN=DNS:{FQDN} </code> to the keytool command:\n-        <pre class=\"brush: bash;\">\n-        keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -ext SAN=DNS:{FQDN}\n-        </pre>\n-        The following command can be run afterwards to verify the contents of the generated certificate:\n-        <pre class=\"brush: bash;\">\n-        keytool -list -v -keystore server.keystore.jks\n-        </pre>\n+            <pre class=\"brush: text;\">\n+                bin/kafka-configs.sh --bootstrap-server localhost:9093 --entity-type brokers --entity-name 0 --alter --add-config \"listener.name.internal.ssl.endpoint.identification.algorithm=\"\n+            </pre>\n+\n+            <p><b>Note:</b></p>\n+            Normally there is no good reason to disable hostname verification apart from being the quickest way to \"just get it to work\" followed\n+            by the promise to \"fix it later when there is more time\"!<br>\n+            Getting hostname verification right is not that hard when done at the right time, but gets much harder once the cluster is up and\n+            running - do yourself a favor and do it now!\n+\n+\n+            <p>If host name verification is enabled, clients will verify the server's fully qualified domain name (FQDN) or ip address against one of the following two fields:\n+            <ol>\n+                <li>Common Name (CN)</li>\n+                <li><a href=\"https://tools.ietf.org/html/rfc5280#section-4.2.1.6\">Subject Alternative Name (SAN)</a></li>\n+            </ol><br>\n+            While Kafka checks both fields, usage of the common name field for hostname verification has been\n+            <a href=\"https://tools.ietf.org/html/rfc2818#section-3.1\">deprecated</a> since 2000 and should be avoided if possible. In addition the\n+            SAN field is much more flexible, allowing for multiple DNS and IP entries to be declared in a certificate.<br>\n+            Another advantage is that if the SAN field is used for hostname verification the common name can be set to a more meaningful value for\n+            authorization purposes. Since we need the SAN field to be contained in the signed certificate, it will be specified when generating the\n+            signing request. It can also be specified when generating the keypair, but this will not automatically be copied into the signing request.<br>\n+\n+\n+            To add a SAN field append the following argument <code> -ext SAN=DNS:{FQDN},IP:{IPADDRESS} </code> to the keytool command:\n+            <pre class=\"brush: bash;\">\n+                keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -destkeystoretype pkcs12 -ext SAN=DNS:{FQDN},IP:{IPADDRESS1}\n+            </pre>\n         </li>\n+\n         <li><h4><a id=\"security_ssl_ca\" href=\"#security_ssl_ca\">Creating your own CA</a></h4>\n-            After the first step, each machine in the cluster has a public-private key pair, and a certificate to identify the machine. The certificate, however, is unsigned, which means that an attacker can create such a certificate to pretend to be any machine.<p>\n-            Therefore, it is important to prevent forged certificates by signing them for each machine in the cluster. A certificate authority (CA) is responsible for signing certificates. CA works likes a government that issues passports\u2014the government stamps (signs) each passport so that the passport becomes difficult to forge. Other governments verify the stamps to ensure the passport is authentic. Similarly, the CA signs the certificates, and the cryptography guarantees that a signed certificate is computationally difficult to forge. Thus, as long as the CA is a genuine and trusted authority, the clients have high assurance that they are connecting to the authentic machines.\n-            <pre class=\"brush: bash;\">\n-            openssl req -new -x509 -keyout ca-key -out ca-cert -days 365</pre>\n+            After this step each machine in the cluster has a public/private key pair which can already be used to encrypt traffic and a certificate\n+            signing request, which is the basis for creating a certificate. To add authentication capabilities this signing request needs to be signed\n+            by a trusted authority, which will be created in this step.\n+\n+            <p>A certificate authority (CA) is responsible for signing certificates. CAs works likes a government that issues passports\u2014the government\n+            stamps (signs) each passport so that the passport becomes difficult to forge. Other governments verify the stamps to ensure the passport is\n+            authentic. Similarly, the CA signs the certificates, and the cryptography guarantees that a signed certificate is computationally difficult to\n+            forge. Thus, as long as the CA is a genuine and trusted authority, the clients have a strong assurance that they are connecting to the authentic\n+            machines.\n+\n+            <p>For this guide we will be our own Certificate Authority, when setting up a production cluster in a corporate environment these certificates would\n+            usually be signed by a corporate CA that is trusted throughout the company, please see <a href=\"#security_ssl_production\">Common Pitfalls in\n+            Production</a> for some things to consider for this case.\n+\n+            <p>Due to a <a href=\"https://www.openssl.org/docs/man1.1.1/man1/x509.html#BUGS\">bug</a> in OpenSSL the x509 module will not copy requested", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89904e2c317e6a05c25bc3ca2846ab6ea705ec25"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIyNTI3MA==", "bodyText": "I think in the instead of on the is more correct", "url": "https://github.com/apache/kafka/pull/8009#discussion_r383225270", "createdAt": "2020-02-24T11:58:59Z", "author": {"login": "mimaison"}, "path": "docs/security.html", "diffHunk": "@@ -37,114 +37,291 @@ <h3><a id=\"security_overview\" href=\"#security_overview\">7.1 Security Overview</a\n     The guides below explain how to configure and use the security features in both clients and brokers.\n \n     <h3><a id=\"security_ssl\" href=\"#security_ssl\">7.2 Encryption and Authentication using SSL</a></h3>\n-    Apache Kafka allows clients to connect over SSL. By default, SSL is disabled but can be turned on as needed.\n+    Apache Kafka allows clients to use SSL for encryption of traffic as well as authentication. By default, SSL is disabled but can be turned on if needed.\n+    The following paragraphs explain in detail how to set up your own PKI infrastructure, use it to create certificates and configure Kafka to use these.\n \n     <ol>\n         <li><h4><a id=\"security_ssl_key\" href=\"#security_ssl_key\">Generate SSL key and certificate for each Kafka broker</a></h4>\n-            The first step of deploying one or more brokers with the SSL support is to generate the key and the certificate for each machine in the cluster. You can use Java's keytool utility to accomplish this task.\n-            We will generate the key into a temporary keystore initially so that we can export and sign it later with CA.\n+            The first step of deploying one or more brokers with SSL support is to generate a public/private keypair for every server.\n+            Since Kafka expects all keys and certificates to be stored in keystores we will use Java's keytool command for this task.\n+            The tool supports two different keystore formats, the Java specific jks format which has been deprecated by now, as well as PKCS12.\n+            PKCS12 is the default format as of Java version 9, to ensure this format is being used regardless of the Java version in use all following\n+            commands explicitly specify the PKCS12 format.\n             <pre class=\"brush: bash;\">\n-            keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA</pre>\n-\n+                keytool -keystore {keystorefile} -alias localhost -validity {validity} -genkey -keyalg RSA -storetype pkcs12\n+            </pre>\n             You need to specify two parameters in the above command:\n             <ol>\n-                <li>keystore: the keystore file that stores the certificate. The keystore file contains the private key of the certificate; therefore, it needs to be kept safely.</li>\n-                <li>validity: the valid time of the certificate in days.</li>\n-            </ol>\n-            <br>\n-\n-        <h5><a id=\"security_confighostname\" href=\"#security_confighostname\">Configuring Host Name Verification</a></h5>\n-        From Kafka version 2.0.0 onwards, host name verification of servers is enabled by default for client connections\n-        as well as inter-broker connections to prevent man-in-the-middle attacks. Server host name verification may be disabled\n-        by setting <code>ssl.endpoint.identification.algorithm</code> to an empty string. For example,\n-        <pre class=\"brush: text;\">\tssl.endpoint.identification.algorithm=</pre>\n-        For dynamically configured broker listeners, hostname verification may be disabled using <code>kafka-configs.sh</code>.\n-        For example,\n-        <pre class=\"brush: text;\">\n-        bin/kafka-configs.sh --bootstrap-server localhost:9093 --entity-type brokers --entity-name 0 --alter --add-config \"listener.name.internal.ssl.endpoint.identification.algorithm=\"\n-        </pre>\n+                <li>keystorefile: the keystore file that stores the keys (and later the certificate) for this broker. The keystore file contains the private\n+                    and public keys of this broker, therefore it needs to be kept safe. Ideally this step is run on the Kafka broker that the key will be\n+                    used on, as this key should never be transmitted/leave the server that it is intended for.</li>\n+                <li>validity: the valid time of the key in days. Please note that this differs from the validity period for the certificate, which\n+                    will be determined in <a href =\"#security_ssl_signing\">Signing the certificate</a>. You can use the same key to request multiple\n+                    certificates: if your key has a validity of 10 years, but your CA will only sign certificates that are valid for one year, you\n+                    can use the same key with 10 certificates over time.</li>\n+            </ol><br>\n+            To obtain a certificate that can be used with the private key that was just created a certificate signing request needs to be created. This\n+            signing request, when signed by a trusted CA results in the actual certificate which can then be installed in the keystore and used for\n+            authentication purposes.<br>\n+            To generate certificate signing requests run the following command for all server keystores created so far.\n \n-        For older versions of Kafka, <code>ssl.endpoint.identification.algorithm</code> is not defined by default, so host name\n-        verification is not performed. The property should be set to <code>HTTPS</code> to enable host name verification.\n+            <pre class=\"brush: bash;\">\n+                keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -destkeystoretype pkcs12 -ext SAN=DNS:{FQDN},IP:{IPADDRESS1}\n+            </pre>\n+            This command assumes that you want to add hostname information to the certificate, if this is not the case, you can omit the extension parameter <code>-ext SAN=DNS:{FQDN},IP:{IPADDRESS1}</code>. Please see below for more information on this.\n \n-        <pre class=\"brush: text;\">\tssl.endpoint.identification.algorithm=HTTPS </pre>\n+            <h5>Host Name Verification</h5>\n+            Host name verification, when enabled, is the process of checking attributes from the certificate that is presented by the server you are\n+            connecting to against the actual hostname or ip address of that server to ensure that you are indeed connecting to the correct server.<br>\n+            The main reason for this check is to prevent man-in-the-middle attacks.\n \n-        Host name verification must be enabled to prevent man-in-the-middle attacks if server endpoints are not validated\n-        externally.\n+            For Kafka, this check has been disabled by default for a long time, but as of Kafka 2.0.0 host name verification of servers is enabled by default\n+            for client connections as well as inter-broker connections.<br>\n+            Server host name verification may be disabled by setting <code>ssl.endpoint.identification.algorithm</code> to an empty string.<br>\n+            For dynamically configured broker listeners, hostname verification may be disabled using <code>kafka-configs.sh</code>:<br>\n \n-        <h5><a id=\"security_configcerthostname\" href=\"#security_configcerthstname\">Configuring Host Name In Certificates</a></h5>\n-        If host name verification is enabled, clients will verify the server's fully qualified domain name (FQDN) against one of\n-        the following two fields:\n-        <ol>\n-            <li>Common Name (CN)\n-            <li>Subject Alternative Name (SAN)\n-        </ol>\n-        <br>\n-        Both fields are valid, RFC-2818 recommends the use of SAN however. SAN is also more flexible, allowing for multiple DNS entries to be declared. Another advantage is that the CN can be set to a more meaningful value for authorization purposes. To add a SAN field  append the following argument <code> -ext SAN=DNS:{FQDN} </code> to the keytool command:\n-        <pre class=\"brush: bash;\">\n-        keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -ext SAN=DNS:{FQDN}\n-        </pre>\n-        The following command can be run afterwards to verify the contents of the generated certificate:\n-        <pre class=\"brush: bash;\">\n-        keytool -list -v -keystore server.keystore.jks\n-        </pre>\n+            <pre class=\"brush: text;\">\n+                bin/kafka-configs.sh --bootstrap-server localhost:9093 --entity-type brokers --entity-name 0 --alter --add-config \"listener.name.internal.ssl.endpoint.identification.algorithm=\"\n+            </pre>\n+\n+            <p><b>Note:</b></p>\n+            Normally there is no good reason to disable hostname verification apart from being the quickest way to \"just get it to work\" followed\n+            by the promise to \"fix it later when there is more time\"!<br>\n+            Getting hostname verification right is not that hard when done at the right time, but gets much harder once the cluster is up and\n+            running - do yourself a favor and do it now!\n+\n+\n+            <p>If host name verification is enabled, clients will verify the server's fully qualified domain name (FQDN) or ip address against one of the following two fields:\n+            <ol>\n+                <li>Common Name (CN)</li>\n+                <li><a href=\"https://tools.ietf.org/html/rfc5280#section-4.2.1.6\">Subject Alternative Name (SAN)</a></li>\n+            </ol><br>\n+            While Kafka checks both fields, usage of the common name field for hostname verification has been\n+            <a href=\"https://tools.ietf.org/html/rfc2818#section-3.1\">deprecated</a> since 2000 and should be avoided if possible. In addition the\n+            SAN field is much more flexible, allowing for multiple DNS and IP entries to be declared in a certificate.<br>\n+            Another advantage is that if the SAN field is used for hostname verification the common name can be set to a more meaningful value for\n+            authorization purposes. Since we need the SAN field to be contained in the signed certificate, it will be specified when generating the\n+            signing request. It can also be specified when generating the keypair, but this will not automatically be copied into the signing request.<br>\n+\n+\n+            To add a SAN field append the following argument <code> -ext SAN=DNS:{FQDN},IP:{IPADDRESS} </code> to the keytool command:\n+            <pre class=\"brush: bash;\">\n+                keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -destkeystoretype pkcs12 -ext SAN=DNS:{FQDN},IP:{IPADDRESS1}\n+            </pre>\n         </li>\n+\n         <li><h4><a id=\"security_ssl_ca\" href=\"#security_ssl_ca\">Creating your own CA</a></h4>\n-            After the first step, each machine in the cluster has a public-private key pair, and a certificate to identify the machine. The certificate, however, is unsigned, which means that an attacker can create such a certificate to pretend to be any machine.<p>\n-            Therefore, it is important to prevent forged certificates by signing them for each machine in the cluster. A certificate authority (CA) is responsible for signing certificates. CA works likes a government that issues passports\u2014the government stamps (signs) each passport so that the passport becomes difficult to forge. Other governments verify the stamps to ensure the passport is authentic. Similarly, the CA signs the certificates, and the cryptography guarantees that a signed certificate is computationally difficult to forge. Thus, as long as the CA is a genuine and trusted authority, the clients have high assurance that they are connecting to the authentic machines.\n-            <pre class=\"brush: bash;\">\n-            openssl req -new -x509 -keyout ca-key -out ca-cert -days 365</pre>\n+            After this step each machine in the cluster has a public/private key pair which can already be used to encrypt traffic and a certificate\n+            signing request, which is the basis for creating a certificate. To add authentication capabilities this signing request needs to be signed\n+            by a trusted authority, which will be created in this step.\n+\n+            <p>A certificate authority (CA) is responsible for signing certificates. CAs works likes a government that issues passports\u2014the government\n+            stamps (signs) each passport so that the passport becomes difficult to forge. Other governments verify the stamps to ensure the passport is\n+            authentic. Similarly, the CA signs the certificates, and the cryptography guarantees that a signed certificate is computationally difficult to\n+            forge. Thus, as long as the CA is a genuine and trusted authority, the clients have a strong assurance that they are connecting to the authentic\n+            machines.\n+\n+            <p>For this guide we will be our own Certificate Authority, when setting up a production cluster in a corporate environment these certificates would\n+            usually be signed by a corporate CA that is trusted throughout the company, please see <a href=\"#security_ssl_production\">Common Pitfalls in\n+            Production</a> for some things to consider for this case.\n+\n+            <p>Due to a <a href=\"https://www.openssl.org/docs/man1.1.1/man1/x509.html#BUGS\">bug</a> in OpenSSL the x509 module will not copy requested\n+            extension fields from CSRs into the final certificate. Since we want the SAN extension to be present in our certificate to enable hostname\n+            verification, we'll use the <i>ca</i> module instead. This requires some additional configuration to be in place before we generate our\n+            CA keypair.<br>\n+\n+            Save the following listing into a file called openssl-ca.cnf and adjust the values for validity and common attributes as necessary.\n+            <pre class=\"brush: bash\">\n+HOME            = .\n+RANDFILE        = $ENV::HOME/.rnd\n+\n+####################################################################\n+[ ca ]\n+default_ca    = CA_default      # The default ca section\n+\n+[ CA_default ]\n+\n+base_dir      = .\n+certificate   = $base_dir/cacert.pem   # The CA certifcate\n+private_key   = $base_dir/cakey.pem    # The CA private key\n+new_certs_dir = $base_dir              # Location for new certs after signing\n+database      = $base_dir/index.txt    # Database index file\n+serial        = $base_dir/serial.txt   # The current serial number\n+\n+default_days     = 1000         # How long to certify for\n+default_crl_days = 30           # How long before next CRL\n+default_md       = sha256       # Use public key default MD\n+preserve         = no           # Keep passed DN ordering\n+\n+x509_extensions = ca_extensions # The extensions to add to the cert\n+\n+email_in_dn     = no            # Don't concat the email in the DN\n+copy_extensions = copy          # Required to copy SANs from CSR to cert\n+\n+####################################################################\n+[ req ]\n+default_bits       = 4096\n+default_keyfile    = cakey.pem\n+distinguished_name = ca_distinguished_name\n+x509_extensions    = ca_extensions\n+string_mask        = utf8only\n+\n+####################################################################\n+[ ca_distinguished_name ]\n+countryName         = Country Name (2 letter code)\n+countryName_default = DE\n+\n+stateOrProvinceName         = State or Province Name (full name)\n+stateOrProvinceName_default = Test Province\n+\n+localityName                = Locality Name (eg, city)\n+localityName_default        = Test Town\n+\n+organizationName            = Organization Name (eg, company)\n+organizationName_default    = Test Company\n+\n+organizationalUnitName         = Organizational Unit (eg, division)\n+organizationalUnitName_default = Test Unit\n+\n+commonName         = Common Name (e.g. server FQDN or YOUR name)\n+commonName_default = Test Name\n+\n+emailAddress         = Email Address\n+emailAddress_default = test@test.com\n+\n+####################################################################\n+[ ca_extensions ]\n+\n+subjectKeyIdentifier   = hash\n+authorityKeyIdentifier = keyid:always, issuer\n+basicConstraints       = critical, CA:true\n+keyUsage               = keyCertSign, cRLSign\n+\n+####################################################################\n+[ signing_policy ]\n+countryName            = optional\n+stateOrProvinceName    = optional\n+localityName           = optional\n+organizationName       = optional\n+organizationalUnitName = optional\n+commonName             = supplied\n+emailAddress           = optional\n+\n+####################################################################\n+[ signing_req ]\n+subjectKeyIdentifier   = hash\n+authorityKeyIdentifier = keyid,issuer\n+basicConstraints       = CA:FALSE\n+keyUsage               = digitalSignature, keyEncipherment\n+            </pre>\n \n-            The generated CA is simply a public-private key pair and certificate, and it is intended to sign other certificates.<br>\n+            Then create a database and serial number file, these will be used to keep track of which certificates were signed with this CA. Both of\n+            these are simply text files that reside in the same directory as your CA keys.\n \n-            The next step is to add the generated CA to the **clients' truststore** so that the clients can trust this CA:\n             <pre class=\"brush: bash;\">\n-            keytool -keystore client.truststore.jks -alias CARoot -import -file ca-cert</pre>\n+                echo 01 > serial.txt\n+                touch index.txt\n+            </pre>\n+\n+            With these steps done you are now ready to generate your CA that will be used to sign certificates later.\n \n-            <b>Note:</b> If you configure the Kafka brokers to require client authentication by setting ssl.client.auth to be \"requested\" or \"required\" on the <a href=\"#config_broker\">Kafka brokers config</a> then you must provide a truststore for the Kafka brokers as well and it should have all the CA certificates that clients' keys were signed by.\n             <pre class=\"brush: bash;\">\n-            keytool -keystore server.truststore.jks -alias CARoot -import -file ca-cert</pre>\n+            openssl req -x509 -config openssl-ca.cnf -newkey rsa:4096 -sha256 -nodes -out cacert.pem -outform PEM\n+            </pre>\n \n-            In contrast to the keystore in step 1 that stores each machine's own identity, the truststore of a client stores all the certificates that the client should trust. Importing a certificate into one's truststore also means trusting all certificates that are signed by that certificate. As the analogy above, trusting the government (CA) also means trusting all passports (certificates) that it has issued. This attribute is called the chain of trust, and it is particularly useful when deploying SSL on a large Kafka cluster. You can sign all certificates in the cluster with a single CA, and have all machines share the same truststore that trusts the CA. That way all machines can authenticate all other machines.</li>\n+            The CA is simply a public/private key pair and certificate that is signed by itself, and is only intended to sign other certificates.<br>\n+            This keypair should be kept very safe, if someone gains access to it, they can create and sign certificates that will be trusted by your\n+            infrastructure, which means they will be able to impersonate anybody when connecting to any service that trusts this CA.<br>\n \n-        <li><h4><a id=\"security_ssl_signing\" href=\"#security_ssl_signing\">Signing the certificate</a></h4>\n-            The next step is to sign all certificates generated by step 1 with the CA generated in step 2. First, you need to export the certificate from the keystore:\n+            The next step is to add the generated CA to the **clients' truststore** so that the clients can trust this CA:\n+            <pre class=\"brush: bash;\">\n+                keytool -keystore client.truststore.jks -alias CARoot -import -file ca-cert\n+            </pre>\n+\n+            <b>Note:</b>\n+            If you configure the Kafka brokers to require client authentication by setting ssl.client.auth to be \"requested\" or \"required\" on the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89904e2c317e6a05c25bc3ca2846ab6ea705ec25"}, "originalPosition": 259}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4763259826937d52e24a97173d17693fa237c07f", "author": {"user": {"login": "soenkeliebau", "name": "S\u00f6nke Liebau"}}, "url": "https://github.com/apache/kafka/commit/4763259826937d52e24a97173d17693fa237c07f", "committedDate": "2020-02-24T16:43:09Z", "message": "Addressed comments from Michael."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY0MjgwNjcz", "url": "https://github.com/apache/kafka/pull/8009#pullrequestreview-364280673", "createdAt": "2020-02-25T16:22:49Z", "commit": {"oid": "4763259826937d52e24a97173d17693fa237c07f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2123, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}