{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyMjE1MjY1", "number": 8844, "title": "KAFKA-9887 fix failed task or connector count on startup failure", "bodyText": "Moved the responsibility for recording task and connector startup and failure metrics from the Worker class  into the status listener that gets passed into the WorkerTask. The status listener is decorated to record the metrics when onStartup or onFailure occur (if failure happens before startup).\nThis gets around the previous issues where these metrics were not being recorded because\nthe WorkerTasks/WorkerConnectors were either not propagating exceptions upwards, or were unable to do so easily because they were running on completely different threads.\nAlso split out WorkerMetricsGroup from being an inner class into being a standard class. This was to make sure the Data Abstraction Coupling checkStyle rule for the Worker class was not violated.\nTesting involved adding some unit tests for the decorated listeners to ensure they recorded metrics correctly. Some manual testing was done with Connectors and Tasks that deliberately threw exceptions in the startup phase to ensure JMX metrics were reported correctly.\nSome of the unit tests for the Worker class had some assertions around startup statistics removed, as setting these statistics is no longer the direct responsibility of the Worker class,\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-06-10T05:39:20Z", "url": "https://github.com/apache/kafka/pull/8844", "merged": true, "mergeCommit": {"oid": "0314801a8e67a96f8cdea85bf55cb5bed808fc34"}, "closed": true, "closedAt": "2021-07-20T22:39:26Z", "author": {"login": "michael-carter-instaclustr"}, "timelineItems": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcpuyLUgH2gAyNDMyMjE1MjY1OjkzZDhkNjJkNzk2Yjg3ODY1Y2IwZDhiMGZlNTc2MjM0NWVmZDhiZTg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABesSUraAH2gAyNDMyMjE1MjY1OjMzM2M5ODUwNTVmM2RiOWEyMWFkMDJmMjcwZGFkYWRkNTA1MzY5MTY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "93d8d62d796b87865cb0d8b0fe5762345efd8be8", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/93d8d62d796b87865cb0d8b0fe5762345efd8be8", "committedDate": "2020-06-10T00:47:25Z", "message": "KAFKA-9887: Fixing failed startup metrics for connectors and tasks\n\nMoved the responsibility for recording task and connector startup and failure metrics from the invocation code\ninto the status listener.\nThe reason behind this is that the WorkerTasks (and subclasses) were either not propagating exceptions upwards,\nor were unable to do so easily because they were running on completely different threads.\n\nAlso split out WorkerMetricsGroup from being an inner class into being a standard class. This was to make sure\nthe Data Abstraction Count checkStyle rule was not violated."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51106fa0cc1e313271e2e9d321335e81b75392ff", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/51106fa0cc1e313271e2e9d321335e81b75392ff", "committedDate": "2020-06-10T01:02:58Z", "message": "KAFKA-9887: Fixing failed startup metrics for connectors and tasks\n\nCleanup only, Removed commented out code."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b483e34335f3fedecd3cb1b5bb2d7bedd45f68d0", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/b483e34335f3fedecd3cb1b5bb2d7bedd45f68d0", "committedDate": "2020-06-10T03:08:16Z", "message": " KAFKA-9887: Fixing failed startup metrics for connectors and tasks\n\nFix broken unit tests that still assume the Worker class is responsible for updating connector and task startup statistics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fc7aa7bda6a761b48d8e3e6ac993fe5bba67597", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/5fc7aa7bda6a761b48d8e3e6ac993fe5bba67597", "committedDate": "2020-06-15T00:17:25Z", "message": "Merge branch 'trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "5fc7aa7bda6a761b48d8e3e6ac993fe5bba67597", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/5fc7aa7bda6a761b48d8e3e6ac993fe5bba67597", "committedDate": "2020-06-15T00:17:25Z", "message": "Merge branch 'trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/45bb0cef1e6396ab198e3dd3b3be6be13339358e", "committedDate": "2020-06-17T23:21:35Z", "message": "Merge remote-tracking branch 'upstream/trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM0NTgxMzE3", "url": "https://github.com/apache/kafka/pull/8844#pullrequestreview-434581317", "createdAt": "2020-06-22T03:22:48Z", "commit": {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwMzoyMjo0OVrOGmw34A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwNDoxODo1M1rOGmxfUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzI5OTgwOA==", "bodyText": "Nit: the name here is a bit verbose. The type signature of the parameter here already tells us that this is for a connector status listener; do you think wrapStatusListener or even just statusListener might convey the necessary information?", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443299808", "createdAt": "2020-06-22T03:22:49Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapConnectorStatusListener(ConnectorStatus.Listener delegateListener) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzI5OTkwMA==", "bodyText": "Same comment here w/r/t naming; I think wrapStatusListener or statusListener may be warranted.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443299900", "createdAt": "2020-06-22T03:23:17Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapTaskStatusListener(TaskStatus.Listener delegateListener) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwMDA2OA==", "bodyText": "Another nit (sorry!): given that this is already an inner class for the WorkerMetricsGroup class, the WorkerMetricsGroup prefix seems redundant. What do you think about just ConnectorStatusListener?", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443300068", "createdAt": "2020-06-22T03:24:14Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapTaskStatusListener(TaskStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupTaskStatusListener(delegateListener);\n+    }\n+\n+    class WorkerMetricsGroupConnectorStatusListener implements ConnectorStatus.Listener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwMDE0Mg==", "bodyText": "Same (nitty) comment here: maybe just TaskStatusListener?", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443300142", "createdAt": "2020-06-22T03:24:41Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapTaskStatusListener(TaskStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupTaskStatusListener(delegateListener);\n+    }\n+\n+    class WorkerMetricsGroupConnectorStatusListener implements ConnectorStatus.Listener {\n+        private final ConnectorStatus.Listener delegateListener;\n+        private boolean startupSucceeded = false;\n+\n+        WorkerMetricsGroupConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+            this.delegateListener = delegateListener;\n+        }\n+\n+        @Override\n+        public void onShutdown(final String connector) {\n+            delegateListener.onShutdown(connector);\n+        }\n+\n+        @Override\n+        public void onFailure(final String connector, final Throwable cause) {\n+            if (!startupSucceeded) {\n+                recordConnectorStartupFailure();\n+            }\n+            delegateListener.onFailure(connector, cause);\n+        }\n+\n+        @Override\n+        public void onPause(final String connector) {\n+            delegateListener.onPause(connector);\n+        }\n+\n+        @Override\n+        public void onResume(final String connector) {\n+            delegateListener.onResume(connector);\n+        }\n+\n+        @Override\n+        public void onStartup(final String connector) {\n+            delegateListener.onStartup(connector);\n+            startupSucceeded = true;\n+            recordConnectorStartupSuccess();\n+        }\n+\n+        @Override\n+        public void onDeletion(final String connector) {\n+            delegateListener.onDeletion(connector);\n+        }\n+    }\n+\n+    class WorkerMetricsGroupTaskStatusListener implements TaskStatus.Listener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwODE3NQ==", "bodyText": "I think we might want to keep this line here in case we fail somehow before even creating the WorkerConnector instance.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443308175", "createdAt": "2020-06-22T04:09:13Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -289,7 +285,6 @@ public void startConnector(\n                 // Can't be put in a finally block because it needs to be swapped before the call on\n                 // statusListener\n                 Plugins.compareAndSwapLoaders(savedLoader);\n-                workerMetricsGroup.recordConnectorStartupFailure();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwODkxNw==", "bodyText": "It seems a little unclean to start calling the statusListener from the subclass when it's been used exclusively by the WorkerTask abstract class up to this point. Not the end of the world but I think we might be able to do this more cleanly by decomposing the existing execute method into separate initializeAndStart (name obviously subject to change) and execute methods, with the call to statusListener::onStartup in between them. This way, we can avoid worrying about the status listener in the subclasses and can  encapsulate some shared logic in the abstract superclass. What are your thoughts?", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443308917", "createdAt": "2020-06-22T04:13:16Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerTask.java", "diffHunk": "@@ -56,7 +56,7 @@\n     private static final String THREAD_NAME_PREFIX = \"task-thread-\";\n \n     protected final ConnectorTaskId id;\n-    private final TaskStatus.Listener statusListener;\n+    protected final TaskStatus.Listener statusListener;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwOTkwNg==", "bodyText": "I think we might want to keep this line here in case we fail somehow before even creating the WorkerTask instance. This can happen if a Converter, Transformation, etc. throws an exception during startup.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443309906", "createdAt": "2020-06-22T04:18:53Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -562,7 +556,6 @@ public boolean startTask(\n                 // statusListener\n                 Plugins.compareAndSwapLoaders(savedLoader);\n                 connectorStatusMetricsGroup.recordTaskRemoved(id);\n-                workerMetricsGroup.recordTaskFailure();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e"}, "originalPosition": 73}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/70b2db9a68ba0c9a86455779344cece99e221ae9", "committedDate": "2020-06-23T08:42:08Z", "message": "KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure\n\nChanges from code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2MDY0MjYz", "url": "https://github.com/apache/kafka/pull/8844#pullrequestreview-436064263", "createdAt": "2020-06-23T18:52:06Z", "commit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxODo1MjowN1rOGn2THQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxOToyMzo0NlrOGn3WQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQzNzI3Nw==", "bodyText": "This is going to be modified and accessed on potentially different threads, right? If so, we should add the volatile modifier here.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444437277", "createdAt": "2020-06-23T18:52:07Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new ConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapStatusListener(TaskStatus.Listener delegateListener) {\n+        return new TaskStatusListener(delegateListener);\n+    }\n+\n+    class ConnectorStatusListener implements ConnectorStatus.Listener {\n+        private final ConnectorStatus.Listener delegateListener;\n+        private boolean startupSucceeded = false;\n+\n+        ConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+            this.delegateListener = delegateListener;\n+        }\n+\n+        @Override\n+        public void onShutdown(final String connector) {\n+            delegateListener.onShutdown(connector);\n+        }\n+\n+        @Override\n+        public void onFailure(final String connector, final Throwable cause) {\n+            if (!startupSucceeded) {\n+                recordConnectorStartupFailure();\n+            }\n+            delegateListener.onFailure(connector, cause);\n+        }\n+\n+        @Override\n+        public void onPause(final String connector) {\n+            delegateListener.onPause(connector);\n+        }\n+\n+        @Override\n+        public void onResume(final String connector) {\n+            delegateListener.onResume(connector);\n+        }\n+\n+        @Override\n+        public void onStartup(final String connector) {\n+            delegateListener.onStartup(connector);\n+            startupSucceeded = true;\n+            recordConnectorStartupSuccess();\n+        }\n+\n+        @Override\n+        public void onDeletion(final String connector) {\n+            delegateListener.onDeletion(connector);\n+        }\n+    }\n+\n+    class TaskStatusListener implements TaskStatus.Listener {\n+        private final TaskStatus.Listener delegatedListener;\n+        private boolean startupSucceeded = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQzNzMxOQ==", "bodyText": "This is going to be modified and accessed on potentially different threads, right? If so, we should add the volatile modifier here.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444437319", "createdAt": "2020-06-23T18:52:13Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new ConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapStatusListener(TaskStatus.Listener delegateListener) {\n+        return new TaskStatusListener(delegateListener);\n+    }\n+\n+    class ConnectorStatusListener implements ConnectorStatus.Listener {\n+        private final ConnectorStatus.Listener delegateListener;\n+        private boolean startupSucceeded = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NTA2OQ==", "bodyText": "It's a little strange that we're mocking the class that we're testing here. Could we test on a real WorkerMetricsGroup object and mock its dependencies (specifically, the ConnectMetrics object that it takes in its constructor) instead? Might be a bit more work but would give us stronger guarantees about the accuracy and coverage of these tests.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444445069", "createdAt": "2020-06-23T19:05:56Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerMetricsGroupTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import static org.easymock.EasyMock.eq;\n+import static org.powermock.api.easymock.PowerMock.createStrictMock;\n+import static org.powermock.api.easymock.PowerMock.expectLastCall;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({Sensor.class})\n+public class WorkerMetricsGroupTest {\n+    private final String connector = \"org.FakeConnector\";\n+    private final ConnectorTaskId task = new ConnectorTaskId(connector, 0);\n+    private final RuntimeException exception = new RuntimeException();\n+\n+    @Test\n+    public void testConnectorStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NjM0MA==", "bodyText": "Nit: can probably just use the @Mock annotation and make these instance instead of local variables so that we don't have to repeat this code at the beginning of each test.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444446340", "createdAt": "2020-06-23T19:08:15Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerMetricsGroupTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import static org.easymock.EasyMock.eq;\n+import static org.powermock.api.easymock.PowerMock.createStrictMock;\n+import static org.powermock.api.easymock.PowerMock.expectLastCall;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({Sensor.class})\n+public class WorkerMetricsGroupTest {\n+    private final String connector = \"org.FakeConnector\";\n+    private final ConnectorTaskId task = new ConnectorTaskId(connector, 0);\n+    private final RuntimeException exception = new RuntimeException();\n+\n+    @Test\n+    public void testConnectorStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);\n+        final ConnectorStatus.Listener delegate = createStrictMock(ConnectorStatus.Listener.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1MDc0OQ==", "bodyText": "Nit: looks like similar calls use eq(connector) instead of connector. I think they both work but we should stick to one or the other.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444450749", "createdAt": "2020-06-23T19:16:32Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerMetricsGroupTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import static org.easymock.EasyMock.eq;\n+import static org.powermock.api.easymock.PowerMock.createStrictMock;\n+import static org.powermock.api.easymock.PowerMock.expectLastCall;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({Sensor.class})\n+public class WorkerMetricsGroupTest {\n+    private final String connector = \"org.FakeConnector\";\n+    private final ConnectorTaskId task = new ConnectorTaskId(connector, 0);\n+    private final RuntimeException exception = new RuntimeException();\n+\n+    @Test\n+    public void testConnectorStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);\n+        final ConnectorStatus.Listener delegate = createStrictMock(ConnectorStatus.Listener.class);\n+        final WorkerMetricsGroup.ConnectorStatusListener connectorListener = mockWorkerMetricsGroup.new ConnectorStatusListener(delegate);\n+\n+        delegate.onStartup(connector);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1MTg2Nw==", "bodyText": "Nit: I think it might make more sense if the expectations are set in chronological order instead of grouping by which mocked instance is having expectations set. So in this case, this line would be moved after the expectation for delegate::onStartup and before the one for delegate::onFailure. But not a big deal, if you think this is more readable feel free to leave as-is.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444451867", "createdAt": "2020-06-23T19:18:45Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerMetricsGroupTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import static org.easymock.EasyMock.eq;\n+import static org.powermock.api.easymock.PowerMock.createStrictMock;\n+import static org.powermock.api.easymock.PowerMock.expectLastCall;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({Sensor.class})\n+public class WorkerMetricsGroupTest {\n+    private final String connector = \"org.FakeConnector\";\n+    private final ConnectorTaskId task = new ConnectorTaskId(connector, 0);\n+    private final RuntimeException exception = new RuntimeException();\n+\n+    @Test\n+    public void testConnectorStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);\n+        final ConnectorStatus.Listener delegate = createStrictMock(ConnectorStatus.Listener.class);\n+        final WorkerMetricsGroup.ConnectorStatusListener connectorListener = mockWorkerMetricsGroup.new ConnectorStatusListener(delegate);\n+\n+        delegate.onStartup(connector);\n+        expectLastCall();\n+\n+        mockWorkerMetricsGroup.recordConnectorStartupSuccess();\n+        expectLastCall();\n+\n+        PowerMock.replayAll();\n+\n+        connectorListener.onStartup(connector);\n+\n+        PowerMock.verifyAll();\n+    }\n+\n+    @Test\n+    public void testConnectorFailureAfterStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);\n+        final ConnectorStatus.Listener delegate = createStrictMock(ConnectorStatus.Listener.class);\n+        final WorkerMetricsGroup.ConnectorStatusListener connectorListener = mockWorkerMetricsGroup.new ConnectorStatusListener(delegate);\n+\n+        delegate.onStartup(eq(connector));\n+        expectLastCall();\n+\n+        delegate.onFailure(eq(connector), eq(exception));\n+        expectLastCall();\n+\n+        mockWorkerMetricsGroup.recordConnectorStartupSuccess();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1NDA0OA==", "bodyText": "It's unfortunate that we're losing test coverage here, especially since it makes issues like the one that necessitates this PR more likely as we can't prevent regressions. Is there a way we can keep some of this testing logic, either through modifying the WorkerTest or by relocating it to the WorkerMetricsGroupTest?", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444454048", "createdAt": "2020-06-23T19:22:56Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerTest.java", "diffHunk": "@@ -336,14 +336,11 @@ public void testStartConnectorFailure() throws Exception {\n             assertEquals(exception, e.getCause());\n         }\n \n-        assertStartupStatistics(worker, 1, 1, 0, 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1NDQ2Ng==", "bodyText": "Ahh, I see--we construct a connector status listener for some and a task status listener for others. Honestly, I think it's probably fine if we just make both available as instance variables and @Mock them.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444454466", "createdAt": "2020-06-23T19:23:46Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerMetricsGroupTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import static org.easymock.EasyMock.eq;\n+import static org.powermock.api.easymock.PowerMock.createStrictMock;\n+import static org.powermock.api.easymock.PowerMock.expectLastCall;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({Sensor.class})\n+public class WorkerMetricsGroupTest {\n+    private final String connector = \"org.FakeConnector\";\n+    private final ConnectorTaskId task = new ConnectorTaskId(connector, 0);\n+    private final RuntimeException exception = new RuntimeException();\n+\n+    @Test\n+    public void testConnectorStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);\n+        final ConnectorStatus.Listener delegate = createStrictMock(ConnectorStatus.Listener.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NjM0MA=="}, "originalCommit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8bf7d92fe6398dc229ada8bc007fbbbc95c72c8c", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/8bf7d92fe6398dc229ada8bc007fbbbc95c72c8c", "committedDate": "2020-06-25T03:19:59Z", "message": "KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure\n\nChanges to unit tests from code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3MTQ5NDcz", "url": "https://github.com/apache/kafka/pull/8844#pullrequestreview-437149473", "createdAt": "2020-06-25T03:51:34Z", "commit": {"oid": "8bf7d92fe6398dc229ada8bc007fbbbc95c72c8c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2912c8fd0957c14c6a31db9f85c39239383c491", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/f2912c8fd0957c14c6a31db9f85c39239383c491", "committedDate": "2020-10-08T22:33:26Z", "message": "Merge branch 'trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a091df56f455fe598655949268f5e8025ad796da", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/a091df56f455fe598655949268f5e8025ad796da", "committedDate": "2020-11-02T23:09:10Z", "message": "Merge branch 'trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "committedDate": "2020-11-03T02:00:50Z", "message": "Fixed unit test that was not using the initializeAndStart() method"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzMzc1OTQw", "url": "https://github.com/apache/kafka/pull/8844#pullrequestreview-613375940", "createdAt": "2021-03-16T15:14:43Z", "commit": {"oid": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xNlQxNToxNDo0M1rOI3sSyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0yOVQxNjo0MzoyNVrOI_fnxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTI2ODI5Ng==", "bodyText": "Let's avoid unnecessary changes.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r595268296", "createdAt": "2021-03-16T15:14:43Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java", "diffHunk": "@@ -191,9 +191,9 @@ public void transitionTo(TargetState state) {\n         consumer.wakeup();\n     }\n \n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQwMDIyMQ==", "bodyText": "Nit: the methods of the ConnectorStatusListener and TaskStatusListener classes are in very different orders. It would help readability to have them in the same order. IMO, the order of the TaskStatusListener methods is nice because it follows the lifecycle.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603400221", "createdAt": "2021-03-29T15:38:09Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new ConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapStatusListener(TaskStatus.Listener delegateListener) {\n+        return new TaskStatusListener(delegateListener);\n+    }\n+\n+    class ConnectorStatusListener implements ConnectorStatus.Listener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQwMjYwNw==", "bodyText": "Why is the order of these methods different than in ConnectorStatusListener?\nAlso, the TaskStatusListener methods always forward the method to the delegate last, whereas the methods of the ConnectorStatusListener use a mixture. Let's make them consistent.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603402607", "createdAt": "2021-03-29T15:41:14Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new ConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapStatusListener(TaskStatus.Listener delegateListener) {\n+        return new TaskStatusListener(delegateListener);\n+    }\n+\n+    class ConnectorStatusListener implements ConnectorStatus.Listener {\n+        private final ConnectorStatus.Listener delegateListener;\n+        private volatile boolean startupSucceeded = false;\n+\n+        ConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+            this.delegateListener = delegateListener;\n+        }\n+\n+        @Override\n+        public void onShutdown(final String connector) {\n+            delegateListener.onShutdown(connector);\n+        }\n+\n+        @Override\n+        public void onFailure(final String connector, final Throwable cause) {\n+            if (!startupSucceeded) {\n+                recordConnectorStartupFailure();\n+            }\n+            delegateListener.onFailure(connector, cause);\n+        }\n+\n+        @Override\n+        public void onPause(final String connector) {\n+            delegateListener.onPause(connector);\n+        }\n+\n+        @Override\n+        public void onResume(final String connector) {\n+            delegateListener.onResume(connector);\n+        }\n+\n+        @Override\n+        public void onStartup(final String connector) {\n+            delegateListener.onStartup(connector);\n+            startupSucceeded = true;\n+            recordConnectorStartupSuccess();\n+        }\n+\n+        @Override\n+        public void onDeletion(final String connector) {\n+            delegateListener.onDeletion(connector);\n+        }\n+    }\n+\n+    class TaskStatusListener implements TaskStatus.Listener {\n+        private final TaskStatus.Listener delegatedListener;\n+        private volatile boolean startupSucceeded = false;\n+\n+        TaskStatusListener(TaskStatus.Listener delegatedListener) {\n+            this.delegatedListener = delegatedListener;\n+        }\n+\n+        @Override\n+        public void onStartup(final ConnectorTaskId id) {\n+            recordTaskSuccess();\n+            startupSucceeded = true;\n+            delegatedListener.onStartup(id);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5"}, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQwNTM0MQ==", "bodyText": "We're removing the INFO-level log message here, which we use to help identify that the worker task entered this method. It might be good to keep an INFO-level log message here, but use something like `{} Executing source task\". WDYT?", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603405341", "createdAt": "2021-03-29T15:44:44Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java", "diffHunk": "@@ -225,12 +225,16 @@ private synchronized void tryStop() {\n         }\n     }\n \n+    @Override\n+    protected void initializeAndStart() {\n+        task.initialize(new WorkerSourceTaskContext(offsetReader, this, configState));\n+        task.start(taskConfig);\n+        log.info(\"{} Source task finished initialization and start\", this);\n+    }\n+\n     @Override\n     public void execute() {\n         try {\n-            task.initialize(new WorkerSourceTaskContext(offsetReader, this, configState));\n-            task.start(taskConfig);\n-            log.info(\"{} Source task finished initialization and start\", this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQwOTM0Mg==", "bodyText": "We never really had an INFO-level log message here (unlike WorkerSourceTask.execute(), though we could always tell by the INFO-level log message in initializeAndStart(). Since the latter now does a bit more work, it probably is better to have an INFO-level log message here at the start of execute(). What do you think about adding an INFO-level log message here, using something like {} Executing sink task\" (similar to WorkerSourceTask.execute()`)?", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603409342", "createdAt": "2021-03-29T15:49:35Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java", "diffHunk": "@@ -191,9 +191,9 @@ public void transitionTo(TargetState state) {\n         consumer.wakeup();\n     }\n \n+\n     @Override\n     public void execute() {\n-        initializeAndStart();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQyMTM0Mw==", "bodyText": "I see how you've just pulled the WorkerSinkTask.initializeAndStart() method up to this abstract class (per @C0urante's suggestion. That is a nice clean way to encapsulate that logic into the base class and keep the metrics behavior hidden from the subclasses. Nicely done.\nIt is a tiny bit unfortunate that the tests need to do something like:\n        workerSourceTask.initialize(TASK_CONFIG);   // This just sets the config on the worker task\n        workerSourceTask.initializeAndStart();            // This calls task.initialize(...) and task.start(...)\n        workerSourceTask.execute();\n\nBut the initializeAndStart() method in the WorkerSinkTask has been around since the beginning, and it's probably not worth changing here. After all, using initializeAndStart() still makes sense within the WorkerSinkTask and now also the WorkerTask and WorkerSourceTask classes. So I'm fine with enlisting that method name as-is.", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603421343", "createdAt": "2021-03-29T16:04:43Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerTask.java", "diffHunk": "@@ -151,6 +151,8 @@ public void removeMetrics() {\n         taskMetricsGroup.close();\n     }\n \n+    protected abstract void initializeAndStart();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQ0OTI4NQ==", "bodyText": "Both of you raise good points. But I tend to agree with @C0urante that it's better to keep these checks. @michael-carter-instaclustr is right that the new WorkerMetricsGroupTest is where we should validate that WorkerMetricsGroup works correctly. These assertions, however, serve to verify that the Worker is calling the WorkerMetricsGroup correctly, and they serve to help detect regressions. Besides, there still are lots of places within WorkerTest where the assertStartupStatistics(...) method is still called, so why keep only some of these rather than keep them all?", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603449285", "createdAt": "2021-03-29T16:43:25Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerTest.java", "diffHunk": "@@ -336,14 +336,11 @@ public void testStartConnectorFailure() throws Exception {\n             assertEquals(exception, e.getCause());\n         }\n \n-        assertStartupStatistics(worker, 1, 1, 0, 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1NDA0OA=="}, "originalCommit": {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9"}, "originalPosition": 15}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bff3bb1e771c5e9ea5d49c27d26b4b16bc385397", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/bff3bb1e771c5e9ea5d49c27d26b4b16bc385397", "committedDate": "2021-03-31T22:54:31Z", "message": "Reorder methods and lines in WorkerMetricsGroup\nAdded additional logging in execute() methods of WorkerSinkTask and WorkerSourceTask"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "52b0bc4da61b178e6cbc1c1776cddf2891768e49", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/52b0bc4da61b178e6cbc1c1776cddf2891768e49", "committedDate": "2021-03-31T23:36:02Z", "message": "Merge remote-tracking branch 'upstream/trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9463460c7c90da4cf4d5b2a5bcfde3e1402fed4", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/e9463460c7c90da4cf4d5b2a5bcfde3e1402fed4", "committedDate": "2021-04-01T01:08:12Z", "message": "fixed broken unit test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8875af670b0fc74cef838e4d4fdfaa1615fd1328", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/8875af670b0fc74cef838e4d4fdfaa1615fd1328", "committedDate": "2021-04-01T01:30:47Z", "message": "re-deleted already removed files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ceb246d5b4a8356781af4ced2fbbf82aa7645d4a", "author": {"user": {"login": "michael-carter-instaclustr", "name": "Michael Carter"}}, "url": "https://github.com/apache/kafka/commit/ceb246d5b4a8356781af4ced2fbbf82aa7645d4a", "committedDate": "2021-04-01T05:43:19Z", "message": "added back some asserts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzEwNjk2MDI3", "url": "https://github.com/apache/kafka/pull/8844#pullrequestreview-710696027", "createdAt": "2021-07-20T15:06:04Z", "commit": {"oid": "ceb246d5b4a8356781af4ced2fbbf82aa7645d4a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ccf09d2ae0a017a7469542c27dabe5cb843c2f9f", "author": {"user": {"login": "rhauch", "name": "Randall Hauch"}}, "url": "https://github.com/apache/kafka/commit/ccf09d2ae0a017a7469542c27dabe5cb843c2f9f", "committedDate": "2021-07-20T15:13:55Z", "message": "Merge branch 'trunk' into kafka-9887"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "333c985055f3db9a21ad02f270dadadd50536916", "author": {"user": {"login": "rhauch", "name": "Randall Hauch"}}, "url": "https://github.com/apache/kafka/commit/333c985055f3db9a21ad02f270dadadd50536916", "committedDate": "2021-07-20T15:41:56Z", "message": "Added onRestart method to listener implementations. This was recently added in KIP-745 (PR #10822)"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 567, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}