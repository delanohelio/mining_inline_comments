{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE2NDIyODM3", "number": 8647, "title": "KAFKA-9669; Loosen validation of inner offsets for older message formats", "bodyText": "Prior to KAFKA-8106, we allowed the v0 and v1 message formats to contain non-consecutive inner offsets. Inside LogValidator, we would detect this case and rewrite the batch. After KAFKA-8106, we changed the logic to raise an error in the case of the v1 message format (v0 was still expected to be rewritten). This caused an incompatibility for older clients which were depending on the looser validation. This patch reverts the old logic of rewriting the batch to fix the invalid inner offsets.\nNote that the v2 message format has always had stricter validation. This patch also adds a test case for this.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-05-12T00:49:57Z", "url": "https://github.com/apache/kafka/pull/8647", "merged": true, "mergeCommit": {"oid": "81cf3fa5f2391c39e550a19874d50fcf18cdfd34"}, "closed": true, "closedAt": "2020-05-12T19:06:09Z", "author": {"login": "hachikuji"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcgZjfXgH2gAyNDE2NDIyODM3OjNiZmRlMGY0ZWI4OTEwZmM4MWUyMzlhMzAwNmE1NzM2ZWE2YmVlMTI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcgnG6BAH2gAyNDE2NDIyODM3OmIxNzRmN2MyNzJhMGNkZWMzOTZlNjEzNTA3YzYxMmRlZDdmOTYwNDQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "committedDate": "2020-05-12T00:58:03Z", "message": "KAFKA-9669; Loosen validation of inner offsets for older message format versions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "committedDate": "2020-05-12T00:58:03Z", "message": "KAFKA-9669; Loosen validation of inner offsets for older message format versions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5Njc3Mzcz", "url": "https://github.com/apache/kafka/pull/8647#pullrequestreview-409677373", "createdAt": "2020-05-12T03:42:21Z", "commit": {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwMzo0MjoyMVrOGT09bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwMzo0MjoyMVrOGT09bw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzQ0MzgyMw==", "bodyText": "First, I don't fully understand the different between version 0, 1, and 2. I am concern if this check (if statement) it still accurate.\n\nWhy do we only update the maxTimestamp if the version is not v0?\nWhy do we disallow in place assignment of records with invalid offsets if the version is not v0?\n\nFor 1, is it because we are only allow to update it in v1 and v2? E.g.\nif (toMagic >= RecordBatch.MAGIC_VALUE_V1)\n        batch.setMaxTimestamp(timestampType, maxTimestamp)\n\nFor 2. is it because in place assignment is always false for v0? E.g.:\n    if (firstBatch.magic != toMagic || toMagic == RecordBatch.MAGIC_VALUE_V0)\n      inPlaceAssignment = false", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423443823", "createdAt": "2020-05-12T03:42:21Z", "author": {"login": "jsancio"}, "path": "core/src/main/scala/kafka/log/LogValidator.scala", "diffHunk": "@@ -423,8 +413,11 @@ private[log] object LogValidator extends Logging {\n               if (batch.magic > RecordBatch.MAGIC_VALUE_V0 && toMagic > RecordBatch.MAGIC_VALUE_V0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12"}, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEwMTkzMzAw", "url": "https://github.com/apache/kafka/pull/8647#pullrequestreview-410193300", "createdAt": "2020-05-12T16:02:03Z", "commit": {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNjowMjowM1rOGUN3TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNjowMjowM1rOGUN3TQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg1MTg1Mw==", "bodyText": "I'm a bit nervous about this method being in the public interface. Could we make it package private and then add a test utility method in the same package that calls it, exposing it only for tests?", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423851853", "createdAt": "2020-05-12T16:02:03Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/record/MemoryRecordsBuilder.java", "diffHunk": "@@ -587,6 +588,35 @@ public void appendUncheckedWithOffset(long offset, LegacyRecord record) {\n         }\n     }\n \n+    /**\n+     * Append a record without doing offset/magic validation (this should only be used in testing).\n+     *\n+     * @param offset The offset of the record\n+     * @param record The record to add\n+     */\n+    public void appendUncheckedWithOffset(long offset, SimpleRecord record) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12"}, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEwMjE3MjIw", "url": "https://github.com/apache/kafka/pull/8647#pullrequestreview-410217220", "createdAt": "2020-05-12T16:29:06Z", "commit": {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNjoyOTowN1rOGUPBUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNjozMDowMlrOGUPD2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg3MDgwMg==", "bodyText": "Can we add a comment here?", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423870802", "createdAt": "2020-05-12T16:29:07Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogValidator.scala", "diffHunk": "@@ -423,8 +413,11 @@ private[log] object LogValidator extends Logging {\n               if (batch.magic > RecordBatch.MAGIC_VALUE_V0 && toMagic > RecordBatch.MAGIC_VALUE_V0) {\n                 if (record.timestamp > maxTimestamp)\n                   maxTimestamp = record.timestamp\n-                validateOffset(batchIndex, record, expectedOffset)\n-              } else None\n+\n+                if (record.offset != expectedOffset)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg3MTQ1MA==", "bodyText": "Nit: Replace 20 with numRecords", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423871450", "createdAt": "2020-05-12T16:30:02Z", "author": {"login": "ijuma"}, "path": "core/src/test/scala/unit/kafka/log/LogValidatorTest.scala", "diffHunk": "@@ -64,6 +64,29 @@ class LogValidatorTest {\n     checkAllowMultiBatch(RecordBatch.MAGIC_VALUE_V1, CompressionType.NONE, CompressionType.GZIP)\n   }\n \n+  @Test\n+  def testValidationOfBatchesWithNonSequentialInnerOffsets(): Unit = {\n+    def testMessageValidation(magicValue: Byte): Unit = {\n+      val numRecords = 20\n+      val invalidRecords = recordsWithNonSequentialInnerOffsets(magicValue, CompressionType.GZIP, numRecords)\n+\n+      // Validation for v2 and above is strict for this case. For older formats, we fix invalid\n+      // internal offsets by rewriting the batch.\n+      if (magicValue >= RecordBatch.MAGIC_VALUE_V2) {\n+        assertThrows[InvalidRecordException] {\n+          validateMessages(invalidRecords, magicValue, CompressionType.GZIP, CompressionType.GZIP)\n+        }\n+      } else {\n+        val result = validateMessages(invalidRecords, magicValue, CompressionType.GZIP, CompressionType.GZIP)\n+        assertEquals(0 until 20, result.validatedRecords.records.asScala.map(_.offset))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12"}, "originalPosition": 36}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b174f7c272a0cdec396e613507c612ded7f96044", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/b174f7c272a0cdec396e613507c612ded7f96044", "committedDate": "2020-05-12T16:45:30Z", "message": "Add comment about internal offset validation"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 944, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}