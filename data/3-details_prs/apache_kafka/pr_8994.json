{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ2MzkxMzQ2", "number": 8994, "title": "KAFKA-10247: Correctly reset state when task is corrupted", "bodyText": "When we detect a task as corrupted, we need to not only close,\nclean up, and recover the local store, but we also need to reset\nthe consumer to the last committed position so that after recovery\nwe can start processing from the correct position.\nWe also need to detect such repaired tasks in the StreamThread\nprocessing loop so they can be re-initialized and recovered, even\nwhen the thread is already in RUNNING.\nAlso, I fixed a bug in which we would incorrectly always consider\na task as corrupted when it contains both persistent and in-memory\nstores.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-07-08T17:43:12Z", "url": "https://github.com/apache/kafka/pull/8994", "merged": true, "mergeCommit": {"oid": "cec5f377b59443a52ed1895d4e76e6f31cd46d66"}, "closed": true, "closedAt": "2020-07-11T18:39:24Z", "author": {"login": "vvcephei"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcy-44EAFqTQ0NTAzMjc2Nw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABczw-5nAFqTQ0Njc3ODM3Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ1MDMyNzY3", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-445032767", "createdAt": "2020-07-08T18:38:32Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ1MTcyNDMy", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-445172432", "createdAt": "2020-07-08T22:30:49Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMjozMDo0OVrOGu7ZDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMjozMTo1NlrOGu7amA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg2MDc1MA==", "bodyText": "I honestly couldn't figure out what is the default default default reset strategy... It seems (from the behavior of the test when we first start up) that if there's no strategy set, and no committed offset, then the client starts at the beginning, but the ClientConfig has the default policy as \"latest\"... What gives?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r451860750", "createdAt": "2020-07-08T22:30:49Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -766,6 +769,24 @@ void runOnce() {\n         return records;\n     }\n \n+    private OffsetResetStrategy getResetStrategy(final TopicPartition partition) {\n+        if (builder.earliestResetTopicsPattern().matcher(partition.topic()).matches()) {\n+            return OffsetResetStrategy.EARLIEST;\n+        } else if (builder.latestResetTopicsPattern().matcher(partition.topic()).matches()) {\n+            return OffsetResetStrategy.LATEST;\n+        } else {\n+            if (originalReset == null || (!originalReset.equals(\"earliest\") && !originalReset.equals(\"latest\"))) {\n+                return OffsetResetStrategy.EARLIEST;\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg2MTE0NA==", "bodyText": "This might be the worst thing I've ever proposed for AK... I can't figure out a better way to just \"reset\" the offset.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r451861144", "createdAt": "2020-07-08T22:31:56Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -193,6 +197,28 @@ private void closeAndRevive(final Map<Task, Collection<TopicPartition>> taskWith\n                 log.error(\"Error suspending corrupted task {} \", task.id(), swallow);\n             }\n             task.closeDirty();\n+            // Pause so we won't poll any more records for this task until it has been re-initialized\n+            // Note, closeDirty already clears the partitiongroup for the task.\n+            mainConsumer().pause(task.inputPartitions());\n+            final Map<TopicPartition, OffsetAndMetadata> committed = mainConsumer().committed(task.inputPartitions());\n+            for (final TopicPartition topicPartition : task.inputPartitions()) {\n+                final OffsetAndMetadata offsetAndMetadata = committed.get(topicPartition);\n+                if (offsetAndMetadata == null) {\n+                    final OffsetResetStrategy strategy = resetStrategy.apply(topicPartition);\n+                    switch (strategy) {\n+                        case EARLIEST:\n+                            mainConsumer().seekToBeginning(Collections.singleton(topicPartition));\n+                            break;\n+                        case LATEST:\n+                            mainConsumer().seekToBeginning(Collections.singleton(topicPartition));\n+                            break;\n+                        default:\n+                            throw new IllegalArgumentException(\"Unexpected reset strategy: \" + strategy);\n+                    }\n+                } else {\n+                    mainConsumer().seek(topicPartition, offsetAndMetadata);\n+                }\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ1MTc3NzUy", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-445177752", "createdAt": "2020-07-08T22:43:51Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMzo0MDoyMVrOGu8xhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMzo0Mzo1OFrOGu81oQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg4MzM5Ng==", "bodyText": "Should this be seekToEnd ?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r451883396", "createdAt": "2020-07-08T23:40:21Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -193,6 +197,28 @@ private void closeAndRevive(final Map<Task, Collection<TopicPartition>> taskWith\n                 log.error(\"Error suspending corrupted task {} \", task.id(), swallow);\n             }\n             task.closeDirty();\n+            // Pause so we won't poll any more records for this task until it has been re-initialized\n+            // Note, closeDirty already clears the partitiongroup for the task.\n+            mainConsumer().pause(task.inputPartitions());\n+            final Map<TopicPartition, OffsetAndMetadata> committed = mainConsumer().committed(task.inputPartitions());\n+            for (final TopicPartition topicPartition : task.inputPartitions()) {\n+                final OffsetAndMetadata offsetAndMetadata = committed.get(topicPartition);\n+                if (offsetAndMetadata == null) {\n+                    final OffsetResetStrategy strategy = resetStrategy.apply(topicPartition);\n+                    switch (strategy) {\n+                        case EARLIEST:\n+                            mainConsumer().seekToBeginning(Collections.singleton(topicPartition));\n+                            break;\n+                        case LATEST:\n+                            mainConsumer().seekToBeginning(Collections.singleton(topicPartition));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg4NDQ0OQ==", "bodyText": "What's up with this?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r451884449", "createdAt": "2020-07-08T23:43:58Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -95,7 +96,7 @@\n      *          |      | Assigned (3)| <----+\n      *          |      +-----+-------+      |\n      *          |            |              |\n-     *          |            |              |\n+     *          |            |--------------+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ1MjA0ODcy", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-445204872", "createdAt": "2020-07-08T23:59:38Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMzo1OTozOFrOGu9HKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQwMDoyMzoyN1rOGu9hZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg4ODkzOQ==", "bodyText": "Why do we need this?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r451888939", "createdAt": "2020-07-08T23:59:38Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -137,7 +138,7 @@\n         STARTING(2, 3, 5),                // 1\n         PARTITIONS_REVOKED(2, 3, 5),      // 2\n         PARTITIONS_ASSIGNED(2, 3, 4, 5),  // 3\n-        RUNNING(2, 3, 5),                 // 4\n+        RUNNING(2, 3, 4, 5),              // 4", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5MTgyMg==", "bodyText": "Does Streams override the client default..?\n\nYes. The client default is \"latest\" but we use \"earliest\" by default (cf https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java#L857). Of course, users can also change the default via StreamsConfig.\nNote that the consumer client can only apply a single strategy to all topics it subscribed to. Hence, if all topics use the same reset policy, we can rely on the consumer configures policy. However, if users specify different reset policies in their code via Consumed for individual topics, the consumer is re-configured to use \"none\" (cf. https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java#L362-L366) and we do a manual seekToBeginning/seekToEnd according to the user define strategy for the corresponding topic (cf https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java#L762-L764) because we need to make a per-topic decision that the consumer cannot make for us.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r451891822", "createdAt": "2020-07-09T00:10:00Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -766,6 +769,24 @@ void runOnce() {\n         return records;\n     }\n \n+    private OffsetResetStrategy getResetStrategy(final TopicPartition partition) {\n+        if (builder.earliestResetTopicsPattern().matcher(partition.topic()).matches()) {\n+            return OffsetResetStrategy.EARLIEST;\n+        } else if (builder.latestResetTopicsPattern().matcher(partition.topic()).matches()) {\n+            return OffsetResetStrategy.LATEST;\n+        } else {\n+            if (originalReset == null || (!originalReset.equals(\"earliest\") && !originalReset.equals(\"latest\"))) {\n+                return OffsetResetStrategy.EARLIEST;\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg2MDc1MA=="}, "originalCommit": null, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5NDI1Mw==", "bodyText": "Wondering if we should reuse this method within StreamThread#resetInvalidOffsets?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r451894253", "createdAt": "2020-07-09T00:18:19Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -766,6 +769,24 @@ void runOnce() {\n         return records;\n     }\n \n+    private OffsetResetStrategy getResetStrategy(final TopicPartition partition) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5NTE3Ng==", "bodyText": "Why do you think is bad? That is just how the API works... Cf https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java#L769-L802 that does the same thing.\nWhat make we wonder, if we can share common code for both cases?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r451895176", "createdAt": "2020-07-09T00:21:42Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -193,6 +197,28 @@ private void closeAndRevive(final Map<Task, Collection<TopicPartition>> taskWith\n                 log.error(\"Error suspending corrupted task {} \", task.id(), swallow);\n             }\n             task.closeDirty();\n+            // Pause so we won't poll any more records for this task until it has been re-initialized\n+            // Note, closeDirty already clears the partitiongroup for the task.\n+            mainConsumer().pause(task.inputPartitions());\n+            final Map<TopicPartition, OffsetAndMetadata> committed = mainConsumer().committed(task.inputPartitions());\n+            for (final TopicPartition topicPartition : task.inputPartitions()) {\n+                final OffsetAndMetadata offsetAndMetadata = committed.get(topicPartition);\n+                if (offsetAndMetadata == null) {\n+                    final OffsetResetStrategy strategy = resetStrategy.apply(topicPartition);\n+                    switch (strategy) {\n+                        case EARLIEST:\n+                            mainConsumer().seekToBeginning(Collections.singleton(topicPartition));\n+                            break;\n+                        case LATEST:\n+                            mainConsumer().seekToBeginning(Collections.singleton(topicPartition));\n+                            break;\n+                        default:\n+                            throw new IllegalArgumentException(\"Unexpected reset strategy: \" + strategy);\n+                    }\n+                } else {\n+                    mainConsumer().seek(topicPartition, offsetAndMetadata);\n+                }\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg2MTE0NA=="}, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5NTY1Mg==", "bodyText": "I think the name of the method is not ideal. We don't set the strategy, but we set a function that can compute the strategy for a partitions. Needed to go forth and back on the PR to understand how it work, and assume the method name had its part in confusing me.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r451895652", "createdAt": "2020-07-09T00:23:27Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -1140,4 +1166,12 @@ public static void executeAndMaybeSwallow(final boolean clean,\n             throw e; },\n             e -> log.debug(\"Ignoring error in unclean {}\", name));\n     }\n+\n+    boolean hasPreRunningTasks() {\n+        return tasks().values().stream().anyMatch(Task::preRunning);\n+    }\n+\n+    public void setResetStrategy(final Function<TopicPartition, OffsetResetStrategy> resetStrategy) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 66}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ1Nzk4MjA4", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-445798208", "createdAt": "2020-07-09T16:52:23Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxNjo1MjoyM1rOGvZq4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxNzowMjoyNlrOGvaB6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM1NjgzNA==", "bodyText": "Just a quality-of-life improvement.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452356834", "createdAt": "2020-07-09T16:52:23Z", "author": {"login": "vvcephei"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java", "diffHunk": "@@ -504,7 +504,7 @@ private void resetOffsetPosition(TopicPartition tp) {\n         if (strategy == OffsetResetStrategy.EARLIEST) {\n             offset = beginningOffsets.get(tp);\n             if (offset == null)\n-                throw new IllegalStateException(\"MockConsumer didn't have beginning offset specified, but tried to seek to beginning\");\n+                throw new IllegalStateException(\"MockConsumer didn't have beginning offset for \" + tp + \" specified, but tried to seek to beginning\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM1NzAyMA==", "bodyText": "Was deceptively named.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452357020", "createdAt": "2020-07-09T16:52:44Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -215,7 +215,7 @@ public StateStore getGlobalStore(final String name) {\n     }\n \n     // package-private for test only\n-    void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n+    void initializeStoreOffsetsFromCheckpoint(final boolean taskDirIsEmpty) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM1NzQ2NA==", "bodyText": "Bugfix: we shouldn't call this task corrupted for not having a checkpoint of a non-persistent store.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452357464", "createdAt": "2020-07-09T16:53:29Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -232,10 +232,16 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n                         log.debug(\"State store {} initialized from checkpoint with offset {} at changelog {}\",\n                                   store.stateStore.name(), store.offset, store.changelogPartition);\n                     } else {\n-                        // with EOS, if the previous run did not shutdown gracefully, we may lost the checkpoint file\n+                        // With EOS, if the previous run did not shutdown gracefully, we may lost the checkpoint file\n                         // and hence we are uncertain that the current local state only contains committed data;\n                         // in that case we need to treat it as a task-corrupted exception\n-                        if (eosEnabled && !storeDirIsEmpty) {\n+\n+                        // Note, this is a little overzealous, since we aren't checking whether the store's specific\n+                        // directory is nonempty, only if there are any directories for any stores. So if there are\n+                        // two stores in a task, and one is correctly written and checkpointed, while the other is\n+                        // neither written nor checkpointed, we _could_ correctly load the first and recover the second\n+                        // but instead we'll consider the whole task corrupted and discard the first and recover both.\n+                        if (store.stateStore.persistent() && eosEnabled && !taskDirIsEmpty) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM1NzYyNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    log.info(\"Closing its state manager and all the registered state stores: {}\", stores);\n          \n          \n            \n                    log.debug(\"Closing its state manager and all the registered state stores: {}\", stores);", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452357627", "createdAt": "2020-07-09T16:53:48Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -462,7 +468,7 @@ public void flush() {\n      */\n     @Override\n     public void close() throws ProcessorStateException {\n-        log.debug(\"Closing its state manager and all the registered state stores: {}\", stores);\n+        log.info(\"Closing its state manager and all the registered state stores: {}\", stores);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM1ODM4MQ==", "bodyText": "Bugfix: If a task has been revived, then it needs to be initialized and restored, even if the thread state is already RUNNING.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452358381", "createdAt": "2020-07-09T16:55:05Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -648,7 +650,7 @@ void runOnce() {\n \n         // only try to initialize the assigned tasks\n         // if the state is still in PARTITION_ASSIGNED after the poll call\n-        if (state == State.PARTITIONS_ASSIGNED) {\n+        if (state == State.PARTITIONS_ASSIGNED || taskManager.hasPreRunningTasks()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM1OTM5Mg==", "bodyText": "Refactored to share the new resetOffsets method.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452359392", "createdAt": "2020-07-09T16:56:46Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -768,9 +770,30 @@ void runOnce() {\n \n     private void resetInvalidOffsets(final InvalidOffsetException e) {\n         final Set<TopicPartition> partitions = e.partitions();\n+        final Set<TopicPartition> notReset = resetOffsets(partitions);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM2MDI4NQ==", "bodyText": "Shouldn't try to reset the main consumer at all if this is only a standby.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452360285", "createdAt": "2020-07-09T16:58:12Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -193,6 +196,26 @@ private void closeAndRevive(final Map<Task, Collection<TopicPartition>> taskWith\n                 log.error(\"Error suspending corrupted task {} \", task.id(), swallow);\n             }\n             task.closeDirty();\n+            if (task.isActive()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM2MTYxOA==", "bodyText": "I don't fully understand how this could happen, but I saw it in several tests, that an active task isn't assigned the input TopicPartition for itself. Whether or not it can happen with a real consumer, or only in tests with the MockConsumer, doesn't really seem important. If the topic isn't assigned, we certainly don't need to reset it.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452361618", "createdAt": "2020-07-09T17:00:25Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -193,6 +196,26 @@ private void closeAndRevive(final Map<Task, Collection<TopicPartition>> taskWith\n                 log.error(\"Error suspending corrupted task {} \", task.id(), swallow);\n             }\n             task.closeDirty();\n+            if (task.isActive()) {\n+                // Pause so we won't poll any more records for this task until it has been re-initialized\n+                // Note, closeDirty already clears the partitiongroup for the task.\n+                final Set<TopicPartition> currentAssignment = mainConsumer().assignment();\n+                final Set<TopicPartition> assignedToPauseAndReset =\n+                    Utils.intersection(HashSet::new, currentAssignment, task.inputPartitions());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM2MjczMQ==", "bodyText": "This all amounts to checking that we really reset the consumer to the last committed position.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452362731", "createdAt": "2020-07-09T17:02:26Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -566,8 +567,20 @@ public void shouldReviveCorruptTasks() {\n         topologyBuilder.addSubscribedTopicsFromAssignment(anyObject(), anyString());\n         expectLastCall().anyTimes();\n \n+        expect(consumer.assignment()).andReturn(taskId00Partitions);\n+        consumer.pause(taskId00Partitions);\n+        expectLastCall();\n+        final OffsetAndMetadata offsetAndMetadata = new OffsetAndMetadata(0L);\n+        expect(consumer.committed(taskId00Partitions)).andReturn(singletonMap(t1p0, offsetAndMetadata));\n+        consumer.seek(t1p0, offsetAndMetadata);\n+        expectLastCall();\n+        consumer.seekToBeginning(emptySet());\n+        expectLastCall();\n         replay(activeTaskCreator, topologyBuilder, consumer, changeLogReader);\n-\n+        taskManager.setPartitionResetter(tp -> {\n+            assertThat(tp, is(empty()));\n+            return emptySet();\n+        });", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ1ODY0MjE3", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-445864217", "createdAt": "2020-07-09T18:24:43Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxODoyNDo0M1rOGvczzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxODoyNDo0M1rOGvczzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQwODI2OA==", "bodyText": "Sound like something we should fix. Can you file a ticket?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452408268", "createdAt": "2020-07-09T18:24:43Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -232,10 +232,16 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n                         log.debug(\"State store {} initialized from checkpoint with offset {} at changelog {}\",\n                                   store.stateStore.name(), store.offset, store.changelogPartition);\n                     } else {\n-                        // with EOS, if the previous run did not shutdown gracefully, we may lost the checkpoint file\n+                        // With EOS, if the previous run did not shutdown gracefully, we may lost the checkpoint file\n                         // and hence we are uncertain that the current local state only contains committed data;\n                         // in that case we need to treat it as a task-corrupted exception\n-                        if (eosEnabled && !storeDirIsEmpty) {\n+\n+                        // Note, this is a little overzealous, since we aren't checking whether the store's specific\n+                        // directory is nonempty, only if there are any directories for any stores. So if there are\n+                        // two stores in a task, and one is correctly written and checkpointed, while the other is\n+                        // neither written nor checkpointed, we _could_ correctly load the first and recover the second\n+                        // but instead we'll consider the whole task corrupted and discard the first and recover both.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "15661551a76cbe1d52422c4ed539262bf139a4de", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/15661551a76cbe1d52422c4ed539262bf139a4de", "committedDate": "2020-07-10T02:06:53Z", "message": "KAFKA-10247: Skip processing if task isn't running"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00ef72788fdb643bc7c8f8b1f58f3cbd0ee66258", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/00ef72788fdb643bc7c8f8b1f58f3cbd0ee66258", "committedDate": "2020-07-10T02:12:01Z", "message": "rebase on trunk"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2MTIwMTI5", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-446120129", "createdAt": "2020-07-10T04:52:22Z", "commit": {"oid": "00ef72788fdb643bc7c8f8b1f58f3cbd0ee66258"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDo1MjoyMlrOGvpyaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDo1MjoyMlrOGvpyaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYyMDkwNQ==", "bodyText": "Nit: As reset policy is set on a per topic basis, it's sufficient to list the topic names -- it does not add value if we list the partitions, because all assigned partitions would be affected anyway.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452620905", "createdAt": "2020-07-10T04:52:22Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -768,9 +770,30 @@ void runOnce() {\n \n     private void resetInvalidOffsets(final InvalidOffsetException e) {\n         final Set<TopicPartition> partitions = e.partitions();\n+        final Set<TopicPartition> notReset = resetOffsets(partitions);\n+        if (!notReset.isEmpty()) {\n+            final String notResetString =\n+                notReset.stream()\n+                        .map(tp -> \"topic \" + tp.topic() + \"(partition \" + tp.partition() + \")\")\n+                        .collect(Collectors.joining(\",\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00ef72788fdb643bc7c8f8b1f58f3cbd0ee66258"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2MTIxNTUw", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-446121550", "createdAt": "2020-07-10T04:58:03Z", "commit": {"oid": "00ef72788fdb643bc7c8f8b1f58f3cbd0ee66258"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDo1ODowM1rOGvp3UA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDo1ODowM1rOGvp3UA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYyMjE2MA==", "bodyText": "I think we should fail for this case, because if user configures \"none\" they request that we fail if we loose track of the offset.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452622160", "createdAt": "2020-07-10T04:58:03Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -193,6 +196,26 @@ private void closeAndRevive(final Map<Task, Collection<TopicPartition>> taskWith\n                 log.error(\"Error suspending corrupted task {} \", task.id(), swallow);\n             }\n             task.closeDirty();\n+            if (task.isActive()) {\n+                // Pause so we won't poll any more records for this task until it has been re-initialized\n+                // Note, closeDirty already clears the partitiongroup for the task.\n+                final Set<TopicPartition> currentAssignment = mainConsumer().assignment();\n+                final Set<TopicPartition> assignedToPauseAndReset =\n+                    Utils.intersection(HashSet::new, currentAssignment, task.inputPartitions());\n+\n+                mainConsumer().pause(assignedToPauseAndReset);\n+                final Map<TopicPartition, OffsetAndMetadata> committed = mainConsumer().committed(assignedToPauseAndReset);\n+                for (final Map.Entry<TopicPartition, OffsetAndMetadata> committedEntry : committed.entrySet()) {\n+                    final OffsetAndMetadata offsetAndMetadata = committedEntry.getValue();\n+                    if (offsetAndMetadata != null) {\n+                        mainConsumer().seek(committedEntry.getKey(), offsetAndMetadata);\n+                        assignedToPauseAndReset.remove(committedEntry.getKey());\n+                    }\n+                }\n+                final Set<TopicPartition> remainder = resetter.apply(assignedToPauseAndReset);\n+                // If anything didn't have a configured policy, reset to beginning\n+                mainConsumer().seekToBeginning(remainder);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00ef72788fdb643bc7c8f8b1f58f3cbd0ee66258"}, "originalPosition": 46}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "60ed4e27134758750c0fd24adbfba52010577327", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/60ed4e27134758750c0fd24adbfba52010577327", "committedDate": "2020-07-10T16:29:37Z", "message": "cr comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NTQxMjQx", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-446541241", "createdAt": "2020-07-10T16:35:24Z", "commit": {"oid": "60ed4e27134758750c0fd24adbfba52010577327"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxNjozNToyNFrOGv989g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxNjozNToyNFrOGv989g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk1MTI4Ng==", "bodyText": "I had to change this to get the StreamThread test to actually use the configured ConsumerConfig.AUTO_OFFSET_RESET_CONFIG := earliest\nReading the conditional, it doesn't make any sense to me, but it's been in the codebase for a long time, so I'm doubting myself. It seems to say that we will only use the provided client configuration if there is an override, but it seems like it should have been \"if there is not an override\".\nRegardless, the \"originalReset\" is only used as a fallback after we apply the builder reset patterns, so I don't see why we should leave it null in any case.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452951286", "createdAt": "2020-07-10T16:35:24Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -359,11 +359,8 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n         consumerConfigs.put(StreamsConfig.InternalConfig.ASSIGNMENT_ERROR_CODE, assignmentErrorCode);\n         final AtomicLong nextScheduledRebalanceMs = new AtomicLong(Long.MAX_VALUE);\n         consumerConfigs.put(StreamsConfig.InternalConfig.NEXT_SCHEDULED_REBALANCE_MS, nextScheduledRebalanceMs);\n-        String originalReset = null;\n-        if (!builder.latestResetTopicsPattern().pattern().equals(\"\") || !builder.earliestResetTopicsPattern().pattern().equals(\"\")) {\n-            originalReset = (String) consumerConfigs.get(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG);\n-            consumerConfigs.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"none\");\n-        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60ed4e27134758750c0fd24adbfba52010577327"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "568dceb5f61c71428432d23d947c5f9b29fb7bfb", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/568dceb5f61c71428432d23d947c5f9b29fb7bfb", "committedDate": "2020-07-10T16:39:49Z", "message": "cr comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NTk5Mjg1", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-446599285", "createdAt": "2020-07-10T18:09:18Z", "commit": {"oid": "568dceb5f61c71428432d23d947c5f9b29fb7bfb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxODowOToxOFrOGwAt1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxODowOToxOFrOGwAt1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk5NjU2NA==", "bodyText": "This method is a one-liner now and is only called in a single place IIRC. Maybe better to remove the method and embed the call?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r452996564", "createdAt": "2020-07-10T18:09:18Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -767,38 +766,65 @@ void runOnce() {\n     }\n \n     private void resetInvalidOffsets(final InvalidOffsetException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "568dceb5f61c71428432d23d947c5f9b29fb7bfb"}, "originalPosition": 53}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a876630e98c9efea68a849fcc9759eac2ee488a4", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/a876630e98c9efea68a849fcc9759eac2ee488a4", "committedDate": "2020-07-10T21:21:46Z", "message": "CR comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f20a4710d4620bad771d7bdac486601b6e4cb7d3", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/f20a4710d4620bad771d7bdac486601b6e4cb7d3", "committedDate": "2020-07-10T21:29:39Z", "message": "partially revert originalReset logic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ae9c240d2856a40169ca6e6362cadc7415b47df", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/5ae9c240d2856a40169ca6e6362cadc7415b47df", "committedDate": "2020-07-10T21:40:57Z", "message": "inline the reset functions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzMzODM0", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-446733834", "createdAt": "2020-07-10T22:31:31Z", "commit": {"oid": "5ae9c240d2856a40169ca6e6362cadc7415b47df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozMTozMVrOGwHYjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozMTozMVrOGwHYjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNTgwNQ==", "bodyText": "We we need this isEmpty check? What happens is we blindly pass an empty set into seekToBeginning? -- Similar for seekToEnd() below?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r453105805", "createdAt": "2020-07-10T22:31:31Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -760,44 +763,62 @@ void runOnce() {\n         try {\n             records = mainConsumer.poll(pollTime);\n         } catch (final InvalidOffsetException e) {\n-            resetInvalidOffsets(e);\n+            resetOffsets(e.partitions(), e);\n         }\n \n         return records;\n     }\n \n-    private void resetInvalidOffsets(final InvalidOffsetException e) {\n-        final Set<TopicPartition> partitions = e.partitions();\n+    private void resetOffsets(final Set<TopicPartition> partitions, final Exception cause) {\n         final Set<String> loggedTopics = new HashSet<>();\n         final Set<TopicPartition> seekToBeginning = new HashSet<>();\n         final Set<TopicPartition> seekToEnd = new HashSet<>();\n+        final Set<TopicPartition> notReset = new HashSet<>();\n \n         for (final TopicPartition partition : partitions) {\n             if (builder.earliestResetTopicsPattern().matcher(partition.topic()).matches()) {\n                 addToResetList(partition, seekToBeginning, \"Setting topic '{}' to consume from {} offset\", \"earliest\", loggedTopics);\n             } else if (builder.latestResetTopicsPattern().matcher(partition.topic()).matches()) {\n                 addToResetList(partition, seekToEnd, \"Setting topic '{}' to consume from {} offset\", \"latest\", loggedTopics);\n             } else {\n-                if (originalReset == null || (!originalReset.equals(\"earliest\") && !originalReset.equals(\"latest\"))) {\n-                    final String errorMessage = \"No valid committed offset found for input topic %s (partition %s) and no valid reset policy configured.\" +\n-                        \" You need to set configuration parameter \\\"auto.offset.reset\\\" or specify a topic specific reset \" +\n-                        \"policy via StreamsBuilder#stream(..., Consumed.with(Topology.AutoOffsetReset)) or StreamsBuilder#table(..., Consumed.with(Topology.AutoOffsetReset))\";\n-                    throw new StreamsException(String.format(errorMessage, partition.topic(), partition.partition()), e);\n-                }\n-\n-                if (originalReset.equals(\"earliest\")) {\n+                if (\"earliest\".equals(originalReset)) {\n                     addToResetList(partition, seekToBeginning, \"No custom setting defined for topic '{}' using original config '{}' for offset reset\", \"earliest\", loggedTopics);\n-                } else { // can only be \"latest\"\n+                } else if (\"latest\".equals(originalReset)) {\n                     addToResetList(partition, seekToEnd, \"No custom setting defined for topic '{}' using original config '{}' for offset reset\", \"latest\", loggedTopics);\n+                } else {\n+                    notReset.add(partition);\n                 }\n             }\n         }\n \n-        if (!seekToBeginning.isEmpty()) {\n-            mainConsumer.seekToBeginning(seekToBeginning);\n-        }\n-        if (!seekToEnd.isEmpty()) {\n-            mainConsumer.seekToEnd(seekToEnd);\n+        if (notReset.isEmpty()) {\n+            if (!seekToBeginning.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5ae9c240d2856a40169ca6e6362cadc7415b47df"}, "originalPosition": 100}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM0NzAy", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-446734702", "createdAt": "2020-07-10T22:34:35Z", "commit": {"oid": "5ae9c240d2856a40169ca6e6362cadc7415b47df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozNDozNVrOGwHbrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozNDozNVrOGwHbrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNjYwNg==", "bodyText": "For my own education: when does the actual resume() happen (and are we sure those partitions are resumed later?)", "url": "https://github.com/apache/kafka/pull/8994#discussion_r453106606", "createdAt": "2020-07-10T22:34:35Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -193,6 +195,34 @@ private void closeAndRevive(final Map<Task, Collection<TopicPartition>> taskWith\n                 log.error(\"Error suspending corrupted task {} \", task.id(), swallow);\n             }\n             task.closeDirty();\n+            if (task.isActive()) {\n+                // Pause so we won't poll any more records for this task until it has been re-initialized\n+                // Note, closeDirty already clears the partitiongroup for the task.\n+                final Set<TopicPartition> currentAssignment = mainConsumer().assignment();\n+                final Set<TopicPartition> taskInputPartitions = task.inputPartitions();\n+                final Set<TopicPartition> assignedToPauseAndReset =\n+                    intersection(HashSet::new, currentAssignment, taskInputPartitions);\n+                if (!assignedToPauseAndReset.equals(taskInputPartitions)) {\n+                    log.warn(\n+                        \"Expected the current consumer assignment {} to contain the input partitions {}. \" +\n+                            \"Will proceed to recover.\",\n+                        currentAssignment,\n+                        taskInputPartitions\n+                    );\n+                }\n+\n+                mainConsumer().pause(assignedToPauseAndReset);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5ae9c240d2856a40169ca6e6362cadc7415b47df"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM4MTU1", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-446738155", "createdAt": "2020-07-10T22:47:17Z", "commit": {"oid": "5ae9c240d2856a40169ca6e6362cadc7415b47df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo0NzoxOFrOGwHn7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo0NzoxOFrOGwHn7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwOTc0MQ==", "bodyText": "Do we need the sink?", "url": "https://github.com/apache/kafka/pull/8994#discussion_r453109741", "createdAt": "2020-07-10T22:47:18Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -1177,6 +1180,109 @@ public void shouldNotCloseTaskAndRemoveFromTaskManagerIfProducerGotFencedInCommi\n         assertEquals(1, thread.activeTasks().size());\n     }\n \n+    @Test\n+    public void shouldReinitializeRevivedTasksInAnyState() {\n+        final StreamThread thread = createStreamThread(CLIENT_ID, new StreamsConfig(configProps(false)), false);\n+\n+        final String storeName = \"store\";\n+        final String storeChangelog = \"stream-thread-test-store-changelog\";\n+        final TopicPartition storeChangelogTopicPartition = new TopicPartition(storeChangelog, 1);\n+\n+        internalTopologyBuilder.addSource(null, \"name\", null, null, null, topic1);\n+        final AtomicBoolean shouldThrow = new AtomicBoolean(false);\n+        final AtomicBoolean processed = new AtomicBoolean(false);\n+        internalTopologyBuilder.addProcessor(\"proc\", new ProcessorSupplier<Object, Object>() {\n+            @Override\n+            public Processor<Object, Object> get() {\n+                return new Processor<Object, Object>() {\n+                    private ProcessorContext context;\n+\n+                    @Override\n+                    public void init(final ProcessorContext context) {\n+                        this.context = context;\n+                    }\n+\n+                    @Override\n+                    public void process(final Object key, final Object value) {\n+                        if (shouldThrow.get()) {\n+                            throw new TaskCorruptedException(singletonMap(task1, new HashSet<TopicPartition>(singleton(storeChangelogTopicPartition))));\n+                        } else {\n+                            processed.set(true);\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void close() {\n+\n+                    }\n+                };\n+            }\n+        }, \"name\");\n+        internalTopologyBuilder.addStateStore(\n+            Stores.keyValueStoreBuilder(\n+                Stores.persistentKeyValueStore(storeName),\n+                Serdes.String(),\n+                Serdes.String()\n+            ),\n+            \"proc\"\n+        );\n+        internalTopologyBuilder.addSink(\"out\", \"output\", null, null, null, \"proc\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5ae9c240d2856a40169ca6e6362cadc7415b47df"}, "originalPosition": 73}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzQwNzQ1", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-446740745", "createdAt": "2020-07-10T22:57:04Z", "commit": {"oid": "5ae9c240d2856a40169ca6e6362cadc7415b47df"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a378948c89335bc5bd91f9101275776671080041", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/a378948c89335bc5bd91f9101275776671080041", "committedDate": "2020-07-11T04:37:08Z", "message": "fix race condition"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a8fbcc37a3f9881be49852b8a300b046a90a920", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/7a8fbcc37a3f9881be49852b8a300b046a90a920", "committedDate": "2020-07-11T04:41:10Z", "message": "remove unnecessary node from test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2Nzc4Mzcz", "url": "https://github.com/apache/kafka/pull/8994#pullrequestreview-446778373", "createdAt": "2020-07-11T04:58:02Z", "commit": {"oid": "7a8fbcc37a3f9881be49852b8a300b046a90a920"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMVQwNDo1ODowMlrOGwKcbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMVQwNDo1ODowMlrOGwKcbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NTk0OQ==", "bodyText": "The flaky test was related to us going into this block from other states. I finally got a clue when one of the tests failed on \"invalid transition from PARTITIONS_REVOKED to RUNNING\". I'm not sure how, exactly, but I think the shutdown test that failed on ConcurrentModificationException was also related, probably due to the test invoking the handleAssignment/Revocation/Lost methods from a different thread (which can normally never happen).\nAnyway, my prior code only intended to add the self transition, but failed to make sure we were actually in a self-transition. It's fixed now.", "url": "https://github.com/apache/kafka/pull/8994#discussion_r453155949", "createdAt": "2020-07-11T04:58:02Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -648,7 +651,9 @@ void runOnce() {\n \n         // only try to initialize the assigned tasks\n         // if the state is still in PARTITION_ASSIGNED after the poll call\n-        if (state == State.PARTITIONS_ASSIGNED) {\n+        if (state == State.PARTITIONS_ASSIGNED\n+            || state == State.RUNNING && taskManager.needsInitializationOrRestoration()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a8fbcc37a3f9881be49852b8a300b046a90a920"}, "originalPosition": 47}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1204, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}