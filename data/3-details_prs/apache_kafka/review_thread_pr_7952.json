{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYyMzczMjI0", "number": 7952, "reviewThreads": {"totalCount": 48, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1Mzo1M1rODYDr1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjo0MDo1N1rODZ5jnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NTUyNzg4OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/message/MessageTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1Mzo1M1rOFdsviA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1Mzo1M1rOFdsviA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4NjA4OA==", "bodyText": "Addressing: #7897 (comment)", "url": "https://github.com/apache/kafka/pull/7952#discussion_r366686088", "createdAt": "2020-01-15T03:53:53Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/message/MessageTest.java", "diffHunk": "@@ -431,11 +431,11 @@ public void testTxnOffsetCommitRequestVersions() throws Exception {\n \n             if (version < 3) {\n                 final short finalVersion = version;\n-                assertThrows(UnsupportedVersionException.class, () -> testAllMessageRoundTripsFromVersion(finalVersion, requestData));\n+                assertThrows(UnsupportedVersionException.class, () -> testEquivalentMessageRoundTrip(finalVersion, requestData));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NTUyODY0OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1NDozN1rOFdsv_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1NDozN1rOFdsv_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4NjIwNA==", "bodyText": "Addressing #7897 (comment)", "url": "https://github.com/apache/kafka/pull/7952#discussion_r366686204", "createdAt": "2020-01-15T03:54:37Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "diffHunk": "@@ -2489,16 +2489,20 @@ class GroupCoordinatorTest {\n     val rebalanceResult = staticMembersJoinAndRebalance(leaderInstanceId, followerInstanceId)\n \n     val leaderNoMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n-      Map(tp -> offset), groupInstanceId = leaderInstanceId)\n+      Map(tp -> offset), memberId = JoinGroupRequest.UNKNOWN_MEMBER_ID, groupInstanceId = leaderInstanceId)\n     assertEquals(Errors.FENCED_INSTANCE_ID, leaderNoMemberIdCommitOffsetResult (tp))\n \n+    val leaderInvalidMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NTUyOTE2OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1NToxMFrOFdswVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwMzo1NToxMFrOFdswVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4NjI5Mw==", "bodyText": "This and the following new tests are addressing the comments for separating valid and invalid scenario: #7897 (comment)", "url": "https://github.com/apache/kafka/pull/7952#discussion_r366686293", "createdAt": "2020-01-15T03:55:10Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "diffHunk": "@@ -2489,16 +2489,20 @@ class GroupCoordinatorTest {\n     val rebalanceResult = staticMembersJoinAndRebalance(leaderInstanceId, followerInstanceId)\n \n     val leaderNoMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n-      Map(tp -> offset), groupInstanceId = leaderInstanceId)\n+      Map(tp -> offset), memberId = JoinGroupRequest.UNKNOWN_MEMBER_ID, groupInstanceId = leaderInstanceId)\n     assertEquals(Errors.FENCED_INSTANCE_ID, leaderNoMemberIdCommitOffsetResult (tp))\n \n+    val leaderInvalidMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n+      Map(tp -> offset), memberId = \"invalid-member\", groupInstanceId = leaderInstanceId)\n+    assertEquals(Errors.FENCED_INSTANCE_ID, leaderInvalidMemberIdCommitOffsetResult (tp))\n+\n     val leaderCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n       Map(tp -> offset), rebalanceResult.leaderId, leaderInstanceId)\n     assertEquals(Errors.NONE, leaderCommitOffsetResult (tp))\n   }\n \n   @Test\n-  def testTxnCommitOffsetWithUnknownMemberId(): Unit = {\n+  def testTxnCommitOffsetWithInvalidMemberId(): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODQ2Mzg2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1MjowMFrOFeJCKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNDozMjoyN1rOFeunMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ==", "bodyText": "We will throw IllegalStateException if unexpected group fencing exception was thrown for old API", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367149611", "createdAt": "2020-01-15T22:52:00Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1497,15 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (isGroupFencingException(error)) {\n+                    if (enableGroupFencing) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3ODQ5NQ==", "bodyText": "I think this check is overkill.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367578495", "createdAt": "2020-01-16T18:26:43Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1497,15 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (isGroupFencingException(error)) {\n+                    if (enableGroupFencing) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ=="}, "originalCommit": null, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU5MTM1NQ==", "bodyText": "But theoretically possible?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367591355", "createdAt": "2020-01-16T18:54:49Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1497,15 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (isGroupFencingException(error)) {\n+                    if (enableGroupFencing) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ=="}, "originalCommit": null, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2NTI5OA==", "bodyText": "After offline discussion, this shall be removed for simplicity.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367765298", "createdAt": "2020-01-17T04:32:27Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1497,15 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (isGroupFencingException(error)) {\n+                    if (enableGroupFencing) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ=="}, "originalCommit": null, "originalPosition": 136}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODQ2NzMzOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1Mzo0MlrOFeJEbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1Mzo0MlrOFeJEbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MDE5MQ==", "bodyText": "We unify the API for groupId and groupMetadata commit here, which includes the groupId within the metadata struct.\nA boolean flag indicating whether to turn on global fencing shall be passed down to the txn commit sender to determine whether we should include (member.id, instance.id, generation.id) in the request.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367150191", "createdAt": "2020-01-15T22:53:42Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -329,17 +329,18 @@ private TransactionalRequestResult beginCompletingTransaction(TransactionResult\n     }\n \n     public synchronized TransactionalRequestResult sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODQ2ODk0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NDozMFrOFeJFdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NDozMFrOFeJFdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MDQ1Mg==", "bodyText": "This separation is to avoid if-else loop complexity warning from checkstyle.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367150452", "createdAt": "2020-01-15T22:54:30Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1524,16 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isGroupFencingException(Errors error) {\n+        return error == Errors.FENCED_INSTANCE_ID\n+                   || error == Errors.UNKNOWN_MEMBER_ID\n+                   || error == Errors.ILLEGAL_GENERATION;\n+    }\n+\n+    private boolean isFatalException(Errors error) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 158}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODQ3MDA0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NTowN1rOFeJGNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NTowN1rOFeJGNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MDY0NQ==", "bodyText": "When working with the multi-version API, I realized that by making the data initialization internal could save a lot of caller's effort.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367150645", "createdAt": "2020-01-15T22:55:07Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "diffHunk": "@@ -45,9 +45,39 @@\n \n         public final TxnOffsetCommitRequestData data;\n \n-        public Builder(TxnOffsetCommitRequestData data) {\n+        public Builder(final String transactionalId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODQ3MzUzOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NjozN1rOFeJIPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1NjozN1rOFeJIPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTE2NA==", "bodyText": "The test coverage for KafkaProducerTest is weak in general. We just did the bare minimum here to route the request through a full init->begin->commit->end workflow and make sure it is working properly.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367151164", "createdAt": "2020-01-15T22:56:37Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -689,6 +698,90 @@ public void testInitTransactionWhileThrottled() {\n         }\n     }\n \n+    @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODQ3NzU5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1ODoyMFrOFeJKsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNDozNDowMFrOFeuoIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg==", "bodyText": "The purpose of this cachedGroupMetadata is to avoid the creation of groupMetadata everytime we call the old API. It could also be served as a security check on whether the consumer group id has changed in the middle by sending out a warning indicating some illegal state. In Streams or other general EOS use cases, this should never happen.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367151792", "createdAt": "2020-01-15T22:58:20Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIzOTgzMQ==", "bodyText": "Hmm, this feels like premature optimization. The offsets map is more likely to be a problem. Also, I'm not sure we should restrict the usage. It is possible today to send offsets for multiple groups. Is there a good reason to restrict this even if it doesn't make sense in streams?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367239831", "createdAt": "2020-01-16T05:43:32Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NTQ4MA==", "bodyText": "While this is allowed, I couldn't imagine the case as straightforward when you are committing offsets for 2 consumer groups within the same txn. But I agree we probably don't need to log a warning or anything here.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367585480", "createdAt": "2020-01-16T18:42:19Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYwNDE4Nw==", "bodyText": "I also feel it may be overkill to cache the cachedGroupMetadata on the producer side -- is it part of the reasons violating ClassFanOutComplexity and ClassDataAbstractionCoupling?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367604187", "createdAt": "2020-01-16T19:22:23Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}, "originalCommit": null, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2NTUzOQ==", "bodyText": "Sounds good, we shall abandon the cache and just initialize a new one everytime: it shouldn't be a big memory overhead after I think about it. (maybe 100B every commit interval)", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367765539", "createdAt": "2020-01-17T04:34:00Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}, "originalCommit": null, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODQ3OTI1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1ODo1OVrOFeJLqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjo1ODo1OVrOFeJLqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MjA0Mg==", "bodyText": "This is just leveraging the same security check here, no harm to do for both API calls.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367152042", "createdAt": "2020-01-15T22:58:59Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone\n+     * mode EOS applications are still relying on it. If the broker version is lower than 2.5.0 which doesn't support the new underlying protocol,\n+     * this API call will throw UnsupportedVersionException.\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.common.errors.IllegalGenerationException if the passed in consumer metadata has illegal generation\n+     * @throws org.apache.kafka.common.errors.UnknownMemberIdException if the passed in consumer metadata has unknown member.id\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,\n+               IllegalGenerationException,\n+               UnknownMemberIdException,\n+               FencedInstanceIdException {\n+        if (!cachedGroupMetadata.groupId().equals(groupMetadata.groupId())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODUwNzg3OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoxMzoxMVrOFeJdIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoxMzoxMVrOFeJdIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1NjUxMw==", "bodyText": "The 3 tests here are primarily evaluating that when we are on groupMetadata mode, we could correctly detect FENCED_INSTANCE_ID, UNKNOWN_MEMBER_ID and ILLEGAL_GENERATION exceptions.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367156513", "createdAt": "2020-01-15T23:13:11Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -940,6 +948,204 @@ public void testUnsupportedForMessageFormatInTxnOffsetCommit() {\n         assertFatalError(UnsupportedForMessageFormatException.class);\n     }\n \n+    @Test\n+    public void testFencedInstanceIdInTxnOffsetCommitByGroupMetadata() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODUyMTk1OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoyMDo0OFrOFeJl9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoyMDo0OFrOFeJl9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODc3NA==", "bodyText": "A full test to set all 3 group fields", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367158774", "createdAt": "2020-01-15T23:20:48Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -2157,6 +2397,56 @@ public void shouldFailAbortIfAddOffsetsFailsWithFatalError() {\n         assertTrue(transactionManager.hasFatalError());\n     }\n \n+    @Test\n+    public void testSendOffsetsWithGroupMetadata() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 358}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODUyMjk5OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/integration/kafka/api/TransactionsBounceTest.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoyMToyNFrOFeJmmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoyMToyNFrOFeJmmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODkzNg==", "bodyText": "Use new API for compatibility test.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367158936", "createdAt": "2020-01-15T23:21:24Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/TransactionsBounceTest.scala", "diffHunk": "@@ -71,7 +73,19 @@ class TransactionsBounceTest extends KafkaServerTestHarness {\n   }\n \n   @Test\n-  def testBrokerFailure(): Unit = {\n+  def testWithGroupId(): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODUyMzM1OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/integration/kafka/api/TransactionsTest.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoyMTozMlrOFeJmyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoyMTozMlrOFeJmyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODk4Ng==", "bodyText": "Same here for compatibility.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367158986", "createdAt": "2020-01-15T23:21:32Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/TransactionsTest.scala", "diffHunk": "@@ -227,7 +227,20 @@ class TransactionsTest extends KafkaServerTestHarness {\n   }\n \n   @Test\n-  def testSendOffsets() = {\n+  def testSendOffsetsWithGroupId() = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2OTA0MzY4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwNTozODoyOVrOFeOerA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwNTozODoyOVrOFeOerA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIzODgyOA==", "bodyText": "Not from this patch, but this should be private.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367238828", "createdAt": "2020-01-16T05:38:29Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -28,7 +28,10 @@\n     final private String memberId;\n     final Optional<String> groupInstanceId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTE4Mjg3OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODoxNjoyMFrOFei70w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODoxNjoyMFrOFei70w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3Mzk3MQ==", "bodyText": "I don't think this comment should be in the javadoc. If we did deprecate the other API, we would just mark the other as deprecated.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367573971", "createdAt": "2020-01-16T18:16:20Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTE4NzI1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODoxNzo1M1rOFei-fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODo1MDo1NlrOFej4bw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NDY1NA==", "bodyText": "I'm wondering if we should use CommitFailedException. In the consumer, we do not expose illegal generation and unknown member id errors directly to the user.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367574654", "createdAt": "2020-01-16T18:17:53Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone\n+     * mode EOS applications are still relying on it. If the broker version is lower than 2.5.0 which doesn't support the new underlying protocol,\n+     * this API call will throw UnsupportedVersionException.\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.common.errors.IllegalGenerationException if the passed in consumer metadata has illegal generation", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4OTQ4Nw==", "bodyText": "That's a good suggestion, I could wrap unknown member id and illegal generation by a commit failed exception.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367589487", "createdAt": "2020-01-16T18:50:56Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone\n+     * mode EOS applications are still relying on it. If the broker version is lower than 2.5.0 which doesn't support the new underlying protocol,\n+     * this API call will throw UnsupportedVersionException.\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.common.errors.IllegalGenerationException if the passed in consumer metadata has illegal generation", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NDY1NA=="}, "originalCommit": null, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTE5NTIyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODoyMDo1MlrOFejDpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQyMjozODoxMFrOFepzZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NTk3Mg==", "bodyText": "nit: I think we can do away with enableGroupFencing and derive its value from ConsumerGroupMetadata. In spite of my comment on the previous PR, it may be simpler to just let the defaults be consistent with the expected default values and just have one path below.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367575972", "createdAt": "2020-01-16T18:20:52Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYwNzUyOA==", "bodyText": "How do we distinguish with the case where only groupId is passed, v.s. the whole groupMetadata is passed but other fields are UNKNOWN_XXX? Do we guarantee that groupMetadata#generationId should never be UNKNOWN_GENERATION_ID (from the broker-side logic we would not check if the generationId < 0)? If yes then we can use that as the boolean flag and get rid of enableGroupFencing.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367607528", "createdAt": "2020-01-16T19:29:46Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NTk3Mg=="}, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzY4NjUwMg==", "bodyText": "I think we should validate the object when it is received in sendOffsets.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367686502", "createdAt": "2020-01-16T22:38:10Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NTk3Mg=="}, "originalCommit": null, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTE5NzgwOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODoyMTo1MFrOFejFUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQyMzozMTowMVrOFeqzXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NjQwMQ==", "bodyText": "nit: this definition looks really awkward", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367576401", "createdAt": "2020-01-16T18:21:50Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +176,15 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException,\n+                                                                                     IllegalGenerationException,\n+                                                                                     UnknownMemberIdException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU5MDkwNA==", "bodyText": "You mean exception throwing right?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367590904", "createdAt": "2020-01-16T18:53:53Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +176,15 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException,\n+                                                                                     IllegalGenerationException,\n+                                                                                     UnknownMemberIdException,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NjQwMQ=="}, "originalCommit": null, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcwMjg3Nw==", "bodyText": "Yeah, since these are runtime exceptions, I think you can leave them off. Users can see the documentation to see what errors we throw.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367702877", "createdAt": "2020-01-16T23:31:01Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +176,15 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException,\n+                                                                                     IllegalGenerationException,\n+                                                                                     UnknownMemberIdException,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NjQwMQ=="}, "originalCommit": null, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTI1MDM5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODo0MDo0OVrOFejmZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNDozNDo1OVrOFeuoxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NDg3MA==", "bodyText": "nit: if you want a new paragraph you need to add <p>", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367584870", "createdAt": "2020-01-16T18:40:49Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2NTcwMg==", "bodyText": "Sounds good", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367765702", "createdAt": "2020-01-17T04:34:59Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NDg3MA=="}, "originalCommit": null, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTI2MzExOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODo0NToyNVrOFejuPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODo0NToyNVrOFejuPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4Njg3OQ==", "bodyText": "ConsumerGroupMetadata does not have a proper toString() implementation -- if we want to log the object, we should add ConsumerGroupMetadata#toString() to ensure a readable log message.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367586879", "createdAt": "2020-01-16T18:45:25Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -329,17 +329,18 @@ private TransactionalRequestResult beginCompletingTransaction(TransactionResult\n     }\n \n     public synchronized TransactionalRequestResult sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                                            String consumerGroupId) {\n+                                                                            final ConsumerGroupMetadata groupMetadata,\n+                                                                            final boolean enableGroupFencing) {\n         ensureTransactional();\n         maybeFailWithError();\n         if (currentState != State.IN_TRANSACTION)\n             throw new KafkaException(\"Cannot send offsets to transaction either because the producer is not in an \" +\n                     \"active transaction\");\n \n-        log.debug(\"Begin adding offsets {} for consumer group {} to transaction\", offsets, consumerGroupId);\n+        log.debug(\"Begin adding offsets {} for consumer group {} to transaction\", offsets, groupMetadata);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTI2NTc1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODo0NjoxN1rOFejv9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNDozNjozMVrOFeupvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NzMxOQ==", "bodyText": "nit: avoid double spaces", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367587319", "createdAt": "2020-01-16T18:46:17Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {\n         for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {\n             OffsetAndMetadata offsetAndMetadata = entry.getValue();\n             CommittedOffset committedOffset = new CommittedOffset(offsetAndMetadata.offset(),\n                     offsetAndMetadata.metadata(), offsetAndMetadata.leaderEpoch());\n             pendingTxnOffsetCommits.put(entry.getKey(), committedOffset);\n         }\n-        TxnOffsetCommitRequest.Builder builder = new TxnOffsetCommitRequest.Builder(\n-            new TxnOffsetCommitRequestData()\n-                .setTransactionalId(transactionalId)\n-                .setGroupId(consumerGroupId)\n-                .setProducerId(producerIdAndEpoch.producerId)\n-                .setProducerEpoch(producerIdAndEpoch.epoch)\n-                .setTopics(TxnOffsetCommitRequest.getTopics(pendingTxnOffsetCommits))\n-        );\n-        return new TxnOffsetCommitHandler(result, builder);\n+\n+        final  TxnOffsetCommitRequest.Builder builder;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2NTk0OQ==", "bodyText": "Good catch!", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367765949", "createdAt": "2020-01-17T04:36:31Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {\n         for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {\n             OffsetAndMetadata offsetAndMetadata = entry.getValue();\n             CommittedOffset committedOffset = new CommittedOffset(offsetAndMetadata.offset(),\n                     offsetAndMetadata.metadata(), offsetAndMetadata.leaderEpoch());\n             pendingTxnOffsetCommits.put(entry.getKey(), committedOffset);\n         }\n-        TxnOffsetCommitRequest.Builder builder = new TxnOffsetCommitRequest.Builder(\n-            new TxnOffsetCommitRequestData()\n-                .setTransactionalId(transactionalId)\n-                .setGroupId(consumerGroupId)\n-                .setProducerId(producerIdAndEpoch.producerId)\n-                .setProducerEpoch(producerIdAndEpoch.epoch)\n-                .setTopics(TxnOffsetCommitRequest.getTopics(pendingTxnOffsetCommits))\n-        );\n-        return new TxnOffsetCommitHandler(result, builder);\n+\n+        final  TxnOffsetCommitRequest.Builder builder;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NzMxOQ=="}, "originalCommit": null, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTI4MTY4OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODo1MTo0NFrOFej6Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNDo1Njo0M1rOFeu2nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4OTkwMw==", "bodyText": "Why this change? Should sendOffsetsToTransaction not be able to handle null gracefully? Seems it would be a regression if we change the behavior and start to fail on null?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367589903", "createdAt": "2020-01-16T18:51:44Z", "author": {"login": "mjsax"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -152,15 +151,15 @@ public void shouldBeginTransactions() {\n     @Test(expected = IllegalStateException.class)\n     public void shouldThrowOnSendOffsetsToTransactionIfTransactionsNotInitialized() {\n         buildMockProducer(true);\n-        producer.sendOffsetsToTransaction(null, null);\n+        producer.sendOffsetsToTransaction(null, \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2OTI0Nw==", "bodyText": "It is actually not, I will try to specify the object type so we don't need to use 0 length string", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367769247", "createdAt": "2020-01-17T04:56:43Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -152,15 +151,15 @@ public void shouldBeginTransactions() {\n     @Test(expected = IllegalStateException.class)\n     public void shouldThrowOnSendOffsetsToTransactionIfTransactionsNotInitialized() {\n         buildMockProducer(true);\n-        producer.sendOffsetsToTransaction(null, null);\n+        producer.sendOffsetsToTransaction(null, \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4OTkwMw=="}, "originalCommit": null, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTM4NjIxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxOToyODoyOVrOFek8pA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxOToyODoyOVrOFek8pA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYwNjk0OA==", "bodyText": "nit: The first param offsets can be final as well.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367606948", "createdAt": "2020-01-16T19:28:29Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -329,17 +329,18 @@ private TransactionalRequestResult beginCompletingTransaction(TransactionResult\n     }\n \n     public synchronized TransactionalRequestResult sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                                            String consumerGroupId) {\n+                                                                            final ConsumerGroupMetadata groupMetadata,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MTUxNTMxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQyMDoxNDo1MFrOFemNpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNDo1NzozNFrOFeu3DA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyNzY4NA==", "bodyText": "See my other comment: it seems we initialize generationId / memberId as UNKNOWN anyways, which means that if enableFencing is false it would stay as UNKNOWN_XX and the broker would not check its generationId or memberId, so it seem we can get rid of the boolean flag indeed since if only groupId is passed in, the other fields' default value is sufficient to bypass the fencing.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367627684", "createdAt": "2020-01-16T20:14:50Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "diffHunk": "@@ -45,9 +45,39 @@\n \n         public final TxnOffsetCommitRequestData data;\n \n-        public Builder(TxnOffsetCommitRequestData data) {\n+        public Builder(final String transactionalId,\n+                       final String consumerGroupId,\n+                       final long producerId,\n+                       final short producerEpoch,\n+                       final Map<TopicPartition, CommittedOffset> pendingTxnOffsetCommits) {\n+            this(transactionalId,\n+                consumerGroupId,\n+                producerId,\n+                producerEpoch,\n+                pendingTxnOffsetCommits,\n+                JoinGroupRequest.UNKNOWN_MEMBER_ID,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2OTM1Ng==", "bodyText": "Yep, we could just get rid of the check entirely, as for groupId based commit the other fields will all be default.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367769356", "createdAt": "2020-01-17T04:57:34Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "diffHunk": "@@ -45,9 +45,39 @@\n \n         public final TxnOffsetCommitRequestData data;\n \n-        public Builder(TxnOffsetCommitRequestData data) {\n+        public Builder(final String transactionalId,\n+                       final String consumerGroupId,\n+                       final long producerId,\n+                       final short producerEpoch,\n+                       final Map<TopicPartition, CommittedOffset> pendingTxnOffsetCommits) {\n+            this(transactionalId,\n+                consumerGroupId,\n+                producerId,\n+                producerEpoch,\n+                pendingTxnOffsetCommits,\n+                JoinGroupRequest.UNKNOWN_MEMBER_ID,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyNzY4NA=="}, "originalCommit": null, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjQ4MjEzOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNTo1MTo1OVrOFevcVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNTo1MTo1OVrOFevcVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc3ODkwMA==", "bodyText": "Test changes in this class are only for new API coverage.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367778900", "createdAt": "2020-01-17T05:51:59Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -16,14 +16,15 @@\n  */\n package org.apache.kafka.clients.producer;\n \n+import org.apache.kafka.clients.consumer.ConsumerGroupMetadata;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjQ4Njc0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNTo1NTo1M1rOFevfNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNTo1NTo1M1rOFevfNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc3OTYzOA==", "bodyText": "After some thoughts, I feel hesitated to classify the FencedInstanceId as a sub type of CommitFailed, for producer exception handling we should abort the current transaction and let consumer rejoin the group as needed. For instanceId fenced, it is more fatal as an indicator of a malicious client that should fail the entire client. Like @hachikuji proposed, it makes sense for us to specify new EOS example code once the changes are merged so that we could make sure the API is user friendly: https://issues.apache.org/jira/browse/KAFKA-9447", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367779638", "createdAt": "2020-01-17T05:55:53Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTIyOTg1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNTowNDozMlrOFfJkHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNTowNDozMlrOFfJkHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNjg3OA==", "bodyText": "I guess we could also get an auth error for the groupId.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368206878", "createdAt": "2020-01-18T05:04:32Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTIzMTY0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToxMDoyMFrOFfJlEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwMDo1MTozNlrOFfMpNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzEyMA==", "bodyText": "More of a meta comment, but after this  patch, it would be possible for users to use ephemeral transactional Ids since we can rely on the group coordinator fencing. One of the potential follow-ups is to figure out how to make this work from a security perspective. For example, we could piggyback on Group write permission to enforce access.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207120", "createdAt": "2020-01-18T05:10:20Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,11 +625,13 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NzMzMw==", "bodyText": "So the producer.id generation is guaranteed to be unique by Zk? If that's the case, I also agree that we should cleanup txn.id security logic. Got 2 tickets to track: https://issues.apache.org/jira/browse/KAFKA-9453\nhttps://issues.apache.org/jira/browse/KAFKA-9454", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368257333", "createdAt": "2020-01-19T00:51:36Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,11 +625,13 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzEyMA=="}, "originalCommit": null, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTIzMjc0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToxNDowMlrOFfJlog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToxNDowMlrOFfJlog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzI2Ng==", "bodyText": "How about this?\n\n... if the commit failed and cannot be retried (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207266", "createdAt": "2020-01-18T05:14:02Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTIzMjg0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToxNTowNFrOFfJlsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwMDozODo0MVrOFfMnmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzI4Mw==", "bodyText": "It seems like we don't need to mention 0.11 here since the requirement for 2.5 is stricter.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207283", "createdAt": "2020-01-18T05:15:04Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NjkyMA==", "bodyText": "The 0.11 and 2.5 unsupported version exceptions are different IMHO.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368256920", "createdAt": "2020-01-19T00:38:41Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzI4Mw=="}, "originalCommit": null, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTIzMzQxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToxNjozMFrOFfJl-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwMDozNzowOFrOFfMnYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzM1Mg==", "bodyText": "Not really sure why we need this method. Why not move the body into the sendOffsetsToTransaction with the same arguments?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207352", "createdAt": "2020-01-18T05:16:30Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,\n+               CommitFailedException,\n+               FencedInstanceIdException {\n+        sendOffsetsToTransactionInternal(offsets, groupMetadata);\n+    }\n+\n+    private void sendOffsetsToTransactionInternal(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata consumerGroupMetadata) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1Njg2Nw==", "bodyText": "This is a legacy, I will clean up", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368256867", "createdAt": "2020-01-19T00:37:08Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,\n+               CommitFailedException,\n+               FencedInstanceIdException {\n+        sendOffsetsToTransactionInternal(offsets, groupMetadata);\n+    }\n+\n+    private void sendOffsetsToTransactionInternal(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata consumerGroupMetadata) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzM1Mg=="}, "originalCommit": null, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTIzMzY2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToxNzo1MFrOFfJmGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToxNzo1MFrOFfJmGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzM4Nw==", "bodyText": "nit: as mentioned elsewhere, I don't think we need to add all of these exceptions to the method. They are all runtime exceptions, so it's still up to the user to read the docs.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207387", "createdAt": "2020-01-18T05:17:50Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTIzNDI5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToyMDowMFrOFfJmcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToyMDowMFrOFfJmcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzQ3NQ==", "bodyText": "nit: we may as well spell out \"Transaction.\" Also, we should probably add :  before the message.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207475", "createdAt": "2020-01-18T05:20:00Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1482,11 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (error == Errors.UNKNOWN_MEMBER_ID\n+                        || error == Errors.ILLEGAL_GENERATION) {\n+                    abortableError(new CommitFailedException(\"Txn offset Commit failed due to consumer group metadata mismatch\" + error.exception().getMessage()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTIzNDkwOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNToyMTo0OVrOFfJmvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNzozNDoxNVrOFgk0Hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ==", "bodyText": "I still don't think this should be a fatal error for the producer. As long as we can still abort the transaction, it should be an abortable error. It's similar to the handling of GROUP_AUTHORIZATION_FAILED.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207549", "createdAt": "2020-01-18T05:21:49Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NzA0OA==", "bodyText": "I'm not strong about this either, as consumer should always be the reliable source for fencing, while producer's exception handling could be simplified.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368257048", "createdAt": "2020-01-19T00:42:50Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, "originalCommit": null, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MzQ0MA==", "bodyText": "Should we make fenced_instance_id non-fatal as well?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368263440", "createdAt": "2020-01-19T03:45:21Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, "originalCommit": null, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI3MjUzNw==", "bodyText": "Just addressed this @guozhangwang", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368272537", "createdAt": "2020-01-19T07:36:20Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, "originalCommit": null, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3ODk3NA==", "bodyText": "Wait, how did we end up back here? I thought we agreed this should not be fatal for the producer? I think it should have a separate branch above, similar to the handling of GROUP_AUTHORIZATION_FAILED.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369678974", "createdAt": "2020-01-22T16:51:24Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, "originalCommit": null, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcwMTkxOA==", "bodyText": "Ugh, my b", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369701918", "createdAt": "2020-01-22T17:34:15Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, "originalCommit": null, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTY2NTczOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/Producer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwMzoyOToyNVrOFfM--g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwNzozNDo1MFrOFfNkKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MjkwNg==", "bodyText": "Why we still have other exceptions declared while in KafkaProducer only ProducerFenced is declared?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368262906", "createdAt": "2020-01-19T03:29:25Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/Producer.java", "diffHunk": "@@ -53,6 +57,15 @@\n     void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                   String consumerGroupId) throws ProducerFencedException;\n \n+    /**\n+     * See {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata)}\n+     */\n+    void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                  ConsumerGroupMetadata groupMetadata) throws ProducerFencedException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI3MjQyNA==", "bodyText": "Will cleanup", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368272424", "createdAt": "2020-01-19T07:34:50Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/Producer.java", "diffHunk": "@@ -53,6 +57,15 @@\n     void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                   String consumerGroupId) throws ProducerFencedException;\n \n+    /**\n+     * See {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata)}\n+     */\n+    void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                  ConsumerGroupMetadata groupMetadata) throws ProducerFencedException,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MjkwNg=="}, "originalCommit": null, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTY2ODYzOnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/integration/kafka/api/TransactionsBounceTest.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwMzo0MDozM1rOFfNAfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwNzozNTo1N1rOFfNkkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MzI5NQ==", "bodyText": "Where is this function defined?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368263295", "createdAt": "2020-01-19T03:40:33Z", "author": {"login": "guozhangwang"}, "path": "core/src/test/scala/integration/kafka/api/TransactionsBounceTest.scala", "diffHunk": "@@ -103,7 +117,7 @@ class TransactionsBounceTest extends KafkaServerTestHarness {\n             !shouldAbort), new ErrorLoggingCallback(outputTopic, record.key, record.value, true))\n         }\n         trace(s\"Sent ${records.size} messages. Committing offsets.\")\n-        producer.sendOffsetsToTransaction(TestUtils.consumerPositions(consumer).asJava, consumerGroup)\n+        commit(producer, consumerGroup, consumer)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI3MjUyOA==", "bodyText": "It's defined as a passed in parameter for testBrokerFailure", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368272528", "createdAt": "2020-01-19T07:35:57Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/TransactionsBounceTest.scala", "diffHunk": "@@ -103,7 +117,7 @@ class TransactionsBounceTest extends KafkaServerTestHarness {\n             !shouldAbort), new ErrorLoggingCallback(outputTopic, record.key, record.value, true))\n         }\n         trace(s\"Sent ${records.size} messages. Committing offsets.\")\n-        producer.sendOffsetsToTransaction(TestUtils.consumerPositions(consumer).asJava, consumerGroup)\n+        commit(producer, consumerGroup, consumer)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MzI5NQ=="}, "originalCommit": null, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NjA1MzQwOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQxODo0OTo0MFrOFfQFJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxNzoyODozMFrOFgCheg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzYzOA==", "bodyText": "It's not really valid to commit offsets with a null groupId. Why don't we use requireNonNull?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313638", "createdAt": "2020-01-19T18:49:40Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +173,13 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {\n+        String groupId = groupMetadata != null ? groupMetadata.groupId() : null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMyMTA1MQ==", "bodyText": "We could do that, it's just a legacy logic for allowing null groupId", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368321051", "createdAt": "2020-01-19T20:41:59Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +173,13 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {\n+        String groupId = groupMetadata != null ? groupMetadata.groupId() : null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzYzOA=="}, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0MDA5MA==", "bodyText": "It never actually made sense since the producer itself doesn't support it.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369140090", "createdAt": "2020-01-21T17:28:30Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +173,13 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {\n+        String groupId = groupMetadata != null ? groupMetadata.groupId() : null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzYzOA=="}, "originalCommit": null, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NjA1MzQ2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQxODo0OTo0NFrOFfQFLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMzowMDo1N1rOFgLrwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzY0Nw==", "bodyText": "Might be worth adding a null check here for groupMetadata. Another simple validation is ensuring that if generationId > 0, then memberId should be non-empty.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313647", "createdAt": "2020-01-19T18:49:44Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,22 +623,60 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,\n+     *                               or encounters unexpected group fencing exception which should only be returned from\n+     *                               new {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata) sendOffsets}.\n      * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n      * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n      *         does not support transactions (i.e. if its version is lower than 0.11.0.0)\n-     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException  fatal error indicating the message\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n      *         format used for the offsets topic on the broker does not support transactions\n      * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n-     *         transactional.id is not authorized. See the exception for more details\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n      * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n      *         other unexpected error\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransaction(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException  if the commit failed and cannot be retried\n+     *         (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODcxMTEzNQ==", "bodyText": "Why do we need a null check here? The groupMetadata itself will through NPE if it is not defined on TransactionManager#sendOffsetsToTransaction", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368711135", "createdAt": "2020-01-20T20:12:08Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,22 +623,60 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,\n+     *                               or encounters unexpected group fencing exception which should only be returned from\n+     *                               new {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata) sendOffsets}.\n      * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n      * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n      *         does not support transactions (i.e. if its version is lower than 0.11.0.0)\n-     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException  fatal error indicating the message\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n      *         format used for the offsets topic on the broker does not support transactions\n      * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n-     *         transactional.id is not authorized. See the exception for more details\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n      * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n      *         other unexpected error\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransaction(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException  if the commit failed and cannot be retried\n+     *         (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzY0Nw=="}, "originalCommit": null, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0MDg1OQ==", "bodyText": "We can give a clear message saying null is not supported. If it's an NPE somewhere down the stack then the user doesn't know if it's a bug or not.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369140859", "createdAt": "2020-01-21T17:30:09Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,22 +623,60 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,\n+     *                               or encounters unexpected group fencing exception which should only be returned from\n+     *                               new {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata) sendOffsets}.\n      * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n      * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n      *         does not support transactions (i.e. if its version is lower than 0.11.0.0)\n-     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException  fatal error indicating the message\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n      *         format used for the offsets topic on the broker does not support transactions\n      * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n-     *         transactional.id is not authorized. See the exception for more details\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n      * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n      *         other unexpected error\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransaction(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException  if the commit failed and cannot be retried\n+     *         (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzY0Nw=="}, "originalCommit": null, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI5MDE3OA==", "bodyText": "sg", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369290178", "createdAt": "2020-01-21T23:00:57Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,22 +623,60 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,\n+     *                               or encounters unexpected group fencing exception which should only be returned from\n+     *                               new {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata) sendOffsets}.\n      * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n      * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n      *         does not support transactions (i.e. if its version is lower than 0.11.0.0)\n-     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException  fatal error indicating the message\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n      *         format used for the offsets topic on the broker does not support transactions\n      * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n-     *         transactional.id is not authorized. See the exception for more details\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n      * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n      *         other unexpected error\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransaction(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException  if the commit failed and cannot be retried\n+     *         (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzY0Nw=="}, "originalCommit": null, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NjA1NDM4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQxODo1MTozOFrOFfQFog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQyMDoyNDoxMVrOFfQcmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzc2Mg==", "bodyText": "Might be nice to have an overload which sets only groupId.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313762", "createdAt": "2020-01-19T18:51:38Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -26,9 +26,12 @@\n     final private String groupId;\n     final private int generationId;\n     final private String memberId;\n-    final Optional<String> groupInstanceId;\n+    final private Optional<String> groupInstanceId;\n \n-    public ConsumerGroupMetadata(String groupId, int generationId, String memberId, Optional<String> groupInstanceId) {\n+    public ConsumerGroupMetadata(String groupId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxOTY0MQ==", "bodyText": "Sg", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368319641", "createdAt": "2020-01-19T20:24:11Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -26,9 +26,12 @@\n     final private String groupId;\n     final private int generationId;\n     final private String memberId;\n-    final Optional<String> groupInstanceId;\n+    final private Optional<String> groupInstanceId;\n \n-    public ConsumerGroupMetadata(String groupId, int generationId, String memberId, Optional<String> groupInstanceId) {\n+    public ConsumerGroupMetadata(String groupId,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzc2Mg=="}, "originalCommit": null, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NjA1NTk5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQxODo1NTo1MlrOFfQGcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMzowNDozM1rOFgLweA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzk2OA==", "bodyText": "I think there's probably a good case to raise this one directly as an abortable error instead of getting wrapped in CommitFailedException. Although it is not fatal for the producer, the user shouldn't ignore it.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313968", "createdAt": "2020-01-19T18:55:52Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,16 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isGroupMetadataMisMatch(Errors error) {\n+        return error == Errors.FENCED_INSTANCE_ID", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzMjc2MA==", "bodyText": "User will have to handle this exception properly by either:\n\naborting the transaction as recommended\nfail the entire application to be more strict\nother cases as they see fit\n\nSo no matter how to handle it, the error shall not be ignored. If we are throwing 3 different types of exceptions, user would as well need to catch 3 different types of exceptions IMHO", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368332760", "createdAt": "2020-01-19T23:33:29Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,16 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isGroupMetadataMisMatch(Errors error) {\n+        return error == Errors.FENCED_INSTANCE_ID", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzk2OA=="}, "originalCommit": null, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0NDI5NA==", "bodyText": "My expectation for illegal generation and unknown member id is that it can be more or less ignored. The user should abort the transaction, but then continue after rejoining the group. The instance fenced error means a new instance of the application has been started somewhere and the application should be stopped.\nBy the way, this is why I suggested writing some example code which shows what we consider to be proper handling. This will give us a better idea if the handling is reasonable, awkward, or incomplete.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369144294", "createdAt": "2020-01-21T17:37:34Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,16 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isGroupMetadataMisMatch(Errors error) {\n+        return error == Errors.FENCED_INSTANCE_ID", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzk2OA=="}, "originalCommit": null, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI5MTM4NA==", "bodyText": "That's true, we also had a jira to track it here: https://issues.apache.org/jira/browse/KAFKA-9447", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369291384", "createdAt": "2020-01-21T23:04:33Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,16 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isGroupMetadataMisMatch(Errors error) {\n+        return error == Errors.FENCED_INSTANCE_ID", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzk2OA=="}, "originalCommit": null, "originalPosition": 121}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NjA1NzgyOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQxOTowMDowNFrOFfQHXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxNzozMTo1OFrOFgCn1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDIwNQ==", "bodyText": "To ensure that we are really testing the state machine as expected, we should provide a valid groupId. Similarly below.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368314205", "createdAt": "2020-01-19T19:00:04Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -152,15 +154,17 @@ public void shouldBeginTransactions() {\n     @Test(expected = IllegalStateException.class)\n     public void shouldThrowOnSendOffsetsToTransactionIfTransactionsNotInitialized() {\n         buildMockProducer(true);\n-        producer.sendOffsetsToTransaction(null, null);\n+        String groupId = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzMjg2NA==", "bodyText": "I guess the MockProducer is putting the null check later than the state check. I could re-order them if you feel better about it.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368332864", "createdAt": "2020-01-19T23:35:19Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -152,15 +154,17 @@ public void shouldBeginTransactions() {\n     @Test(expected = IllegalStateException.class)\n     public void shouldThrowOnSendOffsetsToTransactionIfTransactionsNotInitialized() {\n         buildMockProducer(true);\n-        producer.sendOffsetsToTransaction(null, null);\n+        String groupId = null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDIwNQ=="}, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0MTcxNg==", "bodyText": "The purpose of this test is to raise an exception if the transaction hasn't been initialized. But we are also providing an invalid groupId. To make sure we hit the right error case, we should provide a valid groupId.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369141716", "createdAt": "2020-01-21T17:31:58Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -152,15 +154,17 @@ public void shouldBeginTransactions() {\n     @Test(expected = IllegalStateException.class)\n     public void shouldThrowOnSendOffsetsToTransactionIfTransactionsNotInitialized() {\n         buildMockProducer(true);\n-        producer.sendOffsetsToTransaction(null, null);\n+        String groupId = null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDIwNQ=="}, "originalCommit": null, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NjA1ODg3OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQxOTowMTo0MlrOFfQH3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQyMDoyNDo1OFrOFfQc5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDMzNQ==", "bodyText": "These test cases seem to be identical code other than the error. Can we factor out a helper?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368314335", "createdAt": "2020-01-19T19:01:42Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -940,6 +946,134 @@ public void testUnsupportedForMessageFormatInTxnOffsetCommit() {\n         assertFatalError(UnsupportedForMessageFormatException.class);\n     }\n \n+    @Test\n+    public void testFencedInstanceIdInTxnOffsetCommitByGroupMetadata() {\n+        final String consumerGroupId = \"consumer\";\n+        final long pid = 13131L;\n+        final short epoch = 1;\n+        final TopicPartition tp = new TopicPartition(\"foo\", 0);\n+        final String memberId = \"member\";\n+        final String fencedMemberId = \"fenced_member\";\n+        final String instanceId = \"instance\";\n+\n+        doInitTransactions(pid, epoch);\n+\n+        transactionManager.beginTransaction();\n+\n+        TransactionalRequestResult sendOffsetsResult = transactionManager.sendOffsetsToTransaction(\n+            singletonMap(tp, new OffsetAndMetadata(39L)),\n+            new ConsumerGroupMetadata(consumerGroupId, 5, fencedMemberId, Optional.of(instanceId)));\n+\n+        prepareAddOffsetsToTxnResponse(Errors.NONE, consumerGroupId, pid, epoch);\n+        sender.runOnce();  // AddOffsetsToTxn Handled, TxnOffsetCommit Enqueued\n+        sender.runOnce();  // FindCoordinator Enqueued\n+\n+        prepareFindCoordinatorResponse(Errors.NONE, false, CoordinatorType.GROUP, consumerGroupId);\n+        sender.runOnce();  // FindCoordinator Returned\n+\n+        client.prepareResponse(request -> {\n+            TxnOffsetCommitRequest txnOffsetCommitRequest = (TxnOffsetCommitRequest) request;\n+            assertEquals(consumerGroupId, txnOffsetCommitRequest.data.groupId());\n+            assertEquals(pid, txnOffsetCommitRequest.data.producerId());\n+            assertEquals(epoch, txnOffsetCommitRequest.data.producerEpoch());\n+            return txnOffsetCommitRequest.data.groupInstanceId().equals(instanceId)\n+                && !txnOffsetCommitRequest.data.memberId().equals(memberId);\n+        }, new TxnOffsetCommitResponse(0, singletonMap(tp, Errors.FENCED_INSTANCE_ID)));\n+\n+        sender.runOnce();  // TxnOffsetCommit Handled\n+\n+        assertTrue(transactionManager.hasError());\n+        assertTrue(transactionManager.lastError() instanceof CommitFailedException);\n+        assertTrue(sendOffsetsResult.isCompleted());\n+        assertFalse(sendOffsetsResult.isSuccessful());\n+        assertTrue(sendOffsetsResult.error() instanceof CommitFailedException);\n+        assertAbortableError(CommitFailedException.class);\n+    }\n+\n+    @Test\n+    public void testUnknownMemberIdInTxnOffsetCommitByGroupMetadata() {\n+        final String consumerGroupId = \"consumer\";\n+        final long pid = 13131L;\n+        final short epoch = 1;\n+        final TopicPartition tp = new TopicPartition(\"foo\", 0);\n+        final String memberId = \"member\";\n+        final String unknownMemberId = \"unknownMember\";\n+\n+        doInitTransactions(pid, epoch);\n+\n+        transactionManager.beginTransaction();\n+\n+        TransactionalRequestResult sendOffsetsResult = transactionManager.sendOffsetsToTransaction(\n+            singletonMap(tp, new OffsetAndMetadata(39L)),\n+            new ConsumerGroupMetadata(consumerGroupId, 5, unknownMemberId, Optional.empty()));\n+\n+        prepareAddOffsetsToTxnResponse(Errors.NONE, consumerGroupId, pid, epoch);\n+        sender.runOnce();  // AddOffsetsToTxn Handled, TxnOffsetCommit Enqueued\n+        sender.runOnce();  // FindCoordinator Enqueued\n+\n+        prepareFindCoordinatorResponse(Errors.NONE, false, CoordinatorType.GROUP, consumerGroupId);\n+        sender.runOnce();  // FindCoordinator Returned\n+\n+        client.prepareResponse(request -> {\n+            TxnOffsetCommitRequest txnOffsetCommitRequest = (TxnOffsetCommitRequest) request;\n+            assertEquals(consumerGroupId, txnOffsetCommitRequest.data.groupId());\n+            assertEquals(pid, txnOffsetCommitRequest.data.producerId());\n+            assertEquals(epoch, txnOffsetCommitRequest.data.producerEpoch());\n+            return !txnOffsetCommitRequest.data.memberId().equals(memberId);\n+        }, new TxnOffsetCommitResponse(0, singletonMap(tp, Errors.UNKNOWN_MEMBER_ID)));\n+        sender.runOnce();  // TxnOffsetCommit Handled\n+\n+        assertTrue(transactionManager.hasError());\n+        assertTrue(transactionManager.lastError() instanceof CommitFailedException);\n+        assertTrue(sendOffsetsResult.isCompleted());\n+        assertFalse(sendOffsetsResult.isSuccessful());\n+        assertTrue(sendOffsetsResult.error() instanceof CommitFailedException);\n+        assertAbortableError(CommitFailedException.class);\n+    }\n+\n+    @Test\n+    public void testIllegalGenerationInTxnOffsetCommitByGroupMetadata() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxOTcxNg==", "bodyText": "Actually there are a couple of differences inside the test, such as error type, consumer metadata creation, and request matcher. Probably we could just leave as it is since new readers would just fix one by reading through the whole block", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368319716", "createdAt": "2020-01-19T20:24:58Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -940,6 +946,134 @@ public void testUnsupportedForMessageFormatInTxnOffsetCommit() {\n         assertFatalError(UnsupportedForMessageFormatException.class);\n     }\n \n+    @Test\n+    public void testFencedInstanceIdInTxnOffsetCommitByGroupMetadata() {\n+        final String consumerGroupId = \"consumer\";\n+        final long pid = 13131L;\n+        final short epoch = 1;\n+        final TopicPartition tp = new TopicPartition(\"foo\", 0);\n+        final String memberId = \"member\";\n+        final String fencedMemberId = \"fenced_member\";\n+        final String instanceId = \"instance\";\n+\n+        doInitTransactions(pid, epoch);\n+\n+        transactionManager.beginTransaction();\n+\n+        TransactionalRequestResult sendOffsetsResult = transactionManager.sendOffsetsToTransaction(\n+            singletonMap(tp, new OffsetAndMetadata(39L)),\n+            new ConsumerGroupMetadata(consumerGroupId, 5, fencedMemberId, Optional.of(instanceId)));\n+\n+        prepareAddOffsetsToTxnResponse(Errors.NONE, consumerGroupId, pid, epoch);\n+        sender.runOnce();  // AddOffsetsToTxn Handled, TxnOffsetCommit Enqueued\n+        sender.runOnce();  // FindCoordinator Enqueued\n+\n+        prepareFindCoordinatorResponse(Errors.NONE, false, CoordinatorType.GROUP, consumerGroupId);\n+        sender.runOnce();  // FindCoordinator Returned\n+\n+        client.prepareResponse(request -> {\n+            TxnOffsetCommitRequest txnOffsetCommitRequest = (TxnOffsetCommitRequest) request;\n+            assertEquals(consumerGroupId, txnOffsetCommitRequest.data.groupId());\n+            assertEquals(pid, txnOffsetCommitRequest.data.producerId());\n+            assertEquals(epoch, txnOffsetCommitRequest.data.producerEpoch());\n+            return txnOffsetCommitRequest.data.groupInstanceId().equals(instanceId)\n+                && !txnOffsetCommitRequest.data.memberId().equals(memberId);\n+        }, new TxnOffsetCommitResponse(0, singletonMap(tp, Errors.FENCED_INSTANCE_ID)));\n+\n+        sender.runOnce();  // TxnOffsetCommit Handled\n+\n+        assertTrue(transactionManager.hasError());\n+        assertTrue(transactionManager.lastError() instanceof CommitFailedException);\n+        assertTrue(sendOffsetsResult.isCompleted());\n+        assertFalse(sendOffsetsResult.isSuccessful());\n+        assertTrue(sendOffsetsResult.error() instanceof CommitFailedException);\n+        assertAbortableError(CommitFailedException.class);\n+    }\n+\n+    @Test\n+    public void testUnknownMemberIdInTxnOffsetCommitByGroupMetadata() {\n+        final String consumerGroupId = \"consumer\";\n+        final long pid = 13131L;\n+        final short epoch = 1;\n+        final TopicPartition tp = new TopicPartition(\"foo\", 0);\n+        final String memberId = \"member\";\n+        final String unknownMemberId = \"unknownMember\";\n+\n+        doInitTransactions(pid, epoch);\n+\n+        transactionManager.beginTransaction();\n+\n+        TransactionalRequestResult sendOffsetsResult = transactionManager.sendOffsetsToTransaction(\n+            singletonMap(tp, new OffsetAndMetadata(39L)),\n+            new ConsumerGroupMetadata(consumerGroupId, 5, unknownMemberId, Optional.empty()));\n+\n+        prepareAddOffsetsToTxnResponse(Errors.NONE, consumerGroupId, pid, epoch);\n+        sender.runOnce();  // AddOffsetsToTxn Handled, TxnOffsetCommit Enqueued\n+        sender.runOnce();  // FindCoordinator Enqueued\n+\n+        prepareFindCoordinatorResponse(Errors.NONE, false, CoordinatorType.GROUP, consumerGroupId);\n+        sender.runOnce();  // FindCoordinator Returned\n+\n+        client.prepareResponse(request -> {\n+            TxnOffsetCommitRequest txnOffsetCommitRequest = (TxnOffsetCommitRequest) request;\n+            assertEquals(consumerGroupId, txnOffsetCommitRequest.data.groupId());\n+            assertEquals(pid, txnOffsetCommitRequest.data.producerId());\n+            assertEquals(epoch, txnOffsetCommitRequest.data.producerEpoch());\n+            return !txnOffsetCommitRequest.data.memberId().equals(memberId);\n+        }, new TxnOffsetCommitResponse(0, singletonMap(tp, Errors.UNKNOWN_MEMBER_ID)));\n+        sender.runOnce();  // TxnOffsetCommit Handled\n+\n+        assertTrue(transactionManager.hasError());\n+        assertTrue(transactionManager.lastError() instanceof CommitFailedException);\n+        assertTrue(sendOffsetsResult.isCompleted());\n+        assertFalse(sendOffsetsResult.isSuccessful());\n+        assertTrue(sendOffsetsResult.error() instanceof CommitFailedException);\n+        assertAbortableError(CommitFailedException.class);\n+    }\n+\n+    @Test\n+    public void testIllegalGenerationInTxnOffsetCommitByGroupMetadata() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDMzNQ=="}, "originalCommit": null, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NjA2MDA4OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQxOTowNDoxNFrOFfQIgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQyMzozODoxMVrOFfRRCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDQ5OA==", "bodyText": "Seems this test case would be more interesting if we tried to commit a separate set of offsets before aborting", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368314498", "createdAt": "2020-01-19T19:04:14Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -568,6 +638,31 @@ public void shouldPreserveCommittedConsumerGroupsOffsetsOnAbortIfTransactionsAre\n         assertThat(producer.consumerGroupOffsetsHistory(), equalTo(Collections.singletonList(expectedResult)));\n     }\n \n+    @Test\n+    public void shouldPreserveOffsetsFromCommitByGroupMetadataOnAbortIfTransactionsAreEnabled() {\n+        buildMockProducer(true);\n+        producer.initTransactions();\n+        producer.beginTransaction();\n+\n+        String group = \"g\";\n+        Map<TopicPartition, OffsetAndMetadata> groupCommit = new HashMap<TopicPartition, OffsetAndMetadata>() {\n+            {\n+                put(new TopicPartition(topic, 0), new OffsetAndMetadata(42L, null));\n+                put(new TopicPartition(topic, 1), new OffsetAndMetadata(73L, null));\n+            }\n+        };\n+        producer.sendOffsetsToTransaction(groupCommit, groupMetadata(group));\n+        producer.commitTransaction();\n+\n+        producer.beginTransaction();\n+        producer.abortTransaction();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzMzA2NQ==", "bodyText": "ack", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368333065", "createdAt": "2020-01-19T23:38:11Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -568,6 +638,31 @@ public void shouldPreserveCommittedConsumerGroupsOffsetsOnAbortIfTransactionsAre\n         assertThat(producer.consumerGroupOffsetsHistory(), equalTo(Collections.singletonList(expectedResult)));\n     }\n \n+    @Test\n+    public void shouldPreserveOffsetsFromCommitByGroupMetadataOnAbortIfTransactionsAreEnabled() {\n+        buildMockProducer(true);\n+        producer.initTransactions();\n+        producer.beginTransaction();\n+\n+        String group = \"g\";\n+        Map<TopicPartition, OffsetAndMetadata> groupCommit = new HashMap<TopicPartition, OffsetAndMetadata>() {\n+            {\n+                put(new TopicPartition(topic, 0), new OffsetAndMetadata(42L, null));\n+                put(new TopicPartition(topic, 1), new OffsetAndMetadata(73L, null));\n+            }\n+        };\n+        producer.sendOffsetsToTransaction(groupCommit, groupMetadata(group));\n+        producer.commitTransaction();\n+\n+        producer.beginTransaction();\n+        producer.abortTransaction();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDQ5OA=="}, "originalCommit": null, "originalPosition": 218}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4NDgxOTQyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjozNToyN1rOFgi1fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjozNToyN1rOFgi1fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY2OTUwMw==", "bodyText": "nit: usually we write this like this:\nthis.groupInstanceId = requireNonNull(groupInstanceId, \"group.instance.id can't be null\");", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369669503", "createdAt": "2020-01-22T16:35:27Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -26,15 +29,29 @@\n     final private String groupId;\n     final private int generationId;\n     final private String memberId;\n-    final Optional<String> groupInstanceId;\n+    final private Optional<String> groupInstanceId;\n \n-    public ConsumerGroupMetadata(String groupId, int generationId, String memberId, Optional<String> groupInstanceId) {\n+    public ConsumerGroupMetadata(String groupId,\n+                                 int generationId,\n+                                 String memberId,\n+                                 Optional<String> groupInstanceId) {\n         this.groupId = groupId;\n         this.generationId = generationId;\n+\n+        Objects.requireNonNull(memberId, \"member.id can't be null\");\n         this.memberId = memberId;\n+\n+        Objects.requireNonNull(groupInstanceId, \"group.instance.id can't be null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4NDgzMjI2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjozODo1NVrOFgi9cA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjozODo1NVrOFgi9cA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MTUzNg==", "bodyText": "nit: I don't think there's any reason to mention this. Unexpected errors fall under KafkaException, which is listed below.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369671536", "createdAt": "2020-01-22T16:38:55Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,22 +622,61 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,\n+     *                               or encounters unexpected group fencing exception which should only be returned from", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4NDgzNzk2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjo0MDoyNlrOFgjBCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxODoxMzo0NVrOFgl_jA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MjQ1Ng==", "bodyText": "nit: we may as well move this check into ConsumerGroupMetadata since we have some other null checks there.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369672456", "createdAt": "2020-01-22T16:40:26Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -1228,6 +1270,17 @@ private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[]\n                         record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n     }\n \n+    private void throwIfInvalidGroupMetadata(ConsumerGroupMetadata groupMetadata) {\n+        if (groupMetadata == null) {\n+            throw new IllegalStateException(\"Consumer group metadata could not be null\");\n+        } else if (groupMetadata.groupId() == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcwMTQ3Nw==", "bodyText": "The check is a little bit over-specific for ConsumerGroupMetadata itself, which is why I put advanced check in here so that people could construct group metadata in error format as they want.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369701477", "createdAt": "2020-01-22T17:33:20Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -1228,6 +1270,17 @@ private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[]\n                         record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n     }\n \n+    private void throwIfInvalidGroupMetadata(ConsumerGroupMetadata groupMetadata) {\n+        if (groupMetadata == null) {\n+            throw new IllegalStateException(\"Consumer group metadata could not be null\");\n+        } else if (groupMetadata.groupId() == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MjQ1Ng=="}, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcyMTIyOA==", "bodyText": "Can you elaborate why this is different from e.g. the memberId?", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369721228", "createdAt": "2020-01-22T18:13:45Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -1228,6 +1270,17 @@ private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[]\n                         record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n     }\n \n+    private void throwIfInvalidGroupMetadata(ConsumerGroupMetadata groupMetadata) {\n+        if (groupMetadata == null) {\n+            throw new IllegalStateException(\"Consumer group metadata could not be null\");\n+        } else if (groupMetadata.groupId() == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MjQ1Ng=="}, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4NDgzOTk5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjo0MDo1N1rOFgjCQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjo0MDo1N1rOFgjCQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3Mjc3MQ==", "bodyText": "I think these should all be IllegalArgumentException. The producer is not in an illegal state.", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369672771", "createdAt": "2020-01-22T16:40:57Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -1228,6 +1270,17 @@ private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[]\n                         record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n     }\n \n+    private void throwIfInvalidGroupMetadata(ConsumerGroupMetadata groupMetadata) {\n+        if (groupMetadata == null) {\n+            throw new IllegalStateException(\"Consumer group metadata could not be null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f"}, "originalPosition": 96}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4356, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}