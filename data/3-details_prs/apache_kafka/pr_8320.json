{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkxNTc2ODA3", "number": 8320, "title": "KAFKA-8470: State change logs should not be in TRACE level", "bodyText": "This patch revises the log level and content of many of the state change logger logs and changes its default log level to INFO.", "createdAt": "2020-03-20T14:56:43Z", "url": "https://github.com/apache/kafka/pull/8320", "merged": true, "mergeCommit": {"oid": "c59835c1d7281863722f5c11b54e6b9c07070304"}, "closed": true, "closedAt": "2020-03-26T21:53:41Z", "author": {"login": "stanislavkozlovski"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcPh56QAFqTM3ODU1OTk0Nw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcRgyfDAFqTM4MjMyMDYyNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4NTU5OTQ3", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-378559947", "createdAt": "2020-03-20T15:01:32Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNTowMTozMlrOF5XWgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNTowNDowMlrOF5XdSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NTc0NA==", "bodyText": "Why is this trace?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395695744", "createdAt": "2020-03-20T15:01:32Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -266,9 +266,10 @@ class RequestSendThread(val controllerId: Int,\n \n         val response = clientResponse.responseBody\n \n-        stateChangeLogger.withControllerEpoch(controllerContext.epoch).trace(s\"Received response \" +\n-          s\"${response.toString(requestHeader.apiVersion)} for request $api with correlation id \" +\n-          s\"${requestHeader.correlationId} sent to broker $brokerNode\")\n+        if (stateChangeLogger.isTraceEnabled)\n+          stateChangeLogger.withControllerEpoch(controllerContext.epoch).trace(s\"Received response \" +\n+            s\"${response.toString(requestHeader.apiVersion)} for request $api with correlation id \" +\n+            s\"${requestHeader.correlationId} sent to broker $brokerNode\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NTg5NQ==", "bodyText": "Shouldn't this one be debug at least?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395695895", "createdAt": "2020-03-20T15:01:47Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -447,13 +448,11 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n \n     leaderAndIsrRequestMap.filterKeys(controllerContext.liveOrShuttingDownBrokerIds.contains).foreach {\n       case (broker, leaderAndIsrPartitionStates) =>\n-        if (stateChangeLog.isTraceEnabled) {\n-          leaderAndIsrPartitionStates.foreach { case (topicPartition, state) =>\n-            val typeOfRequest =\n-              if (broker == state.leader) \"become-leader\"\n-              else \"become-follower\"\n-            stateChangeLog.trace(s\"Sending $typeOfRequest LeaderAndIsr request $state to broker $broker for partition $topicPartition\")\n-          }\n+        leaderAndIsrPartitionStates.foreach { case (topicPartition, state) =>\n+          val typeOfRequest =\n+            if (broker == state.leader) \"become-leader\"\n+            else \"become-follower\"\n+          stateChangeLog.info(s\"Sending $typeOfRequest LeaderAndIsr request $state to broker $broker for partition $topicPartition\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NjA4Mw==", "bodyText": "Why is this trace?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395696083", "createdAt": "2020-03-20T15:02:05Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -473,10 +472,11 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n   }\n \n   private def sendUpdateMetadataRequests(controllerEpoch: Int, stateChangeLog: StateChangeLogger): Unit = {\n-    updateMetadataRequestPartitionInfoMap.foreach { case (tp, partitionState) =>\n-      stateChangeLog.trace(s\"Sending UpdateMetadata request $partitionState to brokers $updateMetadataRequestBrokerSet \" +\n-        s\"for partition $tp\")\n-    }\n+    if (stateChangeLog.isTraceEnabled)\n+      updateMetadataRequestPartitionInfoMap.foreach { case (tp, partitionState) =>\n+        stateChangeLog.trace(s\"Sending UpdateMetadata request $partitionState to brokers $updateMetadataRequestBrokerSet \" +\n+          s\"for partition $tp\")\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NjYwOQ==", "bodyText": "Instead of calling this once per partition, I'd do it once before the loop.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395696609", "createdAt": "2020-03-20T15:02:51Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,33 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val cachedPartitions = new mutable.ArrayBuffer[TopicPartition]\n+        updateMetadataRequest.partitionStates.asScala.foreach { state =>\n+          // per-partition logging here proves to be very expensive due to holding up the partition lock and the request thread\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n-              s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            if (stateChangeLogger.isTraceEnabled)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NzExMA==", "bodyText": "Maybe we don't include the actual partitions in these two logs? Just a count or something?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395697110", "createdAt": "2020-03-20T15:03:33Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,33 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val cachedPartitions = new mutable.ArrayBuffer[TopicPartition]\n+        updateMetadataRequest.partitionStates.asScala.foreach { state =>\n+          // per-partition logging here proves to be very expensive due to holding up the partition lock and the request thread\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n-              s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            if (stateChangeLogger.isTraceEnabled)\n+              stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n+                s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n             deletedPartitions += tp\n           } else {\n-            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, info)\n-            stateChangeLogger.trace(s\"Cached leader info $info for partition $tp in response to \" +\n-              s\"UpdateMetadata request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, state)\n+            if (stateChangeLogger.isTraceEnabled)\n+              stateChangeLogger.trace(s\"Cached leader info $state for partition $tp in response to \" +\n+                s\"UpdateMetadata request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            cachedPartitions += tp\n           }\n         }\n-        metadataSnapshot = MetadataSnapshot(partitionStates, controllerId, aliveBrokers, aliveNodes)\n+        stateChangeLogger.info(s\"Deleted ${deletedPartitions.size} partitions from metadata cache in response to UpdateMetadata \" +\n+          s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId (partitions: $deletedPartitions)\")\n+        stateChangeLogger.info(s\"Cached leader info for ${cachedPartitions.size} partitions in response to UpdateMetadata \" +\n+          s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId (partitions: $cachedPartitions)\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NzQ4MQ==", "bodyText": "Why not increment instead of decrement?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395697481", "createdAt": "2020-03-20T15:04:02Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -386,8 +389,10 @@ class ReplicaManager(val config: KafkaConfig,\n               stateChangeLogger.error(s\"Ignoring stop replica (delete=${stopReplicaRequest.deletePartitions}) for \" +\n                 s\"partition $topicPartition due to storage exception\", e)\n               responseMap.put(topicPartition, Errors.KAFKA_STORAGE_ERROR)\n+              stopReplicaCount -= 1", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4NTk2MzMy", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-378596332", "createdAt": "2020-03-20T15:43:33Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNjowMToyN1rOF5Zxmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNjo1ODowMVrOF5b46A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTczNTQ1MA==", "bodyText": "UpdateMetadata doesn't hold partition level lock. It just holds the ReplicaStateLock. We can probably say that it's expensive since it includes all partitions in the cluster.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395735450", "createdAt": "2020-03-20T16:01:27Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,33 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val cachedPartitions = new mutable.ArrayBuffer[TopicPartition]\n+        updateMetadataRequest.partitionStates.asScala.foreach { state =>\n+          // per-partition logging here proves to be very expensive due to holding up the partition lock and the request thread", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTczOTAxMw==", "bodyText": "Since UpdateMetadata includes all partitions for the cluster, at the info level, we could probably just log a count instead of the actual partition list.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395739013", "createdAt": "2020-03-20T16:07:03Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,33 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val cachedPartitions = new mutable.ArrayBuffer[TopicPartition]\n+        updateMetadataRequest.partitionStates.asScala.foreach { state =>\n+          // per-partition logging here proves to be very expensive due to holding up the partition lock and the request thread\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n-              s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            if (stateChangeLogger.isTraceEnabled)\n+              stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n+                s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n             deletedPartitions += tp\n           } else {\n-            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, info)\n-            stateChangeLogger.trace(s\"Cached leader info $info for partition $tp in response to \" +\n-              s\"UpdateMetadata request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, state)\n+            if (stateChangeLogger.isTraceEnabled)\n+              stateChangeLogger.trace(s\"Cached leader info $state for partition $tp in response to \" +\n+                s\"UpdateMetadata request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            cachedPartitions += tp\n           }\n         }\n-        metadataSnapshot = MetadataSnapshot(partitionStates, controllerId, aliveBrokers, aliveNodes)\n+        stateChangeLogger.info(s\"Deleted ${deletedPartitions.size} partitions from metadata cache in response to UpdateMetadata \" +\n+          s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId (partitions: $deletedPartitions)\")\n+        stateChangeLogger.info(s\"Cached leader info for ${cachedPartitions.size} partitions in response to UpdateMetadata \" +\n+          s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId (partitions: $cachedPartitions)\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NzExMA=="}, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NDY3OA==", "bodyText": "stopReplicaCount => SuccessfulStopReplicaCount ?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395744678", "createdAt": "2020-03-20T16:16:17Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -377,7 +377,10 @@ class ReplicaManager(val config: KafkaConfig,\n         // First stop fetchers for all partitions, then stop the corresponding replicas\n         replicaFetcherManager.removeFetcherForPartitions(partitions)\n         replicaAlterLogDirsManager.removeFetcherForPartitions(partitions)\n-        for (topicPartition <- partitions){\n+\n+        var stopReplicaCount = partitions.size", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0ODcwMg==", "bodyText": "In other places, we log a partition in a separate line. So, we should be consistent.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395748702", "createdAt": "2020-03-20T16:22:45Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -377,7 +377,10 @@ class ReplicaManager(val config: KafkaConfig,\n         // First stop fetchers for all partitions, then stop the corresponding replicas\n         replicaFetcherManager.removeFetcherForPartitions(partitions)\n         replicaAlterLogDirsManager.removeFetcherForPartitions(partitions)\n-        for (topicPartition <- partitions){\n+\n+        var stopReplicaCount = partitions.size\n+        stateChangeLogger.info(s\"Handling stop replica (delete=${stopReplicaRequest.deletePartitions}) for ${stopReplicaCount} partitions (${partitions.mkString(\", \")})\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NTAzNw==", "bodyText": "Here, we could just do an info level logging with the partition count, instead of actual partition list.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395755037", "createdAt": "2020-03-20T16:32:35Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1468,7 +1471,7 @@ class ReplicaManager(val config: KafkaConfig,\n \n       replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))\n       partitionsToMakeFollower.foreach { partition =>\n-        stateChangeLogger.trace(s\"Stopped fetchers as part of become-follower request from controller $controllerId \" +\n+        stateChangeLogger.info(s\"Stopped fetchers as part of become-follower request from controller $controllerId \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NTU2MQ==", "bodyText": "This seems to be useless now since we moved the truncation logic inside replica fetcher. So, we can just remove this logging.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395755561", "createdAt": "2020-03-20T16:33:23Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1478,14 +1481,14 @@ class ReplicaManager(val config: KafkaConfig,\n       }\n \n       partitionsToMakeFollower.foreach { partition =>\n-        stateChangeLogger.trace(s\"Truncated logs and checkpointed recovery boundaries for partition \" +\n+        stateChangeLogger.info(s\"Truncated logs and checkpointed recovery boundaries for partition \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc2NDkxNg==", "bodyText": "We probably can just do an info level logging but with just the partition count.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395764916", "createdAt": "2020-03-20T16:49:12Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -473,10 +472,11 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n   }\n \n   private def sendUpdateMetadataRequests(controllerEpoch: Int, stateChangeLog: StateChangeLogger): Unit = {\n-    updateMetadataRequestPartitionInfoMap.foreach { case (tp, partitionState) =>\n-      stateChangeLog.trace(s\"Sending UpdateMetadata request $partitionState to brokers $updateMetadataRequestBrokerSet \" +\n-        s\"for partition $tp\")\n-    }\n+    if (stateChangeLog.isTraceEnabled)\n+      updateMetadataRequestPartitionInfoMap.foreach { case (tp, partitionState) =>\n+        stateChangeLog.trace(s\"Sending UpdateMetadata request $partitionState to brokers $updateMetadataRequestBrokerSet \" +\n+          s\"for partition $tp\")\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NjA4Mw=="}, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc2NjA4OA==", "bodyText": "The main goal is to avoid partition level logging for UpdateMetadata since it includes all partitions in the cluster. So we can probably log in info, but for UpdataMetadata, only log partition count.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395766088", "createdAt": "2020-03-20T16:51:06Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -266,9 +266,10 @@ class RequestSendThread(val controllerId: Int,\n \n         val response = clientResponse.responseBody\n \n-        stateChangeLogger.withControllerEpoch(controllerContext.epoch).trace(s\"Received response \" +\n-          s\"${response.toString(requestHeader.apiVersion)} for request $api with correlation id \" +\n-          s\"${requestHeader.correlationId} sent to broker $brokerNode\")\n+        if (stateChangeLogger.isTraceEnabled)\n+          stateChangeLogger.withControllerEpoch(controllerContext.epoch).trace(s\"Received response \" +\n+            s\"${response.toString(requestHeader.apiVersion)} for request $api with correlation id \" +\n+            s\"${requestHeader.correlationId} sent to broker $brokerNode\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NTc0NA=="}, "originalCommit": null, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc3MDA4OA==", "bodyText": "This logging seems mis-placed. We probably just want to move this to after replicaFetcherManager.removeFetcherForPartitions() with just the partition count. We already have info logging inside Partition.makeLeader() and we can change that logging to stateChangeLog.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395770088", "createdAt": "2020-03-20T16:58:01Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1353,7 +1356,7 @@ class ReplicaManager(val config: KafkaConfig,\n         try {\n           if (partition.makeLeader(controllerId, partitionState, correlationId, highWatermarkCheckpoints)) {\n             partitionsToMakeLeaders += partition\n-            stateChangeLogger.trace(s\"Stopped fetchers as part of become-leader request from \" +\n+            stateChangeLogger.info(s\"Stopped fetchers as part of become-leader request from \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4ODQ1NzQ5", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-378845749", "createdAt": "2020-03-20T22:30:40Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQyMjozMDo0MVrOF5k4VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQyMzo1NjoyNVrOF5mCdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkxNzM5Nw==", "bodyText": "This comment is no longer needed.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395917397", "createdAt": "2020-03-20T22:30:41Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,27 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val cachedPartitions = new mutable.ArrayBuffer[TopicPartition]\n+        updateMetadataRequest.partitionStates.asScala.foreach { state =>\n+          // per-partition logging here proves to be expensive because it includes all partitions in the cluster", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkxNzU3Mw==", "bodyText": "We just need the count. So cachedPartitions could be an int.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395917573", "createdAt": "2020-03-20T22:31:18Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,27 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val cachedPartitions = new mutable.ArrayBuffer[TopicPartition]", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkxOTkwMQ==", "bodyText": "Let's keep this as TRACE logging here.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395919901", "createdAt": "2020-03-20T22:40:01Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1334,12 +1337,6 @@ class ReplicaManager(val config: KafkaConfig,\n                           correlationId: Int,\n                           responseMap: mutable.Map[TopicPartition, Errors],\n                           highWatermarkCheckpoints: OffsetCheckpoints): Set[Partition] = {\n-    partitionStates.keys.foreach { partition =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyMDE2Mw==", "bodyText": "Change the logging to \"Stopped fetchers as part of become-leader request from ...\".", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395920163", "createdAt": "2020-03-20T22:41:06Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1348,12 +1345,15 @@ class ReplicaManager(val config: KafkaConfig,\n     try {\n       // First stop fetchers for all the partitions\n       replicaFetcherManager.removeFetcherForPartitions(partitionStates.keySet.map(_.topicPartition))\n+      stateChangeLogger.info(s\"Handling LeaderAndIsr request correlationId $correlationId from \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyMDI4OA==", "bodyText": "We can remove this logging since partition.makeLeader() logs to stateChangeLog now.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395920288", "createdAt": "2020-03-20T22:41:36Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1348,12 +1345,15 @@ class ReplicaManager(val config: KafkaConfig,\n     try {\n       // First stop fetchers for all the partitions\n       replicaFetcherManager.removeFetcherForPartitions(partitionStates.keySet.map(_.topicPartition))\n+      stateChangeLogger.info(s\"Handling LeaderAndIsr request correlationId $correlationId from \" +\n+        s\"controller $controllerId epoch $controllerEpoch starting the become-leader transition for \" +\n+        s\"${partitionStates.size} partitions\")\n       // Update the partition information to be the leader\n       partitionStates.foreach { case (partition, partitionState) =>\n         try {\n           if (partition.makeLeader(controllerId, partitionState, correlationId, highWatermarkCheckpoints)) {\n             partitionsToMakeLeaders += partition\n-            stateChangeLogger.trace(s\"Stopped fetchers as part of become-leader request from \" +\n+            stateChangeLogger.info(s\"Stopped fetchers as part of become-leader request from \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyMTEwMg==", "bodyText": "Let's keep this as TRACE logging here.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395921102", "createdAt": "2020-03-20T22:44:40Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1384,7 +1384,7 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n \n     partitionStates.keys.foreach { partition =>\n-      stateChangeLogger.trace(s\"Completed LeaderAndIsr request correlationId $correlationId from controller $controllerId \" +\n+      stateChangeLogger.info(s\"Completed LeaderAndIsr request correlationId $correlationId from controller $controllerId \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyMTE4NA==", "bodyText": "Let's keep this as TRACE logging here. But add an info level state change log in Partition.makeFollower().", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395921184", "createdAt": "2020-03-20T22:45:00Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1416,7 +1416,7 @@ class ReplicaManager(val config: KafkaConfig,\n                             responseMap: mutable.Map[TopicPartition, Errors],\n                             highWatermarkCheckpoints: OffsetCheckpoints) : Set[Partition] = {\n     partitionStates.foreach { case (partition, partitionState) =>\n-      stateChangeLogger.trace(s\"Handling LeaderAndIsr request correlationId $correlationId from controller $controllerId \" +\n+      stateChangeLogger.info(s\"Handling LeaderAndIsr request correlationId $correlationId from controller $controllerId \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyMTU5Mw==", "bodyText": "Let's keep this as TRACE logging here.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395921593", "createdAt": "2020-03-20T22:46:38Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1467,25 +1467,16 @@ class ReplicaManager(val config: KafkaConfig,\n       }\n \n       replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))\n-      partitionsToMakeFollower.foreach { partition =>\n-        stateChangeLogger.trace(s\"Stopped fetchers as part of become-follower request from controller $controllerId \" +\n-          s\"epoch $controllerEpoch with correlation id $correlationId for partition ${partition.topicPartition} with leader \" +\n-          s\"${partitionStates(partition).leader}\")\n-      }\n+      stateChangeLogger.info(s\"Stopped fetchers as part of become-follower request from controller $controllerId \" +\n+        s\"epoch $controllerEpoch with correlation id $correlationId for ${partitionsToMakeFollower.size} partitions\")\n \n       partitionsToMakeFollower.foreach { partition =>\n         completeDelayedFetchOrProduceRequests(partition.topicPartition)\n       }\n \n-      partitionsToMakeFollower.foreach { partition =>\n-        stateChangeLogger.trace(s\"Truncated logs and checkpointed recovery boundaries for partition \" +\n-          s\"${partition.topicPartition} as part of become-follower request with correlation id $correlationId from \" +\n-          s\"controller $controllerId epoch $controllerEpoch with leader ${partitionStates(partition).leader}\")\n-      }\n-\n       if (isShuttingDown.get()) {\n         partitionsToMakeFollower.foreach { partition =>\n-          stateChangeLogger.trace(s\"Skipped the adding-fetcher step of the become-follower state \" +\n+          stateChangeLogger.info(s\"Skipped the adding-fetcher step of the become-follower state \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyMjA2MA==", "bodyText": "We already have info level logging in replicaFetcherManager.addFetcherForPartitions(). So we can just remove this logging.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395922060", "createdAt": "2020-03-20T22:48:40Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1501,7 +1492,7 @@ class ReplicaManager(val config: KafkaConfig,\n \n         replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)\n         partitionsToMakeFollowerWithLeaderAndOffset.foreach { case (partition, initialFetchState) =>\n-          stateChangeLogger.trace(s\"Started fetcher to new leader as part of become-follower \" +\n+          stateChangeLogger.info(s\"Started fetcher to new leader as part of become-follower \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyMjA5OA==", "bodyText": "Let's keep this as TRACE logging here.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395922098", "createdAt": "2020-03-20T22:48:48Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1515,7 +1506,7 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n \n     partitionStates.keys.foreach { partition =>\n-      stateChangeLogger.trace(s\"Completed LeaderAndIsr request correlationId $correlationId from controller $controllerId \" +\n+      stateChangeLogger.info(s\"Completed LeaderAndIsr request correlationId $correlationId from controller $controllerId \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyMzAxMw==", "bodyText": "We can probably keep this as trace. While you are at this, could we also add a trace logging to sendStopReplicaRequest()?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395923013", "createdAt": "2020-03-20T22:52:45Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -473,10 +471,8 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n   }\n \n   private def sendUpdateMetadataRequests(controllerEpoch: Int, stateChangeLog: StateChangeLogger): Unit = {\n-    updateMetadataRequestPartitionInfoMap.foreach { case (tp, partitionState) =>\n-      stateChangeLog.trace(s\"Sending UpdateMetadata request $partitionState to brokers $updateMetadataRequestBrokerSet \" +\n-        s\"for partition $tp\")\n-    }\n+    stateChangeLog.trace(s\"Sending UpdateMetadata request to brokers $updateMetadataRequestBrokerSet \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyNDQ3MA==", "bodyText": "We can probably keep this as trace.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395924470", "createdAt": "2020-03-20T22:58:22Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -447,13 +448,11 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n \n     leaderAndIsrRequestMap.filterKeys(controllerContext.liveOrShuttingDownBrokerIds.contains).foreach {\n       case (broker, leaderAndIsrPartitionStates) =>\n-        if (stateChangeLog.isTraceEnabled) {\n-          leaderAndIsrPartitionStates.foreach { case (topicPartition, state) =>\n-            val typeOfRequest =\n-              if (broker == state.leader) \"become-leader\"\n-              else \"become-follower\"\n-            stateChangeLog.trace(s\"Sending $typeOfRequest LeaderAndIsr request $state to broker $broker for partition $topicPartition\")\n-          }\n+        leaderAndIsrPartitionStates.foreach { case (topicPartition, state) =>\n+          val typeOfRequest =\n+            if (broker == state.leader) \"become-leader\"\n+            else \"become-follower\"\n+          stateChangeLog.info(s\"Sending $typeOfRequest LeaderAndIsr request $state to broker $broker for partition $topicPartition\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5NTg5NQ=="}, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkyNjA2NQ==", "bodyText": "We can probably keep this as trace.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395926065", "createdAt": "2020-03-20T23:04:45Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -266,7 +266,7 @@ class RequestSendThread(val controllerId: Int,\n \n         val response = clientResponse.responseBody\n \n-        stateChangeLogger.withControllerEpoch(controllerContext.epoch).trace(s\"Received response \" +\n+        stateChangeLogger.withControllerEpoch(controllerContext.epoch).info(s\"Received response \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNjM3NQ==", "bodyText": "Since we already have logging in replicaFetcherManager.removeFetcherForPartitions(), we probably don't need any new logging in stopReplicas().", "url": "https://github.com/apache/kafka/pull/8320#discussion_r395936375", "createdAt": "2020-03-20T23:56:25Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -377,17 +377,22 @@ class ReplicaManager(val config: KafkaConfig,\n         // First stop fetchers for all partitions, then stop the corresponding replicas\n         replicaFetcherManager.removeFetcherForPartitions(partitions)\n         replicaAlterLogDirsManager.removeFetcherForPartitions(partitions)\n-        for (topicPartition <- partitions){\n+\n+        var successfulStopReplicaCount = 0\n+        stateChangeLogger.info(s\"Handling stop replica (delete=${stopReplicaRequest.deletePartitions}) for ${partitions.size} partitions (${partitions.mkString(\", \")})\")\n+        for (topicPartition <- partitions) {\n           try {\n             stopReplica(topicPartition, stopReplicaRequest.deletePartitions)\n             responseMap.put(topicPartition, Errors.NONE)\n+            successfulStopReplicaCount += 1\n           } catch {\n             case e: KafkaStorageException =>\n               stateChangeLogger.error(s\"Ignoring stop replica (delete=${stopReplicaRequest.deletePartitions}) for \" +\n                 s\"partition $topicPartition due to storage exception\", e)\n               responseMap.put(topicPartition, Errors.KAFKA_STORAGE_ERROR)\n           }\n         }\n+        stateChangeLogger.info(s\"Successfully handled stop replica (delete=${stopReplicaRequest.deletePartitions}) for ${successfulStopReplicaCount} partitions\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4OTQ0MzA4", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-378944308", "createdAt": "2020-03-21T19:20:43Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQxOToyMDo0M1rOF5rNMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQxOToyMDo0M1rOF5rNMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjAyMTA0MQ==", "bodyText": "I was wondering if the debug() logs a couple of lines below are better suited for the stateChangeLogger", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396021041", "createdAt": "2020-03-21T19:20:43Z", "author": {"login": "stanislavkozlovski"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -550,6 +547,7 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n         brokerEpoch, deletePartitions, partitions)\n     }\n \n+    stateChangeLog.trace(s\"Sending StopReplica request (version $stopReplicaRequestVersion) to brokers ${controllerContext.liveOrShuttingDownBrokerIds}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4OTQ0Mzg2", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-378944386", "createdAt": "2020-03-21T19:21:42Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQxOToyMTo0MlrOF5rNeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQxOToyMTo0MlrOF5rNeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjAyMTExMw==", "bodyText": "I think this made it clearer and easy to separate from the makeFollower() log, even though both have a log line indicating that we're handling a become-leader or become-follower request", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396021113", "createdAt": "2020-03-21T19:21:42Z", "author": {"login": "stanislavkozlovski"}, "path": "core/src/main/scala/kafka/cluster/Partition.scala", "diffHunk": "@@ -497,7 +498,7 @@ class Partition(val topicPartition: TopicPartition,\n \n       val leaderLog = localLogOrException\n       val leaderEpochStartOffset = leaderLog.logEndOffset\n-      info(s\"$topicPartition starts at leader epoch ${partitionState.leaderEpoch} from \" +\n+      stateChangeLogger.info(s\"Leader $topicPartition starts at leader epoch ${partitionState.leaderEpoch} from \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5NTYxNzIy", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-379561722", "createdAt": "2020-03-23T15:48:54Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxNTo0ODo1NFrOF6Lugw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxODoyMzo1NlrOF6SfpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU1Mzg1OQ==", "bodyText": "Yes, we could just change the following debug logging to  stateChangeLog.trace. Also, in the logging, we could just log StopReplicaRequestInfo.replica since StopReplicaRequestInfo.deletePartition is already extracted out.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396553859", "createdAt": "2020-03-23T15:48:54Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -550,6 +547,7 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n         brokerEpoch, deletePartitions, partitions)\n     }\n \n+    stateChangeLog.trace(s\"Sending StopReplica request (version $stopReplicaRequestVersion) to brokers ${controllerContext.liveOrShuttingDownBrokerIds}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU1NzY5Nw==", "bodyText": "leaderEpochStartOffset => logEndOffset ?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396557697", "createdAt": "2020-03-23T15:53:45Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/cluster/Partition.scala", "diffHunk": "@@ -568,6 +569,12 @@ class Partition(val topicPartition: TopicPartition,\n       )\n       createLogIfNotExists(localBrokerId, partitionState.isNew, isFutureReplica = false, highWatermarkCheckpoints)\n \n+      val followerLog = localLogOrException\n+      val leaderEpochStartOffset = followerLog.logEndOffset", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU2MDEzNQ==", "bodyText": "This is no longer needed?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396560135", "createdAt": "2020-03-23T15:56:51Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -377,10 +377,14 @@ class ReplicaManager(val config: KafkaConfig,\n         // First stop fetchers for all partitions, then stop the corresponding replicas\n         replicaFetcherManager.removeFetcherForPartitions(partitions)\n         replicaAlterLogDirsManager.removeFetcherForPartitions(partitions)\n-        for (topicPartition <- partitions){\n+\n+        var successfulStopReplicaCount = 0", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU2MDQ5NQ==", "bodyText": "We can just log a count at info level.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396560495", "createdAt": "2020-03-23T15:57:16Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -377,10 +377,14 @@ class ReplicaManager(val config: KafkaConfig,\n         // First stop fetchers for all partitions, then stop the corresponding replicas\n         replicaFetcherManager.removeFetcherForPartitions(partitions)\n         replicaAlterLogDirsManager.removeFetcherForPartitions(partitions)\n-        for (topicPartition <- partitions){\n+\n+        var successfulStopReplicaCount = 0\n+        stateChangeLogger.info(s\"Handling stop replica (delete=${stopReplicaRequest.deletePartitions}) for ${partitions.size} partitions (${partitions.mkString(\", \")})\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU2MTE5Mg==", "bodyText": "Let's keep this as trace.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396561192", "createdAt": "2020-03-23T15:58:08Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1158,12 +1162,10 @@ class ReplicaManager(val config: KafkaConfig,\n   def becomeLeaderOrFollower(correlationId: Int,\n                              leaderAndIsrRequest: LeaderAndIsrRequest,\n                              onLeadershipChange: (Iterable[Partition], Iterable[Partition]) => Unit): LeaderAndIsrResponse = {\n-    if (stateChangeLogger.isTraceEnabled) {\n-      leaderAndIsrRequest.partitionStates.asScala.foreach { partitionState =>\n-        stateChangeLogger.trace(s\"Received LeaderAndIsr request $partitionState \" +\n-          s\"correlation id $correlationId from controller ${leaderAndIsrRequest.controllerId} \" +\n-          s\"epoch ${leaderAndIsrRequest.controllerEpoch}\")\n-      }\n+    leaderAndIsrRequest.partitionStates.asScala.foreach { partitionState =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU2MjQ2MA==", "bodyText": "We can simplify this a bit to avoid mentioning become-leader twice.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396562460", "createdAt": "2020-03-23T15:59:44Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1334,29 +1336,29 @@ class ReplicaManager(val config: KafkaConfig,\n                           correlationId: Int,\n                           responseMap: mutable.Map[TopicPartition, Errors],\n                           highWatermarkCheckpoints: OffsetCheckpoints): Set[Partition] = {\n+    val traceEnabled = stateChangeLogger.isTraceEnabled\n     partitionStates.keys.foreach { partition =>\n-      stateChangeLogger.trace(s\"Handling LeaderAndIsr request correlationId $correlationId from \" +\n-        s\"controller $controllerId epoch $controllerEpoch starting the become-leader transition for \" +\n-        s\"partition ${partition.topicPartition}\")\n-    }\n-\n-    for (partition <- partitionStates.keys)\n+      if (traceEnabled)\n+        stateChangeLogger.trace(s\"Handling LeaderAndIsr request correlationId $correlationId from \" +\n+          s\"controller $controllerId epoch $controllerEpoch starting the become-leader transition for \" +\n+          s\"partition ${partition.topicPartition}\")\n       responseMap.put(partition.topicPartition, Errors.NONE)\n+    }\n \n     val partitionsToMakeLeaders = mutable.Set[Partition]()\n \n     try {\n       // First stop fetchers for all the partitions\n       replicaFetcherManager.removeFetcherForPartitions(partitionStates.keySet.map(_.topicPartition))\n+      stateChangeLogger.info(s\"Stopped fetchers as part of become-leader LeaderAndIsr request correlationId $correlationId from \" +\n+        s\"controller $controllerId epoch $controllerEpoch starting the become-leader transition for \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY2NDc0MQ==", "bodyText": "Hmm, this seems incorrect. If trace is disabled and shutdown is true, we don't want to add the fetchers in the else clause. So the trace testing needs to be inside if (isShuttingDown.get().", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396664741", "createdAt": "2020-03-23T18:23:56Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1467,23 +1472,14 @@ class ReplicaManager(val config: KafkaConfig,\n       }\n \n       replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))\n-      partitionsToMakeFollower.foreach { partition =>\n-        stateChangeLogger.trace(s\"Stopped fetchers as part of become-follower request from controller $controllerId \" +\n-          s\"epoch $controllerEpoch with correlation id $correlationId for partition ${partition.topicPartition} with leader \" +\n-          s\"${partitionStates(partition).leader}\")\n-      }\n+      stateChangeLogger.info(s\"Stopped fetchers as part of become-follower request from controller $controllerId \" +\n+        s\"epoch $controllerEpoch with correlation id $correlationId for ${partitionsToMakeFollower.size} partitions\")\n \n       partitionsToMakeFollower.foreach { partition =>\n         completeDelayedFetchOrProduceRequests(partition.topicPartition)\n       }\n \n-      partitionsToMakeFollower.foreach { partition =>\n-        stateChangeLogger.trace(s\"Truncated logs and checkpointed recovery boundaries for partition \" +\n-          s\"${partition.topicPartition} as part of become-follower request with correlation id $correlationId from \" +\n-          s\"controller $controllerId epoch $controllerEpoch with leader ${partitionStates(partition).leader}\")\n-      }\n-\n-      if (isShuttingDown.get()) {\n+      if (isShuttingDown.get() && traceLoggingEnabled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 145}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5OTA5ODY3", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-379909867", "createdAt": "2020-03-23T23:48:14Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QyMzo0ODoxNFrOF6cVzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwNDoxMjowM1rOF6gbHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgyNjA2MQ==", "bodyText": "Could we include StopReplicaRequest.deletePartitions() in the logging?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396826061", "createdAt": "2020-03-23T23:48:14Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -377,7 +377,9 @@ class ReplicaManager(val config: KafkaConfig,\n         // First stop fetchers for all partitions, then stop the corresponding replicas\n         replicaFetcherManager.removeFetcherForPartitions(partitions)\n         replicaAlterLogDirsManager.removeFetcherForPartitions(partitions)\n-        for (topicPartition <- partitions){\n+\n+        stateChangeLogger.info(s\"Handling stop replica for ${partitions.size} partitions\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgyNjgxNg==", "bodyText": "starting the become-leader transition for => as part of the become-leader transition for", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396826816", "createdAt": "2020-03-23T23:50:43Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1334,29 +1336,29 @@ class ReplicaManager(val config: KafkaConfig,\n                           correlationId: Int,\n                           responseMap: mutable.Map[TopicPartition, Errors],\n                           highWatermarkCheckpoints: OffsetCheckpoints): Set[Partition] = {\n+    val traceEnabled = stateChangeLogger.isTraceEnabled\n     partitionStates.keys.foreach { partition =>\n-      stateChangeLogger.trace(s\"Handling LeaderAndIsr request correlationId $correlationId from \" +\n-        s\"controller $controllerId epoch $controllerEpoch starting the become-leader transition for \" +\n-        s\"partition ${partition.topicPartition}\")\n-    }\n-\n-    for (partition <- partitionStates.keys)\n+      if (traceEnabled)\n+        stateChangeLogger.trace(s\"Handling LeaderAndIsr request correlationId $correlationId from \" +\n+          s\"controller $controllerId epoch $controllerEpoch starting the become-leader transition for \" +\n+          s\"partition ${partition.topicPartition}\")\n       responseMap.put(partition.topicPartition, Errors.NONE)\n+    }\n \n     val partitionsToMakeLeaders = mutable.Set[Partition]()\n \n     try {\n       // First stop fetchers for all the partitions\n       replicaFetcherManager.removeFetcherForPartitions(partitionStates.keySet.map(_.topicPartition))\n+      stateChangeLogger.info(s\"Stopped fetchers as part of LeaderAndIsr request correlationId $correlationId from \" +\n+        s\"controller $controllerId epoch $controllerEpoch starting the become-leader transition for \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgyODUxNw==", "bodyText": "Should we add if (stateChangeLog.isTraceEnabled)?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396828517", "createdAt": "2020-03-23T23:56:12Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -473,10 +472,8 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n   }\n \n   private def sendUpdateMetadataRequests(controllerEpoch: Int, stateChangeLog: StateChangeLogger): Unit = {\n-    updateMetadataRequestPartitionInfoMap.foreach { case (tp, partitionState) =>\n-      stateChangeLog.trace(s\"Sending UpdateMetadata request $partitionState to brokers $updateMetadataRequestBrokerSet \" +\n-        s\"for partition $tp\")\n-    }\n+    stateChangeLog.trace(s\"Sending UpdateMetadata request to brokers $updateMetadataRequestBrokerSet \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgyOTQ1Mg==", "bodyText": "This is covered by the logging below. So, we can just remove this.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396829452", "createdAt": "2020-03-23T23:59:23Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -550,6 +547,7 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n         brokerEpoch, deletePartitions, partitions)\n     }\n \n+    stateChangeLog.trace(s\"Sending StopReplica request (version $stopReplicaRequestVersion) to brokers ${controllerContext.liveOrShuttingDownBrokerIds}\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjAyMTA0MQ=="}, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgyOTU5Mg==", "bodyText": "$brokerId is  => $brokerId contains", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396829592", "createdAt": "2020-03-23T23:59:56Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -550,19 +547,23 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n         brokerEpoch, deletePartitions, partitions)\n     }\n \n+    stateChangeLog.trace(s\"Sending StopReplica request (version $stopReplicaRequestVersion) to brokers ${controllerContext.liveOrShuttingDownBrokerIds}\")\n+    val traceEnabled = stateChangeLog.isTraceEnabled\n     stopReplicaRequestMap.filterKeys(controllerContext.liveOrShuttingDownBrokerIds.contains).foreach { case (brokerId, replicaInfoList) =>\n       val (stopReplicaWithDelete, stopReplicaWithoutDelete) = replicaInfoList.partition(r => r.deletePartition)\n       val brokerEpoch = controllerContext.liveBrokerIdAndEpochs(brokerId)\n \n       if (stopReplicaWithDelete.nonEmpty) {\n-        debug(s\"The stop replica request (delete = true) sent to broker $brokerId is ${stopReplicaWithDelete.mkString(\",\")}\")\n+        if (traceEnabled)\n+          stateChangeLog.trace(s\"The stop replica request (delete = true) sent to broker $brokerId is ${stopReplicaWithDelete.map(_.replica).mkString(\",\")}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgyOTY2NA==", "bodyText": "$brokerId is => $brokerId contains", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396829664", "createdAt": "2020-03-24T00:00:11Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -550,19 +547,23 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n         brokerEpoch, deletePartitions, partitions)\n     }\n \n+    stateChangeLog.trace(s\"Sending StopReplica request (version $stopReplicaRequestVersion) to brokers ${controllerContext.liveOrShuttingDownBrokerIds}\")\n+    val traceEnabled = stateChangeLog.isTraceEnabled\n     stopReplicaRequestMap.filterKeys(controllerContext.liveOrShuttingDownBrokerIds.contains).foreach { case (brokerId, replicaInfoList) =>\n       val (stopReplicaWithDelete, stopReplicaWithoutDelete) = replicaInfoList.partition(r => r.deletePartition)\n       val brokerEpoch = controllerContext.liveBrokerIdAndEpochs(brokerId)\n \n       if (stopReplicaWithDelete.nonEmpty) {\n-        debug(s\"The stop replica request (delete = true) sent to broker $brokerId is ${stopReplicaWithDelete.mkString(\",\")}\")\n+        if (traceEnabled)\n+          stateChangeLog.trace(s\"The stop replica request (delete = true) sent to broker $brokerId is ${stopReplicaWithDelete.map(_.replica).mkString(\",\")}\")\n         val stopReplicaRequest = createStopReplicaRequest(brokerEpoch, stopReplicaWithDelete, deletePartitions = true)\n         val callback = stopReplicaPartitionDeleteResponseCallback(brokerId) _\n         sendRequest(brokerId, stopReplicaRequest, callback)\n       }\n \n       if (stopReplicaWithoutDelete.nonEmpty) {\n-        debug(s\"The stop replica request (delete = false) sent to broker $brokerId is ${stopReplicaWithoutDelete.mkString(\",\")}\")\n+        if (traceEnabled)\n+          stateChangeLog.trace(s\"The stop replica request (delete = false) sent to broker $brokerId is ${stopReplicaWithoutDelete.map(_.replica).mkString(\",\")}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzMDA4Nw==", "bodyText": "Do we need to pass stateChangeLog in? It seems that we can just reference it directly.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396830087", "createdAt": "2020-03-24T00:01:38Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -575,7 +576,7 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n       val stateChangeLog = stateChangeLogger.withControllerEpoch(controllerEpoch)\n       sendLeaderAndIsrRequest(controllerEpoch, stateChangeLog)\n       sendUpdateMetadataRequests(controllerEpoch, stateChangeLog)\n-      sendStopReplicaRequests(controllerEpoch)\n+      sendStopReplicaRequests(controllerEpoch, stateChangeLog)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNTc0NQ==", "bodyText": "To be consistent, could we add the same info logging at the beginning of makeLeaders()?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396835745", "createdAt": "2020-03-24T00:21:45Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1415,14 +1418,16 @@ class ReplicaManager(val config: KafkaConfig,\n                             correlationId: Int,\n                             responseMap: mutable.Map[TopicPartition, Errors],\n                             highWatermarkCheckpoints: OffsetCheckpoints) : Set[Partition] = {\n+    val traceLoggingEnabled = stateChangeLogger.isTraceEnabled\n+    stateChangeLogger.info(s\"Handling LeaderAndIsr request correlationId $correlationId from controller $controllerId \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg4OTcyNA==", "bodyText": "This is actually not very useful. So we can leave this in trace. What's more useful is to add an info logging for the leaderAndIsr after the removeReplicasFromIsr() call in line 221.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396889724", "createdAt": "2020-03-24T03:56:52Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ReplicaStateMachine.scala", "diffHunk": "@@ -422,7 +422,7 @@ class ZkReplicaStateMachine(config: KafkaConfig,\n \n   private def logSuccessfulTransition(replicaId: Int, partition: TopicPartition, currState: ReplicaState, targetState: ReplicaState): Unit = {\n     stateChangeLogger.withControllerEpoch(controllerContext.epoch)\n-      .trace(s\"Changed state of replica $replicaId for partition $partition from $currState to $targetState\")\n+      .info(s\"Changed state of replica $replicaId for partition $partition from $currState to $targetState\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg5Mjk1Ng==", "bodyText": "It would be useful to log isr, addingReplicas and removingReplicas too.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r396892956", "createdAt": "2020-03-24T04:12:03Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/cluster/Partition.scala", "diffHunk": "@@ -497,7 +498,7 @@ class Partition(val topicPartition: TopicPartition,\n \n       val leaderLog = localLogOrException\n       val leaderEpochStartOffset = leaderLog.logEndOffset\n-      info(s\"$topicPartition starts at leader epoch ${partitionState.leaderEpoch} from \" +\n+      stateChangeLogger.info(s\"Leader $topicPartition starts at leader epoch ${partitionState.leaderEpoch} from \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwNDc0MTkz", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-380474193", "createdAt": "2020-03-24T16:17:46Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxNjoxNzo0NlrOF64K9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxNjo1NToxNVrOF658XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI4MjAzNw==", "bodyText": "For this one, it's useful to log for each partition.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r397282037", "createdAt": "2020-03-24T16:17:46Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ReplicaStateMachine.scala", "diffHunk": "@@ -219,6 +224,7 @@ class ZkReplicaStateMachine(config: KafkaConfig,\n           controllerContext.partitionLeadershipInfo.contains(replica.topicPartition)\n         }\n         val updatedLeaderIsrAndControllerEpochs = removeReplicasFromIsr(replicaId, replicasWithLeadershipInfo.map(_.topicPartition))\n+        stateLogger.info(s\"Removed replica $replicaId from the ISR of ${updatedLeaderIsrAndControllerEpochs.size} partitions as part of transition to $OfflineReplica\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI4OTM0Nw==", "bodyText": "Let's keep this trace.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r397289347", "createdAt": "2020-03-24T16:26:51Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/PartitionStateMachine.scala", "diffHunk": "@@ -252,13 +252,13 @@ class ZkPartitionStateMachine(config: KafkaConfig,\n         }\n       case OfflinePartition =>\n         validPartitions.foreach { partition =>\n-          stateChangeLog.trace(s\"Changed partition $partition state from ${partitionState(partition)} to $targetState\")\n+          stateChangeLog.info(s\"Changed partition $partition state from ${partitionState(partition)} to $targetState\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI4OTQxOQ==", "bodyText": "Let's keep this trace.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r397289419", "createdAt": "2020-03-24T16:26:57Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/PartitionStateMachine.scala", "diffHunk": "@@ -252,13 +252,13 @@ class ZkPartitionStateMachine(config: KafkaConfig,\n         }\n       case OfflinePartition =>\n         validPartitions.foreach { partition =>\n-          stateChangeLog.trace(s\"Changed partition $partition state from ${partitionState(partition)} to $targetState\")\n+          stateChangeLog.info(s\"Changed partition $partition state from ${partitionState(partition)} to $targetState\")\n           controllerContext.putPartitionState(partition, OfflinePartition)\n         }\n         Map.empty\n       case NonExistentPartition =>\n         validPartitions.foreach { partition =>\n-          stateChangeLog.trace(s\"Changed partition $partition state from ${partitionState(partition)} to $targetState\")\n+          stateChangeLog.info(s\"Changed partition $partition state from ${partitionState(partition)} to $targetState\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5NjUxMg==", "bodyText": "Could we just combine these 2 lines into a single line?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r397296512", "createdAt": "2020-03-24T16:36:18Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,26 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val newStates = updateMetadataRequest.partitionStates.asScala\n+        newStates.foreach { state =>\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n-              s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n             deletedPartitions += tp\n           } else {\n-            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, info)\n-            stateChangeLogger.trace(s\"Cached leader info $info for partition $tp in response to \" +\n-              s\"UpdateMetadata request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, state)\n           }\n         }\n-        metadataSnapshot = MetadataSnapshot(partitionStates, controllerId, aliveBrokers, aliveNodes)\n+        val cachedPartitionsCount = newStates.size - deletedPartitions.size\n+        stateChangeLogger.info(s\"Deleted ${deletedPartitions.size} partitions from metadata cache in response to UpdateMetadata \" +\n+          s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+        stateChangeLogger.info(s\"Cached leader info for $cachedPartitionsCount partitions in response to UpdateMetadata \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzMwNDc4OQ==", "bodyText": "Didn't realize that we have to construct a new stateChangeLog object. So, the existing approach of constructing it once and pass it along seems better.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r397304789", "createdAt": "2020-03-24T16:47:05Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -572,9 +576,8 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n \n   def sendRequestsToBrokers(controllerEpoch: Int): Unit = {\n     try {\n-      val stateChangeLog = stateChangeLogger.withControllerEpoch(controllerEpoch)\n-      sendLeaderAndIsrRequest(controllerEpoch, stateChangeLog)\n-      sendUpdateMetadataRequests(controllerEpoch, stateChangeLog)\n+      sendLeaderAndIsrRequest(controllerEpoch)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzMwNzQ4NA==", "bodyText": "Could we add an info level logging with the become-leader/become-follower counts for each broker?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r397307484", "createdAt": "2020-03-24T16:50:32Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -447,14 +448,13 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n \n     leaderAndIsrRequestMap.filterKeys(controllerContext.liveOrShuttingDownBrokerIds.contains).foreach {\n       case (broker, leaderAndIsrPartitionStates) =>\n-        if (stateChangeLog.isTraceEnabled) {\n+        if (stateChangeLog.isTraceEnabled)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzMwODQ5OA==", "bodyText": "Since this just has the count, we can make this info level.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r397308498", "createdAt": "2020-03-24T16:51:52Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -472,11 +472,11 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n     leaderAndIsrRequestMap.clear()\n   }\n \n-  private def sendUpdateMetadataRequests(controllerEpoch: Int, stateChangeLog: StateChangeLogger): Unit = {\n-    updateMetadataRequestPartitionInfoMap.foreach { case (tp, partitionState) =>\n-      stateChangeLog.trace(s\"Sending UpdateMetadata request $partitionState to brokers $updateMetadataRequestBrokerSet \" +\n-        s\"for partition $tp\")\n-    }\n+  private def sendUpdateMetadataRequests(controllerEpoch: Int): Unit = {\n+    val stateChangeLog = stateChangeLogger.withControllerEpoch(controllerEpoch)\n+    if (stateChangeLog.isTraceEnabled)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzMxMTA2OA==", "bodyText": "To be consistent with the above changes, let's add an info level logging per broker with just the partition count.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r397311068", "createdAt": "2020-03-24T16:55:15Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -550,19 +551,22 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n         brokerEpoch, deletePartitions, partitions)\n     }\n \n+    val traceEnabled = stateChangeLog.isTraceEnabled\n     stopReplicaRequestMap.filterKeys(controllerContext.liveOrShuttingDownBrokerIds.contains).foreach { case (brokerId, replicaInfoList) =>\n       val (stopReplicaWithDelete, stopReplicaWithoutDelete) = replicaInfoList.partition(r => r.deletePartition)\n       val brokerEpoch = controllerContext.liveBrokerIdAndEpochs(brokerId)\n \n       if (stopReplicaWithDelete.nonEmpty) {\n-        debug(s\"The stop replica request (delete = true) sent to broker $brokerId is ${stopReplicaWithDelete.mkString(\",\")}\")\n+        if (traceEnabled)\n+          stateChangeLog.trace(s\"The stop replica request (delete = true) sent to broker $brokerId contains ${stopReplicaWithDelete.map(_.replica).mkString(\",\")}\")\n         val stopReplicaRequest = createStopReplicaRequest(brokerEpoch, stopReplicaWithDelete, deletePartitions = true)\n         val callback = stopReplicaPartitionDeleteResponseCallback(brokerId) _\n         sendRequest(brokerId, stopReplicaRequest, callback)\n       }\n \n       if (stopReplicaWithoutDelete.nonEmpty) {\n-        debug(s\"The stop replica request (delete = false) sent to broker $brokerId is ${stopReplicaWithoutDelete.mkString(\",\")}\")\n+        if (traceEnabled)\n+          stateChangeLog.trace(s\"The stop replica request (delete = false) sent to broker $brokerId contains ${stopReplicaWithoutDelete.map(_.replica).mkString(\",\")}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxNTUwMTkx", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-381550191", "createdAt": "2020-03-25T21:28:29Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQyMToyODoyOVrOF7vDGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwMjowNjo0MlrOF702fA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE4MTE0Ng==", "bodyText": "To make it clearer, \"Partition xxx state changed to $leaderIsrAndControllerEpoch after removing replica ...\".", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398181146", "createdAt": "2020-03-25T21:28:29Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/ReplicaStateMachine.scala", "diffHunk": "@@ -220,6 +225,7 @@ class ZkReplicaStateMachine(config: KafkaConfig,\n         }\n         val updatedLeaderIsrAndControllerEpochs = removeReplicasFromIsr(replicaId, replicasWithLeadershipInfo.map(_.topicPartition))\n         updatedLeaderIsrAndControllerEpochs.foreach { case (partition, leaderIsrAndControllerEpoch) =>\n+          stateLogger.info(s\"Removed replica $replicaId from the ISR of partition $partition $leaderIsrAndControllerEpoch as part of transition to $OfflineReplica\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE4NTY3NA==", "bodyText": "Yes, this is called on broker offline. But it only sets the in-memory state. The real work is done when changing ReplicaState to OfflineReplica case, which we have info level logging.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398185674", "createdAt": "2020-03-25T21:37:30Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/controller/PartitionStateMachine.scala", "diffHunk": "@@ -252,13 +252,13 @@ class ZkPartitionStateMachine(config: KafkaConfig,\n         }\n       case OfflinePartition =>\n         validPartitions.foreach { partition =>\n-          stateChangeLog.trace(s\"Changed partition $partition state from ${partitionState(partition)} to $targetState\")\n+          stateChangeLog.info(s\"Changed partition $partition state from ${partitionState(partition)} to $targetState\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI4OTM0Nw=="}, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODI2NjkyMw==", "bodyText": "It's probably useful to leave the per partition logging in trace, under the if (isTraceEnabled) flag.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398266923", "createdAt": "2020-03-26T01:31:02Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,25 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val newStates = updateMetadataRequest.partitionStates.asScala\n+        newStates.foreach { state =>\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODI2Njk4NA==", "bodyText": "It's probably useful to leave the per partition logging in trace.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398266984", "createdAt": "2020-03-26T01:31:20Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,25 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val newStates = updateMetadataRequest.partitionStates.asScala\n+        newStates.foreach { state =>\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n-              s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n             deletedPartitions += tp\n           } else {\n-            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, info)\n-            stateChangeLogger.trace(s\"Cached leader info $info for partition $tp in response to \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODI3MjkxNQ==", "bodyText": "Could we change the following logging in line 1245 to info?\n              stateChangeLogger.debug(s\"Ignoring LeaderAndIsr request from \"", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398272915", "createdAt": "2020-03-26T01:54:11Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1334,29 +1336,31 @@ class ReplicaManager(val config: KafkaConfig,\n                           correlationId: Int,\n                           responseMap: mutable.Map[TopicPartition, Errors],\n                           highWatermarkCheckpoints: OffsetCheckpoints): Set[Partition] = {\n+    val traceEnabled = stateChangeLogger.isTraceEnabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODI3NDY5MA==", "bodyText": "Deleted 0 partitions from metadata cache and cached leader info for 2 partitions in response => Deleted 0 partitions and add 2 partitions in metadata cache in response", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398274690", "createdAt": "2020-03-26T02:00:27Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,25 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val newStates = updateMetadataRequest.partitionStates.asScala\n+        newStates.foreach { state =>\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n-              s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n             deletedPartitions += tp\n           } else {\n-            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, info)\n-            stateChangeLogger.trace(s\"Cached leader info $info for partition $tp in response to \" +\n-              s\"UpdateMetadata request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, state)\n           }\n         }\n-        metadataSnapshot = MetadataSnapshot(partitionStates, controllerId, aliveBrokers, aliveNodes)\n+        val cachedPartitionsCount = newStates.size - deletedPartitions.size\n+        stateChangeLogger.info(s\"Deleted ${deletedPartitions.size} partitions from metadata cache and \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODI3NjIyMA==", "bodyText": "Let's just add an info level logging with partition count in the caller becomeLeaderOrFollower() instead of at the beginning of makeLeader() and makeFollowers(). This is because sometimes we ignore partitions in becomeLeaderOrFollower().", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398276220", "createdAt": "2020-03-26T02:06:42Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1415,14 +1420,16 @@ class ReplicaManager(val config: KafkaConfig,\n                             correlationId: Int,\n                             responseMap: mutable.Map[TopicPartition, Errors],\n                             highWatermarkCheckpoints: OffsetCheckpoints) : Set[Partition] = {\n+    val traceLoggingEnabled = stateChangeLogger.isTraceEnabled\n+    stateChangeLogger.info(s\"Handling LeaderAndIsr request correlationId $correlationId from controller $controllerId \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 100}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxOTkyMDMy", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-381992032", "createdAt": "2020-03-26T13:11:48Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxMzoxMTo0OFrOF8GJCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxMzoxMTo0OFrOF8GJCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU1OTQ5Ng==", "bodyText": "Should we add a comment that these trace logs are expensive?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398559496", "createdAt": "2020-03-26T13:11:48Z", "author": {"login": "stanislavkozlovski"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,32 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val traceEnabled = stateChangeLogger.isTraceEnabled\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val newStates = updateMetadataRequest.partitionStates.asScala\n+        newStates.foreach { state =>\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n-              s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            if (traceEnabled)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 38}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "f3aebc0c26e3ff8c9e31c91bfc1fa22506e4e6fe", "author": {"user": {"login": "stanislavkozlovski", "name": "Stanislav Kozlovski"}}, "url": "https://github.com/apache/kafka/commit/f3aebc0c26e3ff8c9e31c91bfc1fa22506e4e6fe", "committedDate": "2020-03-26T13:19:19Z", "message": "KAFKA-8470-state-change-logger\n\nSelect logs should stay in trace\n\nAddress comments\n\nAdd state change logger to Partition#makeLeader()\nRemove per-partition logging in channelManager#sendUpdateMetadataRequest\nRemove per-partition logging in MetadataCache#updateMetadata\nReduce per-partition logging in ReplicaManager\n\nChange logging in Partition#makeLeader and Partition#makeFollower\n\nControllerChannelManager - Add TRACE logging in sendStopReplicaRequests and change some LAIR sending  logging to TRACE\n\nClear unnecessary logging in ReplicaManager and switch to TRACE\n\nWe reduce the number of for loops in become-leader/become-follower LAIR handling, log in trace (because Partition#makeFollower/makeLeader() already log per partition) and add some introductory single info-level logs\n\nRemove unnecessary log in stopReplicas()\n\nAddress PR comments\n\nAddress PR comments\n\nLog number of become-leader/become-follower partition states\n\nDo not re-instantiate StateChangeLogger when sending lair/updateMetadata/stopReplica requests to brokers\n\nAdd per-broker info logs on stop replica requests\n\nLog in trace for NonExistentPartition state switch\n\nLog OfflineReplica state switch per partition in INFO\n\nLog sendUpdateMetadataRequest in INFO\n\nLog OfflinePartition in TRACE for PartitionStateMachine\n\nReturn per-partition TRACE logging in metadata update\n\nRevise ReplicaManager log statement placement, make LeaderAndIsr ignore log INFO and reword remove replica log"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "f3aebc0c26e3ff8c9e31c91bfc1fa22506e4e6fe", "author": {"user": {"login": "stanislavkozlovski", "name": "Stanislav Kozlovski"}}, "url": "https://github.com/apache/kafka/commit/f3aebc0c26e3ff8c9e31c91bfc1fa22506e4e6fe", "committedDate": "2020-03-26T13:19:19Z", "message": "KAFKA-8470-state-change-logger\n\nSelect logs should stay in trace\n\nAddress comments\n\nAdd state change logger to Partition#makeLeader()\nRemove per-partition logging in channelManager#sendUpdateMetadataRequest\nRemove per-partition logging in MetadataCache#updateMetadata\nReduce per-partition logging in ReplicaManager\n\nChange logging in Partition#makeLeader and Partition#makeFollower\n\nControllerChannelManager - Add TRACE logging in sendStopReplicaRequests and change some LAIR sending  logging to TRACE\n\nClear unnecessary logging in ReplicaManager and switch to TRACE\n\nWe reduce the number of for loops in become-leader/become-follower LAIR handling, log in trace (because Partition#makeFollower/makeLeader() already log per partition) and add some introductory single info-level logs\n\nRemove unnecessary log in stopReplicas()\n\nAddress PR comments\n\nAddress PR comments\n\nLog number of become-leader/become-follower partition states\n\nDo not re-instantiate StateChangeLogger when sending lair/updateMetadata/stopReplica requests to brokers\n\nAdd per-broker info logs on stop replica requests\n\nLog in trace for NonExistentPartition state switch\n\nLog OfflineReplica state switch per partition in INFO\n\nLog sendUpdateMetadataRequest in INFO\n\nLog OfflinePartition in TRACE for PartitionStateMachine\n\nReturn per-partition TRACE logging in metadata update\n\nRevise ReplicaManager log statement placement, make LeaderAndIsr ignore log INFO and reword remove replica log"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyMjEwMzE4", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-382210318", "createdAt": "2020-03-26T16:54:22Z", "commit": {"oid": "f3aebc0c26e3ff8c9e31c91bfc1fa22506e4e6fe"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxNjo1NDoyM1rOF8QrLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxNjo1NzoxNVrOF8QzVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODczMjA3Nw==", "bodyText": "I was thinking of logging the partition count at the beginning of becomeLeaderOrFollower(). Otherwise, it's kind of weird to see the request logging after the logging for \"Ignoring\".", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398732077", "createdAt": "2020-03-26T16:54:23Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1255,15 +1257,19 @@ class ReplicaManager(val config: KafkaConfig,\n         val partitionsToBeFollower = partitionStates -- partitionsTobeLeader.keys\n \n         val highWatermarkCheckpoints = new LazyOffsetCheckpoints(this.highWatermarkCheckpoints)\n-        val partitionsBecomeLeader = if (partitionsTobeLeader.nonEmpty)\n+        val partitionsBecomeLeader = if (partitionsTobeLeader.nonEmpty) {\n+          stateChangeLogger.info(s\"Handling LeaderAndIsr request correlationId $correlationId from controller $controllerId \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3aebc0c26e3ff8c9e31c91bfc1fa22506e4e6fe"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODczMjY1Mg==", "bodyText": "Could we put \"add $cachedPartitionsCount partitions\" before \"Deleted ${deletedPartitions.size} partitions\" ?", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398732652", "createdAt": "2020-03-26T16:55:11Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -321,22 +321,32 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val traceEnabled = stateChangeLogger.isTraceEnabled\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val newStates = updateMetadataRequest.partitionStates.asScala\n+        newStates.foreach { state =>\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n-              s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            if (traceEnabled)\n+              stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n+                s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n             deletedPartitions += tp\n           } else {\n-            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, info)\n-            stateChangeLogger.trace(s\"Cached leader info $info for partition $tp in response to \" +\n-              s\"UpdateMetadata request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            addOrUpdatePartitionInfo(partitionStates, tp.topic, tp.partition, state)\n+            if (traceEnabled)\n+              stateChangeLogger.trace(s\"Cached leader info $state for partition $tp in response to \" +\n+                s\"UpdateMetadata request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n           }\n         }\n-        metadataSnapshot = MetadataSnapshot(partitionStates, controllerId, aliveBrokers, aliveNodes)\n+        val cachedPartitionsCount = newStates.size - deletedPartitions.size\n+        stateChangeLogger.info(s\"Deleted ${deletedPartitions.size} partitions and \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3aebc0c26e3ff8c9e31c91bfc1fa22506e4e6fe"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODczNDE2Ng==", "bodyText": "Yes, we can add a comment.", "url": "https://github.com/apache/kafka/pull/8320#discussion_r398734166", "createdAt": "2020-03-26T16:57:15Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -302,22 +302,32 @@ class MetadataCache(brokerId: Int) extends Logging {\n           copy ++= oldPartitionStates\n           partitionStates += (topic -> copy)\n         }\n-        updateMetadataRequest.partitionStates.asScala.foreach { info =>\n-          val controllerId = updateMetadataRequest.controllerId\n-          val controllerEpoch = updateMetadataRequest.controllerEpoch\n-          val tp = new TopicPartition(info.topicName, info.partitionIndex)\n-          if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n+\n+        val traceEnabled = stateChangeLogger.isTraceEnabled\n+        val controllerId = updateMetadataRequest.controllerId\n+        val controllerEpoch = updateMetadataRequest.controllerEpoch\n+        val newStates = updateMetadataRequest.partitionStates.asScala\n+        newStates.foreach { state =>\n+          val tp = new TopicPartition(state.topicName, state.partitionIndex)\n+          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n             removePartitionInfo(partitionStates, tp.topic, tp.partition)\n-            stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n-              s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")\n+            if (traceEnabled)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU1OTQ5Ng=="}, "originalCommit": null, "originalPosition": 38}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1fc70ecb4e4eac9b68ad9762d55275cd26e5b738", "author": {"user": {"login": "stanislavkozlovski", "name": "Stanislav Kozlovski"}}, "url": "https://github.com/apache/kafka/commit/1fc70ecb4e4eac9b68ad9762d55275cd26e5b738", "committedDate": "2020-03-26T18:04:58Z", "message": "Move logging in becomeLeaderOrFollower"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fc7ca7de7ffd00ed32fcd3ced1cc4774ad503c0", "author": {"user": {"login": "stanislavkozlovski", "name": "Stanislav Kozlovski"}}, "url": "https://github.com/apache/kafka/commit/8fc7ca7de7ffd00ed32fcd3ced1cc4774ad503c0", "committedDate": "2020-03-26T18:05:11Z", "message": "Tweak logging in MetadataCache"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyMzIwNjI1", "url": "https://github.com/apache/kafka/pull/8320#pullrequestreview-382320625", "createdAt": "2020-03-26T18:54:54Z", "commit": {"oid": "8fc7ca7de7ffd00ed32fcd3ced1cc4774ad503c0"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 332, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}