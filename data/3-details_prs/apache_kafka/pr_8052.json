{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyMDU5MTUx", "number": 8052, "title": "MINOR: Improve EOS example exception handling", "bodyText": "The current EOS example is over-complicating the exception handling by mixing non fatal and fatal ones. This cleanup is trying to make the code readability better. Will rebase after #8051 is merged\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-02-06T18:58:12Z", "url": "https://github.com/apache/kafka/pull/8052", "merged": true, "mergeCommit": {"oid": "776565f7a8646c1920dbb303aad7fe3edb08d7ce"}, "closed": true, "closedAt": "2020-02-20T17:59:10Z", "author": {"login": "abbccdda"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcBvjFcAFqTM1NDY5Njg4OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcF_dx5gFqTM2MTUyMzE4NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU0Njk2ODg4", "url": "https://github.com/apache/kafka/pull/8052#pullrequestreview-354696888", "createdAt": "2020-02-06T19:03:52Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOTowMzo1MlrOFmmsAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOTowMzo1MlrOFmmsAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAyNDA2NQ==", "bodyText": "I don't think this is the only case that we can abort a transaction. This only handles offset commit failures, but what about send failures?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r376024065", "createdAt": "2020-02-06T19:03:52Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +139,40 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages(int messageProcessed, ConsumerRecords<Integer, String> records)\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            // Begin a new transaction session.\n+            producer.beginTransaction();\n+            for (ConsumerRecord<Integer, String> record : records) {\n+                // Process the record and send to downstream.\n+                ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                producer.send(customizedRecord);\n+            }\n+            Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+            for (TopicPartition topicPartition : consumer.assignment()) {\n+                positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+            }\n+            // Checkpoint the progress by sending offsets to group coordinator broker.\n+            // Under group mode, we must apply consumer group metadata for proper fencing.\n+            if (this.mode.equals(\"groupMode\")) {\n+                producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+            } else {\n+                producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+            }\n+\n+            // Finish the transaction. All sent records should be visible for consumption now.\n+            producer.commitTransaction();\n+            messageProcessed += records.count();\n+        } catch (CommitFailedException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU4NzM0NzQ3", "url": "https://github.com/apache/kafka/pull/8052#pullrequestreview-358734747", "createdAt": "2020-02-14T06:31:23Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwNjozMToyM1rOFpsv4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwNjo0MjowNVrOFps5XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTA5MA==", "bodyText": "Seems like we don't allow a way to set the instanceId in this example, so does it make sense to include FencedInstanceIdException?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379269090", "createdAt": "2020-02-14T06:31:23Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTIwNw==", "bodyText": "Why is InvalidOffsetException fatal?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379269207", "createdAt": "2020-02-14T06:31:52Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -121,46 +130,15 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         }\n \n         int messageProcessed = 0;\n-        boolean abortPreviousTransaction = false;\n         while (messageRemaining.get() > 0) {\n-            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n-            if (records.count() > 0) {\n-                try {\n-                    // Abort previous transaction if instructed.\n-                    if (abortPreviousTransaction) {\n-                        producer.abortTransaction();\n-                        // The consumer fetch position also needs to be reset.\n-                        resetToLastCommittedPositions(consumer);\n-                        abortPreviousTransaction = false;\n-                    }\n-                    // Begin a new transaction session.\n-                    producer.beginTransaction();\n-                    for (ConsumerRecord<Integer, String> record : records) {\n-                        // Process the record and send to downstream.\n-                        ProducerRecord<Integer, String> customizedRecord = transform(record);\n-                        producer.send(customizedRecord);\n-                    }\n-                    Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n-                    for (TopicPartition topicPartition : consumer.assignment()) {\n-                        positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n-                    }\n-                    // Checkpoint the progress by sending offsets to group coordinator broker.\n-                    // Under group mode, we must apply consumer group metadata for proper fencing.\n-                    if (this.mode.equals(\"groupMode\")) {\n-                        producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n-                    } else {\n-                        producer.sendOffsetsToTransaction(positions, consumerGroupId);\n-                    }\n-\n-                    // Finish the transaction. All sent records should be visible for consumption now.\n-                    producer.commitTransaction();\n-                    messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n-                }\n+            try {\n+                messageProcessed += processMessages();\n+            } catch (ProducerFencedException | FencedInstanceIdException | AuthorizationException |\n+                         AuthenticationException | UnsupportedVersionException |\n+                         UnsupportedForMessageFormatException | InvalidTopicException |\n+                         InvalidOffsetException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDEwMg==", "bodyText": "I think we can leave WakeupException and InterruptException out of this. In both of these cases, we would probably just want the application to close. I think the main thing we want this example to show is the \"normal operating\" exceptions.", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379270102", "createdAt": "2020-02-14T06:35:48Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+                } else {\n+                    producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+                }\n+\n+                // Finish the transaction. All sent records should be visible for consumption now.\n+                producer.commitTransaction();\n+                return records.count();\n+            }\n+        } catch (CommitFailedException | WakeupException | InterruptException | TimeoutException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDI5MA==", "bodyText": "Could we do \"group mode\" only in this example? The example doesn't really extend to multiple instances otherwise.", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379270290", "createdAt": "2020-02-14T06:36:39Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MTUxNg==", "bodyText": "Hmm.. Is it actually safe to abort following a TimeoutException? I think this would cause an illegal state error in the producer. To handle this correctly, the application should retry the commit.", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379271516", "createdAt": "2020-02-14T06:42:05Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+                } else {\n+                    producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+                }\n+\n+                // Finish the transaction. All sent records should be visible for consumption now.\n+                producer.commitTransaction();\n+                return records.count();\n+            }\n+        } catch (CommitFailedException | WakeupException | InterruptException | TimeoutException e) {\n+            // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n+            producer.abortTransaction();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 113}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwNjgwODU1", "url": "https://github.com/apache/kafka/pull/8052#pullrequestreview-360680855", "createdAt": "2020-02-18T21:20:54Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMToyMDo1NVrOFrS1ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMToyMDo1NVrOFrS1ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk0MTcwNg==", "bodyText": "For the purpose of understanding EOS, the main exceptions that are worth calling out are ProducerFencedException and FencedInstanceIdException. I would suggest we write the example like this:\ntry {\n   ...\n   producer.commitTransaction;\n} catch (ProducerFencedException e) {\n  throw KafkaException(\"The transactional.id $transactionalId has been claimed by another process\");\n} catch (FencedInstanceIdException e) {\n  throw KafkaException(\"The group.instance.id $instanceId has been claimed by another process\");\n} catch (KafkaException e) {\n  // If we have not been fenced, try to abort the transaction and continue. This will raise immediately\n  // if the producer has hit a fatal error.\n  producer.abortTransaction();\n}", "url": "https://github.com/apache/kafka/pull/8052#discussion_r380941706", "createdAt": "2020-02-18T21:20:55Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -155,12 +157,19 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n                     // Finish the transaction. All sent records should be visible for consumption now.\n                     producer.commitTransaction();\n                     messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n                 }\n+            } catch (CommitFailedException | InvalidOffsetException e) {\n+                // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n+                // Note that abort transaction call could also throw fatal exceptions such as producer fenced.\n+                producer.abortTransaction();\n+\n+                // The consumer fetch position also needs to be reset.\n+                resetToLastCommittedPositions(consumer);\n+            } catch (ProducerFencedException | FencedInstanceIdException | AuthorizationException |", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 80}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwNzAyNjEx", "url": "https://github.com/apache/kafka/pull/8052#pullrequestreview-360702611", "createdAt": "2020-02-18T21:56:21Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMTo1NjoyMVrOFrT50g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMjowMzoxMFrOFrUGww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1OTE4Ng==", "bodyText": "How about this?\n// The consumer fetch position needs to be restored to the committed offset before the transaction started", "url": "https://github.com/apache/kafka/pull/8052#discussion_r380959186", "createdAt": "2020-02-18T21:56:21Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -155,13 +151,20 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n                     // Finish the transaction. All sent records should be visible for consumption now.\n                     producer.commitTransaction();\n                     messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n                 }\n+            } catch (ProducerFencedException e) {\n+                throw new KafkaException(String.format(\"The transactional.id %s has been claimed by another process\", transactionalId));\n+            } catch (FencedInstanceIdException e) {\n+                throw new KafkaException(String.format(\"The group.instance.id %s has been claimed by another process\", groupInstanceId));\n+            } catch (KafkaException e) {\n+                // If we have not been fenced, try to abort the transaction and continue. This will raise immediately\n+                // if the producer has hit a fatal error.\n+                producer.abortTransaction();\n+\n+                // The consumer fetch position also needs to be reset.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2MjQ5OQ==", "bodyText": "I had a question before about the \"groupMode.\" Do we need to include this in the example? I think it would be fine to let this example use the latest recommended pattern and include a comment about it.\nAlso, could we have a helper for the boilerplate conversion to Map<TopicPartition, OffsetAndMetadata>` since it clutters up the core logic?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r380962499", "createdAt": "2020-02-18T22:03:10Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -155,13 +151,20 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n                     // Finish the transaction. All sent records should be visible for consumption now.\n                     producer.commitTransaction();\n                     messageProcessed += records.count();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2903d337010fcd7e2c717343012f1bbc912c0a4", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/e2903d337010fcd7e2c717343012f1bbc912c0a4", "committedDate": "2020-02-19T07:33:05Z", "message": "make code clean"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3053239c3c0ea377c5eed51b4be273e8fca3d43", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/d3053239c3c0ea377c5eed51b4be273e8fca3d43", "committedDate": "2020-02-19T07:33:05Z", "message": "add more exception types"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c01fbe0211de5a19732d19fc4102162a437b76b", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/1c01fbe0211de5a19732d19fc4102162a437b76b", "committedDate": "2020-02-19T07:33:05Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c1166f7f85393ed8db7732b876e9cea2b02d604", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/5c1166f7f85393ed8db7732b876e9cea2b02d604", "committedDate": "2020-02-19T07:33:05Z", "message": "avoid doing the separate func"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eed195dfeb3a10a04b4d33cb26d1e79cfed8b477", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/eed195dfeb3a10a04b4d33cb26d1e79cfed8b477", "committedDate": "2020-02-19T07:33:05Z", "message": "simply catch"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5b56d6c0d897b076b0cfefb87485ae9e87e42651", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/5b56d6c0d897b076b0cfefb87485ae9e87e42651", "committedDate": "2020-02-19T07:33:05Z", "message": "intellij recommendation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0bb8234164e8c5cc561456fffbf1345a8e7fcb55", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/0bb8234164e8c5cc561456fffbf1345a8e7fcb55", "committedDate": "2020-02-19T07:33:05Z", "message": "remove standalone mode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b1905ec71d61b8134284881f706306d1f14c122b", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/b1905ec71d61b8134284881f706306d1f14c122b", "committedDate": "2020-02-19T17:27:54Z", "message": "fix group mode"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "b1905ec71d61b8134284881f706306d1f14c122b", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/b1905ec71d61b8134284881f706306d1f14c122b", "committedDate": "2020-02-19T17:27:54Z", "message": "fix group mode"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxNTIzMTg0", "url": "https://github.com/apache/kafka/pull/8052#pullrequestreview-361523184", "createdAt": "2020-02-19T23:52:15Z", "commit": {"oid": "b1905ec71d61b8134284881f706306d1f14c122b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1765, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}