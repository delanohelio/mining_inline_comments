{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYzNDAyMjU1", "number": 9129, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNToxMzowN1rOEXQhoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNzozMjo1OFrOFDmP0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODIzNDU2OnYy", "diffSide": "RIGHT", "path": "README.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNToxMzowN1rOG-8oiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNToxMzowN1rOG-8oiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY1ODMxMw==", "bodyText": "Rather than \"in order to verify that they are valid\", how about \"in order to verify that they are measuring what you think they are. For example, if you use mocks they may use reflection that can easily dominate the benchmark's run time.\".", "url": "https://github.com/apache/kafka/pull/9129#discussion_r468658313", "createdAt": "2020-08-11T15:13:07Z", "author": {"login": "lbradstreet"}, "path": "README.md", "diffHunk": "@@ -199,6 +199,27 @@ You can run spotbugs using:\n The spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\n directories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n \n+### JMH microbenchmarks ###\n+We use [JMH](https://openjdk.java.net/projects/code-tools/jmh/) to write microbenchmarks that produce reliable results in the JVM.\n+You can run all the benchmarks using:\n+\n+    ./jmh-benchmarks/jmh.sh\n+    \n+Pass a pattern or name after the command to select the benchmarks, for example:\n+\n+    ./jmh-benchmarks/jmh.sh LRUCacheBenchmark\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "debff2513346486163477008efbf5e895f5d25f8"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODI1NDAzOnYy", "diffSide": "RIGHT", "path": "README.md", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNToxNzoyMFrOG-80oA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNjowNjoxNVrOIC3I0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY2MTQwOA==", "bodyText": "While we're at it we can also mention -prof gc and how you should look for the norm allocation rate (since we care about garbage generated per operation rather than per second).", "url": "https://github.com/apache/kafka/pull/9129#discussion_r468661408", "createdAt": "2020-08-11T15:17:20Z", "author": {"login": "lbradstreet"}, "path": "README.md", "diffHunk": "@@ -199,6 +199,27 @@ You can run spotbugs using:\n The spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\n directories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n \n+### JMH microbenchmarks ###", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "debff2513346486163477008efbf5e895f5d25f8"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY2MTUwOQ==", "bodyText": "I'll provide some text for this soon.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r468661509", "createdAt": "2020-08-11T15:17:29Z", "author": {"login": "lbradstreet"}, "path": "README.md", "diffHunk": "@@ -199,6 +199,27 @@ You can run spotbugs using:\n The spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\n directories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n \n+### JMH microbenchmarks ###", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY2MTQwOA=="}, "originalCommit": {"oid": "debff2513346486163477008efbf5e895f5d25f8"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg5NTIyNw==", "bodyText": "Sure. Do you think I should have only the link to jmh-benchmarks/README.md and have all the information on to use it in that page?", "url": "https://github.com/apache/kafka/pull/9129#discussion_r468895227", "createdAt": "2020-08-11T22:16:14Z", "author": {"login": "ijuma"}, "path": "README.md", "diffHunk": "@@ -199,6 +199,27 @@ You can run spotbugs using:\n The spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\n directories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n \n+### JMH microbenchmarks ###", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY2MTQwOA=="}, "originalCommit": {"oid": "debff2513346486163477008efbf5e895f5d25f8"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTEwNjAwMA==", "bodyText": "Including only the link sounds good.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r475106000", "createdAt": "2020-08-22T16:20:08Z", "author": {"login": "lbradstreet"}, "path": "README.md", "diffHunk": "@@ -199,6 +199,27 @@ You can run spotbugs using:\n The spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\n directories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n \n+### JMH microbenchmarks ###", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY2MTQwOA=="}, "originalCommit": {"oid": "debff2513346486163477008efbf5e895f5d25f8"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNzA5Nw==", "bodyText": "Let's drop this and include that link before merge.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r478637097", "createdAt": "2020-08-27T19:11:03Z", "author": {"login": "lbradstreet"}, "path": "README.md", "diffHunk": "@@ -199,6 +199,27 @@ You can run spotbugs using:\n The spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\n directories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n \n+### JMH microbenchmarks ###", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY2MTQwOA=="}, "originalCommit": {"oid": "debff2513346486163477008efbf5e895f5d25f8"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzOTM3Nw==", "bodyText": "Yeah, I fixed this in my local copy, but I wanted to test it before pushing the changes.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r478639377", "createdAt": "2020-08-27T19:15:18Z", "author": {"login": "ijuma"}, "path": "README.md", "diffHunk": "@@ -199,6 +199,27 @@ You can run spotbugs using:\n The spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\n directories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n \n+### JMH microbenchmarks ###", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY2MTQwOA=="}, "originalCommit": {"oid": "debff2513346486163477008efbf5e895f5d25f8"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTg3MTQ0Mg==", "bodyText": "Updated.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r539871442", "createdAt": "2020-12-10T06:06:15Z", "author": {"login": "ijuma"}, "path": "README.md", "diffHunk": "@@ -199,6 +199,27 @@ You can run spotbugs using:\n The spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\n directories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n \n+### JMH microbenchmarks ###", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY2MTQwOA=="}, "originalCommit": {"oid": "debff2513346486163477008efbf5e895f5d25f8"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjEyOTM4OnYy", "diffSide": "RIGHT", "path": "jmh-benchmarks/README.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTowODozMFrOHIdm-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToxNjoyNlrOHId3bQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNTc3MA==", "bodyText": "Suggested addition:\nUsing JMH GC profiler\nIt's good practice to run your benchmark with -prof gc to measure the allocation rate for your code:\n  ./jmh-benchmarks/jmh.sh -prof gc\n\nOf particular importance is the \"norm\" alloc rates, which measure the allocations per operation rather than allocations per second which can increase when you have made your code faster.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r478635770", "createdAt": "2020-08-27T19:08:30Z", "author": {"login": "lbradstreet"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -34,7 +34,18 @@ the jmh.sh script from the jmh-benchmarks module.\n * By default all JMH output goes to stdout.  To run a benchmark and capture the results in a file:\n `./jmh.sh -f 2 -o benchmarkResults.txt LRUCacheBenchmark`\n NOTE: For now this script needs to be run from the jmh-benchmarks directory.\n+\n+### Using JMH with async-profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.\n+JMH includes [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) integration that makes this easy:\n  \n+    LD_LIBRARY_PATH=/path/to/async-profiler ./jmh-benchmarks/jmh.sh -prof async\n+    \n+A number of arguments can be passed to async-profiler, run the following for a description: \n+\n+    ./jmh-benchmarks/jmh.sh -prof async:help\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad5b568aa3f35804b7191d35f4be3bb778fc8e33"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzOTk4MQ==", "bodyText": "Will add.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r478639981", "createdAt": "2020-08-27T19:16:26Z", "author": {"login": "ijuma"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -34,7 +34,18 @@ the jmh.sh script from the jmh-benchmarks module.\n * By default all JMH output goes to stdout.  To run a benchmark and capture the results in a file:\n `./jmh.sh -f 2 -o benchmarkResults.txt LRUCacheBenchmark`\n NOTE: For now this script needs to be run from the jmh-benchmarks directory.\n+\n+### Using JMH with async-profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.\n+JMH includes [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) integration that makes this easy:\n  \n+    LD_LIBRARY_PATH=/path/to/async-profiler ./jmh-benchmarks/jmh.sh -prof async\n+    \n+A number of arguments can be passed to async-profiler, run the following for a description: \n+\n+    ./jmh-benchmarks/jmh.sh -prof async:help\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNTc3MA=="}, "originalCommit": {"oid": "ad5b568aa3f35804b7191d35f4be3bb778fc8e33"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjEzNTczOnYy", "diffSide": "RIGHT", "path": "jmh-benchmarks/README.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToxMDoxOFrOHIdqrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToxNzoyNVrOHId5hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNjcxOQ==", "bodyText": "We should document this variant instead so linux and mac os users are covered.\n -prof async:libPath=/Users/lucas/Downloads/async-profiler-1.8-macos-x64/build/libasyncProfiler.so", "url": "https://github.com/apache/kafka/pull/9129#discussion_r478636719", "createdAt": "2020-08-27T19:10:18Z", "author": {"login": "lbradstreet"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -34,7 +34,18 @@ the jmh.sh script from the jmh-benchmarks module.\n * By default all JMH output goes to stdout.  To run a benchmark and capture the results in a file:\n `./jmh.sh -f 2 -o benchmarkResults.txt LRUCacheBenchmark`\n NOTE: For now this script needs to be run from the jmh-benchmarks directory.\n+\n+### Using JMH with async-profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.\n+JMH includes [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) integration that makes this easy:\n  \n+    LD_LIBRARY_PATH=/path/to/async-profiler ./jmh-benchmarks/jmh.sh -prof async", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad5b568aa3f35804b7191d35f4be3bb778fc8e33"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MDUxOQ==", "bodyText": "Agreed, I tested this variant on Mac, but not Linux yet. Will do before changing.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r478640519", "createdAt": "2020-08-27T19:17:25Z", "author": {"login": "ijuma"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -34,7 +34,18 @@ the jmh.sh script from the jmh-benchmarks module.\n * By default all JMH output goes to stdout.  To run a benchmark and capture the results in a file:\n `./jmh.sh -f 2 -o benchmarkResults.txt LRUCacheBenchmark`\n NOTE: For now this script needs to be run from the jmh-benchmarks directory.\n+\n+### Using JMH with async-profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.\n+JMH includes [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) integration that makes this easy:\n  \n+    LD_LIBRARY_PATH=/path/to/async-profiler ./jmh-benchmarks/jmh.sh -prof async", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNjcxOQ=="}, "originalCommit": {"oid": "ad5b568aa3f35804b7191d35f4be3bb778fc8e33"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM5MDExOTMyOnYy", "diffSide": "RIGHT", "path": "jmh-benchmarks/README.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNjo0Mjo0NlrOIC481g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNzowNDowNlrOIC6A9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTkwMTE0Mg==", "bodyText": "The file name of async-profiler is libasyncProfiler.so. Should we follow the naming in this example?", "url": "https://github.com/apache/kafka/pull/9129#discussion_r539901142", "createdAt": "2020-12-10T06:42:46Z", "author": {"login": "chia7712"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -1,10 +1,69 @@\n-### JMH-Benchmark module\n+### JMH-Benchmarks module\n \n This module contains benchmarks written using [JMH](https://openjdk.java.net/projects/code-tools/jmh/) from OpenJDK.\n Writing correct micro-benchmarks in Java (or another JVM language) is difficult and there are many non-obvious pitfalls (many\n due to compiler optimizations). JMH is a framework for running and analyzing benchmarks (micro or macro) written in Java (or\n another JVM language).\n \n+### Running benchmarks\n+\n+If you want to set specific JMH flags or only run certain benchmarks, passing arguments via\n+gradle tasks is cumbersome. These are simplified by the provided `jmh.sh` script.\n+\n+The default behavior is to run all benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh\n+    \n+Pass a pattern or name after the command to select the benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh LRUCacheBenchmark\n+\n+Check which benchmarks that match the provided pattern:\n+\n+    ./jmh-benchmarks/jmh.sh -l LRUCacheBenchmark\n+\n+Run a specific test and override the number of forks, iterations and warm-up iteration to `2`:\n+\n+    ./jmh-benchmarks/jmh.sh -f 2 -i 2 -wi 2 LRUCacheBenchmark\n+\n+Run a specific test with async and GC profilers on Linux and flame graph output:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc -prof 'async:libPath=/path/to/async-profiler.so;output=flamegraph' LRUCacheBenchmark\n+\n+The following sections cover async profiler and GC profilers in more detail.\n+\n+### Using JMH with async profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.\n+JMH includes [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) integration that makes this easy:\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:libPath=/path/to/async-profiler.so", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cfd375eb595950c325c0d1f2ae02869ad704760a"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTkxODU4MA==", "bodyText": "Yeah, that makes sense. Will do when I'm near a computer.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r539918580", "createdAt": "2020-12-10T07:04:06Z", "author": {"login": "ijuma"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -1,10 +1,69 @@\n-### JMH-Benchmark module\n+### JMH-Benchmarks module\n \n This module contains benchmarks written using [JMH](https://openjdk.java.net/projects/code-tools/jmh/) from OpenJDK.\n Writing correct micro-benchmarks in Java (or another JVM language) is difficult and there are many non-obvious pitfalls (many\n due to compiler optimizations). JMH is a framework for running and analyzing benchmarks (micro or macro) written in Java (or\n another JVM language).\n \n+### Running benchmarks\n+\n+If you want to set specific JMH flags or only run certain benchmarks, passing arguments via\n+gradle tasks is cumbersome. These are simplified by the provided `jmh.sh` script.\n+\n+The default behavior is to run all benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh\n+    \n+Pass a pattern or name after the command to select the benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh LRUCacheBenchmark\n+\n+Check which benchmarks that match the provided pattern:\n+\n+    ./jmh-benchmarks/jmh.sh -l LRUCacheBenchmark\n+\n+Run a specific test and override the number of forks, iterations and warm-up iteration to `2`:\n+\n+    ./jmh-benchmarks/jmh.sh -f 2 -i 2 -wi 2 LRUCacheBenchmark\n+\n+Run a specific test with async and GC profilers on Linux and flame graph output:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc -prof 'async:libPath=/path/to/async-profiler.so;output=flamegraph' LRUCacheBenchmark\n+\n+The following sections cover async profiler and GC profilers in more detail.\n+\n+### Using JMH with async profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.\n+JMH includes [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) integration that makes this easy:\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:libPath=/path/to/async-profiler.so", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTkwMTE0Mg=="}, "originalCommit": {"oid": "cfd375eb595950c325c0d1f2ae02869ad704760a"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM5MjAwMTMzOnYy", "diffSide": "RIGHT", "path": "gradle/spotbugs-exclude.xml", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxMzo0OToxM1rOIDKHhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxMzo0OToxM1rOIDKHhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDE4MjQwNw==", "bodyText": "jmh now uses jmh_generated instead of generated.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r540182407", "createdAt": "2020-12-10T13:49:13Z", "author": {"login": "ijuma"}, "path": "gradle/spotbugs-exclude.xml", "diffHunk": "@@ -237,19 +237,8 @@ For a detailed description of spotbugs bug categories, see https://spotbugs.read\n     </Match>\n \n     <Match>\n-        <!-- Suppress some minor warnings about machine-generated code for\n-             benchmarking. -->\n-        <Or>\n-            <Package name=\"org.apache.kafka.jmh.cache.generated\"/>\n-            <Package name=\"org.apache.kafka.jmh.common.generated\"/>\n-            <Package name=\"org.apache.kafka.jmh.record.generated\"/>\n-            <Package name=\"org.apache.kafka.jmh.partition.generated\"/>\n-            <Package name=\"org.apache.kafka.jmh.producer.generated\"/>\n-            <Package name=\"org.apache.kafka.jmh.fetchsession.generated\"/>\n-            <Package name=\"org.apache.kafka.jmh.fetcher.generated\"/>\n-            <Package name=\"org.apache.kafka.jmh.server.generated\"/>\n-            <Package name=\"org.apache.kafka.jmh.consumer.generated\"/>\n-        </Or>\n+        <!-- Suppress some minor warnings about machine-generated code for benchmarking. -->\n+        <Package name=\"~org\\.apache\\.kafka\\.jmh\\..*\\.jmh_generated\"/>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e52198d80925a06a9532f4c9d04d781de70c079"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM5MzE1ODc5OnYy", "diffSide": "RIGHT", "path": "jmh-benchmarks/README.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNzozMToxMFrOIDU--Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNzo0NzowNlrOIDVvEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM2MDQ0MQ==", "bodyText": "How about:\n\"It's good practice to check profiler output for microbenchmarks in order to verify that they represent application behavior and measure what you expect to measure. Some example pitfalls include the use of expensive mocks or accidental inclusion of test setup code in the benchmarked code.\"", "url": "https://github.com/apache/kafka/pull/9129#discussion_r540360441", "createdAt": "2020-12-10T17:31:10Z", "author": {"login": "lbradstreet"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -1,10 +1,69 @@\n-### JMH-Benchmark module\n+### JMH-Benchmarks module\n \n This module contains benchmarks written using [JMH](https://openjdk.java.net/projects/code-tools/jmh/) from OpenJDK.\n Writing correct micro-benchmarks in Java (or another JVM language) is difficult and there are many non-obvious pitfalls (many\n due to compiler optimizations). JMH is a framework for running and analyzing benchmarks (micro or macro) written in Java (or\n another JVM language).\n \n+### Running benchmarks\n+\n+If you want to set specific JMH flags or only run certain benchmarks, passing arguments via\n+gradle tasks is cumbersome. These are simplified by the provided `jmh.sh` script.\n+\n+The default behavior is to run all benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh\n+    \n+Pass a pattern or name after the command to select the benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh LRUCacheBenchmark\n+\n+Check which benchmarks that match the provided pattern:\n+\n+    ./jmh-benchmarks/jmh.sh -l LRUCacheBenchmark\n+\n+Run a specific test and override the number of forks, iterations and warm-up iteration to `2`:\n+\n+    ./jmh-benchmarks/jmh.sh -f 2 -i 2 -wi 2 LRUCacheBenchmark\n+\n+Run a specific test with async and GC profilers on Linux and flame graph output:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc -prof async:libPath=/path/to/libasyncProfiler.so\\;output=flamegraph LRUCacheBenchmark\n+\n+The following sections cover async profiler and GC profilers in more detail.\n+\n+### Using JMH with async profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e52198d80925a06a9532f4c9d04d781de70c079"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM3Mjc1Mw==", "bodyText": "Will add.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r540372753", "createdAt": "2020-12-10T17:47:06Z", "author": {"login": "ijuma"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -1,10 +1,69 @@\n-### JMH-Benchmark module\n+### JMH-Benchmarks module\n \n This module contains benchmarks written using [JMH](https://openjdk.java.net/projects/code-tools/jmh/) from OpenJDK.\n Writing correct micro-benchmarks in Java (or another JVM language) is difficult and there are many non-obvious pitfalls (many\n due to compiler optimizations). JMH is a framework for running and analyzing benchmarks (micro or macro) written in Java (or\n another JVM language).\n \n+### Running benchmarks\n+\n+If you want to set specific JMH flags or only run certain benchmarks, passing arguments via\n+gradle tasks is cumbersome. These are simplified by the provided `jmh.sh` script.\n+\n+The default behavior is to run all benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh\n+    \n+Pass a pattern or name after the command to select the benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh LRUCacheBenchmark\n+\n+Check which benchmarks that match the provided pattern:\n+\n+    ./jmh-benchmarks/jmh.sh -l LRUCacheBenchmark\n+\n+Run a specific test and override the number of forks, iterations and warm-up iteration to `2`:\n+\n+    ./jmh-benchmarks/jmh.sh -f 2 -i 2 -wi 2 LRUCacheBenchmark\n+\n+Run a specific test with async and GC profilers on Linux and flame graph output:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc -prof async:libPath=/path/to/libasyncProfiler.so\\;output=flamegraph LRUCacheBenchmark\n+\n+The following sections cover async profiler and GC profilers in more detail.\n+\n+### Using JMH with async profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM2MDQ0MQ=="}, "originalCommit": {"oid": "8e52198d80925a06a9532f4c9d04d781de70c079"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM5MzE2Njg5OnYy", "diffSide": "RIGHT", "path": "jmh-benchmarks/README.md", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNzozMjo1OFrOIDVD0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQwMTo1Mzo1NFrOIDliOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM2MTY4Mw==", "bodyText": "Could we include a short section here about what should be put into a PR that has been benchmarked?\nI'm thinking:\n\nBenchmark comparisons for the code before and after the change.\n-prof gc results.\nAn example async profile from at least one run.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r540361683", "createdAt": "2020-12-10T17:32:58Z", "author": {"login": "lbradstreet"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -1,10 +1,69 @@\n-### JMH-Benchmark module\n+### JMH-Benchmarks module\n \n This module contains benchmarks written using [JMH](https://openjdk.java.net/projects/code-tools/jmh/) from OpenJDK.\n Writing correct micro-benchmarks in Java (or another JVM language) is difficult and there are many non-obvious pitfalls (many\n due to compiler optimizations). JMH is a framework for running and analyzing benchmarks (micro or macro) written in Java (or\n another JVM language).\n \n+### Running benchmarks\n+\n+If you want to set specific JMH flags or only run certain benchmarks, passing arguments via\n+gradle tasks is cumbersome. These are simplified by the provided `jmh.sh` script.\n+\n+The default behavior is to run all benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh\n+    \n+Pass a pattern or name after the command to select the benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh LRUCacheBenchmark\n+\n+Check which benchmarks that match the provided pattern:\n+\n+    ./jmh-benchmarks/jmh.sh -l LRUCacheBenchmark\n+\n+Run a specific test and override the number of forks, iterations and warm-up iteration to `2`:\n+\n+    ./jmh-benchmarks/jmh.sh -f 2 -i 2 -wi 2 LRUCacheBenchmark\n+\n+Run a specific test with async and GC profilers on Linux and flame graph output:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc -prof async:libPath=/path/to/libasyncProfiler.so\\;output=flamegraph LRUCacheBenchmark\n+\n+The following sections cover async profiler and GC profilers in more detail.\n+\n+### Using JMH with async profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.\n+JMH includes [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) integration that makes this easy:\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:libPath=/path/to/libasyncProfiler.so\n+\n+With flame graph output (the semicolon is escaped to ensure it is not treated as a command separator):\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:libPath=/path/to/libasyncProfiler.so\\;output=flamegraph\n+\n+A number of arguments can be passed to configure async profiler, run the following for a description:\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:help\n+\n+### Using JMH GC profiler\n+\n+It's good practice to run your benchmark with `-prof gc` to measure its allocation rate:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc\n+\n+Of particular importance is the `norm` alloc rates, which measure the allocations per operation rather than allocations\n+per second which can increase when you have make your code faster.\n+\n+### Running JMH outside of gradle\n+\n+The JMH benchmarks can be run outside of gradle as you would with any executable jar file:\n+\n+    java -jar <kafka-repo-dir>/jmh-benchmarks/build/libs/kafka-jmh-benchmarks-all.jar -f2 LRUCacheBenchmark\n+\n+### Writing benchmarks", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e52198d80925a06a9532f4c9d04d781de70c079"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM3MzQ0NQ==", "bodyText": "Good idea. We should also link from the contributor docs.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r540373445", "createdAt": "2020-12-10T17:48:09Z", "author": {"login": "ijuma"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -1,10 +1,69 @@\n-### JMH-Benchmark module\n+### JMH-Benchmarks module\n \n This module contains benchmarks written using [JMH](https://openjdk.java.net/projects/code-tools/jmh/) from OpenJDK.\n Writing correct micro-benchmarks in Java (or another JVM language) is difficult and there are many non-obvious pitfalls (many\n due to compiler optimizations). JMH is a framework for running and analyzing benchmarks (micro or macro) written in Java (or\n another JVM language).\n \n+### Running benchmarks\n+\n+If you want to set specific JMH flags or only run certain benchmarks, passing arguments via\n+gradle tasks is cumbersome. These are simplified by the provided `jmh.sh` script.\n+\n+The default behavior is to run all benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh\n+    \n+Pass a pattern or name after the command to select the benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh LRUCacheBenchmark\n+\n+Check which benchmarks that match the provided pattern:\n+\n+    ./jmh-benchmarks/jmh.sh -l LRUCacheBenchmark\n+\n+Run a specific test and override the number of forks, iterations and warm-up iteration to `2`:\n+\n+    ./jmh-benchmarks/jmh.sh -f 2 -i 2 -wi 2 LRUCacheBenchmark\n+\n+Run a specific test with async and GC profilers on Linux and flame graph output:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc -prof async:libPath=/path/to/libasyncProfiler.so\\;output=flamegraph LRUCacheBenchmark\n+\n+The following sections cover async profiler and GC profilers in more detail.\n+\n+### Using JMH with async profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.\n+JMH includes [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) integration that makes this easy:\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:libPath=/path/to/libasyncProfiler.so\n+\n+With flame graph output (the semicolon is escaped to ensure it is not treated as a command separator):\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:libPath=/path/to/libasyncProfiler.so\\;output=flamegraph\n+\n+A number of arguments can be passed to configure async profiler, run the following for a description:\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:help\n+\n+### Using JMH GC profiler\n+\n+It's good practice to run your benchmark with `-prof gc` to measure its allocation rate:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc\n+\n+Of particular importance is the `norm` alloc rates, which measure the allocations per operation rather than allocations\n+per second which can increase when you have make your code faster.\n+\n+### Running JMH outside of gradle\n+\n+The JMH benchmarks can be run outside of gradle as you would with any executable jar file:\n+\n+    java -jar <kafka-repo-dir>/jmh-benchmarks/build/libs/kafka-jmh-benchmarks-all.jar -f2 LRUCacheBenchmark\n+\n+### Writing benchmarks", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM2MTY4Mw=="}, "originalCommit": {"oid": "8e52198d80925a06a9532f4c9d04d781de70c079"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDYzMTYxMA==", "bodyText": "I will do this in a separate PR since it's a bit unrelated to the original goal of this PR and it may take a few iterations to get right.", "url": "https://github.com/apache/kafka/pull/9129#discussion_r540631610", "createdAt": "2020-12-11T01:53:54Z", "author": {"login": "ijuma"}, "path": "jmh-benchmarks/README.md", "diffHunk": "@@ -1,10 +1,69 @@\n-### JMH-Benchmark module\n+### JMH-Benchmarks module\n \n This module contains benchmarks written using [JMH](https://openjdk.java.net/projects/code-tools/jmh/) from OpenJDK.\n Writing correct micro-benchmarks in Java (or another JVM language) is difficult and there are many non-obvious pitfalls (many\n due to compiler optimizations). JMH is a framework for running and analyzing benchmarks (micro or macro) written in Java (or\n another JVM language).\n \n+### Running benchmarks\n+\n+If you want to set specific JMH flags or only run certain benchmarks, passing arguments via\n+gradle tasks is cumbersome. These are simplified by the provided `jmh.sh` script.\n+\n+The default behavior is to run all benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh\n+    \n+Pass a pattern or name after the command to select the benchmarks:\n+\n+    ./jmh-benchmarks/jmh.sh LRUCacheBenchmark\n+\n+Check which benchmarks that match the provided pattern:\n+\n+    ./jmh-benchmarks/jmh.sh -l LRUCacheBenchmark\n+\n+Run a specific test and override the number of forks, iterations and warm-up iteration to `2`:\n+\n+    ./jmh-benchmarks/jmh.sh -f 2 -i 2 -wi 2 LRUCacheBenchmark\n+\n+Run a specific test with async and GC profilers on Linux and flame graph output:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc -prof async:libPath=/path/to/libasyncProfiler.so\\;output=flamegraph LRUCacheBenchmark\n+\n+The following sections cover async profiler and GC profilers in more detail.\n+\n+### Using JMH with async profiler\n+\n+It's good practice to check profiler output for microbenchmarks in order to verify that they are valid.\n+JMH includes [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) integration that makes this easy:\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:libPath=/path/to/libasyncProfiler.so\n+\n+With flame graph output (the semicolon is escaped to ensure it is not treated as a command separator):\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:libPath=/path/to/libasyncProfiler.so\\;output=flamegraph\n+\n+A number of arguments can be passed to configure async profiler, run the following for a description:\n+\n+    ./jmh-benchmarks/jmh.sh -prof async:help\n+\n+### Using JMH GC profiler\n+\n+It's good practice to run your benchmark with `-prof gc` to measure its allocation rate:\n+\n+    ./jmh-benchmarks/jmh.sh -prof gc\n+\n+Of particular importance is the `norm` alloc rates, which measure the allocations per operation rather than allocations\n+per second which can increase when you have make your code faster.\n+\n+### Running JMH outside of gradle\n+\n+The JMH benchmarks can be run outside of gradle as you would with any executable jar file:\n+\n+    java -jar <kafka-repo-dir>/jmh-benchmarks/build/libs/kafka-jmh-benchmarks-all.jar -f2 LRUCacheBenchmark\n+\n+### Writing benchmarks", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM2MTY4Mw=="}, "originalCommit": {"oid": "8e52198d80925a06a9532f4c9d04d781de70c079"}, "originalPosition": 66}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2103, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}