{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI2MzU3NjAy", "number": 8775, "title": "KAFKA-10079: improve thread-level stickiness", "bodyText": "Uses a similar (but slightly different) algorithm as in KAFKA-9987 to produce a maximally sticky -- and perfectly balanced -- assignment of tasks to threads within a single client. This is important for in-memory stores which get wiped out when transferred between threads.\nMust be cherrypicked to 2.6", "createdAt": "2020-06-02T05:23:55Z", "url": "https://github.com/apache/kafka/pull/8775", "merged": true, "mergeCommit": {"oid": "0f68dc7a640b26a8edea154ea4ea2b6d93b5104b"}, "closed": true, "closedAt": "2020-06-10T14:56:07Z", "author": {"login": "ableegoldman"}, "timelineItems": {"totalCount": 28, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcnXhGdAFqTQyMjczOTY1Nw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcp65wCgFqTQyODEzOTg0Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyNzM5NjU3", "url": "https://github.com/apache/kafka/pull/8775#pullrequestreview-422739657", "createdAt": "2020-06-02T14:31:34Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNDozMTozNFrOGd0kMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjozMDozMVrOGd6Gog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzkyMzEyMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * @return true if a followup rebalance will be required due to revoekd tasks\n          \n          \n            \n                 * @return true if a followup rebalance will be required due to revoked tasks", "url": "https://github.com/apache/kafka/pull/8775#discussion_r433923120", "createdAt": "2020-06-02T14:31:34Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -938,57 +930,9 @@ private void populatePartitionsByHostMaps(final Map<HostInfo, Set<TopicPartition\n         return assignment;\n     }\n \n-    /**\n-     * Computes the assignment of tasks to threads within each client and assembles the final assignment to send out,\n-     * in the special case of version probing where some members are on different versions and have sent different\n-     * subscriptions.\n-     *\n-     * @return the final assignment for each StreamThread consumer\n-     */\n-    private Map<String, Assignment> versionProbingAssignment(final Map<UUID, ClientMetadata> clientsMetadata,\n-                                                             final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n-                                                             final Map<HostInfo, Set<TopicPartition>> partitionsByHost,\n-                                                             final Map<HostInfo, Set<TopicPartition>> standbyPartitionsByHost,\n-                                                             final Set<TopicPartition> allOwnedPartitions,\n-                                                             final int minUserMetadataVersion,\n-                                                             final int minSupportedMetadataVersion) {\n-        final Map<String, Assignment> assignment = new HashMap<>();\n-\n-        // Since we know another rebalance will be triggered anyway, just try and generate a balanced assignment\n-        // (without violating cooperative protocol) now so that on the second rebalance we can just give tasks\n-        // back to their previous owners\n-        // within the client, distribute tasks to its owned consumers\n-        for (final ClientMetadata clientMetadata : clientsMetadata.values()) {\n-            final ClientState state = clientMetadata.state;\n-\n-            final Map<String, List<TaskId>> interleavedActive =\n-                interleaveConsumerTasksByGroupId(state.activeTasks(), clientMetadata.consumers);\n-            final Map<String, List<TaskId>> interleavedStandby =\n-                interleaveConsumerTasksByGroupId(state.standbyTasks(), clientMetadata.consumers);\n-\n-            addClientAssignments(\n-                assignment,\n-                clientMetadata,\n-                partitionsForTask,\n-                partitionsByHost,\n-                standbyPartitionsByHost,\n-                allOwnedPartitions,\n-                interleavedActive,\n-                interleavedStandby,\n-                minUserMetadataVersion,\n-                minSupportedMetadataVersion,\n-                true,\n-                false);\n-        }\n-\n-        log.info(\"Finished unstable assignment of tasks, a followup rebalance will be scheduled due to version probing.\");\n-\n-        return assignment;\n-    }\n-\n     /**\n      * Adds the encoded assignment for each StreamThread consumer in the client to the overall assignment map\n-     * @return true if this client has been told to schedule a followup rebalance\n+     * @return true if a followup rebalance will be required due to revoekd tasks", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxMzg1OA==", "bodyText": "We have several new methods, and also this new book-kept collection (consumerToPreviousTaskIds), but no new tests for them in ClientStateTest. Can you add the missing coverage?\nThe new methods are more a matter of principle; I'm really concerned that we should have good coverage on the bookkeeping aspect of consumerToPreviousTaskIds because I fear future regressions when we have to maintain two data structures in a consistent fashion", "url": "https://github.com/apache/kafka/pull/8775#discussion_r434013858", "createdAt": "2020-06-02T16:30:31Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -242,8 +250,9 @@ public void addOwnedPartitions(final Collection<TopicPartition> ownedPartitions,\n         }\n     }\n \n-    public void addPreviousTasksAndOffsetSums(final Map<TaskId, Long> taskOffsetSums) {\n+    public void addPreviousTasksAndOffsetSums(final String consumerId, final Map<TaskId, Long> taskOffsetSums) {\n         this.taskOffsetSums.putAll(taskOffsetSums);\n+        consumerToPreviousTaskIds.put(consumerId, taskOffsetSums.keySet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 84}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91400976890ee84bde9c28cc864a2de98c18a31a", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/91400976890ee84bde9c28cc864a2de98c18a31a", "committedDate": "2020-06-03T19:12:55Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "508388975488180e8240cc9edf2955ca5fbeabc4", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/508388975488180e8240cc9edf2955ca5fbeabc4", "committedDate": "2020-06-03T19:12:55Z", "message": "implemented stickiness"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be118634a1a51f6144adf9dc9055c4626bd7d88b", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/be118634a1a51f6144adf9dc9055c4626bd7d88b", "committedDate": "2020-06-03T19:12:55Z", "message": "compiling tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc296fc0380105691bc768b0f4b128fee987b89a", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/dc296fc0380105691bc768b0f4b128fee987b89a", "committedDate": "2020-06-03T19:12:55Z", "message": "improve stickiness to the max"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b8e96cb899d3b6ee6c91766ae2722e7c30ee5e4", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/4b8e96cb899d3b6ee6c91766ae2722e7c30ee5e4", "committedDate": "2020-06-03T19:12:55Z", "message": "debugging last test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8300d491ae64f4f8ab4fba5b2e9baa1ffadd9a7c", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/8300d491ae64f4f8ab4fba5b2e9baa1ffadd9a7c", "committedDate": "2020-06-03T19:12:55Z", "message": "use sorted set for test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d40dd5ae74c3a0b3fc22b60fd0380c44a44d3f7b", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/d40dd5ae74c3a0b3fc22b60fd0380c44a44d3f7b", "committedDate": "2020-06-03T19:12:55Z", "message": "checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5cb6f40bd138fbfa57ac60fccafeb18a4e12c45e", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/5cb6f40bd138fbfa57ac60fccafeb18a4e12c45e", "committedDate": "2020-06-03T19:12:55Z", "message": "add unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72e64ef6089a6ebd7c197e4a0f383c252c9e09f8", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/72e64ef6089a6ebd7c197e4a0f383c252c9e09f8", "committedDate": "2020-06-03T19:12:55Z", "message": "filter for statefulness in SPA"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "acb7a4c0993b7fd7c455b734aa895583341c965d", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/acb7a4c0993b7fd7c455b734aa895583341c965d", "committedDate": "2020-06-03T19:12:55Z", "message": "fixing up tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f580e63fb889115ef66987656459baefcce3473c", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f580e63fb889115ef66987656459baefcce3473c", "committedDate": "2020-06-03T19:12:55Z", "message": "bump log to INFO"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "f580e63fb889115ef66987656459baefcce3473c", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f580e63fb889115ef66987656459baefcce3473c", "committedDate": "2020-06-03T19:12:55Z", "message": "bump log to INFO"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzOTgxNDg3", "url": "https://github.com/apache/kafka/pull/8775#pullrequestreview-423981487", "createdAt": "2020-06-03T22:29:06Z", "commit": {"oid": "f580e63fb889115ef66987656459baefcce3473c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QyMjoyOTowNlrOGevwOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QyMjoyOTowNlrOGevwOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg5Mjg1Nw==", "bodyText": "I missed the extra sort on my last review. It really seems like too much fanciness for the ClientState to sort the tasks in lag order. Would it be too messy to move the sort aspect out to the balancing code that needs it?", "url": "https://github.com/apache/kafka/pull/8775#discussion_r434892857", "createdAt": "2020-06-03T22:29:06Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/ClientStateTest.java", "diffHunk": "@@ -300,20 +302,71 @@ public void shouldNotHaveUnfulfilledQuotaWhenActiveTaskSizeGreaterEqualThanCapac\n     @Test\n     public void shouldAddTasksWithLatestOffsetToPrevActiveTasks() {\n         final Map<TaskId, Long> taskOffsetSums = Collections.singletonMap(TASK_0_1, Task.LATEST_OFFSET);\n-        client.addPreviousTasksAndOffsetSums(taskOffsetSums);\n+        client.addPreviousTasksAndOffsetSums(\"c1\", taskOffsetSums);\n         client.initializePrevTasks(Collections.emptyMap());\n         assertThat(client.prevActiveTasks(), equalTo(Collections.singleton(TASK_0_1)));\n         assertThat(client.previousAssignedTasks(), equalTo(Collections.singleton(TASK_0_1)));\n         assertTrue(client.prevStandbyTasks().isEmpty());\n     }\n \n+    @Test\n+    public void shouldReturnPreviousStatefulTasksForConsumer() {\n+        client.addPreviousTasksAndOffsetSums(\"c1\", Collections.singletonMap(TASK_0_1, Task.LATEST_OFFSET));\n+        client.addPreviousTasksAndOffsetSums(\"c2\", Collections.singletonMap(TASK_0_2, 0L));\n+        client.addPreviousTasksAndOffsetSums(\"c3\", Collections.emptyMap());\n+\n+        client.initializePrevTasks(Collections.emptyMap());\n+        client.computeTaskLags(\n+            UUID_1,\n+            mkMap(\n+                mkEntry(TASK_0_1, 1_000L),\n+                mkEntry(TASK_0_2, 1_000L)\n+            )\n+        );\n+\n+        assertThat(client.previousTasksForConsumer(\"c1\"), equalTo(mkSortedSet(TASK_0_1)));\n+        assertThat(client.previousTasksForConsumer(\"c2\"), equalTo(mkSortedSet(TASK_0_2)));\n+        assertTrue(client.previousTasksForConsumer(\"c3\").isEmpty());\n+    }\n+\n+    @Test\n+    public void shouldReturnPreviousStatefulTasksForConsumerWhenLagIsNotComputed() {\n+        client.addPreviousTasksAndOffsetSums(\"c1\", Collections.singletonMap(TASK_0_1, 1000L));\n+        client.initializePrevTasks(Collections.emptyMap());\n+\n+        assertThat(client.previousTasksForConsumer(\"c1\"), equalTo(mkSortedSet(TASK_0_1)));\n+    }\n+\n+    @Test\n+    public void shouldReturnPreviousStatefulTasksForConsumerInIncreasingLagOrder() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f580e63fb889115ef66987656459baefcce3473c"}, "originalPosition": 54}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c18e59541ed5a5a482766f7bf30d4ba253ac2f8", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/7c18e59541ed5a5a482766f7bf30d4ba253ac2f8", "committedDate": "2020-06-04T16:54:04Z", "message": "pull sorting into SPA"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96a6c23d23b4c8b4018f4bb1bf044ce924f73f90", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/96a6c23d23b4c8b4018f4bb1bf044ce924f73f90", "committedDate": "2020-06-04T16:54:35Z", "message": "checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0NjgwNDQ1", "url": "https://github.com/apache/kafka/pull/8775#pullrequestreview-424680445", "createdAt": "2020-06-04T17:39:18Z", "commit": {"oid": "96a6c23d23b4c8b4018f4bb1bf044ce924f73f90"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzozOToxOFrOGfQveQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzozOToxOFrOGfQveQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQzMzMzNw==", "bodyText": "Is this the right constant to represent \"we don't know the lag\"? Or did I mistake how this is going to be used?", "url": "https://github.com/apache/kafka/pull/8775#discussion_r435433337", "createdAt": "2020-06-04T17:39:18Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -302,14 +300,19 @@ public void computeTaskLags(final UUID uuid, final Map<TaskId, Long> allTaskEndO\n      * @return end offset sum - offset sum\n      *          Task.LATEST_OFFSET if this was previously an active running task on this client\n      */\n-    long lagFor(final TaskId task) {\n-        final Long totalLag = taskLagTotals.get(task);\n+    public long lagFor(final TaskId task) {\n+        final Long totalLag;\n+        if (taskLagTotals.isEmpty()) {\n+            // If we couldn't compute the task lags due to failure to fetch offsets, just return a flat constant\n+            totalLag = 0L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96a6c23d23b4c8b4018f4bb1bf044ce924f73f90"}, "originalPosition": 26}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d26d46290fdd806ef85abd989507495598b2854e", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/d26d46290fdd806ef85abd989507495598b2854e", "committedDate": "2020-06-04T18:39:38Z", "message": "use UNKNOWN_OFFSET_SUM, always initialize lag"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6df10ca2f7c1447a246a18a4cc6fdd2906af7cf5", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/6df10ca2f7c1447a246a18a4cc6fdd2906af7cf5", "committedDate": "2020-06-04T18:40:40Z", "message": "remove no longer relevant  new test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc98357ad9d2e7ee1e37e2098548c52320a379ad", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/fc98357ad9d2e7ee1e37e2098548c52320a379ad", "committedDate": "2020-06-04T18:46:22Z", "message": "fix/rename counter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5cfd406a33deb19d18f85f76860055d78b38351", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/b5cfd406a33deb19d18f85f76860055d78b38351", "committedDate": "2020-06-04T18:59:58Z", "message": "some cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f83baf95aa467a0b1236e7c10ef0ff9a8fced345", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f83baf95aa467a0b1236e7c10ef0ff9a8fced345", "committedDate": "2020-06-04T19:01:28Z", "message": "fixindentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0c5a1954114381f09fb65caff9b5c9a6c60791c", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f0c5a1954114381f09fb65caff9b5c9a6c60791c", "committedDate": "2020-06-04T20:30:55Z", "message": "simplify"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee384a9a9e5697e479010989a90f76a0140f6d66", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/ee384a9a9e5697e479010989a90f76a0140f6d66", "committedDate": "2020-06-04T21:01:14Z", "message": "fix bug caught in test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "168051c69252a4a5e6e64e5162fa8c4ae59ec3ce", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/168051c69252a4a5e6e64e5162fa8c4ae59ec3ce", "committedDate": "2020-06-08T17:02:18Z", "message": "Adding unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b0f6fbe8ea8fd23bcbecbd6f56036bb1e3fb4b6", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/6b0f6fbe8ea8fd23bcbecbd6f56036bb1e3fb4b6", "committedDate": "2020-06-08T17:07:31Z", "message": "checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e921175af03a61f20c24398540c1bdcf5a94fbb1", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/e921175af03a61f20c24398540c1bdcf5a94fbb1", "committedDate": "2020-06-08T17:29:41Z", "message": "remove unused topic partitions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MTM5ODQ3", "url": "https://github.com/apache/kafka/pull/8775#pullrequestreview-428139847", "createdAt": "2020-06-10T14:54:33Z", "commit": {"oid": "e921175af03a61f20c24398540c1bdcf5a94fbb1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 815, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}