{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDExMTg1MTk1", "number": 8589, "title": "KAFKA-9146: KIP-571 Add option to force delete active members in StreamsResetter", "bodyText": "This PR is mainly to enhance https://issues.apache.org/jira/browse/KAFKA-9146.\n\nKafkaAdminClient#removeMembersFromConsumerGroup now support \"removeAll\" members in a given group\nNew cmdline option: --force for StreamsResetter is introduced, if --force specified when using the StreamsResetter, then all the active static/dynamic members will be removed.\n\nRelated KIP:\nKIP-571: https://cwiki.apache.org/confluence/display/KAFKA/KIP-571%3A+Add+option+to+force+remove+members+in+StreamsResetter\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-04-30T06:38:57Z", "url": "https://github.com/apache/kafka/pull/8589", "merged": true, "mergeCommit": {"oid": "90045f63ea357a0ef3ea11464371e12a942ec5b3"}, "closed": true, "closedAt": "2020-05-28T01:41:01Z", "author": {"login": "feyman2016"}, "timelineItems": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABccnIfaAH2gAyNDExMTg1MTk1OjhmMDBjNmY0NzY1OWVlNGEyZDRiM2Y3Yzk2ZTRiNzdmOTEyNGJiNTg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcldLjogH2gAyNDExMTg1MTk1OjUzMjkzMTViMGZiYTU2OWUwZmZkMWUzYzJkOGNiZWEwMDJhNjg0YmE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "8f00c6f47659ee4a2d4b3f7c96e4b77f9124bb58", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/8f00c6f47659ee4a2d4b3f7c96e4b77f9124bb58", "committedDate": "2020-04-30T06:31:32Z", "message": "Add option to force delete active members in StreamsResetter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "617dcf6574d5bb18299fc5ab8de72cc3245e9a29", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/617dcf6574d5bb18299fc5ab8de72cc3245e9a29", "committedDate": "2020-04-30T07:29:26Z", "message": "merge trunk"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e02c3c61d758c6180c4f9a9708b6c8e27b6a3c55", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/e02c3c61d758c6180c4f9a9708b6c8e27b6a3c55", "committedDate": "2020-04-30T09:01:06Z", "message": "update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed", "committedDate": "2020-05-01T14:18:24Z", "message": "fix checkstyle violation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzNjQ3NjQz", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-403647643", "createdAt": "2020-04-30T15:45:14Z", "commit": {"oid": "e02c3c61d758c6180c4f9a9708b6c8e27b6a3c55"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQxNTo0NToxNFrOGOvSvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQxOToxMjo1MFrOGQ30cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEwODA5NQ==", "bodyText": "could we pass the members into the context?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r418108095", "createdAt": "2020-04-30T15:45:14Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3641,37 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        Call findCoordinatorCall;\n+        if (options.removeAll()) {\n+            List<MemberIdentity> members = getMembersFromGroup(groupId);\n+            findCoordinatorCall = getFindCoordinatorCall(context,\n+                () -> getRemoveMembersFromGroupCall(context, members));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e02c3c61d758c6180c4f9a9708b6c8e27b6a3c55"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDMzOTU5Mw==", "bodyText": "Remove print statements", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420339593", "createdAt": "2020-05-05T19:03:29Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,27 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members = new ArrayList<>();\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            System.out.println(\"Encounter exception when trying to get members from group: \" + groupId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0MDIxMQ==", "bodyText": "Curious why we are still continuing in this case, as the member lookup already fails.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420340211", "createdAt": "2020-05-05T19:04:30Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,27 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members = new ArrayList<>();\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            System.out.println(\"Encounter exception when trying to get members from group: \" + groupId);\n+            ex.printStackTrace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0MTg5NA==", "bodyText": "Could we just make members to be Optional<Set<MemberToRemove>> so that we don't need a separate removeAll parameter?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420341894", "createdAt": "2020-05-05T19:07:17Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -32,12 +32,23 @@\n public class RemoveMembersFromConsumerGroupOptions extends AbstractOptions<RemoveMembersFromConsumerGroupOptions> {\n \n     private Set<MemberToRemove> members;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0NDk0Ng==", "bodyText": "style error here.\nI would recommend doing a self style check like:\n./gradlew checkstyleMain checkstyleTest spotbugsMain spotbugsTest spotbugsScoverage compileTestJava otherwise we still need to fix those failures after we do jenkins build.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420344946", "createdAt": "2020-05-05T19:12:50Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,27 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members = new ArrayList<>();\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            System.out.println(\"Encounter exception when trying to get members from group: \" + groupId);\n+            ex.printStackTrace();\n+        }\n+\n+        List<MemberIdentity> memberToRemove = new ArrayList<>();\n+        for (MemberDescription member: members) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "committedDate": "2020-05-07T03:16:23Z", "message": "fix based on comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEwNjE4NTYy", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-410618562", "createdAt": "2020-05-13T06:23:08Z", "commit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNjoyMzowOFrOGUi_og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxNToyOToxNlrOGU3PZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE5ODA1MA==", "bodyText": "nit: space before :", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424198050", "createdAt": "2020-05-13T06:23:08Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,26 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members;\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            throw new KafkaException(\"Encounter exception when trying to get members from group: \" + groupId, ex);\n+        }\n+\n+        List<MemberIdentity> memberToRemove = new ArrayList<>();\n+        for (final MemberDescription member: members) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMDQ4Mw==", "bodyText": "Yes, I feel this is more consistent for internal calls not to do a second round of interpretation for which members set to use.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424510483", "createdAt": "2020-05-13T15:04:03Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3641,37 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        Call findCoordinatorCall;\n+        if (options.removeAll()) {\n+            List<MemberIdentity> members = getMembersFromGroup(groupId);\n+            findCoordinatorCall = getFindCoordinatorCall(context,\n+                () -> getRemoveMembersFromGroupCall(context, members));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEwODA5NQ=="}, "originalCommit": {"oid": "e02c3c61d758c6180c4f9a9708b6c8e27b6a3c55"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMjk5Mw==", "bodyText": "nit: remove extra line", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424512993", "createdAt": "2020-05-13T15:07:20Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -37,7 +37,16 @@ public RemoveMembersFromConsumerGroupOptions(Collection<MemberToRemove> members)\n         this.members = new HashSet<>(members);\n     }\n \n+    public RemoveMembersFromConsumerGroupOptions() {\n+        this.members = new HashSet<>();\n+    }\n+\n     public Set<MemberToRemove> members() {\n         return members;\n     }\n+\n+    public boolean removeAll() {\n+        return members.isEmpty();\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNjA1OA==", "bodyText": "Should be Collection.emptyList()", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424516058", "createdAt": "2020-05-13T15:11:24Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3640,37 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        Call findCoordinatorCall;\n+        if (options.removeAll()) {\n+            List<MemberIdentity> members = getMembersFromGroup(groupId);\n+            findCoordinatorCall = getFindCoordinatorCall(context,\n+                () -> getRemoveMembersFromGroupCall(context, members));\n+        } else {\n+            findCoordinatorCall = getFindCoordinatorCall(context,\n+                () -> getRemoveMembersFromGroupCall(context, new ArrayList<>()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNzU2NA==", "bodyText": "Why do we blindly put  allMembers? I believe we base on context to interpret, but like discussed earlier, this is easy to make mistake, we should rely on one source for members.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424517564", "createdAt": "2020-05-13T15:13:24Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3647,7 +3679,7 @@ void handleResponse(AbstractResponse abstractResponse) {\n \n                 // If coordinator changed since we fetched it, retry\n                 if (ConsumerGroupOperationContext.hasCoordinatorMoved(response)) {\n-                    Call call = getRemoveMembersFromGroupCall(context);\n+                    Call call = getRemoveMembersFromGroupCall(context, allMembers);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxODU0MA==", "bodyText": "And to be clear, I'm not suggesting we have to put stuff into the context, just always passing in the intended removal list and do not depend on context.removeAll again inside internal function.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424518540", "createdAt": "2020-05-13T15:14:40Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3641,37 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        Call findCoordinatorCall;\n+        if (options.removeAll()) {\n+            List<MemberIdentity> members = getMembersFromGroup(groupId);\n+            findCoordinatorCall = getFindCoordinatorCall(context,\n+                () -> getRemoveMembersFromGroupCall(context, members));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEwODA5NQ=="}, "originalCommit": {"oid": "e02c3c61d758c6180c4f9a9708b6c8e27b6a3c55"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMjA1Ng==", "bodyText": "Not necessary change", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424522056", "createdAt": "2020-05-13T15:19:18Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -41,7 +41,7 @@ import org.apache.kafka.common.requests.{DeleteRecordsRequest, MetadataResponse}\n import org.apache.kafka.common.resource.{PatternType, ResourcePattern, ResourceType}\n import org.apache.kafka.common.utils.{Time, Utils}\n import org.apache.kafka.common.{ConsumerGroupState, ElectionType, TopicPartition, TopicPartitionInfo, TopicPartitionReplica}\n-import org.junit.Assert._\n+import org.junit.Assert.{assertEquals, _}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMjc5Mg==", "bodyText": "nit: space after EMPTY_GROUP_INSTANCE_ID", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424522792", "createdAt": "2020-05-13T15:20:13Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"\n       val fakeGroupId = \"fake_group_id\"\n-      val newConsumerConfig = new Properties(consumerConfig)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n-      newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, testInstanceId)\n-      val consumer = createConsumer(configOverrides = newConsumerConfig)\n-      val latch = new CountDownLatch(1)\n+\n+\n+      def createConsumerByGroupInstanceId(groupInstanceId: String) = {\n+        val newConsumerConfig = new Properties(consumerConfig)\n+        newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n+        newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n+        if (groupInstanceId != EMPTY_GROUP_INSTANCE_ID ) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNDE0Ng==", "bodyText": "Could we specify the return type?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424524146", "createdAt": "2020-05-13T15:22:05Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"\n       val fakeGroupId = \"fake_group_id\"\n-      val newConsumerConfig = new Properties(consumerConfig)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n-      newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, testInstanceId)\n-      val consumer = createConsumer(configOverrides = newConsumerConfig)\n-      val latch = new CountDownLatch(1)\n+\n+\n+      def createConsumerByGroupInstanceId(groupInstanceId: String) = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTE3MQ==", "bodyText": "I don't think we really need this struct, could we just put null in groupInstanceSet?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424525171", "createdAt": "2020-05-13T15:23:22Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTQzNg==", "bodyText": "nit: space", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424525436", "createdAt": "2020-05-13T15:23:44Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"\n       val fakeGroupId = \"fake_group_id\"\n-      val newConsumerConfig = new Properties(consumerConfig)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n-      newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, testInstanceId)\n-      val consumer = createConsumer(configOverrides = newConsumerConfig)\n-      val latch = new CountDownLatch(1)\n+\n+\n+      def createConsumerByGroupInstanceId(groupInstanceId: String) = {\n+        val newConsumerConfig = new Properties(consumerConfig)\n+        newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n+        newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n+        if (groupInstanceId != EMPTY_GROUP_INSTANCE_ID ) {\n+          newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, groupInstanceId)\n+        }\n+        createConsumer(configOverrides = newConsumerConfig)\n+      }\n+\n+      // contains two static members and one dynamic member\n+      val groupInstanceSet = Set(testInstanceId, testInstanceId1, EMPTY_GROUP_INSTANCE_ID)\n+      val consumerSet = groupInstanceSet.map(createConsumerByGroupInstanceId(_))\n+      val topicSet = Set(testTopicName, testTopicName1, testTopicName2)\n+\n+      val latch = new CountDownLatch(consumerSet.size)\n       try {\n-        // Start a consumer in a thread that will subscribe to a new group.\n-        val consumerThread = new Thread {\n-          override def run : Unit = {\n-            consumer.subscribe(Collections.singleton(testTopicName))\n-\n-            try {\n-              while (true) {\n-                consumer.poll(JDuration.ofSeconds(5))\n-                if (!consumer.assignment.isEmpty && latch.getCount > 0L)\n-                  latch.countDown()\n-                consumer.commitSync()\n+        def createConsumerThread[K,V](consumer: KafkaConsumer[K,V], topic: String): Thread = {\n+          new Thread {\n+            override def run : Unit = {\n+              consumer.subscribe(Collections.singleton(topic))\n+              try {\n+                while (true) {\n+                  consumer.poll(JDuration.ofSeconds(5))\n+                  if ( !consumer.assignment.isEmpty && latch.getCount > 0L)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTc5OA==", "bodyText": "Why do we suppress here?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424525798", "createdAt": "2020-05-13T15:24:16Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"\n       val fakeGroupId = \"fake_group_id\"\n-      val newConsumerConfig = new Properties(consumerConfig)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n-      newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, testInstanceId)\n-      val consumer = createConsumer(configOverrides = newConsumerConfig)\n-      val latch = new CountDownLatch(1)\n+\n+\n+      def createConsumerByGroupInstanceId(groupInstanceId: String) = {\n+        val newConsumerConfig = new Properties(consumerConfig)\n+        newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n+        newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n+        if (groupInstanceId != EMPTY_GROUP_INSTANCE_ID ) {\n+          newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, groupInstanceId)\n+        }\n+        createConsumer(configOverrides = newConsumerConfig)\n+      }\n+\n+      // contains two static members and one dynamic member\n+      val groupInstanceSet = Set(testInstanceId, testInstanceId1, EMPTY_GROUP_INSTANCE_ID)\n+      val consumerSet = groupInstanceSet.map(createConsumerByGroupInstanceId(_))\n+      val topicSet = Set(testTopicName, testTopicName1, testTopicName2)\n+\n+      val latch = new CountDownLatch(consumerSet.size)\n       try {\n-        // Start a consumer in a thread that will subscribe to a new group.\n-        val consumerThread = new Thread {\n-          override def run : Unit = {\n-            consumer.subscribe(Collections.singleton(testTopicName))\n-\n-            try {\n-              while (true) {\n-                consumer.poll(JDuration.ofSeconds(5))\n-                if (!consumer.assignment.isEmpty && latch.getCount > 0L)\n-                  latch.countDown()\n-                consumer.commitSync()\n+        def createConsumerThread[K,V](consumer: KafkaConsumer[K,V], topic: String): Thread = {\n+          new Thread {\n+            override def run : Unit = {\n+              consumer.subscribe(Collections.singleton(topic))\n+              try {\n+                while (true) {\n+                  consumer.poll(JDuration.ofSeconds(5))\n+                  if ( !consumer.assignment.isEmpty && latch.getCount > 0L)\n+                    latch.countDown()\n+                  consumer.commitSync()\n+                }\n+              } catch {\n+                case _: InterruptException => // Suppress the output to stderr", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNzAyMQ==", "bodyText": "remained -> remaining", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424527021", "createdAt": "2020-05-13T15:25:51Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1147,6 +1175,16 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n \n           assertEquals(testGroupId, testGroupDescription.groupId)\n           assertFalse(testGroupDescription.isSimpleConsumerGroup)\n+          assertEquals(consumerSet.size -1, testGroupDescription.members().size())\n+\n+          // Delete all active members remained (a static member + a dynamic member)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyOTc2Nw==", "bodyText": "Do we also want to edit the usage info on top to mention the force delete option?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424529767", "createdAt": "2020-05-13T15:29:16Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -236,6 +244,8 @@ private void parseArguments(final String[] args) {\n             .withRequiredArg()\n             .ofType(String.class)\n             .describedAs(\"file name\");\n+        forceOption = optionParser.accepts(\"force\", \"Force remove members when long session time out has been configured, \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 59}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b15dedb31214162bef4dd7a5996ae0b5450d240", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/6b15dedb31214162bef4dd7a5996ae0b5450d240", "committedDate": "2020-05-21T08:03:42Z", "message": "update based on comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "committedDate": "2020-05-21T11:08:11Z", "message": "fix comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2MjczNzQ2", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-416273746", "createdAt": "2020-05-21T15:51:54Z", "commit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "state": "COMMENTED", "comments": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNTo1MTo1NVrOGY4jLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNjozODoxNlrOGY6PNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc0NTUxNw==", "bodyText": "I think we should catch Exception here:\nhttps://stackoverflow.com/questions/2274102/difference-between-using-throwable-and-exception-in-a-try-catch", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428745517", "createdAt": "2020-05-21T15:51:55Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,26 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members;\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc0ODkzOA==", "bodyText": "This indentation is a bit weird, let's just merge L3625-3626", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428748938", "createdAt": "2020-05-21T15:56:31Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,26 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members;\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            throw new KafkaException(\"Encounter exception when trying to get members from group: \" + groupId, ex);\n+        }\n+\n+        List<MemberIdentity> memberToRemove = new ArrayList<>();\n+        for (final MemberDescription member : members) {\n+            if (member.groupInstanceId().isPresent()) {\n+                memberToRemove.add(new MemberIdentity().setGroupInstanceId(member.groupInstanceId().get())\n+                );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MTA0OQ==", "bodyText": "Let's get back the original indentation.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428751049", "createdAt": "2020-05-21T16:00:08Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3640,31 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MjYwMA==", "bodyText": "nit: we could merge L3666-3667", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428752600", "createdAt": "2020-05-21T16:02:44Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3640,31 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n+        List<MemberIdentity> members;\n+        if (options.removeAll()) {\n+            members = getMembersFromGroup(groupId);\n+        } else {\n+            members = options.members().stream().map(\n+                    MemberToRemove::toMemberIdentity).collect(Collectors.toList());\n+        }\n         Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+            () -> getRemoveMembersFromGroupCall(context, members));\n         runnable.call(findCoordinatorCall, startFindCoordinatorMs);\n \n         return new RemoveMembersFromConsumerGroupResult(future, options.members());\n     }\n \n-    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context) {\n+    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>,\n+            RemoveMembersFromConsumerGroupOptions> context, List<MemberIdentity> allMembers) {\n         return new Call(\"leaveGroup\",\n                         context.deadline(),\n                         new ConstantNodeIdProvider(context.node().get().id())) {\n             @Override\n             LeaveGroupRequest.Builder createRequest(int timeoutMs) {\n-                return new LeaveGroupRequest.Builder(context.groupId(),\n-                                                     context.options().members().stream().map(\n-                                                         MemberToRemove::toMemberIdentity).collect(Collectors.toList()));\n+                    return new LeaveGroupRequest.Builder(context.groupId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MzAxMg==", "bodyText": "nit: we could name it members now", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428753012", "createdAt": "2020-05-21T16:03:26Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3640,31 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n+        List<MemberIdentity> members;\n+        if (options.removeAll()) {\n+            members = getMembersFromGroup(groupId);\n+        } else {\n+            members = options.members().stream().map(\n+                    MemberToRemove::toMemberIdentity).collect(Collectors.toList());\n+        }\n         Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+            () -> getRemoveMembersFromGroupCall(context, members));\n         runnable.call(findCoordinatorCall, startFindCoordinatorMs);\n \n         return new RemoveMembersFromConsumerGroupResult(future, options.members());\n     }\n \n-    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context) {\n+    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>,\n+            RemoveMembersFromConsumerGroupOptions> context, List<MemberIdentity> allMembers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1NjczOA==", "bodyText": "I could see this doesn't hold true for a plain static member removal. Let's discuss why skipping the individual member check in RemoveMembersFromConsumerGroupResult makes sense over there.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428756738", "createdAt": "2020-05-21T16:09:52Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3660,7 +3686,7 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     // We set member.id to empty here explicitly, so that the lookup will succeed as user doesn't\n                     // know the exact member.id.\n                     memberErrors.put(new MemberIdentity()\n-                                         .setMemberId(JoinGroupRequest.UNKNOWN_MEMBER_ID)\n+                                         .setMemberId(memberResponse.memberId())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1NzY3Ng==", "bodyText": "Collections.emptySet() makes more sense since it is immutable.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428757676", "createdAt": "2020-05-21T16:11:25Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -37,7 +37,15 @@ public RemoveMembersFromConsumerGroupOptions(Collection<MemberToRemove> members)\n         this.members = new HashSet<>(members);\n     }\n \n+    public RemoveMembersFromConsumerGroupOptions() {\n+        this.members = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1ODY4MQ==", "bodyText": "In removeAll() mode, why could we skip the individual member removal results? I guess although we don't need to verify against the original member list (because they don't exist for removeAll), going throw the sub error list is still valuable to make sure there is no unexpected failure.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428758681", "createdAt": "2020-05-21T16:13:16Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -46,26 +46,42 @@\n      * If not, the first member error shall be returned.\n      */\n     public KafkaFuture<Void> all() {\n-        final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n-        this.future.whenComplete((memberErrors, throwable) -> {\n-            if (throwable != null) {\n-                result.completeExceptionally(throwable);\n-            } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+        if (removeAll()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1ODc5OA==", "bodyText": "Remove print statement.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428758798", "createdAt": "2020-05-21T16:13:27Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -46,26 +46,42 @@\n      * If not, the first member error shall be returned.\n      */\n     public KafkaFuture<Void> all() {\n-        final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n-        this.future.whenComplete((memberErrors, throwable) -> {\n-            if (throwable != null) {\n-                result.completeExceptionally(throwable);\n-            } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+        if (removeAll()) {\n+            final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n+            this.future.whenComplete((memberErrors, throwable) -> {\n+                if (throwable != null) {\n+                    result.completeExceptionally(throwable);\n+                } else {\n+                    System.out.println(\"Remove all active members succeeded, removed \" + memberErrors.size() + \" members: \" + memberErrors.keySet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2MjA0Nw==", "bodyText": "This test looks good, but it seems that we didn't test the case where some members get deleted successfully while some are not?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428762047", "createdAt": "2020-05-21T16:19:03Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -2411,6 +2411,50 @@ public void testRemoveMembersFromGroup() throws Exception {\n             assertNull(noErrorResult.all().get());\n             assertNull(noErrorResult.memberResult(memberOne).get());\n             assertNull(noErrorResult.memberResult(memberTwo).get());\n+\n+            // Return with success for \"removeAll\" scenario", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2Mzc4NA==", "bodyText": "Should we check the member removal result here before proceeding? If that call failed, the whole operation should fail with error message containing the result IMHO.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428763784", "createdAt": "2020-05-21T16:22:10Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -186,9 +190,15 @@ private void validateNoActiveConsumers(final String groupId,\n         final List<MemberDescription> members =\n             new ArrayList<>(describeResult.describedGroups().get(groupId).get().members());\n         if (!members.isEmpty()) {\n-            throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n-                    + \"and has following members: \" + members + \". \"\n-                    + \"Make sure to stop all running application instances before running the reset tool.\");\n+            if (options.has(forceOption)) {\n+                System.out.println(\"Force deleting all active members in the group: \" + groupId);\n+                adminClient.removeMembersFromConsumerGroup(groupId, new RemoveMembersFromConsumerGroupOptions()).all();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2NDk3Nw==", "bodyText": "Fair enough", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428764977", "createdAt": "2020-05-21T16:24:15Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTE3MQ=="}, "originalCommit": {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2Nzc3MQ==", "bodyText": "Does this check duplicate L1103? Also I think it makes sense to check all the members' clientId as they should all equal to testClientId", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428767771", "createdAt": "2020-05-21T16:28:56Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1075,13 +1098,17 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n \n           assertEquals(testGroupId, testGroupDescription.groupId())\n           assertFalse(testGroupDescription.isSimpleConsumerGroup)\n-          assertEquals(1, testGroupDescription.members().size())\n+          assertEquals(groupInstanceSet.size, testGroupDescription.members().size())\n           val member = testGroupDescription.members().iterator().next()\n           assertEquals(testClientId, member.clientId())\n-          val topicPartitions = member.assignment().topicPartitions()\n-          assertEquals(testNumPartitions, topicPartitions.size())\n-          assertEquals(testNumPartitions, topicPartitions.asScala.\n-            count(tp => tp.topic().equals(testTopicName)))\n+          val members = testGroupDescription.members()\n+          assertEquals(testClientId, members.asScala.head.clientId())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2OTI1NQ==", "bodyText": "I prefer testInstanceIdOne = \"test_instance_id_1\" and testInstanceIdTwo = \"test_instance_id_2\"", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428769255", "createdAt": "2020-05-21T16:31:25Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,70 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MDAyOA==", "bodyText": "size - 1", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428770028", "createdAt": "2020-05-21T16:32:48Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1147,6 +1174,16 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n \n           assertEquals(testGroupId, testGroupDescription.groupId)\n           assertFalse(testGroupDescription.isSimpleConsumerGroup)\n+          assertEquals(consumerSet.size -1, testGroupDescription.members().size())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MDE3Ng==", "bodyText": "We could remove this comment for now", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428770176", "createdAt": "2020-05-21T16:33:09Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1138,7 +1165,7 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n           val validMemberFuture = removeMembersResult.memberResult(new MemberToRemove(testInstanceId))\n           assertNull(validMemberFuture.get())\n \n-          // The group should contain no member now.\n+          // The group's active members number should decrease by 1", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MDYwMQ==", "bodyText": "nit: format\nI'm pretty surprised this wasn't caught in my previous template. Let me check how to cover this in style test as well.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428770601", "createdAt": "2020-05-21T16:33:50Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1155,12 +1192,15 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n \n           assertTrue(deleteResult.deletedGroups().containsKey(testGroupId))\n           assertNull(deleteResult.deletedGroups().get(testGroupId).get())\n-        } finally {\n-          consumerThread.interrupt()\n-          consumerThread.join()\n-        }\n       } finally {\n-        Utils.closeQuietly(consumer, \"consumer\")\n+        consumerThreads.foreach {\n+          case consumerThread =>\n+            consumerThread.interrupt()\n+            consumerThread.join()\n+        }\n+      }\n+      }finally {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MTM0Ng==", "bodyText": "What does \"\" +  mean?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428771346", "createdAt": "2020-05-21T16:35:08Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -261,6 +261,43 @@ public void shouldNotAllowToResetWhenIntermediateTopicAbsent() throws Exception\n         Assert.assertEquals(1, exitCode);\n     }\n \n+    public void testResetWhenLongSessionTimeoutConfiguredWithForceOption() throws Exception {\n+        appID = testId + \"-with-force-option\";\n+        streamsConfig.put(StreamsConfig.APPLICATION_ID_CONFIG, appID);\n+        streamsConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + STREAMS_CONSUMER_TIMEOUT * 100);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MjA4OQ==", "bodyText": "nit: parameters are not aligned.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428772089", "createdAt": "2020-05-21T16:36:25Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -507,7 +544,7 @@ private Topology setupTopologyWithoutIntermediateUserTopic() {\n         return builder.build();\n     }\n \n-    private void cleanGlobal(final boolean withIntermediateTopics,\n+    private int tryCleanGlobal(final boolean withIntermediateTopics,\n                              final String resetScenario,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MjkzNg==", "bodyText": "Like said earlier, I think we could just return\nreturn new StreamsResetter().run(parameters, cleanUpConfig) == 0", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428772936", "createdAt": "2020-05-21T16:37:52Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -547,6 +584,13 @@ private void cleanGlobal(final boolean withIntermediateTopics,\n         cleanUpConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + CLEANUP_CONSUMER_TIMEOUT);\n \n         final int exitCode = new StreamsResetter().run(parameters, cleanUpConfig);\n+        return exitCode;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MzE3Mw==", "bodyText": "We could add meta comment for the return value here, and instead of returning an exit code, I feel a boolean is suffice to indicate whether the clean operation was successful or not.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428773173", "createdAt": "2020-05-21T16:38:16Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -507,7 +544,7 @@ private Topology setupTopologyWithoutIntermediateUserTopic() {\n         return builder.build();\n     }\n \n-    private void cleanGlobal(final boolean withIntermediateTopics,\n+    private int tryCleanGlobal(final boolean withIntermediateTopics,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1853cfe65f0a2c638ea179ea445b146b3ecdde16", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/1853cfe65f0a2c638ea179ea445b146b3ecdde16", "committedDate": "2020-05-22T06:41:59Z", "message": "fix more comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d88ad3303f050162b51052804ffa5fc2bf935704", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/d88ad3303f050162b51052804ffa5fc2bf935704", "committedDate": "2020-05-22T08:52:28Z", "message": "enhance exception handling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4764677591858a1a0bf6a70e8597d0a885e3e265", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/4764677591858a1a0bf6a70e8597d0a885e3e265", "committedDate": "2020-05-22T10:54:33Z", "message": "fix test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "committedDate": "2020-05-22T14:19:29Z", "message": "fix format"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2OTUwNTg4", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-416950588", "createdAt": "2020-05-22T14:22:23Z", "commit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNDoyMjoyM1rOGZY9uA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNDoyMjoyM1rOGZY9uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTI3NjYwMA==", "bodyText": "Wrap to let the failed member info available for caller like StreamsResetter. Only capture the first found member error like in the non removeAll scenario.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429276600", "createdAt": "2020-05-22T14:22:23Z", "author": {"login": "feyman2016"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -51,9 +52,21 @@\n             if (throwable != null) {\n                 result.completeExceptionally(throwable);\n             } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+                if (removeAll()) {\n+                    for (Map.Entry<MemberIdentity, Errors> entry: memberErrors.entrySet()) {\n+                        Exception exception = entry.getValue().exception();\n+                        if (exception != null) {\n+                            Throwable ex = new KafkaException(\"Encounter exception when trying to remove: \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MDE5ODU1", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-417019855", "createdAt": "2020-05-22T15:57:04Z", "commit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNTo1NzowNFrOGZcLoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNjoyMDoxMVrOGZctqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyOTMxMw==", "bodyText": "nit: extra semi-colon", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429329313", "createdAt": "2020-05-22T15:57:04Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -37,7 +38,15 @@ public RemoveMembersFromConsumerGroupOptions(Collection<MemberToRemove> members)\n         this.members = new HashSet<>(members);\n     }\n \n+    public RemoveMembersFromConsumerGroupOptions() {\n+        this.members = Collections.emptySet();;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzMzE5OQ==", "bodyText": "Let's put the exception in the cause so that we could verify the cause in KafkaAdminClientTest, as:\nif (exception != null) {\n  result.completeExceptionally(new KafkaException(\n \"Encounter exception when trying to remove: \" + entry.getKey(), exception));\n  return;\n}", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429333199", "createdAt": "2020-05-22T16:11:06Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -51,9 +52,21 @@\n             if (throwable != null) {\n                 result.completeExceptionally(throwable);\n             } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+                if (removeAll()) {\n+                    for (Map.Entry<MemberIdentity, Errors> entry: memberErrors.entrySet()) {\n+                        Exception exception = entry.getValue().exception();\n+                        if (exception != null) {\n+                            Throwable ex = new KafkaException(\"Encounter exception when trying to remove: \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzMzM1NQ==", "bodyText": "nit: we could set \"0\" to JoinGroupRequest.UNKNOWN_MEMBER_ID if we don't want to test it out. Having all members use the same member.id is a bit weird.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429333355", "createdAt": "2020-05-22T16:11:21Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -379,6 +379,22 @@ private static MetadataResponse prepareMetadataResponse(Cluster cluster, Errors\n             MetadataResponse.AUTHORIZED_OPERATIONS_OMITTED);\n     }\n \n+    private static DescribeGroupsResponseData prepareDescribeGroupsResponseData(String groupId, List<String> groupInstances,\n+                                                                                List<TopicPartition> topicPartitions) {\n+        final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n+        byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n+        List<DescribedGroupMember> describedGroupMembers = groupInstances.stream().map(groupInstance -> DescribeGroupsResponse.groupMember(\"0\", groupInstance, \"clientId0\", \"clientHost\", memberAssignmentBytes, null)).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzMzk5OQ==", "bodyText": "nit: space after *. Also I feel we could make the context more concrete by:\nWhen long session timeout has been configured, active members could take longer to get expired on the broker thus blocking the reset job to complete. Use the \\\"--force\\\" option could remove those left-over members immediately. Make sure to stop all stream applications when this option is specified to avoid unexpected disruptions.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429333999", "createdAt": "2020-05-22T16:12:30Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -119,7 +122,9 @@\n             + \"* This tool will not clean up the local state on the stream application instances (the persisted \"\n             + \"stores used to cache aggregation results).\\n\"\n             + \"You need to call KafkaStreams#cleanUp() in your application or manually delete them from the \"\n-            + \"directory specified by \\\"state.dir\\\" configuration (/tmp/kafka-streams/<application.id> by default).\\n\\n\"\n+            + \"directory specified by \\\"state.dir\\\" configuration (/tmp/kafka-streams/<application.id> by default).\\n\"\n+            + \"*Please use the \\\"--force\\\" option to force remove active members in case long session \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzODAyNQ==", "bodyText": "I see, this is indeed weird, please file a JIRA so that we could clean in a follow-up PR if others feel the same way.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429338025", "createdAt": "2020-05-22T16:20:11Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -261,6 +261,43 @@ public void shouldNotAllowToResetWhenIntermediateTopicAbsent() throws Exception\n         Assert.assertEquals(1, exitCode);\n     }\n \n+    public void testResetWhenLongSessionTimeoutConfiguredWithForceOption() throws Exception {\n+        appID = testId + \"-with-force-option\";\n+        streamsConfig.put(StreamsConfig.APPLICATION_ID_CONFIG, appID);\n+        streamsConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + STREAMS_CONSUMER_TIMEOUT * 100);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MTM0Ng=="}, "originalCommit": {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca"}, "originalPosition": 7}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MTIwMTc2", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-417120176", "createdAt": "2020-05-22T18:50:05Z", "commit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxODo1MDowNlrOGZgvZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxODo1MDowNlrOGZgvZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQwNDAwNA==", "bodyText": "This is no longer used.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429404004", "createdAt": "2020-05-22T18:50:06Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -27,10 +27,12 @@\n import org.apache.kafka.clients.admin.DescribeConsumerGroupsOptions;\n import org.apache.kafka.clients.admin.DescribeConsumerGroupsResult;\n import org.apache.kafka.clients.admin.MemberDescription;\n+import org.apache.kafka.clients.admin.RemoveMembersFromConsumerGroupOptions;\n import org.apache.kafka.clients.consumer.Consumer;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.kafka.clients.consumer.KafkaConsumer;\n import org.apache.kafka.clients.consumer.OffsetAndTimestamp;\n+import org.apache.kafka.common.KafkaException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b"}, "originalPosition": 9}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91c81b6e4e2a0001e74c929087550e428b06dfa2", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/91c81b6e4e2a0001e74c929087550e428b06dfa2", "committedDate": "2020-05-23T01:54:57Z", "message": "fix comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MjQxMzIx", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-417241321", "createdAt": "2020-05-23T02:01:24Z", "commit": {"oid": "91c81b6e4e2a0001e74c929087550e428b06dfa2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yM1QwMjowMToyNFrOGZm4FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yM1QwMjowMToyNFrOGZm4FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDUzMg==", "bodyText": "No existing help method to assert the cause of exception throw by all(). Also I think it's more straight forward in this way.", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429504532", "createdAt": "2020-05-23T02:01:24Z", "author": {"login": "feyman2016"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -2411,6 +2429,57 @@ public void testRemoveMembersFromGroup() throws Exception {\n             assertNull(noErrorResult.all().get());\n             assertNull(noErrorResult.memberResult(memberOne).get());\n             assertNull(noErrorResult.memberResult(memberTwo).get());\n+\n+            // Test the \"removeAll\" scenario\n+            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n+            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n+            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n+\n+            final List<TopicPartition> topicPartitions = new ArrayList<>();\n+            topicPartitions.add(0, myTopicPartition0);\n+            topicPartitions.add(1, myTopicPartition1);\n+            topicPartitions.add(2, myTopicPartition2);\n+\n+            // construct the DescribeGroupsResponse\n+            DescribeGroupsResponseData data = prepareDescribeGroupsResponseData(groupId, Arrays.asList(instanceOne, instanceTwo), topicPartitions);\n+\n+            // Return with partial failure for \"removeAll\" scenario\n+            // 1 prepare response for AdminClient.describeConsumerGroups\n+            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n+            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n+\n+            // 2 KafkaAdminClient encounter partial failure when trying to delete all members\n+            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n+            env.kafkaClient().prepareResponse(new LeaveGroupResponse(\n+                    new LeaveGroupResponseData().setErrorCode(Errors.NONE.code()).setMembers(\n+                            Arrays.asList(responseOne, responseTwo))\n+            ));\n+            final RemoveMembersFromConsumerGroupResult partialFailureResults = env.adminClient().removeMembersFromConsumerGroup(\n+                    groupId,\n+                    new RemoveMembersFromConsumerGroupOptions()\n+            );\n+            ExecutionException exception = assertThrows(ExecutionException.class, () -> partialFailureResults.all().get());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91c81b6e4e2a0001e74c929087550e428b06dfa2"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MjUxMzg0", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-417251384", "createdAt": "2020-05-23T05:11:29Z", "commit": {"oid": "91c81b6e4e2a0001e74c929087550e428b06dfa2"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "committedDate": "2020-05-23T05:47:08Z", "message": "fix style violation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3Mjg2Mzcz", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-417286373", "createdAt": "2020-05-23T15:19:17Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODIwMDQy", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418820042", "createdAt": "2020-05-27T02:43:18Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo0MzoxOFrOGa3kkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo0MzoxOFrOGa3kkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyNjY0Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    \"Try set '--force' in the cmdline to force delete active members.\");\n          \n          \n            \n                                    + \" You can use option '--force' to remove active members from the group.\");", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430826643", "createdAt": "2020-05-27T02:43:18Z", "author": {"login": "mjsax"}, "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -186,9 +192,19 @@ private void validateNoActiveConsumers(final String groupId,\n         final List<MemberDescription> members =\n             new ArrayList<>(describeResult.describedGroups().get(groupId).get().members());\n         if (!members.isEmpty()) {\n-            throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n-                    + \"and has following members: \" + members + \". \"\n-                    + \"Make sure to stop all running application instances before running the reset tool.\");\n+            if (options.has(forceOption)) {\n+                System.out.println(\"Force deleting all active members in the group: \" + groupId);\n+                try {\n+                    adminClient.removeMembersFromConsumerGroup(groupId, new RemoveMembersFromConsumerGroupOptions()).all().get();\n+                } catch (Exception e) {\n+                    throw e;\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n+                        + \"and has following members: \" + members + \". \"\n+                        + \"Make sure to stop all running application instances before running the reset tool.\" +\n+                        \"Try set '--force' in the cmdline to force delete active members.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODIwMjA1", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418820205", "createdAt": "2020-05-27T02:43:48Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo0Mzo0OFrOGa3lCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo0Mzo0OFrOGa3lCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyNjc2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    + \"Make sure to stop all running application instances before running the reset tool.\" +\n          \n          \n            \n                                    + \"Make sure to stop all running application instances before running the reset tool.\"", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430826763", "createdAt": "2020-05-27T02:43:48Z", "author": {"login": "mjsax"}, "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -186,9 +192,19 @@ private void validateNoActiveConsumers(final String groupId,\n         final List<MemberDescription> members =\n             new ArrayList<>(describeResult.describedGroups().get(groupId).get().members());\n         if (!members.isEmpty()) {\n-            throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n-                    + \"and has following members: \" + members + \". \"\n-                    + \"Make sure to stop all running application instances before running the reset tool.\");\n+            if (options.has(forceOption)) {\n+                System.out.println(\"Force deleting all active members in the group: \" + groupId);\n+                try {\n+                    adminClient.removeMembersFromConsumerGroup(groupId, new RemoveMembersFromConsumerGroupOptions()).all().get();\n+                } catch (Exception e) {\n+                    throw e;\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n+                        + \"and has following members: \" + members + \". \"\n+                        + \"Make sure to stop all running application instances before running the reset tool.\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 66}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODIwNTc1", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418820575", "createdAt": "2020-05-27T02:45:05Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo0NTowNVrOGa3mOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo0NTowNVrOGa3mOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyNzA2NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    forceOption = optionParser.accepts(\"force\", \"Force remove members when long session time out has been configured, \" +\n          \n          \n            \n                    forceOption = optionParser.accepts(\"force\", \"Force the removal of members of the consumer group (intended to remove stopped members if a long session timeout was used). \" +", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430827065", "createdAt": "2020-05-27T02:45:05Z", "author": {"login": "mjsax"}, "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -236,6 +252,8 @@ private void parseArguments(final String[] args) {\n             .withRequiredArg()\n             .ofType(String.class)\n             .describedAs(\"file name\");\n+        forceOption = optionParser.accepts(\"force\", \"Force remove members when long session time out has been configured, \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 76}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODIwNzAx", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418820701", "createdAt": "2020-05-27T02:45:32Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo0NTozMlrOGa3mnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo0NTozMlrOGa3mnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyNzE2NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"please make sure to shut down all stream applications when this option is specified to avoid unexpected rebalances.\");\n          \n          \n            \n                            \"Make sure to shut down all stream applications when this option is specified to avoid unexpected rebalances.\");", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430827165", "createdAt": "2020-05-27T02:45:32Z", "author": {"login": "mjsax"}, "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -236,6 +252,8 @@ private void parseArguments(final String[] args) {\n             .withRequiredArg()\n             .ofType(String.class)\n             .describedAs(\"file name\");\n+        forceOption = optionParser.accepts(\"force\", \"Force remove members when long session time out has been configured, \" +\n+                \"please make sure to shut down all stream applications when this option is specified to avoid unexpected rebalances.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODIyNTAy", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418822502", "createdAt": "2020-05-27T02:51:45Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo1MTo0NlrOGa3sdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo1MTo0NlrOGa3sdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyODY2Mg==", "bodyText": "Why do we need this part? Seems sufficient to end the test here?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430828662", "createdAt": "2020-05-27T02:51:46Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -261,6 +261,42 @@ public void shouldNotAllowToResetWhenIntermediateTopicAbsent() throws Exception\n         Assert.assertEquals(1, exitCode);\n     }\n \n+    public void testResetWhenLongSessionTimeoutConfiguredWithForceOption() throws Exception {\n+        appID = testId + \"-with-force-option\";\n+        streamsConfig.put(StreamsConfig.APPLICATION_ID_CONFIG, appID);\n+        streamsConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + STREAMS_CONSUMER_TIMEOUT * 100);\n+\n+        // Run\n+        streams = new KafkaStreams(setupTopologyWithoutIntermediateUserTopic(), streamsConfig);\n+        streams.start();\n+        final List<KeyValue<Long, Long>> result = IntegrationTestUtils.waitUntilMinKeyValueRecordsReceived(resultConsumerConfig, OUTPUT_TOPIC, 10);\n+\n+        streams.close();\n+\n+        // RESET\n+        streams = new KafkaStreams(setupTopologyWithoutIntermediateUserTopic(), streamsConfig);\n+        streams.cleanUp();\n+\n+        // Reset would fail since long session timeout has been configured\n+        final boolean cleanResult = tryCleanGlobal(false, null, null);\n+        Assert.assertEquals(false, cleanResult);\n+\n+        // Reset will success with --force, it will force delete active members on broker side\n+        cleanGlobal(false, \"--force\", null);\n+\n+        waitForEmptyConsumerGroup(adminClient, appID, TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT);\n+\n+        assertInternalTopicsGotDeleted(null);\n+\n+        // RE-RUN", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 31}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODIyODIz", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418822823", "createdAt": "2020-05-27T02:52:49Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo1Mjo0OVrOGa3thQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjo1Mjo0OVrOGa3thQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyODkzMw==", "bodyText": "With cleanGlobal and --force the consumer group could be empty when cleanGlobal returns, right? Hence, we should do this assertion without timeout or retries?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430828933", "createdAt": "2020-05-27T02:52:49Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -261,6 +261,42 @@ public void shouldNotAllowToResetWhenIntermediateTopicAbsent() throws Exception\n         Assert.assertEquals(1, exitCode);\n     }\n \n+    public void testResetWhenLongSessionTimeoutConfiguredWithForceOption() throws Exception {\n+        appID = testId + \"-with-force-option\";\n+        streamsConfig.put(StreamsConfig.APPLICATION_ID_CONFIG, appID);\n+        streamsConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + STREAMS_CONSUMER_TIMEOUT * 100);\n+\n+        // Run\n+        streams = new KafkaStreams(setupTopologyWithoutIntermediateUserTopic(), streamsConfig);\n+        streams.start();\n+        final List<KeyValue<Long, Long>> result = IntegrationTestUtils.waitUntilMinKeyValueRecordsReceived(resultConsumerConfig, OUTPUT_TOPIC, 10);\n+\n+        streams.close();\n+\n+        // RESET\n+        streams = new KafkaStreams(setupTopologyWithoutIntermediateUserTopic(), streamsConfig);\n+        streams.cleanUp();\n+\n+        // Reset would fail since long session timeout has been configured\n+        final boolean cleanResult = tryCleanGlobal(false, null, null);\n+        Assert.assertEquals(false, cleanResult);\n+\n+        // Reset will success with --force, it will force delete active members on broker side\n+        cleanGlobal(false, \"--force\", null);\n+\n+        waitForEmptyConsumerGroup(adminClient, appID, TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODI1MDcw", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418825070", "createdAt": "2020-05-27T03:00:33Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzowMDozM1rOGa30-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzowMDozM1rOGa30-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMDg0MA==", "bodyText": "If option.members() is empty, it implies that we do a removeAll() -- hence, should we pass in members into the RemoveMembersFromConsumerGroupResult instead of options.members() ?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430830840", "createdAt": "2020-05-27T03:00:33Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3623,22 +3641,26 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n             new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        List<MemberIdentity> members;\n+        if (options.removeAll()) {\n+            members = getMembersFromGroup(groupId);\n+        } else {\n+            members = options.members().stream().map(MemberToRemove::toMemberIdentity).collect(Collectors.toList());\n+        }\n+        Call findCoordinatorCall = getFindCoordinatorCall(context, () -> getRemoveMembersFromGroupCall(context, members));\n         runnable.call(findCoordinatorCall, startFindCoordinatorMs);\n \n         return new RemoveMembersFromConsumerGroupResult(future, options.members());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODI1Mjk2", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418825296", "createdAt": "2020-05-27T03:01:24Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzowMToyNFrOGa31uQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzowMToyNFrOGa31uQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMTAzMw==", "bodyText": "nit: fix formatting:\nprivate Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context,\n                                           List<MemberIdentity> members) {", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430831033", "createdAt": "2020-05-27T03:01:24Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3623,22 +3641,26 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n             new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        List<MemberIdentity> members;\n+        if (options.removeAll()) {\n+            members = getMembersFromGroup(groupId);\n+        } else {\n+            members = options.members().stream().map(MemberToRemove::toMemberIdentity).collect(Collectors.toList());\n+        }\n+        Call findCoordinatorCall = getFindCoordinatorCall(context, () -> getRemoveMembersFromGroupCall(context, members));\n         runnable.call(findCoordinatorCall, startFindCoordinatorMs);\n \n         return new RemoveMembersFromConsumerGroupResult(future, options.members());\n     }\n \n-    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context) {\n+    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>,\n+            RemoveMembersFromConsumerGroupOptions> context, List<MemberIdentity> members) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODI2OTQy", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418826942", "createdAt": "2020-05-27T03:07:09Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzowNzowOVrOGa37Jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzowNzowOVrOGa37Jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMjQyMw==", "bodyText": "As we have different semantics for an empty collection (it was \"remove nothing\" originally, and we change it to \"remove all\"), I am wondering if we should do a check if members is empty or not and throw an exception if empty? Or at least log a WARNING that empty implies \"remove all\" now?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430832423", "createdAt": "2020-05-27T03:07:09Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -37,7 +38,15 @@ public RemoveMembersFromConsumerGroupOptions(Collection<MemberToRemove> members)\n         this.members = new HashSet<>(members);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODI4NDAw", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418828400", "createdAt": "2020-05-27T03:12:09Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzoxMjowOVrOGa3_cA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzoxMjowOVrOGa3_cA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzUyMA==", "bodyText": "Not sure why the removeAll() case needs to be handled differently? Can you elaborate?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430833520", "createdAt": "2020-05-27T03:12:09Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -51,9 +52,21 @@\n             if (throwable != null) {\n                 result.completeExceptionally(throwable);\n             } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+                if (removeAll()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODI4ODY3", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418828867", "createdAt": "2020-05-27T03:13:55Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzoxMzo1NVrOGa4BCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzoxMzo1NVrOGa4BCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzkyOA==", "bodyText": "Why that? I understand that we expect that users don't know the memberId if the so a \"remove all\"; however, I don't see why we need to disallow this call? Can you elaborate?", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430833928", "createdAt": "2020-05-27T03:13:55Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -66,6 +79,9 @@\n      * Returns the selected member future.\n      */\n     public KafkaFuture<Void> memberResult(MemberToRemove member) {\n+        if (removeAll()) {\n+            throw new IllegalArgumentException(\"The method: memberResult is not applicable in 'removeAll' mode\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODI5MjEx", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418829211", "createdAt": "2020-05-27T03:15:16Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzoxNToxNlrOGa4CGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzoxNToxNlrOGa4CGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzNDIwMw==", "bodyText": "Nit: formatting\nprivate static DescribeGroupsResponseData prepareDescribeGroupsResponseData(String groupId,\n                                                                            List<String> groupInstances,\n                                                                            List<TopicPartition> topicPartitions) {", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430834203", "createdAt": "2020-05-27T03:15:16Z", "author": {"login": "mjsax"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -379,6 +380,22 @@ private static MetadataResponse prepareMetadataResponse(Cluster cluster, Errors\n             MetadataResponse.AUTHORIZED_OPERATIONS_OMITTED);\n     }\n \n+    private static DescribeGroupsResponseData prepareDescribeGroupsResponseData(String groupId, List<String> groupInstances,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODMwODk0", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418830894", "createdAt": "2020-05-27T03:21:35Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzoyMTozNlrOGa4HyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzoyMTozNlrOGa4HyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzNTY1Ng==", "bodyText": "nit: formatting: move new NewTopic(...) to next line", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430835656", "createdAt": "2020-05-27T03:21:36Z", "author": {"login": "mjsax"}, "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,70 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODMyMTIz", "url": "https://github.com/apache/kafka/pull/8589#pullrequestreview-418832123", "createdAt": "2020-05-27T03:25:58Z", "commit": {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6dedd1cea6f5a16f5713ff8811bf52768f96529d", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/6dedd1cea6f5a16f5713ff8811bf52768f96529d", "committedDate": "2020-05-27T07:26:33Z", "message": "Update core/src/main/scala/kafka/tools/StreamsResetter.java\n\nCo-authored-by: Matthias J. Sax <mjsax@apache.org>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f015c228354519937681c262fb10415aee1101ce", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/f015c228354519937681c262fb10415aee1101ce", "committedDate": "2020-05-27T07:27:44Z", "message": "Update core/src/main/scala/kafka/tools/StreamsResetter.java\n\nCo-authored-by: Matthias J. Sax <mjsax@apache.org>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f92a3f686c37c36bd5958b60e12c12aacf3ad7a8", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/f92a3f686c37c36bd5958b60e12c12aacf3ad7a8", "committedDate": "2020-05-27T07:28:22Z", "message": "Update core/src/main/scala/kafka/tools/StreamsResetter.java\n\nCo-authored-by: Matthias J. Sax <mjsax@apache.org>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87346c04fe275b2e539eb64ef1fc4eb4d95a663e", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/87346c04fe275b2e539eb64ef1fc4eb4d95a663e", "committedDate": "2020-05-27T07:28:37Z", "message": "Update core/src/main/scala/kafka/tools/StreamsResetter.java\n\nCo-authored-by: Matthias J. Sax <mjsax@apache.org>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "174ba7edc3b5cfdcdea585a7d12480c27eb562bb", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/174ba7edc3b5cfdcdea585a7d12480c27eb562bb", "committedDate": "2020-05-27T17:18:12Z", "message": "fix comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5329315b0fba569e0ffd1e3c2d8cbea002a684ba", "author": {"user": {"login": "feyman2016", "name": null}}, "url": "https://github.com/apache/kafka/commit/5329315b0fba569e0ffd1e3c2d8cbea002a684ba", "committedDate": "2020-05-27T18:01:09Z", "message": "refactor IntegrationTestUtils"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1296, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}