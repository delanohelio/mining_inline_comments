{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIyODE0OTg5", "number": 9608, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMjowMjo0NFrOE6T9Og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMjowMjo0NFrOE6T9Og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTc5ODM0OnYy", "diffSide": "RIGHT", "path": "core/src/test/scala/unit/kafka/log/LogCleanerTest.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMjowMjo0NFrOH1S6FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQyMDo1MTozOVrOH2BqAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NjM1Ng==", "bodyText": "Sorry, but we have several identical comments in other test cases. Are those comments also wrong?", "url": "https://github.com/apache/kafka/pull/9608#discussion_r525646356", "createdAt": "2020-11-18T02:02:44Z", "author": {"login": "hachikuji"}, "path": "core/src/test/scala/unit/kafka/log/LogCleanerTest.scala", "diffHunk": "@@ -815,9 +815,10 @@ class LogCleanerTest {\n                (0 until leo.toInt by 2).forall(!keys.contains(_)))\n   }\n \n+  @Test\n   def testLogCleanerStats(): Unit = {\n-    // because loadFactor is 0.75, this means we can fit 2 messages in the map\n-    val cleaner = makeCleaner(2)\n+    // because loadFactor is 0.75, this means we can fit 3 messages in the map", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1eaa27403f22c841af3915110a7eae5a36d5dabf"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQxMjI4OA==", "bodyText": "I took a look at the testPartialSegmentClean which also uses makeCleaner(2), and noticed it does multiple clean attempts since it keeps filling its map, so the logic of the tests are ok. I think the comments are misleading, I traced the code to LogCleaner.buildOffsetMapForSegment , and there's this line:\nval maxDesiredMapSize = (map.slots * this.dupBufferLoadFactor).toInt\n\nSo we will only be able to put one offset in the map, and won't attempt to put anything else after that one even if it's the same key. I am going to change the comments", "url": "https://github.com/apache/kafka/pull/9608#discussion_r526412288", "createdAt": "2020-11-18T20:51:39Z", "author": {"login": "mattwong949"}, "path": "core/src/test/scala/unit/kafka/log/LogCleanerTest.scala", "diffHunk": "@@ -815,9 +815,10 @@ class LogCleanerTest {\n                (0 until leo.toInt by 2).forall(!keys.contains(_)))\n   }\n \n+  @Test\n   def testLogCleanerStats(): Unit = {\n-    // because loadFactor is 0.75, this means we can fit 2 messages in the map\n-    val cleaner = makeCleaner(2)\n+    // because loadFactor is 0.75, this means we can fit 3 messages in the map", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NjM1Ng=="}, "originalCommit": {"oid": "1eaa27403f22c841af3915110a7eae5a36d5dabf"}, "originalPosition": 8}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3874, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}