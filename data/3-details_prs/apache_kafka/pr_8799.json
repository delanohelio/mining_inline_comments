{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI3NTM2Nzg1", "number": 8799, "title": "KAFKA-8011: Fix flaky RegexSourceIntegrationTest", "bodyText": "Ensure that tests cleanup after themselves and use different app.id per test run.\nCall for review @guozhangwang @ableegoldman", "createdAt": "2020-06-04T01:33:07Z", "url": "https://github.com/apache/kafka/pull/8799", "merged": true, "mergeCommit": {"oid": "5a0e65ed394da76ddebf387739f9dec8687a9485"}, "closed": true, "closedAt": "2020-06-05T21:38:09Z", "author": {"login": "mjsax"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcnzzqbgH2gAyNDI3NTM2Nzg1Ojg5N2MyMDAzYzExZTAzMjQ2NjBkMWYzYmQ4NzdlNGMyODE3MjU3Mzc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcoWQa7AH2gAyNDI3NTM2Nzg1OjkzZjYzNDNmZDdmZWEzMDc2ZTViMzQ1ZmNlNGIzMzYxMzc0NGZhYWU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/897c2003c11e0324660d1f3bd877e4c281725737", "committedDate": "2020-06-04T01:30:43Z", "message": "KAFKA-8011: Fix flaky RegexSourceIntegrationTest"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0MDQ0Njcy", "url": "https://github.com/apache/kafka/pull/8799#pullrequestreview-424044672", "createdAt": "2020-06-04T01:40:02Z", "commit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQwMTo0MDowMlrOGey7gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQwMTo0MDowMlrOGey7gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw==", "bodyText": "Should we call close in the finally block? Here and elsewhere", "url": "https://github.com/apache/kafka/pull/8799#discussion_r434944897", "createdAt": "2020-06-04T01:40:02Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c2a6d56caed5b12cf7bc5bd030be305de754b35", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/8c2a6d56caed5b12cf7bc5bd030be305de754b35", "committedDate": "2020-06-04T22:20:11Z", "message": "Minor"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0OTg5NDU4", "url": "https://github.com/apache/kafka/pull/8799#pullrequestreview-424989458", "createdAt": "2020-06-05T04:34:02Z", "commit": {"oid": "8c2a6d56caed5b12cf7bc5bd030be305de754b35"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNDozNDowMlrOGfgFhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNDozNjozMFrOGfgHrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NDc0Mw==", "bodyText": "Could we use\n    @Rule\n    public TestName testName = new TestName();\n\ninstead as the suffix?", "url": "https://github.com/apache/kafka/pull/8799#discussion_r435684743", "createdAt": "2020-06-05T04:34:02Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -124,7 +124,7 @@ public void setUp() throws InterruptedException {\n         properties.put(ConsumerConfig.METADATA_MAX_AGE_CONFIG, \"1000\");\n         properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n \n-        streamsConfiguration = StreamsTestUtils.getStreamsConfig(\"regex-source-integration-test\",\n+        streamsConfiguration = StreamsTestUtils.getStreamsConfig(\"regex-source-integration-test-\" + topicSuffixGenerator.get(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c2a6d56caed5b12cf7bc5bd030be305de754b35"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NTI5NA==", "bodyText": "Why we need to call streams.close() inside the function given they are always called in tearDown? Ditto below.", "url": "https://github.com/apache/kafka/pull/8799#discussion_r435685294", "createdAt": "2020-06-05T04:36:30Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw=="}, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93f6343fd7fea3076e5b345fce4b33613744faae", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/93f6343fd7fea3076e5b345fce4b33613744faae", "committedDate": "2020-06-05T17:38:54Z", "message": "Github comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 852, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}