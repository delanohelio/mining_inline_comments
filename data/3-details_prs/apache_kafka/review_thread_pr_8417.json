{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4MjczNTQ3", "number": 8417, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQyMjowOToyNVrODuvkFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzoyMzoyMFrOD0wTtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMzQwMzc0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeGroupsResponse.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQyMjowOToyNVrOGA198w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjoxMDo0M1rOGBfPWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzUzNzM5NQ==", "bodyText": "It seems like the previous approach is actually more concise and as clear?", "url": "https://github.com/apache/kafka/pull/8417#discussion_r403537395", "createdAt": "2020-04-04T22:09:25Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeGroupsResponse.java", "diffHunk": "@@ -129,9 +129,9 @@ public int throttleTimeMs() {\n     @Override\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n-        data.groups().forEach(describedGroup -> {\n+        for (DescribedGroup describedGroup : data.groups()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc05bdae617332f2f6792f7a394459ad26a40941"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzkzMzk3OA==", "bodyText": "Fair enough, I reverted those two changes. Would you like me to also change the places where for statements were already being used?", "url": "https://github.com/apache/kafka/pull/8417#discussion_r403933978", "createdAt": "2020-04-06T09:00:35Z", "author": {"login": "tombentley"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeGroupsResponse.java", "diffHunk": "@@ -129,9 +129,9 @@ public int throttleTimeMs() {\n     @Override\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n-        data.groups().forEach(describedGroup -> {\n+        for (DescribedGroup describedGroup : data.groups()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzUzNzM5NQ=="}, "originalCommit": {"oid": "fc05bdae617332f2f6792f7a394459ad26a40941"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDEzODQyMA==", "bodyText": "If you would like to clean that up, sure.", "url": "https://github.com/apache/kafka/pull/8417#discussion_r404138420", "createdAt": "2020-04-06T14:32:04Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeGroupsResponse.java", "diffHunk": "@@ -129,9 +129,9 @@ public int throttleTimeMs() {\n     @Override\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n-        data.groups().forEach(describedGroup -> {\n+        for (DescribedGroup describedGroup : data.groups()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzUzNzM5NQ=="}, "originalCommit": {"oid": "fc05bdae617332f2f6792f7a394459ad26a40941"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMzU5NA==", "bodyText": "@ijuma done.", "url": "https://github.com/apache/kafka/pull/8417#discussion_r404213594", "createdAt": "2020-04-06T16:10:43Z", "author": {"login": "tombentley"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/DescribeGroupsResponse.java", "diffHunk": "@@ -129,9 +129,9 @@ public int throttleTimeMs() {\n     @Override\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n-        data.groups().forEach(describedGroup -> {\n+        for (DescribedGroup describedGroup : data.groups()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzUzNzM5NQ=="}, "originalCommit": {"oid": "fc05bdae617332f2f6792f7a394459ad26a40941"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNTA1NzUxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoyMjozMlrOGEAmCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzo1MTo1NVrOGJohXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1NzIyNg==", "bodyText": "it seems this implementation can be replaced by #errorCounts(Stream<Errors>)", "url": "https://github.com/apache/kafka/pull/8417#discussion_r406857226", "createdAt": "2020-04-10T17:22:32Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -57,6 +59,10 @@ public ByteBuffer serialize(ApiKeys apiKey, short version, int correlationId) {\n         return Collections.singletonMap(error, 1);\n     }\n \n+    protected Map<Errors, Integer> errorCounts(Stream<Errors> errors) {\n+        return errors.collect(Collectors.groupingBy(e -> e, Collectors.summingInt(e -> 1)));\n+    }\n+\n     protected Map<Errors, Integer> errorCounts(Collection<Errors> errors) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0db2d9adfdd491bf185f688dfd87e9742e40bc47"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc1NDI2OQ==", "bodyText": "@chia7712 you're right, but the only two remaining callers of this method are for RPCs which haven't been converted to the message generator. There's little benefit to changing them when there are already PRs for converting those RPCs, and I'm planning to remove this method entirely when those PRs have been merged. I guess I could mark this method as @Deprecated.\nRelatedly there's only a single caller of the apiErrorCounts(Map<?, ApiError> errors) method which is also for an not-yet-converted RPC with a PR. If this gets merged first I'll be able to remove apiErrorCounts(Map<?, ApiError> errors) in that PR.", "url": "https://github.com/apache/kafka/pull/8417#discussion_r412754269", "createdAt": "2020-04-22T07:51:55Z", "author": {"login": "tombentley"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -57,6 +59,10 @@ public ByteBuffer serialize(ApiKeys apiKey, short version, int correlationId) {\n         return Collections.singletonMap(error, 1);\n     }\n \n+    protected Map<Errors, Integer> errorCounts(Stream<Errors> errors) {\n+        return errors.collect(Collectors.groupingBy(e -> e, Collectors.summingInt(e -> 1)));\n+    }\n+\n     protected Map<Errors, Integer> errorCounts(Collection<Errors> errors) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1NzIyNg=="}, "originalCommit": {"oid": "0db2d9adfdd491bf185f688dfd87e9742e40bc47"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNTA2NDAxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/CreatePartitionsResponse.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNzoyNDo1MlrOGEAp0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzo1MjowMFrOGJohjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1ODE5NQ==", "bodyText": "Could we leverage the new method errorCounts(Stream<Errors>)? For example:\nreturn errorCounts(data.results().stream().map(result -> Errors.forCode(result.errorCode())));", "url": "https://github.com/apache/kafka/pull/8417#discussion_r406858195", "createdAt": "2020-04-10T17:24:52Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/CreatePartitionsResponse.java", "diffHunk": "@@ -52,10 +51,9 @@ protected Struct toStruct(short version) {\n     @Override\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> counts = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0db2d9adfdd491bf185f688dfd87e9742e40bc47"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc1NDMxOA==", "bodyText": "@chia7712 what I've tried to do in this PR so far is:\n\nChange for stmt  + updateErrorCounts to use forEach consistently\nChange calls to errorCounts(Collection) to errorCounts(Stream)\n\nI've not tried to change all code to use either forEach or errorCounts(Stream). Obviously we could do that, but @ijuma seems happy enough with continuing to have these two ways to do it.", "url": "https://github.com/apache/kafka/pull/8417#discussion_r412754318", "createdAt": "2020-04-22T07:52:00Z", "author": {"login": "tombentley"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/CreatePartitionsResponse.java", "diffHunk": "@@ -52,10 +51,9 @@ protected Struct toStruct(short version) {\n     @Override\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> counts = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjg1ODE5NQ=="}, "originalCommit": {"oid": "0db2d9adfdd491bf185f688dfd87e9742e40bc47"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NTY3NDgyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMzozMTowMVrOGIUjbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNjozMjoxNlrOGJNWbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM3ODU0MA==", "bodyText": "@tombentley Have we done any testing to verify that this way of doing things is no slower than the old way?", "url": "https://github.com/apache/kafka/pull/8417#discussion_r411378540", "createdAt": "2020-04-20T13:31:01Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -57,6 +59,10 @@ public ByteBuffer serialize(ApiKeys apiKey, short version, int correlationId) {\n         return Collections.singletonMap(error, 1);\n     }\n \n+    protected Map<Errors, Integer> errorCounts(Stream<Errors> errors) {\n+        return errors.collect(Collectors.groupingBy(e -> e, Collectors.summingInt(e -> 1)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0db2d9adfdd491bf185f688dfd87e9742e40bc47"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI4Nzk4Ng==", "bodyText": "@ijuma I wrote a small microbenchmark (committed and reverted if you want to take a look) to compare performance. I picked TxnOffsetCommitResponse (more or less at random, but since it has two levels of nesting for topics and partitions it has a double loop) with an unrepresentitively large number of topics and partitions.\nUsing the old code (errorCounts(errors())), I got this test run:\n{NONE=200000000}\nrun 0, times=20000 took 50172790515ns, 398.62243647820753ops/s\n{NONE=200000000}\nrun 1, times=20000 took 49210843555ns, 406.4144923191004ops/s\n{NONE=200000000}\nrun 2, times=20000 took 49366208092ns, 405.1354311582437ops/s\n{NONE=200000000}\nrun 3, times=20000 took 48628565963ns, 411.2808922890589ops/s\n{NONE=200000000}\nrun 4, times=20000 took 48727847017ns, 410.4429237971969ops/s\n\nI aborted early because it was pretty slow. You can see the JIT is improving the performance a little over time.\nUsing the streaming approach I got this test run:\n{NONE=200000000}\nrun 0, times=20000 took 6984797524ns, 2863.36145482805ops/s\n{NONE=200000000}\nrun 1, times=20000 took 6566254988ns, 3045.8762318171493ops/s\n{NONE=200000000}\nrun 2, times=20000 took 6553362923ns, 3051.868214074797ops/s\n{NONE=200000000}\nrun 3, times=20000 took 6259904961ns, 3194.936684279159ops/s\n{NONE=200000000}\nrun 4, times=20000 took 6675450385ns, 2996.052527772626ops/s\n{NONE=200000000}\nrun 5, times=20000 took 6949088789ns, 2878.075184714696ops/s\n{NONE=200000000}\nrun 6, times=20000 took 6045899635ns, 3308.02712704972ops/s\n{NONE=200000000}\nrun 7, times=20000 took 5845348664ns, 3421.5238730197325ops/s\n{NONE=200000000}\nrun 8, times=20000 took 6370088159ns, 3139.6739732311135ops/s\n{NONE=200000000}\nrun 9, times=20000 took 6799792822ns, 2941.2660831800854ops/s\n{NONE=200000000}\nrun 10, times=20000 took 6641092713ns, 3011.5525959831602ops/s\n{NONE=200000000}\nrun 11, times=20000 took 6621610314ns, 3020.4133211696576ops/s\n{NONE=200000000}\nrun 12, times=20000 took 6339235087ns, 3154.9547738045576ops/s\n{NONE=200000000}\nrun 13, times=20000 took 6461046814ns, 3095.473624593366ops/s\n{NONE=200000000}\nrun 14, times=20000 took 6585386195ns, 3037.027656052296ops/s\n{NONE=200000000}\nrun 15, times=20000 took 6565973868ns, 3046.00664000084ops/s\n{NONE=200000000}\nrun 16, times=20000 took 6585253169ns, 3037.0890058031114ops/s\n{NONE=200000000}\nrun 17, times=20000 took 6618664562ns, 3021.7576087518905ops/s\n{NONE=200000000}\nrun 18, times=20000 took 6592603829ns, 3033.7026945290754ops/s\n{NONE=200000000}\nrun 19, times=20000 took 6567525693ns, 3045.2869063484604ops/s\n\nThis is about 7\u00bd times faster.\nOut of interest I also rewote the TxnOffsetCommitResponse.errorCounts() to use a forEach():\n{NONE=200000000}\nrun 0, times=20000 took 6038137472ns, 3312.279671131012ops/s\n{NONE=200000000}\nrun 1, times=20000 took 5642135982ns, 3544.7568197231726ops/s\n{NONE=200000000}\nrun 2, times=20000 took 5551109425ns, 3602.883400195268ops/s\n{NONE=200000000}\nrun 3, times=20000 took 5511950192ns, 3628.4798126492215ops/s\n{NONE=200000000}\nrun 4, times=20000 took 5180664883ns, 3860.5083423999577ops/s\n{NONE=200000000}\nrun 5, times=20000 took 4571569172ns, 4374.865444997799ops/s\n{NONE=200000000}\nrun 6, times=20000 took 5472660241ns, 3654.529811692726ops/s\n{NONE=200000000}\nrun 7, times=20000 took 5499370051ns, 3636.780179279483ops/s\n{NONE=200000000}\nrun 8, times=20000 took 5523721146ns, 3620.7475850736946ops/s\n{NONE=200000000}\nrun 9, times=20000 took 4691001711ns, 4263.481710761627ops/s\n{NONE=200000000}\nrun 10, times=20000 took 5495174831ns, 3639.5566319698773ops/s\n{NONE=200000000}\nrun 11, times=20000 took 5676661773ns, 3523.1974001210237ops/s\n{NONE=200000000}\nrun 12, times=20000 took 5605106974ns, 3568.174540249194ops/s\n{NONE=200000000}\nrun 13, times=20000 took 5577604479ns, 3585.768778568137ops/s\n{NONE=200000000}\nrun 14, times=20000 took 5544332242ns, 3607.287429222572ops/s\n{NONE=200000000}\nrun 15, times=20000 took 5502312660ns, 3634.835247621134ops/s\n{NONE=200000000}\nrun 16, times=20000 took 5528323376ns, 3617.7333776865516ops/s\n{NONE=200000000}\nrun 17, times=20000 took 5528944581ns, 3617.3269069704934ops/s\n{NONE=200000000}\nrun 18, times=20000 took 5496460628ns, 3638.705223888306ops/s\n{NONE=200000000}\nrun 19, times=20000 took 5511532751ns, 3628.754632070588ops/s\n\nThere was some variability between different runs of this benchmark, the above is one of the better ones, the less good ones had performace similar to the Stream case.\nConclusions:\n\nerrorCounts(Stream) is an improvement over errorCounts(Collection).\nIf we're really interested in getting the best performance then we should probably drop errorCounts(Stream) and use forEach everywhere. The drawback is it's a little more verbose than the errorCounts(Stream) approach.\n\nThoughts?", "url": "https://github.com/apache/kafka/pull/8417#discussion_r412287986", "createdAt": "2020-04-21T15:30:12Z", "author": {"login": "tombentley"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -57,6 +59,10 @@ public ByteBuffer serialize(ApiKeys apiKey, short version, int correlationId) {\n         return Collections.singletonMap(error, 1);\n     }\n \n+    protected Map<Errors, Integer> errorCounts(Stream<Errors> errors) {\n+        return errors.collect(Collectors.groupingBy(e -> e, Collectors.summingInt(e -> 1)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM3ODU0MA=="}, "originalCommit": {"oid": "0db2d9adfdd491bf185f688dfd87e9742e40bc47"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMwOTEwMQ==", "bodyText": "Thanks! I think the way you have it now is both fast and concise, not worth changing it to use forEach given how this is normally used.", "url": "https://github.com/apache/kafka/pull/8417#discussion_r412309101", "createdAt": "2020-04-21T16:32:16Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -57,6 +59,10 @@ public ByteBuffer serialize(ApiKeys apiKey, short version, int correlationId) {\n         return Collections.singletonMap(error, 1);\n     }\n \n+    protected Map<Errors, Integer> errorCounts(Stream<Errors> errors) {\n+        return errors.collect(Collectors.groupingBy(e -> e, Collectors.summingInt(e -> 1)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM3ODU0MA=="}, "originalCommit": {"oid": "0db2d9adfdd491bf185f688dfd87e9742e40bc47"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NTY4MjQyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMzozMjo0M1rOGIUn3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMzozMjo0M1rOGIUn3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM3OTY3OA==", "bodyText": "We can probably update updateErrorsCounts to use getOrDefault (I can't comment on the relevant line directly).", "url": "https://github.com/apache/kafka/pull/8417#discussion_r411379678", "createdAt": "2020-04-20T13:32:43Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -57,6 +59,10 @@ public ByteBuffer serialize(ApiKeys apiKey, short version, int correlationId) {\n         return Collections.singletonMap(error, 1);\n     }\n \n+    protected Map<Errors, Integer> errorCounts(Stream<Errors> errors) {\n+        return errors.collect(Collectors.groupingBy(e -> e, Collectors.summingInt(e -> 1)));\n+    }\n+\n     protected Map<Errors, Integer> errorCounts(Collection<Errors> errors) {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n         for (Errors error : errors)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0db2d9adfdd491bf185f688dfd87e9742e40bc47"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NTY5MzEwOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/AlterPartitionReassignmentsResponse.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMzozNDo1NlrOGIUuJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMzozNDo1NlrOGIUuJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM4MTI4Nw==", "bodyText": "Indenting seems wrong?", "url": "https://github.com/apache/kafka/pull/8417#discussion_r411381287", "createdAt": "2020-04-20T13:34:56Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AlterPartitionReassignmentsResponse.java", "diffHunk": "@@ -66,14 +64,13 @@ public int throttleTimeMs() {\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> counts = new HashMap<>();\n         Errors topLevelErr = Errors.forCode(data.errorCode());\n-        counts.put(topLevelErr, counts.getOrDefault(topLevelErr, 0) + 1);\n+        updateErrorCounts(counts, topLevelErr);\n \n-        for (ReassignableTopicResponse topicResponse : data.responses()) {\n-            for (ReassignablePartitionResponse partitionResponse : topicResponse.partitions()) {\n-                Errors error = Errors.forCode(partitionResponse.errorCode());\n-                counts.put(error, counts.getOrDefault(error, 0) + 1);\n-            }\n-        }\n+        data.responses().forEach(topicResponse ->\n+                topicResponse.partitions().forEach(partitionResponse ->\n+                updateErrorCounts(counts, Errors.forCode(partitionResponse.errorCode()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0db2d9adfdd491bf185f688dfd87e9742e40bc47"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NjQxNDg4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/AlterPartitionReassignmentsResponse.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzoxODoxMlrOGJ17lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzoxODoxMlrOGJ17lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk3Mzk3NA==", "bodyText": "Indent.", "url": "https://github.com/apache/kafka/pull/8417#discussion_r412973974", "createdAt": "2020-04-22T13:18:12Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AlterPartitionReassignmentsResponse.java", "diffHunk": "@@ -66,14 +64,12 @@ public int throttleTimeMs() {\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> counts = new HashMap<>();\n         Errors topLevelErr = Errors.forCode(data.errorCode());\n-        counts.put(topLevelErr, counts.getOrDefault(topLevelErr, 0) + 1);\n+        updateErrorCounts(counts, topLevelErr);\n \n-        for (ReassignableTopicResponse topicResponse : data.responses()) {\n-            for (ReassignablePartitionResponse partitionResponse : topicResponse.partitions()) {\n-                Errors error = Errors.forCode(partitionResponse.errorCode());\n-                counts.put(error, counts.getOrDefault(error, 0) + 1);\n-            }\n-        }\n+        data.responses().forEach(topicResponse ->\n+            topicResponse.partitions().forEach(partitionResponse ->\n+            updateErrorCounts(counts, Errors.forCode(partitionResponse.errorCode()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8da16bfd88e1c0e84dc99fa362e6e4b5762e95c"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NjQxNTkxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/AlterPartitionReassignmentsResponse.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzoxODoyNVrOGJ18MA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzoxODoyNVrOGJ18MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk3NDEyOA==", "bodyText": "Maybe inline.", "url": "https://github.com/apache/kafka/pull/8417#discussion_r412974128", "createdAt": "2020-04-22T13:18:25Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AlterPartitionReassignmentsResponse.java", "diffHunk": "@@ -66,14 +64,12 @@ public int throttleTimeMs() {\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> counts = new HashMap<>();\n         Errors topLevelErr = Errors.forCode(data.errorCode());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8da16bfd88e1c0e84dc99fa362e6e4b5762e95c"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NjQzMzg5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetCommitResponse.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzoyMTo1OVrOGJ2HIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzo1MzowNlrOGJ3rSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk3NjkyOA==", "bodyText": "Is there a reason why we are not doing the map within the flatMap?", "url": "https://github.com/apache/kafka/pull/8417#discussion_r412976928", "createdAt": "2020-04-22T13:21:59Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetCommitResponse.java", "diffHunk": "@@ -95,13 +94,8 @@ public OffsetCommitResponseData data() {\n \n     @Override\n     public Map<Errors, Integer> errorCounts() {\n-        List<Errors> errors = new ArrayList<>();\n-        for (OffsetCommitResponseTopic topic : data.topics()) {\n-            for (OffsetCommitResponsePartition partition : topic.partitions()) {\n-                errors.add(Errors.forCode(partition.errorCode()));\n-            }\n-        }\n-        return errorCounts(errors);\n+        return errorCounts(data.topics().stream().flatMap(topicResult -> topicResult.partitions().stream())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8da16bfd88e1c0e84dc99fa362e6e4b5762e95c"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwMjU2OA==", "bodyText": "No good reason. Good spot.", "url": "https://github.com/apache/kafka/pull/8417#discussion_r413002568", "createdAt": "2020-04-22T13:53:06Z", "author": {"login": "tombentley"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetCommitResponse.java", "diffHunk": "@@ -95,13 +94,8 @@ public OffsetCommitResponseData data() {\n \n     @Override\n     public Map<Errors, Integer> errorCounts() {\n-        List<Errors> errors = new ArrayList<>();\n-        for (OffsetCommitResponseTopic topic : data.topics()) {\n-            for (OffsetCommitResponsePartition partition : topic.partitions()) {\n-                errors.add(Errors.forCode(partition.errorCode()));\n-            }\n-        }\n-        return errorCounts(errors);\n+        return errorCounts(data.topics().stream().flatMap(topicResult -> topicResult.partitions().stream())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk3NjkyOA=="}, "originalCommit": {"oid": "d8da16bfd88e1c0e84dc99fa362e6e4b5762e95c"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NjQ0MDIxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitResponse.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzoyMzoyMFrOGJ2LEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzo1MzoyNlrOGJ3sbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk3NzkzOA==", "bodyText": "Any reason why we don't do the map inside the flatMap?", "url": "https://github.com/apache/kafka/pull/8417#discussion_r412977938", "createdAt": "2020-04-22T13:23:20Z", "author": {"login": "ijuma"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitResponse.java", "diffHunk": "@@ -91,7 +91,9 @@ public int throttleTimeMs() {\n \n     @Override\n     public Map<Errors, Integer> errorCounts() {\n-        return errorCounts(errors().values());\n+        return errorCounts(data.topics().stream()\n+                .flatMap(topic -> topic.partitions().stream())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8da16bfd88e1c0e84dc99fa362e6e4b5762e95c"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwMjg2Mg==", "bodyText": "As above.", "url": "https://github.com/apache/kafka/pull/8417#discussion_r413002862", "createdAt": "2020-04-22T13:53:26Z", "author": {"login": "tombentley"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitResponse.java", "diffHunk": "@@ -91,7 +91,9 @@ public int throttleTimeMs() {\n \n     @Override\n     public Map<Errors, Integer> errorCounts() {\n-        return errorCounts(errors().values());\n+        return errorCounts(data.topics().stream()\n+                .flatMap(topic -> topic.partitions().stream())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk3NzkzOA=="}, "originalCommit": {"oid": "d8da16bfd88e1c0e84dc99fa362e6e4b5762e95c"}, "originalPosition": 6}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3200, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}