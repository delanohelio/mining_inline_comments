{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyMTMxNzcz", "number": 8055, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwNjozMToxMVrODd7IOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxNjo0MjoyNlrODeFSRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNzA0MDU4OnYy", "diffSide": "RIGHT", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwNjozMToxMVrOFmzbSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxNjo0MjozMVrOFnDPeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjIzMjc3Nw==", "bodyText": "seems the return value is never used?", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376232777", "createdAt": "2020-02-07T06:31:11Z", "author": {"login": "chia7712"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -263,36 +266,37 @@ public void startConnect() {\n      *\n      * @param connName   the name of the connector\n      * @param connConfig the intended configuration\n-     * @throws IOException          if call to the REST api fails.\n+     * @throws ConnectException if the configuration fails to be serialized\n      * @throws ConnectRestException if REST api returns error status\n      */\n-    public void configureConnector(String connName, Map<String, String> connConfig) throws IOException {\n+    public String configureConnector(String connName, Map<String, String> connConfig) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ4NDU4Mg==", "bodyText": "Isn't a string returned on line 283?", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376484582", "createdAt": "2020-02-07T16:28:32Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -263,36 +266,37 @@ public void startConnect() {\n      *\n      * @param connName   the name of the connector\n      * @param connConfig the intended configuration\n-     * @throws IOException          if call to the REST api fails.\n+     * @throws ConnectException if the configuration fails to be serialized\n      * @throws ConnectRestException if REST api returns error status\n      */\n-    public void configureConnector(String connName, Map<String, String> connConfig) throws IOException {\n+    public String configureConnector(String connName, Map<String, String> connConfig) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjIzMjc3Nw=="}, "originalCommit": null, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5MTg5Ng==", "bodyText": "BTW, I think changing the return type from void to something else would be considered backward compatible, so this type of change is acceptable.", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376491896", "createdAt": "2020-02-07T16:42:31Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -263,36 +266,37 @@ public void startConnect() {\n      *\n      * @param connName   the name of the connector\n      * @param connConfig the intended configuration\n-     * @throws IOException          if call to the REST api fails.\n+     * @throws ConnectException if the configuration fails to be serialized\n      * @throws ConnectRestException if REST api returns error status\n      */\n-    public void configureConnector(String connName, Map<String, String> connConfig) throws IOException {\n+    public String configureConnector(String connName, Map<String, String> connConfig) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjIzMjc3Nw=="}, "originalCommit": null, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyODY3NDUzOnYy", "diffSide": "RIGHT", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxNjozMjo1M1rOFnC8Dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOTozNTowN1rOFnH--Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ4NjkyNg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * @throws ConnectException if the configuration fails to be serialized\n          \n          \n            \n                 * @throws ConnectException if the configuration fails to be serialized or if the request could not be sent", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376486926", "createdAt": "2020-02-07T16:32:53Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -263,36 +266,37 @@ public void startConnect() {\n      *\n      * @param connName   the name of the connector\n      * @param connConfig the intended configuration\n-     * @throws IOException          if call to the REST api fails.\n+     * @throws ConnectException if the configuration fails to be serialized", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2OTU5Mw==", "bodyText": "Added with the other changes", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376569593", "createdAt": "2020-02-07T19:35:07Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -263,36 +266,37 @@ public void startConnect() {\n      *\n      * @param connName   the name of the connector\n      * @param connConfig the intended configuration\n-     * @throws IOException          if call to the REST api fails.\n+     * @throws ConnectException if the configuration fails to be serialized", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ4NjkyNg=="}, "originalCommit": null, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyODY3NjU0OnYy", "diffSide": "RIGHT", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxNjozMzozNFrOFnC9Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOTozMzo1MFrOFnH8wQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ4NzI1MA==", "bodyText": "The executePut can actually throw ConnectException, so we should reflect that in the JavaDoc", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376487250", "createdAt": "2020-02-07T16:33:34Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -263,36 +266,37 @@ public void startConnect() {\n      *\n      * @param connName   the name of the connector\n      * @param connConfig the intended configuration\n-     * @throws IOException          if call to the REST api fails.\n+     * @throws ConnectException if the configuration fails to be serialized\n      * @throws ConnectRestException if REST api returns error status\n      */\n-    public void configureConnector(String connName, Map<String, String> connConfig) throws IOException {\n+    public String configureConnector(String connName, Map<String, String> connConfig) {\n         String url = endpointForResource(String.format(\"connectors/%s/config\", connName));\n         ObjectMapper mapper = new ObjectMapper();\n-        int status;\n+        String content;\n         try {\n-            String content = mapper.writeValueAsString(connConfig);\n-            status = executePut(url, content);\n+            content = mapper.writeValueAsString(connConfig);\n         } catch (IOException e) {\n-            log.error(\"Could not execute PUT request to \" + url, e);\n-            throw e;\n+            throw new ConnectException(\"Could not serialize connector configuration and execute PUT request\");\n         }\n-        if (status >= HttpServletResponse.SC_BAD_REQUEST) {\n-            throw new ConnectRestException(status, \"Could not execute PUT request\");\n+        Response response = executePut(url, content);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2OTAyNQ==", "bodyText": "Good point. Added", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376569025", "createdAt": "2020-02-07T19:33:50Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -263,36 +266,37 @@ public void startConnect() {\n      *\n      * @param connName   the name of the connector\n      * @param connConfig the intended configuration\n-     * @throws IOException          if call to the REST api fails.\n+     * @throws ConnectException if the configuration fails to be serialized\n      * @throws ConnectRestException if REST api returns error status\n      */\n-    public void configureConnector(String connName, Map<String, String> connConfig) throws IOException {\n+    public String configureConnector(String connName, Map<String, String> connConfig) {\n         String url = endpointForResource(String.format(\"connectors/%s/config\", connName));\n         ObjectMapper mapper = new ObjectMapper();\n-        int status;\n+        String content;\n         try {\n-            String content = mapper.writeValueAsString(connConfig);\n-            status = executePut(url, content);\n+            content = mapper.writeValueAsString(connConfig);\n         } catch (IOException e) {\n-            log.error(\"Could not execute PUT request to \" + url, e);\n-            throw e;\n+            throw new ConnectException(\"Could not serialize connector configuration and execute PUT request\");\n         }\n-        if (status >= HttpServletResponse.SC_BAD_REQUEST) {\n-            throw new ConnectRestException(status, \"Could not execute PUT request\");\n+        Response response = executePut(url, content);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ4NzI1MA=="}, "originalCommit": null, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyODY4NDQ4OnYy", "diffSide": "RIGHT", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxNjozNjowM1rOFnDCUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOTozNTo0OFrOFnIAHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ4ODUyOQ==", "bodyText": "Since the IOException was declared on the signature, it's clear that calling code has to handle this case. But because ConnectException is a runtime exception, we should probably add JavaDoc for this method to explain that ConnectException will be thrown if the endpoint is not known.", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376488529", "createdAt": "2020-02-07T16:36:03Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -305,50 +309,63 @@ public void deleteConnector(String connName) throws IOException {\n      */\n     public Collection<String> connectors() {\n         ObjectMapper mapper = new ObjectMapper();\n-        try {\n-            String url = endpointForResource(\"connectors\");\n-            return mapper.readerFor(Collection.class).readValue(executeGet(url));\n-        } catch (IOException e) {\n-            log.error(\"Could not read connector list\", e);\n-            throw new ConnectException(\"Could not read connector list\", e);\n+        String url = endpointForResource(\"connectors\");\n+        Response response = executeGet(url);\n+        if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n+            try {\n+                return mapper.readerFor(Collection.class).readValue(responseToString(response));\n+            } catch(IOException e){\n+                log.error(\"Could not parse connector list from response: {}\",\n+                        responseToString(response), e);\n+                throw new ConnectException(\"Could not not parse connector list\", e);\n+            }\n         }\n+        throw new ConnectRestException(response.getStatus(),\n+                \"Could not read connector list. Error response: \" + responseToString(response));\n     }\n \n     /**\n      * Get the status for a connector running in this cluster.\n      *\n      * @param connectorName name of the connector\n-     * @return an instance of {@link ConnectorStateInfo} populated with state informaton of the connector and it's tasks.\n+     * @return an instance of {@link ConnectorStateInfo} populated with state information of the connector and its tasks.\n      * @throws ConnectRestException if the HTTP request to the REST API failed with a valid status code.\n      * @throws ConnectException for any other error.\n      */\n     public ConnectorStateInfo connectorStatus(String connectorName) {\n         ObjectMapper mapper = new ObjectMapper();\n+        String url = endpointForResource(String.format(\"connectors/%s/status\", connectorName));\n+        Response response = executeGet(url);\n         try {\n-            String url = endpointForResource(String.format(\"connectors/%s/status\", connectorName));\n-            return mapper.readerFor(ConnectorStateInfo.class).readValue(executeGet(url));\n+            if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n+                return mapper.readerFor(ConnectorStateInfo.class)\n+                        .readValue(responseToString(response));\n+            }\n         } catch (IOException e) {\n-            log.error(\"Could not read connector state\", e);\n-            throw new ConnectException(\"Could not read connector state\", e);\n+            log.error(\"Could not read connector state from response: {}\",\n+                    responseToString(response), e);\n+            throw new ConnectException(\"Could not not parse connector state\", e);\n         }\n+        throw new ConnectRestException(response.getStatus(),\n+                \"Could not read connector state. Error response: \" + responseToString(response));\n     }\n \n-    public String adminEndpoint(String resource) throws IOException {\n+    public String adminEndpoint(String resource) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2OTg4NA==", "bodyText": "Missed that these public methods were missing a javadoc. Added.", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376569884", "createdAt": "2020-02-07T19:35:48Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -305,50 +309,63 @@ public void deleteConnector(String connName) throws IOException {\n      */\n     public Collection<String> connectors() {\n         ObjectMapper mapper = new ObjectMapper();\n-        try {\n-            String url = endpointForResource(\"connectors\");\n-            return mapper.readerFor(Collection.class).readValue(executeGet(url));\n-        } catch (IOException e) {\n-            log.error(\"Could not read connector list\", e);\n-            throw new ConnectException(\"Could not read connector list\", e);\n+        String url = endpointForResource(\"connectors\");\n+        Response response = executeGet(url);\n+        if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n+            try {\n+                return mapper.readerFor(Collection.class).readValue(responseToString(response));\n+            } catch(IOException e){\n+                log.error(\"Could not parse connector list from response: {}\",\n+                        responseToString(response), e);\n+                throw new ConnectException(\"Could not not parse connector list\", e);\n+            }\n         }\n+        throw new ConnectRestException(response.getStatus(),\n+                \"Could not read connector list. Error response: \" + responseToString(response));\n     }\n \n     /**\n      * Get the status for a connector running in this cluster.\n      *\n      * @param connectorName name of the connector\n-     * @return an instance of {@link ConnectorStateInfo} populated with state informaton of the connector and it's tasks.\n+     * @return an instance of {@link ConnectorStateInfo} populated with state information of the connector and its tasks.\n      * @throws ConnectRestException if the HTTP request to the REST API failed with a valid status code.\n      * @throws ConnectException for any other error.\n      */\n     public ConnectorStateInfo connectorStatus(String connectorName) {\n         ObjectMapper mapper = new ObjectMapper();\n+        String url = endpointForResource(String.format(\"connectors/%s/status\", connectorName));\n+        Response response = executeGet(url);\n         try {\n-            String url = endpointForResource(String.format(\"connectors/%s/status\", connectorName));\n-            return mapper.readerFor(ConnectorStateInfo.class).readValue(executeGet(url));\n+            if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n+                return mapper.readerFor(ConnectorStateInfo.class)\n+                        .readValue(responseToString(response));\n+            }\n         } catch (IOException e) {\n-            log.error(\"Could not read connector state\", e);\n-            throw new ConnectException(\"Could not read connector state\", e);\n+            log.error(\"Could not read connector state from response: {}\",\n+                    responseToString(response), e);\n+            throw new ConnectException(\"Could not not parse connector state\", e);\n         }\n+        throw new ConnectRestException(response.getStatus(),\n+                \"Could not read connector state. Error response: \" + responseToString(response));\n     }\n \n-    public String adminEndpoint(String resource) throws IOException {\n+    public String adminEndpoint(String resource) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ4ODUyOQ=="}, "originalCommit": null, "originalPosition": 160}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyODY4NDk1OnYy", "diffSide": "RIGHT", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxNjozNjoxMFrOFnDClw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOTozNjoxM1rOFnIA8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ4ODU5OQ==", "bodyText": "Since the IOException was declared on the signature, it's clear that calling code has to handle this case. But because ConnectException is a runtime exception, we should probably add JavaDoc for this method to explain that ConnectException will be thrown if the endpoint is not known.", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376488599", "createdAt": "2020-02-07T16:36:10Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -305,50 +309,63 @@ public void deleteConnector(String connName) throws IOException {\n      */\n     public Collection<String> connectors() {\n         ObjectMapper mapper = new ObjectMapper();\n-        try {\n-            String url = endpointForResource(\"connectors\");\n-            return mapper.readerFor(Collection.class).readValue(executeGet(url));\n-        } catch (IOException e) {\n-            log.error(\"Could not read connector list\", e);\n-            throw new ConnectException(\"Could not read connector list\", e);\n+        String url = endpointForResource(\"connectors\");\n+        Response response = executeGet(url);\n+        if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n+            try {\n+                return mapper.readerFor(Collection.class).readValue(responseToString(response));\n+            } catch(IOException e){\n+                log.error(\"Could not parse connector list from response: {}\",\n+                        responseToString(response), e);\n+                throw new ConnectException(\"Could not not parse connector list\", e);\n+            }\n         }\n+        throw new ConnectRestException(response.getStatus(),\n+                \"Could not read connector list. Error response: \" + responseToString(response));\n     }\n \n     /**\n      * Get the status for a connector running in this cluster.\n      *\n      * @param connectorName name of the connector\n-     * @return an instance of {@link ConnectorStateInfo} populated with state informaton of the connector and it's tasks.\n+     * @return an instance of {@link ConnectorStateInfo} populated with state information of the connector and its tasks.\n      * @throws ConnectRestException if the HTTP request to the REST API failed with a valid status code.\n      * @throws ConnectException for any other error.\n      */\n     public ConnectorStateInfo connectorStatus(String connectorName) {\n         ObjectMapper mapper = new ObjectMapper();\n+        String url = endpointForResource(String.format(\"connectors/%s/status\", connectorName));\n+        Response response = executeGet(url);\n         try {\n-            String url = endpointForResource(String.format(\"connectors/%s/status\", connectorName));\n-            return mapper.readerFor(ConnectorStateInfo.class).readValue(executeGet(url));\n+            if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n+                return mapper.readerFor(ConnectorStateInfo.class)\n+                        .readValue(responseToString(response));\n+            }\n         } catch (IOException e) {\n-            log.error(\"Could not read connector state\", e);\n-            throw new ConnectException(\"Could not read connector state\", e);\n+            log.error(\"Could not read connector state from response: {}\",\n+                    responseToString(response), e);\n+            throw new ConnectException(\"Could not not parse connector state\", e);\n         }\n+        throw new ConnectRestException(response.getStatus(),\n+                \"Could not read connector state. Error response: \" + responseToString(response));\n     }\n \n-    public String adminEndpoint(String resource) throws IOException {\n+    public String adminEndpoint(String resource) {\n         String url = connectCluster.stream()\n                 .map(WorkerHandle::adminUrl)\n                 .filter(Objects::nonNull)\n                 .findFirst()\n-                .orElseThrow(() -> new IOException(\"Admin endpoint is disabled.\"))\n+                .orElseThrow(() -> new ConnectException(\"Admin endpoint is disabled.\"))\n                 .toString();\n         return url + resource;\n     }\n \n-    public String endpointForResource(String resource) throws IOException {\n+    public String endpointForResource(String resource) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU3MDA5Nw==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376570097", "createdAt": "2020-02-07T19:36:13Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -305,50 +309,63 @@ public void deleteConnector(String connName) throws IOException {\n      */\n     public Collection<String> connectors() {\n         ObjectMapper mapper = new ObjectMapper();\n-        try {\n-            String url = endpointForResource(\"connectors\");\n-            return mapper.readerFor(Collection.class).readValue(executeGet(url));\n-        } catch (IOException e) {\n-            log.error(\"Could not read connector list\", e);\n-            throw new ConnectException(\"Could not read connector list\", e);\n+        String url = endpointForResource(\"connectors\");\n+        Response response = executeGet(url);\n+        if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n+            try {\n+                return mapper.readerFor(Collection.class).readValue(responseToString(response));\n+            } catch(IOException e){\n+                log.error(\"Could not parse connector list from response: {}\",\n+                        responseToString(response), e);\n+                throw new ConnectException(\"Could not not parse connector list\", e);\n+            }\n         }\n+        throw new ConnectRestException(response.getStatus(),\n+                \"Could not read connector list. Error response: \" + responseToString(response));\n     }\n \n     /**\n      * Get the status for a connector running in this cluster.\n      *\n      * @param connectorName name of the connector\n-     * @return an instance of {@link ConnectorStateInfo} populated with state informaton of the connector and it's tasks.\n+     * @return an instance of {@link ConnectorStateInfo} populated with state information of the connector and its tasks.\n      * @throws ConnectRestException if the HTTP request to the REST API failed with a valid status code.\n      * @throws ConnectException for any other error.\n      */\n     public ConnectorStateInfo connectorStatus(String connectorName) {\n         ObjectMapper mapper = new ObjectMapper();\n+        String url = endpointForResource(String.format(\"connectors/%s/status\", connectorName));\n+        Response response = executeGet(url);\n         try {\n-            String url = endpointForResource(String.format(\"connectors/%s/status\", connectorName));\n-            return mapper.readerFor(ConnectorStateInfo.class).readValue(executeGet(url));\n+            if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n+                return mapper.readerFor(ConnectorStateInfo.class)\n+                        .readValue(responseToString(response));\n+            }\n         } catch (IOException e) {\n-            log.error(\"Could not read connector state\", e);\n-            throw new ConnectException(\"Could not read connector state\", e);\n+            log.error(\"Could not read connector state from response: {}\",\n+                    responseToString(response), e);\n+            throw new ConnectException(\"Could not not parse connector state\", e);\n         }\n+        throw new ConnectRestException(response.getStatus(),\n+                \"Could not read connector state. Error response: \" + responseToString(response));\n     }\n \n-    public String adminEndpoint(String resource) throws IOException {\n+    public String adminEndpoint(String resource) {\n         String url = connectCluster.stream()\n                 .map(WorkerHandle::adminUrl)\n                 .filter(Objects::nonNull)\n                 .findFirst()\n-                .orElseThrow(() -> new IOException(\"Admin endpoint is disabled.\"))\n+                .orElseThrow(() -> new ConnectException(\"Admin endpoint is disabled.\"))\n                 .toString();\n         return url + resource;\n     }\n \n-    public String endpointForResource(String resource) throws IOException {\n+    public String endpointForResource(String resource) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ4ODU5OQ=="}, "originalCommit": null, "originalPosition": 172}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyODY5NDc1OnYy", "diffSide": "RIGHT", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxNjozOToxN1rOFnDI4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOTozNzo0NVrOFnIDgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5MDIxMA==", "bodyText": "Changing the return type from int to Response would be a breaking change. While this test harness is technically not part of the public API of Connect, we did intend that other projects could use this harness as long as they understand that we might change the API in breaking ways.\nBut IMO we should still try to evolve the API in ways that are backward compatible, and so I would suggest adding new methods that return Response, having the existing methods delegate to them, and deprecate the old methods.", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376490210", "createdAt": "2020-02-07T16:39:17Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -363,87 +380,97 @@ public EmbeddedKafkaCluster kafka() {\n         return kafkaCluster;\n     }\n \n-    public int executePut(String url, String body) throws IOException {\n-        log.debug(\"Executing PUT request to URL={}. Payload={}\", url, body);\n-        HttpURLConnection httpCon = (HttpURLConnection) new URL(url).openConnection();\n-        httpCon.setDoOutput(true);\n-        httpCon.setRequestProperty(\"Content-Type\", \"application/json\");\n-        httpCon.setRequestMethod(\"PUT\");\n-        try (OutputStreamWriter out = new OutputStreamWriter(httpCon.getOutputStream())) {\n-            out.write(body);\n-        }\n-        if (httpCon.getResponseCode() < HttpURLConnection.HTTP_BAD_REQUEST) {\n-            try (InputStream is = httpCon.getInputStream()) {\n-                log.info(\"PUT response for URL={} is {}\", url, responseToString(is));\n-            }\n-        } else {\n-            try (InputStream is = httpCon.getErrorStream()) {\n-                log.info(\"PUT error response for URL={} is {}\", url, responseToString(is));\n-            }\n-        }\n-        return httpCon.getResponseCode();\n+    /**\n+     * Execute a GET request on the given URL.\n+     *\n+     * @param url the HTTP endpoint\n+     * @return the response to the GET request\n+     * @throws ConnectException if execution of the GET request fails\n+     */\n+    public Response executeGet(String url) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU3MDc1Mg==", "bodyText": "That's an excellent point. I overlooked this possibility.\nI've deprecated all the execute* methods. Since there can't be overloading on the return type alone I've added the new methods as request*. Hope that works.", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376570752", "createdAt": "2020-02-07T19:37:45Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedConnectCluster.java", "diffHunk": "@@ -363,87 +380,97 @@ public EmbeddedKafkaCluster kafka() {\n         return kafkaCluster;\n     }\n \n-    public int executePut(String url, String body) throws IOException {\n-        log.debug(\"Executing PUT request to URL={}. Payload={}\", url, body);\n-        HttpURLConnection httpCon = (HttpURLConnection) new URL(url).openConnection();\n-        httpCon.setDoOutput(true);\n-        httpCon.setRequestProperty(\"Content-Type\", \"application/json\");\n-        httpCon.setRequestMethod(\"PUT\");\n-        try (OutputStreamWriter out = new OutputStreamWriter(httpCon.getOutputStream())) {\n-            out.write(body);\n-        }\n-        if (httpCon.getResponseCode() < HttpURLConnection.HTTP_BAD_REQUEST) {\n-            try (InputStream is = httpCon.getInputStream()) {\n-                log.info(\"PUT response for URL={} is {}\", url, responseToString(is));\n-            }\n-        } else {\n-            try (InputStream is = httpCon.getErrorStream()) {\n-                log.info(\"PUT error response for URL={} is {}\", url, responseToString(is));\n-            }\n-        }\n-        return httpCon.getResponseCode();\n+    /**\n+     * Execute a GET request on the given URL.\n+     *\n+     * @param url the HTTP endpoint\n+     * @return the response to the GET request\n+     * @throws ConnectException if execution of the GET request fails\n+     */\n+    public Response executeGet(String url) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5MDIxMA=="}, "originalCommit": null, "originalPosition": 212}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyODcwNDY4OnYy", "diffSide": "RIGHT", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/SessionedProtocolIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxNjo0MjoyNlrOFnDPUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOTozNDo0MFrOFnH-OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5MTg1Nw==", "bodyText": "Technically, we shouldn't have to change this test if we were to maintain backward compatibility as I suggested on a different comment. But if we were to deprecate the existing executePost method that returns an int (and similar methods), I think it's worth changing this test to use the new methods that do return the Response to prevent a deprecation warning and to show users an example of how to migrate to the new methods.", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376491857", "createdAt": "2020-02-07T16:42:26Z", "author": {"login": "rhauch"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/SessionedProtocolIntegrationTest.java", "diffHunk": "@@ -162,7 +162,7 @@ public void ensureInternalEndpointIsSecured() throws Throwable {\n         );\n         assertEquals(\n             FORBIDDEN.getStatusCode(),\n-            connect.executePost(connectorTasksEndpoint, \"[]\", invalidSignatureHeaders)\n+            connect.executePost(connectorTasksEndpoint, \"[]\", invalidSignatureHeaders).getStatus()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2OTQwMA==", "bodyText": "I agree. Using the new methods now.", "url": "https://github.com/apache/kafka/pull/8055#discussion_r376569400", "createdAt": "2020-02-07T19:34:40Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/SessionedProtocolIntegrationTest.java", "diffHunk": "@@ -162,7 +162,7 @@ public void ensureInternalEndpointIsSecured() throws Throwable {\n         );\n         assertEquals(\n             FORBIDDEN.getStatusCode(),\n-            connect.executePost(connectorTasksEndpoint, \"[]\", invalidSignatureHeaders)\n+            connect.executePost(connectorTasksEndpoint, \"[]\", invalidSignatureHeaders).getStatus()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5MTg1Nw=="}, "originalCommit": null, "originalPosition": 32}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4215, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}