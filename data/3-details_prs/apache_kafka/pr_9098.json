{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4Mzg1NzI0", "number": 9098, "title": "KAFKA-9924: Prepare RocksDB and metrics for RocksDB properties recording", "bodyText": "This PR refactors the RocksDB store and the metrics infrastructure in Streams\nin preparation of the recordings of the RocksDB properties specified in KIP-607.\nThe refactoring includes:\n\nwrapper around BlockedBasedTableConfig to make the cache accessible to the\nRocksDB metrics recorder\nRocksDB metrics recorder now takes also the DB instance and the cache in addition\nto the statistics\nThe value providers for the metrics are added to the RockDB metrics recorder also if\nthe recording level is INFO.\nThe creation of the RocksDB metrics recording trigger is moved to StreamsMetricsImpl\n\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-07-29T11:46:15Z", "url": "https://github.com/apache/kafka/pull/9098", "merged": true, "mergeCommit": {"oid": "5645d906fa319206a9270c080926a21dfddc852a"}, "closed": true, "closedAt": "2020-08-13T19:40:41Z", "author": {"login": "cadonna"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc5paXIAH2gAyNDU4Mzg1NzI0OmRkNjQ3NTM1MzM5YTlkMGNjNjAwM2NhYTVmMjk3MTk1ZmQ2NGQ2MTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc-N6NcAFqTQ2NjA3NTk0Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "dd647535339a9d0cc6003caa5f297195fd64d615", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/dd647535339a9d0cc6003caa5f297195fd64d615", "committedDate": "2020-07-29T11:34:40Z", "message": "Add wrapper around BlockBasedTableConfig to make cache accessible"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "634d18b15ff400dced3b1af6b43c98630e115d8d", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/634d18b15ff400dced3b1af6b43c98630e115d8d", "committedDate": "2020-07-29T11:34:40Z", "message": "Refactor RocksDBMetricsRecorder and instantiation of RocksDBMetricsRecordingTrigger"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "67986c4b3e7c8fa627ec52a10bbdc3138e828b8d", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/67986c4b3e7c8fa627ec52a10bbdc3138e828b8d", "committedDate": "2020-07-30T08:51:12Z", "message": "Add unit test when user specifies new table format config"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0afb35d8bba0d76adf9002bd9db14025cd0ca340", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/0afb35d8bba0d76adf9002bd9db14025cd0ca340", "committedDate": "2020-07-30T10:25:54Z", "message": "Make RocksDB recording trigger member variable final"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NTc0MjA1", "url": "https://github.com/apache/kafka/pull/9098#pullrequestreview-458574205", "createdAt": "2020-07-30T16:39:57Z", "commit": {"oid": "0afb35d8bba0d76adf9002bd9db14025cd0ca340"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNjozOTo1OFrOG5rHTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNjo0Njo0M1rOG5rXlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEyODM5OA==", "bodyText": "Ah, after reading your test, I now see the issue. I'd overlooked the fact that users would independently construct the table config object AND the cache. I see now that this makes it impossible to reliably capture the cache, since users have to actually choose to pass our special table config to the Options and then pass the Cache to that table config.\nThis doesn't seem ideal. What do you think about just using reflection instead?\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache) {\n          \n          \n            \n                        final Cache cache = ((BlockBasedTableConfigWithAccessibleCache) tableFormatConfig).blockCache();\n          \n          \n            \n                        metricsRecorder.addValueProviders(name, db, cache, statistics);\n          \n          \n            \n                    } else {\n          \n          \n            \n                        metricsRecorder.addValueProviders(name, db, null, statistics);\n          \n          \n            \n                        log.warn(\"A table format configuration is used that does not expose the block cache. This means \" +\n          \n          \n            \n                            \"that metrics that relate to the block cache may be wrong if the block cache is shared.\");\n          \n          \n            \n                    }\n          \n          \n            \n                    if (tableFormatConfig instanceof BlockBasedTableConfig) {\n          \n          \n            \n                        final BlockBasedTableConfig blockBasedTableConfig = (BlockBasedTableConfig) tableFormatConfig;\n          \n          \n            \n                        try {\n          \n          \n            \n                            final Field blockCacheField = BlockBasedTableConfig.class.getDeclaredField(\"blockCache_\");\n          \n          \n            \n                            blockCacheField.setAccessible(true);\n          \n          \n            \n                            final Cache nullableBlockCache = (Cache) blockCacheField.get(blockBasedTableConfig);\n          \n          \n            \n                            metricsRecorder.addValueProviders(name, db, nullableBlockCache, statistics);\n          \n          \n            \n                        } catch (final NoSuchFieldException | IllegalAccessException | ClassCastException e) {\n          \n          \n            \n                            log.warn(\"Expected to find and access field 'blockCache_' in BlockBasedTableConfig. \" +\n          \n          \n            \n                                         \"Probably, an incompatible version of RocksDB is being used. \" +\n          \n          \n            \n                                         \"Cache will be missing from memory metrics.\", e);\n          \n          \n            \n                            metricsRecorder.addValueProviders(name, db, null, statistics);\n          \n          \n            \n                        }\n          \n          \n            \n                    } else {\n          \n          \n            \n                        metricsRecorder.addValueProviders(name, db, null, statistics);\n          \n          \n            \n                    }\n          \n      \n    \n    \n  \n\nWe would obviously test all the branches here to de-risk the reflection. We can also add a test that searches the classpath for implementations of TableFormatConfig to ensure we don't miss the memo if RocksDB adds a new TableFormatConfig implementation.\nAlternative thought, if you don't like the reflection: We would also subclass Options and override org.rocksdb.Options#setTableFormatConfig to check if the passed TableFormatConfig is a BlockBasedTableConfig, and if so, then we wrap it with BlockBasedTableConfigWithAccessibleCache.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r463128398", "createdAt": "2020-07-30T16:39:58Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,23 +181,39 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder(configs);\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {\n+            userSpecifiedStatistics = true;\n+        }\n+        if (!userSpecifiedStatistics &&\n             RecordingLevel.forName((String) configs.get(METRICS_RECORDING_LEVEL_CONFIG)) == RecordingLevel.DEBUG) {\n \n-            isStatisticsRegistered = true;\n             // metrics recorder will clean up statistics object\n             final Statistics statistics = new Statistics();\n             userSpecifiedOptions.setStatistics(statistics);\n-            metricsRecorder.addStatistics(name, statistics);\n+        }\n+    }\n+\n+    private void addValueProvidersToMetricsRecorder(final Map<String, Object> configs) {\n+        final TableFormatConfig tableFormatConfig = userSpecifiedOptions.tableFormatConfig();\n+        final Statistics statistics = userSpecifiedStatistics ? null : userSpecifiedOptions.statistics();\n+        if (tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache) {\n+            final Cache cache = ((BlockBasedTableConfigWithAccessibleCache) tableFormatConfig).blockCache();\n+            metricsRecorder.addValueProviders(name, db, cache, statistics);\n+        } else {\n+            metricsRecorder.addValueProviders(name, db, null, statistics);\n+            log.warn(\"A table format configuration is used that does not expose the block cache. This means \" +\n+                \"that metrics that relate to the block cache may be wrong if the block cache is shared.\");\n         }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0afb35d8bba0d76adf9002bd9db14025cd0ca340"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEzMjU2Ng==", "bodyText": "Interesting... Should we add a Time argument to the constructor? It would be a minor amendment to the KIP.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r463132566", "createdAt": "2020-07-30T16:46:43Z", "author": {"login": "vvcephei"}, "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/processor/MockProcessorContext.java", "diffHunk": "@@ -227,7 +228,8 @@ public MockProcessorContext(final Properties config, final TaskId taskId, final\n         this.metrics = new StreamsMetricsImpl(\n             new Metrics(metricConfig),\n             threadId,\n-            streamsConfig.getString(StreamsConfig.BUILT_IN_METRICS_VERSION_CONFIG)\n+            streamsConfig.getString(StreamsConfig.BUILT_IN_METRICS_VERSION_CONFIG),\n+            Time.SYSTEM", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0afb35d8bba0d76adf9002bd9db14025cd0ca340"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4331821d84ecc8873f814cd691e9bb13b7762fe2", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/4331821d84ecc8873f814cd691e9bb13b7762fe2", "committedDate": "2020-07-31T13:46:51Z", "message": "Make warning regarding RocksDB's table configuration clearer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "34dac91f6249d809df5b366eaf82596dde3d5b3b", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/34dac91f6249d809df5b366eaf82596dde3d5b3b", "committedDate": "2020-07-31T13:50:02Z", "message": "Remove unused parameter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/91b3430b9db78b0cff834d6197f509f65a639dcd", "committedDate": "2020-08-10T20:15:57Z", "message": "Throw exception instead of log a warning"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1MjM4NjUx", "url": "https://github.com/apache/kafka/pull/9098#pullrequestreview-465238651", "createdAt": "2020-08-11T16:34:53Z", "commit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjozNDo1M1rOG_AB9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjozNDo1M1rOG_AB9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcxMzk3NQ==", "bodyText": "It seems like we would now be forbidding the use of PlainTableConfig. Is that intentional?", "url": "https://github.com/apache/kafka/pull/9098#discussion_r468713975", "createdAt": "2020-08-11T16:34:53Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -204,17 +204,17 @@ private void maybeSetUpStatistics(final Map<String, Object> configs) {\n         }\n     }\n \n-    private void addValueProvidersToMetricsRecorder(final Map<String, Object> configs) {\n+    private void addValueProvidersToMetricsRecorder() {\n         final TableFormatConfig tableFormatConfig = userSpecifiedOptions.tableFormatConfig();\n         final Statistics statistics = userSpecifiedStatistics ? null : userSpecifiedOptions.statistics();\n-        if (tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache) {\n-            final Cache cache = ((BlockBasedTableConfigWithAccessibleCache) tableFormatConfig).blockCache();\n-            metricsRecorder.addValueProviders(name, db, cache, statistics);\n-        } else {\n-            metricsRecorder.addValueProviders(name, db, null, statistics);\n-            log.warn(\"A table format configuration is used that does not expose the block cache. This means \" +\n-                \"that metrics that relate to the block cache may be wrong if the block cache is shared.\");\n-        }\n+        if (!(tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 25}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1MzE1ODM1", "url": "https://github.com/apache/kafka/pull/9098#pullrequestreview-465315835", "createdAt": "2020-08-11T18:18:55Z", "commit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxODoxODo1NlrOG_DwWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxODoxODo1NlrOG_DwWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NTAwMg==", "bodyText": "Could this ever be null actually? I think even in unit tests the DBOptions would contain stats?", "url": "https://github.com/apache/kafka/pull/9098#discussion_r468775002", "createdAt": "2020-08-11T18:18:56Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,26 +181,42 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder();\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 55}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ebab7af0bb7ea98af111aa626874f678d9fe3c56", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/ebab7af0bb7ea98af111aa626874f678d9fe3c56", "committedDate": "2020-08-11T19:41:48Z", "message": "Allow other table formats than block-based tables"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NDUzNzcw", "url": "https://github.com/apache/kafka/pull/9098#pullrequestreview-465453770", "createdAt": "2020-08-11T21:51:02Z", "commit": {"oid": "ebab7af0bb7ea98af111aa626874f678d9fe3c56"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c967a48033bcf92438e8fc419a6a8b4835ba665", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/5c967a48033bcf92438e8fc419a6a8b4835ba665", "committedDate": "2020-08-12T08:36:07Z", "message": "Improve statistics handling in metrics recorder"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MDA1OTA5", "url": "https://github.com/apache/kafka/pull/9098#pullrequestreview-466005909", "createdAt": "2020-08-12T15:03:23Z", "commit": {"oid": "5c967a48033bcf92438e8fc419a6a8b4835ba665"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTowMzoyM1rOG_lejA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTowMzoyM1rOG_lejA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMyNzUwMA==", "bodyText": "I think it's implied in addValueProviders that if any of the valueProviders' statistics are non-null, then they are all non-null, in which case, this makes sense as a guard. Still, it's kind of subtle.\nWhy not just put a guard inside the loop instead to continue or break if it turns out that valueProviders.statistics == null?", "url": "https://github.com/apache/kafka/pull/9098#discussion_r469327500", "createdAt": "2020-08-12T15:03:23Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorder.java", "diffHunk": "@@ -187,37 +206,39 @@ public void record(final long now) {\n         long bytesReadDuringCompaction = 0;\n         long numberOfOpenFiles = 0;\n         long numberOfFileErrors = 0;\n-        for (final DbAndCacheAndStatistics valueProviders : storeToValueProviders.values()) {\n-            bytesWrittenToDatabase += valueProviders.statistics.getAndResetTickerCount(TickerType.BYTES_WRITTEN);\n-            bytesReadFromDatabase += valueProviders.statistics.getAndResetTickerCount(TickerType.BYTES_READ);\n-            memtableBytesFlushed += valueProviders.statistics.getAndResetTickerCount(TickerType.FLUSH_WRITE_BYTES);\n-            memtableHits += valueProviders.statistics.getAndResetTickerCount(TickerType.MEMTABLE_HIT);\n-            memtableMisses += valueProviders.statistics.getAndResetTickerCount(TickerType.MEMTABLE_MISS);\n-            blockCacheDataHits += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_DATA_HIT);\n-            blockCacheDataMisses += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_DATA_MISS);\n-            blockCacheIndexHits += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_INDEX_HIT);\n-            blockCacheIndexMisses += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_INDEX_MISS);\n-            blockCacheFilterHits += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_FILTER_HIT);\n-            blockCacheFilterMisses += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_FILTER_MISS);\n-            writeStallDuration += valueProviders.statistics.getAndResetTickerCount(TickerType.STALL_MICROS);\n-            bytesWrittenDuringCompaction += valueProviders.statistics.getAndResetTickerCount(TickerType.COMPACT_WRITE_BYTES);\n-            bytesReadDuringCompaction += valueProviders.statistics.getAndResetTickerCount(TickerType.COMPACT_READ_BYTES);\n-            numberOfOpenFiles += valueProviders.statistics.getAndResetTickerCount(TickerType.NO_FILE_OPENS)\n-                - valueProviders.statistics.getAndResetTickerCount(TickerType.NO_FILE_CLOSES);\n-            numberOfFileErrors += valueProviders.statistics.getAndResetTickerCount(TickerType.NO_FILE_ERRORS);\n+        if (storeToValueProviders.values().stream().anyMatch(valueProviders -> valueProviders.statistics != null)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c967a48033bcf92438e8fc419a6a8b4835ba665"}, "originalPosition": 66}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb15c3a5bf91f9a46d6914739b617ca2291f52da", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/fb15c3a5bf91f9a46d6914739b617ca2291f52da", "committedDate": "2020-08-12T15:27:07Z", "message": "Change guard to avoid recording when statistics are null"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MDc1OTQy", "url": "https://github.com/apache/kafka/pull/9098#pullrequestreview-466075942", "createdAt": "2020-08-12T16:21:44Z", "commit": {"oid": "fb15c3a5bf91f9a46d6914739b617ca2291f52da"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 969, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}