{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMxMTA5NjEz", "number": 9676, "title": "KAFKA-10778: Fence appends after write failure", "bodyText": "", "createdAt": "2020-12-02T15:48:24Z", "url": "https://github.com/apache/kafka/pull/9676", "merged": true, "mergeCommit": {"oid": "bf55afecdab9fe00c9defcec04adb27856df93cc"}, "closed": true, "closedAt": "2021-01-06T18:06:57Z", "author": {"login": "tombentley"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdiQixHgH2gAyNTMxMTA5NjEzOmVjNmZiYzQyMDQzNTA1NDY4ODNlNWM2NjRlZDZmZmQ3NzEzMjdhM2U=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdtikYKAFqTU2Mjg4MDEyNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ec6fbc4204350546883e5c664ed6ffd771327a3e", "author": {"user": {"login": "tombentley", "name": "Tom Bentley"}}, "url": "https://github.com/apache/kafka/commit/ec6fbc4204350546883e5c664ed6ffd771327a3e", "committedDate": "2020-12-02T15:47:07Z", "message": "KAFKA-10778: Fence appends after write failure"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzMjYzMDM2", "url": "https://github.com/apache/kafka/pull/9676#pullrequestreview-543263036", "createdAt": "2020-12-02T21:45:51Z", "commit": {"oid": "ec6fbc4204350546883e5c664ed6ffd771327a3e"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMTo0NTo1MlrOH9vbig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMTo0Njo1M1rOH9vdhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDUwMjI4Mg==", "bodyText": "Perhaps we could move this to somewhere near the top? I don't think we get much benefit by delaying the check since duplicates would be a rare case. We probably don't want to have to trust the producer state anyway after an append failure.", "url": "https://github.com/apache/kafka/pull/9676#discussion_r534502282", "createdAt": "2020-12-02T21:45:52Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1219,6 +1219,9 @@ class Log(@volatile private var _dir: File,\n               appendInfo.logAppendTime = duplicate.timestamp\n               appendInfo.logStartOffset = logStartOffset\n             case None =>\n+              if (logDirFailureChannel.logDirIsFailed(parentDir)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec6fbc4204350546883e5c664ed6ffd771327a3e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDUwMjQ4Mg==", "bodyText": "Maybe isOffline or hasFailed?", "url": "https://github.com/apache/kafka/pull/9676#discussion_r534502482", "createdAt": "2020-12-02T21:46:17Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/LogDirFailureChannel.scala", "diffHunk": "@@ -49,6 +49,13 @@ class LogDirFailureChannel(logDirNum: Int) extends Logging {\n       offlineLogDirQueue.add(logDir)\n   }\n \n+  /*\n+   * Return whether the given log dir is offline.\n+   */\n+  def logDirIsFailed(logDir: String): Boolean = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec6fbc4204350546883e5c664ed6ffd771327a3e"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDUwMjc5MQ==", "bodyText": "nit: we can use assertThrows or intercept", "url": "https://github.com/apache/kafka/pull/9676#discussion_r534502791", "createdAt": "2020-12-02T21:46:53Z", "author": {"login": "hachikuji"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -2818,6 +2818,21 @@ class LogTest {\n       new SimpleRecord(RecordBatch.NO_TIMESTAMP, \"key\".getBytes, \"value\".getBytes)), leaderEpoch = 0)\n   }\n \n+  @Test\n+  def testAppendToLogInFailedLogDir(): Unit = {\n+    val log = createLog(logDir, LogConfig())\n+    log.appendAsLeader(TestUtils.singletonRecords(value = null), leaderEpoch = 0)\n+    assertEquals(0, readLog(log, 0, 4096).records.records.iterator.next().offset)\n+    log.logDirFailureChannel.maybeAddOfflineLogDir(logDir.getParent, \"Simulating failed log dir\", new IOException(\"Test failure\"))\n+    try {\n+      log.appendAsLeader(TestUtils.singletonRecords(value = null), leaderEpoch = 0)\n+      fail()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ec6fbc4204350546883e5c664ed6ffd771327a3e"}, "originalPosition": 12}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f9a63fac523f7f97828d20afb0ab88f79812606", "author": {"user": {"login": "tombentley", "name": "Tom Bentley"}}, "url": "https://github.com/apache/kafka/commit/8f9a63fac523f7f97828d20afb0ab88f79812606", "committedDate": "2020-12-03T09:47:51Z", "message": "Review comments + test failures"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "57e439ac0b04049a4690ec62dc63a836b96c42c3", "author": {"user": {"login": "tombentley", "name": "Tom Bentley"}}, "url": "https://github.com/apache/kafka/commit/57e439ac0b04049a4690ec62dc63a836b96c42c3", "committedDate": "2020-12-03T09:59:51Z", "message": "Move up"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ0NTA2ODgz", "url": "https://github.com/apache/kafka/pull/9676#pullrequestreview-544506883", "createdAt": "2020-12-03T22:30:44Z", "commit": {"oid": "8f9a63fac523f7f97828d20afb0ab88f79812606"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMjozMDo0NFrOH-3_Yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMjozMDo0NFrOH-3_Yw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY5MTEwNw==", "bodyText": "Maybe we can leave a more informative error message here? Sth like \"... dir has failed due to a previous IO exception\", just indicating it is not failed because of the current calling trace.", "url": "https://github.com/apache/kafka/pull/9676#discussion_r535691107", "createdAt": "2020-12-03T22:30:44Z", "author": {"login": "guozhangwang"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1219,6 +1219,9 @@ class Log(@volatile private var _dir: File,\n               appendInfo.logAppendTime = duplicate.timestamp\n               appendInfo.logStartOffset = logStartOffset\n             case None =>\n+              if (logDirFailureChannel.logDirIsOffline(parentDir)) {\n+                throw new KafkaStorageException(s\"The log dir $parentDir has failed.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f9a63fac523f7f97828d20afb0ab88f79812606"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22b7aa8964323d5cf278b8ed690043f464098354", "author": {"user": {"login": "tombentley", "name": "Tom Bentley"}}, "url": "https://github.com/apache/kafka/commit/22b7aa8964323d5cf278b8ed690043f464098354", "committedDate": "2020-12-04T09:49:15Z", "message": "Refine exception message"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NTAxNjYz", "url": "https://github.com/apache/kafka/pull/9676#pullrequestreview-547501663", "createdAt": "2020-12-08T18:15:45Z", "commit": {"oid": "22b7aa8964323d5cf278b8ed690043f464098354"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxODoxNTo0NlrOIBur4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxODoxODowNlrOIBu1QA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODY4NDM4Ng==", "bodyText": "Hmm.. In case there is an IOException on an append, we will release the lock and fail the log dir in maybeHandleIOException. There is a window for another append to sneak by. It looks like it should be possible to pull maybeHandleIOException into the locked section here since analyzeAndValidateRecords does not do any IO.", "url": "https://github.com/apache/kafka/pull/9676#discussion_r538684386", "createdAt": "2020-12-08T18:15:46Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1106,6 +1106,13 @@ class Log(@volatile private var _dir: File,\n         // they are valid, insert them in the log\n         lock synchronized {\n           checkIfMemoryMappedBufferClosed()\n+\n+          // check for offline log dir in case a retry following an IOException happens before the log dir", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "22b7aa8964323d5cf278b8ed690043f464098354"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODY4Njc4NA==", "bodyText": "I am not sure if it is really necessary, but since offline dirs are a rare situation, I'm wondering if makes sense to optimize for the common case to avoid the lookup. For example, maybe we could leave offlineLogDirs uninitialized until the first log dir failure.", "url": "https://github.com/apache/kafka/pull/9676#discussion_r538686784", "createdAt": "2020-12-08T18:18:06Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/LogDirFailureChannel.scala", "diffHunk": "@@ -49,6 +49,13 @@ class LogDirFailureChannel(logDirNum: Int) extends Logging {\n       offlineLogDirQueue.add(logDir)\n   }\n \n+  /*\n+   * Return whether the given log dir is offline.\n+   */\n+  def logDirIsOffline(logDir: String): Boolean = {\n+    offlineLogDirs.containsKey(logDir)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "22b7aa8964323d5cf278b8ed690043f464098354"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2f67357f7c913d8cdb32fe496c38489079c737c", "author": {"user": {"login": "tombentley", "name": "Tom Bentley"}}, "url": "https://github.com/apache/kafka/commit/f2f67357f7c913d8cdb32fe496c38489079c737c", "committedDate": "2020-12-09T16:18:13Z", "message": "Review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d7c7974a3249064b63991278403677ff8ba470b", "author": {"user": {"login": "tombentley", "name": "Tom Bentley"}}, "url": "https://github.com/apache/kafka/commit/8d7c7974a3249064b63991278403677ff8ba470b", "committedDate": "2020-12-10T09:22:29Z", "message": "Switch to a flag"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0MDcwMTI4", "url": "https://github.com/apache/kafka/pull/9676#pullrequestreview-554070128", "createdAt": "2020-12-16T20:46:23Z", "commit": {"oid": "8d7c7974a3249064b63991278403677ff8ba470b"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQyMDo0NjoyM1rOIHYb1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQyMDo0OToxNVrOIHYiNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDYxMTI4NQ==", "bodyText": "Seems more intuitive to move this check before the segment read. I don't think we can totally avoid race conditions with a failure in append since we don't have the lock here. Perhaps we could even move this check to maybeHandleIOException so that we handle all cases?", "url": "https://github.com/apache/kafka/pull/9676#discussion_r544611285", "createdAt": "2020-12-16T20:46:23Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1556,6 +1572,8 @@ class Log(@volatile private var _dir: File,\n           done = fetchDataInfo != null || segmentEntry == null\n         }\n \n+        checkForLogDirFailure()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d7c7974a3249064b63991278403677ff8ba470b"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDYxMjkxNw==", "bodyText": "Another way to trigger an IO exception is to rename the log file. This trick is used in testAppendToTransactionIndexFailure. Then we don't need to expose maybeHandleIOException for testing.", "url": "https://github.com/apache/kafka/pull/9676#discussion_r544612917", "createdAt": "2020-12-16T20:49:15Z", "author": {"login": "hachikuji"}, "path": "core/src/test/scala/unit/kafka/log/LogTest.scala", "diffHunk": "@@ -2818,6 +2818,22 @@ class LogTest {\n       new SimpleRecord(RecordBatch.NO_TIMESTAMP, \"key\".getBytes, \"value\".getBytes)), leaderEpoch = 0)\n   }\n \n+  @Test\n+  def testAppendToOrReadFromLogInFailedLogDir(): Unit = {\n+    val log = createLog(logDir, LogConfig())\n+    log.appendAsLeader(TestUtils.singletonRecords(value = null), leaderEpoch = 0)\n+    assertEquals(0, readLog(log, 0, 4096).records.records.iterator.next().offset)\n+    try {\n+      log.maybeHandleIOException(\"Simulating failed log dir\") {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d7c7974a3249064b63991278403677ff8ba470b"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89d8687389fc335f23150d5bbbec1a03ae0bbae9", "author": {"user": {"login": "tombentley", "name": "Tom Bentley"}}, "url": "https://github.com/apache/kafka/commit/89d8687389fc335f23150d5bbbec1a03ae0bbae9", "committedDate": "2020-12-17T14:20:45Z", "message": "Move checkForLogDirFailure() into maybeHandleIOException"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40f0f5a4a99e7d0be4a7fa843b40bb71002457a1", "author": {"user": {"login": "tombentley", "name": "Tom Bentley"}}, "url": "https://github.com/apache/kafka/commit/40f0f5a4a99e7d0be4a7fa843b40bb71002457a1", "committedDate": "2020-12-17T14:21:30Z", "message": "Don't expose log.maybeHandleIOException to test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxOTkwOTY0", "url": "https://github.com/apache/kafka/pull/9676#pullrequestreview-561990964", "createdAt": "2021-01-05T17:34:18Z", "commit": {"oid": "40f0f5a4a99e7d0be4a7fa843b40bb71002457a1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNzozNDoxOVrOIOgjXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNzozNDoxOVrOIOgjXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjA4NDMxOQ==", "bodyText": "Do we still need this since this check is in maybeHandleIOException?", "url": "https://github.com/apache/kafka/pull/9676#discussion_r552084319", "createdAt": "2021-01-05T17:34:19Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1093,19 +1097,25 @@ class Log(@volatile private var _dir: File,\n                      assignOffsets: Boolean,\n                      leaderEpoch: Int,\n                      ignoreRecordSize: Boolean): LogAppendInfo = {\n-    maybeHandleIOException(s\"Error while appending records to $topicPartition in dir ${dir.getParent}\") {\n-      val appendInfo = analyzeAndValidateRecords(records, origin, ignoreRecordSize)\n \n-      // return if we have no valid messages or if this is a duplicate of the last appended entry\n-      if (appendInfo.shallowCount == 0) appendInfo\n-      else {\n+    val appendInfo = analyzeAndValidateRecords(records, origin, ignoreRecordSize)\n \n-        // trim any invalid bytes or partial messages before appending it to the on-disk log\n-        var validRecords = trimInvalidBytes(records, appendInfo)\n+    // return if we have no valid messages or if this is a duplicate of the last appended entry\n+    if (appendInfo.shallowCount == 0) appendInfo\n+    else {\n \n-        // they are valid, insert them in the log\n-        lock synchronized {\n+      // trim any invalid bytes or partial messages before appending it to the on-disk log\n+      var validRecords = trimInvalidBytes(records, appendInfo)\n+\n+      // they are valid, insert them in the log\n+      lock synchronized {\n+        maybeHandleIOException(s\"Error while appending records to $topicPartition in dir ${dir.getParent}\") {\n           checkIfMemoryMappedBufferClosed()\n+\n+          // check for offline log dir in case a retry following an IOException happens before the log dir\n+          // is taken offline, which would result in inconsistent producer state\n+          checkForLogDirFailure()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40f0f5a4a99e7d0be4a7fa843b40bb71002457a1"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f66616a1e9832b8ab3f69911a180bff8d5e1339d", "author": {"user": {"login": "tombentley", "name": "Tom Bentley"}}, "url": "https://github.com/apache/kafka/commit/f66616a1e9832b8ab3f69911a180bff8d5e1339d", "committedDate": "2021-01-06T10:05:19Z", "message": "Review comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyODgwMTI1", "url": "https://github.com/apache/kafka/pull/9676#pullrequestreview-562880125", "createdAt": "2021-01-06T17:00:20Z", "commit": {"oid": "f66616a1e9832b8ab3f69911a180bff8d5e1339d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2516, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}