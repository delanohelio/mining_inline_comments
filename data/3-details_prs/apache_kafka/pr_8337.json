{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkyNzU4Mjg4", "number": 8337, "title": "KAFKA-6145: Pt. 5 Implement high availability assignment", "bodyText": "Adds a new TaskAssignor implementation, currently hidden behind an internal feature flag, that implements the high availability algorithm of KIP-441.\nThe main distinguishing feature of this new assignor is in assigning all active tasks to \"caught-up\" clients (if possible), and instead first assigning a new type of standby task, the \"warmup replica\", to clients who are not caught up.\nThe assignor has 4 main steps:\n\nstateful active task assignment: gets the initial/actual stateful assignment from StateConstrainedBalancedAssignor\nwarmup replica task assignment: gets the final/intended stateful assignment from BalancedAssignor, computes the movements between this and the above, and assigns warmup replicas where stateful tasks will ultimately end up\nstandby replica task assignment: distributes the num.standby replicas by choosing the next least loaded viable client (ie one that has no active, warmup, or standby version of this task already)\nstateless active task assignment: distributes the stateless tasks across client, attempts to balance the active task load across all clients  (task load == num tasks per thread)\n\nNote that step 3) is pretty simple, and loses some of the optimizations used by the StickyTaskAssignor. This is mostly to keep this PR small(er), and once merged we should refactor the task assignors to share parts of the standby assignment algorithm (and maybe stateless tasks too)", "createdAt": "2020-03-24T03:41:08Z", "url": "https://github.com/apache/kafka/pull/8337", "merged": true, "mergeCommit": {"oid": "2322bc0a6fdf8b26619b6aa9f09355d6c25e6298"}, "closed": true, "closedAt": "2020-04-02T18:36:04Z", "author": {"login": "ableegoldman"}, "timelineItems": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcQ6TLrgBqjMxNjE3MzIzNDA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcTexPpgFqTM4NTk2OTkzNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxNzMyNjUw", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-381732650", "createdAt": "2020-03-26T06:36:22Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwNjozNjoyM1rOF75BLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwNjozNjoyM1rOF75BLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODM0NDQ5NQ==", "bodyText": "Moved this to HighAvailabilityTaskAssignor", "url": "https://github.com/apache/kafka/pull/8337#discussion_r398344495", "createdAt": "2020-03-26T06:36:23Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -858,42 +811,6 @@ private boolean populateClientStatesMap(final Map<UUID, ClientState> clientState\n         return taskEndOffsetSums;\n     }\n \n-    /**\n-     * Rankings are computed as follows, with lower being more caught up:\n-     *      Rank -1: active running task\n-     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n-     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n-     *      Rank 1+: all other tasks are ranked according to their actual total lag\n-     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag\n-     */\n-    static Map<TaskId, SortedSet<RankedClient<UUID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 148}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxNzMyODE2", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-381732816", "createdAt": "2020-03-26T06:36:48Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwNjozNjo0OFrOF75B3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwNjozNjo0OFrOF75B3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODM0NDY2OQ==", "bodyText": "Moved to HighAvailabilityTaskAssignor", "url": "https://github.com/apache/kafka/pull/8337#discussion_r398344669", "createdAt": "2020-03-26T06:36:48Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -146,53 +144,6 @@ public String toString() {\n         }\n     }\n \n-    public static class RankedClient<ID extends Comparable<? super ID>> implements Comparable<RankedClient<ID>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxNzM1NjM0", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-381735634", "createdAt": "2020-03-26T06:44:44Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwNjo0NDo0NFrOF75LYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwNjo0NDo0NFrOF75LYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODM0NzEwNw==", "bodyText": "Ultimately, I think we can and should refactor the standby task assignment out of StickyTaskAssignor and reuse the same strategy. But for now, I just put in this \"good-enough\" standby assignment approach so we can get the basic structure of the overall assignment algorithm down first.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r398347107", "createdAt": "2020-03-26T06:44:44Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+            new DefaultBalancedAssignor<ID>().assign(\n+                sortedClients,\n+                statefulTasks,\n+                clientsToNumberOfThreads,\n+                configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements = getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 127}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyNTY1MTU5", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-382565159", "createdAt": "2020-03-27T03:53:30Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwMzo1MzozMFrOF8iUiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwMzo1MzozMFrOF8iUiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTAyMTE5NQ==", "bodyText": "None of these tests are removed, just moved to HighAvailabilityTaskAssignorTest", "url": "https://github.com/apache/kafka/pull/8337#discussion_r399021195", "createdAt": "2020-03-27T03:53:30Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java", "diffHunk": "@@ -1837,126 +1829,6 @@ public void shouldSetAdminClientTimeout() {\n         assertThat(assignorConfiguration.getAdminClientTimeout(), is(2 * 60 * 1000));\n     }\n \n-    @Test\n-    public void shouldRankPreviousClientAboveEquallyCaughtUpClient() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyNDQyMTI3", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-382442127", "createdAt": "2020-03-26T21:42:43Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQyMTo0Mjo0M1rOF8bkeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQyMTo1ODozOFrOF8cAjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkxMDU4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (lagComputationSuccessful && highAvailabilityEnabled) {\n          \n          \n            \n                        taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n          \n          \n            \n                    } else {\n          \n          \n            \n                        taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n          \n          \n            \n                        if (highAvailabilityEnabled) {\n          \n          \n            \n                            // Once high availability is permanently enabled, this will be the default behavior of StickyTaskAssignor\n          \n          \n            \n                            ((StickyTaskAssignor) taskAssignor).preservePreviousTaskAssignment();\n          \n          \n            \n                        }\n          \n          \n            \n                    }\n          \n          \n            \n                    if (highAvailabilityEnabled) {\n          \n          \n            \n                        taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n          \n          \n            \n                    } else {\n          \n          \n            \n                        taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n          \n          \n            \n                        if (!lagComputationSuccessful) {\n          \n          \n            \n                            ((StickyTaskAssignor) taskAssignor).preservePreviousTaskAssignment();\n          \n          \n            \n                        }\n          \n          \n            \n                    }", "url": "https://github.com/apache/kafka/pull/8337#discussion_r398910586", "createdAt": "2020-03-26T21:42:43Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,23 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor taskAssignor;\n+        if (lagComputationSuccessful && highAvailabilityEnabled) {\n+            taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n+        } else {\n+            taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n+            if (highAvailabilityEnabled) {\n+                // Once high availability is permanently enabled, this will be the default behavior of StickyTaskAssignor\n+                ((StickyTaskAssignor) taskAssignor).preservePreviousTaskAssignment();\n+            }\n         }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkxNTQ3Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public static final String HIGH_AVAILABILITY_FLAG_CONFIG = \"high.availability.enabled\";\n          \n          \n            \n                public static final String HIGH_AVAILABILITY_FLAG_CONFIG = \"internal.high.availability.enabled\";\n          \n      \n    \n    \n  \n\nTo document that it's undocumented ;)", "url": "https://github.com/apache/kafka/pull/8337#discussion_r398915477", "createdAt": "2020-03-26T21:53:12Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/AssignorConfiguration.java", "diffHunk": "@@ -38,6 +38,9 @@\n import static org.apache.kafka.streams.processor.internals.assignment.StreamsAssignmentProtocolVersions.LATEST_SUPPORTED_VERSION;\n \n public final class AssignorConfiguration {\n+    public static final String HIGH_AVAILABILITY_FLAG_CONFIG = \"high.availability.enabled\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkxNjA1OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (configs.containsKey(HIGH_AVAILABILITY_FLAG_CONFIG)) {\n          \n          \n            \n                        highAvailabilityEnabled = streamsConfig.getBoolean(HIGH_AVAILABILITY_FLAG_CONFIG);\n          \n          \n            \n                    } else {\n          \n          \n            \n                        highAvailabilityEnabled = false;\n          \n          \n            \n                    }\n          \n          \n            \n            highAvailabilityEnabled = configs.containsKey(HIGH_AVAILABILITY_FLAG_CONFIG) && streamsConfig.getBoolean(HIGH_AVAILABILITY_FLAG_CONFIG);\n          \n      \n    \n    \n  \n\nCouldn't resist.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r398916058", "createdAt": "2020-03-26T21:54:27Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/AssignorConfiguration.java", "diffHunk": "@@ -154,6 +157,12 @@ public AssignorConfiguration(final Map<String, ?> configs) {\n         adminClientTimeout = streamsConfig.getInt(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG);\n \n         copartitionedTopicsEnforcer = new CopartitionedTopicsEnforcer(logPrefix);\n+\n+        if (configs.containsKey(HIGH_AVAILABILITY_FLAG_CONFIG)) {\n+            highAvailabilityEnabled = streamsConfig.getBoolean(HIGH_AVAILABILITY_FLAG_CONFIG);\n+        } else {\n+            highAvailabilityEnabled = false;\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkxNzc3Mg==", "bodyText": "Oof, this implies an ordering dependency in how you call these methods. Should we enforce that ordering? Or should we push this logic up into the ownedPartitions block, if that's the only place where we might learn that we were previously wrong about which tasks were active?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r398917772", "createdAt": "2020-03-26T21:58:38Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -154,9 +160,21 @@ public int activeTaskCount() {\n         return activeTasks.size();\n     }\n \n+    void addPreviousActiveTask(final TaskId task) {\n+        prevActiveTasks.add(task);\n+        prevAssignedTasks.add(task);\n+    }\n+\n+    void addPreviousStandbyTask(final TaskId task) {\n+        prevStandbyTasks.add(task);\n+        prevAssignedTasks.add(task);\n+    }\n+\n     public void addPreviousActiveTasks(final Set<TaskId> prevTasks) {\n         prevActiveTasks.addAll(prevTasks);\n         prevAssignedTasks.addAll(prevTasks);\n+        // We need to remove from prevStandbyTasks as we may have initially added the task as a standby, before\n+        // learning that it was in fact an active (eg from encoded ownedPartitions)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 31}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg0MjkyODYw", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-384292860", "createdAt": "2020-03-30T23:02:46Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMzowMjo0NlrOF9_YrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMzozMjo1OVrOF-AAag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU0NTk2NA==", "bodyText": "I assume this is because of private static final TaskId task0_0, why not just call it TASK_0_0, etc?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400545964", "createdAt": "2020-03-30T23:02:46Z", "author": {"login": "vvcephei"}, "path": "checkstyle/suppressions.xml", "diffHunk": "@@ -208,8 +208,8 @@\n     <suppress checks=\"MethodLength\"\n               files=\"RocksDBWindowStoreTest.java\"/>\n \n-    <suppress checks=\"MemberName\"\n-              files=\"StreamsPartitionAssignorTest.java\"/>\n+    <suppress checks=\"MemberName|ConstantName\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU0NzQzMg==", "bodyText": "Thanks, this block looks more understandable to me now.\nNew question: previously, we would set the sticky assignor to preserve previous task assignments if lag computation weren't successful, but now we only do that if we're falling back from the HA task assignor. Did you mean to also include the \"if (!lagComputationSuccessful){ preserve previous }` logic here?\nIt seems a little hairy, and it does seem clear that we should refactor it, but I'm ok with doing that in a follow-up PR, if you are.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400547432", "createdAt": "2020-03-30T23:07:05Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,25 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor<UUID> taskAssignor;\n+        if (highAvailabilityEnabled) {\n+            if (lagComputationSuccessful) {\n+                taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks,\n+                    assignmentConfigs);\n+            } else {\n+                taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n+                ((StickyTaskAssignor) taskAssignor).preservePreviousTaskAssignment();\n+            }\n+        } else {\n+            taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU1NjEzOA==", "bodyText": "I think I might be missing something... The standbyTaskAssignment is empty here, and also on Line 130.\nWhy do we need to add it to these collections?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400556138", "createdAt": "2020-03-30T23:32:59Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 125}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg0MzU4MTA0", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-384358104", "createdAt": "2020-03-31T02:17:39Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjoxNzozOVrOF-C3FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwNDo0NDo0OVrOF-FJGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwMjkwMQ==", "bodyText": "This is a bit suspicious... If we're polling the queue, we should just loop until the queue is empty, not iterate over another another collection we happen to know has the same number of elements.\nMore specifically, poll might return null, but offer throws an NPE if client is null.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400602901", "createdAt": "2020-03-31T02:17:39Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNDQ3Mw==", "bodyText": "Should this be .equals?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400604473", "createdAt": "2020-03-31T02:23:47Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNjYyNw==", "bodyText": "Please avoid raw types, even when you don't need the type bound.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    for (final RankedClient rankedClient : rankedClients) {\n          \n          \n            \n                    for (final RankedClient<ID> rankedClient : rankedClients) {", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400606627", "createdAt": "2020-03-31T02:32:04Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNzQ2MQ==", "bodyText": "I'm starting to lose track of the details... What is the impact of setting these tasks' ranks as -1 instead of 0?\nIf memory serves, we proposed to just treat all caught-up clients as the same for the purpose of assignments.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400607461", "createdAt": "2020-03-31T02:35:28Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 302}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwODc2OA==", "bodyText": "I feel like I might be missing something, but what's the advantage of creating a method reference and passing it in so that we can invoke it with the object that has that method? I.e., why not just:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        final Set<TaskId> activeTasks = new HashSet<>(activeTaskSet.apply(state));\n          \n          \n            \n                        final Set<TaskId> activeTasks = new HashSet<>(state.prevActiveTasks());\n          \n      \n    \n    \n  \n\nAnd then we don't need the third parameter?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400608768", "createdAt": "2020-03-31T02:40:06Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;\n+                } else if (taskLag == UNKNOWN_OFFSET_SUM) {\n+                    clientRank = 1L;\n+                } else if (taskLag <= acceptableRecoveryLag) {\n+                    clientRank = 0L;\n+                } else {\n+                    clientRank = taskLag;\n+                }\n+                rankedClientCandidates.add(new RankedClient<>(clientId, clientRank));\n+            }\n+        }\n+        log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n+\n+        return statefulTasksToRankedCandidates;\n+    }\n+\n+    /**\n+     * Compute the balance factor as the difference in stateful active task count per thread between the most and\n+     * least loaded clients\n+     */\n+    static int computeBalanceFactor(final Collection<ClientState> clientStates,\n+                                    final Set<TaskId> statefulTasks,\n+                                    final Function<ClientState, Set<TaskId>> activeTaskSet) {\n+        int minActiveStatefulTasksPerThreadCount = Integer.MAX_VALUE;\n+        int maxActiveStatefulTasksPerThreadCount = 0;\n+\n+        for (final ClientState state : clientStates) {\n+            final Set<TaskId> activeTasks = new HashSet<>(activeTaskSet.apply(state));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 329}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwOTk2Mw==", "bodyText": "If I read this right, the current method doesn't actually consider the new proposed assignment. Are we mutating some fields, or could this method actually be invoked at the beginning of the assignment to gate if the current assignment is \"good enough\"?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400609963", "createdAt": "2020-03-31T02:44:45Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;\n+                } else if (taskLag == UNKNOWN_OFFSET_SUM) {\n+                    clientRank = 1L;\n+                } else if (taskLag <= acceptableRecoveryLag) {\n+                    clientRank = 0L;\n+                } else {\n+                    clientRank = taskLag;\n+                }\n+                rankedClientCandidates.add(new RankedClient<>(clientId, clientRank));\n+            }\n+        }\n+        log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n+\n+        return statefulTasksToRankedCandidates;\n+    }\n+\n+    /**\n+     * Compute the balance factor as the difference in stateful active task count per thread between the most and\n+     * least loaded clients\n+     */\n+    static int computeBalanceFactor(final Collection<ClientState> clientStates,\n+                                    final Set<TaskId> statefulTasks,\n+                                    final Function<ClientState, Set<TaskId>> activeTaskSet) {\n+        int minActiveStatefulTasksPerThreadCount = Integer.MAX_VALUE;\n+        int maxActiveStatefulTasksPerThreadCount = 0;\n+\n+        for (final ClientState state : clientStates) {\n+            final Set<TaskId> activeTasks = new HashSet<>(activeTaskSet.apply(state));\n+            activeTasks.retainAll(statefulTasks);\n+            final int taskPerThreadCount = activeTasks.size() / state.capacity();\n+            if (taskPerThreadCount < minActiveStatefulTasksPerThreadCount) {\n+                minActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+            if (taskPerThreadCount > maxActiveStatefulTasksPerThreadCount) {\n+                maxActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+        }\n+\n+        return maxActiveStatefulTasksPerThreadCount - minActiveStatefulTasksPerThreadCount;\n+    }\n+\n+    /**\n+     * Determines whether to use the new proposed assignment or just return the group's previous assignment. The", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 344}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYxMjkwOA==", "bodyText": "I can't understand why there's no warning about this, but it looks like clientId should always use .equals instead of ==.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400612908", "createdAt": "2020-03-31T02:55:37Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;\n+                } else if (taskLag == UNKNOWN_OFFSET_SUM) {\n+                    clientRank = 1L;\n+                } else if (taskLag <= acceptableRecoveryLag) {\n+                    clientRank = 0L;\n+                } else {\n+                    clientRank = taskLag;\n+                }\n+                rankedClientCandidates.add(new RankedClient<>(clientId, clientRank));\n+            }\n+        }\n+        log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n+\n+        return statefulTasksToRankedCandidates;\n+    }\n+\n+    /**\n+     * Compute the balance factor as the difference in stateful active task count per thread between the most and\n+     * least loaded clients\n+     */\n+    static int computeBalanceFactor(final Collection<ClientState> clientStates,\n+                                    final Set<TaskId> statefulTasks,\n+                                    final Function<ClientState, Set<TaskId>> activeTaskSet) {\n+        int minActiveStatefulTasksPerThreadCount = Integer.MAX_VALUE;\n+        int maxActiveStatefulTasksPerThreadCount = 0;\n+\n+        for (final ClientState state : clientStates) {\n+            final Set<TaskId> activeTasks = new HashSet<>(activeTaskSet.apply(state));\n+            activeTasks.retainAll(statefulTasks);\n+            final int taskPerThreadCount = activeTasks.size() / state.capacity();\n+            if (taskPerThreadCount < minActiveStatefulTasksPerThreadCount) {\n+                minActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+            if (taskPerThreadCount > maxActiveStatefulTasksPerThreadCount) {\n+                maxActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+        }\n+\n+        return maxActiveStatefulTasksPerThreadCount - minActiveStatefulTasksPerThreadCount;\n+    }\n+\n+    /**\n+     * Determines whether to use the new proposed assignment or just return the group's previous assignment. The\n+     * previous assignment will be chosen and returned iff all of the following are true:\n+     *   1) it satisfies the state constraint, ie all tasks with caught up clients are assigned to one of those clients\n+     *   2) it satisfies the balance factor\n+     *   3) there are no unassigned tasks (eg due to a client that dropped out of the group)\n+     */\n+    private boolean shouldUsePreviousAssignment() {\n+        if (previousAssignmentIsValid()) {\n+            final int previousAssignmentBalanceFactor =\n+                computeBalanceFactor(clientStates.values(), statefulTasks, ClientState::prevActiveTasks);\n+            return previousAssignmentBalanceFactor <= configs.balanceFactor;\n+        } else {\n+            return false;\n+        }\n+    }\n+\n+    private Map<ID, List<TaskId>> initializeEmptyTaskAssignmentMap() {\n+        return sortedClients.stream().collect(Collectors.toMap(id -> id, id -> new ArrayList<>()));\n+    }\n+\n+    private void assignActiveTasksToClients(final Map<ID, List<TaskId>> activeTasks) {\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID clientId = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            state.assignActiveTasks(activeTasks.get(clientId));\n+        }\n+    }\n+\n+    private void assignStandbyTasksToClients(final Map<ID, List<TaskId>> standbyTasks) {\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID clientId = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            state.assignStandbyTasks(standbyTasks.get(clientId));\n+        }\n+    }\n+\n+    private void assignPreviousTasksToClientStates() {\n+        for (final ClientState clientState : clientStates.values()) {\n+            clientState.assignActiveTasks(clientState.prevActiveTasks());\n+            clientState.assignStandbyTasks(clientState.prevStandbyTasks());\n+        }\n+    }\n+\n+    private PriorityQueue<ID> getClientPriorityQueueByTaskLoad(final List<Map<ID, List<TaskId>>> taskLoadsByClient) {\n+        final PriorityQueue<ID> queue = new PriorityQueue<>(\n+            (client, other) -> {\n+                final int clientTasksPerThread = tasksPerThread(client, taskLoadsByClient);\n+                final int otherTasksPerThread = tasksPerThread(other, taskLoadsByClient);\n+                if (clientTasksPerThread != otherTasksPerThread) {\n+                    return clientTasksPerThread - otherTasksPerThread;\n+                } else {\n+                    return client.compareTo(other);\n+                }\n+            });\n+\n+        queue.addAll(sortedClients);\n+        return queue;\n+    }\n+\n+    private int tasksPerThread(final ID client, final List<Map<ID, List<TaskId>>> taskLoadsByClient) {\n+        double numTasks = 0;\n+        for (final Map<ID, List<TaskId>> assignment : taskLoadsByClient) {\n+            numTasks += assignment.get(client).size();\n+        }\n+        return (int) Math.ceil(numTasks / clientsToNumberOfThreads.get(client));\n+    }\n+\n+    static class RankedClient<ID extends Comparable<? super ID>> implements Comparable<RankedClient<ID>> {\n+        private final ID clientId;\n+        private final long rank;\n+\n+        RankedClient(final ID clientId, final long rank) {\n+            this.clientId = clientId;\n+            this.rank = rank;\n+        }\n+\n+        ID clientId() {\n+            return clientId;\n+        }\n+\n+        long rank() {\n+            return rank;\n+        }\n+\n+        @Override\n+        public int compareTo(final RankedClient<ID> clientIdAndLag) {\n+            if (rank < clientIdAndLag.rank) {\n+                return -1;\n+            } else if (rank > clientIdAndLag.rank) {\n+                return 1;\n+            } else {\n+                return clientId.compareTo(clientIdAndLag.clientId);\n+            }\n+        }\n+\n+        @Override\n+        public boolean equals(final Object o) {\n+            if (this == o) {\n+                return true;\n+            } else if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final RankedClient other = (RankedClient) o;\n+            return clientId == other.clientId() && rank == other.rank();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 447}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYxMzkzNA==", "bodyText": "Here also. It looks like you used the IDE code generator to make these, but they don't seem to be correct. Perhaps there's a configuration wrong somewhere?\nHere's what mine produces:\n        @Override\n        public boolean equals(final Object o) {\n            if (this == o) return true;\n            if (o == null || getClass() != o.getClass()) return false;\n            final Movement<?> movement = (Movement<?>) o;\n            return Objects.equals(task, movement.task) &&\n                Objects.equals(source, movement.source) &&\n                Objects.equals(destination, movement.destination);\n        }", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400613934", "createdAt": "2020-03-31T02:59:24Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;\n+                } else if (taskLag == UNKNOWN_OFFSET_SUM) {\n+                    clientRank = 1L;\n+                } else if (taskLag <= acceptableRecoveryLag) {\n+                    clientRank = 0L;\n+                } else {\n+                    clientRank = taskLag;\n+                }\n+                rankedClientCandidates.add(new RankedClient<>(clientId, clientRank));\n+            }\n+        }\n+        log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n+\n+        return statefulTasksToRankedCandidates;\n+    }\n+\n+    /**\n+     * Compute the balance factor as the difference in stateful active task count per thread between the most and\n+     * least loaded clients\n+     */\n+    static int computeBalanceFactor(final Collection<ClientState> clientStates,\n+                                    final Set<TaskId> statefulTasks,\n+                                    final Function<ClientState, Set<TaskId>> activeTaskSet) {\n+        int minActiveStatefulTasksPerThreadCount = Integer.MAX_VALUE;\n+        int maxActiveStatefulTasksPerThreadCount = 0;\n+\n+        for (final ClientState state : clientStates) {\n+            final Set<TaskId> activeTasks = new HashSet<>(activeTaskSet.apply(state));\n+            activeTasks.retainAll(statefulTasks);\n+            final int taskPerThreadCount = activeTasks.size() / state.capacity();\n+            if (taskPerThreadCount < minActiveStatefulTasksPerThreadCount) {\n+                minActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+            if (taskPerThreadCount > maxActiveStatefulTasksPerThreadCount) {\n+                maxActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+        }\n+\n+        return maxActiveStatefulTasksPerThreadCount - minActiveStatefulTasksPerThreadCount;\n+    }\n+\n+    /**\n+     * Determines whether to use the new proposed assignment or just return the group's previous assignment. The\n+     * previous assignment will be chosen and returned iff all of the following are true:\n+     *   1) it satisfies the state constraint, ie all tasks with caught up clients are assigned to one of those clients\n+     *   2) it satisfies the balance factor\n+     *   3) there are no unassigned tasks (eg due to a client that dropped out of the group)\n+     */\n+    private boolean shouldUsePreviousAssignment() {\n+        if (previousAssignmentIsValid()) {\n+            final int previousAssignmentBalanceFactor =\n+                computeBalanceFactor(clientStates.values(), statefulTasks, ClientState::prevActiveTasks);\n+            return previousAssignmentBalanceFactor <= configs.balanceFactor;\n+        } else {\n+            return false;\n+        }\n+    }\n+\n+    private Map<ID, List<TaskId>> initializeEmptyTaskAssignmentMap() {\n+        return sortedClients.stream().collect(Collectors.toMap(id -> id, id -> new ArrayList<>()));\n+    }\n+\n+    private void assignActiveTasksToClients(final Map<ID, List<TaskId>> activeTasks) {\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID clientId = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            state.assignActiveTasks(activeTasks.get(clientId));\n+        }\n+    }\n+\n+    private void assignStandbyTasksToClients(final Map<ID, List<TaskId>> standbyTasks) {\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID clientId = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            state.assignStandbyTasks(standbyTasks.get(clientId));\n+        }\n+    }\n+\n+    private void assignPreviousTasksToClientStates() {\n+        for (final ClientState clientState : clientStates.values()) {\n+            clientState.assignActiveTasks(clientState.prevActiveTasks());\n+            clientState.assignStandbyTasks(clientState.prevStandbyTasks());\n+        }\n+    }\n+\n+    private PriorityQueue<ID> getClientPriorityQueueByTaskLoad(final List<Map<ID, List<TaskId>>> taskLoadsByClient) {\n+        final PriorityQueue<ID> queue = new PriorityQueue<>(\n+            (client, other) -> {\n+                final int clientTasksPerThread = tasksPerThread(client, taskLoadsByClient);\n+                final int otherTasksPerThread = tasksPerThread(other, taskLoadsByClient);\n+                if (clientTasksPerThread != otherTasksPerThread) {\n+                    return clientTasksPerThread - otherTasksPerThread;\n+                } else {\n+                    return client.compareTo(other);\n+                }\n+            });\n+\n+        queue.addAll(sortedClients);\n+        return queue;\n+    }\n+\n+    private int tasksPerThread(final ID client, final List<Map<ID, List<TaskId>>> taskLoadsByClient) {\n+        double numTasks = 0;\n+        for (final Map<ID, List<TaskId>> assignment : taskLoadsByClient) {\n+            numTasks += assignment.get(client).size();\n+        }\n+        return (int) Math.ceil(numTasks / clientsToNumberOfThreads.get(client));\n+    }\n+\n+    static class RankedClient<ID extends Comparable<? super ID>> implements Comparable<RankedClient<ID>> {\n+        private final ID clientId;\n+        private final long rank;\n+\n+        RankedClient(final ID clientId, final long rank) {\n+            this.clientId = clientId;\n+            this.rank = rank;\n+        }\n+\n+        ID clientId() {\n+            return clientId;\n+        }\n+\n+        long rank() {\n+            return rank;\n+        }\n+\n+        @Override\n+        public int compareTo(final RankedClient<ID> clientIdAndLag) {\n+            if (rank < clientIdAndLag.rank) {\n+                return -1;\n+            } else if (rank > clientIdAndLag.rank) {\n+                return 1;\n+            } else {\n+                return clientId.compareTo(clientIdAndLag.clientId);\n+            }\n+        }\n+\n+        @Override\n+        public boolean equals(final Object o) {\n+            if (this == o) {\n+                return true;\n+            } else if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final RankedClient other = (RankedClient) o;\n+            return clientId == other.clientId() && rank == other.rank();\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(rank, clientId);\n+        }\n+    }\n+\n+    static class Movement<ID> {\n+        final TaskId task;\n+        final ID source;\n+        final ID destination;\n+\n+        Movement(final TaskId task, final ID source, final ID destination) {\n+            this.task = task;\n+            this.source = source;\n+            this.destination = destination;\n+        }\n+\n+        @Override\n+        public boolean equals(final Object o) {\n+            if (this == o) {\n+                return true;\n+            } else if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final Movement other = (Movement) o;\n+            return task == other.task && source == other.source && destination == other.destination;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 475}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYxNzEzNg==", "bodyText": "Just leaving a breadcrumb for other reviewers, these are just testing the behavior of the static method buildClientRankingsByTask, which has moved to HighAvailabilityTaskAssignor.\nThis probably indicates that the method (and RankedClient as well IMHO) should be moved to a top-level class and not be nested inside the assignor, but I don't feel strongly enough to insist on it at the moment.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400617136", "createdAt": "2020-03-31T03:11:16Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java", "diffHunk": "@@ -1837,126 +1829,6 @@ public void shouldSetAdminClientTimeout() {\n         assertThat(assignorConfiguration.getAdminClientTimeout(), is(2 * 60 * 1000));\n     }\n \n-    @Test\n-    public void shouldRankPreviousClientAboveEquallyCaughtUpClient() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTAyMTE5NQ=="}, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYxODA5MA==", "bodyText": "Should this class be parameterized to run all tests both with and without HA?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400618090", "createdAt": "2020-03-31T03:14:49Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java", "diffHunk": "@@ -2011,7 +1883,7 @@ public void shouldReturnAllActiveTasksToPreviousOwnerRegardlessOfBalanceIfEndOff\n         createMockTaskManager(allTasks, emptyTasks);\n         adminClient = EasyMock.createMock(AdminClient.class);\n         expect(adminClient.listOffsets(anyObject())).andThrow(new StreamsException(\"Should be handled\"));\n-        configureDefaultPartitionAssignor();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYyMDQxMw==", "bodyText": "This can be a local variable (and should be, to avoid mistakes in the future)", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400620413", "createdAt": "2020-03-31T03:23:47Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignorTest.java", "diffHunk": "@@ -0,0 +1,732 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptySet;\n+import static java.util.Collections.singleton;\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.common.utils.Utils.mkSortedSet;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.buildClientRankingsByTask;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.computeBalanceFactor;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.getMovements;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.replay;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.SortedSet;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.Movement;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.RankedClient;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+\n+public class HighAvailabilityTaskAssignorTest {\n+    private long acceptableRecoveryLag = 100L;\n+    private int balanceFactor = 1;\n+    private int maxWarmupReplicas = 2;\n+    private int numStandbyReplicas = 0;\n+    private long probingRebalanceInterval = 60 * 1000L;\n+\n+    private AssignmentConfigs configs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYyMjYwOA==", "bodyText": "Ok, now, this variable name is just too far :)\nDo you mind removing that exclusion and just using ALL_CAPS style for constants?\n(and it seems like this should have been named CLIENT_1_ID or something?)", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400622608", "createdAt": "2020-03-31T03:32:40Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignorTest.java", "diffHunk": "@@ -0,0 +1,732 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptySet;\n+import static java.util.Collections.singleton;\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.common.utils.Utils.mkSortedSet;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.buildClientRankingsByTask;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.computeBalanceFactor;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.getMovements;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.replay;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.SortedSet;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.Movement;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.RankedClient;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+\n+public class HighAvailabilityTaskAssignorTest {\n+    private long acceptableRecoveryLag = 100L;\n+    private int balanceFactor = 1;\n+    private int maxWarmupReplicas = 2;\n+    private int numStandbyReplicas = 0;\n+    private long probingRebalanceInterval = 60 * 1000L;\n+\n+    private AssignmentConfigs configs;\n+    private Map<String, ClientState> clientStates = new HashMap<>();\n+    private Set<TaskId> allTasks = new HashSet<>();\n+    private Set<TaskId> statefulTasks = new HashSet<>();\n+\n+    private static final TaskId task0_0 = new TaskId(0, 0);\n+    private static final TaskId task0_1 = new TaskId(0, 1);\n+    private static final TaskId task0_2 = new TaskId(0, 2);\n+    private static final TaskId task0_3 = new TaskId(0, 3);\n+    private static final TaskId task1_0 = new TaskId(1, 0);\n+    private static final TaskId task1_1 = new TaskId(1, 1);\n+    private static final TaskId task1_2 = new TaskId(1, 2);\n+    private static final TaskId task1_3 = new TaskId(1, 3);\n+    private static final TaskId task2_0 = new TaskId(2, 0);\n+    private static final TaskId task2_1 = new TaskId(2, 1);\n+    private static final TaskId task2_3 = new TaskId(2, 3);\n+\n+    private static final String String1 = \"client1\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYyMzI5Mw==", "bodyText": "Oh, also, I think if you fix the == should be .equals comments above, you should be able to use UUIDs for the client ids, which would be good because that's what Streams is going to do, right?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400623293", "createdAt": "2020-03-31T03:35:25Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignorTest.java", "diffHunk": "@@ -0,0 +1,732 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptySet;\n+import static java.util.Collections.singleton;\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.common.utils.Utils.mkSortedSet;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.buildClientRankingsByTask;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.computeBalanceFactor;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.getMovements;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.replay;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.SortedSet;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.Movement;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.RankedClient;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+\n+public class HighAvailabilityTaskAssignorTest {\n+    private long acceptableRecoveryLag = 100L;\n+    private int balanceFactor = 1;\n+    private int maxWarmupReplicas = 2;\n+    private int numStandbyReplicas = 0;\n+    private long probingRebalanceInterval = 60 * 1000L;\n+\n+    private AssignmentConfigs configs;\n+    private Map<String, ClientState> clientStates = new HashMap<>();\n+    private Set<TaskId> allTasks = new HashSet<>();\n+    private Set<TaskId> statefulTasks = new HashSet<>();\n+\n+    private static final TaskId task0_0 = new TaskId(0, 0);\n+    private static final TaskId task0_1 = new TaskId(0, 1);\n+    private static final TaskId task0_2 = new TaskId(0, 2);\n+    private static final TaskId task0_3 = new TaskId(0, 3);\n+    private static final TaskId task1_0 = new TaskId(1, 0);\n+    private static final TaskId task1_1 = new TaskId(1, 1);\n+    private static final TaskId task1_2 = new TaskId(1, 2);\n+    private static final TaskId task1_3 = new TaskId(1, 3);\n+    private static final TaskId task2_0 = new TaskId(2, 0);\n+    private static final TaskId task2_1 = new TaskId(2, 1);\n+    private static final TaskId task2_3 = new TaskId(2, 3);\n+\n+    private static final String String1 = \"client1\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYyMjYwOA=="}, "originalCommit": null, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYzOTk0NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void shouldAssignStandbyReplicasInAdditionToWarmupReplicas() {\n          \n          \n            \n                public void shouldReUseWarmupReplicasForStandbyReplicas() {\n          \n      \n    \n    \n  \n\nJust a name change suggestion. The behavior in the test is what I was expecting, but the method name led me to believe that we were basically doubling up on replicas (ie we'd get three copies of the replica: an active, a warmup, and a standby).", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400639944", "createdAt": "2020-03-31T04:43:28Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignorTest.java", "diffHunk": "@@ -0,0 +1,732 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptySet;\n+import static java.util.Collections.singleton;\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.common.utils.Utils.mkSortedSet;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.buildClientRankingsByTask;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.computeBalanceFactor;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.getMovements;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.replay;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.SortedSet;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.Movement;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.RankedClient;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+\n+public class HighAvailabilityTaskAssignorTest {\n+    private long acceptableRecoveryLag = 100L;\n+    private int balanceFactor = 1;\n+    private int maxWarmupReplicas = 2;\n+    private int numStandbyReplicas = 0;\n+    private long probingRebalanceInterval = 60 * 1000L;\n+\n+    private AssignmentConfigs configs;\n+    private Map<String, ClientState> clientStates = new HashMap<>();\n+    private Set<TaskId> allTasks = new HashSet<>();\n+    private Set<TaskId> statefulTasks = new HashSet<>();\n+\n+    private static final TaskId task0_0 = new TaskId(0, 0);\n+    private static final TaskId task0_1 = new TaskId(0, 1);\n+    private static final TaskId task0_2 = new TaskId(0, 2);\n+    private static final TaskId task0_3 = new TaskId(0, 3);\n+    private static final TaskId task1_0 = new TaskId(1, 0);\n+    private static final TaskId task1_1 = new TaskId(1, 1);\n+    private static final TaskId task1_2 = new TaskId(1, 2);\n+    private static final TaskId task1_3 = new TaskId(1, 3);\n+    private static final TaskId task2_0 = new TaskId(2, 0);\n+    private static final TaskId task2_1 = new TaskId(2, 1);\n+    private static final TaskId task2_3 = new TaskId(2, 3);\n+\n+    private static final String String1 = \"client1\";\n+    private static final String String2 = \"client2\";\n+    private static final String String3 = \"client3\";\n+\n+    private ClientState client1;\n+    private ClientState client2;\n+    private ClientState client3;\n+\n+    private static final Set<TaskId> emptyTasks = emptySet();\n+\n+    private HighAvailabilityTaskAssignor<String> taskAssignor;\n+\n+    private void createTaskAssignor() {\n+        configs = new AssignmentConfigs(\n+            acceptableRecoveryLag,\n+            balanceFactor,\n+            maxWarmupReplicas,\n+            numStandbyReplicas,\n+            probingRebalanceInterval\n+        );\n+        taskAssignor = new HighAvailabilityTaskAssignor<>(\n+            clientStates,\n+            allTasks,\n+            statefulTasks,\n+            configs);\n+    }\n+\n+    @Test\n+    public void shouldRankPreviousClientAboveEquallyCaughtUpClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(Task.LATEST_OFFSET);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, Task.LATEST_OFFSET),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankTaskWithUnknownOffsetSumBelowCaughtUpClientAndClientWithLargeLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(UNKNOWN_OFFSET_SUM);\n+        expect(client2.lagFor(task0_0)).andReturn(50L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String2, 0L),\n+            new RankedClient<>(String1, 1L),\n+            new RankedClient<>(String3, 500L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankAllClientsWithinAcceptableRecoveryLagWithRank0() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(100L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, 0L),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankNotCaughtUpClientsAccordingToLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(900L);\n+        expect(client2.lagFor(task0_0)).andReturn(800L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String3, 500L),\n+            new RankedClient<>(String2, 800L),\n+            new RankedClient<>(String1, 900L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldGetMovementsFromStateConstrainedToBalancedAssignment() {\n+        final Map<String, List<TaskId>> stateConstrainedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_2)),\n+            mkEntry(String2, asList(task0_1, task1_0)),\n+            mkEntry(String3, asList(task0_2, task1_1))\n+        );\n+        final Map<String, List<TaskId>> balancedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_0)),\n+            mkEntry(String2, asList(task0_1, task1_1)),\n+            mkEntry(String3, asList(task0_2, task1_2))\n+        );\n+        final Queue<Movement<String>> expectedMovements = new LinkedList<>();\n+        expectedMovements.add(new Movement<>(task1_2, String1, String3));\n+        expectedMovements.add(new Movement<>(task1_0, String2, String1));\n+        expectedMovements.add(new Movement<>(task1_1, String3, String2));\n+\n+        assertThat(getMovements(stateConstrainedAssignment, balancedAssignment), equalTo(expectedMovements));\n+    }\n+\n+    @Test\n+    public void shouldThrowIllegalStateExceptionIfAssignmentsAreOfDifferentSize() {\n+        final Map<String, List<TaskId>> stateConstrainedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task0_1))\n+        );\n+        final Map<String, List<TaskId>> balancedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_0)),\n+            mkEntry(String2, asList(task0_1, task1_1))\n+        );\n+        assertThrows(IllegalStateException.class, () -> getMovements(stateConstrainedAssignment, balancedAssignment));\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsInvalidIfThereAreUnassignedActiveTasks() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevActiveTasks()).andReturn(singleton(task0_0));\n+        expect(client1.prevStandbyTasks()).andStubReturn(emptyTasks);\n+        replay(client1);\n+        allTasks =  mkSet(task0_0, task0_1);\n+        clientStates = singletonMap(String1, client1);\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsInvalidIfThereAreUnassignedStandbyTasks() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevActiveTasks()).andStubReturn(singleton(task0_0));\n+        expect(client1.prevStandbyTasks()).andReturn(emptyTasks);\n+        replay(client1);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = singletonMap(String1, client1);\n+        numStandbyReplicas = 1;\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsInvalidIfActiveTasksWasNotOnCaughtUpClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevStandbyTasks()).andStubReturn(emptyTasks);\n+        expect(client2.prevStandbyTasks()).andStubReturn(emptyTasks);\n+\n+        expect(client1.prevActiveTasks()).andReturn(singleton(task0_0));\n+        expect(client2.prevActiveTasks()).andReturn(singleton(task0_1));\n+        expect(client1.lagFor(task0_0)).andReturn(500L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        allTasks =  mkSet(task0_0, task0_1);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsValid() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevStandbyTasks()).andStubReturn(emptyTasks);\n+        expect(client2.prevStandbyTasks()).andStubReturn(emptyTasks);\n+\n+        expect(client1.prevActiveTasks()).andReturn(singleton(task0_0));\n+        expect(client2.prevActiveTasks()).andReturn(singleton(task0_1));\n+        expect(client1.lagFor(task0_0)).andReturn(0L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        allTasks =  mkSet(task0_0, task0_1);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+        createTaskAssignor();\n+\n+        assertTrue(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldReturnTrueIfTaskHasNoCaughtUpClients() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(500L);\n+        replay(client1);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = singletonMap(String1, client1);\n+        createTaskAssignor();\n+\n+        assertTrue(taskAssignor.taskIsCaughtUpOnClient(task0_0, String1));\n+    }\n+\n+    @Test\n+    public void shouldReturnTrueIfTaskIsCaughtUpOnClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(0L);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = singletonMap(String1, client1);\n+        replay(client1);\n+        createTaskAssignor();\n+\n+        assertTrue(taskAssignor.taskIsCaughtUpOnClient(task0_0, String1));\n+    }\n+\n+    @Test\n+    public void shouldReturnFalseIfTaskWasNotCaughtUpOnClientButCaughtUpClientsExist() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(500L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.taskIsCaughtUpOnClient(task0_0, String1));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorAsDifferenceBetweenMostAndLeastLoadedClients() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        final Set<ClientState> states = mkSet(client1, client2, client3);\n+        final Set<TaskId> statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task2_0, task2_1, task2_3);\n+\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+\n+        expect(client2.capacity()).andReturn(1);\n+        expect(client2.activeTasks()).andReturn(mkSet(task1_0, task1_1));\n+\n+        expect(client3.capacity()).andReturn(1);\n+        expect(client3.activeTasks()).andReturn(mkSet(task2_0, task2_1, task2_3));\n+\n+        replay(client1, client2, client3);\n+        assertThat(computeBalanceFactor(states, statefulTasks, ClientState::activeTasks), equalTo(2));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorWithDifferentClientCapacities() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        final Set<ClientState> states = mkSet(client1, client2, client3);\n+        final Set<TaskId> statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task2_0, task2_1, task2_3);\n+\n+        // client 1: 4 tasks per thread\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+\n+        // client 2: 1 task per thread\n+        expect(client2.capacity()).andReturn(2);\n+        expect(client2.activeTasks()).andReturn(mkSet(task1_0, task1_1));\n+\n+        // client 3: 1 task per thread\n+        expect(client3.capacity()).andReturn(3);\n+        expect(client3.activeTasks()).andReturn(mkSet(task2_0, task2_1, task2_3));\n+\n+        replay(client1, client2, client3);\n+        assertThat(computeBalanceFactor(states, statefulTasks, ClientState::activeTasks), equalTo(3));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorBasedOnStatefulTasksOnly() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        final Set<ClientState> states = mkSet(client1, client2, client3);\n+\n+        // 0_0 and 0_1 are stateless\n+        final Set<TaskId> statefulTasks = mkSet(task0_2, task0_3, task1_0, task1_1, task2_0, task2_1, task2_3);\n+\n+        // client 1: 2 stateful tasks per thread\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+\n+        // client 2: 1 stateful task per thread\n+        expect(client2.capacity()).andReturn(2);\n+        expect(client2.activeTasks()).andReturn(mkSet(task1_0, task1_1));\n+\n+        // client 3: 1 stateful task per thread\n+        expect(client3.capacity()).andReturn(3);\n+        expect(client3.activeTasks()).andReturn(mkSet(task2_0, task2_1, task2_3));\n+\n+        replay(client1, client2, client3);\n+        assertThat(computeBalanceFactor(states, statefulTasks, ClientState::activeTasks), equalTo(1));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorOfZeroWithOnlyOneClient() {\n+        final Set<TaskId> statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        replay(client1);\n+        assertThat(computeBalanceFactor(singleton(client1), statefulTasks, ClientState::activeTasks), equalTo(0));\n+    }\n+\n+    @Test\n+    public void shouldAssignStandbysForStatefulTasks() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_1));\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0)));\n+        assertThat(client2.activeTasks(), equalTo(mkSet(task0_1)));\n+        assertThat(client1.standbyTasks(), equalTo(mkSet(task0_1)));\n+        assertThat(client2.standbyTasks(), equalTo(mkSet(task0_0)));\n+    }\n+\n+    @Test\n+    public void shouldNotAssignStandbysForStatelessTasks() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = emptyTasks;\n+\n+        client1 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTaskCount(), equalTo(1));\n+        assertThat(client2.activeTaskCount(), equalTo(1));\n+        assertHasNoStandbyTasks(client1, client2);\n+    }\n+\n+    @Test\n+    public void shouldAssignWarmupReplicasEvenIfNoStandbyReplicasConfigured() {\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+        \n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1)));\n+        assertThat(client2.standbyTaskCount(), equalTo(1));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2);\n+    }\n+\n+    @Test\n+    public void shouldNotAssignMoreThanMaxWarmupReplicas() {\n+        maxWarmupReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1, task0_2, task0_3)));\n+        assertThat(client2.standbyTaskCount(), equalTo(1));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2);\n+    }\n+\n+    @Test\n+    public void shouldAssignStandbyReplicasInAdditionToWarmupReplicas() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 524}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY0MDA4OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void shouldReturnFalIfPreviousAssignmentIsReused() {\n          \n          \n            \n                public void shouldReturnFalseIfPreviousAssignmentIsReused() {", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400640088", "createdAt": "2020-03-31T04:43:55Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignorTest.java", "diffHunk": "@@ -0,0 +1,732 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptySet;\n+import static java.util.Collections.singleton;\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.common.utils.Utils.mkSortedSet;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.buildClientRankingsByTask;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.computeBalanceFactor;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.getMovements;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.replay;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.SortedSet;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.Movement;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.RankedClient;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+\n+public class HighAvailabilityTaskAssignorTest {\n+    private long acceptableRecoveryLag = 100L;\n+    private int balanceFactor = 1;\n+    private int maxWarmupReplicas = 2;\n+    private int numStandbyReplicas = 0;\n+    private long probingRebalanceInterval = 60 * 1000L;\n+\n+    private AssignmentConfigs configs;\n+    private Map<String, ClientState> clientStates = new HashMap<>();\n+    private Set<TaskId> allTasks = new HashSet<>();\n+    private Set<TaskId> statefulTasks = new HashSet<>();\n+\n+    private static final TaskId task0_0 = new TaskId(0, 0);\n+    private static final TaskId task0_1 = new TaskId(0, 1);\n+    private static final TaskId task0_2 = new TaskId(0, 2);\n+    private static final TaskId task0_3 = new TaskId(0, 3);\n+    private static final TaskId task1_0 = new TaskId(1, 0);\n+    private static final TaskId task1_1 = new TaskId(1, 1);\n+    private static final TaskId task1_2 = new TaskId(1, 2);\n+    private static final TaskId task1_3 = new TaskId(1, 3);\n+    private static final TaskId task2_0 = new TaskId(2, 0);\n+    private static final TaskId task2_1 = new TaskId(2, 1);\n+    private static final TaskId task2_3 = new TaskId(2, 3);\n+\n+    private static final String String1 = \"client1\";\n+    private static final String String2 = \"client2\";\n+    private static final String String3 = \"client3\";\n+\n+    private ClientState client1;\n+    private ClientState client2;\n+    private ClientState client3;\n+\n+    private static final Set<TaskId> emptyTasks = emptySet();\n+\n+    private HighAvailabilityTaskAssignor<String> taskAssignor;\n+\n+    private void createTaskAssignor() {\n+        configs = new AssignmentConfigs(\n+            acceptableRecoveryLag,\n+            balanceFactor,\n+            maxWarmupReplicas,\n+            numStandbyReplicas,\n+            probingRebalanceInterval\n+        );\n+        taskAssignor = new HighAvailabilityTaskAssignor<>(\n+            clientStates,\n+            allTasks,\n+            statefulTasks,\n+            configs);\n+    }\n+\n+    @Test\n+    public void shouldRankPreviousClientAboveEquallyCaughtUpClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(Task.LATEST_OFFSET);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, Task.LATEST_OFFSET),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankTaskWithUnknownOffsetSumBelowCaughtUpClientAndClientWithLargeLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(UNKNOWN_OFFSET_SUM);\n+        expect(client2.lagFor(task0_0)).andReturn(50L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String2, 0L),\n+            new RankedClient<>(String1, 1L),\n+            new RankedClient<>(String3, 500L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankAllClientsWithinAcceptableRecoveryLagWithRank0() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(100L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, 0L),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankNotCaughtUpClientsAccordingToLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(900L);\n+        expect(client2.lagFor(task0_0)).andReturn(800L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String3, 500L),\n+            new RankedClient<>(String2, 800L),\n+            new RankedClient<>(String1, 900L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldGetMovementsFromStateConstrainedToBalancedAssignment() {\n+        final Map<String, List<TaskId>> stateConstrainedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_2)),\n+            mkEntry(String2, asList(task0_1, task1_0)),\n+            mkEntry(String3, asList(task0_2, task1_1))\n+        );\n+        final Map<String, List<TaskId>> balancedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_0)),\n+            mkEntry(String2, asList(task0_1, task1_1)),\n+            mkEntry(String3, asList(task0_2, task1_2))\n+        );\n+        final Queue<Movement<String>> expectedMovements = new LinkedList<>();\n+        expectedMovements.add(new Movement<>(task1_2, String1, String3));\n+        expectedMovements.add(new Movement<>(task1_0, String2, String1));\n+        expectedMovements.add(new Movement<>(task1_1, String3, String2));\n+\n+        assertThat(getMovements(stateConstrainedAssignment, balancedAssignment), equalTo(expectedMovements));\n+    }\n+\n+    @Test\n+    public void shouldThrowIllegalStateExceptionIfAssignmentsAreOfDifferentSize() {\n+        final Map<String, List<TaskId>> stateConstrainedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task0_1))\n+        );\n+        final Map<String, List<TaskId>> balancedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_0)),\n+            mkEntry(String2, asList(task0_1, task1_1))\n+        );\n+        assertThrows(IllegalStateException.class, () -> getMovements(stateConstrainedAssignment, balancedAssignment));\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsInvalidIfThereAreUnassignedActiveTasks() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevActiveTasks()).andReturn(singleton(task0_0));\n+        expect(client1.prevStandbyTasks()).andStubReturn(emptyTasks);\n+        replay(client1);\n+        allTasks =  mkSet(task0_0, task0_1);\n+        clientStates = singletonMap(String1, client1);\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsInvalidIfThereAreUnassignedStandbyTasks() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevActiveTasks()).andStubReturn(singleton(task0_0));\n+        expect(client1.prevStandbyTasks()).andReturn(emptyTasks);\n+        replay(client1);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = singletonMap(String1, client1);\n+        numStandbyReplicas = 1;\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsInvalidIfActiveTasksWasNotOnCaughtUpClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevStandbyTasks()).andStubReturn(emptyTasks);\n+        expect(client2.prevStandbyTasks()).andStubReturn(emptyTasks);\n+\n+        expect(client1.prevActiveTasks()).andReturn(singleton(task0_0));\n+        expect(client2.prevActiveTasks()).andReturn(singleton(task0_1));\n+        expect(client1.lagFor(task0_0)).andReturn(500L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        allTasks =  mkSet(task0_0, task0_1);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsValid() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevStandbyTasks()).andStubReturn(emptyTasks);\n+        expect(client2.prevStandbyTasks()).andStubReturn(emptyTasks);\n+\n+        expect(client1.prevActiveTasks()).andReturn(singleton(task0_0));\n+        expect(client2.prevActiveTasks()).andReturn(singleton(task0_1));\n+        expect(client1.lagFor(task0_0)).andReturn(0L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        allTasks =  mkSet(task0_0, task0_1);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+        createTaskAssignor();\n+\n+        assertTrue(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldReturnTrueIfTaskHasNoCaughtUpClients() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(500L);\n+        replay(client1);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = singletonMap(String1, client1);\n+        createTaskAssignor();\n+\n+        assertTrue(taskAssignor.taskIsCaughtUpOnClient(task0_0, String1));\n+    }\n+\n+    @Test\n+    public void shouldReturnTrueIfTaskIsCaughtUpOnClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(0L);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = singletonMap(String1, client1);\n+        replay(client1);\n+        createTaskAssignor();\n+\n+        assertTrue(taskAssignor.taskIsCaughtUpOnClient(task0_0, String1));\n+    }\n+\n+    @Test\n+    public void shouldReturnFalseIfTaskWasNotCaughtUpOnClientButCaughtUpClientsExist() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(500L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.taskIsCaughtUpOnClient(task0_0, String1));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorAsDifferenceBetweenMostAndLeastLoadedClients() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        final Set<ClientState> states = mkSet(client1, client2, client3);\n+        final Set<TaskId> statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task2_0, task2_1, task2_3);\n+\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+\n+        expect(client2.capacity()).andReturn(1);\n+        expect(client2.activeTasks()).andReturn(mkSet(task1_0, task1_1));\n+\n+        expect(client3.capacity()).andReturn(1);\n+        expect(client3.activeTasks()).andReturn(mkSet(task2_0, task2_1, task2_3));\n+\n+        replay(client1, client2, client3);\n+        assertThat(computeBalanceFactor(states, statefulTasks, ClientState::activeTasks), equalTo(2));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorWithDifferentClientCapacities() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        final Set<ClientState> states = mkSet(client1, client2, client3);\n+        final Set<TaskId> statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task2_0, task2_1, task2_3);\n+\n+        // client 1: 4 tasks per thread\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+\n+        // client 2: 1 task per thread\n+        expect(client2.capacity()).andReturn(2);\n+        expect(client2.activeTasks()).andReturn(mkSet(task1_0, task1_1));\n+\n+        // client 3: 1 task per thread\n+        expect(client3.capacity()).andReturn(3);\n+        expect(client3.activeTasks()).andReturn(mkSet(task2_0, task2_1, task2_3));\n+\n+        replay(client1, client2, client3);\n+        assertThat(computeBalanceFactor(states, statefulTasks, ClientState::activeTasks), equalTo(3));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorBasedOnStatefulTasksOnly() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        final Set<ClientState> states = mkSet(client1, client2, client3);\n+\n+        // 0_0 and 0_1 are stateless\n+        final Set<TaskId> statefulTasks = mkSet(task0_2, task0_3, task1_0, task1_1, task2_0, task2_1, task2_3);\n+\n+        // client 1: 2 stateful tasks per thread\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+\n+        // client 2: 1 stateful task per thread\n+        expect(client2.capacity()).andReturn(2);\n+        expect(client2.activeTasks()).andReturn(mkSet(task1_0, task1_1));\n+\n+        // client 3: 1 stateful task per thread\n+        expect(client3.capacity()).andReturn(3);\n+        expect(client3.activeTasks()).andReturn(mkSet(task2_0, task2_1, task2_3));\n+\n+        replay(client1, client2, client3);\n+        assertThat(computeBalanceFactor(states, statefulTasks, ClientState::activeTasks), equalTo(1));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorOfZeroWithOnlyOneClient() {\n+        final Set<TaskId> statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        replay(client1);\n+        assertThat(computeBalanceFactor(singleton(client1), statefulTasks, ClientState::activeTasks), equalTo(0));\n+    }\n+\n+    @Test\n+    public void shouldAssignStandbysForStatefulTasks() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_1));\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0)));\n+        assertThat(client2.activeTasks(), equalTo(mkSet(task0_1)));\n+        assertThat(client1.standbyTasks(), equalTo(mkSet(task0_1)));\n+        assertThat(client2.standbyTasks(), equalTo(mkSet(task0_0)));\n+    }\n+\n+    @Test\n+    public void shouldNotAssignStandbysForStatelessTasks() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = emptyTasks;\n+\n+        client1 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTaskCount(), equalTo(1));\n+        assertThat(client2.activeTaskCount(), equalTo(1));\n+        assertHasNoStandbyTasks(client1, client2);\n+    }\n+\n+    @Test\n+    public void shouldAssignWarmupReplicasEvenIfNoStandbyReplicasConfigured() {\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+        \n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1)));\n+        assertThat(client2.standbyTaskCount(), equalTo(1));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2);\n+    }\n+\n+    @Test\n+    public void shouldNotAssignMoreThanMaxWarmupReplicas() {\n+        maxWarmupReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1, task0_2, task0_3)));\n+        assertThat(client2.standbyTaskCount(), equalTo(1));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2);\n+    }\n+\n+    @Test\n+    public void shouldAssignStandbyReplicasInAdditionToWarmupReplicas() {\n+        numStandbyReplicas = 1;\n+        maxWarmupReplicas = 1;\n+\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1, task0_2, task0_3)));\n+        assertThat(client2.standbyTasks(), equalTo(mkSet(task0_0, task0_1, task0_2, task0_3)));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2);\n+    }\n+\n+    @Test\n+    public void shouldNotAssignAnyStandbysWithInsufficientCapacity() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1));\n+\n+        clientStates = getClientStatesWithOneClient();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1)));\n+        assertHasNoStandbyTasks(client1);\n+    }\n+\n+    @Test\n+    public void shouldAssignActiveTasksToNotCaughtUpClientIfNoneExist() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithOneClient();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1)));\n+        assertHasNoStandbyTasks(client1);\n+    }\n+\n+    @Test\n+    public void shouldNotAssignMoreThanMaxWarmupReplicasWithStandbys() {\n+        numStandbyReplicas = 1;\n+\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+        client3 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithThreeClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTaskCount(), equalTo(4));\n+        assertThat(client2.standbyTaskCount(), equalTo(3));\n+        assertThat(client3.standbyTaskCount(), equalTo(3));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2, client3);\n+    }\n+\n+    @Test\n+    public void shouldDistributeStatelessTasksToBalanceTotalActiveTaskLoad() {\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task1_2);\n+        statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1, task0_2, task0_3)));\n+        assertThat(client2.activeTasks(), equalTo(mkSet(task1_0, task1_1, task1_2)));\n+    }\n+\n+    @Test\n+    public void shouldDistributeStatefulActiveTasksToAllClients() {\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task1_2, task1_3, task2_0); // 9 total\n+        statefulTasks = new HashSet<>(allTasks);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(allTasks).withCapacity(100);\n+        client2 = getMockClientWithPreviousCaughtUpTasks(allTasks).withCapacity(50);\n+        client3 = getMockClientWithPreviousCaughtUpTasks(allTasks).withCapacity(1);\n+\n+        clientStates = getClientStatesWithThreeClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertFalse(client1.activeTasks().isEmpty());\n+        assertFalse(client2.activeTasks().isEmpty());\n+        assertFalse(client3.activeTasks().isEmpty());\n+    }\n+\n+    @Test\n+    public void shouldReturnFalIfPreviousAssignmentIsReused() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 628}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY0MDI4Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                MockClientState getMockClientWithPreviousCaughtUpTasks(final Set<TaskId> statefulActiveTasks) {\n          \n          \n            \n                private MockClientState getMockClientWithPreviousCaughtUpTasks(final Set<TaskId> statefulActiveTasks) {", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400640282", "createdAt": "2020-03-31T04:44:49Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignorTest.java", "diffHunk": "@@ -0,0 +1,732 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptySet;\n+import static java.util.Collections.singleton;\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.common.utils.Utils.mkSortedSet;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.buildClientRankingsByTask;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.computeBalanceFactor;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.getMovements;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.replay;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.SortedSet;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.Movement;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.RankedClient;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+\n+public class HighAvailabilityTaskAssignorTest {\n+    private long acceptableRecoveryLag = 100L;\n+    private int balanceFactor = 1;\n+    private int maxWarmupReplicas = 2;\n+    private int numStandbyReplicas = 0;\n+    private long probingRebalanceInterval = 60 * 1000L;\n+\n+    private AssignmentConfigs configs;\n+    private Map<String, ClientState> clientStates = new HashMap<>();\n+    private Set<TaskId> allTasks = new HashSet<>();\n+    private Set<TaskId> statefulTasks = new HashSet<>();\n+\n+    private static final TaskId task0_0 = new TaskId(0, 0);\n+    private static final TaskId task0_1 = new TaskId(0, 1);\n+    private static final TaskId task0_2 = new TaskId(0, 2);\n+    private static final TaskId task0_3 = new TaskId(0, 3);\n+    private static final TaskId task1_0 = new TaskId(1, 0);\n+    private static final TaskId task1_1 = new TaskId(1, 1);\n+    private static final TaskId task1_2 = new TaskId(1, 2);\n+    private static final TaskId task1_3 = new TaskId(1, 3);\n+    private static final TaskId task2_0 = new TaskId(2, 0);\n+    private static final TaskId task2_1 = new TaskId(2, 1);\n+    private static final TaskId task2_3 = new TaskId(2, 3);\n+\n+    private static final String String1 = \"client1\";\n+    private static final String String2 = \"client2\";\n+    private static final String String3 = \"client3\";\n+\n+    private ClientState client1;\n+    private ClientState client2;\n+    private ClientState client3;\n+\n+    private static final Set<TaskId> emptyTasks = emptySet();\n+\n+    private HighAvailabilityTaskAssignor<String> taskAssignor;\n+\n+    private void createTaskAssignor() {\n+        configs = new AssignmentConfigs(\n+            acceptableRecoveryLag,\n+            balanceFactor,\n+            maxWarmupReplicas,\n+            numStandbyReplicas,\n+            probingRebalanceInterval\n+        );\n+        taskAssignor = new HighAvailabilityTaskAssignor<>(\n+            clientStates,\n+            allTasks,\n+            statefulTasks,\n+            configs);\n+    }\n+\n+    @Test\n+    public void shouldRankPreviousClientAboveEquallyCaughtUpClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(Task.LATEST_OFFSET);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, Task.LATEST_OFFSET),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankTaskWithUnknownOffsetSumBelowCaughtUpClientAndClientWithLargeLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(UNKNOWN_OFFSET_SUM);\n+        expect(client2.lagFor(task0_0)).andReturn(50L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String2, 0L),\n+            new RankedClient<>(String1, 1L),\n+            new RankedClient<>(String3, 500L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankAllClientsWithinAcceptableRecoveryLagWithRank0() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(100L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, 0L),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankNotCaughtUpClientsAccordingToLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(900L);\n+        expect(client2.lagFor(task0_0)).andReturn(800L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String3, 500L),\n+            new RankedClient<>(String2, 800L),\n+            new RankedClient<>(String1, 900L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldGetMovementsFromStateConstrainedToBalancedAssignment() {\n+        final Map<String, List<TaskId>> stateConstrainedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_2)),\n+            mkEntry(String2, asList(task0_1, task1_0)),\n+            mkEntry(String3, asList(task0_2, task1_1))\n+        );\n+        final Map<String, List<TaskId>> balancedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_0)),\n+            mkEntry(String2, asList(task0_1, task1_1)),\n+            mkEntry(String3, asList(task0_2, task1_2))\n+        );\n+        final Queue<Movement<String>> expectedMovements = new LinkedList<>();\n+        expectedMovements.add(new Movement<>(task1_2, String1, String3));\n+        expectedMovements.add(new Movement<>(task1_0, String2, String1));\n+        expectedMovements.add(new Movement<>(task1_1, String3, String2));\n+\n+        assertThat(getMovements(stateConstrainedAssignment, balancedAssignment), equalTo(expectedMovements));\n+    }\n+\n+    @Test\n+    public void shouldThrowIllegalStateExceptionIfAssignmentsAreOfDifferentSize() {\n+        final Map<String, List<TaskId>> stateConstrainedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task0_1))\n+        );\n+        final Map<String, List<TaskId>> balancedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_0)),\n+            mkEntry(String2, asList(task0_1, task1_1))\n+        );\n+        assertThrows(IllegalStateException.class, () -> getMovements(stateConstrainedAssignment, balancedAssignment));\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsInvalidIfThereAreUnassignedActiveTasks() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevActiveTasks()).andReturn(singleton(task0_0));\n+        expect(client1.prevStandbyTasks()).andStubReturn(emptyTasks);\n+        replay(client1);\n+        allTasks =  mkSet(task0_0, task0_1);\n+        clientStates = singletonMap(String1, client1);\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsInvalidIfThereAreUnassignedStandbyTasks() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevActiveTasks()).andStubReturn(singleton(task0_0));\n+        expect(client1.prevStandbyTasks()).andReturn(emptyTasks);\n+        replay(client1);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = singletonMap(String1, client1);\n+        numStandbyReplicas = 1;\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsInvalidIfActiveTasksWasNotOnCaughtUpClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevStandbyTasks()).andStubReturn(emptyTasks);\n+        expect(client2.prevStandbyTasks()).andStubReturn(emptyTasks);\n+\n+        expect(client1.prevActiveTasks()).andReturn(singleton(task0_0));\n+        expect(client2.prevActiveTasks()).andReturn(singleton(task0_1));\n+        expect(client1.lagFor(task0_0)).andReturn(500L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        allTasks =  mkSet(task0_0, task0_1);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldDecidePreviousAssignmentIsValid() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.prevStandbyTasks()).andStubReturn(emptyTasks);\n+        expect(client2.prevStandbyTasks()).andStubReturn(emptyTasks);\n+\n+        expect(client1.prevActiveTasks()).andReturn(singleton(task0_0));\n+        expect(client2.prevActiveTasks()).andReturn(singleton(task0_1));\n+        expect(client1.lagFor(task0_0)).andReturn(0L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        allTasks =  mkSet(task0_0, task0_1);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+        createTaskAssignor();\n+\n+        assertTrue(taskAssignor.previousAssignmentIsValid());\n+    }\n+\n+    @Test\n+    public void shouldReturnTrueIfTaskHasNoCaughtUpClients() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(500L);\n+        replay(client1);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = singletonMap(String1, client1);\n+        createTaskAssignor();\n+\n+        assertTrue(taskAssignor.taskIsCaughtUpOnClient(task0_0, String1));\n+    }\n+\n+    @Test\n+    public void shouldReturnTrueIfTaskIsCaughtUpOnClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(0L);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = singletonMap(String1, client1);\n+        replay(client1);\n+        createTaskAssignor();\n+\n+        assertTrue(taskAssignor.taskIsCaughtUpOnClient(task0_0, String1));\n+    }\n+\n+    @Test\n+    public void shouldReturnFalseIfTaskWasNotCaughtUpOnClientButCaughtUpClientsExist() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(500L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+        allTasks =  mkSet(task0_0);\n+        statefulTasks =  mkSet(task0_0);\n+        clientStates = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+        createTaskAssignor();\n+\n+        assertFalse(taskAssignor.taskIsCaughtUpOnClient(task0_0, String1));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorAsDifferenceBetweenMostAndLeastLoadedClients() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        final Set<ClientState> states = mkSet(client1, client2, client3);\n+        final Set<TaskId> statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task2_0, task2_1, task2_3);\n+\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+\n+        expect(client2.capacity()).andReturn(1);\n+        expect(client2.activeTasks()).andReturn(mkSet(task1_0, task1_1));\n+\n+        expect(client3.capacity()).andReturn(1);\n+        expect(client3.activeTasks()).andReturn(mkSet(task2_0, task2_1, task2_3));\n+\n+        replay(client1, client2, client3);\n+        assertThat(computeBalanceFactor(states, statefulTasks, ClientState::activeTasks), equalTo(2));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorWithDifferentClientCapacities() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        final Set<ClientState> states = mkSet(client1, client2, client3);\n+        final Set<TaskId> statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task2_0, task2_1, task2_3);\n+\n+        // client 1: 4 tasks per thread\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+\n+        // client 2: 1 task per thread\n+        expect(client2.capacity()).andReturn(2);\n+        expect(client2.activeTasks()).andReturn(mkSet(task1_0, task1_1));\n+\n+        // client 3: 1 task per thread\n+        expect(client3.capacity()).andReturn(3);\n+        expect(client3.activeTasks()).andReturn(mkSet(task2_0, task2_1, task2_3));\n+\n+        replay(client1, client2, client3);\n+        assertThat(computeBalanceFactor(states, statefulTasks, ClientState::activeTasks), equalTo(3));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorBasedOnStatefulTasksOnly() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        final Set<ClientState> states = mkSet(client1, client2, client3);\n+\n+        // 0_0 and 0_1 are stateless\n+        final Set<TaskId> statefulTasks = mkSet(task0_2, task0_3, task1_0, task1_1, task2_0, task2_1, task2_3);\n+\n+        // client 1: 2 stateful tasks per thread\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+\n+        // client 2: 1 stateful task per thread\n+        expect(client2.capacity()).andReturn(2);\n+        expect(client2.activeTasks()).andReturn(mkSet(task1_0, task1_1));\n+\n+        // client 3: 1 stateful task per thread\n+        expect(client3.capacity()).andReturn(3);\n+        expect(client3.activeTasks()).andReturn(mkSet(task2_0, task2_1, task2_3));\n+\n+        replay(client1, client2, client3);\n+        assertThat(computeBalanceFactor(states, statefulTasks, ClientState::activeTasks), equalTo(1));\n+    }\n+\n+    @Test\n+    public void shouldComputeBalanceFactorOfZeroWithOnlyOneClient() {\n+        final Set<TaskId> statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.capacity()).andReturn(1);\n+        expect(client1.activeTasks()).andReturn(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        replay(client1);\n+        assertThat(computeBalanceFactor(singleton(client1), statefulTasks, ClientState::activeTasks), equalTo(0));\n+    }\n+\n+    @Test\n+    public void shouldAssignStandbysForStatefulTasks() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_1));\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0)));\n+        assertThat(client2.activeTasks(), equalTo(mkSet(task0_1)));\n+        assertThat(client1.standbyTasks(), equalTo(mkSet(task0_1)));\n+        assertThat(client2.standbyTasks(), equalTo(mkSet(task0_0)));\n+    }\n+\n+    @Test\n+    public void shouldNotAssignStandbysForStatelessTasks() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = emptyTasks;\n+\n+        client1 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTaskCount(), equalTo(1));\n+        assertThat(client2.activeTaskCount(), equalTo(1));\n+        assertHasNoStandbyTasks(client1, client2);\n+    }\n+\n+    @Test\n+    public void shouldAssignWarmupReplicasEvenIfNoStandbyReplicasConfigured() {\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+        \n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1)));\n+        assertThat(client2.standbyTaskCount(), equalTo(1));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2);\n+    }\n+\n+    @Test\n+    public void shouldNotAssignMoreThanMaxWarmupReplicas() {\n+        maxWarmupReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1, task0_2, task0_3)));\n+        assertThat(client2.standbyTaskCount(), equalTo(1));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2);\n+    }\n+\n+    @Test\n+    public void shouldAssignStandbyReplicasInAdditionToWarmupReplicas() {\n+        numStandbyReplicas = 1;\n+        maxWarmupReplicas = 1;\n+\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1, task0_2, task0_3)));\n+        assertThat(client2.standbyTasks(), equalTo(mkSet(task0_0, task0_1, task0_2, task0_3)));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2);\n+    }\n+\n+    @Test\n+    public void shouldNotAssignAnyStandbysWithInsufficientCapacity() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1));\n+\n+        clientStates = getClientStatesWithOneClient();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1)));\n+        assertHasNoStandbyTasks(client1);\n+    }\n+\n+    @Test\n+    public void shouldAssignActiveTasksToNotCaughtUpClientIfNoneExist() {\n+        numStandbyReplicas = 1;\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithOneClient();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1)));\n+        assertHasNoStandbyTasks(client1);\n+    }\n+\n+    @Test\n+    public void shouldNotAssignMoreThanMaxWarmupReplicasWithStandbys() {\n+        numStandbyReplicas = 1;\n+\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+        client3 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithThreeClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTaskCount(), equalTo(4));\n+        assertThat(client2.standbyTaskCount(), equalTo(3));\n+        assertThat(client3.standbyTaskCount(), equalTo(3));\n+        assertHasNoStandbyTasks(client1);\n+        assertHasNoActiveTasks(client2, client3);\n+    }\n+\n+    @Test\n+    public void shouldDistributeStatelessTasksToBalanceTotalActiveTaskLoad() {\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task1_2);\n+        statefulTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+\n+        client1 = getMockClientWithPreviousCaughtUpTasks(mkSet(task0_0, task0_1, task0_2, task0_3));\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertThat(client1.activeTasks(), equalTo(mkSet(task0_0, task0_1, task0_2, task0_3)));\n+        assertThat(client2.activeTasks(), equalTo(mkSet(task1_0, task1_1, task1_2)));\n+    }\n+\n+    @Test\n+    public void shouldDistributeStatefulActiveTasksToAllClients() {\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3, task1_0, task1_1, task1_2, task1_3, task2_0); // 9 total\n+        statefulTasks = new HashSet<>(allTasks);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(allTasks).withCapacity(100);\n+        client2 = getMockClientWithPreviousCaughtUpTasks(allTasks).withCapacity(50);\n+        client3 = getMockClientWithPreviousCaughtUpTasks(allTasks).withCapacity(1);\n+\n+        clientStates = getClientStatesWithThreeClients();\n+        createTaskAssignor();\n+        taskAssignor.assign();\n+\n+        assertFalse(client1.activeTasks().isEmpty());\n+        assertFalse(client2.activeTasks().isEmpty());\n+        assertFalse(client3.activeTasks().isEmpty());\n+    }\n+\n+    @Test\n+    public void shouldReturnFalIfPreviousAssignmentIsReused() {\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        statefulTasks = new HashSet<>(allTasks);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(allTasks);\n+        client2 = getMockClientWithPreviousCaughtUpTasks(allTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        assertFalse(taskAssignor.assign());\n+\n+        assertThat(client1.activeTasks(), equalTo(client1.prevActiveTasks()));\n+        assertThat(client2.activeTasks(), equalTo(client2.prevActiveTasks()));\n+    }\n+\n+    @Test\n+    public void shouldReturnFalseIfNoWarmupTasksAreAssigned() {\n+        allTasks = mkSet(task0_0, task0_1, task0_2, task0_3);\n+        statefulTasks = emptyTasks;\n+        client1 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        assertFalse(taskAssignor.assign());\n+        assertHasNoStandbyTasks(client1, client2);\n+    }\n+\n+    @Test\n+    public void shouldReturnTrueIfWarmupTasksAreAssigned() {\n+        allTasks = mkSet(task0_0, task0_1);\n+        statefulTasks = mkSet(task0_0, task0_1);\n+        client1 = getMockClientWithPreviousCaughtUpTasks(allTasks);\n+        client2 = getMockClientWithPreviousCaughtUpTasks(emptyTasks);\n+\n+        clientStates = getClientStatesWithTwoClients();\n+        createTaskAssignor();\n+        assertTrue(taskAssignor.assign());\n+        assertThat(client2.standbyTaskCount(), equalTo(1));\n+    }\n+\n+    private Map<String, ClientState> getClientStatesWithOneClient() {\n+        return singletonMap(String1, client1);\n+    }\n+\n+    private Map<String, ClientState> getClientStatesWithTwoClients() {\n+        return mkMap(mkEntry(String1, client1), mkEntry(String2, client2));\n+    }\n+\n+    private Map<String, ClientState> getClientStatesWithThreeClients() {\n+        return mkMap(mkEntry(String1, client1), mkEntry(String2, client2), mkEntry(String3, client3));\n+    }\n+\n+    private static void assertHasNoActiveTasks(final ClientState... clients) {\n+        for (final ClientState client : clients) {\n+            assertTrue(client.activeTasks().isEmpty());\n+        }\n+    }\n+\n+    private static void assertHasNoStandbyTasks(final ClientState... clients) {\n+        for (final ClientState client : clients) {\n+            assertTrue(client.standbyTasks().isEmpty());\n+        }\n+    }\n+\n+    MockClientState getMockClientWithPreviousCaughtUpTasks(final Set<TaskId> statefulActiveTasks) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 692}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg0NTg4OTg3", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-384588987", "createdAt": "2020-03-31T10:11:35Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMDoxMTozNVrOF-OqNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNjowNjo0OFrOF-dPGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NjIxNA==", "bodyText": "IMO, suppressing checkstyle rules should be the last thing one should do to get a successful validation. Especially, for new code. Otherwise we need to re-discuss the checkstyle rules.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400796214", "createdAt": "2020-03-31T10:11:35Z", "author": {"login": "cadonna"}, "path": "checkstyle/suppressions.xml", "diffHunk": "@@ -208,8 +208,8 @@\n     <suppress checks=\"MethodLength\"\n               files=\"RocksDBWindowStoreTest.java\"/>\n \n-    <suppress checks=\"MemberName\"\n-              files=\"StreamsPartitionAssignorTest.java\"/>\n+    <suppress checks=\"MemberName|ConstantName\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU0NTk2NA=="}, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg0OTYwMQ==", "bodyText": "Q: Where does if (!lagComputationSuccessful) come from, if StickyTaskAssignor did its thing regardless of the lag computation? I have the feeling I am missing something important here.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400849601", "createdAt": "2020-03-31T11:49:44Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,25 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor<UUID> taskAssignor;\n+        if (highAvailabilityEnabled) {\n+            if (lagComputationSuccessful) {\n+                taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks,\n+                    assignmentConfigs);\n+            } else {\n+                taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n+                ((StickyTaskAssignor) taskAssignor).preservePreviousTaskAssignment();\n+            }\n+        } else {\n+            taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU0NzQzMg=="}, "originalCommit": null, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1MDExNA==", "bodyText": "req: Could you please specify a constructor that takes a flag to set whether the previous task assignment should be preserved? That would save us this ugly cast.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400850114", "createdAt": "2020-03-31T11:50:42Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,25 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor<UUID> taskAssignor;\n+        if (highAvailabilityEnabled) {\n+            if (lagComputationSuccessful) {\n+                taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks,\n+                    assignmentConfigs);\n+            } else {\n+                taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n+                ((StickyTaskAssignor) taskAssignor).preservePreviousTaskAssignment();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1NzA0Ng==", "bodyText": "Q: Does our code styleguide not say we should in general write such calls that do not fit in one line as\ntaskAssignor = new HighAvailabilityTaskAssignor<>(\n    clientStates, \n    allTasks, \n    statefulTasks,\n    assignmentConfigs\n);\n\nIn this specific case, I would write all parameters in one line and make the line those 4 symbols longer than allowed.\nMaybe I am bit too picky about code style, but it makes code better readable if we use the same style for same situations. At the same time, I also think that sometimes it makes sense to break those rules for readability, but I cannot see how breaking the rule makes it more readable here. WDYT?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400857046", "createdAt": "2020-03-31T12:03:12Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,25 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor<UUID> taskAssignor;\n+        if (highAvailabilityEnabled) {\n+            if (lagComputationSuccessful) {\n+                taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MDI2NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n          \n          \n            \n                                             final Set<TaskId> allTasks,\n          \n          \n            \n                                             final Set<TaskId> statefulTasks,\n          \n          \n            \n                                             final AssignmentConfigs configs) {\n          \n          \n            \n                public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n          \n          \n            \n                                                    final Set<TaskId> allTasks,\n          \n          \n            \n                                                    final Set<TaskId> statefulTasks,\n          \n          \n            \n                                                    final AssignmentConfigs configs) {", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400870265", "createdAt": "2020-03-31T12:24:57Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg4MzQ4NA==", "bodyText": "prop: Could we pass into getMovements() the number of warm-up replicas and only compute as many movements as needed instead of computing all movements and then using just the first couple of movements.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400883484", "createdAt": "2020-03-31T12:45:54Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkwMDExMw==", "bodyText": "prop: Could you rename the queue class and the variable to something like LeastLoadedClientsForStandbyTasks or ClientsForStandbyTaskSortedByLoad?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400900113", "createdAt": "2020-03-31T13:10:32Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkwNzMyMg==", "bodyText": "IMO, those comments are more confusing than helping. I would prefer to have methods with meaningful names to structure the code. For example,\n\nassignStatefulTasksAndWarmUpReplica() or computeAssignmentFor...\nassignStandByTasks() or computeAssignmentFor...\nassignStatelessTasks() or computeAssignmentFor...", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400907322", "createdAt": "2020-03-31T13:20:38Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkxNzA1MA==", "bodyText": "I do not agree. We need to distribute the stateless tasks, therefore the loop is over the stateless tasks. For each task we need to find the client with the least load which is done with the priority queue (i.e. min-heap). Since we poll a client and add the updated client in each iteration, poll() cannot return null.\nMy question would be why we only consider the stateful active tasks assignment and not the assignment of all tasks, i.e., also standby tasks and warm-up replica in the priority queue. Also those tasks contribute to the load of a client.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400917050", "createdAt": "2020-03-31T13:33:54Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwMjkwMQ=="}, "originalCommit": null, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMTIxNQ==", "bodyText": "prop: Wouldn't this condition be equal to !movements.isEmpty()?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400931215", "createdAt": "2020-03-31T13:53:13Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0Mzk5Mg==", "bodyText": "I see what you mean. I do not have any heart feelings here. Would be interesting to see in experiments how the two approaches differ.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400943992", "createdAt": "2020-03-31T14:09:41Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNzQ2MQ=="}, "originalCommit": null, "originalPosition": 302}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NjI1Nw==", "bodyText": "Q: I might have missed the discussion. Why does an unknown offset result in 1 and not in Long.MAX_VALUE? Sorry if you have already answered this question elsewhere.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400946257", "createdAt": "2020-03-31T14:12:44Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;\n+                } else if (taskLag == UNKNOWN_OFFSET_SUM) {\n+                    clientRank = 1L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 304}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk1MDIxOA==", "bodyText": "FYI: Mine produces the same as John's", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400950218", "createdAt": "2020-03-31T14:17:48Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;\n+                } else if (taskLag == UNKNOWN_OFFSET_SUM) {\n+                    clientRank = 1L;\n+                } else if (taskLag <= acceptableRecoveryLag) {\n+                    clientRank = 0L;\n+                } else {\n+                    clientRank = taskLag;\n+                }\n+                rankedClientCandidates.add(new RankedClient<>(clientId, clientRank));\n+            }\n+        }\n+        log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n+\n+        return statefulTasksToRankedCandidates;\n+    }\n+\n+    /**\n+     * Compute the balance factor as the difference in stateful active task count per thread between the most and\n+     * least loaded clients\n+     */\n+    static int computeBalanceFactor(final Collection<ClientState> clientStates,\n+                                    final Set<TaskId> statefulTasks,\n+                                    final Function<ClientState, Set<TaskId>> activeTaskSet) {\n+        int minActiveStatefulTasksPerThreadCount = Integer.MAX_VALUE;\n+        int maxActiveStatefulTasksPerThreadCount = 0;\n+\n+        for (final ClientState state : clientStates) {\n+            final Set<TaskId> activeTasks = new HashSet<>(activeTaskSet.apply(state));\n+            activeTasks.retainAll(statefulTasks);\n+            final int taskPerThreadCount = activeTasks.size() / state.capacity();\n+            if (taskPerThreadCount < minActiveStatefulTasksPerThreadCount) {\n+                minActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+            if (taskPerThreadCount > maxActiveStatefulTasksPerThreadCount) {\n+                maxActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+        }\n+\n+        return maxActiveStatefulTasksPerThreadCount - minActiveStatefulTasksPerThreadCount;\n+    }\n+\n+    /**\n+     * Determines whether to use the new proposed assignment or just return the group's previous assignment. The\n+     * previous assignment will be chosen and returned iff all of the following are true:\n+     *   1) it satisfies the state constraint, ie all tasks with caught up clients are assigned to one of those clients\n+     *   2) it satisfies the balance factor\n+     *   3) there are no unassigned tasks (eg due to a client that dropped out of the group)\n+     */\n+    private boolean shouldUsePreviousAssignment() {\n+        if (previousAssignmentIsValid()) {\n+            final int previousAssignmentBalanceFactor =\n+                computeBalanceFactor(clientStates.values(), statefulTasks, ClientState::prevActiveTasks);\n+            return previousAssignmentBalanceFactor <= configs.balanceFactor;\n+        } else {\n+            return false;\n+        }\n+    }\n+\n+    private Map<ID, List<TaskId>> initializeEmptyTaskAssignmentMap() {\n+        return sortedClients.stream().collect(Collectors.toMap(id -> id, id -> new ArrayList<>()));\n+    }\n+\n+    private void assignActiveTasksToClients(final Map<ID, List<TaskId>> activeTasks) {\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID clientId = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            state.assignActiveTasks(activeTasks.get(clientId));\n+        }\n+    }\n+\n+    private void assignStandbyTasksToClients(final Map<ID, List<TaskId>> standbyTasks) {\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID clientId = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            state.assignStandbyTasks(standbyTasks.get(clientId));\n+        }\n+    }\n+\n+    private void assignPreviousTasksToClientStates() {\n+        for (final ClientState clientState : clientStates.values()) {\n+            clientState.assignActiveTasks(clientState.prevActiveTasks());\n+            clientState.assignStandbyTasks(clientState.prevStandbyTasks());\n+        }\n+    }\n+\n+    private PriorityQueue<ID> getClientPriorityQueueByTaskLoad(final List<Map<ID, List<TaskId>>> taskLoadsByClient) {\n+        final PriorityQueue<ID> queue = new PriorityQueue<>(\n+            (client, other) -> {\n+                final int clientTasksPerThread = tasksPerThread(client, taskLoadsByClient);\n+                final int otherTasksPerThread = tasksPerThread(other, taskLoadsByClient);\n+                if (clientTasksPerThread != otherTasksPerThread) {\n+                    return clientTasksPerThread - otherTasksPerThread;\n+                } else {\n+                    return client.compareTo(other);\n+                }\n+            });\n+\n+        queue.addAll(sortedClients);\n+        return queue;\n+    }\n+\n+    private int tasksPerThread(final ID client, final List<Map<ID, List<TaskId>>> taskLoadsByClient) {\n+        double numTasks = 0;\n+        for (final Map<ID, List<TaskId>> assignment : taskLoadsByClient) {\n+            numTasks += assignment.get(client).size();\n+        }\n+        return (int) Math.ceil(numTasks / clientsToNumberOfThreads.get(client));\n+    }\n+\n+    static class RankedClient<ID extends Comparable<? super ID>> implements Comparable<RankedClient<ID>> {\n+        private final ID clientId;\n+        private final long rank;\n+\n+        RankedClient(final ID clientId, final long rank) {\n+            this.clientId = clientId;\n+            this.rank = rank;\n+        }\n+\n+        ID clientId() {\n+            return clientId;\n+        }\n+\n+        long rank() {\n+            return rank;\n+        }\n+\n+        @Override\n+        public int compareTo(final RankedClient<ID> clientIdAndLag) {\n+            if (rank < clientIdAndLag.rank) {\n+                return -1;\n+            } else if (rank > clientIdAndLag.rank) {\n+                return 1;\n+            } else {\n+                return clientId.compareTo(clientIdAndLag.clientId);\n+            }\n+        }\n+\n+        @Override\n+        public boolean equals(final Object o) {\n+            if (this == o) {\n+                return true;\n+            } else if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final RankedClient other = (RankedClient) o;\n+            return clientId == other.clientId() && rank == other.rank();\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(rank, clientId);\n+        }\n+    }\n+\n+    static class Movement<ID> {\n+        final TaskId task;\n+        final ID source;\n+        final ID destination;\n+\n+        Movement(final TaskId task, final ID source, final ID destination) {\n+            this.task = task;\n+            this.source = source;\n+            this.destination = destination;\n+        }\n+\n+        @Override\n+        public boolean equals(final Object o) {\n+            if (this == o) {\n+                return true;\n+            } else if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final Movement other = (Movement) o;\n+            return task == other.task && source == other.source && destination == other.destination;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYxMzkzNA=="}, "originalCommit": null, "originalPosition": 475}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk1OTcwMQ==", "bodyText": "prop: Shall we put this code into a factory method that takes the assignor configuration and returns the correct assignor. Due to the better encapsulation, we would be able to test this class independently from the assignor.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400959701", "createdAt": "2020-03-31T14:29:42Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,25 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor<UUID> taskAssignor;\n+        if (highAvailabilityEnabled) {\n+            if (lagComputationSuccessful) {\n+                taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks,\n+                    assignmentConfigs);\n+            } else {\n+                taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n+                ((StickyTaskAssignor) taskAssignor).preservePreviousTaskAssignment();\n+            }\n+        } else {\n+            taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n         }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2MDU0OA==", "bodyText": "See my comment above about making StreamPartitionAssignor independent of the assignor with a factory method.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400960548", "createdAt": "2020-03-31T14:30:48Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java", "diffHunk": "@@ -2011,7 +1883,7 @@ public void shouldReturnAllActiveTasksToPreviousOwnerRegardlessOfBalanceIfEndOff\n         createMockTaskManager(allTasks, emptyTasks);\n         adminClient = EasyMock.createMock(AdminClient.class);\n         expect(adminClient.listOffsets(anyObject())).andThrow(new StreamsException(\"Should be handled\"));\n-        configureDefaultPartitionAssignor();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYxODA5MA=="}, "originalCommit": null, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk4ODM1Ng==", "bodyText": "I agree with @vvcephei.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400988356", "createdAt": "2020-03-31T15:05:46Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignorTest.java", "diffHunk": "@@ -0,0 +1,732 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptySet;\n+import static java.util.Collections.singleton;\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.common.utils.Utils.mkSortedSet;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.buildClientRankingsByTask;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.computeBalanceFactor;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.getMovements;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.replay;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.SortedSet;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.Movement;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.RankedClient;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+\n+public class HighAvailabilityTaskAssignorTest {\n+    private long acceptableRecoveryLag = 100L;\n+    private int balanceFactor = 1;\n+    private int maxWarmupReplicas = 2;\n+    private int numStandbyReplicas = 0;\n+    private long probingRebalanceInterval = 60 * 1000L;\n+\n+    private AssignmentConfigs configs;\n+    private Map<String, ClientState> clientStates = new HashMap<>();\n+    private Set<TaskId> allTasks = new HashSet<>();\n+    private Set<TaskId> statefulTasks = new HashSet<>();\n+\n+    private static final TaskId task0_0 = new TaskId(0, 0);\n+    private static final TaskId task0_1 = new TaskId(0, 1);\n+    private static final TaskId task0_2 = new TaskId(0, 2);\n+    private static final TaskId task0_3 = new TaskId(0, 3);\n+    private static final TaskId task1_0 = new TaskId(1, 0);\n+    private static final TaskId task1_1 = new TaskId(1, 1);\n+    private static final TaskId task1_2 = new TaskId(1, 2);\n+    private static final TaskId task1_3 = new TaskId(1, 3);\n+    private static final TaskId task2_0 = new TaskId(2, 0);\n+    private static final TaskId task2_1 = new TaskId(2, 1);\n+    private static final TaskId task2_3 = new TaskId(2, 3);\n+\n+    private static final String String1 = \"client1\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYyMjYwOA=="}, "originalCommit": null, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk5MTk4Ng==", "bodyText": "req: Could you add a test for buildClientRankingsByTask() with an empty set of statefulTasks?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400991986", "createdAt": "2020-03-31T15:10:31Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignorTest.java", "diffHunk": "@@ -0,0 +1,732 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptySet;\n+import static java.util.Collections.singleton;\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.common.utils.Utils.mkSortedSet;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.buildClientRankingsByTask;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.computeBalanceFactor;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.getMovements;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.replay;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.SortedSet;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.Movement;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.RankedClient;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+\n+public class HighAvailabilityTaskAssignorTest {\n+    private long acceptableRecoveryLag = 100L;\n+    private int balanceFactor = 1;\n+    private int maxWarmupReplicas = 2;\n+    private int numStandbyReplicas = 0;\n+    private long probingRebalanceInterval = 60 * 1000L;\n+\n+    private AssignmentConfigs configs;\n+    private Map<String, ClientState> clientStates = new HashMap<>();\n+    private Set<TaskId> allTasks = new HashSet<>();\n+    private Set<TaskId> statefulTasks = new HashSet<>();\n+\n+    private static final TaskId task0_0 = new TaskId(0, 0);\n+    private static final TaskId task0_1 = new TaskId(0, 1);\n+    private static final TaskId task0_2 = new TaskId(0, 2);\n+    private static final TaskId task0_3 = new TaskId(0, 3);\n+    private static final TaskId task1_0 = new TaskId(1, 0);\n+    private static final TaskId task1_1 = new TaskId(1, 1);\n+    private static final TaskId task1_2 = new TaskId(1, 2);\n+    private static final TaskId task1_3 = new TaskId(1, 3);\n+    private static final TaskId task2_0 = new TaskId(2, 0);\n+    private static final TaskId task2_1 = new TaskId(2, 1);\n+    private static final TaskId task2_3 = new TaskId(2, 3);\n+\n+    private static final String String1 = \"client1\";\n+    private static final String String2 = \"client2\";\n+    private static final String String3 = \"client3\";\n+\n+    private ClientState client1;\n+    private ClientState client2;\n+    private ClientState client3;\n+\n+    private static final Set<TaskId> emptyTasks = emptySet();\n+\n+    private HighAvailabilityTaskAssignor<String> taskAssignor;\n+\n+    private void createTaskAssignor() {\n+        configs = new AssignmentConfigs(\n+            acceptableRecoveryLag,\n+            balanceFactor,\n+            maxWarmupReplicas,\n+            numStandbyReplicas,\n+            probingRebalanceInterval\n+        );\n+        taskAssignor = new HighAvailabilityTaskAssignor<>(\n+            clientStates,\n+            allTasks,\n+            statefulTasks,\n+            configs);\n+    }\n+\n+    @Test\n+    public void shouldRankPreviousClientAboveEquallyCaughtUpClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(Task.LATEST_OFFSET);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, Task.LATEST_OFFSET),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankTaskWithUnknownOffsetSumBelowCaughtUpClientAndClientWithLargeLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(UNKNOWN_OFFSET_SUM);\n+        expect(client2.lagFor(task0_0)).andReturn(50L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String2, 0L),\n+            new RankedClient<>(String1, 1L),\n+            new RankedClient<>(String3, 500L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankAllClientsWithinAcceptableRecoveryLagWithRank0() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(100L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, 0L),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankNotCaughtUpClientsAccordingToLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(900L);\n+        expect(client2.lagFor(task0_0)).andReturn(800L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String3, 500L),\n+            new RankedClient<>(String2, 800L),\n+            new RankedClient<>(String1, 900L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk5ODEyNQ==", "bodyText": "req: Could you please add a test that passes two empty assignments to getMovements().", "url": "https://github.com/apache/kafka/pull/8337#discussion_r400998125", "createdAt": "2020-03-31T15:18:22Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignorTest.java", "diffHunk": "@@ -0,0 +1,732 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptySet;\n+import static java.util.Collections.singleton;\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.common.utils.Utils.mkSortedSet;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.buildClientRankingsByTask;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.computeBalanceFactor;\n+import static org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.getMovements;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.replay;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.SortedSet;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.Movement;\n+import org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor.RankedClient;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+\n+public class HighAvailabilityTaskAssignorTest {\n+    private long acceptableRecoveryLag = 100L;\n+    private int balanceFactor = 1;\n+    private int maxWarmupReplicas = 2;\n+    private int numStandbyReplicas = 0;\n+    private long probingRebalanceInterval = 60 * 1000L;\n+\n+    private AssignmentConfigs configs;\n+    private Map<String, ClientState> clientStates = new HashMap<>();\n+    private Set<TaskId> allTasks = new HashSet<>();\n+    private Set<TaskId> statefulTasks = new HashSet<>();\n+\n+    private static final TaskId task0_0 = new TaskId(0, 0);\n+    private static final TaskId task0_1 = new TaskId(0, 1);\n+    private static final TaskId task0_2 = new TaskId(0, 2);\n+    private static final TaskId task0_3 = new TaskId(0, 3);\n+    private static final TaskId task1_0 = new TaskId(1, 0);\n+    private static final TaskId task1_1 = new TaskId(1, 1);\n+    private static final TaskId task1_2 = new TaskId(1, 2);\n+    private static final TaskId task1_3 = new TaskId(1, 3);\n+    private static final TaskId task2_0 = new TaskId(2, 0);\n+    private static final TaskId task2_1 = new TaskId(2, 1);\n+    private static final TaskId task2_3 = new TaskId(2, 3);\n+\n+    private static final String String1 = \"client1\";\n+    private static final String String2 = \"client2\";\n+    private static final String String3 = \"client3\";\n+\n+    private ClientState client1;\n+    private ClientState client2;\n+    private ClientState client3;\n+\n+    private static final Set<TaskId> emptyTasks = emptySet();\n+\n+    private HighAvailabilityTaskAssignor<String> taskAssignor;\n+\n+    private void createTaskAssignor() {\n+        configs = new AssignmentConfigs(\n+            acceptableRecoveryLag,\n+            balanceFactor,\n+            maxWarmupReplicas,\n+            numStandbyReplicas,\n+            probingRebalanceInterval\n+        );\n+        taskAssignor = new HighAvailabilityTaskAssignor<>(\n+            clientStates,\n+            allTasks,\n+            statefulTasks,\n+            configs);\n+    }\n+\n+    @Test\n+    public void shouldRankPreviousClientAboveEquallyCaughtUpClient() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(Task.LATEST_OFFSET);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, Task.LATEST_OFFSET),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankTaskWithUnknownOffsetSumBelowCaughtUpClientAndClientWithLargeLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(UNKNOWN_OFFSET_SUM);\n+        expect(client2.lagFor(task0_0)).andReturn(50L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String2, 0L),\n+            new RankedClient<>(String1, 1L),\n+            new RankedClient<>(String3, 500L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        final SortedSet<RankedClient<String>> clientRanking = statefulTasksToRankedCandidates.get(task0_0);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(clientRanking, equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankAllClientsWithinAcceptableRecoveryLagWithRank0() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(100L);\n+        expect(client2.lagFor(task0_0)).andReturn(0L);\n+        replay(client1, client2);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String1, 0L),\n+            new RankedClient<>(String2, 0L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldRankNotCaughtUpClientsAccordingToLag() {\n+        client1 = EasyMock.createNiceMock(ClientState.class);\n+        client2 = EasyMock.createNiceMock(ClientState.class);\n+        client3 = EasyMock.createNiceMock(ClientState.class);\n+        expect(client1.lagFor(task0_0)).andReturn(900L);\n+        expect(client2.lagFor(task0_0)).andReturn(800L);\n+        expect(client3.lagFor(task0_0)).andReturn(500L);\n+        replay(client1, client2, client3);\n+\n+        final SortedSet<RankedClient<String>> expectedClientRanking = mkSortedSet(\n+            new RankedClient<>(String3, 500L),\n+            new RankedClient<>(String2, 800L),\n+            new RankedClient<>(String1, 900L)\n+        );\n+\n+        final Map<String, ClientState> states = mkMap(\n+            mkEntry(String1, client1),\n+            mkEntry(String2, client2),\n+            mkEntry(String3, client3)\n+        );\n+\n+        final Map<TaskId, SortedSet<RankedClient<String>>> statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(singleton(task0_0), states, acceptableRecoveryLag);\n+\n+        EasyMock.verify(client1, client2, client3);\n+        assertThat(statefulTasksToRankedCandidates.get(task0_0), equalTo(expectedClientRanking));\n+    }\n+\n+    @Test\n+    public void shouldGetMovementsFromStateConstrainedToBalancedAssignment() {\n+        final Map<String, List<TaskId>> stateConstrainedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_2)),\n+            mkEntry(String2, asList(task0_1, task1_0)),\n+            mkEntry(String3, asList(task0_2, task1_1))\n+        );\n+        final Map<String, List<TaskId>> balancedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_0)),\n+            mkEntry(String2, asList(task0_1, task1_1)),\n+            mkEntry(String3, asList(task0_2, task1_2))\n+        );\n+        final Queue<Movement<String>> expectedMovements = new LinkedList<>();\n+        expectedMovements.add(new Movement<>(task1_2, String1, String3));\n+        expectedMovements.add(new Movement<>(task1_0, String2, String1));\n+        expectedMovements.add(new Movement<>(task1_1, String3, String2));\n+\n+        assertThat(getMovements(stateConstrainedAssignment, balancedAssignment), equalTo(expectedMovements));\n+    }\n+\n+    @Test\n+    public void shouldThrowIllegalStateExceptionIfAssignmentsAreOfDifferentSize() {\n+        final Map<String, List<TaskId>> stateConstrainedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task0_1))\n+        );\n+        final Map<String, List<TaskId>> balancedAssignment = mkMap(\n+            mkEntry(String1, asList(task0_0, task1_0)),\n+            mkEntry(String2, asList(task0_1, task1_1))\n+        );\n+        assertThrows(IllegalStateException.class, () -> getMovements(stateConstrainedAssignment, balancedAssignment));\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTAxOTI0OA==", "bodyText": "Q: Why do we only consider stateful tasks in computeBalanceFactor()?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401019248", "createdAt": "2020-03-31T15:45:22Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;\n+                } else if (taskLag == UNKNOWN_OFFSET_SUM) {\n+                    clientRank = 1L;\n+                } else if (taskLag <= acceptableRecoveryLag) {\n+                    clientRank = 0L;\n+                } else {\n+                    clientRank = taskLag;\n+                }\n+                rankedClientCandidates.add(new RankedClient<>(clientId, clientRank));\n+            }\n+        }\n+        log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n+\n+        return statefulTasksToRankedCandidates;\n+    }\n+\n+    /**\n+     * Compute the balance factor as the difference in stateful active task count per thread between the most and\n+     * least loaded clients\n+     */\n+    static int computeBalanceFactor(final Collection<ClientState> clientStates,\n+                                    final Set<TaskId> statefulTasks,\n+                                    final Function<ClientState, Set<TaskId>> activeTaskSet) {\n+        int minActiveStatefulTasksPerThreadCount = Integer.MAX_VALUE;\n+        int maxActiveStatefulTasksPerThreadCount = 0;\n+\n+        for (final ClientState state : clientStates) {\n+            final Set<TaskId> activeTasks = new HashSet<>(activeTaskSet.apply(state));\n+            activeTasks.retainAll(statefulTasks);\n+            final int taskPerThreadCount = activeTasks.size() / state.capacity();\n+            if (taskPerThreadCount < minActiveStatefulTasksPerThreadCount) {\n+                minActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+            if (taskPerThreadCount > maxActiveStatefulTasksPerThreadCount) {\n+                maxActiveStatefulTasksPerThreadCount = taskPerThreadCount;\n+            }\n+        }\n+\n+        return maxActiveStatefulTasksPerThreadCount - minActiveStatefulTasksPerThreadCount;\n+    }\n+\n+    /**\n+     * Determines whether to use the new proposed assignment or just return the group's previous assignment. The\n+     * previous assignment will be chosen and returned iff all of the following are true:\n+     *   1) it satisfies the state constraint, ie all tasks with caught up clients are assigned to one of those clients\n+     *   2) it satisfies the balance factor\n+     *   3) there are no unassigned tasks (eg due to a client that dropped out of the group)\n+     */\n+    private boolean shouldUsePreviousAssignment() {\n+        if (previousAssignmentIsValid()) {\n+            final int previousAssignmentBalanceFactor =\n+                computeBalanceFactor(clientStates.values(), statefulTasks, ClientState::prevActiveTasks);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 353}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTAzNTAzMw==", "bodyText": "Q: There are a lot of methods that are package-private for testing. I would avoid to do that too much. If we feel we need to test sub components of a class then we might want to factor this components out to their own classes that we can test separately. For example, the validation of the previous assignment can be encapsulated into its own class. Does not need to be in this PR, though. WDYT?", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401035033", "createdAt": "2020-03-31T16:06:48Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 217}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MDMyMjI1", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-385032225", "createdAt": "2020-03-31T19:18:41Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOToxODo0MVrOF-kj-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQyMDo0NjowM1rOF-nklw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE1NTA2NQ==", "bodyText": "Well I guess I personally disagree with the checkstyle rules in this one case, but I'll drop it for now", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401155065", "createdAt": "2020-03-31T19:18:41Z", "author": {"login": "ableegoldman"}, "path": "checkstyle/suppressions.xml", "diffHunk": "@@ -208,8 +208,8 @@\n     <suppress checks=\"MethodLength\"\n               files=\"RocksDBWindowStoreTest.java\"/>\n \n-    <suppress checks=\"MemberName\"\n-              files=\"StreamsPartitionAssignorTest.java\"/>\n+    <suppress checks=\"MemberName|ConstantName\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU0NTk2NA=="}, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE1ODY5MQ==", "bodyText": "This was not intentional, sorry I just failed to catch it. IDEA has started doing this automatically recently...I don't want to blame the upgrade to Catalina, but...", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401158691", "createdAt": "2020-03-31T19:24:50Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,25 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor<UUID> taskAssignor;\n+        if (highAvailabilityEnabled) {\n+            if (lagComputationSuccessful) {\n+                taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1NzA0Ng=="}, "originalCommit": null, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE1OTQxMQ==", "bodyText": "Ack", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401159411", "createdAt": "2020-03-31T19:26:10Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,25 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor<UUID> taskAssignor;\n+        if (highAvailabilityEnabled) {\n+            if (lagComputationSuccessful) {\n+                taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks,\n+                    assignmentConfigs);\n+            } else {\n+                taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n+                ((StickyTaskAssignor) taskAssignor).preservePreviousTaskAssignment();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1MDExNA=="}, "originalCommit": null, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2NzI0Ng==", "bodyText": "lagComputationSuccessful was introduced in a previous KIP-441 PR, to address this concern: ableegoldman#2 (comment)", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401167246", "createdAt": "2020-03-31T19:40:10Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,25 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor<UUID> taskAssignor;\n+        if (highAvailabilityEnabled) {\n+            if (lagComputationSuccessful) {\n+                taskAssignor = new HighAvailabilityTaskAssignor<>(clientStates, allTasks, statefulTasks,\n+                    assignmentConfigs);\n+            } else {\n+                taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);\n+                ((StickyTaskAssignor) taskAssignor).preservePreviousTaskAssignment();\n+            }\n+        } else {\n+            taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU0NzQzMg=="}, "originalCommit": null, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2ODY2Mw==", "bodyText": "Ack, thanks", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401168663", "createdAt": "2020-03-31T19:42:46Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MDI2NQ=="}, "originalCommit": null, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE3MzU0MQ==", "bodyText": "Good point, yes it would", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401173541", "createdAt": "2020-03-31T19:51:37Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMTIxNQ=="}, "originalCommit": null, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE4NDMwNg==", "bodyText": "I think we should still prioritize the client that had the active task over one with a caught-up standby. For one thing, with KIP-429 we have to revoke an active task before moving it to a new client in a followup rebalance. This means deadtime for that active task between being closed on one client, waiting for another rebalance, and finally being recreated from a standby on a new client. We also lose the cache, buffers, etc", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401184306", "createdAt": "2020-03-31T20:10:54Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNzQ2MQ=="}, "originalCommit": null, "originalPosition": 302}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE5MTI4NA==", "bodyText": "IDEA will now yell at me for this so you don't have to \ud83d\ude42", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401191284", "createdAt": "2020-03-31T20:22:50Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNjYyNw=="}, "originalCommit": null, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTIwNDM3NQ==", "bodyText": "Refactoring artifact...originally we would also compute the balance factor for the final assignment for some optimization, but I took it out to keep things simple (relatively speaking...). So now this makes no sense, I agree", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401204375", "createdAt": "2020-03-31T20:46:03Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;\n+                } else if (taskLag == UNKNOWN_OFFSET_SUM) {\n+                    clientRank = 1L;\n+                } else if (taskLag <= acceptableRecoveryLag) {\n+                    clientRank = 0L;\n+                } else {\n+                    clientRank = taskLag;\n+                }\n+                rankedClientCandidates.add(new RankedClient<>(clientId, clientRank));\n+            }\n+        }\n+        log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n+\n+        return statefulTasksToRankedCandidates;\n+    }\n+\n+    /**\n+     * Compute the balance factor as the difference in stateful active task count per thread between the most and\n+     * least loaded clients\n+     */\n+    static int computeBalanceFactor(final Collection<ClientState> clientStates,\n+                                    final Set<TaskId> statefulTasks,\n+                                    final Function<ClientState, Set<TaskId>> activeTaskSet) {\n+        int minActiveStatefulTasksPerThreadCount = Integer.MAX_VALUE;\n+        int maxActiveStatefulTasksPerThreadCount = 0;\n+\n+        for (final ClientState state : clientStates) {\n+            final Set<TaskId> activeTasks = new HashSet<>(activeTaskSet.apply(state));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwODc2OA=="}, "originalCommit": null, "originalPosition": 329}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MTI2MjI3", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-385126227", "createdAt": "2020-03-31T21:42:56Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQyMTo0Mjo1NlrOF-pUZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQyMTo0Njo0OVrOF-pbbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTIzMjk5Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs, false);\n          \n          \n            \n                        taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs, !lagComputationSuccessful);\n          \n      \n    \n    \n  \n\nIt still seems like this is necessary to preserve the agreed on approach to ableegoldman#2 (comment)", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401232997", "createdAt": "2020-03-31T21:42:56Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -748,24 +702,27 @@ private void assignTasksToClients(final Set<String> allSourceTopics,\n         final boolean lagComputationSuccessful =\n             populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogsByStatefulTask);\n \n-        // assign tasks to clients\n         final Set<TaskId> allTasks = partitionsForTask.keySet();\n-        final Set<TaskId> standbyTasks = changelogsByStatefulTask.keySet();\n-\n-        if (lagComputationSuccessful) {\n-            final Map<TaskId, SortedSet<RankedClient<UUID>>> statefulTasksToRankedCandidates =\n-                buildClientRankingsByTask(standbyTasks, clientStates, acceptableRecoveryLag());\n-            log.trace(\"Computed statefulTasksToRankedCandidates map as {}\", statefulTasksToRankedCandidates);\n-        }\n+        final Set<TaskId> statefulTasks = changelogsByStatefulTask.keySet();\n \n         log.debug(\"Assigning tasks {} to clients {} with number of replicas {}\",\n             allTasks, clientStates, numStandbyReplicas());\n \n-        final StickyTaskAssignor<UUID> taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, standbyTasks);\n-        if (!lagComputationSuccessful) {\n-            taskAssignor.preservePreviousTaskAssignment();\n+        final TaskAssignor<UUID> taskAssignor;\n+        if (highAvailabilityEnabled) {\n+            if (lagComputationSuccessful) {\n+                taskAssignor = new HighAvailabilityTaskAssignor<>(\n+                    clientStates,\n+                    allTasks,\n+                    statefulTasks,\n+                    assignmentConfigs);\n+            } else {\n+                taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs, true);\n+            }\n+        } else {\n+            taskAssignor = new StickyTaskAssignor<>(clientStates, allTasks, statefulTasks, assignmentConfigs, false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTIzNDc5OQ==", "bodyText": "That's fair. My concern about the impact was whether it results in non-termination of the probing rebalance cycle, if we always prefer to re-assign the prior active and always propose to move the task to the same caught-up standby, but never consider just giving the active to the caught-up standby, since there is a prior active.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401234799", "createdAt": "2020-03-31T21:46:49Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.Queue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                 final Set<TaskId> allTasks,\n+                                 final Set<TaskId> statefulTasks,\n+                                 final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+                new DefaultBalancedAssignor<ID>().assign(\n+                    sortedClients,\n+                    statefulTasks,\n+                    clientsToNumberOfThreads,\n+                    configs.balanceFactor);\n+\n+        final Queue<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment);\n+        for (int numWarmupReplicas = 0; numWarmupReplicas < configs.maxWarmupReplicas; ++numWarmupReplicas) {\n+            final Movement<ID> movement = movements.poll();\n+            if (movement == null) {\n+                break;\n+            }\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }\n+\n+        // ---------------- Standby Replica Tasks ---------------- //\n+\n+        final List<Map<ID, List<TaskId>>> allStatefulTaskAssignments = asList(\n+            statefulActiveTaskAssignment,\n+            warmupTaskAssignment,\n+            standbyTaskAssignment\n+        );\n+        final ClientValidatingPriorityQueue<ID> standbyTaskClientsQueue =\n+            new ClientValidatingPriorityQueue<>(\n+                configs.numStandbyReplicas,\n+                getClientPriorityQueueByTaskLoad(asList(warmupTaskAssignment, standbyTaskAssignment)),\n+                allStatefulTaskAssignments\n+            );\n+\n+        for (final TaskId task : statefulTasksToRankedCandidates.keySet()) {\n+            final List<ID> clients = standbyTaskClientsQueue.poll(task);\n+            for (final ID client : clients) {\n+                standbyTaskAssignment.get(client).add(task);\n+            }\n+            final int numStandbysAssigned = clients.size();\n+            if (numStandbysAssigned < configs.numStandbyReplicas) {\n+                log.warn(\"Unable to assign {} of {} standby tasks for task [{}]. \" +\n+                             \"There is not enough available capacity. You should \" +\n+                             \"increase the number of threads and/or application instances \" +\n+                             \"to maintain the requested number of standby replicas.\",\n+                    configs.numStandbyReplicas - numStandbysAssigned, configs.numStandbyReplicas, task);\n+            }\n+        }\n+\n+        // ---------------- Stateless Active Tasks ---------------- //\n+\n+        final PriorityQueue<ID> statelessActiveTaskClientsQueue =\n+            getClientPriorityQueueByTaskLoad(asList(statefulActiveTaskAssignment, statelessActiveTaskAssignment));\n+\n+        for (final TaskId task : statelessTasks) {\n+            final ID client = statelessActiveTaskClientsQueue.poll();\n+            statelessActiveTaskAssignment.get(client).add(task);\n+            statelessActiveTaskClientsQueue.offer(client);\n+        }\n+\n+        // ---------------- Assign Tasks To Clients ---------------- //\n+\n+        final boolean followupRebalanceRequired;\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            followupRebalanceRequired = false;\n+        } else {\n+            assignActiveTasksToClients(statefulActiveTaskAssignment);\n+            assignStandbyTasksToClients(warmupTaskAssignment);\n+            assignStandbyTasksToClients(standbyTaskAssignment);\n+            assignActiveTasksToClients(statelessActiveTaskAssignment);\n+\n+            followupRebalanceRequired = warmupTaskAssignment.entrySet().stream().anyMatch(tasks -> !tasks.getValue().isEmpty());\n+        }\n+        return followupRebalanceRequired;\n+    }\n+\n+    /**\n+     * Returns a list of the movements of tasks from statefulActiveTaskAssignment to balancedStatefulActiveTaskAssignment\n+     * @param statefulActiveTaskAssignment the initial assignment, with source clients\n+     * @param balancedStatefulActiveTaskAssignment the final assignment, with destination clients\n+     */\n+    static <ID> Queue<Movement<ID>> getMovements(final Map<ID, List<TaskId>> statefulActiveTaskAssignment,\n+                                                 final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment) {\n+        if (statefulActiveTaskAssignment.size() != balancedStatefulActiveTaskAssignment.size()) {\n+            throw new IllegalStateException(\"Tried to compute movements but assignments differ in size.\");\n+        }\n+\n+        final Map<TaskId, ID> taskToDestinationClient = new HashMap<>();\n+        for (final Map.Entry<ID, List<TaskId>> clientEntry : balancedStatefulActiveTaskAssignment.entrySet()) {\n+            final ID destination = clientEntry.getKey();\n+            for (final TaskId task : clientEntry.getValue()) {\n+                taskToDestinationClient.put(task, destination);\n+            }\n+        }\n+\n+        final Queue<Movement<ID>> movements = new LinkedList<>();\n+        for (final Map.Entry<ID, List<TaskId>> sourceClientEntry : statefulActiveTaskAssignment.entrySet()) {\n+            final ID source = sourceClientEntry.getKey();\n+\n+            for (final TaskId task : sourceClientEntry.getValue()) {\n+                final ID destination = taskToDestinationClient.get(task);\n+                if (destination == null) {\n+                    log.error(\"Task {} is assigned to client {} in initial assignment but has no owner in the final \" +\n+                                  \"balanced assignment.\", task, source);\n+                    throw new IllegalStateException(\"Found task in initial assignment that was not assigned in the final.\");\n+                } else if (source != destination) {\n+                    movements.add(new Movement<>(task, source, destination));\n+                }\n+            }\n+        }\n+        return movements;\n+    }\n+\n+    /**\n+     * @return true iff all active tasks with caught-up client are assigned to one of them, and all tasks are assigned\n+     */\n+    boolean previousAssignmentIsValid() {\n+        final Set<TaskId> unassignedActiveTasks = new HashSet<>(allTasks);\n+        final Map<TaskId, Integer> unassignedStandbyTasks =\n+            configs.numStandbyReplicas == 0 ?\n+                Collections.emptyMap() :\n+                new HashMap<>(statefulTasksToRankedCandidates.keySet().stream()\n+                                  .collect(Collectors.toMap(task -> task, task -> configs.numStandbyReplicas)));\n+\n+        for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+            final ID client = clientEntry.getKey();\n+            final ClientState state = clientEntry.getValue();\n+            final Set<TaskId> prevActiveTasks = state.prevActiveTasks();\n+\n+            // Verify that this client was caught-up on all stateful active tasks\n+            for (final TaskId activeTask : prevActiveTasks) {\n+                if (!taskIsCaughtUpOnClient(activeTask, client)) {\n+                    return false;\n+                }\n+            }\n+            unassignedActiveTasks.removeAll(prevActiveTasks);\n+\n+            if (!unassignedStandbyTasks.isEmpty()) {\n+                for (final TaskId task : state.prevStandbyTasks()) {\n+                    final Integer remainingStandbys = unassignedStandbyTasks.get(task);\n+                    if (remainingStandbys != null) {\n+                        if (remainingStandbys == 1) {\n+                            unassignedStandbyTasks.remove(task);\n+                        } else {\n+                            unassignedStandbyTasks.put(task, remainingStandbys - 1);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        return unassignedActiveTasks.isEmpty() && unassignedStandbyTasks.isEmpty();\n+    }\n+\n+    /**\n+     * @return true if this client is caught-up for this task, or the task has no caught-up clients\n+     */\n+    boolean taskIsCaughtUpOnClient(final TaskId task, final ID client) {\n+        boolean hasNoCaughtUpClients = true;\n+        final SortedSet<RankedClient<ID>> rankedClients = statefulTasksToRankedCandidates.get(task);\n+        if (rankedClients == null) {\n+            return true;\n+        }\n+        for (final RankedClient rankedClient : rankedClients) {\n+            if (rankedClient.rank() <= 0L) {\n+                if (rankedClient.clientId().equals(client)) {\n+                    return true;\n+                } else {\n+                    hasNoCaughtUpClients = false;\n+                }\n+            }\n+\n+            // If we haven't found our client yet, it must not be caught-up\n+            if (rankedClient.rank() > 0L) {\n+                break;\n+            }\n+        }\n+        return hasNoCaughtUpClients;\n+    }\n+\n+    /**\n+     * Rankings are computed as follows, with lower being more caught up:\n+     *      Rank -1: active running task\n+     *      Rank 0: standby or restoring task whose overall lag is within the acceptableRecoveryLag bounds\n+     *      Rank 1: tasks whose lag is unknown, eg because it was not encoded in an older version subscription\n+     *      Rank 1+: all other tasks are ranked according to their actual total lag\n+     * @return Sorted set of all client candidates for each stateful task, ranked by their overall lag. Tasks are\n+     */\n+    static <ID extends Comparable<ID>> SortedMap<TaskId, SortedSet<RankedClient<ID>>> buildClientRankingsByTask(final Set<TaskId> statefulTasks,\n+                                                                                                                final Map<ID, ClientState> clientStates,\n+                                                                                                                final long acceptableRecoveryLag) {\n+        final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates = new TreeMap<>();\n+\n+        for (final TaskId task : statefulTasks) {\n+            final SortedSet<RankedClient<ID>> rankedClientCandidates = new TreeSet<>();\n+            statefulTasksToRankedCandidates.put(task, rankedClientCandidates);\n+\n+            for (final Map.Entry<ID, ClientState> clientEntry : clientStates.entrySet()) {\n+                final ID clientId = clientEntry.getKey();\n+                final long taskLag = clientEntry.getValue().lagFor(task);\n+                final long clientRank;\n+                if (taskLag == Task.LATEST_OFFSET) {\n+                    clientRank = Task.LATEST_OFFSET;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNzQ2MQ=="}, "originalCommit": null, "originalPosition": 302}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MzE0MjA2", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-385314206", "createdAt": "2020-04-01T07:06:29Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzowNjoyOVrOF-zYeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzowNjoyOVrOF-zYeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM5Nzg4Mg==", "bodyText": "Q: IIUC, we do not check if the movement is for free. That is, if the destination is a caught-up client. If it were we would not need to assign a warm-up replica and could consider one more movement. I am also fine with post-poning that to a follow-up PR.", "url": "https://github.com/apache/kafka/pull/8337#discussion_r401397882", "createdAt": "2020-04-01T07:06:29Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java", "diffHunk": "@@ -0,0 +1,548 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.assignment;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.UNKNOWN_OFFSET_SUM;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.PriorityQueue;\n+import java.util.SortedMap;\n+import java.util.SortedSet;\n+import java.util.TreeMap;\n+import java.util.TreeSet;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.Task;\n+import org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration.AssignmentConfigs;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+import java.util.Set;\n+\n+public class HighAvailabilityTaskAssignor<ID extends Comparable<ID>> implements TaskAssignor<ID> {\n+    private static final Logger log = LoggerFactory.getLogger(HighAvailabilityTaskAssignor.class);\n+\n+    private final Map<ID, ClientState> clientStates;\n+    private final Map<ID, Integer> clientsToNumberOfThreads;\n+    private final SortedSet<ID> sortedClients;\n+\n+    private final Set<TaskId> allTasks;\n+    private final SortedSet<TaskId> statefulTasks;\n+    private final SortedSet<TaskId> statelessTasks;\n+\n+    private final AssignmentConfigs configs;\n+\n+    private final SortedMap<TaskId, SortedSet<RankedClient<ID>>> statefulTasksToRankedCandidates;\n+\n+    public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates,\n+                                        final Set<TaskId> allTasks,\n+                                        final Set<TaskId> statefulTasks,\n+                                        final AssignmentConfigs configs) {\n+        this.configs = configs;\n+        this.clientStates = clientStates;\n+        this.allTasks = allTasks;\n+        this.statefulTasks = new TreeSet<>(statefulTasks);\n+\n+        statelessTasks = new TreeSet<>(allTasks);\n+        statelessTasks.removeAll(statefulTasks);\n+\n+        sortedClients = new TreeSet<>();\n+        clientsToNumberOfThreads = new HashMap<>();\n+        clientStates.forEach((client, state) -> {\n+            sortedClients.add(client);\n+            clientsToNumberOfThreads.put(client, state.capacity());\n+        });\n+\n+        statefulTasksToRankedCandidates =\n+            buildClientRankingsByTask(statefulTasks, clientStates, configs.acceptableRecoveryLag);\n+    }\n+\n+    @Override\n+    public boolean assign() {\n+        if (shouldUsePreviousAssignment()) {\n+            assignPreviousTasksToClientStates();\n+            return false;\n+        }\n+\n+        final Map<ID, List<TaskId>> warmupTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> standbyTaskAssignment = initializeEmptyTaskAssignmentMap();\n+        final Map<ID, List<TaskId>> statelessActiveTaskAssignment = initializeEmptyTaskAssignmentMap();\n+\n+        // ---------------- Stateful Active Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> statefulActiveTaskAssignment =\n+            new DefaultStateConstrainedBalancedAssignor<ID>().assign(\n+                statefulTasksToRankedCandidates,\n+                configs.balanceFactor,\n+                sortedClients,\n+                clientsToNumberOfThreads\n+            );\n+\n+        // ---------------- Warmup Replica Tasks ---------------- //\n+\n+        final Map<ID, List<TaskId>> balancedStatefulActiveTaskAssignment =\n+            new DefaultBalancedAssignor<ID>().assign(\n+                sortedClients,\n+                statefulTasks,\n+                clientsToNumberOfThreads,\n+                configs.balanceFactor);\n+\n+        final List<Movement<ID>> movements =\n+            getMovements(statefulActiveTaskAssignment, balancedStatefulActiveTaskAssignment,\n+                configs.maxWarmupReplicas);\n+        for (final Movement<ID> movement : movements) {\n+            warmupTaskAssignment.get(movement.destination).add(movement.task);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 118}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d9d9a3816c0c17c8148912175888d4ce236a831", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/8d9d9a3816c0c17c8148912175888d4ce236a831", "committedDate": "2020-04-01T19:32:50Z", "message": "move assignment and client/task building to new assignor implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ece72fca09df0f9dbb19e050bc72c93bfa411d35", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/ece72fca09df0f9dbb19e050bc72c93bfa411d35", "committedDate": "2020-04-01T19:32:50Z", "message": "Fill in standby task assignment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "faf06e7dbd8839e80a733d703dadc04786242d18", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/faf06e7dbd8839e80a733d703dadc04786242d18", "committedDate": "2020-04-01T19:32:50Z", "message": "implementation done"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ce8cd44bfa05c41cbf628abbbd7ac529118841a", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/2ce8cd44bfa05c41cbf628abbbd7ac529118841a", "committedDate": "2020-04-01T19:32:50Z", "message": "adding tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4521cc4facb719bf496195673c5f8962c301a7d", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/b4521cc4facb719bf496195673c5f8962c301a7d", "committedDate": "2020-04-01T19:32:50Z", "message": "include statefulactvietaskassignment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5044890a888814c33591b50a10139e0f58d36f92", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/5044890a888814c33591b50a10139e0f58d36f92", "committedDate": "2020-04-01T19:32:50Z", "message": "undo some refactoring, save for followup work"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "236c5bbde33fec2b2b318a5331ee83000022d1ba", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/236c5bbde33fec2b2b318a5331ee83000022d1ba", "committedDate": "2020-04-01T19:32:50Z", "message": "should just mock the client state class already.."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3cab7a00d1076add7353a5771f17a4021dd8b2f", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/a3cab7a00d1076add7353a5771f17a4021dd8b2f", "committedDate": "2020-04-01T19:32:50Z", "message": "filling in more tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0071afb1a3fb6895c29a5ec8dfba050b72afd51d", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/0071afb1a3fb6895c29a5ec8dfba050b72afd51d", "committedDate": "2020-04-01T19:32:50Z", "message": "adding even more tasks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5f033ac0e6d332ed8496ec3b993f362586e3ac6", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f5f033ac0e6d332ed8496ec3b993f362586e3ac6", "committedDate": "2020-04-01T19:32:50Z", "message": "initial github review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e82e0ee4fd09438007390649ba8b50c90597c85", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/3e82e0ee4fd09438007390649ba8b50c90597c85", "committedDate": "2020-04-01T19:32:50Z", "message": "enforce ordering in ClientState"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce659074ee4e26c2840f987dd2b9112561460f23", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/ce659074ee4e26c2840f987dd2b9112561460f23", "committedDate": "2020-04-01T19:32:50Z", "message": "fix sticky task assignor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4fd2310381dc4d151a570cf4700b6e3d3ecb3296", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/4fd2310381dc4d151a570cf4700b6e3d3ecb3296", "committedDate": "2020-04-01T19:32:50Z", "message": "use string instead of UUID for consistent ordering"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e67771d3c78221a6d94f38ee56172b0030ca97c7", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/e67771d3c78221a6d94f38ee56172b0030ca97c7", "committedDate": "2020-04-01T19:32:50Z", "message": "fix condition for triggering followup rebalance"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8923d638319ff275cd8ae378fe130bfd68d95aab", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/8923d638319ff275cd8ae378fe130bfd68d95aab", "committedDate": "2020-04-01T19:32:50Z", "message": "checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a50a39a8c9e1d27352a4c872511021c72dec12c", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/9a50a39a8c9e1d27352a4c872511021c72dec12c", "committedDate": "2020-04-01T19:32:50Z", "message": "fix condition"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e03619ca7dfa8eb4ba4d173d66b2fe95063d522", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/6e03619ca7dfa8eb4ba4d173d66b2fe95063d522", "committedDate": "2020-04-01T19:32:50Z", "message": "fix internal config"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88bbe6f1185efd11a52321b12178185e0c0e10a6", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/88bbe6f1185efd11a52321b12178185e0c0e10a6", "committedDate": "2020-04-01T19:32:50Z", "message": "first set of PR review changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "923c1fb774da17c9f67ab08602497504de891c74", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/923c1fb774da17c9f67ab08602497504de891c74", "committedDate": "2020-04-01T19:32:50Z", "message": "fixup tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74b30d18115a0279376c1a0e4afbd5caab4722d4", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/74b30d18115a0279376c1a0e4afbd5caab4722d4", "committedDate": "2020-04-01T19:32:50Z", "message": "remaining github comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f473f60b99f3b3b2f549b5ae48b2be01fc5cf461", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f473f60b99f3b3b2f549b5ae48b2be01fc5cf461", "committedDate": "2020-04-01T19:32:51Z", "message": "use generated code"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "f473f60b99f3b3b2f549b5ae48b2be01fc5cf461", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/f473f60b99f3b3b2f549b5ae48b2be01fc5cf461", "committedDate": "2020-04-01T19:32:51Z", "message": "use generated code"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1OTY5OTM1", "url": "https://github.com/apache/kafka/pull/8337#pullrequestreview-385969935", "createdAt": "2020-04-01T21:41:35Z", "commit": {"oid": "f473f60b99f3b3b2f549b5ae48b2be01fc5cf461"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1632, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}