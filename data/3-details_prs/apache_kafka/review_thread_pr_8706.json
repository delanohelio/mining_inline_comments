{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIxMjkyMDM3", "number": 8706, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxODoyMTo0MVrOD-s5Lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMzo0MToyMVrOEBESDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MDczODM5OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxODoyMTo0MVrOGY9xsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQyMDozNToyOVrOGZB8Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODgzMTE1Mg==", "bodyText": "We should write a proper test case instead of \"piggy-backing\" it into an existing test.", "url": "https://github.com/apache/kafka/pull/8706#discussion_r428831152", "createdAt": "2020-05-21T18:21:41Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -332,6 +332,7 @@ private Properties streamsConfiguration() {\n         config.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 200);\n         config.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 1000);\n         config.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n+        config.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "891abd9e8d70bc08892b9f61ab081acf9befed31"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg5OTM4Mw==", "bodyText": "Added dedicated test", "url": "https://github.com/apache/kafka/pull/8706#discussion_r428899383", "createdAt": "2020-05-21T20:35:29Z", "author": {"login": "dima5rr"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -332,6 +332,7 @@ private Properties streamsConfiguration() {\n         config.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 200);\n         config.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 1000);\n         config.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n+        config.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODgzMTE1Mg=="}, "originalCommit": {"oid": "891abd9e8d70bc08892b9f61ab081acf9befed31"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NTAyNzEyOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yM1QwNTowNzozMlrOGZnhYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yM1QxODoyNzoyMFrOGZqvKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUxNTEwNg==", "bodyText": "stale stores \"are\" not enabled?", "url": "https://github.com/apache/kafka/pull/8706#discussion_r429515106", "createdAt": "2020-05-23T05:07:32Z", "author": {"login": "brary"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -296,6 +297,87 @@ public void shouldQuerySpecificStalePartitionStores() throws Exception {\n         assertThat(store4.get(key), is(nullValue()));\n     }\n \n+    @Test\n+    public void shouldQuerySpecificActivePartitionStoresMultiStreamThreads() throws Exception {\n+        final int batch1NumMessages = 100;\n+        final int key = 1;\n+        final Semaphore semaphore = new Semaphore(0);\n+        final int numStreamThreads = 2;\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n+                Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n+                        .withCachingDisabled())\n+                .toStream()\n+                .peek((k, v) -> semaphore.release());\n+\n+        final Properties streamsConfiguration1 = streamsConfiguration();\n+        streamsConfiguration1.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final Properties streamsConfiguration2 = streamsConfiguration();\n+        streamsConfiguration2.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration1);\n+        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration2);\n+        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n+\n+        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n+\n+        assertTrue(numStreamThreads > 1);\n+        assertTrue(kafkaStreams1.localThreadsMetadata().size() > 1);\n+        assertTrue(kafkaStreams2.localThreadsMetadata().size() > 1);\n+\n+        produceValueRange(key, 0, batch1NumMessages);\n+\n+        // Assert that all messages in the first batch were processed in a timely manner\n+        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n+        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, new IntegerSerializer());\n+\n+        //key belongs to this partition\n+        final int keyPartition = keyQueryMetadata.getPartition();\n+\n+        //key doesn't belongs to this partition\n+        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n+        final boolean kafkaStreams1IsActive = (keyQueryMetadata.getActiveHost().port() % 2) == 1;\n+\n+        StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n+                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n+                        .withPartition(keyPartition);\n+        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n+        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n+        if (kafkaStreams1IsActive) {\n+            store1 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n+        } else {\n+            store2 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n+        }\n+\n+        if (kafkaStreams1IsActive) {\n+            assertThat(store1, is(notNullValue()));\n+            assertThat(store2, is(nullValue()));\n+        } else {\n+            assertThat(store2, is(notNullValue()));\n+            assertThat(store1, is(nullValue()));\n+        }\n+\n+        // Assert that only active for a specific requested partition serves key if stale stores and not enabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3fd8aff27c7370a851469e3ee9f2990a124172fd"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU2Nzc4NA==", "bodyText": "correct, changed test to check both store types", "url": "https://github.com/apache/kafka/pull/8706#discussion_r429567784", "createdAt": "2020-05-23T18:27:20Z", "author": {"login": "dima5rr"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -296,6 +297,87 @@ public void shouldQuerySpecificStalePartitionStores() throws Exception {\n         assertThat(store4.get(key), is(nullValue()));\n     }\n \n+    @Test\n+    public void shouldQuerySpecificActivePartitionStoresMultiStreamThreads() throws Exception {\n+        final int batch1NumMessages = 100;\n+        final int key = 1;\n+        final Semaphore semaphore = new Semaphore(0);\n+        final int numStreamThreads = 2;\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n+                Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n+                        .withCachingDisabled())\n+                .toStream()\n+                .peek((k, v) -> semaphore.release());\n+\n+        final Properties streamsConfiguration1 = streamsConfiguration();\n+        streamsConfiguration1.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final Properties streamsConfiguration2 = streamsConfiguration();\n+        streamsConfiguration2.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration1);\n+        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration2);\n+        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n+\n+        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n+\n+        assertTrue(numStreamThreads > 1);\n+        assertTrue(kafkaStreams1.localThreadsMetadata().size() > 1);\n+        assertTrue(kafkaStreams2.localThreadsMetadata().size() > 1);\n+\n+        produceValueRange(key, 0, batch1NumMessages);\n+\n+        // Assert that all messages in the first batch were processed in a timely manner\n+        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n+        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, new IntegerSerializer());\n+\n+        //key belongs to this partition\n+        final int keyPartition = keyQueryMetadata.getPartition();\n+\n+        //key doesn't belongs to this partition\n+        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n+        final boolean kafkaStreams1IsActive = (keyQueryMetadata.getActiveHost().port() % 2) == 1;\n+\n+        StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n+                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n+                        .withPartition(keyPartition);\n+        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n+        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n+        if (kafkaStreams1IsActive) {\n+            store1 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n+        } else {\n+            store2 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n+        }\n+\n+        if (kafkaStreams1IsActive) {\n+            assertThat(store1, is(notNullValue()));\n+            assertThat(store2, is(nullValue()));\n+        } else {\n+            assertThat(store2, is(notNullValue()));\n+            assertThat(store1, is(nullValue()));\n+        }\n+\n+        // Assert that only active for a specific requested partition serves key if stale stores and not enabled", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUxNTEwNg=="}, "originalCommit": {"oid": "3fd8aff27c7370a851469e3ee9f2990a124172fd"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjczNjQ4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/QueryableStoreProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxODozNzowOFrOGbYJZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQwOTowMDo1MFrOGbsGCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM2MDM1Nw==", "bodyText": "We should extend QueryableStoreProviderTest for this case -- throwing this exception moves from StreamThreadStateStoreProvider to here and we should not just remove the test from StreamThreadStateStoreProviderTest but add a new one to QueryableStoreProviderTest, too.", "url": "https://github.com/apache/kafka/pull/8706#discussion_r431360357", "createdAt": "2020-05-27T18:37:08Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/QueryableStoreProvider.java", "diffHunk": "@@ -58,9 +58,21 @@ public QueryableStoreProvider(final List<StreamThreadStateStoreProvider> storePr\n         }\n         final List<T> allStores = new ArrayList<>();\n         for (final StreamThreadStateStoreProvider storeProvider : storeProviders) {\n-            allStores.addAll(storeProvider.stores(storeQueryParameters));\n+            final List<T> stores = storeProvider.stores(storeQueryParameters);\n+            if (stores != null && !stores.isEmpty()) {\n+                allStores.addAll(stores);\n+                if (storeQueryParameters.partition() != null) {\n+                    break;\n+                }\n+            }\n         }\n         if (allStores.isEmpty()) {\n+            if (storeQueryParameters.partition() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8e956159426a1c0ede7122a3c87ab489d7487b0"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTY4NzE3OQ==", "bodyText": "I extended StateStoreProviderStub functionality to add store by partition with default partition 0, + relevant tests in QueryableStoreProviderTest", "url": "https://github.com/apache/kafka/pull/8706#discussion_r431687179", "createdAt": "2020-05-28T09:00:50Z", "author": {"login": "dima5rr"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/QueryableStoreProvider.java", "diffHunk": "@@ -58,9 +58,21 @@ public QueryableStoreProvider(final List<StreamThreadStateStoreProvider> storePr\n         }\n         final List<T> allStores = new ArrayList<>();\n         for (final StreamThreadStateStoreProvider storeProvider : storeProviders) {\n-            allStores.addAll(storeProvider.stores(storeQueryParameters));\n+            final List<T> stores = storeProvider.stores(storeQueryParameters);\n+            if (stores != null && !stores.isEmpty()) {\n+                allStores.addAll(stores);\n+                if (storeQueryParameters.partition() != null) {\n+                    break;\n+                }\n+            }\n         }\n         if (allStores.isEmpty()) {\n+            if (storeQueryParameters.partition() != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM2MDM1Nw=="}, "originalCommit": {"oid": "c8e956159426a1c0ede7122a3c87ab489d7487b0"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Njc0MzM0OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxODozOToxN1rOGbYNzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxODozOToxN1rOGbYNzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM2MTQ4NQ==", "bodyText": "numStreamThreads is a final variable -> assertion can be removed", "url": "https://github.com/apache/kafka/pull/8706#discussion_r431361485", "createdAt": "2020-05-27T18:39:17Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java", "diffHunk": "@@ -296,6 +289,75 @@ public void shouldQuerySpecificStalePartitionStores() throws Exception {\n         assertThat(store4.get(key), is(nullValue()));\n     }\n \n+    @Test\n+    public void shouldQuerySpecificStalePartitionStoresMultiStreamThreads() throws Exception {\n+        final int batch1NumMessages = 100;\n+        final int key = 1;\n+        final Semaphore semaphore = new Semaphore(0);\n+        final int numStreamThreads = 2;\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n+                Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n+                        .withCachingDisabled())\n+                .toStream()\n+                .peek((k, v) -> semaphore.release());\n+\n+        final Properties streamsConfiguration1 = streamsConfiguration();\n+        streamsConfiguration1.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final Properties streamsConfiguration2 = streamsConfiguration();\n+        streamsConfiguration2.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, numStreamThreads);\n+\n+        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration1);\n+        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration2);\n+        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n+\n+        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n+\n+        assertTrue(numStreamThreads > 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8e956159426a1c0ede7122a3c87ab489d7487b0"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MTU2OTUzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/QueryableStoreProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMTo1MTo0NlrOGcIA4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMTo1MTo0NlrOGcIA4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NDYxMA==", "bodyText": "Thinking about this one more, stores can never be null? Can we remove this check?", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432144610", "createdAt": "2020-05-28T21:51:46Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/QueryableStoreProvider.java", "diffHunk": "@@ -58,9 +58,21 @@ public QueryableStoreProvider(final List<StreamThreadStateStoreProvider> storePr\n         }\n         final List<T> allStores = new ArrayList<>();\n         for (final StreamThreadStateStoreProvider storeProvider : storeProviders) {\n-            allStores.addAll(storeProvider.stores(storeQueryParameters));\n+            final List<T> stores = storeProvider.stores(storeQueryParameters);\n+            if (stores != null && !stores.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MTU3MjcwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/WrappingStoreProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMTo1MzowMlrOGcIC4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMTo1MzowMlrOGcIC4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NTEyMQ==", "bodyText": "As above: stores should never be null, and thus we don't need this change? Also the check for isEmpty does give us much, we can still call addAll even it stores is empty?", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432145121", "createdAt": "2020-05-28T21:53:02Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/WrappingStoreProvider.java", "diffHunk": "@@ -48,7 +48,9 @@ public void setStoreQueryParameters(final StoreQueryParameters storeQueryParamet\n         final List<T> allStores = new ArrayList<>();\n         for (final StreamThreadStateStoreProvider provider : storeProviders) {\n             final List<T> stores = provider.stores(storeQueryParameters);\n-            allStores.addAll(stores);\n+            if (stores != null && !stores.isEmpty()) {\n+                allStores.addAll(stores);\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MTU4MTYzOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/QueryableStoreProviderTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMTo1NjoxMlrOGcIISQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxODo0NToxNFrOGcoJ_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NjUwNQ==", "bodyText": "It might be better to test if the right store is returned instead of just checking for not-null? For this, in before() we need to get a reference on the store we pass into addStore()?", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432146505", "createdAt": "2020-05-28T21:56:12Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/QueryableStoreProviderTest.java", "diffHunk": "@@ -88,5 +91,23 @@ public void shouldFindGlobalStores() {\n         assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(\"global\", QueryableStoreTypes.keyValueStore())));\n     }\n \n+    @Test\n+    public void shouldReturnKVStoreWithPartitionWhenItExists() {\n+        assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions - 1)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjM5MzQ1OQ==", "bodyText": "I think how to validate returned store reference, QueryableStoreProvider always wraps it in CompositeReadOnlyKeyValueStore?", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432393459", "createdAt": "2020-05-29T10:22:08Z", "author": {"login": "dima5rr"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/QueryableStoreProviderTest.java", "diffHunk": "@@ -88,5 +91,23 @@ public void shouldFindGlobalStores() {\n         assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(\"global\", QueryableStoreTypes.keyValueStore())));\n     }\n \n+    @Test\n+    public void shouldReturnKVStoreWithPartitionWhenItExists() {\n+        assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions - 1)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NjUwNQ=="}, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY3MTIyOQ==", "bodyText": "Hmmm... Good point. Let leave it as-is. It's also covered in integration tests that the right store is returned.", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432671229", "createdAt": "2020-05-29T18:45:14Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/QueryableStoreProviderTest.java", "diffHunk": "@@ -88,5 +91,23 @@ public void shouldFindGlobalStores() {\n         assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(\"global\", QueryableStoreTypes.keyValueStore())));\n     }\n \n+    @Test\n+    public void shouldReturnKVStoreWithPartitionWhenItExists() {\n+        assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions - 1)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0NjUwNQ=="}, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MTU5NTM4OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/QueryableStoreProviderTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMjowMToyM1rOGcIRFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMjowMToyM1rOGcIRFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0ODc1Ng==", "bodyText": "Can we split this as follows:\nfinal StoreQueryParameters parameters = (StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions + 1);\n\nfinal InvalidStateStoreException exception = asserThrows(\n  InvalidStateStoreException.class,\n  () -> storeProvider.getStore(parameters)\n);\nassertThat(exception.message(), equalTo(\"...\"));\n\nAnd remove the (excpected = ...) annotation.\n(1) We should always limit the code that might throw the exception (eg, if withPartition would throw an InvalidStateStoreException the test should fail, but would pass in it's current setup) (2) We should always verify the exception cause -- getStore() could throw an InvalidStateStoreException or multiple reasons and we should make sure it's throwing for the reason under test.\nSame below for the windowed case", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432148756", "createdAt": "2020-05-28T22:01:23Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/QueryableStoreProviderTest.java", "diffHunk": "@@ -88,5 +91,23 @@ public void shouldFindGlobalStores() {\n         assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(\"global\", QueryableStoreTypes.keyValueStore())));\n     }\n \n+    @Test\n+    public void shouldReturnKVStoreWithPartitionWhenItExists() {\n+        assertNotNull(storeProvider.getStore(StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions - 1)));\n+    }\n+\n+    @Test(expected = InvalidStateStoreException.class)\n+    public void shouldThrowExceptionWhenKVStoreWithPartitionDoesntExists() {\n+        storeProvider.getStore(StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions + 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f251f7cbaa5db21450a3c93556cd98d93c1ef6e"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NTU0MTkxOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/test/StateStoreProviderStub.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMzo0MToyMVrOGcvBEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMzo0MToyMVrOGcvBEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc4MzYzMg==", "bodyText": "nit: space", "url": "https://github.com/apache/kafka/pull/8706#discussion_r432783632", "createdAt": "2020-05-29T23:41:21Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/test/StateStoreProviderStub.java", "diffHunk": "@@ -22,16 +22,22 @@\n import org.apache.kafka.streams.state.QueryableStoreType;\n import org.apache.kafka.streams.state.internals.StreamThreadStateStoreProvider;\n \n+import java.util.AbstractMap.SimpleEntry;\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.stream.Collectors;\n \n public class StateStoreProviderStub extends StreamThreadStateStoreProvider {\n \n-    private final Map<String, StateStore> stores = new HashMap<>();\n+    //<store name : partition> -> state store", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7836004c631beb69184d2601a974645312b71312"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2707, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}