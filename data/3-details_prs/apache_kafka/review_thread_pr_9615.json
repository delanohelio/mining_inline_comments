{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIzNDAyMzg4", "number": 9615, "reviewThreads": {"totalCount": 38, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzowNjo0MlrOE7J5cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxODoxMTo1MFrOFA6wFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDYzNjAzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzowNjo0MlrOH2oyHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxODoxNjo1N1rOH2rnXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1MzM0MQ==", "bodyText": "Assume the following thread list [t2, t3, t4], threadIdx would be 4, which is already there. You should keep the currently used threadIdxs and check those to decide on the next threadIdx.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527053341", "createdAt": "2020-11-19T17:06:42Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,57 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {\n+            if (state == State.RUNNING || state == State.REBALANCING) {\n+                final int threadIdx = threads.size() + 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5OTc0Mg==", "bodyText": "Looks like I didn't understand threadIdx. that makes sense now", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527099742", "createdAt": "2020-11-19T18:16:57Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,57 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {\n+            if (state == State.RUNNING || state == State.REBALANCING) {\n+                final int threadIdx = threads.size() + 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1MzM0MQ=="}, "originalCommit": null, "originalPosition": 148}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDY1MDYxOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzoxMDowMFrOH2o7SQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzoxMDowMFrOH2o7SQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1NTY4OQ==", "bodyText": "This should be:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            final long cacheSizePerThread = getCacheSizePerThread(threadIdx);\n          \n          \n            \n                            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527055689", "createdAt": "2020-11-19T17:10:00Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,57 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {\n+            if (state == State.RUNNING || state == State.REBALANCING) {\n+                final int threadIdx = threads.size() + 1;\n+                final long cacheSizePerThread = getCacheSizePerThread(threadIdx);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 149}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDY1NzU5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzoxMTozN1rOH2o_oA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzoxMTozN1rOH2o_oA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1NjgwMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            resizeThreadCache(threadIdx);\n          \n          \n            \n                            resizeThreadCache(threads.size() + 1);", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527056800", "createdAt": "2020-11-19T17:11:37Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,57 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {\n+            if (state == State.RUNNING || state == State.REBALANCING) {\n+                final int threadIdx = threads.size() + 1;\n+                final long cacheSizePerThread = getCacheSizePerThread(threadIdx);\n+                resizeThreadCache(threadIdx);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDgzNDE2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzo1Mzo1NVrOH2qt3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxODoxNzowMFrOH2rngw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA4NTAyMA==", "bodyText": "Where is the stream thread started?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527085020", "createdAt": "2020-11-19T17:53:55Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,57 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {\n+            if (state == State.RUNNING || state == State.REBALANCING) {\n+                final int threadIdx = threads.size() + 1;\n+                final long cacheSizePerThread = getCacheSizePerThread(threadIdx);\n+                resizeThreadCache(threadIdx);\n+                final StreamThread streamThread = StreamThread.create(\n+                        internalTopologyBuilder,\n+                        config,\n+                        clientSupplier,\n+                        adminClient,\n+                        processId,\n+                        clientId,\n+                        streamsMetrics,\n+                        time,\n+                        streamsMetadataState,\n+                        cacheSizePerThread,\n+                        stateDirectory,\n+                        delegatingStateRestoreListener,\n+                        threadIdx,\n+                        KafkaStreams.this::closeToError,\n+                        streamsUncaughtExceptionHandler\n+                );\n+                threads.add(streamThread);\n+                threadState.put(streamThread.getId(), streamThread.state());\n+                storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+                streamThread.setStateListener(streamStateListener);\n+                return Optional.of(streamThread.getName());\n+            } else {\n+                return Optional.empty();\n+            }\n+        }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5OTc3OQ==", "bodyText": "right before the positive return :)", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527099779", "createdAt": "2020-11-19T18:17:00Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,57 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {\n+            if (state == State.RUNNING || state == State.REBALANCING) {\n+                final int threadIdx = threads.size() + 1;\n+                final long cacheSizePerThread = getCacheSizePerThread(threadIdx);\n+                resizeThreadCache(threadIdx);\n+                final StreamThread streamThread = StreamThread.create(\n+                        internalTopologyBuilder,\n+                        config,\n+                        clientSupplier,\n+                        adminClient,\n+                        processId,\n+                        clientId,\n+                        streamsMetrics,\n+                        time,\n+                        streamsMetadataState,\n+                        cacheSizePerThread,\n+                        stateDirectory,\n+                        delegatingStateRestoreListener,\n+                        threadIdx,\n+                        KafkaStreams.this::closeToError,\n+                        streamsUncaughtExceptionHandler\n+                );\n+                threads.add(streamThread);\n+                threadState.put(streamThread.getId(), streamThread.state());\n+                storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+                streamThread.setStateListener(streamStateListener);\n+                return Optional.of(streamThread.getName());\n+            } else {\n+                return Optional.empty();\n+            }\n+        }\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA4NTAyMA=="}, "originalCommit": null, "originalPosition": 177}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNTIxNzMyOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxOTozMzowMlrOH2ucDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxOTozMzowMlrOH2ucDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0NTk5Ng==", "bodyText": "You should not use try-catch here but just add throws InterruptedException to the method signature.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527145996", "createdAt": "2020-11-19T19:33:02Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -588,6 +592,29 @@ public void testCloseIsIdempotent() {\n             closeCount, MockMetricsReporter.CLOSE_COUNT.get());\n     }\n \n+    @Test\n+    public void testAddThread() {\n+        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1);\n+        final KafkaStreams streams = new KafkaStreams(getBuilderWithSource().build(), props, supplier, time);\n+        streams.start();\n+        final int oldSize = streams.threads.size();\n+        try {\n+            TestUtils.waitForCondition(() -> streams.state() == KafkaStreams.State.RUNNING, 15L, \"wait until running\");\n+        } catch (final InterruptedException e) {\n+            e.printStackTrace();\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNTI0MTEzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxOTozOToxOFrOH2uqJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxNzoxMDozOVrOH3YkdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0OTYwNA==", "bodyText": "Why do we need to synchronize the whole method on stateLock?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527149604", "createdAt": "2020-11-19T19:39:18Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,72 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3NzA0OA==", "bodyText": "Well we don't want it changing state while adding a thread", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527277048", "createdAt": "2020-11-19T23:41:37Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,72 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0OTYwNA=="}, "originalCommit": null, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2MDUxOQ==", "bodyText": "Wouldn't it be sufficent to check in the beginning if the Streams client is in RUNNING or REBALANCING, then optimistically create the stream thread, and before we start the stream thread check if the client is not in PENDING_SHUTDOWN and not in ERROR and not in NOT_RUNNING? State changes between RUNNING and REBALANCING should not affect adding a stream thread, right?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527560519", "createdAt": "2020-11-20T09:27:33Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,72 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0OTYwNA=="}, "originalCommit": null, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgzNjI3Nw==", "bodyText": "Okay we can check then only synchronize around the start of the thread to make sure it doesn't shutdown between the check and the starting", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527836277", "createdAt": "2020-11-20T17:10:39Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,72 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0OTYwNA=="}, "originalCommit": null, "originalPosition": 146}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNTI0NDU3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxOTo0MDowMVrOH2usDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxOTo0MDowMVrOH2usDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE1MDA5NQ==", "bodyText": "Could we also use isRunningOrRebalancing() here?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527150095", "createdAt": "2020-11-19T19:40:01Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,72 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {\n+            if (state == State.RUNNING || state == State.REBALANCING) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNTMzNzE3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMDowNTo0MlrOH2vloA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMDowNTo0MlrOH2vloA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE2NDgzMg==", "bodyText": "We do something really similar when we start the stream threads at startup. Could you try to extract this part to a method?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527164832", "createdAt": "2020-11-19T20:05:42Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,72 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {\n+            if (state == State.RUNNING || state == State.REBALANCING) {\n+                final int threadIdx = getNextThreadIndex();\n+                final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+                resizeThreadCache(threads.size() + 1);\n+                final StreamThread streamThread = StreamThread.create(\n+                        internalTopologyBuilder,\n+                        config,\n+                        clientSupplier,\n+                        adminClient,\n+                        processId,\n+                        clientId,\n+                        streamsMetrics,\n+                        time,\n+                        streamsMetadataState,\n+                        cacheSizePerThread,\n+                        stateDirectory,\n+                        delegatingStateRestoreListener,\n+                        threadIdx,\n+                        KafkaStreams.this::closeToError,\n+                        streamsUncaughtExceptionHandler\n+                );\n+                threads.add(streamThread);\n+                threadState.put(streamThread.getId(), streamThread.state());\n+                storeProviders.add(new StreamThreadStateStoreProvider(streamThread));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 170}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNTM4ODczOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMDoyMDozM1rOH2wFUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMDoyMDozM1rOH2wFUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE3Mjk0Nw==", "bodyText": "I would prefer to use shouldAddThread() as name although the pattern is different for the other test methods.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527172947", "createdAt": "2020-11-19T20:20:33Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -588,6 +592,29 @@ public void testCloseIsIdempotent() {\n             closeCount, MockMetricsReporter.CLOSE_COUNT.get());\n     }\n \n+    @Test\n+    public void testAddThread() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNTM5MDM0OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMDoyMTowMFrOH2wGUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMDoyMTowMFrOH2wGUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE3MzIwMA==", "bodyText": "I would prefer to use shouldNotAddThread() as name although the pattern is different for the other test methods.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527173200", "createdAt": "2020-11-19T20:21:00Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -588,6 +592,29 @@ public void testCloseIsIdempotent() {\n             closeCount, MockMetricsReporter.CLOSE_COUNT.get());\n     }\n \n+    @Test\n+    public void testAddThread() {\n+        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1);\n+        final KafkaStreams streams = new KafkaStreams(getBuilderWithSource().build(), props, supplier, time);\n+        streams.start();\n+        final int oldSize = streams.threads.size();\n+        try {\n+            TestUtils.waitForCondition(() -> streams.state() == KafkaStreams.State.RUNNING, 15L, \"wait until running\");\n+        } catch (final InterruptedException e) {\n+            e.printStackTrace();\n+        }\n+        assertThat(streams.addStreamThread(), equalTo(Optional.of(\"newThread\")));\n+        assertThat(streams.threads.size(), equalTo(oldSize + 1));\n+    }\n+\n+    @Test\n+    public void testAddThreadNotDuringStart() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNTQwODM0OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMDoyNjoxMFrOH2wRWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxNzozNzo1MVrOH3Z2cw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE3NjAyNQ==", "bodyText": "Additionally to the unit tests that you wrote, I think we also need integration tests.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527176025", "createdAt": "2020-11-19T20:26:10Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,72 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3NzEzNQ==", "bodyText": "you are right, Ill add one", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527277135", "createdAt": "2020-11-19T23:41:53Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,72 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE3NjAyNQ=="}, "originalCommit": null, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg1NzI2Nw==", "bodyText": "@cadonna added", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527857267", "createdAt": "2020-11-20T17:37:51Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +904,72 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE3NjAyNQ=="}, "originalCommit": null, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzY0NzY2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwODo0NjoyM1rOH3F5zA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwODo0NjoyM1rOH3F5zA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzUzMDQ0NA==", "bodyText": "I think it would be cleaner to pass cacheSizePerThread to resizeThreadCache() instead of the number of stream threads. We would then just call getCacheSizePerThread() once instead of once in addStreamThread() and once in resizeThreadCache(). We would also just need to compute threads.size() + 1 once.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527530444", "createdAt": "2020-11-20T08:46:23Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +885,77 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread makeThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (stateLock) {\n+            if (isRunningOrRebalancing()) {\n+                final int threadIdx = getNextThreadIndex();\n+                final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+                resizeThreadCache(threads.size() + 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 185}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzcyNjI4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTowNDoyNFrOH3GrqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTowNDoyNFrOH3GrqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU0MzIwOQ==", "bodyText": "IMO, createStreamThread() would describe the behavior better.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r527543209", "createdAt": "2020-11-20T09:04:24Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,11 +885,77 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread makeThread(final long cacheSizePerThread, final int threadIdx) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDUzMjMzOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMTowNzoyNlrOH47yLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMTowNzoyNlrOH47yLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2MTgwNA==", "bodyText": "Please adjust indentation:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            mkMap(\n          \n          \n            \n                                    mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n          \n          \n            \n                                    mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n          \n          \n            \n                                    mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n          \n          \n            \n                                    mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n          \n          \n            \n                                    mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n          \n          \n            \n                                    mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n          \n          \n            \n                            )\n          \n          \n            \n                        mkMap(\n          \n          \n            \n                            mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n          \n          \n            \n                            mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n          \n          \n            \n                            mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n          \n          \n            \n                            mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n          \n          \n            \n                            mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n          \n          \n            \n                            mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n          \n          \n            \n                        )", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529461804", "createdAt": "2020-11-24T11:07:26Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d44bce5251dbb94c8751739b75424f9e043c0ba"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDUzMzQ0OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMTowNzo0NVrOH47y1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMTowNzo0NVrOH47y1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2MTk3NQ==", "bodyText": "wrong indentation", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529461975", "createdAt": "2020-11-24T11:07:45Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    private void produceMessages(final long timestamp, final String streamOneInput, final String msg) {\n+        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+                streamOneInput,\n+                Collections.singletonList(new KeyValue<>(\"1\", msg)),\n+                TestUtils.producerConfig(\n+                        CLUSTER.bootstrapServers(),\n+                        StringSerializer.class,\n+                        StringSerializer.class,\n+                        new Properties()),\n+                timestamp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d44bce5251dbb94c8751739b75424f9e043c0ba"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDU0NzU3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMToxMToyMlrOH477dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNjozNjowNFrOH5LTyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2NDE4Mw==", "bodyText": "We should wait for the new stream thread with a timeout, otherwise we risk that this test may become flaky.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529464183", "createdAt": "2020-11-24T11:11:22Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    private void produceMessages(final long timestamp, final String streamOneInput, final String msg) {\n+        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+                streamOneInput,\n+                Collections.singletonList(new KeyValue<>(\"1\", msg)),\n+                TestUtils.producerConfig(\n+                        CLUSTER.bootstrapServers(),\n+                        StringSerializer.class,\n+                        StringSerializer.class,\n+                        new Properties()),\n+                timestamp);\n+    }\n+\n+    @Test\n+    public void shouldAddStreamThread() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+            final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n+\n+            kafkaStreams.addStreamThread();\n+            produceMessages(0L, inputTopic, \"A\");\n+\n+            assertThat(kafkaStreams.localThreadsMetadata().size(), equalTo(oldThreadCount + 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d44bce5251dbb94c8751739b75424f9e043c0ba"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTcxNjE2OQ==", "bodyText": "we can wait for it to be added to the thread meta data. I assume that is what you mean", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529716169", "createdAt": "2020-11-24T16:36:04Z", "author": {"login": "wcarlson5"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    private void produceMessages(final long timestamp, final String streamOneInput, final String msg) {\n+        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+                streamOneInput,\n+                Collections.singletonList(new KeyValue<>(\"1\", msg)),\n+                TestUtils.producerConfig(\n+                        CLUSTER.bootstrapServers(),\n+                        StringSerializer.class,\n+                        StringSerializer.class,\n+                        new Properties()),\n+                timestamp);\n+    }\n+\n+    @Test\n+    public void shouldAddStreamThread() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+            final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n+\n+            kafkaStreams.addStreamThread();\n+            produceMessages(0L, inputTopic, \"A\");\n+\n+            assertThat(kafkaStreams.localThreadsMetadata().size(), equalTo(oldThreadCount + 1));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2NDE4Mw=="}, "originalCommit": {"oid": "2d44bce5251dbb94c8751739b75424f9e043c0ba"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDU1MTE0OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMToxMjowOVrOH479iQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNjoyNzowMFrOH5K6Gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2NDcxMw==", "bodyText": "Do we need this line?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529464713", "createdAt": "2020-11-24T11:12:09Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    private void produceMessages(final long timestamp, final String streamOneInput, final String msg) {\n+        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+                streamOneInput,\n+                Collections.singletonList(new KeyValue<>(\"1\", msg)),\n+                TestUtils.producerConfig(\n+                        CLUSTER.bootstrapServers(),\n+                        StringSerializer.class,\n+                        StringSerializer.class,\n+                        new Properties()),\n+                timestamp);\n+    }\n+\n+    @Test\n+    public void shouldAddStreamThread() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+            final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n+\n+            kafkaStreams.addStreamThread();\n+            produceMessages(0L, inputTopic, \"A\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d44bce5251dbb94c8751739b75424f9e043c0ba"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTcwOTU5NQ==", "bodyText": "no, we don't", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529709595", "createdAt": "2020-11-24T16:27:00Z", "author": {"login": "wcarlson5"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    private void produceMessages(final long timestamp, final String streamOneInput, final String msg) {\n+        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+                streamOneInput,\n+                Collections.singletonList(new KeyValue<>(\"1\", msg)),\n+                TestUtils.producerConfig(\n+                        CLUSTER.bootstrapServers(),\n+                        StringSerializer.class,\n+                        StringSerializer.class,\n+                        new Properties()),\n+                timestamp);\n+    }\n+\n+    @Test\n+    public void shouldAddStreamThread() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+            final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n+\n+            kafkaStreams.addStreamThread();\n+            produceMessages(0L, inputTopic, \"A\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2NDcxMw=="}, "originalCommit": {"oid": "2d44bce5251dbb94c8751739b75424f9e043c0ba"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDg5OTg4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo0Njo0OVrOH4_PQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNjozMjo0N1rOH5LKZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxODQwMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        synchronized (stateLock) {\n          \n          \n            \n                            if (isRunningOrRebalancing()) {\n          \n          \n            \n                                streamThread.start();\n          \n          \n            \n                            } else {\n          \n          \n            \n                                return Optional.empty();\n          \n          \n            \n                            }\n          \n          \n            \n                        }\n          \n          \n            \n                        return Optional.of(streamThread.getName());\n          \n          \n            \n                        synchronized (stateLock) {\n          \n          \n            \n                            if (isRunningOrRebalancing()) {\n          \n          \n            \n                                streamThread.start();\n          \n          \n            \n                                return Optional.of(streamThread.getName());\n          \n          \n            \n                            } else {\n          \n          \n            \n                                return Optional.empty();\n          \n          \n            \n                            }\n          \n          \n            \n                        }", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529518403", "createdAt": "2020-11-24T12:46:49Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                } else {\n+                    return Optional.empty();\n+                }\n+            }\n+            return Optional.of(streamThread.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d44bce5251dbb94c8751739b75424f9e043c0ba"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTcxMzc2NA==", "bodyText": "sure", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529713764", "createdAt": "2020-11-24T16:32:47Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                } else {\n+                    return Optional.empty();\n+                }\n+            }\n+            return Optional.of(streamThread.getName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxODQwMw=="}, "originalCommit": {"oid": "2d44bce5251dbb94c8751739b75424f9e043c0ba"}, "originalPosition": 194}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMzA0MTU3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMDoyODo1M1rOH5T_YQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMDoyODo1M1rOH5T_YQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTg1ODQwMQ==", "bodyText": "nit: If not all parameters fit on one line, we put each of them on a new line. Additionally we put also the closing parenthesis on a new line.\nnit: Lines should -- if possible -- not exceed 120 characters.\nnit: I like when tests are visually structured with one block for setup, the call under test, and one block for verifications.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n          \n          \n            \n                        final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n          \n          \n            \n            \n          \n          \n            \n                        final Optional<String> name = kafkaStreams.addStreamThread();\n          \n          \n            \n                        assertThat(name, CoreMatchers.not(Optional.empty()));\n          \n          \n            \n                        TestUtils.waitForCondition(() -> kafkaStreams.localThreadsMetadata().stream().sequential().map(ThreadMetadata::threadName).anyMatch(t -> t.equals(name.orElse(\"\"))),\n          \n          \n            \n                            \"Wait for the thread to be added\");\n          \n          \n            \n                        assertThat(kafkaStreams.localThreadsMetadata().size(), equalTo(oldThreadCount + 1));\n          \n          \n            \n                        StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n          \n          \n            \n                        final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n          \n          \n            \n            \n          \n          \n            \n                        final Optional<String> name = kafkaStreams.addStreamThread();\n          \n          \n            \n                        \n          \n          \n            \n                        assertThat(name, CoreMatchers.not(Optional.empty()));\n          \n          \n            \n                        TestUtils.waitForCondition(\n          \n          \n            \n                            () -> kafkaStreams.localThreadsMetadata().stream().sequential()\n          \n          \n            \n                                .map(ThreadMetadata::threadName).anyMatch(t -> t.equals(name.orElse(\"\"))), \n          \n          \n            \n                            \"Wait for the thread to be added\"\n          \n          \n            \n                        );\n          \n          \n            \n                        assertThat(kafkaStreams.localThreadsMetadata().size(), equalTo(oldThreadCount + 1));", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529858401", "createdAt": "2020-11-24T20:28:53Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.processor.ThreadMetadata;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.hamcrest.CoreMatchers;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Optional;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+            mkMap(\n+                mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+            )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    @Test\n+    public void shouldAddStreamThread() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+            final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n+\n+            final Optional<String> name = kafkaStreams.addStreamThread();\n+            assertThat(name, CoreMatchers.not(Optional.empty()));\n+            TestUtils.waitForCondition(() -> kafkaStreams.localThreadsMetadata().stream().sequential().map(ThreadMetadata::threadName).anyMatch(t -> t.equals(name.orElse(\"\"))),\n+                \"Wait for the thread to be added\");\n+            assertThat(kafkaStreams.localThreadsMetadata().size(), equalTo(oldThreadCount + 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70d500aae259184538feb662047f75897bb89b4d"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDEyMDEzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoxMDowOVrOH8VVuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoyMTo0NlrOH8592A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyNjIzMg==", "bodyText": "nit. remove unnecessary this.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533026232", "createdAt": "2020-12-01T02:10:09Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -398,6 +407,7 @@ public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler st\n         final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n         synchronized (stateLock) {\n             if (state == State.CREATED) {\n+                this.streamsUncaughtExceptionHandler = handler;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU2ODYxMQ==", "bodyText": "the this. is necessary. the parameter is the same name", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533568611", "createdAt": "2020-12-01T16:55:02Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -398,6 +407,7 @@ public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler st\n         final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n         synchronized (stateLock) {\n             if (state == State.CREATED) {\n+                this.streamsUncaughtExceptionHandler = handler;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyNjIzMg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyNjMyOA==", "bodyText": "Ah. Was missing that as you assign handler that is not a StreamsUncaughtExceptionHandler but a Consumer<Throwable>...", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533626328", "createdAt": "2020-12-01T18:21:46Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -398,6 +407,7 @@ public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler st\n         final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n         synchronized (stateLock) {\n             if (state == State.CREATED) {\n+                this.streamsUncaughtExceptionHandler = handler;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyNjIzMg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDEzMzIxOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoxNjowMlrOH8VdPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzowMjozMVrOH82yHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyODE1Ng==", "bodyText": "Nit: can we change the loop to int = 1; i <= numStreamThreads and just pass in i here?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533028156", "createdAt": "2020-12-01T02:16:02Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -846,43 +856,24 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n         for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n-                internalTopologyBuilder,\n-                config,\n-                clientSupplier,\n-                adminClient,\n-                processId,\n-                clientId,\n-                streamsMetrics,\n-                time,\n-                streamsMetadataState,\n-                cacheSizePerThread,\n-                stateDirectory,\n-                delegatingStateRestoreListener,\n-                i + 1,\n-                KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+            createStreamThread(cacheSizePerThread, i + 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU3NDE3Mg==", "bodyText": "I think so", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533574172", "createdAt": "2020-12-01T17:02:31Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -846,43 +856,24 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n         for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n-                internalTopologyBuilder,\n-                config,\n-                clientSupplier,\n-                adminClient,\n-                processId,\n-                clientId,\n-                streamsMetrics,\n-                time,\n-                streamsMetadataState,\n-                cacheSizePerThread,\n-                stateDirectory,\n-                delegatingStateRestoreListener,\n-                i + 1,\n-                KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+            createStreamThread(cacheSizePerThread, i + 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyODE1Ng=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDEzNTI2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoxNzowNlrOH8Veeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoxNzowNlrOH8Veeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyODQ3NA==", "bodyText": "Add missing <p> tag", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533028474", "createdAt": "2020-12-01T02:17:06Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 170}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDEzNTY0OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoxNzoxNVrOH8Verg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoxNzoxNVrOH8Verg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyODUyNg==", "bodyText": "As above.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533028526", "createdAt": "2020-12-01T02:17:15Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 175}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDEzNjYzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoxNzo1NFrOH8VfZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzowODo0NlrOH83C9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyODcwOA==", "bodyText": "Should we link to StreamConfig instead?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533028708", "createdAt": "2020-12-01T02:17:54Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU3ODQ4Ng==", "bodyText": "I think that makes more sense.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533578486", "createdAt": "2020-12-01T17:08:46Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyODcwOA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 174}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDE0MTM2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoyMDoyNFrOH8VibA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoyMzowMlrOH86BBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTQ4NA==", "bodyText": "Can we create the StreamStateListener before we call createStreamThread and do setStateListener within createStreamThread ? If yes, we also don't need to call setStateListener within addStreamThread", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533029484", "createdAt": "2020-12-01T02:20:24Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -846,43 +856,24 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n         for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n-                internalTopologyBuilder,\n-                config,\n-                clientSupplier,\n-                adminClient,\n-                processId,\n-                clientId,\n-                streamsMetrics,\n-                time,\n-                streamsMetadataState,\n-                cacheSizePerThread,\n-                stateDirectory,\n-                delegatingStateRestoreListener,\n-                i + 1,\n-                KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+            createStreamThread(cacheSizePerThread, i + 1);\n         }\n \n         ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n             Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n \n-        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);\n+        streamStateListener = new StreamStateListener(threadState, globalThreadState);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU3NjczNg==", "bodyText": "good idea. I don't know why the SteamStateListener is created after the stream threads are made but it seems to work.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533576736", "createdAt": "2020-12-01T17:06:07Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -846,43 +856,24 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n         for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n-                internalTopologyBuilder,\n-                config,\n-                clientSupplier,\n-                adminClient,\n-                processId,\n-                clientId,\n-                streamsMetrics,\n-                time,\n-                streamsMetadataState,\n-                cacheSizePerThread,\n-                stateDirectory,\n-                delegatingStateRestoreListener,\n-                i + 1,\n-                KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+            createStreamThread(cacheSizePerThread, i + 1);\n         }\n \n         ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n             Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n \n-        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);\n+        streamStateListener = new StreamStateListener(threadState, globalThreadState);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTQ4NA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyNzE0Mw==", "bodyText": "Maybe we had some cyclic dependency at some point in the past? Not sure.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533627143", "createdAt": "2020-12-01T18:23:02Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -846,43 +856,24 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n         for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n-                internalTopologyBuilder,\n-                config,\n-                clientSupplier,\n-                adminClient,\n-                processId,\n-                clientId,\n-                streamsMetrics,\n-                time,\n-                streamsMetadataState,\n-                cacheSizePerThread,\n-                stateDirectory,\n-                delegatingStateRestoreListener,\n-                i + 1,\n-                KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+            createStreamThread(cacheSizePerThread, i + 1);\n         }\n \n         ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n             Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n \n-        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);\n+        streamStateListener = new StreamStateListener(threadState, globalThreadState);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTQ4NA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDE0NDE1OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoyMTo1MFrOH8VkNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNTozNjo0N1rOH9g3wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTk0Mg==", "bodyText": "Just to clarify for myself: if we don't start() the thread, no harm is done creating it? Or would we need to do some cleanup even if we don't start the thread?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533029942", "createdAt": "2020-12-01T02:21:50Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU4Mjc2MA==", "bodyText": "I think I explain this above. But we can remove from the thread list.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533582760", "createdAt": "2020-12-01T17:15:03Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTk0Mg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzNzQ1MQ==", "bodyText": "Maybe. We should ensure that we do proper cleanup for all cases.\nWhat make we wonder: I don't see any code (except the remove you added below) that would remove a StreamThread from the list? Will this be done in a different PR?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533637451", "createdAt": "2020-12-01T18:39:51Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTk0Mg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY1NjczMg==", "bodyText": "There will be two more cases of remove. In the replace thread option and in the remove thread option.\nI'm not really convinced it is necessary but I don't see a problem with re-resizing the cache if we do not start the thread. I don't think there will be any side affects as the client should be shutting down, but if we resize there should be a little extra info in the state and store providers but it would not get used", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533656732", "createdAt": "2020-12-01T19:11:28Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTk0Mg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY3NTQyOQ==", "bodyText": "What about checking for the state and do the clean-up only if the state is not PENDING_SHUTDOWN and not ERROR and not NOT_RUNNING? In this way we are safe for future changes that break our assumption on state transitions and we make sure not to do unnecessary stuff when we are shutting down.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533675429", "createdAt": "2020-12-01T19:43:38Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTk0Mg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY3Njk3Ng==", "bodyText": "From running or rebalancing aren't those the only states we can get to?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533676976", "createdAt": "2020-12-01T19:46:18Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTk0Mg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY4NzAzMQ==", "bodyText": "Yes, currently this assumption is correct, but if the state transitions change in future, we would be safe if we do the cleanup.\nOn a second thought, we are probably not 100% safe because if a transition from NOT_RUNNING to RUNNING is added (or any other transition that goes from the above mentioned states to RUNNING or REBALANCING), we would still not do the clean up.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533687031", "createdAt": "2020-12-01T20:03:41Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTk0Mg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNzY0MA==", "bodyText": "I think when a state transition is changed or add is when these changes should be made. Removing from the thread list is low cost as is increasing the size of the cache, so it won't be expensive to make these changes for all cases.\nI think the two good options we have is that we can move the cache resize and create thread into the stateLock or we can undo the changes we made if we have to abort starting the new thread.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533707640", "createdAt": "2020-12-01T20:41:11Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTk0Mg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI2Mzc0Ng==", "bodyText": "See my other comment #9615 (comment)", "url": "https://github.com/apache/kafka/pull/9615#discussion_r534263746", "createdAt": "2020-12-02T15:36:47Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyOTk0Mg=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 189}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDE0ODg3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoyNDoyMVrOH8Vm-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODozNDoyM1rOH86cAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMDY0OA==", "bodyText": "Don't we need to get the stateLock as an outer most guard (and not check isRunningOrRebalancing() twice)? It seems weird to create a thread but later not start it and throw it away -- especially because we resize the caches (but also don't undo the resizing)?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533030648", "createdAt": "2020-12-01T02:24:21Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU4NDk1Ng==", "bodyText": "If it is not running or rebalancing we after it was already running or rebalancing on line 930 we know the client has stopped. The number of threads will be reset to the config and everything will be rebuilt anyways, so changing the cache size should not matter.\nThe state lock is so that in between the second check and starting the thread the state does not change to pending shutdown or something else. I don't think its necessary to guard the whole method as the cache should be thrown out if it's not being started.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533584956", "createdAt": "2020-12-01T17:18:08Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMDY0OA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzNDA0OQ==", "bodyText": "I see. So we exploit that possible state transitions are limited. Thanks for explaining. Makes sense.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533634049", "createdAt": "2020-12-01T18:34:23Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMDY0OA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDE1MDc0OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoyNToxMVrOH8VoAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxOToxMzo0NlrOH875hA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMDkxNA==", "bodyText": "Why do we compute the names from scratch, but not incrementally maintain them as member variable?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533030914", "createdAt": "2020-12-01T02:25:11Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                    return Optional.of(streamThread.getName());\n+                } else {\n+                    return Optional.empty();\n+                }\n+            }\n+        } else {\n+            return Optional.empty();\n+        }\n+    }\n+\n+    private int getNextThreadIndex() {\n+        final HashSet<String> names = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU4NzcxOQ==", "bodyText": "As threads are removed we want to reuse those names, so incrementing would not work for us. Maybe there is away to store a next name, but then the logic would have to be spread out in a few places and I prefer to just compute a few names.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533587719", "createdAt": "2020-12-01T17:22:00Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                    return Optional.of(streamThread.getName());\n+                } else {\n+                    return Optional.empty();\n+                }\n+            }\n+        } else {\n+            return Optional.empty();\n+        }\n+    }\n+\n+    private int getNextThreadIndex() {\n+        final HashSet<String> names = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMDkxNA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTUzMQ==", "bodyText": "That is not what I meant. But it might not matter much anyway.\nWhile we need to loop over all used names in L951 below to reuse, we don't need to compute names from scratch but would just modify names each time we add/remove a thread. But it's not perf-critical so re-doing the computation is fine, too.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533631531", "createdAt": "2020-12-01T18:30:03Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                    return Optional.of(streamThread.getName());\n+                } else {\n+                    return Optional.empty();\n+                }\n+            }\n+        } else {\n+            return Optional.empty();\n+        }\n+    }\n+\n+    private int getNextThreadIndex() {\n+        final HashSet<String> names = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMDkxNA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY1Nzk4OA==", "bodyText": "I'll remove a few of the unnecessary + operations then", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533657988", "createdAt": "2020-12-01T19:13:46Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                    return Optional.of(streamThread.getName());\n+                } else {\n+                    return Optional.empty();\n+                }\n+            }\n+        } else {\n+            return Optional.empty();\n+        }\n+    }\n+\n+    private int getNextThreadIndex() {\n+        final HashSet<String> names = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMDkxNA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 201}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDE1Mjg4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoyNjoxMlrOH8VpPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxOToxMzoxMVrOH874Ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMTIyOA==", "bodyText": "Why this check?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533031228", "createdAt": "2020-12-01T02:26:12Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -76,6 +76,9 @@ public void resize(final long newCacheSizeBytes) {\n         final boolean shrink = newCacheSizeBytes < maxCacheSizeBytes;\n         maxCacheSizeBytes = newCacheSizeBytes;\n         if (shrink) {\n+            if (caches.values().isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU4ODcxMg==", "bodyText": "Apparently CircularIterators throw an error if they are made on empty lists. And if there are no caches to resize we don't need to bother with the rest of this.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533588712", "createdAt": "2020-12-01T17:23:30Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -76,6 +76,9 @@ public void resize(final long newCacheSizeBytes) {\n         final boolean shrink = newCacheSizeBytes < maxCacheSizeBytes;\n         maxCacheSizeBytes = newCacheSizeBytes;\n         if (shrink) {\n+            if (caches.values().isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMTIyOA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMjMzMg==", "bodyText": "I see -- so it's a bug fix on the side (not directly related to this RP) -- the original PR that added this method should have added this check.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533632332", "createdAt": "2020-12-01T18:31:22Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -76,6 +76,9 @@ public void resize(final long newCacheSizeBytes) {\n         final boolean shrink = newCacheSizeBytes < maxCacheSizeBytes;\n         maxCacheSizeBytes = newCacheSizeBytes;\n         if (shrink) {\n+            if (caches.values().isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMTIyOA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY1NzY1OQ==", "bodyText": "yeah, I didn't realize this was a problem, but when I added more test coverage it showed up", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533657659", "createdAt": "2020-12-01T19:13:11Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -76,6 +76,9 @@ public void resize(final long newCacheSizeBytes) {\n         final boolean shrink = newCacheSizeBytes < maxCacheSizeBytes;\n         maxCacheSizeBytes = newCacheSizeBytes;\n         if (shrink) {\n+            if (caches.values().isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMTIyOA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDE1NTcyOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoyNzozM1rOH8Vq5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoyNzozM1rOH8Vq5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMTY1Mg==", "bodyText": "shouldAddThreadWhenRunning", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533031652", "createdAt": "2020-12-01T02:27:33Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -588,6 +592,25 @@ public void testCloseIsIdempotent() {\n             closeCount, MockMetricsReporter.CLOSE_COUNT.get());\n     }\n \n+    @Test\n+    public void shouldAddThread() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDE1NzU2OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoyODoyMVrOH8Vr_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzoyNzoxNlrOH831HA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMTkzNA==", "bodyText": "shouldNotAddThreadWhenCreated\nShould we also close() KafkaStreams and check that adding a thread is not possible and/or even put the client into ERROR state and test?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533031934", "createdAt": "2020-12-01T02:28:21Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -588,6 +592,25 @@ public void testCloseIsIdempotent() {\n             closeCount, MockMetricsReporter.CLOSE_COUNT.get());\n     }\n \n+    @Test\n+    public void shouldAddThread() throws InterruptedException {\n+        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1);\n+        final KafkaStreams streams = new KafkaStreams(getBuilderWithSource().build(), props, supplier, time);\n+        streams.start();\n+        final int oldSize = streams.threads.size();\n+        TestUtils.waitForCondition(() -> streams.state() == KafkaStreams.State.RUNNING, 15L, \"wait until running\");\n+        assertThat(streams.addStreamThread(), equalTo(Optional.of(\"newThread\")));\n+        assertThat(streams.threads.size(), equalTo(oldSize + 1));\n+    }\n+\n+    @Test\n+    public void shouldNotAddThread() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU5MTMyNA==", "bodyText": "Good idea I'll add some tests.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533591324", "createdAt": "2020-12-01T17:27:16Z", "author": {"login": "wcarlson5"}, "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -588,6 +592,25 @@ public void testCloseIsIdempotent() {\n             closeCount, MockMetricsReporter.CLOSE_COUNT.get());\n     }\n \n+    @Test\n+    public void shouldAddThread() throws InterruptedException {\n+        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1);\n+        final KafkaStreams streams = new KafkaStreams(getBuilderWithSource().build(), props, supplier, time);\n+        streams.start();\n+        final int oldSize = streams.threads.size();\n+        TestUtils.waitForCondition(() -> streams.state() == KafkaStreams.State.RUNNING, 15L, \"wait until running\");\n+        assertThat(streams.addStreamThread(), equalTo(Optional.of(\"newThread\")));\n+        assertThat(streams.threads.size(), equalTo(oldSize + 1));\n+    }\n+\n+    @Test\n+    public void shouldNotAddThread() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMTkzNA=="}, "originalCommit": {"oid": "e2130ad1193ea2de05814b1218f33f216a438b6c"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NzkyNDgxOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoyNDo1NlrOH86Ftg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxOTowNTowOVrOH87mvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyODM0Mg==", "bodyText": "i + 1 -> i\nWondering why this does not result in a test failure? (Or does it; Jenkins is still running.) -- Maybe we want to add a small test that verifies that we name threads correctly.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533628342", "createdAt": "2020-12-01T18:24:56Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -846,18 +856,37 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n-        for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n+        streamStateListener = new StreamStateListener(threadState, globalThreadState);\n+        if (hasGlobalTopology) {\n+            globalStreamThread.setStateListener(streamStateListener);\n+        }\n+        for (int i = 1; i <= numStreamThreads; i++) {\n+            createStreamThread(cacheSizePerThread, i + 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4cd470a4a5883481a5bd79d9b992a717470e5413"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY1MzE4MA==", "bodyText": "good catch. I don't think we make sure the thread index starts at 1. But let me fix that", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533653180", "createdAt": "2020-12-01T19:05:09Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -846,18 +856,37 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n-        for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n+        streamStateListener = new StreamStateListener(threadState, globalThreadState);\n+        if (hasGlobalTopology) {\n+            globalStreamThread.setStateListener(streamStateListener);\n+        }\n+        for (int i = 1; i <= numStreamThreads; i++) {\n+            createStreamThread(cacheSizePerThread, i + 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyODM0Mg=="}, "originalCommit": {"oid": "4cd470a4a5883481a5bd79d9b992a717470e5413"}, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0OTU2MTQ5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMzo1MTowNFrOH9JX7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoxMzo0MVrOH9leyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3ODc2Nw==", "bodyText": "We should also shutdown the thread if it doesn't get started, otherwise me may leak (consumer or producer) clients. But I'm actually not sure why we don't just do everything (resize cache, create thread) inside the synchronized block? I'm guessing it would deadlock due to locking on the statelock but can't we just synchronize on something else that wouldn't interfere with the StreamThread creation?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533878767", "createdAt": "2020-12-02T03:51:04Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +899,73 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                    return Optional.of(streamThread.getName());\n+                } else {\n+                    threads.remove(streamThread);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85f5ca44aaf6a9f7b3bd4e5ba098e8a67d2219d9"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI2MTg0Mw==", "bodyText": "Good point about the shutdown of the stream thread!\nActually, I did not want to have everything in the synchronized block because I thought blocking the client state more than needed was not a good idea. I thought decreasing the size of the cache might be costly if the evicted records are forwarded downstream.\nNow that you mention to synchronize on a separate lock, I noticed that we probably need to put resize, start, and cleanup in the same synchronized block. The reason is that if two threads call addStreamThread() one after the other and the later thread passes\nfinal long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n\nbefore the earlier thread adds the new stream thread to threads in createStreamThread(), the later thread would compute the wrong cache size.\nSo, I am in favor of having a separate lock that just synchronizes the threads calling addStreamThread(). Maybe we can simply synchronize the whole method (which means to synchronize with start() and close()).\nStill a minor issue seems to be the synchronization betweenisRunningOrRebalancing() and streamThread.start(). If between these two calls the Streams client transits to ERROR (the global stream thread died) an IllegalStateException would be thrown from the StreamStateListener because the Streams client would try to transit from ERROR to REBALANCING. But I guess that would also happen if the Streams client transits to ERROR before the new stream thread transits to PARTITION_ASSIGNED and calls the StreamStateListener that would transit the Streams client to REBALANCING. So it needs to be fixed somewhere else.\nDid I miss something?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r534261843", "createdAt": "2020-12-02T15:34:24Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +899,73 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                    return Optional.of(streamThread.getName());\n+                } else {\n+                    threads.remove(streamThread);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3ODc2Nw=="}, "originalCommit": {"oid": "85f5ca44aaf6a9f7b3bd4e5ba098e8a67d2219d9"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMxMzg0NQ==", "bodyText": "Unfortunately I don't think we can shutdown a thread until we have started it.\nI don't think there should be a dead lock by just using the state lock around most of the method. It as mostly about cost. However I think that its is probably the safest way as it solves our problem about needing to remove a thread we have just created and we won't potentially waste time resizing the cache as such.\nIf we synchronize on a new lock we end up with all the problems we were trying to solve earlier anyways with the possible state changes and having to clean up un-started threads", "url": "https://github.com/apache/kafka/pull/9615#discussion_r534313845", "createdAt": "2020-12-02T16:39:12Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +899,73 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                    return Optional.of(streamThread.getName());\n+                } else {\n+                    threads.remove(streamThread);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3ODc2Nw=="}, "originalCommit": {"oid": "85f5ca44aaf6a9f7b3bd4e5ba098e8a67d2219d9"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMxOTUwMA==", "bodyText": "Unfortunately I don't think we can shutdown a thread until we have started it.\n\nHave a look at \n  \n    \n      kafka/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n    \n    \n        Lines 976 to 983\n      in\n      aeeb7b2\n    \n    \n    \n    \n\n        \n          \n           public void shutdown() { \n        \n\n        \n          \n               log.info(\"Informed to shut down\"); \n        \n\n        \n          \n               final State oldState = setState(State.PENDING_SHUTDOWN); \n        \n\n        \n          \n               if (oldState == State.CREATED) { \n        \n\n        \n          \n                   // The thread may not have been started. Take responsibility for shutting down \n        \n\n        \n          \n                   completeShutdown(true); \n        \n\n        \n          \n               } \n        \n\n        \n          \n           }", "url": "https://github.com/apache/kafka/pull/9615#discussion_r534319500", "createdAt": "2020-12-02T16:46:46Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +899,73 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                    return Optional.of(streamThread.getName());\n+                } else {\n+                    threads.remove(streamThread);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3ODc2Nw=="}, "originalCommit": {"oid": "85f5ca44aaf6a9f7b3bd4e5ba098e8a67d2219d9"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMzOTI3NQ==", "bodyText": "Oh okay, when I shutdown unstarted threads in a test I got a java.lang.IllegalStateException Unexpected state transition. But it looks like that is the client.\nI added a new lock for the add threads, and shutdown the thread. I think this address the problem you found with concurrent resizes. As well as @ableegoldman 's concerns", "url": "https://github.com/apache/kafka/pull/9615#discussion_r534339275", "createdAt": "2020-12-02T17:13:41Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +899,73 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                    return Optional.of(streamThread.getName());\n+                } else {\n+                    threads.remove(streamThread);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3ODc2Nw=="}, "originalCommit": {"oid": "85f5ca44aaf6a9f7b3bd4e5ba098e8a67d2219d9"}, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0OTU3MTU1OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMzo1NjowMVrOH9JdWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMzo1NjowMVrOH9JdWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg4MDE1NA==", "bodyText": "Can we also assert that the state gets to RUNNING after the new thread has joined", "url": "https://github.com/apache/kafka/pull/9615#discussion_r533880154", "createdAt": "2020-12-02T03:56:01Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.processor.ThreadMetadata;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.hamcrest.CoreMatchers;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Optional;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+            mkMap(\n+                mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+            )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    @Test\n+    public void shouldAddStreamThread() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+            final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n+\n+            final Optional<String> name = kafkaStreams.addStreamThread();\n+\n+            assertThat(name, CoreMatchers.not(Optional.empty()));\n+            TestUtils.waitForCondition(\n+                () -> kafkaStreams.localThreadsMetadata().stream().sequential()\n+                        .map(ThreadMetadata::threadName).anyMatch(t -> t.equals(name.orElse(\"\"))),\n+                \"Wait for the thread to be added\"\n+            );\n+            assertThat(kafkaStreams.localThreadsMetadata().size(), equalTo(oldThreadCount + 1));\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85f5ca44aaf6a9f7b3bd4e5ba098e8a67d2219d9"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1OTAyMDQxOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNjoyNjoyNFrOH-lPZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxODoxNzowN1rOH-qkKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTM4MzkwOQ==", "bodyText": "nit: If it happens that you need to push another commit, could you fix the indentation here? Sorry that I haven't noticed this before.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r535383909", "createdAt": "2020-12-03T16:26:24Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +900,75 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f6e589e0024878ebfd8b4657e8a04df5278bb90"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ3MTE0Ng==", "bodyText": "ah good catch. the diff makes that hard to see as it was actually moved to a new method.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r535471146", "createdAt": "2020-12-03T18:17:07Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +900,75 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTM4MzkwOQ=="}, "originalCommit": {"oid": "6f6e589e0024878ebfd8b4657e8a04df5278bb90"}, "originalPosition": 142}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1OTA5OTg0OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNjo0MTozNlrOH-l_NQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxOTowNDowNFrOH-siXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTM5NjE0OQ==", "bodyText": "Sorry to bother you again with the synchronization on the stateLock, but could you explain why we still need it after we synchronize on newThread?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r535396149", "createdAt": "2020-12-03T16:41:36Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +900,75 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (newThread) {\n+            if (isRunningOrRebalancing()) {\n+                final int threadIdx = getNextThreadIndex();\n+                final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+                resizeThreadCache(cacheSizePerThread);\n+                final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+                synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f6e589e0024878ebfd8b4657e8a04df5278bb90"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ2ODU3NA==", "bodyText": "Well newThread only syncs the addThread method. There is still the race condition between the second check of is running and starting the thread. It seems like a bad idea to leave that open as it could cause thread state changes when there shouldn't be. Starting the thread is relatively low cost so this shouldn't have much impact perf wise.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r535468574", "createdAt": "2020-12-03T18:14:12Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +900,75 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (newThread) {\n+            if (isRunningOrRebalancing()) {\n+                final int threadIdx = getNextThreadIndex();\n+                final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+                resizeThreadCache(cacheSizePerThread);\n+                final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+                synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTM5NjE0OQ=="}, "originalCommit": {"oid": "6f6e589e0024878ebfd8b4657e8a04df5278bb90"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUwMzQ1Mw==", "bodyText": "Expanding on this, the problem in the shutdown thread. When the join only waits for alive threads, and to be alive the thread needs to be started.\nSo if in between the check and the start thread another thread transitions the state to NOT_RUNNING the thread will not join in the shutdown thread. Then when it continues it will start as it passed the check and we will have a thread running after the client is shutdown.\nThis would be extremely though race condition to find or reproduce so best to just avoid it.", "url": "https://github.com/apache/kafka/pull/9615#discussion_r535503453", "createdAt": "2020-12-03T19:04:04Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +900,75 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (newThread) {\n+            if (isRunningOrRebalancing()) {\n+                final int threadIdx = getNextThreadIndex();\n+                final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+                resizeThreadCache(cacheSizePerThread);\n+                final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+                synchronized (stateLock) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTM5NjE0OQ=="}, "originalCommit": {"oid": "6f6e589e0024878ebfd8b4657e8a04df5278bb90"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1OTE3NDg1OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNjo1NDowNVrOH-mteA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxODoyNDowN1rOH-q77Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQwNzk5Mg==", "bodyText": "Shouldn't that be int i = 1; i <= threads.size(); i++? Otherwise, we would look up *-StreamThread-0\" and we would not look up \"*-StreamThread-\" + threads.size().\nCould you add some tests that check the correct naming as @mjsax suggested?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r535407992", "createdAt": "2020-12-03T16:54:05Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +900,75 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (newThread) {\n+            if (isRunningOrRebalancing()) {\n+                final int threadIdx = getNextThreadIndex();\n+                final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+                resizeThreadCache(cacheSizePerThread);\n+                final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+                synchronized (stateLock) {\n+                    if (isRunningOrRebalancing()) {\n+                        streamThread.start();\n+                        return Optional.of(streamThread.getName());\n+                    } else {\n+                        streamThread.shutdown();\n+                        threads.remove(streamThread);\n+                        resizeThreadCache(getCacheSizePerThread(threads.size()));\n+                        return Optional.empty();\n+                    }\n+                }\n+            }\n+        }\n+        return Optional.empty();\n+    }\n \n-        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);\n-        if (hasGlobalTopology) {\n-            globalStreamThread.setStateListener(streamStateListener);\n+    private int getNextThreadIndex() {\n+        final HashSet<String> names = new HashSet<>();\n+        for (final StreamThread streamThread: threads) {\n+            names.add(streamThread.getName());\n         }\n-        for (final StreamThread thread : threads) {\n-            thread.setStateListener(streamStateListener);\n+        final String baseName = clientId + \"-StreamThread-\";\n+        for (int i = 0; i < threads.size(); i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f6e589e0024878ebfd8b4657e8a04df5278bb90"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ3NzIyOQ==", "bodyText": "Sure, I missed that suggestion", "url": "https://github.com/apache/kafka/pull/9615#discussion_r535477229", "createdAt": "2020-12-03T18:24:07Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -870,43 +900,75 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1,\n+                threadIdx,\n                 KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n+                streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n \n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (newThread) {\n+            if (isRunningOrRebalancing()) {\n+                final int threadIdx = getNextThreadIndex();\n+                final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+                resizeThreadCache(cacheSizePerThread);\n+                final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+                synchronized (stateLock) {\n+                    if (isRunningOrRebalancing()) {\n+                        streamThread.start();\n+                        return Optional.of(streamThread.getName());\n+                    } else {\n+                        streamThread.shutdown();\n+                        threads.remove(streamThread);\n+                        resizeThreadCache(getCacheSizePerThread(threads.size()));\n+                        return Optional.empty();\n+                    }\n+                }\n+            }\n+        }\n+        return Optional.empty();\n+    }\n \n-        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);\n-        if (hasGlobalTopology) {\n-            globalStreamThread.setStateListener(streamStateListener);\n+    private int getNextThreadIndex() {\n+        final HashSet<String> names = new HashSet<>();\n+        for (final StreamThread streamThread: threads) {\n+            names.add(streamThread.getName());\n         }\n-        for (final StreamThread thread : threads) {\n-            thread.setStateListener(streamStateListener);\n+        final String baseName = clientId + \"-StreamThread-\";\n+        for (int i = 0; i < threads.size(); i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQwNzk5Mg=="}, "originalCommit": {"oid": "6f6e589e0024878ebfd8b4657e8a04df5278bb90"}, "originalPosition": 200}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NTA2OTAwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxODoxMTo1MFrOH_cRQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxOToxMToxM1rOH_eTEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI4NTUwNQ==", "bodyText": "Why do we need this new lock-object? Would it not be simpler to just reuse stateLock ?", "url": "https://github.com/apache/kafka/pull/9615#discussion_r536285505", "createdAt": "2020-12-04T18:11:50Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -845,67 +856,118 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n-        for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n-                internalTopologyBuilder,\n-                config,\n-                clientSupplier,\n-                adminClient,\n-                processId,\n-                clientId,\n-                streamsMetrics,\n-                time,\n-                streamsMetadataState,\n-                cacheSizePerThread,\n-                stateDirectory,\n-                delegatingStateRestoreListener,\n-                i + 1,\n-                KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n-\n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n-\n-        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n+        streamStateListener = new StreamStateListener(threadState, globalThreadState);\n         if (hasGlobalTopology) {\n             globalStreamThread.setStateListener(streamStateListener);\n         }\n-        for (final StreamThread thread : threads) {\n-            thread.setStateListener(streamStateListener);\n+        for (int i = 1; i <= numStreamThreads; i++) {\n+            createStreamThread(cacheSizePerThread, i);\n         }\n \n+        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n+            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+\n         final GlobalStateStoreProvider globalStateStoreProvider = new GlobalStateStoreProvider(internalTopologyBuilder.globalStateStores());\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+            internalTopologyBuilder,\n+            config,\n+            clientSupplier,\n+            adminClient,\n+            processId,\n+            clientId,\n+            streamsMetrics,\n+            time,\n+            streamsMetadataState,\n+            cacheSizePerThread,\n+            stateDirectory,\n+            delegatingStateRestoreListener,\n+            threadIdx,\n+            KafkaStreams.this::closeToError,\n+            streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (changeThreadCount) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af3e5674f77037796801afcd445e126c1aa7f6b0"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMxODczNw==", "bodyText": "We thought it would be better use a separate lock because it is serving a different purpose. It will also use used in remove thread. It might be simpler to reuse the statelock but I don\u2019t think that would be cleaner. We are really locking on the thread cache access and the thread indexes", "url": "https://github.com/apache/kafka/pull/9615#discussion_r536318737", "createdAt": "2020-12-04T19:11:13Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -845,67 +856,118 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n-        for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n-                internalTopologyBuilder,\n-                config,\n-                clientSupplier,\n-                adminClient,\n-                processId,\n-                clientId,\n-                streamsMetrics,\n-                time,\n-                streamsMetadataState,\n-                cacheSizePerThread,\n-                stateDirectory,\n-                delegatingStateRestoreListener,\n-                i + 1,\n-                KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n-\n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n-\n-        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n+        streamStateListener = new StreamStateListener(threadState, globalThreadState);\n         if (hasGlobalTopology) {\n             globalStreamThread.setStateListener(streamStateListener);\n         }\n-        for (final StreamThread thread : threads) {\n-            thread.setStateListener(streamStateListener);\n+        for (int i = 1; i <= numStreamThreads; i++) {\n+            createStreamThread(cacheSizePerThread, i);\n         }\n \n+        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n+            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+\n         final GlobalStateStoreProvider globalStateStoreProvider = new GlobalStateStoreProvider(internalTopologyBuilder.globalStateStores());\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+            internalTopologyBuilder,\n+            config,\n+            clientSupplier,\n+            adminClient,\n+            processId,\n+            clientId,\n+            streamsMetrics,\n+            time,\n+            streamsMetadataState,\n+            cacheSizePerThread,\n+            stateDirectory,\n+            delegatingStateRestoreListener,\n+            threadIdx,\n+            KafkaStreams.this::closeToError,\n+            streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (changeThreadCount) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI4NTUwNQ=="}, "originalCommit": {"oid": "af3e5674f77037796801afcd445e126c1aa7f6b0"}, "originalPosition": 191}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3895, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}