{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk1MDYwNjQ3", "number": 8380, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMjozMDoyOFrODs4KBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMjozNjowOVrODs4P_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4Mzg0MDA3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsProducer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMjozMDoyOFrOF9-ngA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMTo0NzowNVrOF-uC6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDUzMzM3Ng==", "bodyText": "We can get the processing mode from the first parameter config right?", "url": "https://github.com/apache/kafka/pull/8380#discussion_r400533376", "createdAt": "2020-03-30T22:30:28Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsProducer.java", "diffHunk": "@@ -52,31 +61,78 @@\n     private final Logger log;\n     private final String logPrefix;\n \n+    private final StreamThread.ProcessingMode processingMode;\n     private final Producer<byte[], byte[]> producer;\n-    private final boolean eosEnabled;\n \n     private boolean transactionInFlight = false;\n     private boolean transactionInitialized = false;\n \n-    public StreamsProducer(final Producer<byte[], byte[]> producer,\n-                           final boolean eosEnabled,\n+    public StreamsProducer(final StreamsConfig config,\n+                           final String threadId,\n+                           final KafkaClientSupplier clientSupplier,\n+                           final StreamThread.ProcessingMode processingMode,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMDQ0Mw==", "bodyText": "+1", "url": "https://github.com/apache/kafka/pull/8380#discussion_r401310443", "createdAt": "2020-04-01T01:47:05Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsProducer.java", "diffHunk": "@@ -52,31 +61,78 @@\n     private final Logger log;\n     private final String logPrefix;\n \n+    private final StreamThread.ProcessingMode processingMode;\n     private final Producer<byte[], byte[]> producer;\n-    private final boolean eosEnabled;\n \n     private boolean transactionInFlight = false;\n     private boolean transactionInitialized = false;\n \n-    public StreamsProducer(final Producer<byte[], byte[]> producer,\n-                           final boolean eosEnabled,\n+    public StreamsProducer(final StreamsConfig config,\n+                           final String threadId,\n+                           final KafkaClientSupplier clientSupplier,\n+                           final StreamThread.ProcessingMode processingMode,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDUzMzM3Ng=="}, "originalCommit": null, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4Mzg1NTMzOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsProducerTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMjozNjowOVrOF9-w2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxOToxNjowM1rOF_O-Yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDUzNTc2OQ==", "bodyText": "This is a meta comment for this test class: I think there are a lot of opportunities to reduce the 500+ LOC here sine many are duplicated code. For example, we can have a single mock KafkaProducer and have ALO / EOS_ALPHA / EOS_BETA streams producer wrapping the client supplier which would return the mock producer. And then in each unit test we could save creating the mock producer, creating the streams producer etc which are almost in every test function.", "url": "https://github.com/apache/kafka/pull/8380#discussion_r400535769", "createdAt": "2020-03-30T22:36:09Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsProducerTest.java", "diffHunk": "@@ -66,27 +72,57 @@\n         Collections.emptySet()\n     );\n \n-    private final ByteArraySerializer byteArraySerializer = new ByteArraySerializer();\n-    private final Map<TopicPartition, OffsetAndMetadata> offsetsAndMetadata = mkMap(\n-        mkEntry(new TopicPartition(topic, 0), new OffsetAndMetadata(0L, null))\n+    private final StreamsConfig config = new StreamsConfig(mkMap(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MjYwNg==", "bodyText": "We can do some of that but not all. If we use a mock(Producer.class) what you say works.\nHowever, if we use MockProducer this does not work, because we need to setup the MockProducer either for non-eos or eos and thus we need two instances. Therefore, we also need an StreamsProducer for each case.", "url": "https://github.com/apache/kafka/pull/8380#discussion_r401342606", "createdAt": "2020-04-01T03:58:48Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsProducerTest.java", "diffHunk": "@@ -66,27 +72,57 @@\n         Collections.emptySet()\n     );\n \n-    private final ByteArraySerializer byteArraySerializer = new ByteArraySerializer();\n-    private final Map<TopicPartition, OffsetAndMetadata> offsetsAndMetadata = mkMap(\n-        mkEntry(new TopicPartition(topic, 0), new OffsetAndMetadata(0L, null))\n+    private final StreamsConfig config = new StreamsConfig(mkMap(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDUzNTc2OQ=="}, "originalCommit": null, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg0OTk1NA==", "bodyText": "Yes I'm talking about using a mock(Producer.class).", "url": "https://github.com/apache/kafka/pull/8380#discussion_r401849954", "createdAt": "2020-04-01T19:16:03Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsProducerTest.java", "diffHunk": "@@ -66,27 +72,57 @@\n         Collections.emptySet()\n     );\n \n-    private final ByteArraySerializer byteArraySerializer = new ByteArraySerializer();\n-    private final Map<TopicPartition, OffsetAndMetadata> offsetsAndMetadata = mkMap(\n-        mkEntry(new TopicPartition(topic, 0), new OffsetAndMetadata(0L, null))\n+    private final StreamsConfig config = new StreamsConfig(mkMap(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDUzNTc2OQ=="}, "originalCommit": null, "originalPosition": 48}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3142, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}