{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI3NTM2Nzg1", "number": 8799, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQwMTo0MDowMlrOECYEog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNDozNDowMlrOEC0HmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwOTI3MDEwOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQwMTo0MDowMlrOGey7gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzozNDo0OFrOGf3TlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw==", "bodyText": "Should we call close in the finally block? Here and elsewhere", "url": "https://github.com/apache/kafka/pull/8799#discussion_r434944897", "createdAt": "2020-06-04T01:40:02Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MzY1MA==", "bodyText": "I don't think that is necessary -- there is an @After method that closed the client for us.", "url": "https://github.com/apache/kafka/pull/8799#discussion_r435583650", "createdAt": "2020-06-04T22:18:55Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw=="}, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4NDQzOA==", "bodyText": "Then why close it here as well?", "url": "https://github.com/apache/kafka/pull/8799#discussion_r435584438", "createdAt": "2020-06-04T22:21:04Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw=="}, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4NzAxNw==", "bodyText": "I think it's better to first close it before we delete the topics.", "url": "https://github.com/apache/kafka/pull/8799#discussion_r435587017", "createdAt": "2020-06-04T22:28:50Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw=="}, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4ODg0Nw==", "bodyText": "Well, won't we end up deleting the topics before closing it if we never reach the first streams.close ? Or does it not really matter in that case since something has already gone wrong (just curious, I'm fine with it as-is btw)", "url": "https://github.com/apache/kafka/pull/8799#discussion_r435588847", "createdAt": "2020-06-04T22:33:48Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw=="}, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU5NzM5Nw==", "bodyText": "Yes, that is my reasoning.", "url": "https://github.com/apache/kafka/pull/8799#discussion_r435597397", "createdAt": "2020-06-04T22:58:32Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw=="}, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NTI5NA==", "bodyText": "Why we need to call streams.close() inside the function given they are always called in tearDown? Ditto below.", "url": "https://github.com/apache/kafka/pull/8799#discussion_r435685294", "createdAt": "2020-06-05T04:36:30Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw=="}, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2NTE3Mg==", "bodyText": "As mentioned above: we should close the client before we delete the input topics. -- Seems cleaner.", "url": "https://github.com/apache/kafka/pull/8799#discussion_r436065172", "createdAt": "2020-06-05T17:34:48Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -142,83 +142,89 @@ public void tearDown() throws IOException {\n \n     @Test\n     public void testRegexMatchesTopicsAWhenCreated() throws Exception {\n+        try {\n+            final Serde<String> stringSerde = Serdes.String();\n \n-        final Serde<String> stringSerde = Serdes.String();\n-\n-        final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n-        // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n-        // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n-        // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n-        final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            final List<String> expectedFirstAssignment = Collections.singletonList(\"TEST-TOPIC-1\");\n+            // we compare lists of subscribed topics and hence requiring the order as well; this is guaranteed\n+            // with KIP-429 since we would NOT revoke TEST-TOPIC-1 but only add TEST-TOPIC-2 so the list is always\n+            // in the order of \"TEST-TOPIC-1, TEST-TOPIC-2\". Note if KIP-429 behavior ever changed it may become a flaky test\n+            final List<String> expectedSecondAssignment = Arrays.asList(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-1\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-1\");\n \n-        final StreamsBuilder builder = new StreamsBuilder();\n+            final StreamsBuilder builder = new StreamsBuilder();\n \n-        final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n+            final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n \n-        pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n-        final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n-        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n-            @Override\n-            public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n-                return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n-                    @Override\n-                    public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n-                        super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n-                    }\n-                };\n+            pattern1Stream.to(outputTopic, Produced.with(stringSerde, stringSerde));\n+            final List<String> assignedTopics = new CopyOnWriteArrayList<>();\n+            streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {\n+                @Override\n+                public Consumer<byte[], byte[]> getConsumer(final Map<String, Object> config) {\n+                    return new KafkaConsumer<byte[], byte[]>(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {\n+                        @Override\n+                        public void subscribe(final Pattern topics, final ConsumerRebalanceListener listener) {\n+                            super.subscribe(topics, new TheConsumerRebalanceListener(assignedTopics, listener));\n+                        }\n+                    };\n \n-            }\n-        });\n+                }\n+            });\n \n-        streams.start();\n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n+            streams.start();\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedFirstAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        CLUSTER.createTopic(\"TEST-TOPIC-2\");\n+            CLUSTER.createTopic(\"TEST-TOPIC-2\");\n \n-        TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n+            TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n-        streams.close();\n-        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+            streams.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NDg5Nw=="}, "originalCommit": {"oid": "897c2003c11e0324660d1f3bd877e4c281725737"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMzg2NTIxOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNDozNDowMlrOGfgFhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNDozNDowMlrOGfgFhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NDc0Mw==", "bodyText": "Could we use\n    @Rule\n    public TestName testName = new TestName();\n\ninstead as the suffix?", "url": "https://github.com/apache/kafka/pull/8799#discussion_r435684743", "createdAt": "2020-06-05T04:34:02Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -124,7 +124,7 @@ public void setUp() throws InterruptedException {\n         properties.put(ConsumerConfig.METADATA_MAX_AGE_CONFIG, \"1000\");\n         properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n \n-        streamsConfiguration = StreamsTestUtils.getStreamsConfig(\"regex-source-integration-test\",\n+        streamsConfiguration = StreamsTestUtils.getStreamsConfig(\"regex-source-integration-test-\" + topicSuffixGenerator.get(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c2a6d56caed5b12cf7bc5bd030be305de754b35"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2510, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}