{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1NTgzMjE0", "number": 8256, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMzo0Njo1MFrODmTABg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQyMjoyMjozMlrODm4JVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNDgzNzgyOnYy", "diffSide": "LEFT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMzo0Njo1MFrOFzocnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMzo0Njo1MFrOFzocnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTY4NDM4MQ==", "bodyText": "This is the fix. For an explanation read the commit message.", "url": "https://github.com/apache/kafka/pull/8256#discussion_r389684381", "createdAt": "2020-03-09T13:46:50Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -188,11 +188,12 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n+        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // with the measurements from Rocks DB\n+        maybeSetUpMetricsRecorder(context, configs);\n+\n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n-\n-        // Do this last because the prior operations could throw exceptions.\n-        maybeSetUpMetricsRecorder(context, configs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a652b378d51c3a83b71758d191d439457123b6ba"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNDg3MDU3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMzo1MTozN1rOFzoyRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMzo1MTozN1rOFzoyRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTY4OTkyNw==", "bodyText": "This verifies that the metrics are updated when the measurements in the statistics object change. Unfortunately, the tests the use this verification run more than a minute, because the thread that triggers the recordings of the RocksDB metrics takes some time to record its first value.", "url": "https://github.com/apache/kafka/pull/8256#discussion_r389689927", "createdAt": "2020-03-09T13:51:37Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "diffHunk": "@@ -283,13 +333,38 @@ private void verifyRocksDBMetrics(final KafkaStreams kafkaStreams, final String\n         checkMetricByName(listMetricStore, NUMBER_OF_FILE_ERRORS, 1);\n     }\n \n-    private void checkMetricByName(final List<Metric> listMetric, final String metricName, final int numMetric) {\n+    private void checkMetricByName(final List<Metric> listMetric,\n+                                   final String metricName,\n+                                   final int numMetric) {\n         final List<Metric> metrics = listMetric.stream()\n             .filter(m -> m.metricName().name().equals(metricName))\n             .collect(Collectors.toList());\n-        Assert.assertEquals(\"Size of metrics of type:'\" + metricName + \"' must be equal to \" + numMetric + \" but it's equal to \" + metrics.size(), numMetric, metrics.size());\n-        for (final Metric m : metrics) {\n-            Assert.assertNotNull(\"Metric:'\" + m.metricName() + \"' must be not null\", m.metricValue());\n+        assertThat(\n+            \"Size of metrics of type:'\" + metricName + \"' must be equal to \" + numMetric + \" but it's equal to \" + metrics.size(),\n+            metrics.size(),\n+            is(numMetric)\n+        );\n+        for (final Metric metric : metrics) {\n+            assertThat(\"Metric:'\" + metric.metricName() + \"' must be not null\", metric.metricValue(), is(notNullValue()));\n         }\n     }\n-}\n+\n+    private void verifyThatBytesWrittenTotalIncreases(final KafkaStreams kafkaStreams,\n+                                                      final String metricsScope) throws InterruptedException {\n+        final List<Metric> metric = getRocksDBMetrics(kafkaStreams, metricsScope).stream()\n+            .filter(m -> BYTES_WRITTEN_TOTAL.equals(m.metricName().name()))\n+            .collect(Collectors.toList());\n+        TestUtils.waitForCondition(\n+            () -> (double) metric.get(0).metricValue() > 0,\n+            TIMEOUT,\n+            () -> \"RocksDB metric bytes.written.total did not increase in \" + TIMEOUT + \" ms\"\n+        );\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a652b378d51c3a83b71758d191d439457123b6ba"}, "originalPosition": 211}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNDg3NDI1OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMzo1MjoxMlrOFzo0mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMzo1MjoxMlrOFzo0mQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTY5MDUyMQ==", "bodyText": "This is one of the tests that verifies the fix. See my comment in verifyThatBytesWrittenTotalIncreases().", "url": "https://github.com/apache/kafka/pull/8256#discussion_r389690521", "createdAt": "2020-03-09T13:52:12Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "diffHunk": "@@ -142,21 +155,58 @@ public void shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailur\n         final Properties streamsConfiguration = streamsConfig();\n         IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n         final StreamsBuilder builder = builderForSegmentedStateStore();\n+        final String metricsScope = \"rocksdb-window-state-id\";\n+\n+        cleanUpStateRunAndVerify(\n+            builder,\n+            streamsConfiguration,\n+            LongDeserializer.class,\n+            LongDeserializer.class,\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );\n \n         cleanUpStateRunAndVerify(\n             builder,\n             streamsConfiguration,\n             LongDeserializer.class,\n             LongDeserializer.class,\n-            \"rocksdb-window-state-id\"\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );\n+    }\n+\n+    @Test\n+    public void shouldVerifyThatMetricsGetMeasurementsFromRocksDBForNonSegmentedStateStore() throws Exception {\n+        final Properties streamsConfiguration = streamsConfig();\n+        IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n+        final StreamsBuilder builder = builderForNonSegmentedStateStore();\n+        final String metricsScope = \"rocksdb-state-id\";\n+\n+        cleanUpStateRunAndVerify(\n+            builder,\n+            streamsConfiguration,\n+            IntegerDeserializer.class,\n+            StringDeserializer.class,\n+            this::verifyThatBytesWrittenTotalIncreases,\n+            metricsScope\n         );\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a652b378d51c3a83b71758d191d439457123b6ba"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyMDkyMzc0OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQyMjoyMjozMlrOF0jItQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwOTozOTo0MFrOF1XQjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY0NTk0MQ==", "bodyText": "Do I read this right, that we're doing the exact same thing twice?", "url": "https://github.com/apache/kafka/pull/8256#discussion_r390645941", "createdAt": "2020-03-10T22:22:32Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "diffHunk": "@@ -142,21 +155,58 @@ public void shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailur\n         final Properties streamsConfiguration = streamsConfig();\n         IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n         final StreamsBuilder builder = builderForSegmentedStateStore();\n+        final String metricsScope = \"rocksdb-window-state-id\";\n+\n+        cleanUpStateRunAndVerify(\n+            builder,\n+            streamsConfiguration,\n+            LongDeserializer.class,\n+            LongDeserializer.class,\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );\n \n         cleanUpStateRunAndVerify(\n             builder,\n             streamsConfiguration,\n             LongDeserializer.class,\n             LongDeserializer.class,\n-            \"rocksdb-window-state-id\"\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a652b378d51c3a83b71758d191d439457123b6ba"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgxOTAyOA==", "bodyText": "As the test name says shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailureWithEmptyStateDir() this test verifies that the metrics are still there after a failure and an empty state dir (see https://issues.apache.org/jira/browse/KAFKA-9355).\nI basically simulate a failure by closing the app, wiping out the state, re-starting the app, verifying the exposure of the metrics, and closing the app. That results in doing twice the same thing.", "url": "https://github.com/apache/kafka/pull/8256#discussion_r390819028", "createdAt": "2020-03-11T08:48:50Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "diffHunk": "@@ -142,21 +155,58 @@ public void shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailur\n         final Properties streamsConfiguration = streamsConfig();\n         IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n         final StreamsBuilder builder = builderForSegmentedStateStore();\n+        final String metricsScope = \"rocksdb-window-state-id\";\n+\n+        cleanUpStateRunAndVerify(\n+            builder,\n+            streamsConfiguration,\n+            LongDeserializer.class,\n+            LongDeserializer.class,\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );\n \n         cleanUpStateRunAndVerify(\n             builder,\n             streamsConfiguration,\n             LongDeserializer.class,\n             LongDeserializer.class,\n-            \"rocksdb-window-state-id\"\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY0NTk0MQ=="}, "originalCommit": {"oid": "a652b378d51c3a83b71758d191d439457123b6ba"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE2NjE4OQ==", "bodyText": "Oh, I see. Definitely wasn't obvious by reading the test.", "url": "https://github.com/apache/kafka/pull/8256#discussion_r391166189", "createdAt": "2020-03-11T18:07:52Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "diffHunk": "@@ -142,21 +155,58 @@ public void shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailur\n         final Properties streamsConfiguration = streamsConfig();\n         IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n         final StreamsBuilder builder = builderForSegmentedStateStore();\n+        final String metricsScope = \"rocksdb-window-state-id\";\n+\n+        cleanUpStateRunAndVerify(\n+            builder,\n+            streamsConfiguration,\n+            LongDeserializer.class,\n+            LongDeserializer.class,\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );\n \n         cleanUpStateRunAndVerify(\n             builder,\n             streamsConfiguration,\n             LongDeserializer.class,\n             LongDeserializer.class,\n-            \"rocksdb-window-state-id\"\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY0NTk0MQ=="}, "originalCommit": {"oid": "a652b378d51c3a83b71758d191d439457123b6ba"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ5OTkxOQ==", "bodyText": "I tried to make the tests clearer.", "url": "https://github.com/apache/kafka/pull/8256#discussion_r391499919", "createdAt": "2020-03-12T09:39:40Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "diffHunk": "@@ -142,21 +155,58 @@ public void shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailur\n         final Properties streamsConfiguration = streamsConfig();\n         IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n         final StreamsBuilder builder = builderForSegmentedStateStore();\n+        final String metricsScope = \"rocksdb-window-state-id\";\n+\n+        cleanUpStateRunAndVerify(\n+            builder,\n+            streamsConfiguration,\n+            LongDeserializer.class,\n+            LongDeserializer.class,\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );\n \n         cleanUpStateRunAndVerify(\n             builder,\n             streamsConfiguration,\n             LongDeserializer.class,\n             LongDeserializer.class,\n-            \"rocksdb-window-state-id\"\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY0NTk0MQ=="}, "originalCommit": {"oid": "a652b378d51c3a83b71758d191d439457123b6ba"}, "originalPosition": 90}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3277, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}