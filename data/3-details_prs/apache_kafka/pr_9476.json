{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3ODg2NDIz", "number": 9476, "title": "MINOR: Refactor RaftClientTest to be used by other tests", "bodyText": "There is a lot of functionality in KafkaRaftClientTest that is useful for writing other tests. Refactor that functionality into another class that can be reused in other tests.\nMore detailed description of your change,\nif necessary. The PR title and PR message become\nthe squashed commit message, so use a separate\ncomment to ping reviewers.\nSummary of testing strategy (including rationale)\nfor the feature or bug fix. Unit and/or integration\ntests are expected for any behaviour change and\nsystem tests should be considered for larger changes.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-10-21T21:56:37Z", "url": "https://github.com/apache/kafka/pull/9476", "merged": true, "mergeCommit": {"oid": "94820ca652aceccef5f617e6ca139d139fa25a1b"}, "closed": true, "closedAt": "2020-10-23T01:14:27Z", "author": {"login": "jsancio"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdUkdFKAH2gAyNTA3ODg2NDIzOjAwNmMxMGI0OTk5ZjVkMzc5NjI5ODc0YWEyMjQyMzBiODM1OTJjNzk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdVKJFUgFqTUxNTE3NTY5Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "006c10b4999f5d379629874aa224230b83592c79", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/006c10b4999f5d379629874aa224230b83592c79", "committedDate": "2020-10-21T03:04:04Z", "message": "MINOR: Refactor RaftClientTest to be used by other tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5471c7864aa14ff4c671c96e2d99f70e32e18163", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/5471c7864aa14ff4c671c96e2d99f70e32e18163", "committedDate": "2020-10-21T21:46:59Z", "message": "Refactor all of the KafkaRaftClientTest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f", "committedDate": "2020-10-21T21:54:44Z", "message": "Remove commentted out imports"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0MjM1NTcx", "url": "https://github.com/apache/kafka/pull/9476#pullrequestreview-514235571", "createdAt": "2020-10-21T22:30:52Z", "commit": {"oid": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQyMjozMTowNlrOHmJU0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQyMjo0MzoxN1rOHmKBiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc2MDcyMw==", "bodyText": "I think nearly every call to updateQuorumStateStore is just writing an initial state. Seems like we can introduce a more direct option to the builder.\nBy the way, one of the annoyances is needing to provide voters through the initial state and through build below. Since we always need voters, maybe we can provide it in the builder constructor. That would allow us to add helpers to construct the state. For example, we could turn this into:\nnew RaftClientTestContext.Builder(voters)\n  .initializeAsFollower(epoch, otherNodeId)\n  .build()\nSimilarly, we could probably do state assertions in the test context as well and save the need to always pass through voters (e.g. we could have context.assertFollower(epoch, leaderId) instead of the cumbersome assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState())).", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509760723", "createdAt": "2020-10-21T22:31:06Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -1729,126 +1695,156 @@ public void testLeaderGracefulShutdownTimeout() throws Exception {\n     public void testFollowerGracefulShutdown() throws Exception {\n         int otherNodeId = 1;\n         int epoch = 5;\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n \n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), quorumStateStore.readElectionState());\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f"}, "originalPosition": 2485}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc2NzQxMA==", "bodyText": "nit: we have assertions like this in many test cases. With a more direct api to update quorum state, we can move these assertions into that api.", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509767410", "createdAt": "2020-10-21T22:36:45Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -1729,126 +1695,156 @@ public void testLeaderGracefulShutdownTimeout() throws Exception {\n     public void testFollowerGracefulShutdown() throws Exception {\n         int otherNodeId = 1;\n         int epoch = 5;\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n \n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), quorumStateStore.readElectionState());\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n+                });\n+            })\n+            .build(voters);\n \n-        client.poll();\n+        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState());\n+\n+        context.client.poll();\n \n         int shutdownTimeoutMs = 5000;\n-        CompletableFuture<Void> shutdownFuture = client.shutdown(shutdownTimeoutMs);\n-        assertTrue(client.isRunning());\n+        CompletableFuture<Void> shutdownFuture = context.client.shutdown(shutdownTimeoutMs);\n+        assertTrue(context.client.isRunning());\n         assertFalse(shutdownFuture.isDone());\n \n-        client.poll();\n-        assertFalse(client.isRunning());\n+        context.client.poll();\n+        assertFalse(context.client.isRunning());\n         assertTrue(shutdownFuture.isDone());\n         assertNull(shutdownFuture.get());\n     }\n \n     @Test\n     public void testGracefulShutdownSingleMemberQuorum() throws IOException {\n-        KafkaRaftClient client = buildClient(Collections.singleton(localId));\n+        RaftClientTestContext context = RaftClientTestContext.build(Collections.singleton(LOCAL_ID));\n+\n         assertEquals(ElectionState.withElectedLeader(\n-            1, localId, Collections.singleton(localId)), quorumStateStore.readElectionState());\n-        client.poll();\n-        assertEquals(0, channel.drainSendQueue().size());\n+            1, LOCAL_ID, Collections.singleton(LOCAL_ID)), context.quorumStateStore.readElectionState());\n+        context.client.poll();\n+        assertEquals(0, context.channel.drainSendQueue().size());\n         int shutdownTimeoutMs = 5000;\n-        client.shutdown(shutdownTimeoutMs);\n-        assertTrue(client.isRunning());\n-        client.poll();\n-        assertFalse(client.isRunning());\n+        context.client.shutdown(shutdownTimeoutMs);\n+        assertTrue(context.client.isRunning());\n+        context.client.poll();\n+        assertFalse(context.client.isRunning());\n     }\n \n     @Test\n     public void testFollowerReplication() throws Exception {\n         int otherNodeId = 1;\n         int epoch = 5;\n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), quorumStateStore.readElectionState());\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n+\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n+                });\n+            })\n+            .build(voters);\n+\n+        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState());\n \n-        pollUntilSend(client);\n+        context.pollUntilSend();\n \n-        int fetchQuorumCorrelationId = assertSentFetchRequest(epoch, 0L, 0);\n+        int fetchQuorumCorrelationId = context.assertSentFetchRequest(epoch, 0L, 0);\n         Records records = MemoryRecords.withRecords(0L, CompressionType.NONE,\n             3, new SimpleRecord(\"a\".getBytes()), new SimpleRecord(\"b\".getBytes()));\n         FetchResponseData response = fetchResponse(epoch, otherNodeId, records, 0L, Errors.NONE);\n-        deliverResponse(fetchQuorumCorrelationId, otherNodeId, response);\n+        context.deliverResponse(fetchQuorumCorrelationId, otherNodeId, response);\n \n-        client.poll();\n-        assertEquals(2L, log.endOffset().offset);\n-        assertEquals(2L, log.lastFlushedOffset());\n+        context.client.poll();\n+        assertEquals(2L, context.log.endOffset().offset);\n+        assertEquals(2L, context.log.lastFlushedOffset());\n     }\n \n     @Test\n     public void testEmptyRecordSetInFetchResponse() throws Exception {\n         int otherNodeId = 1;\n         int epoch = 5;\n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n \n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), quorumStateStore.readElectionState());\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n+                });\n+            })\n+            .build(voters);\n+\n+        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f"}, "originalPosition": 2592}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc3MjE2OQ==", "bodyText": "nit: it is a tad vexing to see all the context prefixes. I guess another option might be to define RaftClientTestContext as an abstract class so that the test method can define the test behavior within the scope of a subclass.\nFor example:\nnew RaftClientTestContext(builder) {\n  void run() {\n    assertTrue(client.isShuttingDown());\n    ...\n  }\n}\nNot required, just an alternative to consider.", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509772169", "createdAt": "2020-10-21T22:43:17Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -1536,67 +1522,70 @@ public void testObserverLeaderRediscoveryAfterRequestTimeout() throws Exception\n         int otherNodeId = 2;\n         int epoch = 5;\n         Set<Integer> voters = Utils.mkSet(leaderId, otherNodeId);\n-        KafkaRaftClient client = buildClient(voters);\n-        discoverLeaderAsObserver(client, voters, leaderId, epoch);\n \n-        pollUntilSend(client);\n-        RaftRequest.Outbound fetchRequest1 = assertSentFetchRequest();\n+        RaftClientTestContext context = RaftClientTestContext.build(voters);\n+\n+        context.discoverLeaderAsObserver(voters, leaderId, epoch);\n+\n+        context.pollUntilSend();\n+        RaftRequest.Outbound fetchRequest1 = context.assertSentFetchRequest();\n         assertEquals(leaderId, fetchRequest1.destinationId());\n-        assertFetchRequestData(fetchRequest1, epoch, 0L, 0);\n+        RaftClientTestContext.assertFetchRequestData(fetchRequest1, epoch, 0L, 0);\n \n-        time.sleep(requestTimeoutMs);\n-        pollUntilSend(client);\n+        context.time.sleep(REQUEST_TIMEOUT_MS);\n+        context.pollUntilSend();\n \n         // We should retry the Fetch against the other voter since the original\n         // voter connection will be backing off.\n-        RaftRequest.Outbound fetchRequest2 = assertSentFetchRequest();\n+        RaftRequest.Outbound fetchRequest2 = context.assertSentFetchRequest();\n         assertNotEquals(leaderId, fetchRequest2.destinationId());\n         assertTrue(voters.contains(fetchRequest2.destinationId()));\n-        assertFetchRequestData(fetchRequest2, epoch, 0L, 0);\n+        RaftClientTestContext.assertFetchRequestData(fetchRequest2, epoch, 0L, 0);\n \n-        deliverResponse(fetchRequest2.correlationId, fetchRequest2.destinationId(),\n+        context.deliverResponse(fetchRequest2.correlationId, fetchRequest2.destinationId(),\n             fetchResponse(epoch, leaderId, MemoryRecords.EMPTY, 0L, Errors.FENCED_LEADER_EPOCH));\n-        client.poll();\n+        context.client.poll();\n \n-        assertEquals(ElectionState.withElectedLeader(epoch, leaderId, voters), quorumStateStore.readElectionState());\n+        assertEquals(ElectionState.withElectedLeader(epoch, leaderId, voters), context.quorumStateStore.readElectionState());\n     }\n \n     @Test\n     public void testLeaderGracefulShutdown() throws Exception {\n         int otherNodeId = 1;\n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n         int epoch = 1;\n-        KafkaRaftClient client = initializeAsLeader(voters, epoch);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n+\n+        RaftClientTestContext context = RaftClientTestContext.initializeAsLeader(voters, epoch);\n \n         // Now shutdown\n         int shutdownTimeoutMs = 5000;\n-        CompletableFuture<Void> shutdownFuture = client.shutdown(shutdownTimeoutMs);\n+        CompletableFuture<Void> shutdownFuture = context.client.shutdown(shutdownTimeoutMs);\n \n         // We should still be running until we have had a chance to send EndQuorumEpoch\n-        assertTrue(client.isShuttingDown());\n-        assertTrue(client.isRunning());\n+        assertTrue(context.client.isShuttingDown());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f"}, "originalPosition": 2294}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0MzE0MDA5", "url": "https://github.com/apache/kafka/pull/9476#pullrequestreview-514314009", "createdAt": "2020-10-22T02:21:10Z", "commit": {"oid": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwMjoyMToxMFrOHmOLiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwMjoyMToxMFrOHmOLiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MDI2NQ==", "bodyText": "@hachikuji is this a bug? Shouldn't the leader (LOCAL_ID) always be a voter (the second argument for this function)?", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509840265", "createdAt": "2020-10-22T02:21:10Z", "author": {"login": "jsancio"}, "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -90,470 +76,480 @@\n import static org.junit.jupiter.api.Assertions.assertTrue;\n \n public class KafkaRaftClientTest {\n-    private static final TopicPartition METADATA_PARTITION = new TopicPartition(\"metadata\", 0);\n-\n-    private final int localId = 0;\n-    private final int electionTimeoutMs = 10000;\n-    private final int electionBackoffMaxMs = 100;\n-    private final int fetchTimeoutMs = 50000;   // fetch timeout is usually larger than election timeout\n-    private final int retryBackoffMs = 50;\n-    private final int requestTimeoutMs = 5000;\n-    private final int fetchMaxWaitMs = 0;\n-\n-    private final MockTime time = new MockTime();\n-    private final MockLog log = new MockLog(METADATA_PARTITION);\n-    private final MockNetworkChannel channel = new MockNetworkChannel();\n-    private final Random random = Mockito.spy(new Random(1));\n-    private final QuorumStateStore quorumStateStore = new MockQuorumStateStore();\n-\n-    @AfterEach\n-    public void cleanUp() throws IOException {\n-        quorumStateStore.clear();\n-    }\n-\n-    private InetSocketAddress mockAddress(int id) {\n-        return new InetSocketAddress(\"localhost\", 9990 + id);\n-    }\n-\n-    private KafkaRaftClient buildClient(Set<Integer> voters) throws IOException {\n-        return buildClient(voters, new Metrics(time));\n-    }\n-\n-    private KafkaRaftClient buildClient(Set<Integer> voters, Metrics metrics) throws IOException {\n-        LogContext logContext = new LogContext();\n-        QuorumState quorum = new QuorumState(localId, voters, electionTimeoutMs, fetchTimeoutMs,\n-            quorumStateStore, time, logContext, random);\n-\n-        Map<Integer, InetSocketAddress> voterAddresses = voters.stream().collect(Collectors.toMap(\n-            Function.identity(),\n-            this::mockAddress\n-        ));\n-\n-        KafkaRaftClient client = new KafkaRaftClient(channel, log, quorum, time, metrics,\n-            new MockFuturePurgatory<>(time), new MockFuturePurgatory<>(time), voterAddresses,\n-            electionBackoffMaxMs, retryBackoffMs, requestTimeoutMs, fetchMaxWaitMs, logContext, random);\n-\n-        client.initialize();\n-\n-        return client;\n-    }\n-\n     @Test\n     public void testInitializeSingleMemberQuorum() throws IOException {\n-        buildClient(Collections.singleton(localId));\n-        assertEquals(ElectionState.withElectedLeader(1, localId, Collections.singleton(localId)),\n-            quorumStateStore.readElectionState());\n+        RaftClientTestContext context = RaftClientTestContext.build(Collections.singleton(LOCAL_ID));\n+        assertEquals(\n+            ElectionState.withElectedLeader(1, LOCAL_ID, Collections.singleton(LOCAL_ID)),\n+            context.quorumStateStore.readElectionState()\n+        );\n     }\n \n     @Test\n     public void testInitializeAsLeaderFromStateStoreSingleMemberQuorum() throws Exception {\n         // Start off as leader. We should still bump the epoch after initialization\n \n         int initialEpoch = 2;\n-        Set<Integer> voters = Collections.singleton(localId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(initialEpoch, localId, voters));\n-\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(1L, log.endOffset().offset);\n-        assertEquals(initialEpoch + 1, log.lastFetchedEpoch());\n-        assertEquals(new LeaderAndEpoch(OptionalInt.of(localId), initialEpoch + 1),\n-            client.currentLeaderAndEpoch());\n-        assertEquals(ElectionState.withElectedLeader(initialEpoch + 1, localId, voters),\n-            quorumStateStore.readElectionState());\n+        Set<Integer> voters = Collections.singleton(LOCAL_ID);\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(\n+                        ElectionState.withElectedLeader(initialEpoch, LOCAL_ID, voters)\n+                    );\n+                });\n+            })\n+            .build(voters);\n+\n+        assertEquals(1L, context.log.endOffset().offset);\n+        assertEquals(initialEpoch + 1, context.log.lastFetchedEpoch());\n+        assertEquals(new LeaderAndEpoch(OptionalInt.of(LOCAL_ID), initialEpoch + 1),\n+            context.client.currentLeaderAndEpoch());\n+        assertEquals(ElectionState.withElectedLeader(initialEpoch + 1, LOCAL_ID, voters),\n+            context.quorumStateStore.readElectionState());\n     }\n \n     @Test\n     public void testInitializeAsLeaderFromStateStore() throws Exception {\n-        Set<Integer> voters = Utils.mkSet(localId, 1);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, 1);\n         int epoch = 2;\n \n-        Mockito.doReturn(0).when(random).nextInt(electionTimeoutMs);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, localId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(0L, log.endOffset().offset);\n-        assertEquals(ElectionState.withUnknownLeader(epoch, voters), quorumStateStore.readElectionState());\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateRandom(random -> {\n+                Mockito.doReturn(0).when(random).nextInt(RaftClientTestContext.ELECTION_TIMEOUT_MS);\n+            })\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, LOCAL_ID, voters));\n+                });\n+            })\n+            .build(voters);\n+\n \n-        time.sleep(electionTimeoutMs);\n-        pollUntilSend(client);\n-        assertSentVoteRequest(epoch + 1, 0, 0L);\n+        assertEquals(0L, context.log.endOffset().offset);\n+        assertEquals(ElectionState.withUnknownLeader(epoch, voters), context.quorumStateStore.readElectionState());\n+\n+        context.time.sleep(RaftClientTestContext.ELECTION_TIMEOUT_MS);\n+        context.pollUntilSend();\n+        context.assertSentVoteRequest(epoch + 1, 0, 0L);\n     }\n \n     @Test\n     public void testInitializeAsCandidateFromStateStore() throws Exception {\n         // Need 3 node to require a 2-node majority\n-        Set<Integer> voters = Utils.mkSet(localId, 1, 2);\n-        quorumStateStore.writeElectionState(ElectionState.withVotedCandidate(2, localId, voters));\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, 1, 2);\n+\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withVotedCandidate(2, LOCAL_ID, voters));\n+                });\n+            })\n+            .build(voters);\n \n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(0L, log.endOffset().offset);\n+        assertEquals(0L, context.log.endOffset().offset);\n \n         // Send out vote requests.\n-        client.poll();\n+        context.client.poll();\n \n-        List<RaftRequest.Outbound> voteRequests = collectVoteRequests(2, 0, 0);\n+        List<RaftRequest.Outbound> voteRequests = context.collectVoteRequests(2, 0, 0);\n         assertEquals(2, voteRequests.size());\n     }\n \n     @Test\n     public void testInitializeAsCandidateAndBecomeLeader() throws Exception {\n         final int otherNodeId = 1;\n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        KafkaRaftClient client = buildClient(voters);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n+        RaftClientTestContext context = RaftClientTestContext.build(voters);\n \n-        assertEquals(ElectionState.withUnknownLeader(0, voters), quorumStateStore.readElectionState());\n-        time.sleep(2 * electionTimeoutMs);\n+        assertEquals(ElectionState.withUnknownLeader(0, voters), context.quorumStateStore.readElectionState());\n+        context.time.sleep(2 * RaftClientTestContext.ELECTION_TIMEOUT_MS);\n \n-        pollUntilSend(client);\n-        assertEquals(ElectionState.withVotedCandidate(1, localId, voters), quorumStateStore.readElectionState());\n+        context.pollUntilSend();\n+        assertEquals(ElectionState.withVotedCandidate(1, LOCAL_ID, voters), context.quorumStateStore.readElectionState());\n \n-        int correlationId = assertSentVoteRequest(1, 0, 0L);\n-        deliverResponse(correlationId, otherNodeId, voteResponse(true, Optional.empty(), 1));\n+        int correlationId = context.assertSentVoteRequest(1, 0, 0L);\n+        context.deliverResponse(correlationId, otherNodeId, RaftClientTestContext.voteResponse(true, Optional.empty(), 1));\n \n         // Become leader after receiving the vote\n-        client.poll();\n-        assertEquals(ElectionState.withElectedLeader(1, localId, voters), quorumStateStore.readElectionState());\n-        long electionTimestamp = time.milliseconds();\n+        context.client.poll();\n+        assertEquals(ElectionState.withElectedLeader(1, LOCAL_ID, voters), context.quorumStateStore.readElectionState());\n+        long electionTimestamp = context.time.milliseconds();\n \n         // Leader change record appended\n-        assertEquals(1L, log.endOffset().offset);\n-        assertEquals(1L, log.lastFlushedOffset());\n+        assertEquals(1L, context.log.endOffset().offset);\n+        assertEquals(1L, context.log.lastFlushedOffset());\n \n         // Send BeginQuorumEpoch to voters\n-        client.poll();\n-        assertSentBeginQuorumEpochRequest(1);\n+        context.client.poll();\n+        context.assertSentBeginQuorumEpochRequest(1);\n \n-        Records records = log.read(0, Isolation.UNCOMMITTED).records;\n+        Records records = context.log.read(0, Isolation.UNCOMMITTED).records;\n         RecordBatch batch = records.batches().iterator().next();\n         assertTrue(batch.isControlBatch());\n \n         Record record = batch.iterator().next();\n         assertEquals(electionTimestamp, record.timestamp());\n-        verifyLeaderChangeMessage(localId, Collections.singletonList(otherNodeId),\n-            record.key(), record.value());\n+        RaftClientTestContext.verifyLeaderChangeMessage(LOCAL_ID, Collections.singletonList(otherNodeId), record.key(), record.value());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f"}, "originalPosition": 294}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f200afd8fa571bbc43c7e567e5d53c44cf33506", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/8f200afd8fa571bbc43c7e567e5d53c44cf33506", "committedDate": "2020-10-22T03:23:52Z", "message": "Avoid the need to repeat the voter set"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1MDI4MTk2", "url": "https://github.com/apache/kafka/pull/9476#pullrequestreview-515028196", "createdAt": "2020-10-22T18:56:44Z", "commit": {"oid": "8f200afd8fa571bbc43c7e567e5d53c44cf33506"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxODo1Njo0NFrOHmvkbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxOToxMDowNFrOHmwC2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM4NzMxMA==", "bodyText": "I'm somewhat inclined to add the local id to the builder rather than making it constant. It makes the builder a bit more self-contained.\nOn a similar note, it would be nice to push the other static config values into the builder as well.", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510387310", "createdAt": "2020-10-22T18:56:44Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.raft;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.BeginQuorumEpochRequestData;\n+import org.apache.kafka.common.message.BeginQuorumEpochResponseData;\n+import org.apache.kafka.common.message.DescribeQuorumResponseData.ReplicaState;\n+import org.apache.kafka.common.message.DescribeQuorumResponseData;\n+import org.apache.kafka.common.message.EndQuorumEpochRequestData;\n+import org.apache.kafka.common.message.EndQuorumEpochResponseData;\n+import org.apache.kafka.common.message.FetchRequestData;\n+import org.apache.kafka.common.message.FetchResponseData;\n+import org.apache.kafka.common.message.LeaderChangeMessage.Voter;\n+import org.apache.kafka.common.message.LeaderChangeMessage;\n+import org.apache.kafka.common.message.VoteRequestData;\n+import org.apache.kafka.common.message.VoteResponseData;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.protocol.ApiKeys;\n+import org.apache.kafka.common.protocol.ApiMessage;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.record.CompressionType;\n+import org.apache.kafka.common.record.ControlRecordType;\n+import org.apache.kafka.common.record.ControlRecordUtils;\n+import org.apache.kafka.common.record.MemoryRecords;\n+import org.apache.kafka.common.record.Record;\n+import org.apache.kafka.common.record.Records;\n+import org.apache.kafka.common.record.SimpleRecord;\n+import org.apache.kafka.common.requests.BeginQuorumEpochResponse;\n+import org.apache.kafka.common.requests.DescribeQuorumResponse;\n+import org.apache.kafka.common.requests.VoteResponse;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.test.TestUtils;\n+import org.mockito.Mockito;\n+import static org.apache.kafka.raft.RaftUtil.hasValidTopicPartition;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+final class RaftClientTestContext {\n+    private static final int FETCH_MAX_WAIT_MS = 0;\n+\n+    static final TopicPartition METADATA_PARTITION = new TopicPartition(\"metadata\", 0);\n+    static final int LOCAL_ID = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f200afd8fa571bbc43c7e567e5d53c44cf33506"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM5MDgxOQ==", "bodyText": "nit: this indentation looks kind of funky", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510390819", "createdAt": "2020-10-22T19:02:45Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.raft;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.BeginQuorumEpochRequestData;\n+import org.apache.kafka.common.message.BeginQuorumEpochResponseData;\n+import org.apache.kafka.common.message.DescribeQuorumResponseData.ReplicaState;\n+import org.apache.kafka.common.message.DescribeQuorumResponseData;\n+import org.apache.kafka.common.message.EndQuorumEpochRequestData;\n+import org.apache.kafka.common.message.EndQuorumEpochResponseData;\n+import org.apache.kafka.common.message.FetchRequestData;\n+import org.apache.kafka.common.message.FetchResponseData;\n+import org.apache.kafka.common.message.LeaderChangeMessage.Voter;\n+import org.apache.kafka.common.message.LeaderChangeMessage;\n+import org.apache.kafka.common.message.VoteRequestData;\n+import org.apache.kafka.common.message.VoteResponseData;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.protocol.ApiKeys;\n+import org.apache.kafka.common.protocol.ApiMessage;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.record.CompressionType;\n+import org.apache.kafka.common.record.ControlRecordType;\n+import org.apache.kafka.common.record.ControlRecordUtils;\n+import org.apache.kafka.common.record.MemoryRecords;\n+import org.apache.kafka.common.record.Record;\n+import org.apache.kafka.common.record.Records;\n+import org.apache.kafka.common.record.SimpleRecord;\n+import org.apache.kafka.common.requests.BeginQuorumEpochResponse;\n+import org.apache.kafka.common.requests.DescribeQuorumResponse;\n+import org.apache.kafka.common.requests.VoteResponse;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.test.TestUtils;\n+import org.mockito.Mockito;\n+import static org.apache.kafka.raft.RaftUtil.hasValidTopicPartition;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+final class RaftClientTestContext {\n+    private static final int FETCH_MAX_WAIT_MS = 0;\n+\n+    static final TopicPartition METADATA_PARTITION = new TopicPartition(\"metadata\", 0);\n+    static final int LOCAL_ID = 0;\n+\n+    static final int ELECTION_BACKOFF_MAX_MS = 100;\n+    static final int ELECTION_TIMEOUT_MS = 10000;\n+    // fetch timeout is usually larger than election timeout\n+    static final int FETCH_TIMEOUT_MS = 50000;\n+    static final int REQUEST_TIMEOUT_MS = 5000;\n+    static final int RETRY_BACKOFF_MS = 50;\n+\n+    private final QuorumStateStore quorumStateStore;\n+    private final Random random;\n+\n+    final KafkaRaftClient client;\n+    final Metrics metrics;\n+    final MockLog log;\n+    final MockNetworkChannel channel;\n+    final MockTime time;\n+    final Set<Integer> voters;\n+\n+    public static final class Builder {\n+        private final QuorumStateStore quorumStateStore = new MockQuorumStateStore();\n+        private final Random random = Mockito.spy(new Random(1));\n+        private final MockLog log = new MockLog(METADATA_PARTITION);\n+        private final Set<Integer> voters;\n+\n+        Builder(Set<Integer> voters) {\n+            this.voters = voters;\n+        }\n+\n+        Builder withElectedLeader(int epoch, int leaderId) throws IOException {\n+            quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, leaderId, voters));\n+            return this;\n+        }\n+\n+        Builder withUnknownLeader(int epoch) throws IOException {\n+            quorumStateStore.writeElectionState(ElectionState.withUnknownLeader(epoch, voters));\n+            return this;\n+        }\n+\n+        Builder withVotedCandidate(int epoch, int votedId) throws IOException {\n+            quorumStateStore.writeElectionState(ElectionState.withVotedCandidate(epoch, votedId, voters));\n+            return this;\n+        }\n+\n+        Builder updateRandom(Consumer<Random> consumer) {\n+            consumer.accept(random);\n+            return this;\n+        }\n+\n+        Builder updateLog(Consumer<MockLog> consumer) {\n+            consumer.accept(log);\n+            return this;\n+        }\n+\n+        RaftClientTestContext build() throws IOException {\n+            MockTime time = new MockTime();\n+            Metrics metrics = new Metrics(time);\n+            MockNetworkChannel channel = new MockNetworkChannel();\n+            LogContext logContext = new LogContext();\n+            QuorumState quorum = new QuorumState(LOCAL_ID, voters, ELECTION_TIMEOUT_MS, FETCH_TIMEOUT_MS,\n+                    quorumStateStore, time, logContext, random);\n+\n+            Map<Integer, InetSocketAddress> voterAddresses = voters.stream().collect(Collectors.toMap(\n+                        Function.identity(),\n+                        RaftClientTestContext::mockAddress\n+                        ));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f200afd8fa571bbc43c7e567e5d53c44cf33506"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM5NTA5Ng==", "bodyText": "Yeah, that's fair. It looks like the code current just includes all followers. I guess we need to carry over the voters into the LeaderState if we want to implement the description above. Let's open a separate sub-task for https://issues.apache.org/jira/browse/KAFKA-9876 and decide what we want to do there.", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510395096", "createdAt": "2020-10-22T19:10:04Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -90,470 +76,480 @@\n import static org.junit.jupiter.api.Assertions.assertTrue;\n \n public class KafkaRaftClientTest {\n-    private static final TopicPartition METADATA_PARTITION = new TopicPartition(\"metadata\", 0);\n-\n-    private final int localId = 0;\n-    private final int electionTimeoutMs = 10000;\n-    private final int electionBackoffMaxMs = 100;\n-    private final int fetchTimeoutMs = 50000;   // fetch timeout is usually larger than election timeout\n-    private final int retryBackoffMs = 50;\n-    private final int requestTimeoutMs = 5000;\n-    private final int fetchMaxWaitMs = 0;\n-\n-    private final MockTime time = new MockTime();\n-    private final MockLog log = new MockLog(METADATA_PARTITION);\n-    private final MockNetworkChannel channel = new MockNetworkChannel();\n-    private final Random random = Mockito.spy(new Random(1));\n-    private final QuorumStateStore quorumStateStore = new MockQuorumStateStore();\n-\n-    @AfterEach\n-    public void cleanUp() throws IOException {\n-        quorumStateStore.clear();\n-    }\n-\n-    private InetSocketAddress mockAddress(int id) {\n-        return new InetSocketAddress(\"localhost\", 9990 + id);\n-    }\n-\n-    private KafkaRaftClient buildClient(Set<Integer> voters) throws IOException {\n-        return buildClient(voters, new Metrics(time));\n-    }\n-\n-    private KafkaRaftClient buildClient(Set<Integer> voters, Metrics metrics) throws IOException {\n-        LogContext logContext = new LogContext();\n-        QuorumState quorum = new QuorumState(localId, voters, electionTimeoutMs, fetchTimeoutMs,\n-            quorumStateStore, time, logContext, random);\n-\n-        Map<Integer, InetSocketAddress> voterAddresses = voters.stream().collect(Collectors.toMap(\n-            Function.identity(),\n-            this::mockAddress\n-        ));\n-\n-        KafkaRaftClient client = new KafkaRaftClient(channel, log, quorum, time, metrics,\n-            new MockFuturePurgatory<>(time), new MockFuturePurgatory<>(time), voterAddresses,\n-            electionBackoffMaxMs, retryBackoffMs, requestTimeoutMs, fetchMaxWaitMs, logContext, random);\n-\n-        client.initialize();\n-\n-        return client;\n-    }\n-\n     @Test\n     public void testInitializeSingleMemberQuorum() throws IOException {\n-        buildClient(Collections.singleton(localId));\n-        assertEquals(ElectionState.withElectedLeader(1, localId, Collections.singleton(localId)),\n-            quorumStateStore.readElectionState());\n+        RaftClientTestContext context = RaftClientTestContext.build(Collections.singleton(LOCAL_ID));\n+        assertEquals(\n+            ElectionState.withElectedLeader(1, LOCAL_ID, Collections.singleton(LOCAL_ID)),\n+            context.quorumStateStore.readElectionState()\n+        );\n     }\n \n     @Test\n     public void testInitializeAsLeaderFromStateStoreSingleMemberQuorum() throws Exception {\n         // Start off as leader. We should still bump the epoch after initialization\n \n         int initialEpoch = 2;\n-        Set<Integer> voters = Collections.singleton(localId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(initialEpoch, localId, voters));\n-\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(1L, log.endOffset().offset);\n-        assertEquals(initialEpoch + 1, log.lastFetchedEpoch());\n-        assertEquals(new LeaderAndEpoch(OptionalInt.of(localId), initialEpoch + 1),\n-            client.currentLeaderAndEpoch());\n-        assertEquals(ElectionState.withElectedLeader(initialEpoch + 1, localId, voters),\n-            quorumStateStore.readElectionState());\n+        Set<Integer> voters = Collections.singleton(LOCAL_ID);\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(\n+                        ElectionState.withElectedLeader(initialEpoch, LOCAL_ID, voters)\n+                    );\n+                });\n+            })\n+            .build(voters);\n+\n+        assertEquals(1L, context.log.endOffset().offset);\n+        assertEquals(initialEpoch + 1, context.log.lastFetchedEpoch());\n+        assertEquals(new LeaderAndEpoch(OptionalInt.of(LOCAL_ID), initialEpoch + 1),\n+            context.client.currentLeaderAndEpoch());\n+        assertEquals(ElectionState.withElectedLeader(initialEpoch + 1, LOCAL_ID, voters),\n+            context.quorumStateStore.readElectionState());\n     }\n \n     @Test\n     public void testInitializeAsLeaderFromStateStore() throws Exception {\n-        Set<Integer> voters = Utils.mkSet(localId, 1);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, 1);\n         int epoch = 2;\n \n-        Mockito.doReturn(0).when(random).nextInt(electionTimeoutMs);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, localId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(0L, log.endOffset().offset);\n-        assertEquals(ElectionState.withUnknownLeader(epoch, voters), quorumStateStore.readElectionState());\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateRandom(random -> {\n+                Mockito.doReturn(0).when(random).nextInt(RaftClientTestContext.ELECTION_TIMEOUT_MS);\n+            })\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, LOCAL_ID, voters));\n+                });\n+            })\n+            .build(voters);\n+\n \n-        time.sleep(electionTimeoutMs);\n-        pollUntilSend(client);\n-        assertSentVoteRequest(epoch + 1, 0, 0L);\n+        assertEquals(0L, context.log.endOffset().offset);\n+        assertEquals(ElectionState.withUnknownLeader(epoch, voters), context.quorumStateStore.readElectionState());\n+\n+        context.time.sleep(RaftClientTestContext.ELECTION_TIMEOUT_MS);\n+        context.pollUntilSend();\n+        context.assertSentVoteRequest(epoch + 1, 0, 0L);\n     }\n \n     @Test\n     public void testInitializeAsCandidateFromStateStore() throws Exception {\n         // Need 3 node to require a 2-node majority\n-        Set<Integer> voters = Utils.mkSet(localId, 1, 2);\n-        quorumStateStore.writeElectionState(ElectionState.withVotedCandidate(2, localId, voters));\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, 1, 2);\n+\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withVotedCandidate(2, LOCAL_ID, voters));\n+                });\n+            })\n+            .build(voters);\n \n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(0L, log.endOffset().offset);\n+        assertEquals(0L, context.log.endOffset().offset);\n \n         // Send out vote requests.\n-        client.poll();\n+        context.client.poll();\n \n-        List<RaftRequest.Outbound> voteRequests = collectVoteRequests(2, 0, 0);\n+        List<RaftRequest.Outbound> voteRequests = context.collectVoteRequests(2, 0, 0);\n         assertEquals(2, voteRequests.size());\n     }\n \n     @Test\n     public void testInitializeAsCandidateAndBecomeLeader() throws Exception {\n         final int otherNodeId = 1;\n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        KafkaRaftClient client = buildClient(voters);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n+        RaftClientTestContext context = RaftClientTestContext.build(voters);\n \n-        assertEquals(ElectionState.withUnknownLeader(0, voters), quorumStateStore.readElectionState());\n-        time.sleep(2 * electionTimeoutMs);\n+        assertEquals(ElectionState.withUnknownLeader(0, voters), context.quorumStateStore.readElectionState());\n+        context.time.sleep(2 * RaftClientTestContext.ELECTION_TIMEOUT_MS);\n \n-        pollUntilSend(client);\n-        assertEquals(ElectionState.withVotedCandidate(1, localId, voters), quorumStateStore.readElectionState());\n+        context.pollUntilSend();\n+        assertEquals(ElectionState.withVotedCandidate(1, LOCAL_ID, voters), context.quorumStateStore.readElectionState());\n \n-        int correlationId = assertSentVoteRequest(1, 0, 0L);\n-        deliverResponse(correlationId, otherNodeId, voteResponse(true, Optional.empty(), 1));\n+        int correlationId = context.assertSentVoteRequest(1, 0, 0L);\n+        context.deliverResponse(correlationId, otherNodeId, RaftClientTestContext.voteResponse(true, Optional.empty(), 1));\n \n         // Become leader after receiving the vote\n-        client.poll();\n-        assertEquals(ElectionState.withElectedLeader(1, localId, voters), quorumStateStore.readElectionState());\n-        long electionTimestamp = time.milliseconds();\n+        context.client.poll();\n+        assertEquals(ElectionState.withElectedLeader(1, LOCAL_ID, voters), context.quorumStateStore.readElectionState());\n+        long electionTimestamp = context.time.milliseconds();\n \n         // Leader change record appended\n-        assertEquals(1L, log.endOffset().offset);\n-        assertEquals(1L, log.lastFlushedOffset());\n+        assertEquals(1L, context.log.endOffset().offset);\n+        assertEquals(1L, context.log.lastFlushedOffset());\n \n         // Send BeginQuorumEpoch to voters\n-        client.poll();\n-        assertSentBeginQuorumEpochRequest(1);\n+        context.client.poll();\n+        context.assertSentBeginQuorumEpochRequest(1);\n \n-        Records records = log.read(0, Isolation.UNCOMMITTED).records;\n+        Records records = context.log.read(0, Isolation.UNCOMMITTED).records;\n         RecordBatch batch = records.batches().iterator().next();\n         assertTrue(batch.isControlBatch());\n \n         Record record = batch.iterator().next();\n         assertEquals(electionTimestamp, record.timestamp());\n-        verifyLeaderChangeMessage(localId, Collections.singletonList(otherNodeId),\n-            record.key(), record.value());\n+        RaftClientTestContext.verifyLeaderChangeMessage(LOCAL_ID, Collections.singletonList(otherNodeId), record.key(), record.value());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MDI2NQ=="}, "originalCommit": {"oid": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f"}, "originalPosition": 294}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6db5a627ed3fa91f8de65586bb973c389e98948a", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/6db5a627ed3fa91f8de65586bb973c389e98948a", "committedDate": "2020-10-22T20:50:01Z", "message": "Don't assume that each context has the same configuration"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1MTU3OTM3", "url": "https://github.com/apache/kafka/pull/9476#pullrequestreview-515157937", "createdAt": "2020-10-22T22:15:41Z", "commit": {"oid": "6db5a627ed3fa91f8de65586bb973c389e98948a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMjoxNTo0MlrOHm1xRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMjoxNTo0MlrOHm1xRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ4ODkwMg==", "bodyText": "The pattern I had in mind was a little different. I was thinking something like this:\n        int localId = 0;\n        int otherNodeId = 1;\n        int epoch = 2;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n          .withVotedCandidate(epoch, otherNodeId)\n          .build()\nThen we don't have the awkwardness of the partial reliance on the static LOCAL_ID. I like this better because the ids have to be explicitly declared in each test case, which makes it easier to follow.", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510488902", "createdAt": "2020-10-22T22:15:42Z", "author": {"login": "hachikuji"}, "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -278,13 +265,13 @@ public void testEndQuorumStartsNewElectionAfterBackoffIfReceivedFromVotedCandida\n             .withVotedCandidate(epoch, otherNodeId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6db5a627ed3fa91f8de65586bb973c389e98948a"}, "originalPosition": 184}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "47c94de723519691fa9749cc21d9ef1dc65fe85f", "author": {"user": {"login": "jsancio", "name": "Jos\u00e9 Armando Garc\u00eda Sancio"}}, "url": "https://github.com/apache/kafka/commit/47c94de723519691fa9749cc21d9ef1dc65fe85f", "committedDate": "2020-10-22T22:41:20Z", "message": "Remove LOCAL_ID and make it configurable in the Builder"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1MTc1Njk3", "url": "https://github.com/apache/kafka/pull/9476#pullrequestreview-515175697", "createdAt": "2020-10-22T22:58:37Z", "commit": {"oid": "47c94de723519691fa9749cc21d9ef1dc65fe85f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2839, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}