{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAyOTAwNjkx", "number": 8476, "title": "KAFKA-9838; Add log concurrency test and fix minor race condition", "bodyText": "The patch adds a new test case for validating concurrent read/write behavior in the Log implementation. In the process of verifying this, we found a race condition in read. The previous logic checks whether the start offset is equal to the end offset before collecting the high watermark. It is possible that the log is truncated in between these two conditions which could cause the high watermark to be equal to the log end offset. When this happens, LogSegment.read fails because it is unable to find the starting position to read from.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-04-14T00:09:56Z", "url": "https://github.com/apache/kafka/pull/8476", "merged": true, "mergeCommit": {"oid": "413c4b55b56838cf5ec8d0e0fa758a955f84404e"}, "closed": true, "closedAt": "2020-04-16T00:18:31Z", "author": {"login": "hachikuji"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcXYDrogH2gAyNDAyOTAwNjkxOmRhMjQwMDQ5MThhMmVlZmFiY2ZkNWM5YjNmNGE5ZjRiMTVhZjRmM2M=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcX-EY_gFqTM5NDEwODY0MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "da24004918a2eefabcfd5c9b3f4a9f4b15af4f3c", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/da24004918a2eefabcfd5c9b3f4a9f4b15af4f3c", "committedDate": "2020-04-14T00:08:05Z", "message": "KAFKA-9838; Add log concurrency test and fix minor race condition"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d0290c405efe3bdfe6357c350f82e189dbdbc822", "author": {"user": {"login": "hachikuji", "name": "Jason Gustafson"}}, "url": "https://github.com/apache/kafka/commit/d0290c405efe3bdfe6357c350f82e189dbdbc822", "committedDate": "2020-04-14T00:55:55Z", "message": "Fix a couple style issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0MDQ3NDQz", "url": "https://github.com/apache/kafka/pull/8476#pullrequestreview-394047443", "createdAt": "2020-04-15T18:54:22Z", "commit": {"oid": "d0290c405efe3bdfe6357c350f82e189dbdbc822"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxODo1NDoyMlrOGGHN3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxOTowMjowOVrOGGHgjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA2Mjg3Nw==", "bodyText": "Why in this case we use maxOffsetMetadata and in the else if we use startOffsetMetadata as emptyFetchDataInfo#fetchOffsetMetadata? Is there a specific rationale for that?", "url": "https://github.com/apache/kafka/pull/8476#discussion_r409062877", "createdAt": "2020-04-15T18:54:22Z", "author": {"login": "guozhangwang"}, "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1483,12 +1480,14 @@ class Log(@volatile private var _dir: File,\n           s\"but we only have log segments in the range $logStartOffset to $endOffset.\")\n \n       val maxOffsetMetadata = isolation match {\n-        case FetchLogEnd => nextOffsetMetadata\n+        case FetchLogEnd => endOffsetMetadata\n         case FetchHighWatermark => fetchHighWatermarkMetadata\n         case FetchTxnCommitted => fetchLastStableOffsetMetadata\n       }\n \n-      if (startOffset > maxOffsetMetadata.messageOffset) {\n+      if (startOffset == maxOffsetMetadata.messageOffset) {\n+        return emptyFetchDataInfo(maxOffsetMetadata, includeAbortedTxns)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0290c405efe3bdfe6357c350f82e189dbdbc822"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA2NjY2Nw==", "bodyText": "Could we check last / next offset of the batch as well?", "url": "https://github.com/apache/kafka/pull/8476#discussion_r409066667", "createdAt": "2020-04-15T19:00:22Z", "author": {"login": "guozhangwang"}, "path": "core/src/test/scala/unit/kafka/log/LogConcurrencyTest.scala", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.log\n+\n+import java.util.Properties\n+import java.util.concurrent.{Callable, Executors}\n+\n+import kafka.server.{BrokerTopicStats, FetchHighWatermark, LogDirFailureChannel}\n+import kafka.utils.{KafkaScheduler, TestUtils}\n+import org.apache.kafka.common.record.SimpleRecord\n+import org.apache.kafka.common.utils.{Time, Utils}\n+import org.junit.Assert._\n+import org.junit.{After, Before, Test}\n+\n+import scala.collection.mutable.ListBuffer\n+import scala.util.Random\n+\n+class LogConcurrencyTest {\n+  private val brokerTopicStats = new BrokerTopicStats\n+  private val random = new Random()\n+  private val scheduler = new KafkaScheduler(1)\n+  private val tmpDir = TestUtils.tempDir()\n+  private val logDir = TestUtils.randomPartitionLogDir(tmpDir)\n+\n+  @Before\n+  def setup(): Unit = {\n+    scheduler.startup()\n+  }\n+\n+  @After\n+  def shutdown(): Unit = {\n+    scheduler.shutdown()\n+    Utils.delete(tmpDir)\n+  }\n+\n+  @Test\n+  def testUncommittedDataNotConsumed(): Unit = {\n+    testUncommittedDataNotConsumed(createLog())\n+  }\n+\n+  @Test\n+  def testUncommittedDataNotConsumedFrequentSegmentRolls(): Unit = {\n+    val logProps = new Properties()\n+    logProps.put(LogConfig.SegmentBytesProp, 237: Integer)\n+    val logConfig = LogConfig(logProps)\n+    testUncommittedDataNotConsumed(createLog(logConfig))\n+  }\n+\n+  def testUncommittedDataNotConsumed(log: Log): Unit = {\n+    val executor = Executors.newFixedThreadPool(2)\n+    try {\n+      val maxOffset = 5000\n+      val consumer = new ConsumerTask(log, maxOffset)\n+      val appendTask = new LogAppendTask(log, maxOffset)\n+\n+      val consumerFuture = executor.submit(consumer)\n+      val fetcherTaskFuture = executor.submit(appendTask)\n+\n+      fetcherTaskFuture.get()\n+      consumerFuture.get()\n+\n+      validateConsumedData(log, consumer.consumedBatches)\n+    } finally executor.shutdownNow()\n+  }\n+\n+  /**\n+   * Simple consumption task which reads the log in ascending order and collects\n+   * consumed batches for validation\n+   */\n+  private class ConsumerTask(log: Log, lastOffset: Int) extends Callable[Unit] {\n+    val consumedBatches = ListBuffer.empty[FetchedBatch]\n+\n+    override def call(): Unit = {\n+      var fetchOffset = 0L\n+      while (log.highWatermark < lastOffset) {\n+        val readInfo = log.read(\n+          startOffset = fetchOffset,\n+          maxLength = 1,\n+          isolation = FetchHighWatermark,\n+          minOneMessage = true\n+        )\n+        readInfo.records.batches().forEach { batch =>\n+          consumedBatches += FetchedBatch(batch.baseOffset, batch.partitionLeaderEpoch)\n+          fetchOffset = batch.lastOffset + 1\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This class simulates basic leader/follower behavior.\n+   */\n+  private class LogAppendTask(log: Log, lastOffset: Long) extends Callable[Unit] {\n+    override def call(): Unit = {\n+      var leaderEpoch = 1\n+      var isLeader = true\n+\n+      while (log.highWatermark < lastOffset) {\n+        random.nextInt(2) match {\n+          case 0 =>\n+            val logEndOffsetMetadata = log.logEndOffsetMetadata\n+            val logEndOffset = logEndOffsetMetadata.messageOffset\n+            val batchSize = random.nextInt(9) + 1\n+            val records = (0 to batchSize).map(i => new SimpleRecord(s\"$i\".getBytes))\n+\n+            if (isLeader) {\n+              log.appendAsLeader(TestUtils.records(records), leaderEpoch)\n+              log.maybeIncrementHighWatermark(logEndOffsetMetadata)\n+            } else {\n+              log.appendAsFollower(TestUtils.records(records,\n+                baseOffset = logEndOffset,\n+                partitionLeaderEpoch = leaderEpoch))\n+              log.updateHighWatermark(logEndOffset)\n+            }\n+\n+          case 1 =>\n+            isLeader = !isLeader\n+            leaderEpoch += 1\n+\n+            if (!isLeader) {\n+              log.truncateTo(log.highWatermark)\n+            }\n+        }\n+      }\n+    }\n+  }\n+\n+  private def createLog(config: LogConfig = LogConfig(new Properties())): Log = {\n+    Log(dir = logDir,\n+      config = config,\n+      logStartOffset = 0L,\n+      recoveryPoint = 0L,\n+      scheduler = scheduler,\n+      brokerTopicStats = brokerTopicStats,\n+      time = Time.SYSTEM,\n+      maxProducerIdExpirationMs = 60 * 60 * 1000,\n+      producerIdExpirationCheckIntervalMs = LogManager.ProducerIdExpirationCheckIntervalMs,\n+      logDirFailureChannel = new LogDirFailureChannel(10))\n+  }\n+\n+  private def validateConsumedData(log: Log, consumedBatches: Iterable[FetchedBatch]): Unit = {\n+    val iter = consumedBatches.iterator\n+    log.logSegments.foreach { segment =>\n+      segment.log.batches.forEach { batch =>\n+        if (iter.hasNext) {\n+          val consumedBatch = iter.next()\n+          try {\n+            assertEquals(\"Consumed batch with unexpected leader epoch\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0290c405efe3bdfe6357c350f82e189dbdbc822"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA2NzY2Mg==", "bodyText": "I'm just curious how long would a single run take with 5000 records and a max batchsize of 10? Being a bit paranoid of it taking too long.", "url": "https://github.com/apache/kafka/pull/8476#discussion_r409067662", "createdAt": "2020-04-15T19:02:09Z", "author": {"login": "guozhangwang"}, "path": "core/src/test/scala/unit/kafka/log/LogConcurrencyTest.scala", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.log\n+\n+import java.util.Properties\n+import java.util.concurrent.{Callable, Executors}\n+\n+import kafka.server.{BrokerTopicStats, FetchHighWatermark, LogDirFailureChannel}\n+import kafka.utils.{KafkaScheduler, TestUtils}\n+import org.apache.kafka.common.record.SimpleRecord\n+import org.apache.kafka.common.utils.{Time, Utils}\n+import org.junit.Assert._\n+import org.junit.{After, Before, Test}\n+\n+import scala.collection.mutable.ListBuffer\n+import scala.util.Random\n+\n+class LogConcurrencyTest {\n+  private val brokerTopicStats = new BrokerTopicStats\n+  private val random = new Random()\n+  private val scheduler = new KafkaScheduler(1)\n+  private val tmpDir = TestUtils.tempDir()\n+  private val logDir = TestUtils.randomPartitionLogDir(tmpDir)\n+\n+  @Before\n+  def setup(): Unit = {\n+    scheduler.startup()\n+  }\n+\n+  @After\n+  def shutdown(): Unit = {\n+    scheduler.shutdown()\n+    Utils.delete(tmpDir)\n+  }\n+\n+  @Test\n+  def testUncommittedDataNotConsumed(): Unit = {\n+    testUncommittedDataNotConsumed(createLog())\n+  }\n+\n+  @Test\n+  def testUncommittedDataNotConsumedFrequentSegmentRolls(): Unit = {\n+    val logProps = new Properties()\n+    logProps.put(LogConfig.SegmentBytesProp, 237: Integer)\n+    val logConfig = LogConfig(logProps)\n+    testUncommittedDataNotConsumed(createLog(logConfig))\n+  }\n+\n+  def testUncommittedDataNotConsumed(log: Log): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0290c405efe3bdfe6357c350f82e189dbdbc822"}, "originalPosition": 64}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0MTA4NjQx", "url": "https://github.com/apache/kafka/pull/8476#pullrequestreview-394108641", "createdAt": "2020-04-15T20:25:15Z", "commit": {"oid": "d0290c405efe3bdfe6357c350f82e189dbdbc822"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1487, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}