{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4Mzg1NzI0", "number": 9098, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNjozOTo1OFrOETwkUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTowMzoyM1rOEXqwoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MTU0MTI4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNjozOTo1OFrOG5rHTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxMzo0MTo1MFrOG6I_aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEyODM5OA==", "bodyText": "Ah, after reading your test, I now see the issue. I'd overlooked the fact that users would independently construct the table config object AND the cache. I see now that this makes it impossible to reliably capture the cache, since users have to actually choose to pass our special table config to the Options and then pass the Cache to that table config.\nThis doesn't seem ideal. What do you think about just using reflection instead?\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache) {\n          \n          \n            \n                        final Cache cache = ((BlockBasedTableConfigWithAccessibleCache) tableFormatConfig).blockCache();\n          \n          \n            \n                        metricsRecorder.addValueProviders(name, db, cache, statistics);\n          \n          \n            \n                    } else {\n          \n          \n            \n                        metricsRecorder.addValueProviders(name, db, null, statistics);\n          \n          \n            \n                        log.warn(\"A table format configuration is used that does not expose the block cache. This means \" +\n          \n          \n            \n                            \"that metrics that relate to the block cache may be wrong if the block cache is shared.\");\n          \n          \n            \n                    }\n          \n          \n            \n                    if (tableFormatConfig instanceof BlockBasedTableConfig) {\n          \n          \n            \n                        final BlockBasedTableConfig blockBasedTableConfig = (BlockBasedTableConfig) tableFormatConfig;\n          \n          \n            \n                        try {\n          \n          \n            \n                            final Field blockCacheField = BlockBasedTableConfig.class.getDeclaredField(\"blockCache_\");\n          \n          \n            \n                            blockCacheField.setAccessible(true);\n          \n          \n            \n                            final Cache nullableBlockCache = (Cache) blockCacheField.get(blockBasedTableConfig);\n          \n          \n            \n                            metricsRecorder.addValueProviders(name, db, nullableBlockCache, statistics);\n          \n          \n            \n                        } catch (final NoSuchFieldException | IllegalAccessException | ClassCastException e) {\n          \n          \n            \n                            log.warn(\"Expected to find and access field 'blockCache_' in BlockBasedTableConfig. \" +\n          \n          \n            \n                                         \"Probably, an incompatible version of RocksDB is being used. \" +\n          \n          \n            \n                                         \"Cache will be missing from memory metrics.\", e);\n          \n          \n            \n                            metricsRecorder.addValueProviders(name, db, null, statistics);\n          \n          \n            \n                        }\n          \n          \n            \n                    } else {\n          \n          \n            \n                        metricsRecorder.addValueProviders(name, db, null, statistics);\n          \n          \n            \n                    }\n          \n      \n    \n    \n  \n\nWe would obviously test all the branches here to de-risk the reflection. We can also add a test that searches the classpath for implementations of TableFormatConfig to ensure we don't miss the memo if RocksDB adds a new TableFormatConfig implementation.\nAlternative thought, if you don't like the reflection: We would also subclass Options and override org.rocksdb.Options#setTableFormatConfig to check if the passed TableFormatConfig is a BlockBasedTableConfig, and if so, then we wrap it with BlockBasedTableConfigWithAccessibleCache.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r463128398", "createdAt": "2020-07-30T16:39:58Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,23 +181,39 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder(configs);\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {\n+            userSpecifiedStatistics = true;\n+        }\n+        if (!userSpecifiedStatistics &&\n             RecordingLevel.forName((String) configs.get(METRICS_RECORDING_LEVEL_CONFIG)) == RecordingLevel.DEBUG) {\n \n-            isStatisticsRegistered = true;\n             // metrics recorder will clean up statistics object\n             final Statistics statistics = new Statistics();\n             userSpecifiedOptions.setStatistics(statistics);\n-            metricsRecorder.addStatistics(name, statistics);\n+        }\n+    }\n+\n+    private void addValueProvidersToMetricsRecorder(final Map<String, Object> configs) {\n+        final TableFormatConfig tableFormatConfig = userSpecifiedOptions.tableFormatConfig();\n+        final Statistics statistics = userSpecifiedStatistics ? null : userSpecifiedOptions.statistics();\n+        if (tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache) {\n+            final Cache cache = ((BlockBasedTableConfigWithAccessibleCache) tableFormatConfig).blockCache();\n+            metricsRecorder.addValueProviders(name, db, cache, statistics);\n+        } else {\n+            metricsRecorder.addValueProviders(name, db, null, statistics);\n+            log.warn(\"A table format configuration is used that does not expose the block cache. This means \" +\n+                \"that metrics that relate to the block cache may be wrong if the block cache is shared.\");\n         }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0afb35d8bba0d76adf9002bd9db14025cd0ca340"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzYxNzg5OQ==", "bodyText": "I agree with you that it is not ideal and thank you for this lesson on reflection.\nIndeed, I do not like reflection in this case, because it makes the code too much dependent on RocksDB internals. We should use reflection to check if the public API to configure RocksDB changed in a newer version, but that is another story.\nI do not understand how the alternative of wrapping BlockBasedTableConfig into BlockBasedTableConfigWithAccessibleCache should work. Since the cache is not accessible in BlockBasedTableConfig it will also not be accessible when it is wrapped in BlockBasedTableConfigWithAccessibleCache (despite the name). We need to get the reference to the cache when the cache is set in BlockBasedTableConfig. If the cache is already set we can only use reflection.\nSince the block based table format is the only format in RocksDB that uses the cache, I do not see why a user absolutely needs to pass a new BlockBasedTableConfig object. I think for now it is OK to log a warning, and clearly document that the provided BlockBasedTableConfig object should be used.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r463617899", "createdAt": "2020-07-31T13:41:50Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,23 +181,39 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder(configs);\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {\n+            userSpecifiedStatistics = true;\n+        }\n+        if (!userSpecifiedStatistics &&\n             RecordingLevel.forName((String) configs.get(METRICS_RECORDING_LEVEL_CONFIG)) == RecordingLevel.DEBUG) {\n \n-            isStatisticsRegistered = true;\n             // metrics recorder will clean up statistics object\n             final Statistics statistics = new Statistics();\n             userSpecifiedOptions.setStatistics(statistics);\n-            metricsRecorder.addStatistics(name, statistics);\n+        }\n+    }\n+\n+    private void addValueProvidersToMetricsRecorder(final Map<String, Object> configs) {\n+        final TableFormatConfig tableFormatConfig = userSpecifiedOptions.tableFormatConfig();\n+        final Statistics statistics = userSpecifiedStatistics ? null : userSpecifiedOptions.statistics();\n+        if (tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache) {\n+            final Cache cache = ((BlockBasedTableConfigWithAccessibleCache) tableFormatConfig).blockCache();\n+            metricsRecorder.addValueProviders(name, db, cache, statistics);\n+        } else {\n+            metricsRecorder.addValueProviders(name, db, null, statistics);\n+            log.warn(\"A table format configuration is used that does not expose the block cache. This means \" +\n+                \"that metrics that relate to the block cache may be wrong if the block cache is shared.\");\n         }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEyODM5OA=="}, "originalCommit": {"oid": "0afb35d8bba0d76adf9002bd9db14025cd0ca340"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MTU2NzAxOnYy", "diffSide": "RIGHT", "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/processor/MockProcessorContext.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNjo0Njo0M1rOG5rXlg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxMjoyMzoyN1rOG6GmwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEzMjU2Ng==", "bodyText": "Interesting... Should we add a Time argument to the constructor? It would be a minor amendment to the KIP.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r463132566", "createdAt": "2020-07-30T16:46:43Z", "author": {"login": "vvcephei"}, "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/processor/MockProcessorContext.java", "diffHunk": "@@ -227,7 +228,8 @@ public MockProcessorContext(final Properties config, final TaskId taskId, final\n         this.metrics = new StreamsMetricsImpl(\n             new Metrics(metricConfig),\n             threadId,\n-            streamsConfig.getString(StreamsConfig.BUILT_IN_METRICS_VERSION_CONFIG)\n+            streamsConfig.getString(StreamsConfig.BUILT_IN_METRICS_VERSION_CONFIG),\n+            Time.SYSTEM", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0afb35d8bba0d76adf9002bd9db14025cd0ca340"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU3ODgxNg==", "bodyText": "I would prefer to postpone that, because currently it is not strictly needed and the time is only used in the RocksDB recording trigger that records only internal RocksDB metrics. I do not see how exposing time would be useful for users during testing. If anybody complains, we can still do it in a future KIP.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r463578816", "createdAt": "2020-07-31T12:23:27Z", "author": {"login": "cadonna"}, "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/processor/MockProcessorContext.java", "diffHunk": "@@ -227,7 +228,8 @@ public MockProcessorContext(final Properties config, final TaskId taskId, final\n         this.metrics = new StreamsMetricsImpl(\n             new Metrics(metricConfig),\n             threadId,\n-            streamsConfig.getString(StreamsConfig.BUILT_IN_METRICS_VERSION_CONFIG)\n+            streamsConfig.getString(StreamsConfig.BUILT_IN_METRICS_VERSION_CONFIG),\n+            Time.SYSTEM", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEzMjU2Ng=="}, "originalCommit": {"oid": "0afb35d8bba0d76adf9002bd9db14025cd0ca340"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODU4MzI3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjozNDo1M1rOG_AB9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxOTowNTozNlrOG_FdGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcxMzk3NQ==", "bodyText": "It seems like we would now be forbidding the use of PlainTableConfig. Is that intentional?", "url": "https://github.com/apache/kafka/pull/9098#discussion_r468713975", "createdAt": "2020-08-11T16:34:53Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -204,17 +204,17 @@ private void maybeSetUpStatistics(final Map<String, Object> configs) {\n         }\n     }\n \n-    private void addValueProvidersToMetricsRecorder(final Map<String, Object> configs) {\n+    private void addValueProvidersToMetricsRecorder() {\n         final TableFormatConfig tableFormatConfig = userSpecifiedOptions.tableFormatConfig();\n         final Statistics statistics = userSpecifiedStatistics ? null : userSpecifiedOptions.statistics();\n-        if (tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache) {\n-            final Cache cache = ((BlockBasedTableConfigWithAccessibleCache) tableFormatConfig).blockCache();\n-            metricsRecorder.addValueProviders(name, db, cache, statistics);\n-        } else {\n-            metricsRecorder.addValueProviders(name, db, null, statistics);\n-            log.warn(\"A table format configuration is used that does not expose the block cache. This means \" +\n-                \"that metrics that relate to the block cache may be wrong if the block cache is shared.\");\n-        }\n+        if (!(tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgwMjg0MQ==", "bodyText": "No, it was not intentional. I simply did not think hard enough.\nI agree with you that we should also allow PlainTableConfig. If users use the PlainTable format they should already expect that block cache specific metrics do not show up or report constant zero.\nThank you for pointing this out!", "url": "https://github.com/apache/kafka/pull/9098#discussion_r468802841", "createdAt": "2020-08-11T19:05:36Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -204,17 +204,17 @@ private void maybeSetUpStatistics(final Map<String, Object> configs) {\n         }\n     }\n \n-    private void addValueProvidersToMetricsRecorder(final Map<String, Object> configs) {\n+    private void addValueProvidersToMetricsRecorder() {\n         final TableFormatConfig tableFormatConfig = userSpecifiedOptions.tableFormatConfig();\n         final Statistics statistics = userSpecifiedStatistics ? null : userSpecifiedOptions.statistics();\n-        if (tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache) {\n-            final Cache cache = ((BlockBasedTableConfigWithAccessibleCache) tableFormatConfig).blockCache();\n-            metricsRecorder.addValueProviders(name, db, cache, statistics);\n-        } else {\n-            metricsRecorder.addValueProviders(name, db, null, statistics);\n-            log.warn(\"A table format configuration is used that does not expose the block cache. This means \" +\n-                \"that metrics that relate to the block cache may be wrong if the block cache is shared.\");\n-        }\n+        if (!(tableFormatConfig instanceof BlockBasedTableConfigWithAccessibleCache)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcxMzk3NQ=="}, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODk2MTY4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxODoxODo1NlrOG_DwWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNzoyNTo1OVrOG_rQHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NTAwMg==", "bodyText": "Could this ever be null actually? I think even in unit tests the DBOptions would contain stats?", "url": "https://github.com/apache/kafka/pull/9098#discussion_r468775002", "createdAt": "2020-08-11T18:18:56Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,26 +181,42 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder();\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc5NjMzMw==", "bodyText": "The statistics are null when it is not set in the options. If it were not null unit test RocksDBTest#shouldAddValueProvidersWithStatisticsToInjectedMetricsRecorderWhenRecordingLevelDebug() would fail. I also verified with a debug run.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r468796333", "createdAt": "2020-08-11T18:53:39Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,26 +181,42 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder();\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NTAwMg=="}, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg5MTEyMg==", "bodyText": "I was thinking that, if we know maybeSetUpStatistics is only called once in lifetime of the store then here we could check that userSpecifiedOptions.statistics() == null and otherwise throw illegal-state exception. And then in addValueProvidersToMetricsRecorder we check that ``userSpecifiedOptions.statistics() != null` and otherwise throw illegal-state exception. This is to make the call-trace assumptions more specific.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r468891122", "createdAt": "2020-08-11T22:05:34Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,26 +181,42 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder();\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NTAwMg=="}, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTA5NTc1Nw==", "bodyText": "I see what you are aiming at. However, why should we throw an IllegalStateException when userSpecifiedOptions.statistics() != null? The user could provide a statistics object through the config setter and use it to read the statistics externally to our metric framework. Such a pattern was supported before and was not changed in this PR or the PR that introduced the statistics-based RocksDB metrics.\nAnyways, it is good that you mentioned this, because I checked again the code in the metrics recorder and a null check was missing. Plus I included some checks to ensure that either all statistics of a metrics recorder arenull or all statistics of a metrics recorder are NOT null.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r469095757", "createdAt": "2020-08-12T08:32:29Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,26 +181,42 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder();\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NTAwMg=="}, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM4ODY1NA==", "bodyText": "Hmm, that means if a user calls setStatistics externally then streams itself would not provide the built-in metrics, is that right? I was not aware of this, and if it is by-design then that's fine.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r469388654", "createdAt": "2020-08-12T16:29:58Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,26 +181,42 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder();\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NTAwMg=="}, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQyMjExMA==", "bodyText": "Actually, Streams would provide the built-in metrics, but not update them. I also thought about not providing them at all, but that is a bit tricky and I did not want spent too much time on such a rare case. I will open a Jira and defer this to later.", "url": "https://github.com/apache/kafka/pull/9098#discussion_r469422110", "createdAt": "2020-08-12T17:25:59Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -181,26 +181,42 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n-        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // Setup statistics before the database is opened, otherwise the statistics are not updated\n         // with the measurements from Rocks DB\n-        maybeSetUpMetricsRecorder(configs);\n+        maybeSetUpStatistics(configs);\n \n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n+\n+        addValueProvidersToMetricsRecorder();\n     }\n \n-    private void maybeSetUpMetricsRecorder(final Map<String, Object> configs) {\n-        if (userSpecifiedOptions.statistics() == null &&\n+    private void maybeSetUpStatistics(final Map<String, Object> configs) {\n+        if (userSpecifiedOptions.statistics() != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NTAwMg=="}, "originalCommit": {"oid": "91b3430b9db78b0cff834d6197f509f65a639dcd"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMjUzMjgwOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTowMzoyM1rOG_lejA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTowMzoyM1rOG_lejA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMyNzUwMA==", "bodyText": "I think it's implied in addValueProviders that if any of the valueProviders' statistics are non-null, then they are all non-null, in which case, this makes sense as a guard. Still, it's kind of subtle.\nWhy not just put a guard inside the loop instead to continue or break if it turns out that valueProviders.statistics == null?", "url": "https://github.com/apache/kafka/pull/9098#discussion_r469327500", "createdAt": "2020-08-12T15:03:23Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorder.java", "diffHunk": "@@ -187,37 +206,39 @@ public void record(final long now) {\n         long bytesReadDuringCompaction = 0;\n         long numberOfOpenFiles = 0;\n         long numberOfFileErrors = 0;\n-        for (final DbAndCacheAndStatistics valueProviders : storeToValueProviders.values()) {\n-            bytesWrittenToDatabase += valueProviders.statistics.getAndResetTickerCount(TickerType.BYTES_WRITTEN);\n-            bytesReadFromDatabase += valueProviders.statistics.getAndResetTickerCount(TickerType.BYTES_READ);\n-            memtableBytesFlushed += valueProviders.statistics.getAndResetTickerCount(TickerType.FLUSH_WRITE_BYTES);\n-            memtableHits += valueProviders.statistics.getAndResetTickerCount(TickerType.MEMTABLE_HIT);\n-            memtableMisses += valueProviders.statistics.getAndResetTickerCount(TickerType.MEMTABLE_MISS);\n-            blockCacheDataHits += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_DATA_HIT);\n-            blockCacheDataMisses += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_DATA_MISS);\n-            blockCacheIndexHits += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_INDEX_HIT);\n-            blockCacheIndexMisses += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_INDEX_MISS);\n-            blockCacheFilterHits += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_FILTER_HIT);\n-            blockCacheFilterMisses += valueProviders.statistics.getAndResetTickerCount(TickerType.BLOCK_CACHE_FILTER_MISS);\n-            writeStallDuration += valueProviders.statistics.getAndResetTickerCount(TickerType.STALL_MICROS);\n-            bytesWrittenDuringCompaction += valueProviders.statistics.getAndResetTickerCount(TickerType.COMPACT_WRITE_BYTES);\n-            bytesReadDuringCompaction += valueProviders.statistics.getAndResetTickerCount(TickerType.COMPACT_READ_BYTES);\n-            numberOfOpenFiles += valueProviders.statistics.getAndResetTickerCount(TickerType.NO_FILE_OPENS)\n-                - valueProviders.statistics.getAndResetTickerCount(TickerType.NO_FILE_CLOSES);\n-            numberOfFileErrors += valueProviders.statistics.getAndResetTickerCount(TickerType.NO_FILE_ERRORS);\n+        if (storeToValueProviders.values().stream().anyMatch(valueProviders -> valueProviders.statistics != null)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c967a48033bcf92438e8fc419a6a8b4835ba665"}, "originalPosition": 66}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2039, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}