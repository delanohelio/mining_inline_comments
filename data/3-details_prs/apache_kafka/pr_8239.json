{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg0OTIzNDAy", "number": 8239, "title": "KAFKA-9666: Don't increase transactional epoch when trying to fence if the log append fails", "bodyText": "When fencing producers, we currently blindly bump the epoch by 1 and write an abort marker to the transaction log. If the log is unavailable (for example, because the number of in-sync replicas is less than min.in.sync.replicas), we will roll back the attempted write of the abort marker, but still increment the epoch in the transaction metadata cache. During periods of prolonged log unavailability, producer retires of InitProducerId calls can cause the epoch to be increased to the point of exhaustion, at which point further InitProducerId calls fail because the producer can no longer be fenced. With this patch, we track whenever we have failed to write the bumped epoch, and when that has happened, we don't bump the epoch any further when attempting to fence. This is safe because the in-memory epoch is still causes old producers to be fenced.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-03-06T16:55:16Z", "url": "https://github.com/apache/kafka/pull/8239", "merged": true, "mergeCommit": {"oid": "2eeae09ca3e5a9af89e1f15c0d772413ddc489ec"}, "closed": true, "closedAt": "2020-07-15T21:16:07Z", "author": {"login": "bob-barrett"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcLFnc8AFqTM3MDU4NjE5Ng==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc1N7N_gFqTQ0OTE2MzkzNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNTg2MTk2", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-370586196", "createdAt": "2020-03-06T19:51:52Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQxOTo1MTo1MlrOFzFhCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQxOTo1MTo1MlrOFzFhCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTExMjA3NQ==", "bodyText": "nit: period in the end", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389112075", "createdAt": "2020-03-06T19:51:52Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -242,10 +242,21 @@ class TransactionCoordinator(brokerId: Int,\n         case Ongoing =>\n           // indicate to abort the current ongoing txn first. Note that this epoch is never returned to the\n           // user. We will abort the ongoing transaction and return CONCURRENT_TRANSACTIONS to the client.\n-          // This forces the client to retry, which will ensure that the epoch is bumped a second time. In\n-          // particular, if fencing the current producer exhausts the available epochs for the current producerId,\n-          // then when the client retries, we will generate a new producerId.\n-          Right(coordinatorEpoch, txnMetadata.prepareFenceProducerEpoch())\n+          // This forces the client to retry, which will ensure that the epoch is bumped a second time. If the\n+          // epoch is exhausted, rotate the producer ID. Subsequent calls from the same producer will return the\n+          // new producer ID and epoch. This defends against cases of frequent retries during periods of persistent\n+          // coordinator unavailability, during which time the abort markers will not be written to the log and the\n+          // repeated fencing may lead to epoch exhaustion", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNTk2OTI1", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-370596925", "createdAt": "2020-03-06T20:10:57Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDoxMDo1N1rOFzGB7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMjoyNjowNlrOFzJS2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyMDQ5Mg==", "bodyText": "This logic is too tricky, could you add some comments on why the above 3 scenarios contribute to the fenced id rotation and why we are going to bypass the error handling? I could have some sense of why this is correct, but would feel very hard to read this path again.", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389120492", "createdAt": "2020-03-06T20:10:57Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -363,10 +374,13 @@ class TransactionCoordinator(brokerId: Int,\n           val txnMetadata = epochAndTxnMetadata.transactionMetadata\n           val coordinatorEpoch = epochAndTxnMetadata.coordinatorEpoch\n \n+          val isFencedProducerIdRotation = txnMetadata.isProducerEpochExhausted &&", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MDY2OA==", "bodyText": "I want to be clear about the symptom which is we don't handle epoch exhaustion during the fencing right? If yes, we should mention it more specifically as frequent retries just expose the problem, but the fix itself suggests to an error handling gap.", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389170668", "createdAt": "2020-03-06T22:16:08Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -242,10 +242,21 @@ class TransactionCoordinator(brokerId: Int,\n         case Ongoing =>\n           // indicate to abort the current ongoing txn first. Note that this epoch is never returned to the\n           // user. We will abort the ongoing transaction and return CONCURRENT_TRANSACTIONS to the client.\n-          // This forces the client to retry, which will ensure that the epoch is bumped a second time. In\n-          // particular, if fencing the current producer exhausts the available epochs for the current producerId,\n-          // then when the client retries, we will generate a new producerId.\n-          Right(coordinatorEpoch, txnMetadata.prepareFenceProducerEpoch())\n+          // This forces the client to retry, which will ensure that the epoch is bumped a second time. If the", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MTcxNA==", "bodyText": "This could be merged with above else case", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389171714", "createdAt": "2020-03-06T22:19:09Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -537,7 +553,13 @@ class TransactionCoordinator(brokerId: Int,\n                 \"pending state transition\")\n               None\n             } else {\n-              Some(txnMetadata.prepareFenceProducerEpoch())\n+              if (txnMetadata.isProducerEpochExhausted) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MzY4MA==", "bodyText": "Could we simplify this logic by just passing epoch as a field?", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389173680", "createdAt": "2020-03-06T22:25:20Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionMetadata.scala", "diffHunk": "@@ -259,12 +259,15 @@ private[transaction] class TransactionMetadata(val transactionalId: String,\n   def prepareProducerIdRotation(newProducerId: Long,\n                                 newTxnTimeoutMs: Int,\n                                 updateTimestamp: Long,\n-                                recordLastEpoch: Boolean): TxnTransitMetadata = {\n-    if (hasPendingTransaction)\n+                                recordLastEpoch: Boolean,\n+                                fenceProducer: Boolean): TxnTransitMetadata = {\n+    if (hasPendingTransaction && !fenceProducer)\n       throw new IllegalStateException(\"Cannot rotate producer ids while a transaction is still pending\")\n \n-    prepareTransitionTo(Empty, newProducerId, 0, if (recordLastEpoch) producerEpoch else RecordBatch.NO_PRODUCER_EPOCH,\n-      newTxnTimeoutMs, immutable.Set.empty[TopicPartition], -1, updateTimestamp)\n+    logger.info(s\"Rotating producer ID from $producerId to $newProducerId because the producer epoch was exhausted\")\n+    prepareTransitionTo(if (fenceProducer) PrepareEpochFence else Empty, newProducerId, 0,\n+      if (recordLastEpoch) producerEpoch else RecordBatch.NO_PRODUCER_EPOCH, newTxnTimeoutMs,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3Mzk3Ng==", "bodyText": "Similarly, let's pass a new state instead of a boolean which needs to be determined again.", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389173976", "createdAt": "2020-03-06T22:26:06Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionMetadata.scala", "diffHunk": "@@ -259,12 +259,15 @@ private[transaction] class TransactionMetadata(val transactionalId: String,\n   def prepareProducerIdRotation(newProducerId: Long,\n                                 newTxnTimeoutMs: Int,\n                                 updateTimestamp: Long,\n-                                recordLastEpoch: Boolean): TxnTransitMetadata = {\n-    if (hasPendingTransaction)\n+                                recordLastEpoch: Boolean,\n+                                fenceProducer: Boolean): TxnTransitMetadata = {\n+    if (hasPendingTransaction && !fenceProducer)\n       throw new IllegalStateException(\"Cannot rotate producer ids while a transaction is still pending\")\n \n-    prepareTransitionTo(Empty, newProducerId, 0, if (recordLastEpoch) producerEpoch else RecordBatch.NO_PRODUCER_EPOCH,\n-      newTxnTimeoutMs, immutable.Set.empty[TopicPartition], -1, updateTimestamp)\n+    logger.info(s\"Rotating producer ID from $producerId to $newProducerId because the producer epoch was exhausted\")\n+    prepareTransitionTo(if (fenceProducer) PrepareEpochFence else Empty, newProducerId, 0,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNzA3NzAw", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-370707700", "createdAt": "2020-03-07T01:14:26Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxMzkwODMz", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-371390833", "createdAt": "2020-03-09T17:37:34Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNzozNzozNFrOFzynhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNzozNzozNFrOFzynhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg1MTAxMw==", "bodyText": "Could we also verify other modules like pidManager here?", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389851013", "createdAt": "2020-03-09T17:37:34Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/unit/kafka/coordinator/transaction/TransactionCoordinatorTest.scala", "diffHunk": "@@ -861,6 +862,39 @@ class TransactionCoordinatorTest {\n     EasyMock.verify(transactionManager)\n   }\n \n+  @Test\n+  def shouldAbortExpiredTransactionsInOngoingStateAndRotateProducerIdIfEpochIsExhausted(): Unit = {\n+    val now = time.milliseconds()\n+    val exhaustedProducerEpoch = (Short.MaxValue - 1).toShort\n+    val txnMetadata = new TransactionMetadata(transactionalId, producerId, producerId, exhaustedProducerEpoch,\n+      RecordBatch.NO_PRODUCER_EPOCH, txnTimeoutMs, Ongoing, partitions, now, now)\n+\n+    EasyMock.expect(transactionManager.timedOutTransactions())\n+      .andReturn(List(TransactionalIdAndProducerIdEpoch(transactionalId, producerId, exhaustedProducerEpoch)))\n+    EasyMock.expect(transactionManager.getTransactionState(EasyMock.eq(transactionalId)))\n+      .andReturn(Right(Some(CoordinatorEpochAndTxnMetadata(coordinatorEpoch, txnMetadata))))\n+      .times(2)\n+\n+    val newProducerId = producerId + 1\n+    EasyMock.expect(pidManager.generateProducerId()).andAnswer(() => newProducerId)\n+    val expectedTransition = TxnTransitMetadata(newProducerId, newProducerId, 0, exhaustedProducerEpoch, txnTimeoutMs,\n+      PrepareAbort, partitions.toSet, now, now + TransactionStateManager.DefaultAbortTimedOutTransactionsIntervalMs)\n+\n+    EasyMock.expect(transactionManager.appendTransactionToLog(EasyMock.eq(transactionalId),\n+      EasyMock.eq(coordinatorEpoch),\n+      EasyMock.eq(expectedTransition),\n+      EasyMock.capture(capturedErrorsCallback),\n+      EasyMock.anyObject())\n+    ).andAnswer(() => {}).once()\n+\n+    EasyMock.replay(transactionManager, transactionMarkerChannelManager, pidManager)\n+\n+    coordinator.startup(false)\n+    time.sleep(TransactionStateManager.DefaultAbortTimedOutTransactionsIntervalMs)\n+    scheduler.tick()\n+    EasyMock.verify(transactionManager)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 94}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxMzkxMjYz", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-371391263", "createdAt": "2020-03-09T17:38:10Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNDAzODc1", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-372403875", "createdAt": "2020-03-11T00:16:31Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMDoxNjozMVrOF0lXWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMDo1MDoxNFrOF0l4rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY4MjQ1Nw==", "bodyText": "Do all of these checks make sense for an EndTxnRequest from the client? I guess we could get a call to EndTxn from a zombie producer while it is in the middle of being fenced. I think the checks below would result in CONCURRENT_TRANSACTIONS which would cause the zombie to retry until the transition completes. Maybe that's reasonable?", "url": "https://github.com/apache/kafka/pull/8239#discussion_r390682457", "createdAt": "2020-03-11T00:16:31Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -364,9 +365,14 @@ class TransactionCoordinator(brokerId: Int,\n           val coordinatorEpoch = epochAndTxnMetadata.coordinatorEpoch\n \n           txnMetadata.inLock {\n-            if (txnMetadata.producerId != producerId)\n+            // If we are ending the transaction due to a fenced producer and we are rotating the producer ID because the\n+            // epoch was exhausted, we need to skip the typical ID and epoch checks because the transaction metadata\n+            // object will already have been changed.\n+            val isFencedProducerRotation = txnMetadata.isProducerEpochExhausted &&", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY4NDQyOA==", "bodyText": "Is this check equivalent to txnMetadata.pendingState.contains(PrepareEpochFence)?", "url": "https://github.com/apache/kafka/pull/8239#discussion_r390684428", "createdAt": "2020-03-11T00:24:00Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -364,9 +365,14 @@ class TransactionCoordinator(brokerId: Int,\n           val coordinatorEpoch = epochAndTxnMetadata.coordinatorEpoch\n \n           txnMetadata.inLock {\n-            if (txnMetadata.producerId != producerId)\n+            // If we are ending the transaction due to a fenced producer and we are rotating the producer ID because the\n+            // epoch was exhausted, we need to skip the typical ID and epoch checks because the transaction metadata\n+            // object will already have been changed.\n+            val isFencedProducerRotation = txnMetadata.isProducerEpochExhausted &&\n+              txnMetadata.pendingState.contains(PrepareEpochFence)\n+            if (txnMetadata.producerId != producerId && !isFencedProducerRotation)\n               Left(Errors.INVALID_PRODUCER_ID_MAPPING)\n-            else if (producerEpoch < txnMetadata.producerEpoch)\n+            else if (producerEpoch < txnMetadata.producerEpoch && !isFencedProducerRotation)\n               Left(Errors.INVALID_PRODUCER_EPOCH)\n             else if (txnMetadata.pendingTransitionInProgress && txnMetadata.pendingState.get != PrepareEpochFence)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5MDk5MQ==", "bodyText": "I'm trying to follow the logic here. Suppose we have an ongoing transaction that will be aborted after this call returns. We need to transition to PrepareAbort and we need to send markers using the old producerId and Short.MaxValue as the epoch. Does this logic ensure that that happens?", "url": "https://github.com/apache/kafka/pull/8239#discussion_r390690991", "createdAt": "2020-03-11T00:50:14Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -552,6 +560,22 @@ class TransactionCoordinator(brokerId: Int,\n     }\n   }\n \n+  // Fence the producer by either incrementing the producer epoch or, if the epoch is exhausted, rotating the producer ID.\n+  // Rotating the producer ID is necessary because we can't always write the metadata transition to the transaction log\n+  // (such as in the case when there are too few in-sync replicas), but we always reflect the fencing in the transaction\n+  // metadata. If we bump the epoch to the point of exhaustion but fail to write to the log, we would be stuck\n+  // with an Ongoing transaction that couldn't be closed by the coordinator because our epoch is exhausted and couldn't\n+  // be closed by the client because it would be stuck without a valid producer ID and epoch.\n+  private def prepareFenceProducer(txnMetadata: TransactionMetadata): TxnTransitMetadata = {\n+    if (txnMetadata.isProducerEpochExhausted) {\n+      val newProducerId = producerIdManager.generateProducerId()\n+      txnMetadata.prepareProducerIdRotation(newProducerId, txnMetadata.txnTimeoutMs, time.milliseconds(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c979aba51b0732d9bc71c7179003d2a14afeef33", "author": {"user": {"login": "bob-barrett", "name": "Bob Barrett"}}, "url": "https://github.com/apache/kafka/commit/c979aba51b0732d9bc71c7179003d2a14afeef33", "committedDate": "2020-03-19T16:50:24Z", "message": "KAFKA-9666: Don't increase transactional epoch when trying to fence if the log append fails"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "c979aba51b0732d9bc71c7179003d2a14afeef33", "author": {"user": {"login": "bob-barrett", "name": "Bob Barrett"}}, "url": "https://github.com/apache/kafka/commit/c979aba51b0732d9bc71c7179003d2a14afeef33", "committedDate": "2020-03-19T16:50:24Z", "message": "KAFKA-9666: Don't increase transactional epoch when trying to fence if the log append fails"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNTYyODQ5", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-392562849", "createdAt": "2020-04-14T02:32:00Z", "commit": {"oid": "c979aba51b0732d9bc71c7179003d2a14afeef33"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2ODQ0NDIw", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-406844420", "createdAt": "2020-05-06T17:43:28Z", "commit": {"oid": "c979aba51b0732d9bc71c7179003d2a14afeef33"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQxNzo0MzoyOFrOGReRJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQxNzo0MzoyOFrOGReRJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk3NDg4Ng==", "bodyText": "Took me a while to remember this issue... So basically the coordinator has decided to abort a transaction and has bumped the epoch. However, when it tries to write the updated state to the log, it fails, which leaves us in an inconsistent state. Of course failing to write to the log doesn't necessarily mean that the entry wasn't appended. In fact, it could still become committed. There is no way to take the write back once it gets to the log. Hence I'm a little hesitant about the logic to revert to the previous epoch in this case. Would it still be possible for the fenced producer to make progress with the old epoch after reverting? Perhaps another idea would be to keep the epoch bumped in memory, but remember the fact that the write had failed. So the next time we go to retry the abort, we do not need to bump the epoch again. Does that make sense?", "url": "https://github.com/apache/kafka/pull/8239#discussion_r420974886", "createdAt": "2020-05-06T17:43:28Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -487,6 +487,33 @@ class TransactionCoordinator(brokerId: Int,\n               info(s\"Aborting sending of transaction markers and returning $error error to client for $transactionalId's EndTransaction request of $txnMarkerResult, \" +\n                 s\"since appending $newMetadata to transaction log with coordinator epoch $coordinatorEpoch failed\")\n \n+              txnManager.getTransactionState(transactionalId).right.foreach {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c979aba51b0732d9bc71c7179003d2a14afeef33"}, "originalPosition": 13}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7cf16c6479442c53716a89d435291388085a7568", "author": {"user": {"login": "bob-barrett", "name": "Bob Barrett"}}, "url": "https://github.com/apache/kafka/commit/7cf16c6479442c53716a89d435291388085a7568", "committedDate": "2020-06-08T17:23:54Z", "message": "Merge branch 'trunk' into KAFKA-9666"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1125ae3d46b02bbf39603595e33a53ea27e3c1d6", "author": {"user": {"login": "bob-barrett", "name": "Bob Barrett"}}, "url": "https://github.com/apache/kafka/commit/1125ae3d46b02bbf39603595e33a53ea27e3c1d6", "committedDate": "2020-06-08T23:11:17Z", "message": "Retain bumped epoch in memory without increasing it until it is successfully written"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e5b573e9311719da997bb7c890e4de4c311b6d2", "author": {"user": {"login": "bob-barrett", "name": "Bob Barrett"}}, "url": "https://github.com/apache/kafka/commit/6e5b573e9311719da997bb7c890e4de4c311b6d2", "committedDate": "2020-06-09T00:12:30Z", "message": "Fix flakiness in integration test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzMzY2ODUz", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-443366853", "createdAt": "2020-07-06T19:56:23Z", "commit": {"oid": "6e5b573e9311719da997bb7c890e4de4c311b6d2"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3NTYwMzc4", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-447560378", "createdAt": "2020-07-13T20:02:58Z", "commit": {"oid": "6e5b573e9311719da997bb7c890e4de4c311b6d2"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMDowMjo1OFrOGw3zrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxOTozOTo1M1rOGxieQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg5OTE4MQ==", "bodyText": "Looks like this was forgotten.", "url": "https://github.com/apache/kafka/pull/8239#discussion_r453899181", "createdAt": "2020-07-13T20:02:58Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -501,6 +502,21 @@ class TransactionCoordinator(brokerId: Int,\n               info(s\"Aborting sending of transaction markers and returning $error error to client for $transactionalId's EndTransaction request of $txnMarkerResult, \" +\n                 s\"since appending $newMetadata to transaction log with coordinator epoch $coordinatorEpoch failed\")\n \n+              if (isEpochFence) {\n+                txnManager.getTransactionState(transactionalId).foreach {\n+                  case None =>\n+                    warn(s\"The coordinator still owns the transaction partition for $transactionalId, but there is \" +\n+                      s\"no metadata in the cache; this is not expected\")\n+\n+                  case Some(epochAndMetadata) =>\n+                    if (epochAndMetadata.coordinatorEpoch == coordinatorEpoch) {\n+                      // This was attempted epoch fence that failed, so mark this state on the metadata\n+                      epochAndMetadata.transactionMetadata.hasFailedEpochFence = true\n+                      warn(\"\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e5b573e9311719da997bb7c890e4de4c311b6d2"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5NjM1Ng==", "bodyText": "I believe it's accurate to say that if hasFailedEpochFence is set, then the bumped epoch could not have been returned to the client. Is that right? It might be worth a comment emphasizing that.", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454596356", "createdAt": "2020-07-14T19:36:10Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionMetadata.scala", "diffHunk": "@@ -210,7 +214,9 @@ private[transaction] class TransactionMetadata(val transactionalId: String,\n     if (producerEpoch == Short.MaxValue)\n       throw new IllegalStateException(s\"Cannot fence producer with epoch equal to Short.MaxValue since this would overflow\")\n \n-    prepareTransitionTo(PrepareEpochFence, producerId, (producerEpoch + 1).toShort, RecordBatch.NO_PRODUCER_EPOCH, txnTimeoutMs,\n+    val bumpedEpoch = if (hasFailedEpochFence) producerEpoch else (producerEpoch + 1).toShort", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e5b573e9311719da997bb7c890e4de4c311b6d2"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5NjY4Mw==", "bodyText": "Can you explain why we no longer need to set this?", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454596683", "createdAt": "2020-07-14T19:36:51Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -394,8 +395,8 @@ class TransactionCoordinator(brokerId: Int,\n                 if (nextState == PrepareAbort && txnMetadata.pendingState.contains(PrepareEpochFence)) {\n                   // We should clear the pending state to make way for the transition to PrepareAbort and also bump\n                   // the epoch in the transaction metadata we are about to append.\n+                  isEpochFence = true\n                   txnMetadata.pendingState = None\n-                  txnMetadata.lastProducerEpoch = txnMetadata.producerEpoch", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e5b573e9311719da997bb7c890e4de4c311b6d2"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5ODAyOA==", "bodyText": "Hmm was this wrong? It seems weird to have last producer epoch set to a value which is 2 less than the producer epoch.", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454598028", "createdAt": "2020-07-14T19:39:34Z", "author": {"login": "hachikuji"}, "path": "core/src/test/scala/unit/kafka/coordinator/transaction/TransactionCoordinatorTest.scala", "diffHunk": "@@ -564,7 +564,7 @@ class TransactionCoordinatorTest {\n       .anyTimes()\n \n     val originalMetadata = new TransactionMetadata(transactionalId, producerId, producerId, (producerEpoch + 1).toShort,\n-      producerEpoch, txnTimeoutMs, Ongoing, partitions, time.milliseconds(), time.milliseconds())\n+      (producerEpoch - 1).toShort, txnTimeoutMs, Ongoing, partitions, time.milliseconds(), time.milliseconds())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e5b573e9311719da997bb7c890e4de4c311b6d2"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5ODIxMQ==", "bodyText": "nit: did we not need this?", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454598211", "createdAt": "2020-07-14T19:39:53Z", "author": {"login": "hachikuji"}, "path": "core/src/test/scala/unit/kafka/coordinator/transaction/TransactionCoordinatorTest.scala", "diffHunk": "@@ -614,6 +614,83 @@ class TransactionCoordinatorTest {\n     EasyMock.verify(transactionManager)\n   }\n \n+  @Test\n+  def shouldNotRepeatedlyBumpEpochDueToInitPidDuringOngoingTxnIfAppendToLogFails(): Unit = {\n+    val txnMetadata = new TransactionMetadata(transactionalId, producerId, producerId, producerEpoch,\n+      RecordBatch.NO_PRODUCER_EPOCH, txnTimeoutMs, Ongoing, partitions, time.milliseconds(), time.milliseconds())\n+\n+    EasyMock.expect(transactionManager.validateTransactionTimeoutMs(EasyMock.anyInt()))\n+      .andReturn(true)\n+      .anyTimes()\n+\n+    EasyMock.expect(transactionManager.putTransactionStateIfNotExists(EasyMock.anyObject[TransactionMetadata]()))\n+      .andReturn(Right(CoordinatorEpochAndTxnMetadata(coordinatorEpoch, txnMetadata)))\n+      .anyTimes()\n+\n+    EasyMock.expect(transactionManager.getTransactionState(EasyMock.eq(transactionalId)))\n+      .andAnswer(() => Right(Some(CoordinatorEpochAndTxnMetadata(coordinatorEpoch, txnMetadata))))\n+      .anyTimes()\n+\n+    /* val txnMetadataAfterAppendFailure = new TransactionMetadata(transactionalId, producerId, producerId, (producerEpoch + 1).toShort,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e5b573e9311719da997bb7c890e4de4c311b6d2"}, "originalPosition": 30}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc22f931854318a4df3cb3f13c9b30c12d0ed9c8", "author": {"user": {"login": "bob-barrett", "name": "Bob Barrett"}}, "url": "https://github.com/apache/kafka/commit/cc22f931854318a4df3cb3f13c9b30c12d0ed9c8", "committedDate": "2020-07-15T09:06:16Z", "message": "PR feedback"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ5MTYzOTM0", "url": "https://github.com/apache/kafka/pull/8239#pullrequestreview-449163934", "createdAt": "2020-07-15T17:17:31Z", "commit": {"oid": "cc22f931854318a4df3cb3f13c9b30c12d0ed9c8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 127, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}