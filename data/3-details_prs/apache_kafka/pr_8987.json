{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ0OTY5Mzk5", "number": 8987, "title": "KAFKA-10221: Backport fix for KAFKA-9603 to 2.5", "bodyText": "KAFKA-9603 reports that the number of open files keeps increasing\nin RocksDB. The reason is that bulk loading is turned on but\nnever turned off in segmented state stores for standby tasks.\nThis bug was fixed in 2.6 through PR #8661 by using code that is not present in 2.5.\nSo cherry-picking was not possible.\nThis PR backports the fix to 2.5.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-07-06T19:49:21Z", "url": "https://github.com/apache/kafka/pull/8987", "merged": true, "mergeCommit": {"oid": "17f9f3ae56a1049f035841a36cdc70a33ba91779"}, "closed": true, "closedAt": "2020-07-08T02:52:55Z", "author": {"login": "cadonna"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcyWh8cgH2gAyNDQ0OTY5Mzk5OjY1MjI1MDM0NGZjYjZkNTliZDI5MWQ0NTg4ZTQxYTg0ZDYwODc0NzA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcyrYtQAH2gAyNDQ0OTY5Mzk5OmY0YWU4ZWExOTBjMmNkZGI2NTA2NmJiYmUzMDU0ZjQwZmU3YmNlZTc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "652250344fcb6d59bd291d4588e41a84d6087470", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/652250344fcb6d59bd291d4588e41a84d6087470", "committedDate": "2020-07-06T19:37:17Z", "message": "KAFKA-10221: Backport fix for KAFKA-9603 to 2.5\n\nKAFKA-9603 reports that the number of open files keeps increasing\nin RocksDB. The reason is that bulk loading is turned on but\nnever turned off in segmented state stores for standby tasks.\n\nThis bug was fixed in 2.6 by using code that is not present in 2.5.\n\nThis PR backports the fix to 2.5."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ0MDE3NDc3", "url": "https://github.com/apache/kafka/pull/8987#pullrequestreview-444017477", "createdAt": "2020-07-07T15:41:50Z", "commit": {"oid": "652250344fcb6d59bd291d4588e41a84d6087470"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNTo0MTo1MFrOGuEh_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNTo0MTo1MFrOGuEh_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDk2MTkxOQ==", "bodyText": "Woah, this is subtle. IIUC, the fix works by asserting that we should only enable bulk loading if the provided context is a ProcessorContextImpl, which is the kind of context that is only provided when adding the store to an active task.\nThis seems correct to me, and although it's very subtle, it also seems ok as a patch for an older codebase that won't need to be maintained much. But maybe we can have a comment, or an internal method for the check, like\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            if (!bulkLoadSegments.contains(segment) && context instanceof ProcessorContextImpl) {\n          \n          \n            \n                            if (!bulkLoadSegments.contains(segment) && isStoreForActiveTask(context)) {\n          \n      \n    \n    \n  \n\nso that it'll be more obvious what's going on here?", "url": "https://github.com/apache/kafka/pull/8987#discussion_r450961919", "createdAt": "2020-07-07T15:41:50Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/AbstractRocksDBSegmentedBytesStore.java", "diffHunk": "@@ -251,7 +252,7 @@ void restoreAllInternal(final Collection<KeyValue<byte[], byte[]>> records) {\n                 // This handles the case that state store is moved to a new client and does not\n                 // have the local RocksDB instance for the segment. In this case, toggleDBForBulkLoading\n                 // will only close the database and open it again with bulk loading enabled.\n-                if (!bulkLoadSegments.contains(segment)) {\n+                if (!bulkLoadSegments.contains(segment) && context instanceof ProcessorContextImpl) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "652250344fcb6d59bd291d4588e41a84d6087470"}, "originalPosition": 13}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f4ae8ea190c2cddb65066bbbe3054f40fe7bcee7", "author": {"user": {"login": "cadonna", "name": "Bruno Cadonna"}}, "url": "https://github.com/apache/kafka/commit/f4ae8ea190c2cddb65066bbbe3054f40fe7bcee7", "committedDate": "2020-07-07T19:55:12Z", "message": "Make code more readable"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1179, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}