{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1NjE2Njg3", "number": 8257, "title": "KAFKA-9539; Add leader epoch in StopReplicaRequest (KIP-570)", "bodyText": "This PR implements KIP-570.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-03-09T14:20:17Z", "url": "https://github.com/apache/kafka/pull/8257", "merged": true, "mergeCommit": {"oid": "7c7d55dbd8d42f6378d13ba02d62633366a7ede8"}, "closed": true, "closedAt": "2020-04-14T18:39:57Z", "author": {"login": "dajac"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcL-t2xgFqTM3MTIyNTYzOA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcXlBEsAFqTM5MzAyOTE1Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxMjI1NjM4", "url": "https://github.com/apache/kafka/pull/8257#pullrequestreview-371225638", "createdAt": "2020-03-09T14:23:26Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNDoyMzoyNlrOFzqulg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNDoyMzoyNlrOFzqulg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTcyMTc1MA==", "bodyText": "\ud83d\udc40 During the implementation, I have realized that the schema which has been proposed in the KIP does not work (my mistake). I propose to use the following schema instead. This schema will allow us to add more fields in the future. If the reviewer agree with this, I will update the KIP and and the VOTE thread.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r389721750", "createdAt": "2020-03-09T14:23:26Z", "author": {"login": "dajac"}, "path": "clients/src/main/resources/common/message/StopReplicaRequest.json", "diffHunk": "@@ -19,7 +19,11 @@\n   \"name\": \"StopReplicaRequest\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxMjI4MTE2", "url": "https://github.com/apache/kafka/pull/8257#pullrequestreview-371228116", "createdAt": "2020-03-09T14:26:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNDoyNjoxNlrOFzq2Gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNDoyNjoxNlrOFzq2Gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTcyMzY3NA==", "bodyText": "\ud83d\udc40 I have added a new IBP version to gate the new API version. I was wondering if the was really necessary as the new version of the API is backward compatible.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r389723674", "createdAt": "2020-03-09T14:26:16Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/api/ApiVersion.scala", "diffHunk": "@@ -96,7 +96,9 @@ object ApiVersion {\n     // Flexible version support in inter-broker APIs\n     KAFKA_2_4_IV1,\n     // No new APIs, equivalent to 2.4-IV1\n-    KAFKA_2_5_IV0\n+    KAFKA_2_5_IV0,\n+    // Introduced StopReplicaRequest V3 containing the leader epoch for each partition (KIP-570)\n+    KAFKA_2_6_IV0", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxMjI5NDU2", "url": "https://github.com/apache/kafka/pull/8257#pullrequestreview-371229456", "createdAt": "2020-03-09T14:27:43Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNDoyNzo0M1rOFzq6Lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNDoyNzo0M1rOFzq6Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTcyNDcxOQ==", "bodyText": "\ud83d\udc40 This is the logic which handle the sentinel. -2 is used when a topic is deleted and also when the partition doesn't have leadership information yet.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r389724719", "createdAt": "2020-03-09T14:27:43Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -397,8 +398,25 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n                                       topicPartition: TopicPartition,\n                                       deletePartition: Boolean): Unit = {\n     brokerIds.filter(_ >= 0).foreach { brokerId =>\n-      val stopReplicaInfos = stopReplicaRequestMap.getOrElseUpdate(brokerId, ListBuffer.empty[StopReplicaRequestInfo])\n-      stopReplicaInfos.append(StopReplicaRequestInfo(PartitionAndReplica(topicPartition, brokerId), deletePartition))\n+      val result = if (deletePartition)\n+        stopReplicaRequestMapWithDelete.getOrElseUpdate(brokerId, mutable.Map.empty)\n+      else\n+        stopReplicaRequestMapWithoutDelete.getOrElseUpdate(brokerId, mutable.Map.empty)\n+\n+      // A sentinel (-2) is used as an epoch if the topic is queued for deletion or\n+      // does not have a leader yet. This sentinel overrides any existing epoch.\n+      val leaderEpoch = if (controllerContext.isTopicQueuedUpForDeletion(topicPartition.topic)) {\n+        LeaderAndIsr.EpochDuringDelete\n+      } else {\n+        controllerContext.partitionLeadershipInfo.get(topicPartition)\n+          .map(_.leaderAndIsr.leaderEpoch)\n+          .getOrElse(LeaderAndIsr.EpochDuringDelete)\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NjU2MTUw", "url": "https://github.com/apache/kafka/pull/8257#pullrequestreview-375656150", "createdAt": "2020-03-16T23:53:10Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMzo1MzoxMFrOF3JmwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDo1NDoxOFrOF3KhtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3MzM3Ng==", "bodyText": "Wonder if it makes sense to add this method to StopReplicaRequest. Often the code expects to work with TopicPartition.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r393373376", "createdAt": "2020-03-16T23:53:10Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/StopReplicaRequestTest.java", "diffHunk": "@@ -44,22 +52,144 @@ public void testUnsupportedVersion() {\n \n     @Test\n     public void testGetErrorResponse() {\n+        List<StopReplicaTopicState> topicStates = topicStates();\n+\n+        Set<StopReplicaPartitionError> expectedPartitions = new HashSet<>();\n+        for (StopReplicaTopicState topicState : topicStates) {\n+            for (StopReplicaPartitionState partitionState: topicState.partitionStates()) {\n+                expectedPartitions.add(new StopReplicaPartitionError()\n+                    .setTopicName(topicState.topicName())\n+                    .setPartitionIndex(partitionState.partitionIndex())\n+                    .setErrorCode(Errors.CLUSTER_AUTHORIZATION_FAILED.code()));\n+            }\n+        }\n+\n         for (short version = STOP_REPLICA.oldestVersion(); version < STOP_REPLICA.latestVersion(); version++) {\n             StopReplicaRequest.Builder builder = new StopReplicaRequest.Builder(version,\n-                    0, 0, 0L, false, Collections.emptyList());\n+                    0, 0, 0L, false, topicStates);\n             StopReplicaRequest request = builder.build();\n             StopReplicaResponse response = request.getErrorResponse(0,\n                     new ClusterAuthorizationException(\"Not authorized\"));\n             assertEquals(Errors.CLUSTER_AUTHORIZATION_FAILED, response.error());\n+            assertEquals(expectedPartitions, new HashSet<>(response.partitionErrors()));\n+        }\n+    }\n+\n+    @Test\n+    public void testBuilderNormalization() {\n+        List<StopReplicaTopicState> topicStates = topicStates();\n+\n+        Set<TopicPartition> expectedPartitions = new HashSet<>();\n+        for (StopReplicaTopicState topicState : topicStates) {\n+            for (StopReplicaPartitionState partitionState: topicState.partitionStates()) {\n+                expectedPartitions.add(\n+                    new TopicPartition(topicState.topicName(), partitionState.partitionIndex()));\n+            }\n+        }\n+\n+        Map<TopicPartition, StopReplicaPartitionState> expectedPartitionStates = new HashMap<>();\n+        for (StopReplicaTopicState topicState : topicStates) {\n+            for (StopReplicaPartitionState partitionState: topicState.partitionStates()) {\n+                expectedPartitionStates.put(\n+                    new TopicPartition(topicState.topicName(), partitionState.partitionIndex()),\n+                    partitionState);\n+            }\n+        }\n+\n+        for (short version = STOP_REPLICA.oldestVersion(); version < STOP_REPLICA.latestVersion(); version++) {\n+            StopReplicaRequest request = new StopReplicaRequest.Builder(version, 0, 1, 0,\n+                true, topicStates).build(version);\n+            StopReplicaRequestData data = request.data();\n+\n+            if (version < 1) {\n+                Set<TopicPartition> partitions = new HashSet<>();\n+                for (StopReplicaPartitionV0 partition : data.ungroupedPartitions()) {\n+                    partitions.add(new TopicPartition(partition.topicName(), partition.partitionIndex()));\n+                }\n+                assertEquals(expectedPartitions, partitions);\n+            } else if (version < 3) {\n+                Set<TopicPartition> partitions = new HashSet<>();\n+                for (StopReplicaTopicV1 topic : data.topics()) {\n+                    for (Integer partition : topic.partitionIndexes()) {\n+                        partitions.add(new TopicPartition(topic.name(), partition));\n+                    }\n+                }\n+                assertEquals(expectedPartitions, partitions);\n+            } else {\n+                Map<TopicPartition, StopReplicaPartitionState> partitionStates = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3MzgxNA==", "bodyText": "Might be worth adding one case where the epoch is -2.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r393373814", "createdAt": "2020-03-16T23:54:50Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/StopReplicaRequestTest.java", "diffHunk": "@@ -44,22 +52,144 @@ public void testUnsupportedVersion() {\n \n     @Test\n     public void testGetErrorResponse() {\n+        List<StopReplicaTopicState> topicStates = topicStates();\n+\n+        Set<StopReplicaPartitionError> expectedPartitions = new HashSet<>();\n+        for (StopReplicaTopicState topicState : topicStates) {\n+            for (StopReplicaPartitionState partitionState: topicState.partitionStates()) {\n+                expectedPartitions.add(new StopReplicaPartitionError()\n+                    .setTopicName(topicState.topicName())\n+                    .setPartitionIndex(partitionState.partitionIndex())\n+                    .setErrorCode(Errors.CLUSTER_AUTHORIZATION_FAILED.code()));\n+            }\n+        }\n+\n         for (short version = STOP_REPLICA.oldestVersion(); version < STOP_REPLICA.latestVersion(); version++) {\n             StopReplicaRequest.Builder builder = new StopReplicaRequest.Builder(version,\n-                    0, 0, 0L, false, Collections.emptyList());\n+                    0, 0, 0L, false, topicStates);\n             StopReplicaRequest request = builder.build();\n             StopReplicaResponse response = request.getErrorResponse(0,\n                     new ClusterAuthorizationException(\"Not authorized\"));\n             assertEquals(Errors.CLUSTER_AUTHORIZATION_FAILED, response.error());\n+            assertEquals(expectedPartitions, new HashSet<>(response.partitionErrors()));\n+        }\n+    }\n+\n+    @Test\n+    public void testBuilderNormalization() {\n+        List<StopReplicaTopicState> topicStates = topicStates();\n+\n+        Set<TopicPartition> expectedPartitions = new HashSet<>();\n+        for (StopReplicaTopicState topicState : topicStates) {\n+            for (StopReplicaPartitionState partitionState: topicState.partitionStates()) {\n+                expectedPartitions.add(\n+                    new TopicPartition(topicState.topicName(), partitionState.partitionIndex()));\n+            }\n+        }\n+\n+        Map<TopicPartition, StopReplicaPartitionState> expectedPartitionStates = new HashMap<>();\n+        for (StopReplicaTopicState topicState : topicStates) {\n+            for (StopReplicaPartitionState partitionState: topicState.partitionStates()) {\n+                expectedPartitionStates.put(\n+                    new TopicPartition(topicState.topicName(), partitionState.partitionIndex()),\n+                    partitionState);\n+            }\n+        }\n+\n+        for (short version = STOP_REPLICA.oldestVersion(); version < STOP_REPLICA.latestVersion(); version++) {\n+            StopReplicaRequest request = new StopReplicaRequest.Builder(version, 0, 1, 0,\n+                true, topicStates).build(version);\n+            StopReplicaRequestData data = request.data();\n+\n+            if (version < 1) {\n+                Set<TopicPartition> partitions = new HashSet<>();\n+                for (StopReplicaPartitionV0 partition : data.ungroupedPartitions()) {\n+                    partitions.add(new TopicPartition(partition.topicName(), partition.partitionIndex()));\n+                }\n+                assertEquals(expectedPartitions, partitions);\n+            } else if (version < 3) {\n+                Set<TopicPartition> partitions = new HashSet<>();\n+                for (StopReplicaTopicV1 topic : data.topics()) {\n+                    for (Integer partition : topic.partitionIndexes()) {\n+                        partitions.add(new TopicPartition(topic.name(), partition));\n+                    }\n+                }\n+                assertEquals(expectedPartitions, partitions);\n+            } else {\n+                Map<TopicPartition, StopReplicaPartitionState> partitionStates = new HashMap<>();\n+                for (StopReplicaTopicState topicState : topicStates) {\n+                    for (StopReplicaPartitionState partitionState: topicState.partitionStates()) {\n+                        partitionStates.put(\n+                            new TopicPartition(topicState.topicName(), partitionState.partitionIndex()),\n+                            partitionState);\n+                    }\n+                }\n+                assertEquals(expectedPartitionStates, partitionStates);\n+            }\n         }\n     }\n \n     @Test\n-    public void testStopReplicaRequestNormalization() {\n-        Set<TopicPartition> tps = TestUtils.generateRandomTopicPartitions(10, 10);\n-        StopReplicaRequest.Builder builder = new StopReplicaRequest.Builder((short) 5, 0, 0, 0, false, tps);\n-        assertTrue(MessageTestUtil.messageSize(builder.build((short) 1).data(), (short) 1) <\n-            MessageTestUtil.messageSize(builder.build((short) 0).data(), (short) 0));\n+    public void testTopicStatesNormalization() {\n+        List<StopReplicaTopicState> topicStates = topicStates();\n+\n+        for (short version = STOP_REPLICA.oldestVersion(); version < STOP_REPLICA.latestVersion(); version++) {\n+            // Create a request for version to get its struct\n+            StopReplicaRequest baseRequest = new StopReplicaRequest.Builder(version, 0, 1, 0,\n+                true, topicStates).build(version);\n+\n+            // Construct the request from the struct\n+            StopReplicaRequest request = new StopReplicaRequest(baseRequest.toStruct(), version);\n+\n+            Map<TopicPartition, StopReplicaPartitionState> partitionStates = new HashMap<>();\n+            for (StopReplicaTopicState topicState : request.topicStates()) {\n+                for (StopReplicaPartitionState partitionState: topicState.partitionStates()) {\n+                    partitionStates.put(\n+                        new TopicPartition(topicState.topicName(), partitionState.partitionIndex()),\n+                        partitionState);\n+                }\n+            }\n+\n+            assertEquals(4, partitionStates.size());\n+\n+            for (StopReplicaTopicState expectedTopicState : topicStates) {\n+                for (StopReplicaPartitionState expectedPartitionState: expectedTopicState.partitionStates()) {\n+                    TopicPartition tp = new TopicPartition(expectedTopicState.topicName(),\n+                        expectedPartitionState.partitionIndex());\n+                    StopReplicaPartitionState partitionState = partitionStates.get(tp);\n+\n+                    assertEquals(expectedPartitionState.partitionIndex(), partitionState.partitionIndex());\n+\n+                    if (version >= 3) {\n+                        assertEquals(expectedPartitionState.leaderEpoch(), partitionState.leaderEpoch());\n+                    } else {\n+                        assertEquals(-1, partitionState.leaderEpoch());\n+                    }\n+                }\n+            }\n+        }\n     }\n \n+    private List<StopReplicaTopicState> topicStates() {\n+        List<StopReplicaTopicState> topicStates = new ArrayList<>();\n+        StopReplicaTopicState topic0 = new StopReplicaTopicState()\n+            .setTopicName(\"topic0\");\n+        topic0.partitionStates().add(new StopReplicaPartitionState()\n+            .setPartitionIndex(0)\n+            .setLeaderEpoch(0));\n+        topic0.partitionStates().add(new StopReplicaPartitionState()\n+            .setPartitionIndex(1)\n+            .setLeaderEpoch(1));\n+        topicStates.add(topic0);\n+        StopReplicaTopicState topic1 = new StopReplicaTopicState()\n+            .setTopicName(\"topic1\");\n+        topic1.partitionStates().add(new StopReplicaPartitionState()\n+            .setPartitionIndex(2)\n+            .setLeaderEpoch(2));\n+        topic1.partitionStates().add(new StopReplicaPartitionState()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjkxMQ==", "bodyText": "It's a bit annoying that the DeletePartitions flag is set at the top level. It would be nice to move that into the partition state. A KIP for another day I guess...", "url": "https://github.com/apache/kafka/pull/8257#discussion_r393376911", "createdAt": "2020-03-17T00:06:35Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/resources/common/message/StopReplicaRequest.json", "diffHunk": "@@ -37,12 +41,24 @@\n       { \"name\": \"PartitionIndex\", \"type\": \"int32\", \"versions\": \"0\",\n         \"about\": \"The partition index.\" }\n     ]},\n-    { \"name\": \"Topics\", \"type\": \"[]StopReplicaTopic\", \"versions\": \"1+\",\n+    { \"name\": \"Topics\", \"type\": \"[]StopReplicaTopicV1\", \"versions\": \"1-2\",\n       \"about\": \"The topics to stop.\", \"fields\": [\n-      { \"name\": \"Name\", \"type\": \"string\", \"versions\": \"1+\", \"entityType\": \"topicName\",\n+      { \"name\": \"Name\", \"type\": \"string\", \"versions\": \"1-2\", \"entityType\": \"topicName\",\n         \"about\": \"The topic name.\" },\n-      { \"name\": \"PartitionIndexes\", \"type\": \"[]int32\", \"versions\": \"1+\",\n+      { \"name\": \"PartitionIndexes\", \"type\": \"[]int32\", \"versions\": \"1-2\",\n         \"about\": \"The partition indexes.\" }\n+    ]},\n+    { \"name\": \"TopicStates\", \"type\": \"[]StopReplicaTopicState\", \"versions\": \"3+\",\n+      \"about\": \"Each topic.\", \"fields\": [\n+      { \"name\": \"TopicName\", \"type\": \"string\", \"versions\": \"3+\", \"entityType\": \"topicName\",\n+        \"about\": \"The topic name.\" },\n+      { \"name\": \"PartitionStates\", \"type\": \"[]StopReplicaPartitionState\", \"versions\": \"3+\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4NTU1Mg==", "bodyText": "The iff was probably intentional, if a bit pedantic. I'm fine with the change though.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r393385552", "createdAt": "2020-03-17T00:42:05Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -707,7 +707,7 @@ class LogManager(logDirs: Seq[File],\n    * @param topicPartition The partition whose log needs to be returned or created\n    * @param config The configuration of the log that should be applied for log creation\n    * @param isNew Whether the replica should have existed on the broker or not\n-   * @param isFuture True iff the future log of the specified partition should be returned or created\n+   * @param isFuture True if the future log of the specified partition should be returned or created", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4NzQ0OQ==", "bodyText": "Hmm.. This error seems a little inaccurate. Could we use FENCED_LEADER_EPOCH?", "url": "https://github.com/apache/kafka/pull/8257#discussion_r393387449", "createdAt": "2020-03-17T00:50:11Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -364,30 +368,98 @@ class ReplicaManager(val config: KafkaConfig,\n     delayedFetchPurgatory.checkAndComplete(topicPartitionOperationKey)\n   }\n \n-  def stopReplicas(stopReplicaRequest: StopReplicaRequest): (mutable.Map[TopicPartition, Errors], Errors) = {\n+  def stopReplicas(correlationId: Int, stopReplicaRequest: StopReplicaRequest): (mutable.Map[TopicPartition, Errors], Errors) = {\n     replicaStateChangeLock synchronized {\n+      val controllerId = stopReplicaRequest.controllerId\n+      val deletePartition = stopReplicaRequest.deletePartitions\n       val responseMap = new collection.mutable.HashMap[TopicPartition, Errors]\n       if (stopReplicaRequest.controllerEpoch() < controllerEpoch) {\n-        stateChangeLogger.warn(\"Received stop replica request from an old controller epoch \" +\n-          s\"${stopReplicaRequest.controllerEpoch}. Latest known controller epoch is $controllerEpoch\")\n+        stateChangeLogger.warn(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+          s\"controller $controllerId with correlation id $correlationId \" +\n+          s\"since its controller epoch ${stopReplicaRequest.controllerEpoch} is old. \" +\n+          s\"Latest known controller epoch is $controllerEpoch\")\n         (responseMap, Errors.STALE_CONTROLLER_EPOCH)\n       } else {\n-        val partitions = stopReplicaRequest.partitions.asScala.toSet\n+        val partitions = mutable.Set.empty[TopicPartition]\n         controllerEpoch = stopReplicaRequest.controllerEpoch\n+\n+        stopReplicaRequest.topicStates.asScala.foreach { topicState =>\n+          topicState.partitionStates.asScala.foreach { partitionState =>\n+            val topicPartition = new TopicPartition(topicState.topicName, partitionState.partitionIndex)\n+\n+            getPartition(topicPartition) match {\n+              case HostedPartition.Offline =>\n+                stateChangeLogger.warn(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+                  s\"controller $controllerId with correlation id $correlationId \" +\n+                  s\"epoch $controllerEpoch for partition $topicPartition as the local replica for the \" +\n+                  \"partition is in an offline log directory\")\n+                responseMap.put(topicPartition, Errors.KAFKA_STORAGE_ERROR)\n+\n+              case HostedPartition.Online(partition) =>\n+                val currentLeaderEpoch = partition.getLeaderEpoch\n+                val requestLeaderEpoch = partitionState.leaderEpoch\n+                // When a topic is deleted, the leader epoch is not incremented. To circumvent this,\n+                // a sentinel value (EpochDuringDelete) overwriting any previous epoch is used.\n+                // When an older version of the StopReplica request which does not contain the leader\n+                // epoch, a sentinel value (NoEpoch) is used and bypass the epoch validation.\n+                if (requestLeaderEpoch == LeaderAndIsr.EpochDuringDelete ||\n+                    requestLeaderEpoch == LeaderAndIsr.NoEpoch ||\n+                    requestLeaderEpoch > currentLeaderEpoch) {\n+                  partitions += topicPartition\n+                } else if (requestLeaderEpoch < currentLeaderEpoch) {\n+                  stateChangeLogger.warn(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+                    s\"controller $controllerId with correlation id $correlationId \" +\n+                    s\"epoch $controllerEpoch for partition $topicPartition since its associated \" +\n+                    s\"leader epoch $requestLeaderEpoch is smaller than the current \" +\n+                    s\"leader epoch $currentLeaderEpoch\")\n+                  responseMap.put(topicPartition, Errors.STALE_CONTROLLER_EPOCH)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4ODQ2OA==", "bodyText": "This changes the order of the operations. Previously we would have stopped fetchers before attempting to delete the log directory. Are we sure this is safe?", "url": "https://github.com/apache/kafka/pull/8257#discussion_r393388468", "createdAt": "2020-03-17T00:54:18Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -364,30 +368,98 @@ class ReplicaManager(val config: KafkaConfig,\n     delayedFetchPurgatory.checkAndComplete(topicPartitionOperationKey)\n   }\n \n-  def stopReplicas(stopReplicaRequest: StopReplicaRequest): (mutable.Map[TopicPartition, Errors], Errors) = {\n+  def stopReplicas(correlationId: Int, stopReplicaRequest: StopReplicaRequest): (mutable.Map[TopicPartition, Errors], Errors) = {\n     replicaStateChangeLock synchronized {\n+      val controllerId = stopReplicaRequest.controllerId\n+      val deletePartition = stopReplicaRequest.deletePartitions\n       val responseMap = new collection.mutable.HashMap[TopicPartition, Errors]\n       if (stopReplicaRequest.controllerEpoch() < controllerEpoch) {\n-        stateChangeLogger.warn(\"Received stop replica request from an old controller epoch \" +\n-          s\"${stopReplicaRequest.controllerEpoch}. Latest known controller epoch is $controllerEpoch\")\n+        stateChangeLogger.warn(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+          s\"controller $controllerId with correlation id $correlationId \" +\n+          s\"since its controller epoch ${stopReplicaRequest.controllerEpoch} is old. \" +\n+          s\"Latest known controller epoch is $controllerEpoch\")\n         (responseMap, Errors.STALE_CONTROLLER_EPOCH)\n       } else {\n-        val partitions = stopReplicaRequest.partitions.asScala.toSet\n+        val partitions = mutable.Set.empty[TopicPartition]\n         controllerEpoch = stopReplicaRequest.controllerEpoch\n+\n+        stopReplicaRequest.topicStates.asScala.foreach { topicState =>\n+          topicState.partitionStates.asScala.foreach { partitionState =>\n+            val topicPartition = new TopicPartition(topicState.topicName, partitionState.partitionIndex)\n+\n+            getPartition(topicPartition) match {\n+              case HostedPartition.Offline =>\n+                stateChangeLogger.warn(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+                  s\"controller $controllerId with correlation id $correlationId \" +\n+                  s\"epoch $controllerEpoch for partition $topicPartition as the local replica for the \" +\n+                  \"partition is in an offline log directory\")\n+                responseMap.put(topicPartition, Errors.KAFKA_STORAGE_ERROR)\n+\n+              case HostedPartition.Online(partition) =>\n+                val currentLeaderEpoch = partition.getLeaderEpoch\n+                val requestLeaderEpoch = partitionState.leaderEpoch\n+                // When a topic is deleted, the leader epoch is not incremented. To circumvent this,\n+                // a sentinel value (EpochDuringDelete) overwriting any previous epoch is used.\n+                // When an older version of the StopReplica request which does not contain the leader\n+                // epoch, a sentinel value (NoEpoch) is used and bypass the epoch validation.\n+                if (requestLeaderEpoch == LeaderAndIsr.EpochDuringDelete ||\n+                    requestLeaderEpoch == LeaderAndIsr.NoEpoch ||\n+                    requestLeaderEpoch > currentLeaderEpoch) {\n+                  partitions += topicPartition\n+                } else if (requestLeaderEpoch < currentLeaderEpoch) {\n+                  stateChangeLogger.warn(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+                    s\"controller $controllerId with correlation id $correlationId \" +\n+                    s\"epoch $controllerEpoch for partition $topicPartition since its associated \" +\n+                    s\"leader epoch $requestLeaderEpoch is smaller than the current \" +\n+                    s\"leader epoch $currentLeaderEpoch\")\n+                  responseMap.put(topicPartition, Errors.STALE_CONTROLLER_EPOCH)\n+                } else {\n+                  stateChangeLogger.debug(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+                    s\"controller $controllerId with correlation id $correlationId \" +\n+                    s\"epoch $controllerEpoch for partition $topicPartition since its associated \" +\n+                    s\"leader epoch $requestLeaderEpoch matches the current leader epoch\")\n+                  responseMap.put(topicPartition, Errors.STALE_CONTROLLER_EPOCH)\n+                }\n+\n+              case HostedPartition.None =>\n+                try {\n+                  // Delete log and corresponding folders in case replica manager doesn't hold them anymore.\n+                  // This could happen when topic is being deleted while broker is down and recovers.\n+                  maybeCleanReplica(topicPartition, deletePartition)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 126}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyODI5NzQ5", "url": "https://github.com/apache/kafka/pull/8257#pullrequestreview-382829749", "createdAt": "2020-03-27T12:54:19Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxMjo1NDoxOVrOF8v2NA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxMjo1NDoxOVrOF8v2NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI0MjgwNA==", "bodyText": "@hachikuji It looks like that we could improve this now that we do have the leader epoch. I am not familiar at all with transactions. Can I just pass the epoch when provided here?", "url": "https://github.com/apache/kafka/pull/8257#discussion_r399242804", "createdAt": "2020-03-27T12:54:19Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -236,22 +236,22 @@ class KafkaApis(val requestChannel: RequestChannel,\n     if (isBrokerEpochStale(stopReplicaRequest.brokerEpoch)) {\n       // When the broker restarts very quickly, it is possible for this broker to receive request intended\n       // for its previous generation so the broker should skip the stale request.\n-      info(\"Received stop replica request with broker epoch \" +\n+      info(\"Received StopReplica request with broker epoch \" +\n         s\"${stopReplicaRequest.brokerEpoch} smaller than the current broker epoch ${controller.brokerEpoch}\")\n       sendResponseExemptThrottle(request, new StopReplicaResponse(new StopReplicaResponseData().setErrorCode(Errors.STALE_BROKER_EPOCH.code)))\n     } else {\n-      val (result, error) = replicaManager.stopReplicas(stopReplicaRequest)\n+      val (result, error) = replicaManager.stopReplicas(request.context.correlationId, stopReplicaRequest)\n       // Clear the coordinator caches in case we were the leader. In the case of a reassignment, we\n       // cannot rely on the LeaderAndIsr API for this since it is only sent to active replicas.\n-      result.foreach { case (topicPartition, error) =>\n-        if (error == Errors.NONE && stopReplicaRequest.deletePartitions) {\n-          if (topicPartition.topic == GROUP_METADATA_TOPIC_NAME) {\n-            groupCoordinator.onResignation(topicPartition.partition)\n-          } else if (topicPartition.topic == TRANSACTION_STATE_TOPIC_NAME) {\n-            // The StopReplica API does not pass through the leader epoch\n-            txnCoordinator.onResignation(topicPartition.partition, coordinatorEpoch = None)\n-          }\n-        }\n+      result.foreach {\n+        case (topicPartition, Left(true)) if topicPartition.topic == GROUP_METADATA_TOPIC_NAME =>\n+          groupCoordinator.onResignation(topicPartition.partition)\n+\n+        case (topicPartition, Left(true)) if topicPartition.topic == TRANSACTION_STATE_TOPIC_NAME =>\n+          // The StopReplica API does not pass through the leader epoch\n+          txnCoordinator.onResignation(topicPartition.partition, coordinatorEpoch = None)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg0MTQ2NTcw", "url": "https://github.com/apache/kafka/pull/8257#pullrequestreview-384146570", "createdAt": "2020-03-30T19:04:00Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxOTowNDoyMVrOF94C1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxOTozNDowMlrOF95I-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQyNTY4Ng==", "bodyText": "Might not be too big of a problem, but it would be nice to avoid this pass through all the partitions. As it is we have 1) first pass to split partitions, 2) second pass to validate split, 3) third pass to convert to the needed type. Seems like we should be able to save some work here, like perhaps moving the conversion to the caller (even though it's annoying).", "url": "https://github.com/apache/kafka/pull/8257#discussion_r400425686", "createdAt": "2020-03-30T19:04:21Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/StopReplicaRequest.java", "diffHunk": "@@ -17,75 +17,93 @@\n package org.apache.kafka.common.requests;\n \n import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.errors.UnsupportedVersionException;\n import org.apache.kafka.common.message.StopReplicaRequestData;\n+import org.apache.kafka.common.message.StopReplicaRequestData.StopReplicaPartitionState;\n import org.apache.kafka.common.message.StopReplicaRequestData.StopReplicaPartitionV0;\n-import org.apache.kafka.common.message.StopReplicaRequestData.StopReplicaTopic;\n+import org.apache.kafka.common.message.StopReplicaRequestData.StopReplicaTopicV1;\n+import org.apache.kafka.common.message.StopReplicaRequestData.StopReplicaTopicState;\n import org.apache.kafka.common.message.StopReplicaResponseData;\n import org.apache.kafka.common.message.StopReplicaResponseData.StopReplicaPartitionError;\n import org.apache.kafka.common.protocol.ApiKeys;\n import org.apache.kafka.common.protocol.Errors;\n import org.apache.kafka.common.protocol.types.Struct;\n-import org.apache.kafka.common.utils.CollectionUtils;\n-import org.apache.kafka.common.utils.FlattenedIterator;\n import org.apache.kafka.common.utils.MappedIterator;\n import org.apache.kafka.common.utils.Utils;\n \n import java.nio.ByteBuffer;\n import java.util.ArrayList;\n-import java.util.Collection;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n public class StopReplicaRequest extends AbstractControlRequest {\n \n     public static class Builder extends AbstractControlRequest.Builder<StopReplicaRequest> {\n-        private final boolean deletePartitions;\n-        private final Collection<TopicPartition> partitions;\n+        private final List<StopReplicaTopicState> topicStates;\n \n-        public Builder(short version, int controllerId, int controllerEpoch, long brokerEpoch, boolean deletePartitions,\n-                       Collection<TopicPartition> partitions) {\n+        public Builder(short version, int controllerId, int controllerEpoch, long brokerEpoch,\n+                       List<StopReplicaTopicState> topicStates) {\n             super(ApiKeys.STOP_REPLICA, version, controllerId, controllerEpoch, brokerEpoch);\n-            this.deletePartitions = deletePartitions;\n-            this.partitions = partitions;\n+            this.topicStates = topicStates;\n         }\n \n         public StopReplicaRequest build(short version) {\n             StopReplicaRequestData data = new StopReplicaRequestData()\n                 .setControllerId(controllerId)\n                 .setControllerEpoch(controllerEpoch)\n-                .setBrokerEpoch(brokerEpoch)\n-                .setDeletePartitions(deletePartitions);\n-\n-            if (version >= 1) {\n-                Map<String, List<Integer>> topicPartitionsMap = CollectionUtils.groupPartitionsByTopic(partitions);\n-                List<StopReplicaTopic> topics = topicPartitionsMap.entrySet().stream().map(entry ->\n-                    new StopReplicaTopic()\n-                        .setName(entry.getKey())\n-                        .setPartitionIndexes(entry.getValue())\n-                ).collect(Collectors.toList());\n+                .setBrokerEpoch(brokerEpoch);\n+\n+            if (version >= 3) {\n+                data.setTopicStates(topicStates);\n+            } else if (version >= 1) {\n+                data.setDeletePartitions(deletePartitions());\n+                List<StopReplicaTopicV1> topics = topicStates.stream().map(topic ->\n+                    new StopReplicaTopicV1()\n+                        .setName(topic.topicName())\n+                        .setPartitionIndexes(topic.partitionStates().stream()\n+                            .map(StopReplicaPartitionState::partitionIndex)\n+                            .collect(Collectors.toList())))\n+                    .collect(Collectors.toList());\n                 data.setTopics(topics);\n             } else {\n-                List<StopReplicaPartitionV0> requestPartitions = partitions.stream().map(tp ->\n-                    new StopReplicaPartitionV0()\n-                        .setTopicName(tp.topic())\n-                        .setPartitionIndex(tp.partition())\n-                ).collect(Collectors.toList());\n-                data.setUngroupedPartitions(requestPartitions);\n+                data.setDeletePartitions(deletePartitions());\n+                List<StopReplicaPartitionV0> partitions = topicStates.stream().flatMap(topic ->\n+                    topic.partitionStates().stream().map(partition ->\n+                        new StopReplicaPartitionV0()\n+                            .setTopicName(topic.topicName())\n+                            .setPartitionIndex(partition.partitionIndex())))\n+                    .collect(Collectors.toList());\n+                data.setUngroupedPartitions(partitions);\n             }\n \n             return new StopReplicaRequest(data, version);\n         }\n \n+        private boolean deletePartitions() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQyNjYyMw==", "bodyText": "It seems safe to pass through when defined.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r400426623", "createdAt": "2020-03-30T19:06:08Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -236,22 +236,22 @@ class KafkaApis(val requestChannel: RequestChannel,\n     if (isBrokerEpochStale(stopReplicaRequest.brokerEpoch)) {\n       // When the broker restarts very quickly, it is possible for this broker to receive request intended\n       // for its previous generation so the broker should skip the stale request.\n-      info(\"Received stop replica request with broker epoch \" +\n+      info(\"Received StopReplica request with broker epoch \" +\n         s\"${stopReplicaRequest.brokerEpoch} smaller than the current broker epoch ${controller.brokerEpoch}\")\n       sendResponseExemptThrottle(request, new StopReplicaResponse(new StopReplicaResponseData().setErrorCode(Errors.STALE_BROKER_EPOCH.code)))\n     } else {\n-      val (result, error) = replicaManager.stopReplicas(stopReplicaRequest)\n+      val (result, error) = replicaManager.stopReplicas(request.context.correlationId, stopReplicaRequest)\n       // Clear the coordinator caches in case we were the leader. In the case of a reassignment, we\n       // cannot rely on the LeaderAndIsr API for this since it is only sent to active replicas.\n-      result.foreach { case (topicPartition, error) =>\n-        if (error == Errors.NONE && stopReplicaRequest.deletePartitions) {\n-          if (topicPartition.topic == GROUP_METADATA_TOPIC_NAME) {\n-            groupCoordinator.onResignation(topicPartition.partition)\n-          } else if (topicPartition.topic == TRANSACTION_STATE_TOPIC_NAME) {\n-            // The StopReplica API does not pass through the leader epoch\n-            txnCoordinator.onResignation(topicPartition.partition, coordinatorEpoch = None)\n-          }\n-        }\n+      result.foreach {\n+        case (topicPartition, Left(true)) if topicPartition.topic == GROUP_METADATA_TOPIC_NAME =>\n+          groupCoordinator.onResignation(topicPartition.partition)\n+\n+        case (topicPartition, Left(true)) if topicPartition.topic == TRANSACTION_STATE_TOPIC_NAME =>\n+          // The StopReplica API does not pass through the leader epoch\n+          txnCoordinator.onResignation(topicPartition.partition, coordinatorEpoch = None)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI0MjgwNA=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQzMTgzNg==", "bodyText": "The return type is a bit awkward. As far as I can tell, the left side is just returning the deletion status, which is taken from the request. Was this an optimization in order to avoid another traversal of the request?", "url": "https://github.com/apache/kafka/pull/8257#discussion_r400431836", "createdAt": "2020-03-30T19:15:26Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -236,22 +236,22 @@ class KafkaApis(val requestChannel: RequestChannel,\n     if (isBrokerEpochStale(stopReplicaRequest.brokerEpoch)) {\n       // When the broker restarts very quickly, it is possible for this broker to receive request intended\n       // for its previous generation so the broker should skip the stale request.\n-      info(\"Received stop replica request with broker epoch \" +\n+      info(\"Received StopReplica request with broker epoch \" +\n         s\"${stopReplicaRequest.brokerEpoch} smaller than the current broker epoch ${controller.brokerEpoch}\")\n       sendResponseExemptThrottle(request, new StopReplicaResponse(new StopReplicaResponseData().setErrorCode(Errors.STALE_BROKER_EPOCH.code)))\n     } else {\n-      val (result, error) = replicaManager.stopReplicas(stopReplicaRequest)\n+      val (result, error) = replicaManager.stopReplicas(request.context.correlationId, stopReplicaRequest)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ0MzY0MA==", "bodyText": "I am not sure I followed your response to my previous question. My concern was actually the happy path when the partition exists locally. If we delete first before stopping replica fetchers, then would the fetcher thread handle that gracefully? By removing the fetchers first, we are guaranteed that we couldn't have a write in progress at the time of deletion.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r400443640", "createdAt": "2020-03-30T19:34:02Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -364,32 +358,107 @@ class ReplicaManager(val config: KafkaConfig,\n     delayedFetchPurgatory.checkAndComplete(topicPartitionOperationKey)\n   }\n \n-  def stopReplicas(stopReplicaRequest: StopReplicaRequest): (mutable.Map[TopicPartition, Errors], Errors) = {\n+  def stopReplicas(correlationId: Int, stopReplicaRequest: StopReplicaRequest): (mutable.Map[TopicPartition, Either[Boolean, Errors]], Errors) = {\n+    val controllerId = stopReplicaRequest.controllerId\n+    val requestPartitionStates = stopReplicaRequest.partitionStates.asScala\n+    stateChangeLogger.info(s\"Handling StopReplica request correlationId $correlationId from controller \" +\n+      s\"$controllerId for ${requestPartitionStates.size} partitions\")\n+    if (stateChangeLogger.isTraceEnabled)\n+      requestPartitionStates.foreach { case (topicPartition, partitionState) =>\n+        stateChangeLogger.trace(s\"Received StopReplica request $partitionState \" +\n+          s\"correlation id $correlationId from controller $controllerId \" +\n+          s\"epoch ${stopReplicaRequest.controllerEpoch} for partition $topicPartition\")\n+      }\n+\n     replicaStateChangeLock synchronized {\n-      val responseMap = new collection.mutable.HashMap[TopicPartition, Errors]\n-      if (stopReplicaRequest.controllerEpoch() < controllerEpoch) {\n-        stateChangeLogger.warn(\"Received stop replica request from an old controller epoch \" +\n-          s\"${stopReplicaRequest.controllerEpoch}. Latest known controller epoch is $controllerEpoch\")\n+      val responseMap = new collection.mutable.HashMap[TopicPartition, Either[Boolean, Errors]]\n+      if (stopReplicaRequest.controllerEpoch < controllerEpoch) {\n+        stateChangeLogger.warn(s\"Ignoring StopReplica request from \" +\n+          s\"controller $controllerId with correlation id $correlationId \" +\n+          s\"since its controller epoch ${stopReplicaRequest.controllerEpoch} is old. \" +\n+          s\"Latest known controller epoch is $controllerEpoch\")\n         (responseMap, Errors.STALE_CONTROLLER_EPOCH)\n       } else {\n-        val partitions = stopReplicaRequest.partitions.asScala.toSet\n+        val stoppedPartitions = mutable.Map.empty[TopicPartition, StopReplicaPartitionState]\n         controllerEpoch = stopReplicaRequest.controllerEpoch\n+\n+        requestPartitionStates.foreach { case (topicPartition, partitionState) =>\n+          val deletePartition = partitionState.deletePartition\n+\n+          getPartition(topicPartition) match {\n+            case HostedPartition.Offline =>\n+              stateChangeLogger.warn(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+                s\"controller $controllerId with correlation id $correlationId \" +\n+                s\"epoch $controllerEpoch for partition $topicPartition as the local replica for the \" +\n+                \"partition is in an offline log directory\")\n+              responseMap.put(topicPartition, Right(Errors.KAFKA_STORAGE_ERROR))\n+\n+            case HostedPartition.Online(partition) =>\n+              val currentLeaderEpoch = partition.getLeaderEpoch\n+              val requestLeaderEpoch = partitionState.leaderEpoch\n+              // When a topic is deleted, the leader epoch is not incremented. To circumvent this,\n+              // a sentinel value (EpochDuringDelete) overwriting any previous epoch is used.\n+              // When an older version of the StopReplica request which does not contain the leader\n+              // epoch, a sentinel value (NoEpoch) is used and bypass the epoch validation.\n+              if (requestLeaderEpoch == LeaderAndIsr.EpochDuringDelete ||\n+                  requestLeaderEpoch == LeaderAndIsr.NoEpoch ||\n+                  requestLeaderEpoch > currentLeaderEpoch) {\n+                stoppedPartitions += topicPartition -> partitionState\n+              } else if (requestLeaderEpoch < currentLeaderEpoch) {\n+                stateChangeLogger.warn(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+                  s\"controller $controllerId with correlation id $correlationId \" +\n+                  s\"epoch $controllerEpoch for partition $topicPartition since its associated \" +\n+                  s\"leader epoch $requestLeaderEpoch is smaller than the current \" +\n+                  s\"leader epoch $currentLeaderEpoch\")\n+                responseMap.put(topicPartition, Right(Errors.FENCED_LEADER_EPOCH))\n+              } else {\n+                stateChangeLogger.info(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+                  s\"controller $controllerId with correlation id $correlationId \" +\n+                  s\"epoch $controllerEpoch for partition $topicPartition since its associated \" +\n+                  s\"leader epoch $requestLeaderEpoch matches the current leader epoch\")\n+                responseMap.put(topicPartition, Right(Errors.FENCED_LEADER_EPOCH))\n+              }\n+\n+            case HostedPartition.None =>\n+              try {\n+                // Delete log and corresponding folders in case replica manager doesn't hold them anymore.\n+                // This could happen when topic is being deleted while broker is down and recovers.\n+                maybeCleanReplica(topicPartition, deletePartition)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 133}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "cdff56b9a8b65d52a109098ed56d548cd95b2da8", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/cdff56b9a8b65d52a109098ed56d548cd95b2da8", "committedDate": "2020-04-07T14:36:33Z", "message": "KAFKA-9539; Add leader epoch in StopReplicaRequest (KIP-570)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "cdff56b9a8b65d52a109098ed56d548cd95b2da8", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/cdff56b9a8b65d52a109098ed56d548cd95b2da8", "committedDate": "2020-04-07T14:36:33Z", "message": "KAFKA-9539; Add leader epoch in StopReplicaRequest (KIP-570)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxMjgxMDcw", "url": "https://github.com/apache/kafka/pull/8257#pullrequestreview-391281070", "createdAt": "2020-04-10T06:05:00Z", "commit": {"oid": "cdff56b9a8b65d52a109098ed56d548cd95b2da8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwNjowNTowMFrOGDx6FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwNjowNTowMFrOGDx6FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjYxNjU5Ng==", "bodyText": "AND not OR. could be replaced by >= 0 as well.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r406616596", "createdAt": "2020-04-10T06:05:00Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -236,20 +237,34 @@ class KafkaApis(val requestChannel: RequestChannel,\n     if (isBrokerEpochStale(stopReplicaRequest.brokerEpoch)) {\n       // When the broker restarts very quickly, it is possible for this broker to receive request intended\n       // for its previous generation so the broker should skip the stale request.\n-      info(\"Received stop replica request with broker epoch \" +\n+      info(\"Received StopReplica request with broker epoch \" +\n         s\"${stopReplicaRequest.brokerEpoch} smaller than the current broker epoch ${controller.brokerEpoch}\")\n-      sendResponseExemptThrottle(request, new StopReplicaResponse(new StopReplicaResponseData().setErrorCode(Errors.STALE_BROKER_EPOCH.code)))\n+      sendResponseExemptThrottle(request, new StopReplicaResponse(\n+        new StopReplicaResponseData().setErrorCode(Errors.STALE_BROKER_EPOCH.code)))\n     } else {\n-      val (result, error) = replicaManager.stopReplicas(stopReplicaRequest)\n+      val partitionStates = stopReplicaRequest.partitionStates().asScala\n+      val (result, error) = replicaManager.stopReplicas(\n+        request.context.correlationId,\n+        stopReplicaRequest.controllerId,\n+        stopReplicaRequest.controllerEpoch,\n+        stopReplicaRequest.brokerEpoch,\n+        partitionStates)\n       // Clear the coordinator caches in case we were the leader. In the case of a reassignment, we\n       // cannot rely on the LeaderAndIsr API for this since it is only sent to active replicas.\n       result.foreach { case (topicPartition, error) =>\n-        if (error == Errors.NONE && stopReplicaRequest.deletePartitions) {\n-          if (topicPartition.topic == GROUP_METADATA_TOPIC_NAME) {\n+        if (error == Errors.NONE) {\n+          if (topicPartition.topic == GROUP_METADATA_TOPIC_NAME\n+              && partitionStates(topicPartition).deletePartition) {\n             groupCoordinator.onResignation(topicPartition.partition)\n-          } else if (topicPartition.topic == TRANSACTION_STATE_TOPIC_NAME) {\n-            // The StopReplica API does not pass through the leader epoch\n-            txnCoordinator.onResignation(topicPartition.partition, coordinatorEpoch = None)\n+          } else if (topicPartition.topic == TRANSACTION_STATE_TOPIC_NAME\n+                     && partitionStates(topicPartition).deletePartition) {\n+            val partitionState = partitionStates(topicPartition)\n+            val leaderEpoch = if (partitionState.leaderEpoch != LeaderAndIsr.EpochDuringDelete ||", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cdff56b9a8b65d52a109098ed56d548cd95b2da8"}, "originalPosition": 42}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0edeeeb600dc1978d23f44e6a8630fa07aaaade3", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/0edeeeb600dc1978d23f44e6a8630fa07aaaade3", "committedDate": "2020-04-13T15:48:46Z", "message": "fixup"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNTQxMTY1", "url": "https://github.com/apache/kafka/pull/8257#pullrequestreview-392541165", "createdAt": "2020-04-14T01:20:08Z", "commit": {"oid": "0edeeeb600dc1978d23f44e6a8630fa07aaaade3"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMToyMDowOFrOGE6vYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMTo0MDozMFrOGE7Fng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwOTg5MA==", "bodyText": "The first part of this definitely makes sense, but what is the motivation for the second part? Why not use LeaderAndIsr.NoEpoch? Though I can't really think of what would cause this case to be hit.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r407809890", "createdAt": "2020-04-14T01:20:08Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -396,9 +395,23 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n   def addStopReplicaRequestForBrokers(brokerIds: Seq[Int],\n                                       topicPartition: TopicPartition,\n                                       deletePartition: Boolean): Unit = {\n+    // A sentinel (-2) is used as an epoch if the topic is queued for deletion or\n+    // does not have a leader yet. This sentinel overrides any existing epoch.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0edeeeb600dc1978d23f44e6a8630fa07aaaade3"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgxMDUzNw==", "bodyText": "No need to fix here, but do you know why we do this filtering?", "url": "https://github.com/apache/kafka/pull/8257#discussion_r407810537", "createdAt": "2020-04-14T01:22:29Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -396,9 +395,23 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n   def addStopReplicaRequestForBrokers(brokerIds: Seq[Int],\n                                       topicPartition: TopicPartition,\n                                       deletePartition: Boolean): Unit = {\n+    // A sentinel (-2) is used as an epoch if the topic is queued for deletion or\n+    // does not have a leader yet. This sentinel overrides any existing epoch.\n+    val leaderEpoch = if (controllerContext.isTopicQueuedUpForDeletion(topicPartition.topic)) {\n+      LeaderAndIsr.EpochDuringDelete\n+    } else {\n+      controllerContext.partitionLeadershipInfo.get(topicPartition)\n+        .map(_.leaderAndIsr.leaderEpoch)\n+        .getOrElse(LeaderAndIsr.EpochDuringDelete)\n+    }\n+\n     brokerIds.filter(_ >= 0).foreach { brokerId =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0edeeeb600dc1978d23f44e6a8630fa07aaaade3"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgxNDk0Nw==", "bodyText": "Could potentially use nonOfflinePartition(topicPartition).foreach", "url": "https://github.com/apache/kafka/pull/8257#discussion_r407814947", "createdAt": "2020-04-14T01:38:14Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -323,24 +324,17 @@ class ReplicaManager(val config: KafkaConfig,\n       brokerTopicStats.removeMetrics(topic)\n   }\n \n-  def stopReplica(topicPartition: TopicPartition, deletePartition: Boolean)  = {\n-    stateChangeLogger.trace(s\"Handling stop replica (delete=$deletePartition) for partition $topicPartition\")\n-\n+  def stopReplica(topicPartition: TopicPartition, deletePartition: Boolean): Unit  = {\n     if (deletePartition) {\n       getPartition(topicPartition) match {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0edeeeb600dc1978d23f44e6a8630fa07aaaade3"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgxNTU4Mg==", "bodyText": "Good call updating this.", "url": "https://github.com/apache/kafka/pull/8257#discussion_r407815582", "createdAt": "2020-04-14T01:40:30Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -364,32 +356,97 @@ class ReplicaManager(val config: KafkaConfig,\n     delayedFetchPurgatory.checkAndComplete(topicPartitionOperationKey)\n   }\n \n-  def stopReplicas(stopReplicaRequest: StopReplicaRequest): (mutable.Map[TopicPartition, Errors], Errors) = {\n+  def stopReplicas(correlationId: Int,\n+                   controllerId: Int,\n+                   controllerEpoch: Int,\n+                   brokerEpoch: Long,\n+                   partitionStates: Map[TopicPartition, StopReplicaPartitionState]\n+                  ): (mutable.Map[TopicPartition, Errors], Errors) = {\n+    stateChangeLogger.info(s\"Handling StopReplica request correlationId $correlationId from controller \" +\n+      s\"$controllerId for ${partitionStates.size} partitions\")\n+    if (stateChangeLogger.isTraceEnabled)\n+      partitionStates.foreach { case (topicPartition, partitionState) =>\n+        stateChangeLogger.trace(s\"Received StopReplica request $partitionState \" +\n+          s\"correlation id $correlationId from controller $controllerId \" +\n+          s\"epoch $controllerEpoch for partition $topicPartition\")\n+      }\n+\n     replicaStateChangeLock synchronized {\n       val responseMap = new collection.mutable.HashMap[TopicPartition, Errors]\n-      if (stopReplicaRequest.controllerEpoch() < controllerEpoch) {\n-        stateChangeLogger.warn(\"Received stop replica request from an old controller epoch \" +\n-          s\"${stopReplicaRequest.controllerEpoch}. Latest known controller epoch is $controllerEpoch\")\n+      if (controllerEpoch < this.controllerEpoch) {\n+        stateChangeLogger.warn(s\"Ignoring StopReplica request from \" +\n+          s\"controller $controllerId with correlation id $correlationId \" +\n+          s\"since its controller epoch $controllerEpoch is old. \" +\n+          s\"Latest known controller epoch is ${this.controllerEpoch}\")\n         (responseMap, Errors.STALE_CONTROLLER_EPOCH)\n       } else {\n-        val partitions = stopReplicaRequest.partitions.asScala.toSet\n-        controllerEpoch = stopReplicaRequest.controllerEpoch\n+        this.controllerEpoch = controllerEpoch", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0edeeeb600dc1978d23f44e6a8630fa07aaaade3"}, "originalPosition": 78}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "49360d6d46bf292c7b9a774be923073fd049c19d", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/49360d6d46bf292c7b9a774be923073fd049c19d", "committedDate": "2020-04-14T13:15:53Z", "message": "Address review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzMDI5MTU3", "url": "https://github.com/apache/kafka/pull/8257#pullrequestreview-393029157", "createdAt": "2020-04-14T15:14:00Z", "commit": {"oid": "49360d6d46bf292c7b9a774be923073fd049c19d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 182, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}