{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY5MzYzMDU0", "number": 9196, "title": "KAFKA-10402: Upgrade system tests to python3", "bodyText": "For now, Kafka system tests use python2 which is outdated and not supported.\nThis PR upgrades python to the third version.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-08-18T10:17:40Z", "url": "https://github.com/apache/kafka/pull/9196", "merged": true, "mergeCommit": {"oid": "4e65030e055104a7526e85b563a11890c61d6ddf"}, "closed": true, "closedAt": "2020-10-07T16:41:31Z", "author": {"login": "nizhikov"}, "timelineItems": {"totalCount": 37, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdBY-8dAFqTQ3MjkyMzQ1Mw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdQNT_7AH2gAyNDY5MzYzMDU0OjJlNDdlYzM3NzJhMzk5ODNjMTVlYTdhZTY5ODkxNWU3ODQyOTQ1NGI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyOTIzNDUz", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-472923453", "createdAt": "2020-08-22T12:40:01Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo0MDowMVrOHFE-hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMjo1Njo1M1rOHFFD8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjQ3MA==", "bodyText": "No need to explicit conversion to int (result is already int)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086470", "createdAt": "2020-08-22T12:40:01Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/benchmarks/core/benchmark_test.py", "diffHunk": "@@ -88,7 +88,7 @@ def test_producer_throughput(self, acks, topic, num_producers=1, message_size=DE\n         self.validate_versions(client_version, broker_version)\n         self.start_kafka(security_protocol, security_protocol, broker_version, tls_version)\n         # Always generate the same total amount of data\n-        nrecords = int(self.target_data_size / message_size)\n+        nrecords = int(self.target_data_size // message_size)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU2MQ==", "bodyText": "redundant conversion to iterator (.items() is already iterable)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086561", "createdAt": "2020-08-22T12:40:49Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -114,7 +114,7 @@ def metrics(self, host=None, client_id=None, name=None, group=None, tags=None):\n         Get any collected metrics that match the specified parameters, yielding each as a tuple of\n         (key, [<timestamp, value>, ...]) values.\n         \"\"\"\n-        for k, values in self._http_metrics.iteritems():\n+        for k, values in iter(self._http_metrics.items()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU4Mw==", "bodyText": "Same as above + tuple can be constructed from generator, no need to create list for that\nJust use tuple(raw_metric['tags'].items())", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086583", "createdAt": "2020-08-22T12:40:59Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -154,7 +154,7 @@ def do_POST(self):\n             name = raw_metric['name']\n             group = raw_metric['group']\n             # Convert to tuple of pairs because dicts & lists are unhashable\n-            tags = tuple([(k, v) for k, v in raw_metric['tags'].iteritems()]),\n+            tags = tuple([(k, v) for k, v in iter(raw_metric['tags'].items())]),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njc3NA==", "bodyText": "No need to create iterator from items(), join can accept generator easily, no need to convert it to list.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086774", "createdAt": "2020-08-22T12:43:11Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/performance/producer_performance.py", "diffHunk": "@@ -78,7 +78,7 @@ def start_cmd(self, node):\n             'bootstrap_servers': self.kafka.bootstrap_servers(self.security_config.security_protocol),\n             'client_id': self.client_id,\n             'kafka_run_class': self.path.script(\"kafka-run-class.sh\", node),\n-            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.iteritems()])\n+            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in iter(self.http_metrics_client_configs.items())])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg0MA==", "bodyText": "No need to create iterator from iterable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086840", "createdAt": "2020-08-22T12:44:17Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/security/security_config.py", "diffHunk": "@@ -362,7 +362,7 @@ def props(self, prefix=''):\n             return \"\"\n         if self.has_sasl and not self.static_jaas_conf and 'sasl.jaas.config' not in self.properties:\n             raise Exception(\"JAAS configuration property has not yet been initialized\")\n-        config_lines = (prefix + key + \"=\" + value for key, value in self.properties.iteritems())\n+        config_lines = (prefix + key + \"=\" + value for key, value in iter(self.properties.items()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg4Mg==", "bodyText": "No need to create iterator from iterable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086882", "createdAt": "2020-08-22T12:44:51Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -361,7 +361,7 @@ def clean_node(self, node):\n \n     def current_assignment(self):\n         with self.lock:\n-            return { handler.node: handler.current_assignment() for handler in self.event_handlers.itervalues() }\n+            return { handler.node: handler.current_assignment() for handler in iter(self.event_handlers.values()) }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkwNg==", "bodyText": "No need to create iterator from iterable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086906", "createdAt": "2020-08-22T12:45:05Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -372,7 +372,7 @@ def current_position(self, tp):\n \n     def owner(self, tp):\n         with self.lock:\n-            for handler in self.event_handlers.itervalues():\n+            for handler in iter(self.event_handlers.values()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkyNQ==", "bodyText": "Same as above.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086925", "createdAt": "2020-08-22T12:45:13Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk1MQ==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086951", "createdAt": "2020-08-22T12:45:21Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk2Nw==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086967", "createdAt": "2020-08-22T12:45:29Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk4OQ==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086989", "createdAt": "2020-08-22T12:45:40Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk5OQ==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086999", "createdAt": "2020-08-22T12:45:48Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Rebalancing]\n \n     def dead_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzMQ==", "bodyText": "Same as above", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087031", "createdAt": "2020-08-22T12:45:56Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Rebalancing]\n \n     def dead_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Dead]\n \n     def alive_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzOA==", "bodyText": "No need to create iterator from iterable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087038", "createdAt": "2020-08-22T12:46:20Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "diffHunk": "@@ -86,14 +88,14 @@ def invoke_compatibility_program(self, features):\n                \"--topic %s \" % (self.zk.path.script(\"kafka-run-class.sh\", node),\n                                self.kafka.bootstrap_servers(),\n                                len(self.kafka.nodes),\n-                               self.topics.keys()[0]))\n-        for k, v in features.iteritems():\n+                               [*self.topics.keys()][0]))\n+        for k, v in iter(features.items()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzE5MA==", "bodyText": "I suppose that next(iter(self.topics.keys())) is more readable, than this mix of brackets and stars", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087190", "createdAt": "2020-08-22T12:48:35Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "diffHunk": "@@ -86,14 +88,14 @@ def invoke_compatibility_program(self, features):\n                \"--topic %s \" % (self.zk.path.script(\"kafka-run-class.sh\", node),\n                                self.kafka.bootstrap_servers(),\n                                len(self.kafka.nodes),\n-                               self.topics.keys()[0]))\n-        for k, v in features.iteritems():\n+                               [*self.topics.keys()][0]))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzIxNg==", "bodyText": "No need to create iterator", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087216", "createdAt": "2020-08-22T12:48:59Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/client/quota_test.py", "diffHunk": "@@ -162,7 +162,7 @@ def test_quota(self, quota_type, override_quota=True, producer_num=1, consumer_n\n             jmx_attributes=['bytes-consumed-rate'], version=client_version)\n         consumer.run()\n \n-        for idx, messages in consumer.messages_consumed.iteritems():\n+        for idx, messages in iter(consumer.messages_consumed.items()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzQwNA==", "bodyText": "src_seqno_max = max(src_seqnos) if len(src_seqnos) else 0 is more readable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087404", "createdAt": "2020-08-22T12:50:53Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,14 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            if len(src_seqnos) == 0:\n+                src_seqno_max = 0\n+            else:\n+                src_seqno_max = max(src_seqnos)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzU1OQ==", "bodyText": "No need to create list and iterator, just\nsorted(seqno for seqno, count in src_seqno_counts.items() if count > 1)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087559", "createdAt": "2020-08-22T12:53:20Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,14 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            if len(src_seqnos) == 0:\n+                src_seqno_max = 0\n+            else:\n+                src_seqno_max = max(src_seqnos)\n             self.logger.debug(\"Max source seqno: %d\", src_seqno_max)\n             src_seqno_counts = Counter(src_seqnos)\n             missing_src_seqnos = sorted(set(range(src_seqno_max)).difference(set(src_seqnos)))\n-            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.iteritems() if count > 1])\n+            duplicate_src_seqnos = sorted([seqno for seqno,count in iter(src_seqno_counts.items()) if count > 1])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzY0Mw==", "bodyText": "No need to create iterator", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087643", "createdAt": "2020-08-22T12:54:23Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/end_to_end.py", "diffHunk": "@@ -87,7 +85,7 @@ def on_record_consumed(self, record, node):\n \n     def await_consumed_offsets(self, last_acked_offsets, timeout_sec):\n         def has_finished_consuming():\n-            for partition, offset in last_acked_offsets.iteritems():\n+            for partition, offset in iter(last_acked_offsets.items()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc0NA==", "bodyText": "list(self.topics.keys())[topic_index] is more readable", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087744", "createdAt": "2020-08-22T12:55:27Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "diffHunk": "@@ -119,7 +119,7 @@ def __init__(self, test_context):\n     def fail_broker_type(self, failure_mode, broker_type):\n         # Pick a random topic and bounce it's leader\n         topic_index = randint(0, len(self.topics.keys()) - 1)\n-        topic = self.topics.keys()[topic_index]\n+        topic = [*self.topics.keys()][topic_index]", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc3NA==", "bodyText": "No need to create iterator", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087774", "createdAt": "2020-08-22T12:55:42Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/verifiable_consumer_test.py", "diffHunk": "@@ -40,7 +40,7 @@ def _all_partitions(self, topic, num_partitions):\n \n     def _partitions(self, assignment):\n         partitions = []\n-        for parts in assignment.itervalues():\n+        for parts in iter(assignment.values()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzg1OA==", "bodyText": "If you start to refactor this class, may be refactor also call to super constructor? LooseVersion is now normal class (in python3). Just super().__init__(version_string)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087858", "createdAt": "2020-08-22T12:56:53Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyOTI0ODkx", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-472924891", "createdAt": "2020-08-22T13:06:04Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMzowNjowNFrOHFFGwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMzowNjowNFrOHFFGwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4ODU3Nw==", "bodyText": "You do not need all these functions above, if you call super method properly super()._cmp(other)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475088577", "createdAt": "2020-08-22T13:06:04Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):\n+        return self._cmp(other) == 0\n+\n+    def __lt__(self, other):\n+        return self._cmp(other) < 0\n+\n+    def __le__(self, other):\n+        return self._cmp(other) <= 0\n+\n+    def __gt__(self, other):\n+        return self._cmp(other) > 0\n+\n+    def __ge__(self, other):\n+        return self._cmp(other) >= 0\n+\n+    def _cmp(self, other):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyOTk0Njc4", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-472994678", "createdAt": "2020-08-23T09:15:13Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxNToxM1rOHFLlSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToxOTozNlrOHFLm8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NDY5Ng==", "bodyText": "You don't have to create list in order to use join, just\n ' '.join(\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.items())\nOr, even better, just\n ' '.join(\"%s=%s\" % kv for kv in self.http_metrics_client_configs.items())", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475194696", "createdAt": "2020-08-23T09:15:13Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/performance/producer_performance.py", "diffHunk": "@@ -78,7 +78,7 @@ def start_cmd(self, node):\n             'bootstrap_servers': self.kafka.bootstrap_servers(self.security_config.security_protocol),\n             'client_id': self.client_id,\n             'kafka_run_class': self.path.script(\"kafka-run-class.sh\", node),\n-            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.iteritems()])\n+            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.items()])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NDkwMw==", "bodyText": "You don't have to create list here, use generator as ctor args :\ntags = tuple(raw_metric['tags'].items())", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475194903", "createdAt": "2020-08-23T09:17:03Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -154,7 +154,7 @@ def do_POST(self):\n             name = raw_metric['name']\n             group = raw_metric['group']\n             # Convert to tuple of pairs because dicts & lists are unhashable\n-            tags = tuple([(k, v) for k, v in raw_metric['tags'].iteritems()]),\n+            tags = tuple([(k, v) for k, v in raw_metric['tags'].items()]),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTAwNw==", "bodyText": "Rewrite please it like this:\nsorted(seqno for seqno,count in sink_seqno_counts.items() if count > 1)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195007", "createdAt": "2020-08-23T09:18:12Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -440,11 +441,11 @@ def test_bounce(self, clean, connect_protocol):\n             sink_seqnos = [msg['seqno'] for msg in sink_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because\n             # clean bouncing should commit on rebalance.\n-            sink_seqno_max = max(sink_seqnos)\n+            sink_seqno_max = max(sink_seqnos) if len(sink_seqnos) else 0\n             self.logger.debug(\"Max sink seqno: %d\", sink_seqno_max)\n             sink_seqno_counts = Counter(sink_seqnos)\n             missing_sink_seqnos = sorted(set(range(sink_seqno_max)).difference(set(sink_seqnos)))\n-            duplicate_sink_seqnos = sorted([seqno for seqno,count in sink_seqno_counts.iteritems() if count > 1])\n+            duplicate_sink_seqnos = sorted([seqno for seqno,count in iter(sink_seqno_counts.items()) if count > 1])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTAyOQ==", "bodyText": "Rewrite please it like this:\nsorted(seqno for seqno,count in iter(sink_seqno_counts.items()) if count > 1)", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195029", "createdAt": "2020-08-23T09:18:28Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,11 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            src_seqno_max = max(src_seqnos) if len(src_seqnos) else 0\n             self.logger.debug(\"Max source seqno: %d\", src_seqno_max)\n             src_seqno_counts = Counter(src_seqnos)\n             missing_src_seqnos = sorted(set(range(src_seqno_max)).difference(set(src_seqnos)))\n-            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.iteritems() if count > 1])\n+            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.items() if count > 1])", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTEyMA==", "bodyText": "Yes, but I don't understand why not call super methods properly, this approach is outdated even for python 2.7", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195120", "createdAt": "2020-08-23T09:19:36Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):\n+        return self._cmp(other) == 0\n+\n+    def __lt__(self, other):\n+        return self._cmp(other) < 0\n+\n+    def __le__(self, other):\n+        return self._cmp(other) <= 0\n+\n+    def __gt__(self, other):\n+        return self._cmp(other) > 0\n+\n+    def __ge__(self, other):\n+        return self._cmp(other) >= 0\n+\n+    def _cmp(self, other):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4ODU3Nw=="}, "originalCommit": null, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyOTk1NDgz", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-472995483", "createdAt": "2020-08-23T09:27:35Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToyNzozNVrOHFLqGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOToyNzozNVrOHFLqGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTkyOQ==", "bodyText": "Please, remove list creation here also", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195929", "createdAt": "2020-08-23T09:27:35Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in self.event_handlers.values())\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in self.event_handlers.values())\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in self.event_handlers.values()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyOTk1NjMw", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-472995630", "createdAt": "2020-08-23T09:30:05Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOTozMDowNlrOHFLq-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QwOTozMDowNlrOHFLq-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NjE1Mg==", "bodyText": "You don't fix it, unfortunatelly", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475196152", "createdAt": "2020-08-23T09:30:06Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/tests/verifiable_consumer_test.py", "diffHunk": "@@ -40,7 +40,7 @@ def _all_partitions(self, topic, num_partitions):\n \n     def _partitions(self, assignment):\n         partitions = []\n-        for parts in assignment.itervalues():\n+        for parts in iter(assignment.values()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczMDE2OTIw", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-473016920", "createdAt": "2020-08-23T14:36:58Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QxNDozNjo1OVrOHFNkNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yM1QxNDozNjo1OVrOHFNkNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTIyNzE5MA==", "bodyText": "Oops, forgot new line...", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475227190", "createdAt": "2020-08-23T14:36:59Z", "author": {"login": "ivandasch"}, "path": "tests/kafkatest/utils/__init__.py", "diffHunk": "@@ -13,4 +13,4 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-from util import kafkatest_version, is_version, is_int, is_int_with_prefix, node_is_reachable, validate_delivery\n+from .util import kafkatest_version, is_version, is_int, is_int_with_prefix, node_is_reachable, validate_delivery", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgxNjA5MzE1", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-481609315", "createdAt": "2020-09-03T08:24:42Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwODoyNDo0MlrOHMbsoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwODo0MDoyM1rOHMcSAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5ODc1Mw==", "bodyText": "Add a comment explaining why the hold is necssary.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482798753", "createdAt": "2020-09-03T08:24:42Z", "author": {"login": "edenhill"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw==", "bodyText": "Should ducktape no longer be version pinned? (it probably needs to be to avoid future build breakages of old kafka branches).\nOr is this just during Python3-ification of ducktape itself?", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482799763", "createdAt": "2020-09-03T08:26:12Z", "author": {"login": "edenhill"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNjc2NA==", "bodyText": "nit: I believe % is a bit deprecated in favour of .format(..) or f\"This means .. {measured_rates}\" (for >=3.6).", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482806764", "createdAt": "2020-09-03T08:37:41Z", "author": {"login": "edenhill"}, "path": "tests/kafkatest/tests/core/network_degrade_test.py", "diffHunk": "@@ -129,10 +129,10 @@ def test_rate(self, task_name, device_name, latency_ms, rate_limit_kbit):\n         self.logger.info(\"Measured rates: %s\" % measured_rates)\n \n         # We expect to see measured rates within an order of magnitude of our target rate\n-        low_kbps = rate_limit_kbit / 10\n+        low_kbps = rate_limit_kbit // 10\n         high_kbps = rate_limit_kbit * 10\n         acceptable_rates = [r for r in measured_rates if low_kbps < r < high_kbps]\n \n         msg = \"Expected most of the measured rates to be within an order of magnitude of target %d.\" % rate_limit_kbit\n-        msg += \" This means `tc` did not limit the bandwidth as expected.\"\n+        msg += \" This means `tc` did not limit the bandwidth as expected. Measured rates %s\" % str(measured_rates)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNzI0Mw==", "bodyText": "Since this PR is about upgrading to Python3 it probably shouldn't modify test parameters.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482807243", "createdAt": "2020-09-03T08:38:35Z", "author": {"login": "edenhill"}, "path": "tests/kafkatest/tests/core/replica_scale_test.py", "diffHunk": "@@ -48,7 +46,7 @@ def teardown(self):\n         self.zk.stop()\n \n     @cluster(num_nodes=12)\n-    @parametrize(topic_count=500, partition_count=34, replication_factor=3)\n+    @parametrize(topic_count=100, partition_count=34, replication_factor=3)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwODMyMA==", "bodyText": "alternatively:\ntopic = random.choice(list(self.topics.keys()))", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482808320", "createdAt": "2020-09-03T08:40:23Z", "author": {"login": "edenhill"}, "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "diffHunk": "@@ -119,7 +119,7 @@ def __init__(self, test_context):\n     def fail_broker_type(self, failure_mode, broker_type):\n         # Pick a random topic and bounce it's leader\n         topic_index = randint(0, len(self.topics.keys()) - 1)\n-        topic = self.topics.keys()[topic_index]\n+        topic = list(self.topics.keys())[topic_index]", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyNDEzNTUw", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-482413550", "createdAt": "2020-09-04T07:14:50Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQwNzoxNDo1MFrOHNCX2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQwNzoxNDo1MFrOHNCX2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQzMjQwOA==", "bodyText": "Great!\nSuggest updating the title of this PR to include [DO NOT MERGE] until the ducktape version is updated.", "url": "https://github.com/apache/kafka/pull/9196#discussion_r483432408", "createdAt": "2020-09-04T07:14:50Z", "author": {"login": "edenhill"}, "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, "originalCommit": null, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyNDczODAx", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-482473801", "createdAt": "2020-09-04T08:46:53Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "931b2737701818da8e898aac00d03ba48489500e", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/931b2737701818da8e898aac00d03ba48489500e", "committedDate": "2020-09-23T21:29:16Z", "message": "KAFKA-10402: WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7271e4dc727d8ba778bb375a74ede6e9427832ce", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/7271e4dc727d8ba778bb375a74ede6e9427832ce", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: fixing imports."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f5ed7100f439a8e4a389cecb97e7aad0a2e0035", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/5f5ed7100f439a8e4a389cecb97e7aad0a2e0035", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: has_key -> in, iteritems -> iter(items) fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9973345959483f3ee9bceafb8d302f192e6e539f", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/9973345959483f3ee9bceafb8d302f192e6e539f", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: iteriterms -> iter(dict.items), itervalues -> iter(dict.values)."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9486c964b0454ac5488a7ca41e9afcbd98e6bd6d", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/9486c964b0454ac5488a7ca41e9afcbd98e6bd6d", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: basestring -> str"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71218d875780acf67ece492aed20a12bf109efdf", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/71218d875780acf67ece492aed20a12bf109efdf", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: syntax fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0b68c095be8f5604faa19a8084222d77a6071d6", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/f0b68c095be8f5604faa19a8084222d77a6071d6", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: reduce topic_count to run tests on small servers."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a814612a0e30513e70b48eb1a0e8cbe07eb03f93", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/a814612a0e30513e70b48eb1a0e8cbe07eb03f93", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: fix usage iterable as array."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "575818b55229196b2c874c97be0587e7f5d0fac1", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/575818b55229196b2c874c97be0587e7f5d0fac1", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: fix comparation of str(DEV_BRANCH)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a4ea97fc9fe5f88982ee00a17ffe4c7acff0525", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/8a4ea97fc9fe5f88982ee00a17ffe4c7acff0525", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: xrange -> range"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4522601f3450a163c33d91205af1ca7be881a4e2", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/4522601f3450a163c33d91205af1ca7be881a4e2", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: division operator + import http.server"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7c6833723960e26e2ec94d7430d37fc4d61d1c4", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/b7c6833723960e26e2ec94d7430d37fc4d61d1c4", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: division operator fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "887d4284819bb53f92442b09ea106857b6a6cdfa", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/887d4284819bb53f92442b09ea106857b6a6cdfa", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: various syntax fixes based on the tests results."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "975968a98ac1bd3efec429ea1fe1f74d68606b75", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/975968a98ac1bd3efec429ea1fe1f74d68606b75", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: final test fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9be51f9f9dedf920f272b0c6b8ef42ab373b16f", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/a9be51f9f9dedf920f272b0c6b8ef42ab373b16f", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: final test fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9614020d7b5fb0332fb4e3229bfe6e269454c079", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/9614020d7b5fb0332fb4e3229bfe6e269454c079", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: code review fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1d523efcefcf47ffd5d1f4b77833bc0f706e817", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/e1d523efcefcf47ffd5d1f4b77833bc0f706e817", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: code review fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "18e48af0a67f1b8a8a96455de5092583890e690d", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/18e48af0a67f1b8a8a96455de5092583890e690d", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: code review fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d706fc73d06b4edabd0979dcd2c3f1e75f5736b0", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/d706fc73d06b4edabd0979dcd2c3f1e75f5736b0", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: code review fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "14712e64299d700bfd19279cf0ddc878b8d17ab2", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/14712e64299d700bfd19279cf0ddc878b8d17ab2", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: code review fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4bb0f1d7568d56640915ecb49fe47de5e9550c0c", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/4bb0f1d7568d56640915ecb49fe47de5e9550c0c", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: code review fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c31fd72593cb93b0b5785c31bd973f6a12b5c04c", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/c31fd72593cb93b0b5785c31bd973f6a12b5c04c", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: code review fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "316dc95a0dc4ae6d49327a34ea31e2824726bbed", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/316dc95a0dc4ae6d49327a34ea31e2824726bbed", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: decreasing topic count to run tests on docker"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "316dc95a0dc4ae6d49327a34ea31e2824726bbed", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/316dc95a0dc4ae6d49327a34ea31e2824726bbed", "committedDate": "2020-09-23T21:30:25Z", "message": "KAFKA-10402: decreasing topic count to run tests on docker"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk3MzI5MDUz", "url": "https://github.com/apache/kafka/pull/9196#pullrequestreview-497329053", "createdAt": "2020-09-28T09:16:30Z", "commit": {"oid": "316dc95a0dc4ae6d49327a34ea31e2824726bbed"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2db3aa5fac9579ff595b66a29e83617c8c47d87b", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/2db3aa5fac9579ff595b66a29e83617c8c47d87b", "committedDate": "2020-10-07T13:26:05Z", "message": "Merge branch 'trunk' into KAFKA-10402"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e47ec3772a39983c15ea7ae698915e78429454b", "author": {"user": {"login": "nizhikov", "name": "Nikolay"}}, "url": "https://github.com/apache/kafka/commit/2e47ec3772a39983c15ea7ae698915e78429454b", "committedDate": "2020-10-07T13:50:38Z", "message": "KAFKA-10402: ducktape 0.8.0"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 782, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}