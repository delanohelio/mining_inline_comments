{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcxMTM3NjA1", "number": 8040, "title": "KAFKA-6607: Commit correct offsets for transactional input data", "bodyText": "Currently, Kafka Streams commits \"offset + 1\" that may lead to incorrect \"consumer lag\" if the input topic is transactional, because the committed offset does \"step on\" the commit marker, instead of \"skipping it\".\nWith this PR, we commit \"offsetOfNextRecord\" or consumer.position() to step over potential transactional markers to fix this issue.\nCall for review @guozhangwang @ableegoldman\nThis PR is against 2.5 branch on purpose to avoid conflict with the current Kafka Streams refactoring. After the refactoring is merged, we can port this PR to trunk.", "createdAt": "2020-02-05T01:16:19Z", "url": "https://github.com/apache/kafka/pull/8040", "merged": true, "mergeCommit": {"oid": "4912a8d262df4a3ebb26a0d28f36a4c19b439ff8"}, "closed": true, "closedAt": "2020-02-11T21:59:47Z", "author": {"login": "mjsax"}, "timelineItems": {"totalCount": 35, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcBLs4VgFqTM1MzQxMzAyMA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcDI5ovgH2gAyMzcxMTM3NjA1Ojk0NGZlOGVjMzcyMGE0M2Q4OTU2NjlmMzQwMTg0ZDAyNWM4ODA3MDg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDEzMDIw", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353413020", "createdAt": "2020-02-05T01:17:59Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToxNzo1OVrOFlo_gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToxNzo1OVrOFlo_gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMzI1MA==", "bodyText": "Some additional side cleanup", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375013250", "createdAt": "2020-02-05T01:17:59Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -58,15 +58,14 @@\n     private int totalBuffered;\n     private boolean allBuffered;\n \n-\n-    public static class RecordInfo {\n+    static class RecordInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDEzMTc0", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353413174", "createdAt": "2020-02-05T01:18:28Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToxODoyOFrOFlpAEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToxODoyOFrOFlpAEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMzM5NQ==", "bodyText": "This new method is add for the fix", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375013395", "createdAt": "2020-02-05T01:18:28Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -172,25 +178,35 @@ int addRawRecords(final TopicPartition partition, final Iterable<ConsumerRecord<\n         return newSize;\n     }\n \n-    public Set<TopicPartition> partitions() {\n+    Set<TopicPartition> partitions() {\n         return Collections.unmodifiableSet(partitionQueues.keySet());\n     }\n \n     /**\n      * Return the stream-time of this partition group defined as the largest timestamp seen across all partitions\n      */\n-    public long streamTime() {\n+    long streamTime() {\n         return streamTime;\n     }\n \n+    Long headRecordOffset(final TopicPartition partition) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDEzNDE4", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353413418", "createdAt": "2020-02-05T01:19:10Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToxOToxMFrOFlpBBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToxOToxMFrOFlpBBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMzYzOQ==", "bodyText": "To reuse this condition, we move it to out test utils class", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375013639", "createdAt": "2020-02-05T01:19:10Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -170,25 +168,11 @@ private void prepareConfigs() {\n     private static final long CLEANUP_CONSUMER_TIMEOUT = 2000L;\n     private static final int TIMEOUT_MULTIPLIER = 15;\n \n-    private class ConsumerGroupInactiveCondition implements TestCondition {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 31}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDEzNTI1", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353413525", "createdAt": "2020-02-05T01:19:31Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToxOTozMVrOFlpBXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToxOTozMVrOFlpBXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMzcyNA==", "bodyText": "new method create in test utils class to make is reusable", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375013724", "createdAt": "2020-02-05T01:19:31Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -170,25 +168,11 @@ private void prepareConfigs() {\n     private static final long CLEANUP_CONSUMER_TIMEOUT = 2000L;\n     private static final int TIMEOUT_MULTIPLIER = 15;\n \n-    private class ConsumerGroupInactiveCondition implements TestCondition {\n-        @Override\n-        public boolean conditionMet() {\n-            try {\n-                final ConsumerGroupDescription groupDescription = adminClient.describeConsumerGroups(Collections.singletonList(appID)).describedGroups().get(appID).get();\n-                return groupDescription.members().isEmpty();\n-            } catch (final ExecutionException | InterruptedException e) {\n-                return false;\n-            }\n-        }\n-    }\n-\n     void prepareTest() throws Exception {\n         prepareConfigs();\n         prepareEnvironment();\n \n-        // busy wait until cluster (ie, ConsumerGroupCoordinator) is available\n-        TestUtils.waitForCondition(new ConsumerGroupInactiveCondition(), TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT,\n-                \"Test consumer group \" + appID + \" still active even after waiting \" + (TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT) + \" ms.\");\n+        waitForEmptyConsumerGroup(adminClient, appID, TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE0MDk1", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353414095", "createdAt": "2020-02-05T01:21:10Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyMToxMFrOFlpDMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyMToxMFrOFlpDMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDE5NA==", "bodyText": "Need to set retries no a not-zero value for transactions...", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375014194", "createdAt": "2020-02-05T01:21:10Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java", "diffHunk": "@@ -176,12 +214,20 @@ private void runSimpleCopyTest(final int numberOfRestarts,\n                 startKafkaStreamsAndWaitForRunningState(streams, MAX_WAIT_TIME_MS);\n \n                 final List<KeyValue<Long, Long>> inputData = prepareData(i * 100, i * 100 + 10L, 0L, 1L);\n+                System.out.println(\"mjsax: \" + inputData.size());\n+\n+                final Properties producerConfigs = new Properties();\n+                if (inputTopicTransactional) {\n+                    producerConfigs.setProperty(ProducerConfig.TRANSACTIONAL_ID_CONFIG, applicationId + \"-input-producer\");\n+                    producerConfigs.setProperty(ProducerConfig.RETRIES_CONFIG, \"\" + Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 126}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE0Njgw", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353414680", "createdAt": "2020-02-05T01:23:08Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyMzowOFrOFlpFKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyMzowOFrOFlpFKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDY5OQ==", "bodyText": "The original method was too long and checkstyle failed -- we could also add a checkstyle exception... This was just a quick fix -- let me know what you think", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375014699", "createdAt": "2020-02-05T01:23:08Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/PartitionGroupTest.java", "diffHunk": "@@ -88,6 +91,14 @@ private static Sensor getValueSensor(final Metrics metrics, final MetricName met\n \n     @Test\n     public void testTimeTracking() {\n+        testFirstBatch();\n+        testSecondBatch();\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE0NzU1", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353414755", "createdAt": "2020-02-05T01:23:25Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyMzoyNVrOFlpFcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyMzoyNVrOFlpFcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDc2OQ==", "bodyText": "add verification for the \"head record offset\"", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375014769", "createdAt": "2020-02-05T01:23:25Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/PartitionGroupTest.java", "diffHunk": "@@ -109,12 +120,13 @@ public void testTimeTracking() {\n         // st: -1 since no records was being processed yet\n \n         verifyBuffered(6, 3, 3);\n+        assertEquals(1L, group.partitionTimestamp(partition1));\n+        assertEquals(2L, group.partitionTimestamp(partition2));\n+        assertEquals(1L, group.headRecordOffset(partition1).longValue());\n+        assertEquals(2L, group.headRecordOffset(partition2).longValue());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE0OTY1", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353414965", "createdAt": "2020-02-05T01:24:04Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNDowNFrOFlpGIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNDowNFrOFlpGIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDk0Nw==", "bodyText": "Improve some existing tests, and add couple of more that are missing.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375014947", "createdAt": "2020-02-05T01:24:04Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/PartitionGroupTest.java", "diffHunk": "@@ -305,16 +340,79 @@ public void shouldSetPartitionTimestampAndStreamTime() {\n     }\n \n     @Test\n-    public void shouldThrowNullpointerUponSetPartitionTimestampFailure() {\n-        assertThrows(errMessage, NullPointerException.class, () -> {\n-            group.setPartitionTime(randomPartition, 0L);\n-        });\n+    public void shouldThrowIllegalStateExceptionUponAddRecordsIfPartitionUnknown() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 152}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE1MDU1", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353415055", "createdAt": "2020-02-05T01:24:20Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNDoyMFrOFlpGcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNDoyMFrOFlpGcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNTAyNQ==", "bodyText": "Side cleanup", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375015025", "createdAt": "2020-02-05T01:24:20Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java", "diffHunk": "@@ -47,14 +48,18 @@\n import java.util.Collections;\n import java.util.List;\n \n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.instanceOf;\n+import static org.hamcrest.MatcherAssert.assertThat;\n import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertThrows;\n import static org.junit.Assert.assertTrue;\n \n public class RecordQueueTest {\n     private final Serializer<Integer> intSerializer = new IntegerSerializer();\n     private final Deserializer<Integer> intDeserializer = new IntegerDeserializer();\n     private final TimestampExtractor timestampExtractor = new MockTimestampExtractor();\n-    private final String[] topics = {\"topic\"};", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE1MTIw", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353415120", "createdAt": "2020-02-05T01:24:33Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNDozNFrOFlpGqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNDozNFrOFlpGqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNTA4MQ==", "bodyText": "add \"head record offset\" verification", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375015081", "createdAt": "2020-02-05T01:24:34Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java", "diffHunk": "@@ -98,10 +103,10 @@ public void after() {\n \n     @Test\n     public void testTimeTracking() {\n-\n         assertTrue(queue.isEmpty());\n         assertEquals(0, queue.size());\n         assertEquals(RecordQueue.UNKNOWN, queue.headRecordTimestamp());\n+        assertNull(queue.headRecordOffset());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 56}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE1MTkx", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353415191", "createdAt": "2020-02-05T01:24:48Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNDo0OVrOFlpG7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNDo0OVrOFlpG7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNTE0OQ==", "bodyText": "just some test improvments", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375015149", "createdAt": "2020-02-05T01:24:49Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java", "diffHunk": "@@ -245,13 +262,17 @@ public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() {\n         queue.addRawRecords(records);\n     }\n \n-    @Test(expected = StreamsException.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 141}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE1NDg0", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353415484", "createdAt": "2020-02-05T01:25:46Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNTo0NlrOFlpH3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNTo0NlrOFlpH3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNTM5MQ==", "bodyText": "Because we call consumer.position()  now, we need to fix the mock consumer setup in the TTD", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375015391", "createdAt": "2020-02-05T01:25:46Z", "author": {"login": "mjsax"}, "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java", "diffHunk": "@@ -333,22 +333,28 @@ public void onRestoreEnd(final TopicPartition topicPartition, final String store\n             offsetsByTopicPartition.put(tp, new AtomicLong());\n         }\n         consumer.assign(partitionsByTopic.values());\n+        final Map<TopicPartition, Long> startOffsets = new HashMap<>();\n+        for (final TopicPartition topicPartition : partitionsByTopic.values()) {\n+            startOffsets.put(topicPartition, 0L);\n+        }\n+        consumer.updateBeginningOffsets(startOffsets);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE1NzI4", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353415728", "createdAt": "2020-02-05T01:26:37Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNjozN1rOFlpItw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNjozN1rOFlpItw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNTYwNw==", "bodyText": "We cannot share the consumer any longer, because the global task calls unassign() that nukes our setup from above.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375015607", "createdAt": "2020-02-05T01:26:37Z", "author": {"login": "mjsax"}, "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java", "diffHunk": "@@ -333,22 +333,28 @@ public void onRestoreEnd(final TopicPartition topicPartition, final String store\n             offsetsByTopicPartition.put(tp, new AtomicLong());\n         }\n         consumer.assign(partitionsByTopic.values());\n+        final Map<TopicPartition, Long> startOffsets = new HashMap<>();\n+        for (final TopicPartition topicPartition : partitionsByTopic.values()) {\n+            startOffsets.put(topicPartition, 0L);\n+        }\n+        consumer.updateBeginningOffsets(startOffsets);\n \n         if (globalTopology != null) {\n+            final MockConsumer<byte[], byte[]> globalConsumer = new MockConsumer<>(OffsetResetStrategy.NONE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDE1ODk2", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-353415896", "createdAt": "2020-02-05T01:27:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNzoxNVrOFlpJUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMToyNzoxNVrOFlpJUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNTc2MA==", "bodyText": "This was actually detected by the improved tests... Minor side fix.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375015760", "createdAt": "2020-02-05T01:27:15Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -204,14 +220,15 @@ boolean allPartitionsBuffered() {\n         return allBuffered;\n     }\n \n-    public void close() {\n+    void close() {\n         clear();\n         partitionQueues.clear();\n     }\n \n-    public void clear() {\n+    void clear() {\n         nonEmptyQueuesByTime.clear();\n         streamTime = RecordQueue.UNKNOWN;\n+        totalBuffered = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 110}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU0MTI5NjEy", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-354129612", "createdAt": "2020-02-06T00:14:47Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQwMDoxNDo0N1rOFmLlHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQwMDoyNzozOVrOFmLygQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU3OTkzNA==", "bodyText": "We need to consider handling two exceptions that consumer.position may throw: KafkaException -> should be a fatal one; TimeoutException -> in this case we cannot commit, probably have to treat as fatal..", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375579934", "createdAt": "2020-02-06T00:14:47Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -496,9 +496,15 @@ void commit(final boolean startNewTransaction, final Map<TopicPartition, Long> p\n         }\n \n         final Map<TopicPartition, OffsetAndMetadata> consumedOffsetsAndMetadata = new HashMap<>(consumedOffsets.size());\n+\n         for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n             final TopicPartition partition = entry.getKey();\n-            final long offset = entry.getValue() + 1;\n+            Long offset = partitionGroup.headRecordOffset(partition);\n+            if (offset == null) {\n+                // this call should never block, because we know that we did process data for this partition\n+                // and thus the consumer should have a valid local position that it can return immediately\n+                offset = consumer.position(partition);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU4MTA5NQ==", "bodyText": "The default value for retries are Integer.MAX_VALUE anyways right?", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375581095", "createdAt": "2020-02-06T00:19:07Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java", "diffHunk": "@@ -176,12 +214,20 @@ private void runSimpleCopyTest(final int numberOfRestarts,\n                 startKafkaStreamsAndWaitForRunningState(streams, MAX_WAIT_TIME_MS);\n \n                 final List<KeyValue<Long, Long>> inputData = prepareData(i * 100, i * 100 + 10L, 0L, 1L);\n+                System.out.println(\"mjsax: \" + inputData.size());\n+\n+                final Properties producerConfigs = new Properties();\n+                if (inputTopicTransactional) {\n+                    producerConfigs.setProperty(ProducerConfig.TRANSACTIONAL_ID_CONFIG, applicationId + \"-input-producer\");\n+                    producerConfigs.setProperty(ProducerConfig.RETRIES_CONFIG, \"\" + Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDE5NA=="}, "originalCommit": null, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU4MTI0Nw==", "bodyText": "nit: unkonwn-partition.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375581247", "createdAt": "2020-02-06T00:19:44Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/PartitionGroupTest.java", "diffHunk": "@@ -39,16 +39,19 @@\n \n import static org.apache.kafka.common.utils.Utils.mkEntry;\n import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.IsEqual.equalTo;\n import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNull;\n import static org.junit.Assert.assertThrows;\n \n public class PartitionGroupTest {\n     private final LogContext logContext = new LogContext();\n     private final Serializer<Integer> intSerializer = new IntegerSerializer();\n     private final Deserializer<Integer> intDeserializer = new IntegerDeserializer();\n     private final TimestampExtractor timestampExtractor = new MockTimestampExtractor();\n-    private final TopicPartition randomPartition = new TopicPartition(\"random-partition\", 0);\n-    private final String errMessage = \"Partition \" + randomPartition + \" not found.\";\n+    private final TopicPartition unknownPartition = new TopicPartition(\"unknonw-partition\", 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU4MTU1Nw==", "bodyText": "Sounds good to me -- better not add more checkstyle exceptions :)", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375581557", "createdAt": "2020-02-06T00:20:51Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/PartitionGroupTest.java", "diffHunk": "@@ -88,6 +91,14 @@ private static Sensor getValueSensor(final Metrics metrics, final MetricName met\n \n     @Test\n     public void testTimeTracking() {\n+        testFirstBatch();\n+        testSecondBatch();\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDY5OQ=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU4MzM2MQ==", "bodyText": "Not clear why? In MockConsumer we only do the following:\npublic synchronized void unsubscribe() {\n        ensureNotClosed();\n        committed.clear();\n        subscriptions.unsubscribe();\n    }\n\nAnd the beginningOffsets map are not nuked.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r375583361", "createdAt": "2020-02-06T00:27:39Z", "author": {"login": "guozhangwang"}, "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java", "diffHunk": "@@ -333,22 +333,28 @@ public void onRestoreEnd(final TopicPartition topicPartition, final String store\n             offsetsByTopicPartition.put(tp, new AtomicLong());\n         }\n         consumer.assign(partitionsByTopic.values());\n+        final Map<TopicPartition, Long> startOffsets = new HashMap<>();\n+        for (final TopicPartition topicPartition : partitionsByTopic.values()) {\n+            startOffsets.put(topicPartition, 0L);\n+        }\n+        consumer.updateBeginningOffsets(startOffsets);\n \n         if (globalTopology != null) {\n+            final MockConsumer<byte[], byte[]> globalConsumer = new MockConsumer<>(OffsetResetStrategy.NONE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNTYwNw=="}, "originalCommit": null, "originalPosition": 27}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTI2NTYx", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-355526561", "createdAt": "2020-02-08T03:21:23Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyMToyM1rOFnO6eQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyMToyM1rOFnO6eQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4MzEyOQ==", "bodyText": "Even if records might not be empty, we need to filter out the dummy records we added to indicate tx-markers", "url": "https://github.com/apache/kafka/pull/8040#discussion_r376683129", "createdAt": "2020-02-08T03:21:23Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -636,6 +636,8 @@ private ListOffsetResult fetchOffsetsByTimes(Map<TopicPartition, Long> timestamp\n                     List<ConsumerRecord<K, V>> records = fetchRecords(nextInLineFetch, recordsRemaining);\n \n                     if (!records.isEmpty()) {\n+                        records = records.stream().filter(r -> !(r instanceof NoConsumerRecord)).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTI2NTk3", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-355526597", "createdAt": "2020-02-08T03:21:56Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyMTo1N1rOFnO6nA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyMTo1N1rOFnO6nA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4MzE2NA==", "bodyText": "We add a dummy record is we stepped over an tx-marker", "url": "https://github.com/apache/kafka/pull/8040#discussion_r376683164", "createdAt": "2020-02-08T03:21:57Z", "author": {"login": "mjsax"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -1539,10 +1543,14 @@ private Record nextFetchedRecord() {\n                     }\n                     if (lastRecord == null)\n                         break;\n-                    records.add(parseRecord(partition, currentBatch, lastRecord));\n-                    recordsRead++;\n-                    bytesRead += lastRecord.sizeInBytes();\n-                    nextFetchOffset = lastRecord.offset() + 1;\n+                    if (lastRecord instanceof NoRecord) {\n+                        records.add(new NoConsumerRecord<>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTI2NzY4", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-355526768", "createdAt": "2020-02-08T03:25:37Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyNTozN1rOFnO7Xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyNTozN1rOFnO7Xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4MzM1OQ==", "bodyText": "Instead of nothing, we return an empty list if we step over a tx-marker. After a second fetchRecords() we return nothing.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r376683359", "createdAt": "2020-02-08T03:25:37Z", "author": {"login": "mjsax"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -2602,6 +2602,9 @@ public void testSkippingAbortedTransactions() {\n         assertTrue(fetcher.hasCompletedFetches());\n \n         Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n+        assertTrue(fetchedRecords.get(tp0).isEmpty());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTI2Nzg0", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-355526784", "createdAt": "2020-02-08T03:26:01Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyNjowMlrOFnO7gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyNjowMlrOFnO7gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4MzM5NA==", "bodyText": "We know pass in the current consumerPosition to track it correctly.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r376683394", "createdAt": "2020-02-08T03:26:02Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -149,11 +151,17 @@ StampedRecord nextRecord(final RecordInfo info) {\n      * @param rawRecords  the raw records\n      * @return the queue size for the partition\n      */\n-    int addRawRecords(final TopicPartition partition, final Iterable<ConsumerRecord<byte[], byte[]>> rawRecords) {\n+    int addRawRecords(final TopicPartition partition,\n+                      final Iterable<ConsumerRecord<byte[], byte[]>> rawRecords,\n+                      final long consumerPosition) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTI2ODAz", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-355526803", "createdAt": "2020-02-08T03:26:29Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyNjoyOVrOFnO7mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyNjoyOVrOFnO7mQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4MzQxNw==", "bodyText": "We track the consumer position expliclity now", "url": "https://github.com/apache/kafka/pull/8040#discussion_r376683417", "createdAt": "2020-02-08T03:26:29Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordQueue.java", "diffHunk": "@@ -48,6 +48,7 @@\n \n     private StampedRecord headRecord = null;\n     private long partitionTime = RecordQueue.UNKNOWN;\n+    private long consumerPosition = -1L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTI2ODMw", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-355526830", "createdAt": "2020-02-08T03:27:08Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyNzowOFrOFnO7vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzoyNzowOFrOFnO7vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4MzQ1NA==", "bodyText": "This could happen if the buffer is empty and if the consumer only stepped over a commit marker passing in empty list of records.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r376683454", "createdAt": "2020-02-08T03:27:08Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordQueue.java", "diffHunk": "@@ -104,10 +105,27 @@ public TopicPartition partition() {\n      * @param rawRecords the raw records\n      * @return the size of this queue\n      */\n-    int addRawRecords(final Iterable<ConsumerRecord<byte[], byte[]>> rawRecords) {\n+    int addRawRecords(final Iterable<ConsumerRecord<byte[], byte[]>> rawRecords,\n+                      final long consumerPosition) {\n         for (final ConsumerRecord<byte[], byte[]> rawRecord : rawRecords) {\n             fifoQueue.addLast(rawRecord);\n         }\n+        if (consumerPosition <= this.consumerPosition) {\n+            throw new IllegalArgumentException(String.format(\n+                \"Consumer position must go forward; current %d, new %d\",\n+                this.consumerPosition,\n+                consumerPosition));\n+        }\n+        if (!fifoQueue.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTI2OTUy", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-355526952", "createdAt": "2020-02-08T03:30:01Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzozMDowMVrOFnO8Pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzozMDowMVrOFnO8Pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4MzU4Mg==", "bodyText": "Previously, we clear the partitionGroup within closeTopology() that we call above -- however, because of the consumer position tracking, we need to delay it after the commit.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r376683582", "createdAt": "2020-02-08T03:30:01Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -621,6 +622,7 @@ void suspend(final boolean clean,\n             try {\n                 commit(false, partitionTimes);\n             } finally {\n+                partitionGroup.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTI2OTg0", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-355526984", "createdAt": "2020-02-08T03:30:42Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzozMDo0MlrOFnO8Zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzozMDo0MlrOFnO8Zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4MzYyMg==", "bodyText": "We add the current consumer position when we add records to the queue now.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r376683622", "createdAt": "2020-02-08T03:30:42Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -929,7 +930,21 @@ private void addRecordsToTasks(final ConsumerRecords<byte[], byte[]> records) {\n                 throw new TaskMigratedException(task);\n             }\n \n-            task.addRecords(partition, records.records(partition));\n+            final long consumerPosition;\n+            try {\n+                consumerPosition = consumer.position(partition);\n+            } catch (final TimeoutException error) {\n+                // the `consumer.position()` call should never block, because we know that we did process data\n+                // for the requested partition and thus the consumer should have a valid local position\n+                // that it can return immediately\n+\n+                // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                throw new IllegalStateException(error);\n+            } catch (final KafkaException fatal) {\n+                throw new StreamsException(fatal);\n+            }\n+\n+            task.addRecords(partition, records.records(partition), consumerPosition);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTI3MDA0", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-355527004", "createdAt": "2020-02-08T03:31:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzozMToxNlrOFnO8iw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwMzozMToxNlrOFnO8iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4MzY1OQ==", "bodyText": "I improve this test a little bit, adding more conditions.", "url": "https://github.com/apache/kafka/pull/8040#discussion_r376683659", "createdAt": "2020-02-08T03:31:16Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java", "diffHunk": "@@ -116,38 +127,66 @@ public void createTopics() throws Exception {\n \n     @Test\n     public void shouldBeAbleToRunWithEosEnabled() throws Exception {\n-        runSimpleCopyTest(1, SINGLE_PARTITION_INPUT_TOPIC, null, SINGLE_PARTITION_OUTPUT_TOPIC);\n+        runSimpleCopyTest(1, SINGLE_PARTITION_INPUT_TOPIC, null, SINGLE_PARTITION_OUTPUT_TOPIC, false);\n+    }\n+\n+    @Test\n+    public void shouldCommitCorrectOffsetIfInputTopicIsTransactional() throws Exception {\n+        runSimpleCopyTest(1, SINGLE_PARTITION_INPUT_TOPIC, null, SINGLE_PARTITION_OUTPUT_TOPIC, true);\n+\n+        try (final Admin adminClient = Admin.create(mkMap(mkEntry(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers())));\n+            final Consumer<byte[], byte[]> consumer = new KafkaConsumer<>(mkMap(\n+                mkEntry(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                mkEntry(ConsumerConfig.GROUP_ID_CONFIG, applicationId),\n+                mkEntry(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class),\n+                mkEntry(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class)))) {\n+\n+            waitForEmptyConsumerGroup(adminClient, applicationId, 5 * MAX_POLL_INTERVAL_MS);\n+\n+            final TopicPartition topicPartition = new TopicPartition(SINGLE_PARTITION_INPUT_TOPIC, 0);\n+            final Collection<TopicPartition> topicPartitions = Collections.singleton(topicPartition);\n+\n+            final long committedOffset = adminClient.listConsumerGroupOffsets(applicationId).partitionsToOffsetAndMetadata().get().get(topicPartition).offset();\n+\n+            consumer.assign(topicPartitions);\n+            final long consumerPosition = consumer.position(topicPartition);\n+            final long endOffset = consumer.endOffsets(topicPartitions).get(topicPartition);\n+\n+            assertThat(committedOffset, equalTo(consumerPosition));\n+            assertThat(committedOffset, equalTo(endOffset));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 75}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a564d863a6fab1f46f84746e458b98bb3c17208", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/8a564d863a6fab1f46f84746e458b98bb3c17208", "committedDate": "2020-02-11T01:09:44Z", "message": "KAFKA-6607: Commit correct offsets for transactional input data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d73faa32e31ca49c6bd13953d4621975db40d146", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/d73faa32e31ca49c6bd13953d4621975db40d146", "committedDate": "2020-02-11T01:09:44Z", "message": "Remove debug stuff"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96f63c37ec0135d1c579c36a1c4200fe56d3ea07", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/96f63c37ec0135d1c579c36a1c4200fe56d3ea07", "committedDate": "2020-02-11T01:09:44Z", "message": "Github comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be4557192c09d5b2473a49cfb8c5707e71999da7", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/be4557192c09d5b2473a49cfb8c5707e71999da7", "committedDate": "2020-02-11T01:09:44Z", "message": "Fix test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f3c62b60fc1a4a73a3770838ebbc83dcafe0a8d", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/7f3c62b60fc1a4a73a3770838ebbc83dcafe0a8d", "committedDate": "2020-02-11T01:09:44Z", "message": "Revert consumer change and fix StreamThread to not drop records"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "7f3c62b60fc1a4a73a3770838ebbc83dcafe0a8d", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/7f3c62b60fc1a4a73a3770838ebbc83dcafe0a8d", "committedDate": "2020-02-11T01:09:44Z", "message": "Revert consumer change and fix StreamThread to not drop records"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU2MzkzNTQw", "url": "https://github.com/apache/kafka/pull/8040#pullrequestreview-356393540", "createdAt": "2020-02-11T02:41:54Z", "commit": {"oid": "7f3c62b60fc1a4a73a3770838ebbc83dcafe0a8d"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQwMjo0MTo1NFrOFn8M9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQwMjo0MTo1NFrOFn8M9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQyNTE0Mw==", "bodyText": "maybe we can also log this as INFO for debugging purposes?", "url": "https://github.com/apache/kafka/pull/8040#discussion_r377425143", "createdAt": "2020-02-11T02:41:54Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -917,6 +917,13 @@ private void addRecordsToTasks(final ConsumerRecords<byte[], byte[]> records) {\n             final StreamTask task = taskManager.activeTask(partition);\n \n             if (task == null) {\n+                if (!isRunning()) {\n+                    // if we are in PENDING_SHUTDOWN and don't find the task it implies that it was a newly assigned\n+                    // task that we just skipped to create;\n+                    // hence, we just skip adding the corresponding records\n+                    continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f3c62b60fc1a4a73a3770838ebbc83dcafe0a8d"}, "originalPosition": 36}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "944fe8ec3720a43d895669f340184d025c880708", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/944fe8ec3720a43d895669f340184d025c880708", "committedDate": "2020-02-11T03:10:03Z", "message": "Github comment"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1735, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}