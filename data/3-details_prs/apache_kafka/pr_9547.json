{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE0NTc3MzM3", "number": 9547, "title": "KAFKA-9630; Replace OffsetsForLeaderEpoch request/response with automated protocol", "bodyText": "This PR migrates the OffsetsForLeaderEpoch request/response to the automated protocol. It also refactors the OffsetsForLeaderEpochClient to use directly the internal structs generated by the automated protocol. It relies on the existing tests.\nIt seems that we could also refactor the broker (api layer, fetcher) to directly use the internal structs of the generated protocol but, as it is more involved, I propose to address it in a separate PR.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-11-03T08:45:39Z", "url": "https://github.com/apache/kafka/pull/9547", "merged": true, "mergeCommit": {"oid": "51c833e7959bd6ab7fbb043f76933456b40ecae4"}, "closed": true, "closedAt": "2020-11-19T10:41:50Z", "author": {"login": "dajac"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdZKfMiAFqTUyMzE4ODE2NA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdd-D-tABqjQwMTQ0NTM1MTM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIzMTg4MTY0", "url": "https://github.com/apache/kafka/pull/9547#pullrequestreview-523188164", "createdAt": "2020-11-04T09:38:27Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwOTozODoyN1rOHtQHbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwOTozODoyN1rOHtQHbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzIxMjAxMg==", "bodyText": "Previous \"name\" is topic (https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/protocol/CommonFields.java#L25) and the \"name\" in auto-generated protocol is name. Does it break the compatibility? For example, a cluster mixed by auto-generated protocol and stale protocol.", "url": "https://github.com/apache/kafka/pull/9547#discussion_r517212012", "createdAt": "2020-11-04T09:38:27Z", "author": {"login": "chia7712"}, "path": "clients/src/main/resources/common/message/OffsetForLeaderEpochRequest.json", "diffHunk": "@@ -32,13 +32,13 @@\n     { \"name\": \"Topics\", \"type\": \"[]OffsetForLeaderTopic\", \"versions\": \"0+\",\n       \"about\": \"Each topic to get offsets for.\", \"fields\": [\n       { \"name\": \"Name\", \"type\": \"string\", \"versions\": \"0+\", \"entityType\": \"topicName\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 3}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyNjQ5MDk0", "url": "https://github.com/apache/kafka/pull/9547#pullrequestreview-532649094", "createdAt": "2020-11-17T18:03:55Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODowMzo1NVrOH1CUww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODoxMDo1M1rOH1CmnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NDY1OQ==", "bodyText": "Wonder if it might be simpler to initialize partitionsToRetry from the request key set.", "url": "https://github.com/apache/kafka/pull/9547#discussion_r525374659", "createdAt": "2020-11-17T18:03:55Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/OffsetsForLeaderEpochClient.java", "diffHunk": "@@ -61,67 +77,76 @@ protected OffsetForEpochResult handleResponse(\n             Map<TopicPartition, SubscriptionState.FetchPosition> requestData,\n             OffsetsForLeaderEpochResponse response) {\n \n+        Set<TopicPartition> missingPartitions = new HashSet<>(requestData.keySet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTIyOQ==", "bodyText": "We have similar logic in OffsetsForLeaderEpochClient.prepareRequest. Wonder if we should push it to the Builder?", "url": "https://github.com/apache/kafka/pull/9547#discussion_r525379229", "createdAt": "2020-11-17T18:10:53Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetsForLeaderEpochRequest.java", "diffHunk": "@@ -51,169 +47,120 @@\n      */\n     public static final int DEBUGGING_REPLICA_ID = -2;\n \n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"An array of topics to get epochs for\");\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"An array of partitions to get epochs for\");\n-\n-    private static final Field.Int32 LEADER_EPOCH = new Field.Int32(\"leader_epoch\",\n-            \"The epoch to lookup an offset for.\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            LEADER_EPOCH);\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V0 = new Schema(\n-            TOPICS_V0);\n-\n-    // V1 request is the same as v0. Per-partition leader epoch has been added to response\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V1 = OFFSET_FOR_LEADER_EPOCH_REQUEST_V0;\n-\n-    // V2 adds the current leader epoch to support fencing and the addition of the throttle time in the response\n-    private static final Field PARTITIONS_V2 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            CURRENT_LEADER_EPOCH,\n-            LEADER_EPOCH);\n-    private static final Field TOPICS_V2 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V2);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V2 = new Schema(\n-            TOPICS_V2);\n-\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V3 = new Schema(\n-            REPLICA_ID,\n-            TOPICS_V2);\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{OFFSET_FOR_LEADER_EPOCH_REQUEST_V0, OFFSET_FOR_LEADER_EPOCH_REQUEST_V1,\n-            OFFSET_FOR_LEADER_EPOCH_REQUEST_V2, OFFSET_FOR_LEADER_EPOCH_REQUEST_V3};\n-    }\n-\n-    private final Map<TopicPartition, PartitionData> epochsByPartition;\n-\n-    private final int replicaId;\n-\n-    public Map<TopicPartition, PartitionData> epochsByTopicPartition() {\n-        return epochsByPartition;\n-    }\n-\n-    public int replicaId() {\n-        return replicaId;\n-    }\n+    private final OffsetForLeaderEpochRequestData data;\n \n     public static class Builder extends AbstractRequest.Builder<OffsetsForLeaderEpochRequest> {\n-        private final Map<TopicPartition, PartitionData> epochsByPartition;\n-        private final int replicaId;\n+        private final OffsetForLeaderEpochRequestData data;\n \n-        Builder(short oldestAllowedVersion, short latestAllowedVersion, Map<TopicPartition, PartitionData> epochsByPartition, int replicaId) {\n+        Builder(short oldestAllowedVersion, short latestAllowedVersion, OffsetForLeaderEpochRequestData data) {\n             super(ApiKeys.OFFSET_FOR_LEADER_EPOCH, oldestAllowedVersion, latestAllowedVersion);\n-            this.epochsByPartition = epochsByPartition;\n-            this.replicaId = replicaId;\n+            this.data = data;\n         }\n \n-        public static Builder forConsumer(Map<TopicPartition, PartitionData> epochsByPartition) {\n+        public static Builder forConsumer(OffsetForLeaderTopicCollection epochsByPartition) {\n             // Old versions of this API require CLUSTER permission which is not typically granted\n             // to clients. Beginning with version 3, the broker requires only TOPIC Describe\n             // permission for the topic of each requested partition. In order to ensure client\n             // compatibility, we only send this request when we can guarantee the relaxed permissions.\n-            return new Builder((short) 3, ApiKeys.OFFSET_FOR_LEADER_EPOCH.latestVersion(),\n-                    epochsByPartition, CONSUMER_REPLICA_ID);\n+            OffsetForLeaderEpochRequestData data = new OffsetForLeaderEpochRequestData();\n+            data.setReplicaId(CONSUMER_REPLICA_ID);\n+            data.setTopics(epochsByPartition);\n+            return new Builder((short) 3, ApiKeys.OFFSET_FOR_LEADER_EPOCH.latestVersion(), data);\n         }\n \n         public static Builder forFollower(short version, Map<TopicPartition, PartitionData> epochsByPartition, int replicaId) {\n-            return new Builder(version, version, epochsByPartition, replicaId);\n+            OffsetForLeaderEpochRequestData data = new OffsetForLeaderEpochRequestData();\n+            data.setReplicaId(replicaId);\n+\n+            epochsByPartition.forEach((partitionKey, partitionValue) -> {\n+                OffsetForLeaderTopic topic = data.topics().find(partitionKey.topic());\n+                if (topic == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 128}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzNzE3NDEy", "url": "https://github.com/apache/kafka/pull/9547#pullrequestreview-533717412", "createdAt": "2020-11-18T17:44:09Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzNzI2MDg2", "url": "https://github.com/apache/kafka/pull/9547#pullrequestreview-533726086", "createdAt": "2020-11-18T17:52:52Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxNzo1Mjo1MlrOH163wQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxODowMDowMFrOH17Puw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMwMTEyMQ==", "bodyText": "not sure why this kind of method still exist in each request. It is not used anymore.", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526301121", "createdAt": "2020-11-18T17:52:52Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetsForLeaderEpochRequest.java", "diffHunk": "@@ -51,169 +47,120 @@\n      */\n     public static final int DEBUGGING_REPLICA_ID = -2;\n \n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"An array of topics to get epochs for\");\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"An array of partitions to get epochs for\");\n-\n-    private static final Field.Int32 LEADER_EPOCH = new Field.Int32(\"leader_epoch\",\n-            \"The epoch to lookup an offset for.\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            LEADER_EPOCH);\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V0 = new Schema(\n-            TOPICS_V0);\n-\n-    // V1 request is the same as v0. Per-partition leader epoch has been added to response\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V1 = OFFSET_FOR_LEADER_EPOCH_REQUEST_V0;\n-\n-    // V2 adds the current leader epoch to support fencing and the addition of the throttle time in the response\n-    private static final Field PARTITIONS_V2 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            CURRENT_LEADER_EPOCH,\n-            LEADER_EPOCH);\n-    private static final Field TOPICS_V2 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V2);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V2 = new Schema(\n-            TOPICS_V2);\n-\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V3 = new Schema(\n-            REPLICA_ID,\n-            TOPICS_V2);\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{OFFSET_FOR_LEADER_EPOCH_REQUEST_V0, OFFSET_FOR_LEADER_EPOCH_REQUEST_V1,\n-            OFFSET_FOR_LEADER_EPOCH_REQUEST_V2, OFFSET_FOR_LEADER_EPOCH_REQUEST_V3};\n-    }\n-\n-    private final Map<TopicPartition, PartitionData> epochsByPartition;\n-\n-    private final int replicaId;\n-\n-    public Map<TopicPartition, PartitionData> epochsByTopicPartition() {\n-        return epochsByPartition;\n-    }\n-\n-    public int replicaId() {\n-        return replicaId;\n-    }\n+    private final OffsetForLeaderEpochRequestData data;\n \n     public static class Builder extends AbstractRequest.Builder<OffsetsForLeaderEpochRequest> {\n-        private final Map<TopicPartition, PartitionData> epochsByPartition;\n-        private final int replicaId;\n+        private final OffsetForLeaderEpochRequestData data;\n \n-        Builder(short oldestAllowedVersion, short latestAllowedVersion, Map<TopicPartition, PartitionData> epochsByPartition, int replicaId) {\n+        Builder(short oldestAllowedVersion, short latestAllowedVersion, OffsetForLeaderEpochRequestData data) {\n             super(ApiKeys.OFFSET_FOR_LEADER_EPOCH, oldestAllowedVersion, latestAllowedVersion);\n-            this.epochsByPartition = epochsByPartition;\n-            this.replicaId = replicaId;\n+            this.data = data;\n         }\n \n-        public static Builder forConsumer(Map<TopicPartition, PartitionData> epochsByPartition) {\n+        public static Builder forConsumer(OffsetForLeaderTopicCollection epochsByPartition) {\n             // Old versions of this API require CLUSTER permission which is not typically granted\n             // to clients. Beginning with version 3, the broker requires only TOPIC Describe\n             // permission for the topic of each requested partition. In order to ensure client\n             // compatibility, we only send this request when we can guarantee the relaxed permissions.\n-            return new Builder((short) 3, ApiKeys.OFFSET_FOR_LEADER_EPOCH.latestVersion(),\n-                    epochsByPartition, CONSUMER_REPLICA_ID);\n+            OffsetForLeaderEpochRequestData data = new OffsetForLeaderEpochRequestData();\n+            data.setReplicaId(CONSUMER_REPLICA_ID);\n+            data.setTopics(epochsByPartition);\n+            return new Builder((short) 3, ApiKeys.OFFSET_FOR_LEADER_EPOCH.latestVersion(), data);\n         }\n \n         public static Builder forFollower(short version, Map<TopicPartition, PartitionData> epochsByPartition, int replicaId) {\n-            return new Builder(version, version, epochsByPartition, replicaId);\n+            OffsetForLeaderEpochRequestData data = new OffsetForLeaderEpochRequestData();\n+            data.setReplicaId(replicaId);\n+\n+            epochsByPartition.forEach((partitionKey, partitionValue) -> {\n+                OffsetForLeaderTopic topic = data.topics().find(partitionKey.topic());\n+                if (topic == null) {\n+                    topic = new OffsetForLeaderTopic().setTopic(partitionKey.topic());\n+                    data.topics().add(topic);\n+                }\n+                topic.partitions().add(new OffsetForLeaderPartition()\n+                    .setPartition(partitionKey.partition())\n+                    .setLeaderEpoch(partitionValue.leaderEpoch)\n+                    .setCurrentLeaderEpoch(partitionValue.currentLeaderEpoch\n+                        .orElse(RecordBatch.NO_PARTITION_LEADER_EPOCH))\n+                );\n+            });\n+            return new Builder(version, version, data);\n         }\n \n         @Override\n         public OffsetsForLeaderEpochRequest build(short version) {\n             if (version < oldestAllowedVersion() || version > latestAllowedVersion())\n                 throw new UnsupportedVersionException(\"Cannot build \" + this + \" with version \" + version);\n-            return new OffsetsForLeaderEpochRequest(epochsByPartition, replicaId, version);\n-        }\n \n-        public static OffsetsForLeaderEpochRequest parse(ByteBuffer buffer, short version) {\n-            return new OffsetsForLeaderEpochRequest(ApiKeys.OFFSET_FOR_LEADER_EPOCH.parseRequest(version, buffer), version);\n+            return new OffsetsForLeaderEpochRequest(data, version);\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"OffsetsForLeaderEpochRequest(\").\n-                    append(\"epochsByPartition=\").append(epochsByPartition).\n-                    append(\")\");\n-            return bld.toString();\n+            return data.toString();\n         }\n     }\n \n-    public OffsetsForLeaderEpochRequest(Map<TopicPartition, PartitionData> epochsByPartition, int replicaId, short version) {\n+    public OffsetsForLeaderEpochRequest(OffsetForLeaderEpochRequestData data, short version) {\n         super(ApiKeys.OFFSET_FOR_LEADER_EPOCH, version);\n-        this.epochsByPartition = epochsByPartition;\n-        this.replicaId = replicaId;\n+        this.data = data;\n     }\n \n     public OffsetsForLeaderEpochRequest(Struct struct, short version) {\n         super(ApiKeys.OFFSET_FOR_LEADER_EPOCH, version);\n-        replicaId = struct.getOrElse(REPLICA_ID, DEBUGGING_REPLICA_ID);\n-        epochsByPartition = new HashMap<>();\n-        for (Object topicAndEpochsObj : struct.get(TOPICS)) {\n-            Struct topicAndEpochs = (Struct) topicAndEpochsObj;\n-            String topic = topicAndEpochs.get(TOPIC_NAME);\n-            for (Object partitionAndEpochObj : topicAndEpochs.get(PARTITIONS)) {\n-                Struct partitionAndEpoch = (Struct) partitionAndEpochObj;\n-                int partitionId = partitionAndEpoch.get(PARTITION_ID);\n-                int leaderEpoch = partitionAndEpoch.get(LEADER_EPOCH);\n-                Optional<Integer> currentEpoch = RequestUtils.getLeaderEpoch(partitionAndEpoch, CURRENT_LEADER_EPOCH);\n-                TopicPartition tp = new TopicPartition(topic, partitionId);\n-                epochsByPartition.put(tp, new PartitionData(currentEpoch, leaderEpoch));\n-            }\n-        }\n+        this.data = new OffsetForLeaderEpochRequestData(struct, version);\n     }\n \n-    public static OffsetsForLeaderEpochRequest parse(ByteBuffer buffer, short versionId) {\n-        return new OffsetsForLeaderEpochRequest(ApiKeys.OFFSET_FOR_LEADER_EPOCH.parseRequest(versionId, buffer), versionId);\n+    public OffsetForLeaderEpochRequestData data() {\n+        return data;\n+    }\n+\n+    public Map<TopicPartition, PartitionData> epochsByTopicPartition() {\n+        Map<TopicPartition, PartitionData> epochsByTopicPartition = new HashMap<>();\n+\n+        data.topics().forEach(topic ->\n+            topic.partitions().forEach(partition ->\n+                epochsByTopicPartition.put(\n+                    new TopicPartition(topic.topic(), partition.partition()),\n+                    new PartitionData(\n+                        RequestUtils.getLeaderEpoch(partition.currentLeaderEpoch()),\n+                        partition.leaderEpoch()))));\n+\n+        return epochsByTopicPartition;\n+    }\n+\n+    public int replicaId() {\n+        return data.replicaId();\n+    }\n+\n+    public static OffsetsForLeaderEpochRequest parse(ByteBuffer buffer, short version) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMwNjU4NQ==", "bodyText": "Is it worth using data rather than responses() to avoid extra conversion?", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526306585", "createdAt": "2020-11-18T17:59:02Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetsForLeaderEpochResponse.java", "diffHunk": "@@ -51,133 +41,82 @@\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n public class OffsetsForLeaderEpochResponse extends AbstractResponse {\n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"An array of topics for which we have leader offsets for some requested partition leader epoch\");\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"An array of offsets by partition\");\n-    private static final Field.Int64 END_OFFSET = new Field.Int64(\"end_offset\", \"The end offset\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            ERROR_CODE,\n-            PARTITION_ID,\n-            END_OFFSET);\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V0 = new Schema(\n-            TOPICS_V0);\n-\n-    // V1 added a per-partition leader epoch field which specifies which leader epoch the end offset belongs to\n-    private static final Field PARTITIONS_V1 = PARTITIONS.withFields(\n-            ERROR_CODE,\n-            PARTITION_ID,\n-            LEADER_EPOCH,\n-            END_OFFSET);\n-    private static final Field TOPICS_V1 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V1);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V1 = new Schema(\n-            TOPICS_V1);\n-\n-    // V2 bumped for addition of current leader epoch to the request schema and the addition of the throttle\n-    // time in the response\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2 = new Schema(\n-            THROTTLE_TIME_MS,\n-            TOPICS_V1);\n-\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V3 = OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2;\n-\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{OFFSET_FOR_LEADER_EPOCH_RESPONSE_V0, OFFSET_FOR_LEADER_EPOCH_RESPONSE_V1,\n-            OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2, OFFSET_FOR_LEADER_EPOCH_RESPONSE_V3};\n+\n+    private final OffsetForLeaderEpochResponseData data;\n+\n+    public OffsetsForLeaderEpochResponse(OffsetForLeaderEpochResponseData data) {\n+        this.data = data;\n     }\n \n-    private final int throttleTimeMs;\n-    private final Map<TopicPartition, EpochEndOffset> epochEndOffsetsByPartition;\n-\n-    public OffsetsForLeaderEpochResponse(Struct struct) {\n-        this.throttleTimeMs = struct.getOrElse(THROTTLE_TIME_MS, DEFAULT_THROTTLE_TIME);\n-        this.epochEndOffsetsByPartition = new HashMap<>();\n-        for (Object topicAndEpocsObj : struct.get(TOPICS)) {\n-            Struct topicAndEpochs = (Struct) topicAndEpocsObj;\n-            String topic = topicAndEpochs.get(TOPIC_NAME);\n-            for (Object partitionAndEpochObj : topicAndEpochs.get(PARTITIONS)) {\n-                Struct partitionAndEpoch = (Struct) partitionAndEpochObj;\n-                Errors error = Errors.forCode(partitionAndEpoch.get(ERROR_CODE));\n-                int partitionId = partitionAndEpoch.get(PARTITION_ID);\n-                TopicPartition tp = new TopicPartition(topic, partitionId);\n-                int leaderEpoch = partitionAndEpoch.getOrElse(LEADER_EPOCH, RecordBatch.NO_PARTITION_LEADER_EPOCH);\n-                long endOffset = partitionAndEpoch.get(END_OFFSET);\n-                epochEndOffsetsByPartition.put(tp, new EpochEndOffset(error, leaderEpoch, endOffset));\n-            }\n-        }\n+    public OffsetsForLeaderEpochResponse(Struct struct, short version) {\n+        data = new OffsetForLeaderEpochResponseData(struct, version);\n+    }\n+\n+    public OffsetsForLeaderEpochResponse(Map<TopicPartition, EpochEndOffset> offsets) {\n+        this(0, offsets);\n     }\n \n-    public OffsetsForLeaderEpochResponse(Map<TopicPartition, EpochEndOffset> epochsByTopic) {\n-        this(DEFAULT_THROTTLE_TIME, epochsByTopic);\n+    public OffsetsForLeaderEpochResponse(int throttleTimeMs, Map<TopicPartition, EpochEndOffset> offsets) {\n+        data = new OffsetForLeaderEpochResponseData();\n+        data.setThrottleTimeMs(throttleTimeMs);\n+\n+        offsets.forEach((tp, offset) -> {\n+            OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+            if (topic == null) {\n+                topic = new OffsetForLeaderTopicResult().setTopic(tp.topic());\n+                data.topics().add(topic);\n+            }\n+            topic.partitions().add(new OffsetForLeaderPartitionResult()\n+                .setPartition(tp.partition())\n+                .setErrorCode(offset.error().code())\n+                .setLeaderEpoch(offset.leaderEpoch())\n+                .setEndOffset(offset.endOffset()));\n+        });\n     }\n \n-    public OffsetsForLeaderEpochResponse(int throttleTimeMs, Map<TopicPartition, EpochEndOffset> epochsByTopic) {\n-        this.throttleTimeMs = throttleTimeMs;\n-        this.epochEndOffsetsByPartition = epochsByTopic;\n+    public OffsetForLeaderEpochResponseData data() {\n+        return data;\n     }\n \n     public Map<TopicPartition, EpochEndOffset> responses() {\n+        Map<TopicPartition, EpochEndOffset> epochEndOffsetsByPartition = new HashMap<>();\n+\n+        data.topics().forEach(topic ->\n+            topic.partitions().forEach(partition ->\n+                epochEndOffsetsByPartition.put(\n+                    new TopicPartition(topic.topic(), partition.partition()),\n+                    new EpochEndOffset(\n+                        Errors.forCode(partition.errorCode()),\n+                        partition.leaderEpoch(),\n+                        partition.endOffset()))));\n+\n         return epochEndOffsetsByPartition;\n     }\n \n     @Override\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n-        epochEndOffsetsByPartition.values().forEach(response ->\n+        responses().values().forEach(response ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMwNzI1OQ==", "bodyText": "I hope we can get rid of those conversion in the future :)", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526307259", "createdAt": "2020-11-18T18:00:00Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetsForLeaderEpochResponse.java", "diffHunk": "@@ -51,133 +41,82 @@\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n public class OffsetsForLeaderEpochResponse extends AbstractResponse {\n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"An array of topics for which we have leader offsets for some requested partition leader epoch\");\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"An array of offsets by partition\");\n-    private static final Field.Int64 END_OFFSET = new Field.Int64(\"end_offset\", \"The end offset\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            ERROR_CODE,\n-            PARTITION_ID,\n-            END_OFFSET);\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V0 = new Schema(\n-            TOPICS_V0);\n-\n-    // V1 added a per-partition leader epoch field which specifies which leader epoch the end offset belongs to\n-    private static final Field PARTITIONS_V1 = PARTITIONS.withFields(\n-            ERROR_CODE,\n-            PARTITION_ID,\n-            LEADER_EPOCH,\n-            END_OFFSET);\n-    private static final Field TOPICS_V1 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V1);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V1 = new Schema(\n-            TOPICS_V1);\n-\n-    // V2 bumped for addition of current leader epoch to the request schema and the addition of the throttle\n-    // time in the response\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2 = new Schema(\n-            THROTTLE_TIME_MS,\n-            TOPICS_V1);\n-\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V3 = OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2;\n-\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{OFFSET_FOR_LEADER_EPOCH_RESPONSE_V0, OFFSET_FOR_LEADER_EPOCH_RESPONSE_V1,\n-            OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2, OFFSET_FOR_LEADER_EPOCH_RESPONSE_V3};\n+\n+    private final OffsetForLeaderEpochResponseData data;\n+\n+    public OffsetsForLeaderEpochResponse(OffsetForLeaderEpochResponseData data) {\n+        this.data = data;\n     }\n \n-    private final int throttleTimeMs;\n-    private final Map<TopicPartition, EpochEndOffset> epochEndOffsetsByPartition;\n-\n-    public OffsetsForLeaderEpochResponse(Struct struct) {\n-        this.throttleTimeMs = struct.getOrElse(THROTTLE_TIME_MS, DEFAULT_THROTTLE_TIME);\n-        this.epochEndOffsetsByPartition = new HashMap<>();\n-        for (Object topicAndEpocsObj : struct.get(TOPICS)) {\n-            Struct topicAndEpochs = (Struct) topicAndEpocsObj;\n-            String topic = topicAndEpochs.get(TOPIC_NAME);\n-            for (Object partitionAndEpochObj : topicAndEpochs.get(PARTITIONS)) {\n-                Struct partitionAndEpoch = (Struct) partitionAndEpochObj;\n-                Errors error = Errors.forCode(partitionAndEpoch.get(ERROR_CODE));\n-                int partitionId = partitionAndEpoch.get(PARTITION_ID);\n-                TopicPartition tp = new TopicPartition(topic, partitionId);\n-                int leaderEpoch = partitionAndEpoch.getOrElse(LEADER_EPOCH, RecordBatch.NO_PARTITION_LEADER_EPOCH);\n-                long endOffset = partitionAndEpoch.get(END_OFFSET);\n-                epochEndOffsetsByPartition.put(tp, new EpochEndOffset(error, leaderEpoch, endOffset));\n-            }\n-        }\n+    public OffsetsForLeaderEpochResponse(Struct struct, short version) {\n+        data = new OffsetForLeaderEpochResponseData(struct, version);\n+    }\n+\n+    public OffsetsForLeaderEpochResponse(Map<TopicPartition, EpochEndOffset> offsets) {\n+        this(0, offsets);\n     }\n \n-    public OffsetsForLeaderEpochResponse(Map<TopicPartition, EpochEndOffset> epochsByTopic) {\n-        this(DEFAULT_THROTTLE_TIME, epochsByTopic);\n+    public OffsetsForLeaderEpochResponse(int throttleTimeMs, Map<TopicPartition, EpochEndOffset> offsets) {\n+        data = new OffsetForLeaderEpochResponseData();\n+        data.setThrottleTimeMs(throttleTimeMs);\n+\n+        offsets.forEach((tp, offset) -> {\n+            OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+            if (topic == null) {\n+                topic = new OffsetForLeaderTopicResult().setTopic(tp.topic());\n+                data.topics().add(topic);\n+            }\n+            topic.partitions().add(new OffsetForLeaderPartitionResult()\n+                .setPartition(tp.partition())\n+                .setErrorCode(offset.error().code())\n+                .setLeaderEpoch(offset.leaderEpoch())\n+                .setEndOffset(offset.endOffset()));\n+        });\n     }\n \n-    public OffsetsForLeaderEpochResponse(int throttleTimeMs, Map<TopicPartition, EpochEndOffset> epochsByTopic) {\n-        this.throttleTimeMs = throttleTimeMs;\n-        this.epochEndOffsetsByPartition = epochsByTopic;\n+    public OffsetForLeaderEpochResponseData data() {\n+        return data;\n     }\n \n     public Map<TopicPartition, EpochEndOffset> responses() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 138}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a5d8c5440222955abe825c06b1e1fb380c22e6c", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/7a5d8c5440222955abe825c06b1e1fb380c22e6c", "committedDate": "2020-11-19T07:52:45Z", "message": "1 to 1 migration to auto generated protocol."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6cbe529a89e4b3d0c19f2b60c00b9f81ac0a9dff", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/6cbe529a89e4b3d0c19f2b60c00b9f81ac0a9dff", "committedDate": "2020-11-19T07:59:03Z", "message": "Move `OffsetsForLeaderEpochRequest.Builder.forConsumer`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c47fad6802a2547e33902fc699fe8485ded58644", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/c47fad6802a2547e33902fc699fe8485ded58644", "committedDate": "2020-11-19T07:59:03Z", "message": "refactor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1ab26b1bc4361b6506cb83e2f1b4a543f09a9d23", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/1ab26b1bc4361b6506cb83e2f1b4a543f09a9d23", "committedDate": "2020-11-19T07:59:03Z", "message": "Migrate OffsetsForLeaderEpochClient to use OffsetForLeaderEpochResponseData directly."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc1bc36ad39e58719b858a7073b20ae34bcdbefe", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/fc1bc36ad39e58719b858a7073b20ae34bcdbefe", "committedDate": "2020-11-19T07:59:04Z", "message": "fixup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "29dc946e78427a910f366f87409d8b5a6c72a7dd", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/29dc946e78427a910f366f87409d8b5a6c72a7dd", "committedDate": "2020-11-19T07:59:04Z", "message": "Use OffsetForLeaderPartitionResult in OffsetsForLeaderEpochClient instead of EpochEndOffset."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d77bf9987dd2d94488b3f4b5cc4e5dee952c5792", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/d77bf9987dd2d94488b3f4b5cc4e5dee952c5792", "committedDate": "2020-11-19T07:59:04Z", "message": "Rename fields"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "554a686ba45676295a8d8a5f5b61a5d1c9ea4e1c", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/554a686ba45676295a8d8a5f5b61a5d1c9ea4e1c", "committedDate": "2020-11-19T07:59:04Z", "message": "fixup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a15d435b47cf74dcfd465a9a2813b216dcfbe512", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/a15d435b47cf74dcfd465a9a2813b216dcfbe512", "committedDate": "2020-11-19T07:59:04Z", "message": "address reviews"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "a15d435b47cf74dcfd465a9a2813b216dcfbe512", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/a15d435b47cf74dcfd465a9a2813b216dcfbe512", "committedDate": "2020-11-19T07:59:04Z", "message": "address reviews"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2663, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}