{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIxMTMwNzA5", "number": 9596, "title": "KAFKA-10723: Fix LogManager shutdown error handling", "bodyText": "The asynchronous shutdown in LogManager has the shortcoming that if during shutdown any of the internal futures fail, then we do not always ensure that all futures are completed before LogManager.shutdown returns. This is because, this line in the finally clause shuts down the thread pools asynchronously. As a result, despite the shut down completed message from KafkaServer is seen in the error logs, some futures continue to run from inside LogManager attempting to close some logs. This is misleading during debugging. Also sometimes it introduces an avoidable post-shutdown activity where resources (such as file handles) are released or persistent state is checkpointed in the Broker.\nIn this PR, we fix the above behavior such that we prevent leakage of threads. If any of the futures throw an error, we  skip creating of checkpoint and clean shutdown file only for the affected log directory. We continue to wait for all futures to complete for all the directories.\nTest plan:\nAdded a new unit test: LogManager.testHandlingExceptionsDuringShutdown.", "createdAt": "2020-11-15T01:59:13Z", "url": "https://github.com/apache/kafka/pull/9596", "merged": true, "mergeCommit": {"oid": "dcbd28da53bfc6edb78fd1735993163fc6f4c7c7"}, "closed": true, "closedAt": "2020-11-19T18:52:18Z", "author": {"login": "kowshik"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdcmg0KgH2gAyNTIxMTMwNzA5OjNhMzZiNTRmZTZmNTBlMjUzOGZmNjg0YmU3ZWQ2MjZjM2FmZTgzZjQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdeHThGgFqTUzNDc0NjY5Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "author": {"user": {"login": "kowshik", "name": "Kowshik Prakasam"}}, "url": "https://github.com/apache/kafka/commit/3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "committedDate": "2020-11-15T01:59:21Z", "message": "KAFKA-10723: Fix LogManager shutdown error handling"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "author": {"user": {"login": "kowshik", "name": "Kowshik Prakasam"}}, "url": "https://github.com/apache/kafka/commit/3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "committedDate": "2020-11-15T01:59:21Z", "message": "KAFKA-10723: Fix LogManager shutdown error handling"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMxMTY3Nzc3", "url": "https://github.com/apache/kafka/pull/9596#pullrequestreview-531167777", "createdAt": "2020-11-16T09:56:43Z", "commit": {"oid": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQwOTo1Njo0M1rOHzxrLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQwOTo1Njo0M1rOHzxrLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDA1MzI5Mg==", "bodyText": "If the end user delete the log files Manually , the server cannot be stopped. and The cannot startup it again? so in this case ,how do they resolve it ?", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524053292", "createdAt": "2020-11-16T09:56:43Z", "author": {"login": "lqjack"}, "path": "core/src/test/scala/unit/kafka/log/LogManagerTest.scala", "diffHunk": "@@ -83,6 +87,51 @@ class LogManagerTest {\n     log.appendAsLeader(TestUtils.singletonRecords(\"test\".getBytes()), leaderEpoch = 0)\n   }\n \n+  /**\n+   * Tests that all internal futures are completed before LogManager.shutdown() returns to the\n+   * caller during error situations.\n+   */\n+  @Test\n+  def testHandlingExceptionsDuringShutdown(): Unit = {\n+    logManager.shutdown()\n+\n+    // We create two directories logDir1 and logDir2 to help effectively test error handling\n+    // during LogManager.shutdown().\n+    val logDir1 = TestUtils.tempDir()\n+    val logDir2 = TestUtils.tempDir()\n+    logManager = createLogManager(Seq(logDir1, logDir2))\n+    assertEquals(2, logManager.liveLogDirs.size)\n+    logManager.startup()\n+\n+    val log1 = logManager.getOrCreateLog(new TopicPartition(name, 0), () => logConfig)\n+    val log2 = logManager.getOrCreateLog(new TopicPartition(name, 1), () => logConfig)\n+\n+    val logFile1 = new File(logDir1, name + \"-0\")\n+    assertTrue(logFile1.exists)\n+    val logFile2 = new File(logDir2, name + \"-1\")\n+    assertTrue(logFile2.exists)\n+\n+    log1.appendAsLeader(TestUtils.singletonRecords(\"test1\".getBytes()), leaderEpoch = 0)\n+    log1.takeProducerSnapshot()\n+    log1.appendAsLeader(TestUtils.singletonRecords(\"test1\".getBytes()), leaderEpoch = 0)\n+\n+    log2.appendAsLeader(TestUtils.singletonRecords(\"test2\".getBytes()), leaderEpoch = 0)\n+    log2.takeProducerSnapshot()\n+    log2.appendAsLeader(TestUtils.singletonRecords(\"test2\".getBytes()), leaderEpoch = 0)\n+\n+    // This should cause log1.close() to fail during LogManger shutdown sequence.\n+    FileUtils.deleteDirectory(logFile1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4"}, "originalPosition": 73}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMxODM1Nzc0", "url": "https://github.com/apache/kafka/pull/9596#pullrequestreview-531835774", "createdAt": "2020-11-16T22:22:04Z", "commit": {"oid": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQyMjoyMjowNFrOH0XixA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQyMjoyMjo0OVrOH0XmRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDY3MzczMg==", "bodyText": "Hmm, since we are about to shut down the JVM, should we just log a WARN here instead of throwing the exception?", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524673732", "createdAt": "2020-11-16T22:22:04Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -477,27 +477,41 @@ class LogManager(logDirs: Seq[File],\n       jobs(dir) = jobsForDir.map(pool.submit).toSeq\n     }\n \n+    var firstExceptionOpt: Option[Throwable] = Option.empty\n     try {\n       for ((dir, dirJobs) <- jobs) {\n-        dirJobs.foreach(_.get)\n+        val errorsForDirJobs = dirJobs.map {\n+          future =>\n+            try {\n+              future.get\n+              Option.empty\n+            } catch {\n+              case e: ExecutionException =>\n+                error(s\"There was an error in one of the threads during LogManager shutdown: ${e.getCause}\")\n+                Some(e.getCause)\n+            }\n+        }.filter{ e => e.isDefined }.map{ e => e.get }\n+\n+        if (firstExceptionOpt.isEmpty) {\n+          firstExceptionOpt = errorsForDirJobs.headOption\n+        }\n \n-        val logs = logsInDir(localLogsByDir, dir)\n+        if (errorsForDirJobs.isEmpty) {\n+          val logs = logsInDir(localLogsByDir, dir)\n \n-        // update the last flush point\n-        debug(s\"Updating recovery points at $dir\")\n-        checkpointRecoveryOffsetsInDir(dir, logs)\n+          // update the last flush point\n+          debug(s\"Updating recovery points at $dir\")\n+          checkpointRecoveryOffsetsInDir(dir, logs)\n \n-        debug(s\"Updating log start offsets at $dir\")\n-        checkpointLogStartOffsetsInDir(dir, logs)\n+          debug(s\"Updating log start offsets at $dir\")\n+          checkpointLogStartOffsetsInDir(dir, logs)\n \n-        // mark that the shutdown was clean by creating marker file\n-        debug(s\"Writing clean shutdown marker at $dir\")\n-        CoreUtils.swallow(Files.createFile(new File(dir, Log.CleanShutdownFile).toPath), this)\n+          // mark that the shutdown was clean by creating marker file\n+          debug(s\"Writing clean shutdown marker at $dir\")\n+          CoreUtils.swallow(Files.createFile(new File(dir, Log.CleanShutdownFile).toPath), this)\n+        }\n       }\n-    } catch {\n-      case e: ExecutionException =>\n-        error(s\"There was an error in one of the threads during LogManager shutdown: ${e.getCause}\")\n-        throw e.getCause\n+      firstExceptionOpt.foreach{ e => throw e}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDY3NDYyOQ==", "bodyText": "Hmm, do we need this given that we do this in tearDown() already?", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524674629", "createdAt": "2020-11-16T22:22:49Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/log/LogManagerTest.scala", "diffHunk": "@@ -83,6 +87,51 @@ class LogManagerTest {\n     log.appendAsLeader(TestUtils.singletonRecords(\"test\".getBytes()), leaderEpoch = 0)\n   }\n \n+  /**\n+   * Tests that all internal futures are completed before LogManager.shutdown() returns to the\n+   * caller during error situations.\n+   */\n+  @Test\n+  def testHandlingExceptionsDuringShutdown(): Unit = {\n+    logManager.shutdown()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4"}, "originalPosition": 46}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "author": {"user": {"login": "kowshik", "name": "Kowshik Prakasam"}}, "url": "https://github.com/apache/kafka/commit/f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "committedDate": "2020-11-17T02:51:50Z", "message": "Address comments from Jun"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "author": {"user": {"login": "kowshik", "name": "Kowshik Prakasam"}}, "url": "https://github.com/apache/kafka/commit/f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "committedDate": "2020-11-17T02:51:50Z", "message": "Address comments from Jun"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzMTI3Njk0", "url": "https://github.com/apache/kafka/pull/9596#pullrequestreview-533127694", "createdAt": "2020-11-18T06:06:57Z", "commit": {"oid": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwNjowNjo1N1rOH1ebLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwNjowOTowOVrOH1ed-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTA1NA==", "bodyText": "Nit: this should be in the previous line.", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525835054", "createdAt": "2020-11-18T06:06:57Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -479,25 +479,33 @@ class LogManager(logDirs: Seq[File],\n \n     try {\n       for ((dir, dirJobs) <- jobs) {\n-        dirJobs.foreach(_.get)\n+        val hasErrors = dirJobs.exists {\n+          future =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTQ5NQ==", "bodyText": "This looks wrong. exists short-circuits. I think you want map followed by exists.", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525835495", "createdAt": "2020-11-18T06:08:16Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -479,25 +479,33 @@ class LogManager(logDirs: Seq[File],\n \n     try {\n       for ((dir, dirJobs) <- jobs) {\n-        dirJobs.foreach(_.get)\n+        val hasErrors = dirJobs.exists {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTc2OQ==", "bodyText": "You can use scala.util.Try to wrap the call and get a Success or Failure.", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525835769", "createdAt": "2020-11-18T06:09:09Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -479,25 +479,33 @@ class LogManager(logDirs: Seq[File],\n \n     try {\n       for ((dir, dirJobs) <- jobs) {\n-        dirJobs.foreach(_.get)\n+        val hasErrors = dirJobs.exists {\n+          future =>\n+            try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8716429b48cad8af6ad73109c1d9f7442823c02f", "author": {"user": {"login": "kowshik", "name": "Kowshik Prakasam"}}, "url": "https://github.com/apache/kafka/commit/8716429b48cad8af6ad73109c1d9f7442823c02f", "committedDate": "2020-11-18T06:46:45Z", "message": "Address comments from Ismael"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0NzQ2Njkz", "url": "https://github.com/apache/kafka/pull/9596#pullrequestreview-534746693", "createdAt": "2020-11-19T18:45:37Z", "commit": {"oid": "8716429b48cad8af6ad73109c1d9f7442823c02f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2769, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}