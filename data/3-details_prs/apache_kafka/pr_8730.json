{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIzNjQ4ODYy", "number": 8730, "title": "KAFKA-10048: Possible data gap for a consumer after a failover when u\u2026", "bodyText": "Changed the MM2 checkpoint mirror task to ensure it replicates consumer offsets even when they are equal to zero to avoid issues with consumers after failovers.\nModified the test case to cover the possible scenario of consumer gap, as described on KAFKA-10048.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-05-27T06:58:08Z", "url": "https://github.com/apache/kafka/pull/8730", "merged": true, "mergeCommit": {"oid": "6b95f1ec57c303b758f0bea4cc96943108adce2c"}, "closed": true, "closedAt": "2020-10-02T16:34:51Z", "author": {"login": "asdaraujo"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABclwUs0AFqTQyMDI2Njg3NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdOonU8AFqTUwMTI4MTUyNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwMjY2ODc1", "url": "https://github.com/apache/kafka/pull/8730#pullrequestreview-420266875", "createdAt": "2020-05-28T16:05:11Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxNjowNToxMVrOGb8Q-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxNjoxMzo0OFrOGb8o_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1MjEyMw==", "bodyText": "Can we add a deadline to this function? Something like \n  \n    \n      kafka/connect/mirror-client/src/main/java/org/apache/kafka/connect/mirror/MirrorClient.java\n    \n    \n         Line 164\n      in\n      1c4eb1a\n    \n    \n    \n    \n\n        \n          \n           while (System.currentTimeMillis() < deadline && !endOfStream(consumer, checkpointAssignment)) {", "url": "https://github.com/apache/kafka/pull/8730#discussion_r431952123", "createdAt": "2020-05-28T16:05:11Z", "author": {"login": "ryannedolan"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -316,6 +354,23 @@ public void testReplication() throws InterruptedException {\n             backup.kafka().consume(NUM_RECORDS_PRODUCED, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n     }\n \n+    private Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> consumeAllMessages(Consumer<byte[], byte[]> consumer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1NDgzOQ==", "bodyText": "I don't see why we need the cast, ceil, and coercion here? Integer math?", "url": "https://github.com/apache/kafka/pull/8730#discussion_r431954839", "createdAt": "2020-05-28T16:09:36Z", "author": {"login": "ryannedolan"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -272,28 +303,35 @@ public void testReplication() throws InterruptedException {\n         waitForCondition(() -> {\n             try {\n                 return primaryClient.remoteConsumerOffsets(\"consumer-group-1\", \"backup\",\n-                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 1));\n             } catch (Throwable e) {\n                 return false;\n             }\n         }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n \n         Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(\"consumer-group-1\", \"backup\",\n                 Duration.ofMillis(CHECKPOINT_DURATION_MS));\n- \n+\n         // Failback consumer group to primary cluster\n-        Consumer<byte[], byte[]> consumer2 = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", \"consumer-group-1\"));\n-        consumer2.assign(primaryOffsets.keySet());\n+        Consumer<byte[], byte[]> consumer2 = primary.kafka().createConsumer(consumerProps);\n+        List<TopicPartition> primaryPartitions = IntStream.range(0, NUM_PARTITIONS)\n+                .boxed()\n+                .flatMap(p -> Stream.of(new TopicPartition(\"test-topic-1\", p), new TopicPartition(\"backup.test-topic-1\", p)))\n+                .collect(Collectors.toList());\n+        consumer2.assign(primaryPartitions);\n         primaryOffsets.forEach(consumer2::seek);\n-        consumer2.poll(Duration.ofMillis(500));\n \n         assertTrue(\"Consumer failedback to zero upstream offset.\", consumer2.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n         assertTrue(\"Consumer failedback to zero downstream offset.\", consumer2.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n         assertTrue(\"Consumer failedback beyond expected upstream offset.\", consumer2.position(\n-            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            new TopicPartition(\"test-topic-1\", 0)) <= Math.ceil((float) NUM_RECORDS_PRODUCED / (NUM_PARTITIONS - 1)) + Math.ceil((float) NUM_RECORDS_PRODUCED / NUM_PARTITIONS));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1Nzk2OA==", "bodyText": "There is a lot of magic here -- why the special case and magic numbers? Can we restructure this to test the two cases separately maybe?", "url": "https://github.com/apache/kafka/pull/8730#discussion_r431957968", "createdAt": "2020-05-28T16:13:29Z", "author": {"login": "ryannedolan"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -244,26 +251,50 @@ public void testReplication() throws InterruptedException {\n \n         assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n             new TopicPartition(\"primary.test-topic-1\", 0)));\n+        assertTrue(\"Offset of empty partition not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", NUM_PARTITIONS - 1)));\n+\n+        // Produce additional messages.\n+        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n+            // produce to all partitions this time\n+            primary.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-2-\" + i);\n+            backup.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-2-\" + i);\n+        }\n \n         // Failover consumer group to backup cluster.\n-        Consumer<byte[], byte[]> consumer1 = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", \"consumer-group-1\"));\n-        consumer1.assign(backupOffsets.keySet());\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", \"consumer-group-1\");\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        Consumer<byte[], byte[]> consumer1 = backup.kafka().createConsumer(consumerProps);\n+        List<TopicPartition> backupPartitions = IntStream.range(0, NUM_PARTITIONS)\n+                .boxed()\n+                .flatMap(p -> Stream.of(new TopicPartition(\"test-topic-1\", p), new TopicPartition(\"primary.test-topic-1\", p)))\n+                .collect(Collectors.toList());\n+        consumer1.assign(backupPartitions);\n         backupOffsets.forEach(consumer1::seek);\n-        consumer1.poll(Duration.ofMillis(500));\n-        consumer1.commitSync();\n \n         assertTrue(\"Consumer failedover to zero offset.\", consumer1.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n         assertTrue(\"Consumer failedover beyond expected offset.\", consumer1.position(\n-            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= Math.ceil((float) NUM_RECORDS_PRODUCED / (NUM_PARTITIONS - 1)));\n+        assertEquals(\"Consumer failedover to non-zero offset on last partition.\", 0,\n+            consumer1.position(new TopicPartition(\"primary.test-topic-1\", NUM_PARTITIONS - 1)));\n         assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n             CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n \n+        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> messages1 = consumeAllMessages(consumer1);\n+        System.out.println(messages1);\n+        for (TopicPartition tp : backupPartitions) {\n+            assertNotNull(\"No data consumed from partition \" + tp + \".\", messages1.get(tp));\n+            int expectedMessageCount = tp.toString().equals(\"test-topic-1-0\") ? 22 : 10;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1ODI3MQ==", "bodyText": "errant println", "url": "https://github.com/apache/kafka/pull/8730#discussion_r431958271", "createdAt": "2020-05-28T16:13:48Z", "author": {"login": "ryannedolan"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -244,26 +251,50 @@ public void testReplication() throws InterruptedException {\n \n         assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n             new TopicPartition(\"primary.test-topic-1\", 0)));\n+        assertTrue(\"Offset of empty partition not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", NUM_PARTITIONS - 1)));\n+\n+        // Produce additional messages.\n+        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n+            // produce to all partitions this time\n+            primary.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-2-\" + i);\n+            backup.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-2-\" + i);\n+        }\n \n         // Failover consumer group to backup cluster.\n-        Consumer<byte[], byte[]> consumer1 = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", \"consumer-group-1\"));\n-        consumer1.assign(backupOffsets.keySet());\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", \"consumer-group-1\");\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        Consumer<byte[], byte[]> consumer1 = backup.kafka().createConsumer(consumerProps);\n+        List<TopicPartition> backupPartitions = IntStream.range(0, NUM_PARTITIONS)\n+                .boxed()\n+                .flatMap(p -> Stream.of(new TopicPartition(\"test-topic-1\", p), new TopicPartition(\"primary.test-topic-1\", p)))\n+                .collect(Collectors.toList());\n+        consumer1.assign(backupPartitions);\n         backupOffsets.forEach(consumer1::seek);\n-        consumer1.poll(Duration.ofMillis(500));\n-        consumer1.commitSync();\n \n         assertTrue(\"Consumer failedover to zero offset.\", consumer1.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n         assertTrue(\"Consumer failedover beyond expected offset.\", consumer1.position(\n-            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= Math.ceil((float) NUM_RECORDS_PRODUCED / (NUM_PARTITIONS - 1)));\n+        assertEquals(\"Consumer failedover to non-zero offset on last partition.\", 0,\n+            consumer1.position(new TopicPartition(\"primary.test-topic-1\", NUM_PARTITIONS - 1)));\n         assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n             CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n \n+        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> messages1 = consumeAllMessages(consumer1);\n+        System.out.println(messages1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 100}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "17f67504bd3a6773d2c266f1755c6c4993222f1d", "author": {"user": {"login": "asdaraujo", "name": "Andre Araujo"}}, "url": "https://github.com/apache/kafka/commit/17f67504bd3a6773d2c266f1755c6c4993222f1d", "committedDate": "2020-05-29T21:55:09Z", "message": "KAFKA-10048: Possible data gap for a consumer after a failover when using MM2\n\nEnsure that the MM2 checkpoint mirror task replicates consumer offsets even when they are\nzero to avoid issues with consumers after failovers.\n\nAuthor: Andre Araujo <asdaraujo@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0NjY5MDQ1", "url": "https://github.com/apache/kafka/pull/8730#pullrequestreview-424669045", "createdAt": "2020-06-04T17:24:07Z", "commit": {"oid": "17f67504bd3a6773d2c266f1755c6c4993222f1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzoyNDowN1rOGfQLbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzoyNDowN1rOGfQLbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQyNDExMQ==", "bodyText": "Can downstream offset be negative?", "url": "https://github.com/apache/kafka/pull/8730#discussion_r435424111", "createdAt": "2020-06-04T17:24:07Z", "author": {"login": "heritamas"}, "path": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorCheckpointTask.java", "diffHunk": "@@ -132,7 +132,7 @@ public String version() {\n             return listConsumerGroupOffsets(group).entrySet().stream()\n                 .filter(x -> shouldCheckpointTopic(x.getKey().topic()))\n                 .map(x -> checkpoint(group, x.getKey(), x.getValue()))\n-                .filter(x -> x.downstreamOffset() > 0)  // ignore offsets we cannot translate accurately\n+                .filter(x -> x.downstreamOffset() >= 0)  // ignore offsets we cannot translate accurately", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "17f67504bd3a6773d2c266f1755c6c4993222f1d"}, "originalPosition": 5}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "17f67504bd3a6773d2c266f1755c6c4993222f1d", "author": {"user": {"login": "asdaraujo", "name": "Andre Araujo"}}, "url": "https://github.com/apache/kafka/commit/17f67504bd3a6773d2c266f1755c6c4993222f1d", "committedDate": "2020-05-29T21:55:09Z", "message": "KAFKA-10048: Possible data gap for a consumer after a failover when using MM2\n\nEnsure that the MM2 checkpoint mirror task replicates consumer offsets even when they are\nzero to avoid issues with consumers after failovers.\n\nAuthor: Andre Araujo <asdaraujo@gmail.com>"}, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NTM1NjQ4", "url": "https://github.com/apache/kafka/pull/8730#pullrequestreview-458535648", "createdAt": "2020-07-30T15:52:20Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNTo1MjoyMVrOG5pQPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNjo0Njo1MVrOG5rX6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA5NzkxOA==", "bodyText": "This comment needs updating", "url": "https://github.com/apache/kafka/pull/8730#discussion_r463097918", "createdAt": "2020-07-30T15:52:21Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -367,14 +406,37 @@ public void testOneWayReplicationWithAutorOffsetSync1() throws InterruptedExcept\n         time.sleep(5000);\n \n         // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n-        consumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n-            \"group.id\", \"consumer-group-1\"), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+        consumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"primary.test-topic-1\", \"primary.test-topic-2\");\n \n         records = consumer.poll(Duration.ofMillis(500));\n         // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n         assertEquals(\"consumer record size is not zero\", 0, records.count());\n         consumer.close();\n+    }\n+\n+    private void produceMessages(EmbeddedConnectCluster cluster, String topicName, int partitions, String msgPrefix) {\n+        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n+            // produce to all partitions but the last one", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 268}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEyODQxNQ==", "bodyText": "Would it be better using a separate topic in order to keep a partition without any records? By changing this topic it affects existing checks in all tests", "url": "https://github.com/apache/kafka/pull/8730#discussion_r463128415", "createdAt": "2020-07-30T16:39:59Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -128,10 +136,23 @@ public void setup() throws InterruptedException {\n         backup.kafka().createTopic(\"primary.test-topic-1\", 1);\n         backup.kafka().createTopic(\"heartbeats\", 1);\n \n-        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n-            primary.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-1-\" + i);\n-            backup.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-2-\" + i);\n-        }\n+        // produce to all partitions but the last one", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEyODk2OA==", "bodyText": "As this does not change, I wonder if we could direct initialize consumerProps when it's declared", "url": "https://github.com/apache/kafka/pull/8730#discussion_r463128968", "createdAt": "2020-07-30T16:40:56Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -128,10 +136,23 @@ public void setup() throws InterruptedException {\n         backup.kafka().createTopic(\"primary.test-topic-1\", 1);\n         backup.kafka().createTopic(\"heartbeats\", 1);\n \n-        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n-            primary.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-1-\" + i);\n-            backup.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-2-\" + i);\n-        }\n+        // produce to all partitions but the last one\n+        produceMessages(primary, \"test-topic-1\", NUM_PARTITIONS - 1, \"message-1-\");\n+        produceMessages(backup, \"test-topic-1\", NUM_PARTITIONS - 1, \"message-2-\");\n+\n+        consumerProps = new HashMap<String, Object>() {{", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEyOTU5MA==", "bodyText": "Do we still need these 2 blocks? In setup() we already consumed all messages", "url": "https://github.com/apache/kafka/pull/8730#discussion_r463129590", "createdAt": "2020-07-30T16:42:00Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -190,24 +211,19 @@ public void close() {\n     public void testReplication() throws InterruptedException {\n \n         // create consumers before starting the connectors so we don't need to wait for discovery\n-        Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n-            \"group.id\", \"consumer-group-1\"), \"test-topic-1\", \"backup.test-topic-1\");\n+        Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\", \"backup.test-topic-1\");\n         consumer1.poll(Duration.ofMillis(500));\n         consumer1.commitSync();\n         consumer1.close();\n \n-        Consumer<byte[], byte[]> consumer2 = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n-            \"group.id\", \"consumer-group-1\"), \"test-topic-1\", \"primary.test-topic-1\");\n+        Consumer<byte[], byte[]> consumer2 = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\", \"primary.test-topic-1\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzEzMjY1MA==", "bodyText": "I'm actually surprized we only see positions 22 and 10. Why do we only get test-topic-1-0 here and not the other 9 partitions?", "url": "https://github.com/apache/kafka/pull/8730#discussion_r463132650", "createdAt": "2020-07-30T16:46:51Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -244,26 +251,50 @@ public void testReplication() throws InterruptedException {\n \n         assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n             new TopicPartition(\"primary.test-topic-1\", 0)));\n+        assertTrue(\"Offset of empty partition not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", NUM_PARTITIONS - 1)));\n+\n+        // Produce additional messages.\n+        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n+            // produce to all partitions this time\n+            primary.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-2-\" + i);\n+            backup.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-2-\" + i);\n+        }\n \n         // Failover consumer group to backup cluster.\n-        Consumer<byte[], byte[]> consumer1 = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", \"consumer-group-1\"));\n-        consumer1.assign(backupOffsets.keySet());\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", \"consumer-group-1\");\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        Consumer<byte[], byte[]> consumer1 = backup.kafka().createConsumer(consumerProps);\n+        List<TopicPartition> backupPartitions = IntStream.range(0, NUM_PARTITIONS)\n+                .boxed()\n+                .flatMap(p -> Stream.of(new TopicPartition(\"test-topic-1\", p), new TopicPartition(\"primary.test-topic-1\", p)))\n+                .collect(Collectors.toList());\n+        consumer1.assign(backupPartitions);\n         backupOffsets.forEach(consumer1::seek);\n-        consumer1.poll(Duration.ofMillis(500));\n-        consumer1.commitSync();\n \n         assertTrue(\"Consumer failedover to zero offset.\", consumer1.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n         assertTrue(\"Consumer failedover beyond expected offset.\", consumer1.position(\n-            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= Math.ceil((float) NUM_RECORDS_PRODUCED / (NUM_PARTITIONS - 1)));\n+        assertEquals(\"Consumer failedover to non-zero offset on last partition.\", 0,\n+            consumer1.position(new TopicPartition(\"primary.test-topic-1\", NUM_PARTITIONS - 1)));\n         assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n             CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n \n+        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> messages1 = consumeAllMessages(consumer1);\n+        System.out.println(messages1);\n+        for (TopicPartition tp : backupPartitions) {\n+            assertNotNull(\"No data consumed from partition \" + tp + \".\", messages1.get(tp));\n+            int expectedMessageCount = tp.toString().equals(\"test-topic-1-0\") ? 22 : 10;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1Nzk2OA=="}, "originalCommit": null, "originalPosition": 103}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwNzEwMjAz", "url": "https://github.com/apache/kafka/pull/8730#pullrequestreview-490710203", "createdAt": "2020-09-17T15:16:55Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNToxNjo1NVrOHTnreA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNToxNjo1NVrOHTnreA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMzNTA5Ng==", "bodyText": "this overwrite of mm2config should go in the setup method, IMHO", "url": "https://github.com/apache/kafka/pull/8730#discussion_r490335096", "createdAt": "2020-09-17T15:16:55Z", "author": {"login": "edoardocomar"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -283,49 +296,140 @@ public void testReplication() throws InterruptedException {\n \n         waitForCondition(() -> {\n             try {\n-                return primaryClient.remoteConsumerOffsets(\"consumer-group-1\", \"backup\",\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n                     Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n             } catch (Throwable e) {\n                 return false;\n             }\n         }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n \n-        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(\"consumer-group-1\", \"backup\",\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n                 Duration.ofMillis(CHECKPOINT_DURATION_MS));\n- \n+\n         // Failback consumer group to primary cluster\n-        consumer2 = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", \"consumer-group-1\"));\n-        consumer2.assign(primaryOffsets.keySet());\n-        primaryOffsets.forEach(consumer2::seek);\n-        consumer2.poll(Duration.ofMillis(500));\n-\n-        assertTrue(\"Consumer failedback to zero upstream offset.\", consumer2.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n-        assertTrue(\"Consumer failedback to zero downstream offset.\", consumer2.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n-        assertTrue(\"Consumer failedback beyond expected upstream offset.\", consumer2.position(\n-            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n-        assertTrue(\"Consumer failedback beyond expected downstream offset.\", consumer2.position(\n-            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n-        \n-        consumer2.close();\n-      \n+        primaryConsumer = primary.kafka().createConsumer(consumerProps);\n+        primaryConsumer.assign(allPartitions(\"test-topic-1\", \"backup.test-topic-1\"));\n+        seek(primaryConsumer, primaryOffsets);\n+        consumeAllMessages(primaryConsumer, 0);\n+\n+        assertTrue(\"Consumer failedback to zero upstream offset.\", primaryConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback to zero downstream offset.\", primaryConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback beyond expected upstream offset.\", primaryConsumer.position(\n+            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PER_PARTITION);\n+        assertTrue(\"Consumer failedback beyond expected downstream offset.\", primaryConsumer.position(\n+            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PER_PARTITION);\n+\n+        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> messages2 = consumeAllMessages(primaryConsumer, 0);\n+        // If offset translation was successful we expect no messages to be consumed after failback\n+        assertEquals(\"Data was consumed from partitions: \" + messages2.keySet() + \".\", 0, messages2.size());\n+        primaryConsumer.close();\n+\n         // create more matching topics\n         primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n         backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n \n-        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n-            primary.kafka().produce(\"test-topic-2\", 0, \"key\", \"message-2-\" + i);\n-            backup.kafka().produce(\"test-topic-3\", 0, \"key\", \"message-3-\" + i);\n+        produceMessages(primary, \"test-topic-2\", \"message-3-\", 1);\n+        produceMessages(backup, \"test-topic-3\", \"message-4-\", 1);\n+\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+    }\n+\n+    @Test\n+    public void testReplicationWithEmptyPartition() throws InterruptedException {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+\n+        // create topics\n+        String topic = \"test-topic-empty\";\n+        String primaryTopicReplica = \"primary.\" + topic;\n+        String backupTopicReplica = \"backup.\" + topic;\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+        primary.kafka().createTopic(backupTopicReplica, 1);\n+        backup.kafka().createTopic(topic, NUM_PARTITIONS);\n+        backup.kafka().createTopic(primaryTopicReplica, 1);\n+\n+        // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic, backupTopicReplica);\n+        consumeAllMessages(consumer, 0);\n+\n+        // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster\n+        produceMessages(primary, topic, \"message-1-\", NUM_PARTITIONS - 1);\n+\n+        // Consume all messages\n+        consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1));\n+        consumer.close();\n+\n+        // Consumer group offsets after consumption: topic's last partition doesn't yet has data, so\n+        // the committed offset is 0. All other topic's partition should have offset equal to NUM_RECORDS_PER_PARTITION.\n+        // backupTopicReplica still has a single empty partition, since MM2 is not yet started, and its record offset is 0.\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 317}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwNzE0ODQ5", "url": "https://github.com/apache/kafka/pull/8730#pullrequestreview-490714849", "createdAt": "2020-09-17T15:21:47Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNToyMTo0N1rOHTn5Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNToyOTozNlrOHToP1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMzODU5MQ==", "bodyText": "This test is overly complicated. I think it could:\n\nCreate a topic\nProduce messages to all partitions but one\nConsume all messages\nStart a single MirrorMaker2 instance primary->backup\nUse RemoteClusterUtils.translateOffsets() to retrieve offsets\nAssert offset for the last partition is 0\n\nFor example, something along these lines (this cuts a few corners so you'd need to improve it)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void testReplicationWithEmptyPartition() throws InterruptedException {\n          \n          \n            \n                @Test\n          \n          \n            \n                public void testReplicationWithEmptyPartition() throws Exception {\n          \n          \n            \n                    String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n          \n          \n            \n                    Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n          \n          \n            \n                        put(\"group.id\", consumerGroupName);\n          \n          \n            \n                        put(\"auto.offset.reset\", \"earliest\");\n          \n          \n            \n                    }};\n          \n          \n            \n            \n          \n          \n            \n                    String topic = \"test-topic-empty\";\n          \n          \n            \n                    primary.kafka().createTopic(topic, NUM_PARTITIONS);\n          \n          \n            \n                    mm2Config = new MirrorMakerConfig(mm2Props);\n          \n          \n            \n                    // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster\n          \n          \n            \n                    produceMessages(primary, topic, \"message-1-\", NUM_PARTITIONS - 1);\n          \n          \n            \n            \n          \n          \n            \n                    // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery\n          \n          \n            \n                    Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic);\n          \n          \n            \n                    consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1));\n          \n          \n            \n                    consumer.close();\n          \n          \n            \n            \n          \n          \n            \n                    waitUntilMirrorMakerIsRunning(backup, mm2Config, \"primary\", \"backup\");\n          \n          \n            \n            \n          \n          \n            \n                    Map<TopicPartition, OffsetAndMetadata> backupOffsets = RemoteClusterUtils.translateOffsets(\n          \n          \n            \n                            mm2Config.clientConfig(\"backup\").adminConfig(),\n          \n          \n            \n                            \"primary\",\n          \n          \n            \n                            consumerGroupName,\n          \n          \n            \n                            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n          \n          \n            \n            \n          \n          \n            \n                    OffsetAndMetadata oam = backupOffsets.get(new TopicPartition(\"primary.\" + topic, NUM_PARTITIONS - 1));\n          \n          \n            \n                    assertNotNull(oam);\n          \n          \n            \n                    assertEquals(0, oam.offset());\n          \n          \n            \n                }", "url": "https://github.com/apache/kafka/pull/8730#discussion_r490338591", "createdAt": "2020-09-17T15:21:47Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -283,49 +296,140 @@ public void testReplication() throws InterruptedException {\n \n         waitForCondition(() -> {\n             try {\n-                return primaryClient.remoteConsumerOffsets(\"consumer-group-1\", \"backup\",\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n                     Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n             } catch (Throwable e) {\n                 return false;\n             }\n         }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n \n-        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(\"consumer-group-1\", \"backup\",\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n                 Duration.ofMillis(CHECKPOINT_DURATION_MS));\n- \n+\n         // Failback consumer group to primary cluster\n-        consumer2 = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", \"consumer-group-1\"));\n-        consumer2.assign(primaryOffsets.keySet());\n-        primaryOffsets.forEach(consumer2::seek);\n-        consumer2.poll(Duration.ofMillis(500));\n-\n-        assertTrue(\"Consumer failedback to zero upstream offset.\", consumer2.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n-        assertTrue(\"Consumer failedback to zero downstream offset.\", consumer2.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n-        assertTrue(\"Consumer failedback beyond expected upstream offset.\", consumer2.position(\n-            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n-        assertTrue(\"Consumer failedback beyond expected downstream offset.\", consumer2.position(\n-            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n-        \n-        consumer2.close();\n-      \n+        primaryConsumer = primary.kafka().createConsumer(consumerProps);\n+        primaryConsumer.assign(allPartitions(\"test-topic-1\", \"backup.test-topic-1\"));\n+        seek(primaryConsumer, primaryOffsets);\n+        consumeAllMessages(primaryConsumer, 0);\n+\n+        assertTrue(\"Consumer failedback to zero upstream offset.\", primaryConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback to zero downstream offset.\", primaryConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback beyond expected upstream offset.\", primaryConsumer.position(\n+            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PER_PARTITION);\n+        assertTrue(\"Consumer failedback beyond expected downstream offset.\", primaryConsumer.position(\n+            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PER_PARTITION);\n+\n+        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> messages2 = consumeAllMessages(primaryConsumer, 0);\n+        // If offset translation was successful we expect no messages to be consumed after failback\n+        assertEquals(\"Data was consumed from partitions: \" + messages2.keySet() + \".\", 0, messages2.size());\n+        primaryConsumer.close();\n+\n         // create more matching topics\n         primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n         backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n \n-        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n-            primary.kafka().produce(\"test-topic-2\", 0, \"key\", \"message-2-\" + i);\n-            backup.kafka().produce(\"test-topic-3\", 0, \"key\", \"message-3-\" + i);\n+        produceMessages(primary, \"test-topic-2\", \"message-3-\", 1);\n+        produceMessages(backup, \"test-topic-3\", \"message-4-\", 1);\n+\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+    }\n+\n+    @Test\n+    public void testReplicationWithEmptyPartition() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 286}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM0MzYxNA==", "bodyText": "We can use Collections.singletonMap() here", "url": "https://github.com/apache/kafka/pull/8730#discussion_r490343614", "createdAt": "2020-09-17T15:28:36Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -136,10 +141,19 @@ public void setup() throws InterruptedException {\n         backup.kafka().createTopic(\"primary.test-topic-1\", 1);\n         backup.kafka().createTopic(\"heartbeats\", 1);\n \n-        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n-            primary.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-1-\" + i);\n-            backup.kafka().produce(\"test-topic-1\", i % NUM_PARTITIONS, \"key\", \"message-2-\" + i);\n-        }\n+        // produce to all partitions of test-topic-1\n+        produceMessages(primary, \"test-topic-1\", \"message-1-\");\n+        produceMessages(backup, \"test-topic-1\", \"message-2-\");\n+\n+        // Generate some consumer activity on both clusters to ensure the checkpoint connector always starts promptly\n+        Map<String, Object> dummyProps = new HashMap<String, Object>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM0NDQwNw==", "bodyText": "latest is the default, why are we setting it?", "url": "https://github.com/apache/kafka/pull/8730#discussion_r490344407", "createdAt": "2020-09-17T15:29:36Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -201,26 +213,24 @@ public void close() {\n \n     @Test\n     public void testReplication() throws InterruptedException {\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 109}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwMTg1MzU5", "url": "https://github.com/apache/kafka/pull/8730#pullrequestreview-500185359", "createdAt": "2020-10-01T09:52:24Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQwOTo1MjoyNFrOHbC8FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQwOTo1NDo1OFrOHbDCRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODEyMTc0OQ==", "bodyText": "Is this left over from debugging?", "url": "https://github.com/apache/kafka/pull/8730#discussion_r498121749", "createdAt": "2020-10-01T09:52:24Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -381,45 +440,46 @@ public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedExceptio\n \n         waitUntilMirrorMakerIsRunning(backup, mm2Config, \"primary\", \"backup\");\n \n-        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n-        Consumer<byte[], byte[]> consumer = backup.kafka().createConsumerAndSubscribeTo(\n-            Collections.singletonMap(\"group.id\", \"consumer-group-1\"), \"primary.test-topic-1\");\n+        // Map<TopicPartition, OffsetAndMetadata> offsets =", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 420}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODEyMzMzMw==", "bodyText": "I wonder if we should pass NUM_PARTITIONS instead of null for the last argument. Then numPartitions can be an int in the other produceMessages() method. WDYT?", "url": "https://github.com/apache/kafka/pull/8730#discussion_r498123333", "createdAt": "2020-10-01T09:54:58Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -429,4 +489,69 @@ private void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n         } catch (Throwable e) {\n         }\n     }\n+\n+    private void produceMessages(EmbeddedConnectCluster cluster, String topicName, String msgPrefix) {\n+        produceMessages(cluster, topicName, msgPrefix, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 488}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e73f16151a7901e7af853b698cb3b7df67ab4f5", "author": {"user": {"login": "asdaraujo", "name": "Andre Araujo"}}, "url": "https://github.com/apache/kafka/commit/9e73f16151a7901e7af853b698cb3b7df67ab4f5", "committedDate": "2020-10-01T17:18:55Z", "message": "KAFKA-10048: Possible data gap for a consumer after a failover when using MM2\n\nEnsure that the MM2 checkpoint mirror task replicates consumer offsets even when they are\nzero to avoid issues with consumers after failovers.\n\nAuthor: Andre Araujo <asdaraujo@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "9e73f16151a7901e7af853b698cb3b7df67ab4f5", "author": {"user": {"login": "asdaraujo", "name": "Andre Araujo"}}, "url": "https://github.com/apache/kafka/commit/9e73f16151a7901e7af853b698cb3b7df67ab4f5", "committedDate": "2020-10-01T17:18:55Z", "message": "KAFKA-10048: Possible data gap for a consumer after a failover when using MM2\n\nEnsure that the MM2 checkpoint mirror task replicates consumer offsets even when they are\nzero to avoid issues with consumers after failovers.\n\nAuthor: Andre Araujo <asdaraujo@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxMjgxNTI2", "url": "https://github.com/apache/kafka/pull/8730#pullrequestreview-501281526", "createdAt": "2020-10-02T16:31:20Z", "commit": {"oid": "9e73f16151a7901e7af853b698cb3b7df67ab4f5"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1183, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}