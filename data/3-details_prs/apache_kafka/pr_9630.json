{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI0Nzg1MjQx", "number": 9630, "title": "KAFKA-10739; Replace EpochEndOffset with automated protocol", "bodyText": "This patch follows up #9547. It refactors KafkaApis, ReplicaManager and Partition to use OffsetForLeaderPartitionResult instead of EpochEndOffset. In the mean time, it removes OffsetsForLeaderEpochRequest#epochsByTopicPartition and OffsetsForLeaderEpochResponse#responses and replaces their usages to use the automated protocol directly. Finally, it removes old constructors in OffsetsForLeaderEpochResponse. The patch relies on existing tests.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-11-20T15:38:38Z", "url": "https://github.com/apache/kafka/pull/9630", "merged": true, "mergeCommit": {"oid": "10364e4b0c1f3757d9291d4ac11978cd5f7d08a3"}, "closed": true, "closedAt": "2020-12-03T17:50:30Z", "author": {"login": "dajac"}, "timelineItems": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdfRytsAFqTUzNjI2NzU0MA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdih3YSgBqjQwNjcwOTkzODE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM2MjY3NTQw", "url": "https://github.com/apache/kafka/pull/9630#pullrequestreview-536267540", "createdAt": "2020-11-23T08:52:01Z", "commit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwODo1MjowMVrOH4D3NA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwOTowNTowMlrOH4ESGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NTU4OA==", "bodyText": "Could we avoid duplicate conversion between scala and java? It can be rewrite by java stream APIs so the  asScala  can be avoid.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r528545588", "createdAt": "2020-11-23T08:52:01Z", "author": {"login": "chia7712"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1862,23 +1864,51 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n   }\n \n-  def lastOffsetForLeaderEpoch(requestedEpochInfo: Map[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData]): Map[TopicPartition, EpochEndOffset] = {\n-    requestedEpochInfo.map { case (tp, partitionData) =>\n-      val epochEndOffset = getPartition(tp) match {\n-        case HostedPartition.Online(partition) =>\n-          partition.lastOffsetForLeaderEpoch(partitionData.currentLeaderEpoch, partitionData.leaderEpoch,\n-            fetchOnlyFromLeader = true)\n-\n-        case HostedPartition.Offline =>\n-          new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None if metadataCache.contains(tp) =>\n-          new EpochEndOffset(Errors.NOT_LEADER_OR_FOLLOWER, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None =>\n-          new EpochEndOffset(Errors.UNKNOWN_TOPIC_OR_PARTITION, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n+  def lastOffsetForLeaderEpoch(\n+    requestedEpochInfo: Seq[OffsetForLeaderTopic]\n+  ): Seq[OffsetForLeaderTopicResult] = {\n+    requestedEpochInfo.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NjA4Mg==", "bodyText": "ditto", "url": "https://github.com/apache/kafka/pull/9630#discussion_r528546082", "createdAt": "2020-11-23T08:52:56Z", "author": {"login": "chia7712"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -2592,25 +2596,39 @@ class KafkaApis(val requestChannel: RequestChannel,\n \n   def handleOffsetForLeaderEpochRequest(request: RequestChannel.Request): Unit = {\n     val offsetForLeaderEpoch = request.body[OffsetsForLeaderEpochRequest]\n-    val requestInfo = offsetForLeaderEpoch.epochsByTopicPartition.asScala\n+    val topics = offsetForLeaderEpoch.data.topics.asScala.toSeq\n \n     // The OffsetsForLeaderEpoch API was initially only used for inter-broker communication and required\n     // cluster permission. With KIP-320, the consumer now also uses this API to check for log truncation\n     // following a leader change, so we also allow topic describe permission.\n-    val (authorizedPartitions, unauthorizedPartitions) =\n+    val (authorizedTopics, unauthorizedTopics) =\n       if (authorize(request.context, CLUSTER_ACTION, CLUSTER, CLUSTER_NAME, logIfDenied = false))\n-        (requestInfo, Map.empty[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData])\n-      else partitionMapByAuthorized(request.context, DESCRIBE, TOPIC, requestInfo)(_.topic)\n+        (topics, Seq.empty[OffsetForLeaderTopic])\n+      else partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, topics)(_.topic)\n+\n+    val endOffsetsForAuthorizedPartitions = replicaManager.lastOffsetForLeaderEpoch(authorizedTopics)\n+    val endOffsetsForUnauthorizedPartitions = unauthorizedTopics.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU1MjQ3Mw==", "bodyText": "Should it be topic.partitions.add(offsetForLeaderPartition.duplicate())?", "url": "https://github.com/apache/kafka/pull/9630#discussion_r528552473", "createdAt": "2020-11-23T09:05:02Z", "author": {"login": "chia7712"}, "path": "core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala", "diffHunk": "@@ -78,7 +80,19 @@ class ReplicaFetcherMockBlockingSend(offsets: java.util.Map[TopicPartition, Epoc\n         callback.foreach(_.apply())\n         epochFetchCount += 1\n         lastUsedOffsetForLeaderEpochVersion = requestBuilder.latestAllowedVersion()\n-        new OffsetsForLeaderEpochResponse(currentOffsets)\n+\n+        val data = new OffsetForLeaderEpochResponseData()\n+        currentOffsets.forEach((tp, offsetForLeaderPartition) => {\n+          var topic = data.topics.find(tp.topic)\n+          if (topic == null) {\n+            topic = new OffsetForLeaderTopicResult()\n+              .setTopic(tp.topic)\n+            data.topics.add(topic)\n+          }\n+          topic.partitions.add(offsetForLeaderPartition.setPartition(tp.partition))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca51ce11e25da1385fdc239c204a0729242249bd"}, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMDY2MDIz", "url": "https://github.com/apache/kafka/pull/9630#pullrequestreview-542066023", "createdAt": "2020-12-01T16:16:27Z", "commit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNjoxNjoyN1rOH80r5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNjoyNzoyMlrOH81MpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUzOTgxMg==", "bodyText": "I'm wondering if it is reasonable to rely on defaults for some of these. I guess there's value in being explicit, but it is a tad vexing to see the same code repeated for a few of these cases.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533539812", "createdAt": "2020-12-01T16:16:27Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1862,23 +1864,51 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n   }\n \n-  def lastOffsetForLeaderEpoch(requestedEpochInfo: Map[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData]): Map[TopicPartition, EpochEndOffset] = {\n-    requestedEpochInfo.map { case (tp, partitionData) =>\n-      val epochEndOffset = getPartition(tp) match {\n-        case HostedPartition.Online(partition) =>\n-          partition.lastOffsetForLeaderEpoch(partitionData.currentLeaderEpoch, partitionData.leaderEpoch,\n-            fetchOnlyFromLeader = true)\n-\n-        case HostedPartition.Offline =>\n-          new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None if metadataCache.contains(tp) =>\n-          new EpochEndOffset(Errors.NOT_LEADER_OR_FOLLOWER, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None =>\n-          new EpochEndOffset(Errors.UNKNOWN_TOPIC_OR_PARTITION, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n+  def lastOffsetForLeaderEpoch(\n+    requestedEpochInfo: Seq[OffsetForLeaderTopic]\n+  ): Seq[OffsetForLeaderTopicResult] = {\n+    requestedEpochInfo.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>\n+        val tp = new TopicPartition(offsetForLeaderTopic.topic, offsetForLeaderPartition.partition)\n+        getPartition(tp) match {\n+          case HostedPartition.Online(partition) =>\n+            val currentLeaderEpochOpt =\n+              if (offsetForLeaderPartition.currentLeaderEpoch == RecordBatch.NO_PARTITION_LEADER_EPOCH)\n+                Optional.empty[Integer]\n+              else\n+                Optional.of[Integer](offsetForLeaderPartition.currentLeaderEpoch)\n+\n+            partition.lastOffsetForLeaderEpoch(\n+              currentLeaderEpochOpt,\n+              offsetForLeaderPartition.leaderEpoch,\n+              fetchOnlyFromLeader = true)\n+\n+          case HostedPartition.Offline =>\n+            new OffsetForLeaderPartitionResult()\n+              .setPartition(offsetForLeaderPartition.partition)\n+              .setErrorCode(Errors.KAFKA_STORAGE_ERROR.code)\n+              .setLeaderEpoch(UNDEFINED_EPOCH)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0MTczOQ==", "bodyText": "Maybe just me, but OffsetForLeaderPartitionResult seems more cumbersome and less descriptive than EpochEndOffset. Would it be worth changing the name in the generated schema?", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533541739", "createdAt": "2020-12-01T16:18:59Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3727,15 +3733,24 @@ public void testOffsetValidationRequestGrouping() {\n             assertTrue(expectedPartitions.size() > 0);\n             allRequestedPartitions.addAll(expectedPartitions);\n \n-            Map<TopicPartition, EpochEndOffset> endOffsets = expectedPartitions.stream().collect(Collectors.toMap(\n-                Function.identity(),\n-                tp -> new EpochEndOffset(Errors.NONE, 4, 0)\n-            ));\n+            OffsetForLeaderEpochResponseData data = new OffsetForLeaderEpochResponseData();\n+            expectedPartitions.forEach(tp -> {\n+                OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+                if (topic == null) {\n+                    topic = new OffsetForLeaderTopicResult().setTopic(tp.topic());\n+                    data.topics().add(topic);\n+                }\n+                topic.partitions().add(new OffsetForLeaderPartitionResult()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0ODE5Ng==", "bodyText": "Not for this patch, but all of this boilerplate we need to build the topic groupings gets annoying. It is such a common case that it might be worth writing a special type that lets the parser construct Map<TopicPartition, Data> directly since that is really what the code wants. Alternatively, maybe we could flatten the schemas and introduce compression.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533548196", "createdAt": "2020-12-01T16:27:22Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3727,15 +3733,24 @@ public void testOffsetValidationRequestGrouping() {\n             assertTrue(expectedPartitions.size() > 0);\n             allRequestedPartitions.addAll(expectedPartitions);\n \n-            Map<TopicPartition, EpochEndOffset> endOffsets = expectedPartitions.stream().collect(Collectors.toMap(\n-                Function.identity(),\n-                tp -> new EpochEndOffset(Errors.NONE, 4, 0)\n-            ));\n+            OffsetForLeaderEpochResponseData data = new OffsetForLeaderEpochResponseData();\n+            expectedPartitions.forEach(tp -> {\n+                OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+                if (topic == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7237f6ce11e4a7d75d929842a478a77695a6fe0b"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzMTEwMzIz", "url": "https://github.com/apache/kafka/pull/9630#pullrequestreview-543110323", "createdAt": "2020-12-02T18:13:18Z", "commit": {"oid": "d192b83e0993500cd0345d3aea48a21cdc9ab190"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxODoxMzoxOFrOH9n7VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxODoxMzoxOFrOH9n7VQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM3OTM0OQ==", "bodyText": "In the case of the error code, I think it might be better to be explicit.", "url": "https://github.com/apache/kafka/pull/9630#discussion_r534379349", "createdAt": "2020-12-02T18:13:18Z", "author": {"login": "hachikuji"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1839,20 +1839,17 @@ private OffsetsForLeaderEpochResponse createLeaderEpochResponse() {\n             .setPartitions(Arrays.asList(\n                 new OffsetForLeaderPartitionResult()\n                     .setPartition(0)\n-                    .setErrorCode(Errors.NONE.code())\n                     .setLeaderEpoch(1)\n                     .setEndOffset(0),\n                 new OffsetForLeaderPartitionResult()\n                     .setPartition(1)\n-                    .setErrorCode(Errors.NONE.code())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d192b83e0993500cd0345d3aea48a21cdc9ab190"}, "originalPosition": 9}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32329a384fc6f7679184e1337dd8bad803b53d71", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/32329a384fc6f7679184e1337dd8bad803b53d71", "committedDate": "2020-12-03T10:14:40Z", "message": "Migrate KafkaApis and ReplicaManager"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7c0b25fa3ed1d3449aea60e13bb564a634430e3", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/f7c0b25fa3ed1d3449aea60e13bb564a634430e3", "committedDate": "2020-12-03T10:39:33Z", "message": "use OffsetForLeaderEpochResponseData.OffsetForLeaderPartitionResult in Partition and change all the related usages"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7839109a8b9e6343403007bfc1bd139e0432ab7", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/d7839109a8b9e6343403007bfc1bd139e0432ab7", "committedDate": "2020-12-03T10:39:33Z", "message": "Remove OffsetsForLeaderEpochRequest#epochsByTopicPartition"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c70dd2a74e6c8fb5e5d8fc632fe2b8801cf71061", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/c70dd2a74e6c8fb5e5d8fc632fe2b8801cf71061", "committedDate": "2020-12-03T10:39:34Z", "message": "remove OffsetsForLeaderEpochResponse#responses"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d23fb390c7fd0beaabbd770ec32932b11b0f2e24", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/d23fb390c7fd0beaabbd770ec32932b11b0f2e24", "committedDate": "2020-12-03T10:39:34Z", "message": "remove old constructors in OffsetsForLeaderEpochResponse"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a89452470216b6dc0574fe94442b577c1148e1e", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/4a89452470216b6dc0574fe94442b577c1148e1e", "committedDate": "2020-12-03T10:48:52Z", "message": "Migrate ReplicaFetcherMockBlockingSend"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "549e6fc77532da5e9a0baaa749f646990f2eb120", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/549e6fc77532da5e9a0baaa749f646990f2eb120", "committedDate": "2020-12-03T10:48:52Z", "message": "fix ReplicaFetcherThreadBenchmark"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ae4479172a2897e716c3d6b78249f802e967e4d6", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/ae4479172a2897e716c3d6b78249f802e967e4d6", "committedDate": "2020-12-03T10:56:34Z", "message": "Move constants from EpochEndOffset to OffsetsForLeaderEpochResponse"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d39f87eaf56a922994d047e6ae0cc668e08a3008", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/d39f87eaf56a922994d047e6ae0cc668e08a3008", "committedDate": "2020-12-03T10:56:34Z", "message": "bye bye EpochEndOffset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "655885b14f4931a2c8660f30005d2e038da5b0d7", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/655885b14f4931a2c8660f30005d2e038da5b0d7", "committedDate": "2020-12-03T10:59:59Z", "message": "clean up the code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71f139c7c01d032363a114c1def753a7e580252d", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/71f139c7c01d032363a114c1def753a7e580252d", "committedDate": "2020-12-03T11:00:00Z", "message": "address review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4008993b492405e41378db53e8135a649f030307", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/4008993b492405e41378db53e8135a649f030307", "committedDate": "2020-12-03T11:03:27Z", "message": "Relies on default values in the schema whereever possible"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "864644ab8dd06e0174010cf134437e5cc5224b50", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/864644ab8dd06e0174010cf134437e5cc5224b50", "committedDate": "2020-12-03T11:51:33Z", "message": "Rename OffsetForLeaderPartitionResult to EpochEndOffset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a9f87a118c051bfc6e6a944ef21db79db9b5068", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/2a9f87a118c051bfc6e6a944ef21db79db9b5068", "committedDate": "2020-12-03T11:57:38Z", "message": "address review"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "50dd6235a7799f08881eb62196030314b2a66fb1", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/50dd6235a7799f08881eb62196030314b2a66fb1", "committedDate": "2020-12-03T08:22:17Z", "message": "address review"}, "afterCommit": {"oid": "2a9f87a118c051bfc6e6a944ef21db79db9b5068", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/2a9f87a118c051bfc6e6a944ef21db79db9b5068", "committedDate": "2020-12-03T11:57:38Z", "message": "address review"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2437, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}