{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc4NDk3OTA5", "number": 8155, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwNTozNToxM1rODiNx_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QyMTo1MjowMVrODo5pdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MjAzOTY2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwNTozNToxM1rOFtWCPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwMDoyNzozOFrOFt0t-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTI2MQ==", "bodyText": "not sure that we should default the time to 0. I think we should let the caller pass in value they want.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383091261", "createdAt": "2020-02-24T05:35:13Z", "author": {"login": "soondenana"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -520,21 +520,22 @@ class GroupMetadataManager(brokerId: Int,\n   def scheduleLoadGroupAndOffsets(offsetsPartition: Int, onGroupLoaded: GroupMetadata => Unit): Unit = {\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n+      val nowInMs = time.milliseconds()\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, nowInMs))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long = 0L): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU4OTQwNA==", "bodyText": "Agree, done.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383589404", "createdAt": "2020-02-25T00:12:34Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -520,21 +520,22 @@ class GroupMetadataManager(brokerId: Int,\n   def scheduleLoadGroupAndOffsets(offsetsPartition: Int, onGroupLoaded: GroupMetadata => Unit): Unit = {\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n+      val nowInMs = time.milliseconds()\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, nowInMs))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long = 0L): Unit = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTI2MQ=="}, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU5Mzk3Ng==", "bodyText": "(note: the reason I had left it as 0 by default was to avoid the extra dummy parameter in all the test calls, added that now)", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383593976", "createdAt": "2020-02-25T00:27:38Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -520,21 +520,22 @@ class GroupMetadataManager(brokerId: Int,\n   def scheduleLoadGroupAndOffsets(offsetsPartition: Int, onGroupLoaded: GroupMetadata => Unit): Unit = {\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n+      val nowInMs = time.milliseconds()\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, nowInMs))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long = 0L): Unit = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTI2MQ=="}, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MjA0MTE0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwNTozNjowM1rOFtWC7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwMDoxMzowMlrOFt0cqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTQzOQ==", "bodyText": "nit: move it after info line. Maybe get rid of variable altogether and put is on the method call itself.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383091439", "createdAt": "2020-02-24T05:36:03Z", "author": {"login": "soondenana"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -520,21 +520,22 @@ class GroupMetadataManager(brokerId: Int,\n   def scheduleLoadGroupAndOffsets(offsetsPartition: Int, onGroupLoaded: GroupMetadata => Unit): Unit = {\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n+      val nowInMs = time.milliseconds()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU4OTU0NA==", "bodyText": "Makes sense, done.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383589544", "createdAt": "2020-02-25T00:13:02Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -520,21 +520,22 @@ class GroupMetadataManager(brokerId: Int,\n   def scheduleLoadGroupAndOffsets(offsetsPartition: Int, onGroupLoaded: GroupMetadata => Unit): Unit = {\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n+      val nowInMs = time.milliseconds()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTQzOQ=="}, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MjA0OTI0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwNTo0MzowM1rOFtWHLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwMDoxNDozNVrOFt0enA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MjUyNg==", "bodyText": "no need to have a default value for the parameter.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383092526", "createdAt": "2020-02-24T05:43:03Z", "author": {"login": "soondenana"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -393,11 +388,16 @@ class TransactionStateManager(brokerId: Int,\n       loadingPartitions.add(partitionAndLeaderEpoch)\n     }\n \n-    def loadTransactions(): Unit = {\n+    def loadTransactions(startTimeInMs: java.lang.Long = 0L): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU5MDA0NA==", "bodyText": "Agree, done.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383590044", "createdAt": "2020-02-25T00:14:35Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -393,11 +388,16 @@ class TransactionStateManager(brokerId: Int,\n       loadingPartitions.add(partitionAndLeaderEpoch)\n     }\n \n-    def loadTransactions(): Unit = {\n+    def loadTransactions(startTimeInMs: java.lang.Long = 0L): Unit = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MjUyNg=="}, "originalCommit": null, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNDA0NjIxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzoyNzo0MVrOF1BTmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxOTowOTozNlrOF1FASQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0MDI1MQ==", "bodyText": "nit: break this into multiple lines.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391140251", "createdAt": "2020-03-11T17:27:41Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,20 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, time.milliseconds()))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long): Unit = {\n     try {\n-      val startMs = time.milliseconds()\n+      val schedulerTimeInMs = time.milliseconds() - startTimeInMs\n       doLoadGroupsAndOffsets(topicPartition, onGroupLoaded)\n-      val endMs = time.milliseconds()\n-      val timeLapse = endMs - startMs\n-      partitionLoadSensor.record(timeLapse, endMs, false)\n-      info(s\"Finished loading offsets and group metadata from $topicPartition in $timeLapse milliseconds.\")\n+      val endTimeInMs = time.milliseconds()\n+      val totalLoadingTimeInMs = time.milliseconds() - startTimeInMs\n+      partitionLoadSensor.record(totalLoadingTimeInMs, endTimeInMs, false)\n+      info(s\"Finished loading offsets and group metadata from $topicPartition in $totalLoadingTimeInMs milliseconds, of which $schedulerTimeInMs milliseconds was spent in the scheduler.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIwMDg0MQ==", "bodyText": "Done.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391200841", "createdAt": "2020-03-11T19:09:36Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,20 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, time.milliseconds()))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long): Unit = {\n     try {\n-      val startMs = time.milliseconds()\n+      val schedulerTimeInMs = time.milliseconds() - startTimeInMs\n       doLoadGroupsAndOffsets(topicPartition, onGroupLoaded)\n-      val endMs = time.milliseconds()\n-      val timeLapse = endMs - startMs\n-      partitionLoadSensor.record(timeLapse, endMs, false)\n-      info(s\"Finished loading offsets and group metadata from $topicPartition in $timeLapse milliseconds.\")\n+      val endTimeInMs = time.milliseconds()\n+      val totalLoadingTimeInMs = time.milliseconds() - startTimeInMs\n+      partitionLoadSensor.record(totalLoadingTimeInMs, endTimeInMs, false)\n+      info(s\"Finished loading offsets and group metadata from $topicPartition in $totalLoadingTimeInMs milliseconds, of which $schedulerTimeInMs milliseconds was spent in the scheduler.\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0MDI1MQ=="}, "originalCommit": {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNDA1ODQ4OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzozMDoxOVrOF1Ba7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxOTo0Mjo0MlrOF1GCIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0MjEyNQ==", "bodyText": "Hmm.. Does this do what's intended? Wouldn't time.milliseconds only be evaluated when the callback is invoked?", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391142125", "createdAt": "2020-03-11T17:30:19Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,20 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, time.milliseconds()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIxNzY5OA==", "bodyText": "True, has to be evaluated before passing in. Done.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391217698", "createdAt": "2020-03-11T19:42:42Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,20 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, time.milliseconds()))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0MjEyNQ=="}, "originalCommit": {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNDA2OTQ0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzozMjozM1rOF1BhTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxOToxMTozM1rOF1FEKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0Mzc1Ng==", "bodyText": "nit: Conventionally, we would drop In and make this schedulerTimeMs. A few more of these in the patch.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391143756", "createdAt": "2020-03-11T17:32:33Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,20 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, time.milliseconds()))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long): Unit = {\n     try {\n-      val startMs = time.milliseconds()\n+      val schedulerTimeInMs = time.milliseconds() - startTimeInMs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIwMTgzNQ==", "bodyText": "Done", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391201835", "createdAt": "2020-03-11T19:11:33Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,20 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, time.milliseconds()))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long): Unit = {\n     try {\n-      val startMs = time.milliseconds()\n+      val schedulerTimeInMs = time.milliseconds() - startTimeInMs", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0Mzc1Ng=="}, "originalCommit": {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNDA4NTQ5OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzozNjoxNFrOF1BrHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxOToxMToyN1rOF1FD_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0NjI2OA==", "bodyText": "nit: maybe we could call this something more descriptive like scheduleStartMs", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391146268", "createdAt": "2020-03-11T17:36:14Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -435,7 +435,8 @@ class TransactionStateManager(brokerId: Int,\n       info(s\"Completed loading transaction metadata from $topicPartition for coordinator epoch $coordinatorEpoch\")\n     }\n \n-    scheduler.schedule(s\"load-txns-for-partition-$topicPartition\", loadTransactions)\n+    val nowInMs = time.milliseconds()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIwMTc4OA==", "bodyText": "Done", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391201788", "createdAt": "2020-03-11T19:11:27Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -435,7 +435,8 @@ class TransactionStateManager(brokerId: Int,\n       info(s\"Completed loading transaction metadata from $topicPartition for coordinator epoch $coordinatorEpoch\")\n     }\n \n-    scheduler.schedule(s\"load-txns-for-partition-$topicPartition\", loadTransactions)\n+    val nowInMs = time.milliseconds()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0NjI2OA=="}, "originalCommit": {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyOTA5MTkxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQyMjoyMTozM1rOF1x8UQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQwNDozNDozN1rOF2XuMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzEwNQ==", "bodyText": "nit: can we use endTimeMs?", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391937105", "createdAt": "2020-03-12T22:21:33Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,23 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      val startTimeMs = time.milliseconds()\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, startTimeMs))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeMs: java.lang.Long): Unit = {\n     try {\n-      val startMs = time.milliseconds()\n+      val schedulerTimeMs = time.milliseconds() - startTimeMs\n       doLoadGroupsAndOffsets(topicPartition, onGroupLoaded)\n-      val endMs = time.milliseconds()\n-      val timeLapse = endMs - startMs\n-      partitionLoadSensor.record(timeLapse, endMs, false)\n-      info(s\"Finished loading offsets and group metadata from $topicPartition in $timeLapse milliseconds.\")\n+      val endTimeMs = time.milliseconds()\n+      val totalLoadingTimeMs = time.milliseconds() - startTimeMs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1NjA4Mw==", "bodyText": "d'oh, yes of course.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r392556083", "createdAt": "2020-03-14T04:34:37Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,23 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      val startTimeMs = time.milliseconds()\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, startTimeMs))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeMs: java.lang.Long): Unit = {\n     try {\n-      val startMs = time.milliseconds()\n+      val schedulerTimeMs = time.milliseconds() - startTimeMs\n       doLoadGroupsAndOffsets(topicPartition, onGroupLoaded)\n-      val endMs = time.milliseconds()\n-      val timeLapse = endMs - startMs\n-      partitionLoadSensor.record(timeLapse, endMs, false)\n-      info(s\"Finished loading offsets and group metadata from $topicPartition in $timeLapse milliseconds.\")\n+      val endTimeMs = time.milliseconds()\n+      val totalLoadingTimeMs = time.milliseconds() - startTimeMs", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzEwNQ=="}, "originalCommit": {"oid": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyOTA5MzE4OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQyMjoyMjowN1rOF1x9Fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQwNDozNTozMlrOF2XuWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzMwMg==", "bodyText": "nit: maybe we call this totalLoadingTimeMs for consistency", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391937302", "createdAt": "2020-03-12T22:22:07Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -393,11 +388,16 @@ class TransactionStateManager(brokerId: Int,\n       loadingPartitions.add(partitionAndLeaderEpoch)\n     }\n \n-    def loadTransactions(): Unit = {\n+    def loadTransactions(startTimeMs: java.lang.Long): Unit = {\n+      val schedulerTime = time.milliseconds() - startTimeMs\n       info(s\"Loading transaction metadata from $topicPartition at epoch $coordinatorEpoch\")\n       validateTransactionTopicPartitionCountIsStable()\n \n       val loadedTransactions = loadTransactionMetadata(topicPartition, coordinatorEpoch)\n+      val endTimeMs = time.milliseconds()\n+      val timeLapse = endTimeMs - startTimeMs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1NjEyMw==", "bodyText": "Done.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r392556123", "createdAt": "2020-03-14T04:35:32Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -393,11 +388,16 @@ class TransactionStateManager(brokerId: Int,\n       loadingPartitions.add(partitionAndLeaderEpoch)\n     }\n \n-    def loadTransactions(): Unit = {\n+    def loadTransactions(startTimeMs: java.lang.Long): Unit = {\n+      val schedulerTime = time.milliseconds() - startTimeMs\n       info(s\"Loading transaction metadata from $topicPartition at epoch $coordinatorEpoch\")\n       validateTransactionTopicPartitionCountIsStable()\n \n       val loadedTransactions = loadTransactionMetadata(topicPartition, coordinatorEpoch)\n+      val endTimeMs = time.milliseconds()\n+      val timeLapse = endTimeMs - startTimeMs", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzMwMg=="}, "originalCommit": {"oid": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyOTA5MzYwOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQyMjoyMjoyMVrOF1x9Xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQwNDozNjozOVrOF2XuoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzM3NA==", "bodyText": "nit: schedulerTimeMs for consistency?", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391937374", "createdAt": "2020-03-12T22:22:21Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -393,11 +388,16 @@ class TransactionStateManager(brokerId: Int,\n       loadingPartitions.add(partitionAndLeaderEpoch)\n     }\n \n-    def loadTransactions(): Unit = {\n+    def loadTransactions(startTimeMs: java.lang.Long): Unit = {\n+      val schedulerTime = time.milliseconds() - startTimeMs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1NjE5Mg==", "bodyText": "Done", "url": "https://github.com/apache/kafka/pull/8155#discussion_r392556192", "createdAt": "2020-03-14T04:36:39Z", "author": {"login": "agam"}, "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -393,11 +388,16 @@ class TransactionStateManager(brokerId: Int,\n       loadingPartitions.add(partitionAndLeaderEpoch)\n     }\n \n-    def loadTransactions(): Unit = {\n+    def loadTransactions(startTimeMs: java.lang.Long): Unit = {\n+      val schedulerTime = time.milliseconds() - startTimeMs", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzM3NA=="}, "originalCommit": {"oid": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0MjE0MTM0OnYy", "diffSide": "RIGHT", "path": "docs/ops.html", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QyMTo1MjowMVrOF3vWvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QyMjo0NjoxN1rOF3wuEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk5MTg3MA==", "bodyText": "I think the short description is ok as it was. But maybe we could add something like this to the long description:\n\nmaximum time, in milliseconds, it took to load offsets and group metadata from the consumer offset partitions loaded in the last 30 seconds (including time spent waiting for the loading task to be scheduled)", "url": "https://github.com/apache/kafka/pull/8155#discussion_r393991870", "createdAt": "2020-03-17T21:52:01Z", "author": {"login": "hachikuji"}, "path": "docs/ops.html", "diffHunk": "@@ -1070,22 +1070,22 @@ <h4><a id=\"remote_jmx\" href=\"#remote_jmx\">Security Considerations for Remote Mon\n             Disconnected|SyncConnected|AuthFailed|ConnectedReadOnly|SaslAuthenticated|Expired.</td>\n       </tr>\n       <tr>\n-        <td>Max time to load group metadata</td>\n+        <td>Max time to load group metadata (including scheduling time)</td>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fec36f2220520f4a241c0b4b0c8d18475bdd284"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDAxNDIyNA==", "bodyText": "Ack, added this to all the long-form descriptions.", "url": "https://github.com/apache/kafka/pull/8155#discussion_r394014224", "createdAt": "2020-03-17T22:46:17Z", "author": {"login": "agam"}, "path": "docs/ops.html", "diffHunk": "@@ -1070,22 +1070,22 @@ <h4><a id=\"remote_jmx\" href=\"#remote_jmx\">Security Considerations for Remote Mon\n             Disconnected|SyncConnected|AuthFailed|ConnectedReadOnly|SaslAuthenticated|Expired.</td>\n       </tr>\n       <tr>\n-        <td>Max time to load group metadata</td>\n+        <td>Max time to load group metadata (including scheduling time)</td>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk5MTg3MA=="}, "originalCommit": {"oid": "6fec36f2220520f4a241c0b4b0c8d18475bdd284"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4071, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}