{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyMDU5MTUx", "number": 8052, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOTowMzo1MlrODdy9FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMjowMzoxMFrODg3o7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNTcwMTMyOnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOTowMzo1MlrOFmmsAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOTowMzo1MlrOFmmsAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAyNDA2NQ==", "bodyText": "I don't think this is the only case that we can abort a transaction. This only handles offset commit failures, but what about send failures?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r376024065", "createdAt": "2020-02-06T19:03:52Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +139,40 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages(int messageProcessed, ConsumerRecords<Integer, String> records)\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            // Begin a new transaction session.\n+            producer.beginTransaction();\n+            for (ConsumerRecord<Integer, String> record : records) {\n+                // Process the record and send to downstream.\n+                ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                producer.send(customizedRecord);\n+            }\n+            Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+            for (TopicPartition topicPartition : consumer.assignment()) {\n+                positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+            }\n+            // Checkpoint the progress by sending offsets to group coordinator broker.\n+            // Under group mode, we must apply consumer group metadata for proper fencing.\n+            if (this.mode.equals(\"groupMode\")) {\n+                producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+            } else {\n+                producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+            }\n+\n+            // Finish the transaction. All sent records should be visible for consumption now.\n+            producer.commitTransaction();\n+            messageProcessed += records.count();\n+        } catch (CommitFailedException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NjYxMjk2OnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwNjozMToyM1rOFpsv4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwNzo1NjoxNFrOFpuHew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTA5MA==", "bodyText": "Seems like we don't allow a way to set the instanceId in this example, so does it make sense to include FencedInstanceIdException?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379269090", "createdAt": "2020-02-14T06:31:23Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI5MTUxNQ==", "bodyText": "It should be configured at consumer level, I could add it to the consumer config.", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379291515", "createdAt": "2020-02-14T07:56:14Z", "author": {"login": "abbccdda"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTA5MA=="}, "originalCommit": null, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NjYxMzgwOnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwNjozMTo1MlrOFpswVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwNzo1NToyOVrOFpuGeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTIwNw==", "bodyText": "Why is InvalidOffsetException fatal?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379269207", "createdAt": "2020-02-14T06:31:52Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -121,46 +130,15 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         }\n \n         int messageProcessed = 0;\n-        boolean abortPreviousTransaction = false;\n         while (messageRemaining.get() > 0) {\n-            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n-            if (records.count() > 0) {\n-                try {\n-                    // Abort previous transaction if instructed.\n-                    if (abortPreviousTransaction) {\n-                        producer.abortTransaction();\n-                        // The consumer fetch position also needs to be reset.\n-                        resetToLastCommittedPositions(consumer);\n-                        abortPreviousTransaction = false;\n-                    }\n-                    // Begin a new transaction session.\n-                    producer.beginTransaction();\n-                    for (ConsumerRecord<Integer, String> record : records) {\n-                        // Process the record and send to downstream.\n-                        ProducerRecord<Integer, String> customizedRecord = transform(record);\n-                        producer.send(customizedRecord);\n-                    }\n-                    Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n-                    for (TopicPartition topicPartition : consumer.assignment()) {\n-                        positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n-                    }\n-                    // Checkpoint the progress by sending offsets to group coordinator broker.\n-                    // Under group mode, we must apply consumer group metadata for proper fencing.\n-                    if (this.mode.equals(\"groupMode\")) {\n-                        producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n-                    } else {\n-                        producer.sendOffsetsToTransaction(positions, consumerGroupId);\n-                    }\n-\n-                    // Finish the transaction. All sent records should be visible for consumption now.\n-                    producer.commitTransaction();\n-                    messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n-                }\n+            try {\n+                messageProcessed += processMessages();\n+            } catch (ProducerFencedException | FencedInstanceIdException | AuthorizationException |\n+                         AuthenticationException | UnsupportedVersionException |\n+                         UnsupportedForMessageFormatException | InvalidTopicException |\n+                         InvalidOffsetException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI5MTI1Ng==", "bodyText": "I guess it could be retriable.", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379291256", "createdAt": "2020-02-14T07:55:29Z", "author": {"login": "abbccdda"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -121,46 +130,15 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         }\n \n         int messageProcessed = 0;\n-        boolean abortPreviousTransaction = false;\n         while (messageRemaining.get() > 0) {\n-            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n-            if (records.count() > 0) {\n-                try {\n-                    // Abort previous transaction if instructed.\n-                    if (abortPreviousTransaction) {\n-                        producer.abortTransaction();\n-                        // The consumer fetch position also needs to be reset.\n-                        resetToLastCommittedPositions(consumer);\n-                        abortPreviousTransaction = false;\n-                    }\n-                    // Begin a new transaction session.\n-                    producer.beginTransaction();\n-                    for (ConsumerRecord<Integer, String> record : records) {\n-                        // Process the record and send to downstream.\n-                        ProducerRecord<Integer, String> customizedRecord = transform(record);\n-                        producer.send(customizedRecord);\n-                    }\n-                    Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n-                    for (TopicPartition topicPartition : consumer.assignment()) {\n-                        positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n-                    }\n-                    // Checkpoint the progress by sending offsets to group coordinator broker.\n-                    // Under group mode, we must apply consumer group metadata for proper fencing.\n-                    if (this.mode.equals(\"groupMode\")) {\n-                        producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n-                    } else {\n-                        producer.sendOffsetsToTransaction(positions, consumerGroupId);\n-                    }\n-\n-                    // Finish the transaction. All sent records should be visible for consumption now.\n-                    producer.commitTransaction();\n-                    messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n-                }\n+            try {\n+                messageProcessed += processMessages();\n+            } catch (ProducerFencedException | FencedInstanceIdException | AuthorizationException |\n+                         AuthenticationException | UnsupportedVersionException |\n+                         UnsupportedForMessageFormatException | InvalidTopicException |\n+                         InvalidOffsetException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTIwNw=="}, "originalCommit": null, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NjYxOTc5OnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwNjozNTo0OFrOFpsz1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQxOTo1Mzo0MFrOFqB7_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDEwMg==", "bodyText": "I think we can leave WakeupException and InterruptException out of this. In both of these cases, we would probably just want the application to close. I think the main thing we want this example to show is the \"normal operating\" exceptions.", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379270102", "createdAt": "2020-02-14T06:35:48Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+                } else {\n+                    producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+                }\n+\n+                // Finish the transaction. All sent records should be visible for consumption now.\n+                producer.commitTransaction();\n+                return records.count();\n+            }\n+        } catch (CommitFailedException | WakeupException | InterruptException | TimeoutException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTYxNjI1NA==", "bodyText": "Sounds good", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379616254", "createdAt": "2020-02-14T19:53:40Z", "author": {"login": "abbccdda"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+                } else {\n+                    producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+                }\n+\n+                // Finish the transaction. All sent records should be visible for consumption now.\n+                producer.commitTransaction();\n+                return records.count();\n+            }\n+        } catch (CommitFailedException | WakeupException | InterruptException | TimeoutException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDEwMg=="}, "originalCommit": null, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NjYyMTA4OnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwNjozNjozOVrOFps0kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQxOTo1NzowNlrOFqCBlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDI5MA==", "bodyText": "Could we do \"group mode\" only in this example? The example doesn't really extend to multiple instances otherwise.", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379270290", "createdAt": "2020-02-14T06:36:39Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTYxNzY4Ng==", "bodyText": "Not sure I follow, we could manually compute the partitions to assign to for the standalone mode?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379617686", "createdAt": "2020-02-14T19:57:06Z", "author": {"login": "abbccdda"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDI5MA=="}, "originalCommit": null, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NjYyOTA5OnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwNjo0MjowNVrOFps5XA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQyMDoxMTozMVrOFqCZBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MTUxNg==", "bodyText": "Hmm.. Is it actually safe to abort following a TimeoutException? I think this would cause an illegal state error in the producer. To handle this correctly, the application should retry the commit.", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379271516", "createdAt": "2020-02-14T06:42:05Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+                } else {\n+                    producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+                }\n+\n+                // Finish the transaction. All sent records should be visible for consumption now.\n+                producer.commitTransaction();\n+                return records.count();\n+            }\n+        } catch (CommitFailedException | WakeupException | InterruptException | TimeoutException e) {\n+            // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n+            producer.abortTransaction();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTYyMzY4NA==", "bodyText": "Or we shouldn't handle the timeout, as we always rely on max_block to ensure the request is successful?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379623684", "createdAt": "2020-02-14T20:11:31Z", "author": {"login": "abbccdda"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+                } else {\n+                    producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+                }\n+\n+                // Finish the transaction. All sent records should be visible for consumption now.\n+                producer.commitTransaction();\n+                return records.count();\n+            }\n+        } catch (CommitFailedException | WakeupException | InterruptException | TimeoutException e) {\n+            // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n+            producer.abortTransaction();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MTUxNg=="}, "originalCommit": null, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1Nzc5NjUyOnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMToyMDo1NVrOFrS1ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMToyMDo1NVrOFrS1ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk0MTcwNg==", "bodyText": "For the purpose of understanding EOS, the main exceptions that are worth calling out are ProducerFencedException and FencedInstanceIdException. I would suggest we write the example like this:\ntry {\n   ...\n   producer.commitTransaction;\n} catch (ProducerFencedException e) {\n  throw KafkaException(\"The transactional.id $transactionalId has been claimed by another process\");\n} catch (FencedInstanceIdException e) {\n  throw KafkaException(\"The group.instance.id $instanceId has been claimed by another process\");\n} catch (KafkaException e) {\n  // If we have not been fenced, try to abort the transaction and continue. This will raise immediately\n  // if the producer has hit a fatal error.\n  producer.abortTransaction();\n}", "url": "https://github.com/apache/kafka/pull/8052#discussion_r380941706", "createdAt": "2020-02-18T21:20:55Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -155,12 +157,19 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n                     // Finish the transaction. All sent records should be visible for consumption now.\n                     producer.commitTransaction();\n                     messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n                 }\n+            } catch (CommitFailedException | InvalidOffsetException e) {\n+                // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n+                // Note that abort transaction call could also throw fatal exceptions such as producer fenced.\n+                producer.abortTransaction();\n+\n+                // The consumer fetch position also needs to be reset.\n+                resetToLastCommittedPositions(consumer);\n+            } catch (ProducerFencedException | FencedInstanceIdException | AuthorizationException |", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1NzkwNTYyOnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMTo1NjoyMVrOFrT50g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMTo1NjoyMVrOFrT50g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1OTE4Ng==", "bodyText": "How about this?\n// The consumer fetch position needs to be restored to the committed offset before the transaction started", "url": "https://github.com/apache/kafka/pull/8052#discussion_r380959186", "createdAt": "2020-02-18T21:56:21Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -155,13 +151,20 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n                     // Finish the transaction. All sent records should be visible for consumption now.\n                     producer.commitTransaction();\n                     messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n                 }\n+            } catch (ProducerFencedException e) {\n+                throw new KafkaException(String.format(\"The transactional.id %s has been claimed by another process\", transactionalId));\n+            } catch (FencedInstanceIdException e) {\n+                throw new KafkaException(String.format(\"The group.instance.id %s has been claimed by another process\", groupInstanceId));\n+            } catch (KafkaException e) {\n+                // If we have not been fenced, try to abort the transaction and continue. This will raise immediately\n+                // if the producer has hit a fatal error.\n+                producer.abortTransaction();\n+\n+                // The consumer fetch position also needs to be reset.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1NzkyNjIzOnYy", "diffSide": "RIGHT", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMjowMzoxMFrOFrUGww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMjowMzoxMFrOFrUGww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2MjQ5OQ==", "bodyText": "I had a question before about the \"groupMode.\" Do we need to include this in the example? I think it would be fine to let this example use the latest recommended pattern and include a comment about it.\nAlso, could we have a helper for the boilerplate conversion to Map<TopicPartition, OffsetAndMetadata>` since it clutters up the core logic?", "url": "https://github.com/apache/kafka/pull/8052#discussion_r380962499", "createdAt": "2020-02-18T22:03:10Z", "author": {"login": "hachikuji"}, "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -155,13 +151,20 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n                     // Finish the transaction. All sent records should be visible for consumption now.\n                     producer.commitTransaction();\n                     messageProcessed += records.count();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4205, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}