{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQyOTEwMjIz", "number": 9769, "title": "KAFKA-10774; Support Describe topic using topic IDs", "bodyText": "More detailed description of your change\n\nAdd topicNames in MetadataCache and alter KafkaApis.handleTopicMetadataRequest according to the KIP\nAdd method describeTopics(TopicCollection) in KafkaAdminClient, similar to describeTopics\nChange DescribeTopicsResult to support TopicId\n\nSummary of testing strategy (including rationale)\nTest locally, here is some result:\nNew server + new Client\nkafka-topics.sh --describe --zookeeper localhost:2181 --topic-id a-Paxi-LSka9sIVy9UFp_Q\nException in thread \"main\" java.lang.IllegalArgumentException: --topic-id can used only with --bootstrap-server\n\nkafka-topics.sh --describe --bootstrap-server localhost:9092 --topic-id a-Paxi-LSka9sIVy9UFp_Q\nTopic: old-version-topic\tTopicId: a-Paxi-LSka9sIVy9UFp_Q\tPartitionCount: 2\tReplicationFactor: 1\tConfigs: segment.bytes=1073741824\n\tTopic: old-version-topic\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n\tTopic: old-version-topic\tPartition: 1\tLeader: 0\tReplicas: 0\tIsr: 0\n\nOld Server + new Client\nkafka-topics.sh --describe --bootstrap-server localhost:9092 --topic-id a-Paxi-LSka9sIVy9UFp_Q\nError while executing topic command : TopicId a-Paxi-LSka9sIVy9UFp_Q not found.\n\nNew server + old client\nkafka-topics.sh --describe --bootstrap-server localhost:9092 --topic-id a-Paxi-LSka9sIVy9UFp_Q\nException in thread \"main\" joptsimple.UnrecognizedOptionException: topic-id is not a recognized option\n\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-12-19T10:42:50Z", "url": "https://github.com/apache/kafka/pull/9769", "merged": true, "mergeCommit": {"oid": "1d22b0d70686aef5689b775ea2ea7610a37f3e8c"}, "closed": true, "closedAt": "2021-08-28T08:00:37Z", "author": {"login": "dengziming"}, "timelineItems": {"totalCount": 80, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdn0tH_AFqTU1NTk3MzE1OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABe4vCrwgFqTc0MTAwMDAwNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1OTczMTU4", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-555973158", "createdAt": "2020-12-19T22:44:37Z", "commit": {"oid": "e4c8a228182a54d07f9e3b6bd91cabf89b688b23"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOVQyMjo0NDozOFrOII_DIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOVQyMjo0NDozOFrOII_DIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjI5MjUxMw==", "bodyText": "nit: typo \"dose\" -> \"does\" I also had a slightly different message in my PR that implements this error. Either one is fine. https://github.com/apache/kafka/pull/9684/files", "url": "https://github.com/apache/kafka/pull/9769#discussion_r546292513", "createdAt": "2020-12-19T22:44:38Z", "author": {"login": "jolshan"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/Errors.java", "diffHunk": "@@ -343,7 +344,8 @@\n     INVALID_UPDATE_VERSION(95, \"The given update version was invalid.\", InvalidUpdateVersionException::new),\n     FEATURE_UPDATE_FAILED(96, \"Unable to update finalized features due to an unexpected server error.\", FeatureUpdateFailedException::new),\n     PRINCIPAL_DESERIALIZATION_FAILURE(97, \"Request principal deserialization failed during forwarding. \" +\n-         \"This indicates an internal error on the broker cluster security setup.\", PrincipalDeserializationException::new);\n+         \"This indicates an internal error on the broker cluster security setup.\", PrincipalDeserializationException::new),\n+    UNKNOWN_TOPIC_ID(98, \"The topic ID dose not exist\", UnknownTopicIdException::new);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4c8a228182a54d07f9e3b6bd91cabf89b688b23"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2NTc4MDYz", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-556578063", "createdAt": "2020-12-21T18:24:27Z", "commit": {"oid": "6018b4b98bccad2d8507936e2f6af8441e5121c9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODoyNDoyOFrOIJhsOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODoyNDoyOFrOIJhsOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MDA5MQ==", "bodyText": "I think this parameterization is a pretty good idea, and I can add it to my delete topics PR. But if we are going to change the public API, we should update the KIP and potentially update the mailing list with the changes.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r546860091", "createdAt": "2020-12-21T18:24:28Z", "author": {"login": "jolshan"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -31,29 +31,29 @@\n  * The API of this class is evolving, see {@link Admin} for details.\n  */\n @InterfaceStability.Evolving\n-public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+public class DescribeTopicsResult<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6018b4b98bccad2d8507936e2f6af8441e5121c9"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2NTgxMTYx", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-556581161", "createdAt": "2020-12-21T18:30:00Z", "commit": {"oid": "6018b4b98bccad2d8507936e2f6af8441e5121c9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODozMDowMFrOIJh2bA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODozMDowMFrOIJh2bA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MjcwMA==", "bodyText": "nit: javadoc comment missing", "url": "https://github.com/apache/kafka/pull/9769#discussion_r546862700", "createdAt": "2020-12-21T18:30:00Z", "author": {"login": "jolshan"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -287,7 +288,23 @@ default DescribeTopicsResult describeTopics(Collection<String> topicNames) {\n      * @param options    The options to use when describing the topic.\n      * @return The DescribeTopicsResult.\n      */\n-    DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options);\n+    DescribeTopicsResult<String> describeTopics(Collection<String> topicNames, DescribeTopicsOptions options);\n+\n+    /**\n+     * Describe some topics in the cluster by their topicId, with the default options.\n+     * <p>\n+     * This is a convenience method for {@link #describeTopicsWithIds(Collection, DescribeTopicsOptions)} with\n+     * default options. See the overload for more details.\n+     *\n+     * @param topicIds The topicIds of the topics to describe.\n+     * @return The DescribeTopicsResult.\n+     */\n+    default DescribeTopicsResult<Uuid> describeTopicsWithIds(Collection<Uuid> topicIds) {\n+        return describeTopicsWithIds(topicIds, new DescribeTopicsOptions());\n+    }\n+\n+    DescribeTopicsResult<Uuid> describeTopicsWithIds(Collection<Uuid> topicIds, DescribeTopicsOptions options);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6018b4b98bccad2d8507936e2f6af8441e5121c9"}, "originalPosition": 37}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6018b4b98bccad2d8507936e2f6af8441e5121c9", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/6018b4b98bccad2d8507936e2f6af8441e5121c9", "committedDate": "2020-12-21T10:51:54Z", "message": "Merge branch 'trunk' into KAFKA-10774"}, "afterCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/73a8ea197c261f7ef44d777665d0bc879e4e595e", "committedDate": "2021-01-02T01:22:47Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\n\nresolve edge conditions\n\nresolve edge conditions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxMzkzMDA2", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-561393006", "createdAt": "2021-01-04T22:28:50Z", "commit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQyMjoyODo1MFrOIODbFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQyMjoyODo1MFrOIODbFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTYwNzA2MQ==", "bodyText": "Hey, with the new addition of gating topic IDs behind IBP 2.8, can we do a check of the interbroker protocol version in this method and if it is not at least 2.8, return with UNSUPPORTED_VERSION error. There is a method in the 2.8 PR to easily get this information: KafkaConfig.usesTopicId\nHere's the other PR for reference: #9814\nHere's the KIP with the updated error behavior: https://cwiki.apache.org/confluence/display/KAFKA/KIP-516%3A+Topic+Identifiers#KIP516:TopicIdentifiers-AdminandKafkaAdminClient\nI will update the delete topics logic to follow this behavior as well.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r551607061", "createdAt": "2021-01-04T22:28:50Z", "author": {"login": "jolshan"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1238,8 +1239,21 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY2MjA4NzU4", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-566208758", "createdAt": "2021-01-12T12:12:05Z", "commit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxMjoxMjowNVrOIR-x1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxMjo1MDo0NVrOISAFog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTcyNTI2OQ==", "bodyText": "We need to keep the Admin API backwards compatible. An application that was written using the 2.7.0 should not break if it is compiled with a 2.8.0 clients jar. You can always add an internal class with shared code to avoid duplication, but the public API itself needs to remain compatible.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555725269", "createdAt": "2021-01-12T12:12:05Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -31,29 +31,29 @@\n  * The API of this class is evolving, see {@link Admin} for details.\n  */\n @InterfaceStability.Evolving\n-public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+public class DescribeTopicsResult<T> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MDA5MQ=="}, "originalCommit": {"oid": "6018b4b98bccad2d8507936e2f6af8441e5121c9"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTczMDc1NQ==", "bodyText": "We seemed to have removed a constructor?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555730755", "createdAt": "2021-01-12T12:21:47Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java", "diffHunk": "@@ -62,25 +62,25 @@ public int hashCode() {\n      *                   leadership and replica information for that partition.\n      */\n     public TopicDescription(String name, boolean internal, List<TopicPartitionInfo> partitions) {\n-        this(name, internal, partitions, Collections.emptySet());\n+        this(name, Uuid.ZERO_UUID, internal, partitions);\n+    }\n+\n+    public TopicDescription(String name, Uuid topicId, boolean internal, List<TopicPartitionInfo> partitions) {\n+        this(name, topicId, internal, partitions, Collections.emptySet());\n     }\n \n     /**\n      * Create an instance with the specified parameters.\n      *\n      * @param name The topic name\n+     * @param topicId the topic id\n      * @param internal Whether the topic is internal to Kafka\n      * @param partitions A list of partitions where the index represents the partition id and the element contains\n      *                   leadership and replica information for that partition.\n      * @param authorizedOperations authorized operations for this topic, or null if this is not known.\n      */\n-    public TopicDescription(String name, boolean internal, List<TopicPartitionInfo> partitions,\n+    public TopicDescription(String name, Uuid topicId, boolean internal, List<TopicPartitionInfo> partitions,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTczODUwOA==", "bodyText": "Couldn't unsupported version mean that topic ids are not supported (rather than disablingTopicCreation)? In any case, you can't create topics with topic ids right?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555738508", "createdAt": "2021-01-12T12:36:03Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -1816,7 +1823,103 @@ void handleFailure(Throwable throwable) {\n         if (!topicNamesList.isEmpty()) {\n             runnable.call(call, now);\n         }\n-        return new DescribeTopicsResult(new HashMap<>(topicFutures));\n+        return new DescribeTopicsResult<>(new HashMap<>(topicFutures));\n+    }\n+\n+    @Override\n+    public DescribeTopicsResult<Uuid> describeTopicsWithIds(Collection<Uuid> topicIds, DescribeTopicsOptions options) {\n+\n+        final Map<Uuid, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicIds.size());\n+        final List<Uuid> topicIdsList = new ArrayList<>();\n+        for (Uuid topicId : topicIds) {\n+            if (topicIdIsUnrepresentable(topicId)) {\n+                KafkaFutureImpl<TopicDescription> future = new KafkaFutureImpl<>();\n+                future.completeExceptionally(new InvalidTopicException(\"The given topic id '\" +\n+                        topicId + \"' cannot be represented in a request.\"));\n+                topicFutures.put(topicId, future);\n+            } else if (!topicFutures.containsKey(topicId)) {\n+                topicFutures.put(topicId, new KafkaFutureImpl<>());\n+                topicIdsList.add(topicId);\n+            }\n+        }\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeTopicsWithIds\", calcDeadlineMs(now, options.timeoutMs()),\n+                new LeastLoadedNodeProvider()) {\n+\n+            private boolean supportsDisablingTopicCreation = true;\n+\n+            @Override\n+            MetadataRequest.Builder createRequest(int timeoutMs) {\n+                if (supportsDisablingTopicCreation)\n+                    return new MetadataRequest.Builder(new MetadataRequestData()\n+                            .setTopics(convertTopicIdsToMetadataRequestTopic(topicIdsList))\n+                            .setAllowAutoTopicCreation(false)\n+                            .setIncludeTopicAuthorizedOperations(options.includeAuthorizedOperations()));\n+                else\n+                    return MetadataRequest.Builder.allTopics();\n+            }\n+\n+            @Override\n+            void handleResponse(AbstractResponse abstractResponse) {\n+                MetadataResponse response = (MetadataResponse) abstractResponse;\n+                // Handle server responses for particular topics.\n+                Cluster cluster = response.cluster();\n+                Map<String, Errors> errors = response.errors();\n+                for (Map.Entry<Uuid, KafkaFutureImpl<TopicDescription>> entry : topicFutures.entrySet()) {\n+                    Uuid topicId = entry.getKey();\n+                    KafkaFutureImpl<TopicDescription> future = entry.getValue();\n+\n+                    String topicName = cluster.topicName(topicId);\n+                    if (topicName == null) {\n+                        future.completeExceptionally(new UnknownTopicIdException(\"TopicId \" + topicId + \" not found.\"));\n+                        continue;\n+                    }\n+                    Errors topicError = errors.get(topicName);\n+                    if (topicError != null) {\n+                        future.completeExceptionally(topicError.exception());\n+                        continue;\n+                    }\n+\n+                    boolean isInternal = cluster.internalTopics().contains(topicName);\n+                    List<PartitionInfo> partitionInfos = cluster.partitionsForTopic(topicName);\n+                    List<TopicPartitionInfo> partitions = new ArrayList<>(partitionInfos.size());\n+                    for (PartitionInfo partitionInfo : partitionInfos) {\n+                        TopicPartitionInfo topicPartitionInfo = new TopicPartitionInfo(\n+                                partitionInfo.partition(), leader(partitionInfo), Arrays.asList(partitionInfo.replicas()),\n+                                Arrays.asList(partitionInfo.inSyncReplicas()));\n+                        partitions.add(topicPartitionInfo);\n+                    }\n+                    partitions.sort(Comparator.comparingInt(TopicPartitionInfo::partition));\n+                    TopicDescription topicDescription = new TopicDescription(topicName, topicId, isInternal, partitions,\n+                            validAclOperations(response.topicAuthorizedOperations(topicName).get()));\n+                    future.complete(topicDescription);\n+                }\n+            }\n+\n+            private Node leader(PartitionInfo partitionInfo) {\n+                if (partitionInfo.leader() == null || partitionInfo.leader().id() == Node.noNode().id())\n+                    return null;\n+                return partitionInfo.leader();\n+            }\n+\n+            @Override\n+            boolean handleUnsupportedVersionException(UnsupportedVersionException exception) {\n+                if (supportsDisablingTopicCreation) {\n+                    supportsDisablingTopicCreation = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0MDE5OQ==", "bodyText": "What happens if name is null - won't we quietly ignore? Would it be better to throw an exception since we don't want anyone using this with topic ids?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555740199", "createdAt": "2021-01-12T12:39:04Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,7 +91,7 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n-            if (metadata.errorCode() != Errors.NONE.code())\n+            if (metadata.errorCode() != Errors.NONE.code() && metadata.name() != null)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0MTAxMA==", "bodyText": "Do we want the option to test with and without topic ids?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555741010", "createdAt": "2021-01-12T12:40:36Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/MockAdminClient.java", "diffHunk": "@@ -206,6 +209,8 @@ synchronized public void addTopic(boolean internal,\n                 logDirs.add(brokerLogDirs.get(partition.leader().id()).get(0));\n             }\n         }\n+        Uuid topicId = Uuid.randomUuid();\n+        topicIds.put(name, topicId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0MzM1Mg==", "bodyText": "We have removed this check?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555743352", "createdAt": "2021-01-12T12:44:48Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -742,10 +760,16 @@ object TopicCommand extends Logging {\n       if (has(bootstrapServerOpt) == has(zkConnectOpt))\n         throw new IllegalArgumentException(\"Only one of --bootstrap-server or --zookeeper must be specified\")\n \n+      if (has(topicIdOpt) && has(zkConnectOpt)) {\n+        throw new IllegalArgumentException(\"--topic-id can used only with --bootstrap-server\")\n+      }\n+\n       if (!has(bootstrapServerOpt))\n         CommandLineUtils.checkRequiredArgs(parser, options, zkConnectOpt)\n-      if(has(describeOpt) && has(ifExistsOpt))\n-        CommandLineUtils.checkRequiredArgs(parser, options, topicOpt)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0NjcyMg==", "bodyText": "topics may also be empty?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555746722", "createdAt": "2021-01-12T12:50:45Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -313,42 +313,54 @@ object TopicCommand extends Logging {\n     }\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n-      val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+      val topicId = opts.topicId.map(Uuid.fromString).filter(_ != Uuid.ZERO_UUID)\n+      val topics = if (topicId.isEmpty)\n+        getTopics(opts.topic, opts.excludeInternalTopics)\n+      else\n+        Seq()\n \n-      if (topics.nonEmpty) {\n-        val allConfigs = adminClient.describeConfigs(topics.map(new ConfigResource(Type.TOPIC, _)).asJavaCollection).values()\n-        val liveBrokers = adminClient.describeCluster().nodes().get().asScala.map(_.id())\n-        val topicDescriptions = adminClient.describeTopics(topics.asJavaCollection).all().get().values().asScala\n-        val describeOptions = new DescribeOptions(opts, liveBrokers.toSet)\n-        val topicPartitions = topicDescriptions\n-          .flatMap(td => td.partitions.iterator().asScala.map(p => new TopicPartition(td.name(), p.partition())))\n-          .toSet.asJava\n-        val reassignments = listAllReassignments(topicPartitions)\n-\n-        for (td <- topicDescriptions) {\n-          val topicName = td.name\n-          val topicId = td.topicId()\n-          val config = allConfigs.get(new ConfigResource(Type.TOPIC, topicName)).get()\n-          val sortedPartitions = td.partitions.asScala.sortBy(_.partition)\n-\n-          if (describeOptions.describeConfigs) {\n-            val hasNonDefault = config.entries().asScala.exists(!_.isDefault)\n-            if (!opts.reportOverriddenConfigs || hasNonDefault) {\n-              val numPartitions = td.partitions().size\n-              val firstPartition = td.partitions.iterator.next()\n-              val reassignment = reassignments.get(new TopicPartition(td.name, firstPartition.partition))\n-              val topicDesc = TopicDescription(topicName, topicId, numPartitions, getReplicationFactor(firstPartition, reassignment), config, markedForDeletion = false)\n-              topicDesc.printDescription()\n-            }\n+      if (topicId.isEmpty)\n+        ensureTopicExists(topics, opts.topic, !opts.ifExists)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "originalPosition": 38}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/73a8ea197c261f7ef44d777665d0bc879e4e595e", "committedDate": "2021-01-02T01:22:47Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\n\nresolve edge conditions\n\nresolve edge conditions"}, "afterCommit": {"oid": "0e252600f78836a1fb48539f4d234fa78c01755f", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/0e252600f78836a1fb48539f4d234fa78c01755f", "committedDate": "2021-01-13T00:00:08Z", "message": "wip"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0e252600f78836a1fb48539f4d234fa78c01755f", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/0e252600f78836a1fb48539f4d234fa78c01755f", "committedDate": "2021-01-13T00:00:08Z", "message": "wip"}, "afterCommit": {"oid": "5df1f32a45a7b4218631f750d56d431ad3e7e53f", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/5df1f32a45a7b4218631f750d56d431ad3e7e53f", "committedDate": "2021-01-13T14:41:27Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nfix"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "311f488adb77849b50af552ac5c1549e542dc554", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/311f488adb77849b50af552ac5c1549e542dc554", "committedDate": "2021-01-13T15:26:47Z", "message": "resolve comments"}, "afterCommit": {"oid": "4e20a8d3550f7b0f0258dbea0ae310cf5bb70063", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/4e20a8d3550f7b0f0258dbea0ae310cf5bb70063", "committedDate": "2021-01-21T03:58:44Z", "message": "Gate  topic IDs behind IBP 2.8.1"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczNzgwMDQ1", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-573780045", "createdAt": "2021-01-21T22:13:04Z", "commit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "state": "COMMENTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQyMjoxMzowNFrOIYL6Tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQyMjo1NjowM1rOIYNHbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzMTg4Nw==", "bodyText": "Could we move the code shared between describeTopics and describeTopicsWithIds to a common private method?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562231887", "createdAt": "2021-01-21T22:13:04Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -1822,6 +1829,88 @@ void handleFailure(Throwable throwable) {\n         return new DescribeTopicsResult(new HashMap<>(topicFutures));\n     }\n \n+    @Override\n+    public DescribeTopicsResultWithIds describeTopicsWithIds(Collection<Uuid> topicIds, DescribeTopicsOptions options) {\n+\n+        final Map<Uuid, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicIds.size());\n+        final List<Uuid> topicIdsList = new ArrayList<>();\n+        for (Uuid topicId : topicIds) {\n+            if (topicIdIsUnrepresentable(topicId)) {\n+                KafkaFutureImpl<TopicDescription> future = new KafkaFutureImpl<>();\n+                future.completeExceptionally(new InvalidTopicException(\"The given topic id '\" +\n+                        topicId + \"' cannot be represented in a request.\"));\n+                topicFutures.put(topicId, future);\n+            } else if (!topicFutures.containsKey(topicId)) {\n+                topicFutures.put(topicId, new KafkaFutureImpl<>());\n+                topicIdsList.add(topicId);\n+            }\n+        }\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeTopicsWithIds\", calcDeadlineMs(now, options.timeoutMs()),\n+                new LeastLoadedNodeProvider()) {\n+\n+            @Override\n+            MetadataRequest.Builder createRequest(int timeoutMs) {\n+                return new MetadataRequest.Builder(new MetadataRequestData()\n+                        .setTopics(convertTopicIdsToMetadataRequestTopic(topicIdsList))\n+                        .setAllowAutoTopicCreation(false)\n+                        .setIncludeTopicAuthorizedOperations(options.includeAuthorizedOperations()));\n+            }\n+\n+            @Override\n+            void handleResponse(AbstractResponse abstractResponse) {\n+                MetadataResponse response = (MetadataResponse) abstractResponse;\n+                // Handle server responses for particular topics.\n+                Cluster cluster = response.cluster();\n+                Map<Uuid, Errors> errors = response.errorsByTopicId();\n+                for (Map.Entry<Uuid, KafkaFutureImpl<TopicDescription>> entry : topicFutures.entrySet()) {\n+                    Uuid topicId = entry.getKey();\n+                    KafkaFutureImpl<TopicDescription> future = entry.getValue();\n+\n+                    String topicName = cluster.topicName(topicId);\n+                    if (topicName == null) {\n+                        future.completeExceptionally(new UnknownTopicIdException(\"TopicId \" + topicId + \" not found.\"));\n+                        continue;\n+                    }\n+                    Errors topicError = errors.get(topicId);\n+                    if (topicError != null) {\n+                        future.completeExceptionally(topicError.exception());\n+                        continue;\n+                    }\n+\n+                    boolean isInternal = cluster.internalTopics().contains(topicName);\n+                    List<PartitionInfo> partitionInfos = cluster.partitionsForTopic(topicName);\n+                    List<TopicPartitionInfo> partitions = new ArrayList<>(partitionInfos.size());\n+                    for (PartitionInfo partitionInfo : partitionInfos) {\n+                        TopicPartitionInfo topicPartitionInfo = new TopicPartitionInfo(\n+                                partitionInfo.partition(), leader(partitionInfo), Arrays.asList(partitionInfo.replicas()),\n+                                Arrays.asList(partitionInfo.inSyncReplicas()));\n+                        partitions.add(topicPartitionInfo);\n+                    }\n+                    partitions.sort(Comparator.comparingInt(TopicPartitionInfo::partition));\n+                    TopicDescription topicDescription = new TopicDescription(topicName, isInternal, partitions,\n+                            validAclOperations(response.topicAuthorizedOperations(topicName).get()), topicId);\n+                    future.complete(topicDescription);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzMjE4Mw==", "bodyText": "This could be shared with describeTopics as well?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562232183", "createdAt": "2021-01-21T22:13:42Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -1822,6 +1829,88 @@ void handleFailure(Throwable throwable) {\n         return new DescribeTopicsResult(new HashMap<>(topicFutures));\n     }\n \n+    @Override\n+    public DescribeTopicsResultWithIds describeTopicsWithIds(Collection<Uuid> topicIds, DescribeTopicsOptions options) {\n+\n+        final Map<Uuid, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicIds.size());\n+        final List<Uuid> topicIdsList = new ArrayList<>();\n+        for (Uuid topicId : topicIds) {\n+            if (topicIdIsUnrepresentable(topicId)) {\n+                KafkaFutureImpl<TopicDescription> future = new KafkaFutureImpl<>();\n+                future.completeExceptionally(new InvalidTopicException(\"The given topic id '\" +\n+                        topicId + \"' cannot be represented in a request.\"));\n+                topicFutures.put(topicId, future);\n+            } else if (!topicFutures.containsKey(topicId)) {\n+                topicFutures.put(topicId, new KafkaFutureImpl<>());\n+                topicIdsList.add(topicId);\n+            }\n+        }\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeTopicsWithIds\", calcDeadlineMs(now, options.timeoutMs()),\n+                new LeastLoadedNodeProvider()) {\n+\n+            @Override\n+            MetadataRequest.Builder createRequest(int timeoutMs) {\n+                return new MetadataRequest.Builder(new MetadataRequestData()\n+                        .setTopics(convertTopicIdsToMetadataRequestTopic(topicIdsList))\n+                        .setAllowAutoTopicCreation(false)\n+                        .setIncludeTopicAuthorizedOperations(options.includeAuthorizedOperations()));\n+            }\n+\n+            @Override\n+            void handleResponse(AbstractResponse abstractResponse) {\n+                MetadataResponse response = (MetadataResponse) abstractResponse;\n+                // Handle server responses for particular topics.\n+                Cluster cluster = response.cluster();\n+                Map<Uuid, Errors> errors = response.errorsByTopicId();\n+                for (Map.Entry<Uuid, KafkaFutureImpl<TopicDescription>> entry : topicFutures.entrySet()) {\n+                    Uuid topicId = entry.getKey();\n+                    KafkaFutureImpl<TopicDescription> future = entry.getValue();\n+\n+                    String topicName = cluster.topicName(topicId);\n+                    if (topicName == null) {\n+                        future.completeExceptionally(new UnknownTopicIdException(\"TopicId \" + topicId + \" not found.\"));\n+                        continue;\n+                    }\n+                    Errors topicError = errors.get(topicId);\n+                    if (topicError != null) {\n+                        future.completeExceptionally(topicError.exception());\n+                        continue;\n+                    }\n+\n+                    boolean isInternal = cluster.internalTopics().contains(topicName);\n+                    List<PartitionInfo> partitionInfos = cluster.partitionsForTopic(topicName);\n+                    List<TopicPartitionInfo> partitions = new ArrayList<>(partitionInfos.size());\n+                    for (PartitionInfo partitionInfo : partitionInfos) {\n+                        TopicPartitionInfo topicPartitionInfo = new TopicPartitionInfo(\n+                                partitionInfo.partition(), leader(partitionInfo), Arrays.asList(partitionInfo.replicas()),\n+                                Arrays.asList(partitionInfo.inSyncReplicas()));\n+                        partitions.add(topicPartitionInfo);\n+                    }\n+                    partitions.sort(Comparator.comparingInt(TopicPartitionInfo::partition));\n+                    TopicDescription topicDescription = new TopicDescription(topicName, isInternal, partitions,\n+                            validAclOperations(response.topicAuthorizedOperations(topicName).get()), topicId);\n+                    future.complete(topicDescription);\n+                }\n+            }\n+\n+            private Node leader(PartitionInfo partitionInfo) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzMzIzNQ==", "bodyText": "Do we really need this constructor in the public class? We could just use the one below?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562233235", "createdAt": "2021-01-21T22:15:55Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java", "diffHunk": "@@ -65,6 +65,19 @@ public TopicDescription(String name, boolean internal, List<TopicPartitionInfo>\n         this(name, internal, partitions, Collections.emptySet());\n     }\n \n+    /**\n+     * Create an instance with the specified parameters.\n+     *\n+     * @param name The topic name\n+     * @param internal Whether the topic is internal to Kafka\n+     * @param partitions A list of partitions where the index represents the partition id and the element contains\n+     *                   leadership and replica information for that partition.\n+     * @param topicId the topic id\n+     */\n+    public TopicDescription(String name, boolean internal, List<TopicPartitionInfo> partitions, Uuid topicId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzMzcxOA==", "bodyText": "Looks like default is empty set rather than null?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562233718", "createdAt": "2021-01-21T22:16:52Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java", "diffHunk": "@@ -79,6 +92,16 @@ public TopicDescription(String name, boolean internal, List<TopicPartitionInfo>\n         this(name, internal, partitions, authorizedOperations, Uuid.ZERO_UUID);\n     }\n \n+    /**\n+     * Create an instance with the specified parameters.\n+     *\n+     * @param name The topic name\n+     * @param internal Whether the topic is internal to Kafka\n+     * @param partitions A list of partitions where the index represents the partition id and the element contains\n+     *                   leadership and replica information for that partition.\n+     * @param authorizedOperations authorized operations for this topic, or null if this is not known.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzNDMyNw==", "bodyText": "super() is implied, so we can just leave the method empty?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562234327", "createdAt": "2021-01-21T22:18:02Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/errors/UnknownTopicIdException.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.errors;\n+\n+public class UnknownTopicIdException extends ApiException {\n+    private static final long serialVersionUID = 1L;\n+    public UnknownTopicIdException() {\n+        super();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzNDYwNA==", "bodyText": "typo: does", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562234604", "createdAt": "2021-01-21T22:18:30Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/Errors.java", "diffHunk": "@@ -350,7 +351,8 @@\n     POSITION_OUT_OF_RANGE(\n         99,\n         \"Requested position is not greater than or equal to zero, and less than the size of the snapshot.\",\n-        PositionOutOfRangeException::new);\n+        PositionOutOfRangeException::new),\n+    UNKNOWN_TOPIC_ID(100, \"The topic ID dose not exist\", UnknownTopicIdException::new);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzODU3Ng==", "bodyText": "We should never get here through the public APIs right? We could use IllegalStateException.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562238576", "createdAt": "2021-01-21T22:27:17Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,12 +91,31 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.name() == null) {\n+                throw new NullPointerException(\"Use errorsByTopicId() when manage topic using topic id\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzODg3OQ==", "bodyText": "As before, IllegalStateException?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562238879", "createdAt": "2021-01-21T22:27:51Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,12 +91,31 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.name() == null) {\n+                throw new NullPointerException(\"Use errorsByTopicId() when manage topic using topic id\");\n+            }\n             if (metadata.errorCode() != Errors.NONE.code())\n                 errors.put(metadata.name(), Errors.forCode(metadata.errorCode()));\n         }\n         return errors;\n     }\n \n+    /**\n+     * Get a map of the topicIds which had metadata errors\n+     * @return the map\n+     */\n+    public Map<Uuid, Errors> errorsByTopicId() {\n+        Map<Uuid, Errors> errors = new HashMap<>();\n+        for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.topicId() == Uuid.ZERO_UUID) {\n+                throw new NullPointerException(\"Use errors() when manage topic using topic name\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0MTA3Mg==", "bodyText": "we would fail if both are provided?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562241072", "createdAt": "2021-01-21T22:32:43Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -313,42 +313,57 @@ object TopicCommand extends Logging {\n     }\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n-      val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+      val topicId = opts.topicId.map(Uuid.fromString).filter(_ != Uuid.ZERO_UUID)\n+      // if topicId is provided and not zero, will use topicId regardless of topic name", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0NDEyMw==", "bodyText": "Since listTopics uses MetadataRequest, we just need to add topic ids from the MetadataResponse to TopicListing?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562244123", "createdAt": "2021-01-21T22:39:19Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -313,42 +313,54 @@ object TopicCommand extends Logging {\n     }\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n-      val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+      val topicId = opts.topicId.map(Uuid.fromString).filter(_ != Uuid.ZERO_UUID)\n+      val topics = if (topicId.isEmpty)\n+        getTopics(opts.topic, opts.excludeInternalTopics)\n+      else\n+        Seq()\n \n-      if (topics.nonEmpty) {\n-        val allConfigs = adminClient.describeConfigs(topics.map(new ConfigResource(Type.TOPIC, _)).asJavaCollection).values()\n-        val liveBrokers = adminClient.describeCluster().nodes().get().asScala.map(_.id())\n-        val topicDescriptions = adminClient.describeTopics(topics.asJavaCollection).all().get().values().asScala\n-        val describeOptions = new DescribeOptions(opts, liveBrokers.toSet)\n-        val topicPartitions = topicDescriptions\n-          .flatMap(td => td.partitions.iterator().asScala.map(p => new TopicPartition(td.name(), p.partition())))\n-          .toSet.asJava\n-        val reassignments = listAllReassignments(topicPartitions)\n-\n-        for (td <- topicDescriptions) {\n-          val topicName = td.name\n-          val topicId = td.topicId()\n-          val config = allConfigs.get(new ConfigResource(Type.TOPIC, topicName)).get()\n-          val sortedPartitions = td.partitions.asScala.sortBy(_.partition)\n-\n-          if (describeOptions.describeConfigs) {\n-            val hasNonDefault = config.entries().asScala.exists(!_.isDefault)\n-            if (!opts.reportOverriddenConfigs || hasNonDefault) {\n-              val numPartitions = td.partitions().size\n-              val firstPartition = td.partitions.iterator.next()\n-              val reassignment = reassignments.get(new TopicPartition(td.name, firstPartition.partition))\n-              val topicDesc = TopicDescription(topicName, topicId, numPartitions, getReplicationFactor(firstPartition, reassignment), config, markedForDeletion = false)\n-              topicDesc.printDescription()\n-            }\n+      if (topicId.isEmpty)\n+        ensureTopicExists(topics, opts.topic, !opts.ifExists)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0NjcyMg=="}, "originalCommit": {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0NTEwNQ==", "bodyText": "for manage topic => for describing topics?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562245105", "createdAt": "2021-01-21T22:41:27Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -635,6 +650,11 @@ object TopicCommand extends Logging {\n                          .withRequiredArg\n                          .describedAs(\"topic\")\n                          .ofType(classOf[String])\n+    private val topicIdOpt = parser.accepts(\"topic-id\", \"The topic-id to describe.\" +\n+      \"This is used only with --bootstrap-server option for manage topic.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0NzUzNA==", "bodyText": "unSupported => unsupported since it is one word (below as well)", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562247534", "createdAt": "2021-01-21T22:47:10Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1190,8 +1192,31 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val supportedVersionTopicIds = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1) topicIds else Set.empty[Uuid]\n+\n+    val unSupportedVersionTopicIds = topicIds.diff(supportedVersionTopicIds)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI1MTYyOQ==", "bodyText": "@jolshan Shouldn't we use KAFKA_2_8_IV1 for KafkaConfig.usesTopicId and use that here?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562251629", "createdAt": "2021-01-21T22:56:03Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1190,8 +1192,31 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val supportedVersionTopicIds = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1) topicIds else Set.empty[Uuid]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4091d1b9b8a52403648add5b06b422f9a0d252c7"}, "originalPosition": 88}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1MjY1OTg5", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-575265989", "createdAt": "2021-01-25T10:37:47Z", "commit": {"oid": "e4ce3d77cbe1d46b1880d522de83bc4f1ffe3dc4"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMDozNzo0OFrOIZgrug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMDo0MDozNFrOIZgyjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzYyMDc5NA==", "bodyText": "Don't we need the config for the third broker?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563620794", "createdAt": "2021-01-25T10:37:48Z", "author": {"login": "rajinisivaram"}, "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,117 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package integration.kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_2_8_IV1}\n+import kafka.network.SocketServer\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_2_8_IV1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ce3d77cbe1d46b1880d522de83bc4f1ffe3dc4"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzYyMjU0Mg==", "bodyText": "Instead of restarting brokers, we could delete the controller node in ZK to force controller election. It doesn't guarantee that the expected broker id becomes the next controller, but it may still get there faster than broker restarts", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563622542", "createdAt": "2021-01-25T10:40:34Z", "author": {"login": "rajinisivaram"}, "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,117 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package integration.kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_2_8_IV1}\n+import kafka.network.SocketServer\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_2_8_IV1)\n+    )\n+  }\n+\n+  @Test\n+  def testTopicIdUnsupported(): Unit = {\n+\n+    val topic = \"topic\"\n+\n+    // Ensure controller version = KAFKA_2_8_IV1, and then create a topic\n+    ensureControllerIn(Seq(1))\n+    createTopic(topic,  Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    // We can get topicId from the controller\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 10.toShort), brokerSocketServer(1))\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+    assertNotEquals(Uuid.ZERO_UUID, topicId)\n+    assertNotNull(topicId)\n+\n+    // Send request to a broker whose version=KAFKA_2_8_IV0\n+    val resp2 = sendMetadataRequest(new MetadataRequest(requestData(topic, topicId), 10.toShort), brokerSocketServer(0))\n+    assertEquals(Errors.UNSUPPORTED_VERSION, resp2.topicMetadata.iterator().next().error())\n+  }\n+\n+  @Test\n+  def testUnknownTopicId(): Unit = {\n+\n+    val topic = \"topic\"\n+\n+    // Kill controller and restart until broker 2 become controller\n+    ensureControllerIn(Seq(1))\n+    createTopic(topic, Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 10.toShort), brokerSocketServer(1))\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+\n+    // We could still get topic metadata by topicId\n+    val topicMetadata = sendMetadataRequest(new MetadataRequest(requestData(null, topicId), 10.toShort), brokerSocketServer(1))\n+      .topicMetadata.iterator().next()\n+    assertEquals(topicId, topicMetadata.topicId())\n+    assertEquals(topic, topicMetadata.topic())\n+\n+    // Make the broker whose version=KAFKA_2_8_IV0 controller\n+    ensureControllerIn(Seq(0))\n+\n+    // Restart the broker whose version=KAFKA_2_8_IV1, and the controller will send metadata request to it\n+    killBroker(1)\n+    restartDeadBrokers()\n+\n+    // Send request to a broker whose version=KAFKA_2_8_IV1\n+    val resp2 = sendMetadataRequest(new MetadataRequest(requestData(topic, topicId), 10.toShort), brokerSocketServer(1))\n+    assertEquals(Errors.UNKNOWN_TOPIC_ID, resp2.topicMetadata.iterator().next().error())\n+  }\n+\n+  private def ensureControllerIn(brokerIds: Seq[Int]): Unit = {\n+    while (!brokerIds.contains(controllerSocketServer.config.brokerId)) {\n+      killBroker(controllerSocketServer.config.brokerId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ce3d77cbe1d46b1880d522de83bc4f1ffe3dc4"}, "originalPosition": 95}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1MzgxMzM3", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-575381337", "createdAt": "2021-01-25T13:12:35Z", "commit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1NTg3NTMw", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-575587530", "createdAt": "2021-01-25T16:42:37Z", "commit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNjo0MjozN1rOIZv6dQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNjo0MjozN1rOIZv6dQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg3MDMyNQ==", "bodyText": "I'm curious if this diff is needed. It seems that the above check will result in all topicIds being left out or all of them being included.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563870325", "createdAt": "2021-01-25T16:42:37Z", "author": {"login": "jolshan"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1190,8 +1192,31 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val supportedVersionTopicIds = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1) topicIds else Set.empty[Uuid]\n+\n+    val unsupportedVersionTopicIds = topicIds.diff(supportedVersionTopicIds)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "originalPosition": 90}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1NTkwNzE1", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-575590715", "createdAt": "2021-01-25T16:45:44Z", "commit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNjo0NTo0NFrOIZwDwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNjo0NTo0NFrOIZwDwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg3MjcwNQ==", "bodyText": "Does this potentially acknowledge a topic exists if we give a valid id?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563872705", "createdAt": "2021-01-25T16:45:44Z", "author": {"login": "jolshan"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1223,7 +1247,7 @@ class KafkaApis(val requestChannel: RequestChannel,\n         Set.empty[MetadataResponseTopic]\n       else\n         unauthorizedForDescribeTopics.map(topic =>\n-          metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, false, util.Collections.emptyList()))\n+          metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, metadataCache.getTopicId(topic), false, util.Collections.emptyList()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "originalPosition": 129}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1NjAxMjc2", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-575601276", "createdAt": "2021-01-25T16:56:11Z", "commit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNjo1NjoxMVrOIZwjHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNjo1NjoxMVrOIZwjHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg4MDczMg==", "bodyText": "This test is super cool and will be very useful when testing other request types like fetch.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563880732", "createdAt": "2021-01-25T16:56:11Z", "author": {"login": "jolshan"}, "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,125 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package integration.kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_2_8_IV1}\n+import kafka.network.SocketServer\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import kafka.zk.ZkVersion\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1NjE5NTc5", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-575619579", "createdAt": "2021-01-25T17:13:32Z", "commit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNzoxMzozM1rOIZxXJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNzoxMzozM1rOIZxXJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg5NDA1NA==", "bodyText": "This scenario is a bit of a corner case and maybe not a huge deal either way, but does it make more sense to respond with UNKNOWN_TOPIC_ID or UNSUPPORTED_VERSION here? Maybe either is fine since we can expect UNKNOWN_TOPIC_ID or UNSUPPORTED_VERSION during an upgrade like this anyway.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563894054", "createdAt": "2021-01-25T17:13:33Z", "author": {"login": "jolshan"}, "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,125 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package integration.kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_2_8_IV1}\n+import kafka.network.SocketServer\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import kafka.zk.ZkVersion\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_2_8_IV1),\n+      createConfig(2, KAFKA_2_8_IV1)\n+    )\n+  }\n+\n+  @Test\n+  def testTopicIdUnsupported(): Unit = {\n+\n+    val topic = \"topic\"\n+\n+    // Ensure controller version = KAFKA_2_8_IV1, and then create a topic\n+    ensureControllerIn(Seq(1, 2))\n+    createTopic(topic,  Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    // We can get topicId from the controller\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 10.toShort), controllerSocketServer)\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+    assertNotEquals(Uuid.ZERO_UUID, topicId)\n+    assertNotNull(topicId)\n+\n+    // Send request to a broker whose version=KAFKA_2_8_IV0\n+    val resp2 = sendMetadataRequest(new MetadataRequest(requestData(topic, topicId), 10.toShort), brokerSocketServer(0))\n+    assertEquals(Errors.UNSUPPORTED_VERSION, resp2.topicMetadata.iterator().next().error())\n+  }\n+\n+  @Test\n+  def testUnknownTopicId(): Unit = {\n+\n+    val topic = \"topic\"\n+\n+    // Kill controller and restart until broker 2 become controller\n+    ensureControllerIn(Seq(1, 2))\n+    createTopic(topic, Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 10.toShort), controllerSocketServer)\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+\n+    // We could still get topic metadata by topicId\n+    val topicMetadata = sendMetadataRequest(new MetadataRequest(requestData(null, topicId), 10.toShort), controllerSocketServer)\n+      .topicMetadata.iterator().next()\n+    assertEquals(topicId, topicMetadata.topicId())\n+    assertEquals(topic, topicMetadata.topic())\n+\n+    // Make the broker whose version=KAFKA_2_8_IV0 controller\n+    ensureControllerIn(Seq(0))\n+\n+    // Restart the broker whose version=KAFKA_2_8_IV1, and the controller will send metadata request to it\n+    killBroker(1)\n+    restartDeadBrokers()\n+\n+    // Send request to a broker whose version=KAFKA_2_8_IV1 and restarted just now\n+    val resp2 = sendMetadataRequest(new MetadataRequest(requestData(topic, topicId), 10.toShort), brokerSocketServer(1))\n+    assertEquals(Errors.UNKNOWN_TOPIC_ID, resp2.topicMetadata.iterator().next().error())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "originalPosition": 92}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1Njk3NzY5", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-575697769", "createdAt": "2021-01-25T18:37:26Z", "commit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxODozNzoyN1rOIZ1FlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxODozNzoyN1rOIZ1FlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzk1NTA5Mg==", "bodyText": "I think this usage is fine since we will only get here if use the topic name version of the request and the topic does not exist.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563955092", "createdAt": "2021-01-25T18:37:27Z", "author": {"login": "jolshan"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1213,8 +1238,7 @@ class KafkaApis(val requestChannel: RequestChannel,\n     }\n \n     val unauthorizedForCreateTopicMetadata = unauthorizedForCreateTopics.map(topic =>\n-      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, isInternal(topic), util.Collections.emptyList()))\n-\n+      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, metadataCache.getTopicId(topic), isInternal(topic), util.Collections.emptyList()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5d599617ebd049005f63b29165546862997907f"}, "originalPosition": 120}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc2NTE1NzY2", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-576515766", "createdAt": "2021-01-26T16:15:08Z", "commit": {"oid": "3f363b9be4734f78219a5413fe379d32f7ae9b11"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQxNjoxNTowOFrOIae4Hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQxNjoxNTowOFrOIae4Hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDYzOTc3NA==", "bodyText": "nit: remove commented out line.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564639774", "createdAt": "2021-01-26T16:15:08Z", "author": {"login": "jolshan"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1194,9 +1194,13 @@ class KafkaApis(val requestChannel: RequestChannel,\n \n     // Check if topicId is presented firstly.\n     val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n-    val supportedVersionTopicIds = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1) topicIds else Set.empty[Uuid]\n \n-    val unsupportedVersionTopicIds = topicIds.diff(supportedVersionTopicIds)\n+    val (supportedVersionTopicIds, unsupportedVersionTopicIds) = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1)\n+      (topicIds, Set.empty[Uuid])\n+    else\n+      (Set.empty[Uuid], topicIds)\n+\n+    // val unsupportedVersionTopicIds = topicIds.diff(supportedVersionTopicIds)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f363b9be4734f78219a5413fe379d32f7ae9b11"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc2NTA0MTAx", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-576504101", "createdAt": "2021-01-26T16:04:06Z", "commit": {"oid": "3f363b9be4734f78219a5413fe379d32f7ae9b11"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQxNjowNDowNlrOIaeUUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQxNjoxNzoyNlrOIae_Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDYzMDYwOA==", "bodyText": "typo: should have been \"The id name of the topic\"", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564630608", "createdAt": "2021-01-26T16:04:06Z", "author": {"login": "satishd"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicListing.java", "diffHunk": "@@ -17,24 +17,36 @@\n \n package org.apache.kafka.clients.admin;\n \n+import org.apache.kafka.common.Uuid;\n+\n /**\n  * A listing of a topic in the cluster.\n  */\n public class TopicListing {\n     private final String name;\n+    private final Uuid topicId;\n     private final boolean internal;\n \n     /**\n      * Create an instance with the specified parameters.\n      *\n      * @param name The topic name\n+     * @param topicId The topic id.\n      * @param internal Whether the topic is internal to Kafka\n      */\n-    public TopicListing(String name, boolean internal) {\n+    public TopicListing(String name, Uuid topicId, boolean internal) {\n+        this.topicId = topicId;\n         this.name = name;\n         this.internal = internal;\n     }\n \n+    /**\n+     * The name of the topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f363b9be4734f78219a5413fe379d32f7ae9b11"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDY0MTU5MQ==", "bodyText": "Based on the above comment, does not it need to handle UUID.ZERO_UUID too?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564641591", "createdAt": "2021-01-26T16:17:26Z", "author": {"login": "satishd"}, "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -313,42 +314,59 @@ object TopicCommand extends Logging {\n     }\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n-      val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+      // if topicId is provided and not zero, will use topicId regardless of topic name\n+      val useTopicId = opts.topicId.map(Uuid.fromString).nonEmpty", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f363b9be4734f78219a5413fe379d32f7ae9b11"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc3Njg0ODY0", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-577684864", "createdAt": "2021-01-27T19:27:11Z", "commit": {"oid": "3f363b9be4734f78219a5413fe379d32f7ae9b11"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QxOToyNzoxMVrOIbX_bA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QxOToyNzoxMVrOIbX_bA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTU3NTUzMg==", "bodyText": "So will we never reach this code path when using topic IDs? I think we are using topics to decide authorization. So in the case where we use ids and the name exists, then we will expose the name and return a zero ID? Might be useful to create an authorizer integration test with topic IDs to ensure correctness.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r565575532", "createdAt": "2021-01-27T19:27:11Z", "author": {"login": "jolshan"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1223,7 +1251,7 @@ class KafkaApis(val requestChannel: RequestChannel,\n         Set.empty[MetadataResponseTopic]\n       else\n         unauthorizedForDescribeTopics.map(topic =>\n-          metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, false, util.Collections.emptyList()))\n+          metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, Uuid.ZERO_UUID, false, util.Collections.emptyList()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f363b9be4734f78219a5413fe379d32f7ae9b11"}, "originalPosition": 133}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc3ODgzOTY0", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-577883964", "createdAt": "2021-01-28T00:16:15Z", "commit": {"oid": "4d88cfa2a5e7c5d5c0911d76a97d4d45076f770e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4d88cfa2a5e7c5d5c0911d76a97d4d45076f770e", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/4d88cfa2a5e7c5d5c0911d76a97d4d45076f770e", "committedDate": "2021-01-27T02:12:38Z", "message": "resolve comments"}, "afterCommit": {"oid": "1854a1ad82310ec556bdccfbc2188295183e2aef", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/1854a1ad82310ec556bdccfbc2188295183e2aef", "committedDate": "2021-01-28T09:18:08Z", "message": "Add Unauthorized unit test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc4NjA4MTY3", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-578608167", "createdAt": "2021-01-28T18:09:27Z", "commit": {"oid": "1854a1ad82310ec556bdccfbc2188295183e2aef"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc4NjM3NzI3", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-578637727", "createdAt": "2021-01-28T18:46:26Z", "commit": {"oid": "1854a1ad82310ec556bdccfbc2188295183e2aef"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxODo0NjoyNlrOIcF4Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxODo0NjoyNlrOIcF4Hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjMyNzMyNw==", "bodyText": "@dengziming Thanks for the test! This line and the line declaring metadataByTopicName below are failing the scala 2.12 build, can we rewrite without mapValues so that the Java8/Scala2.12 build passes? Thanks.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r566327327", "createdAt": "2021-01-28T18:46:26Z", "author": {"login": "rajinisivaram"}, "path": "core/src/test/scala/unit/kafka/server/KafkaApisTest.scala", "diffHunk": "@@ -1879,6 +1879,109 @@ class KafkaApisTest {\n     assertTrue(response.topicsByError(Errors.UNKNOWN_TOPIC_OR_PARTITION).isEmpty)\n   }\n \n+  @Test\n+  def testUnauthorizedTopicMetadataRequest(): Unit = {\n+\n+    // 1. Set up broker information\n+    val plaintextListener = ListenerName.forSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+    val broker = new UpdateMetadataBroker()\n+      .setId(0)\n+      .setRack(\"rack\")\n+      .setEndpoints(Seq(\n+        new UpdateMetadataEndpoint()\n+          .setHost(\"broker0\")\n+          .setPort(9092)\n+          .setSecurityProtocol(SecurityProtocol.PLAINTEXT.id)\n+          .setListener(plaintextListener.value)\n+      ).asJava)\n+\n+    // 2. Set up authorizer\n+    val authorizer: Authorizer = EasyMock.niceMock(classOf[Authorizer])\n+    val unauthorizedTopic = \"unauthorized-topic\"\n+    val authorizedTopic = \"authorized-topic\"\n+\n+    val expectedActions = Seq(\n+      new Action(AclOperation.DESCRIBE, new ResourcePattern(ResourceType.TOPIC, unauthorizedTopic, PatternType.LITERAL), 1, true, true),\n+      new Action(AclOperation.DESCRIBE, new ResourcePattern(ResourceType.TOPIC, authorizedTopic, PatternType.LITERAL), 1, true, true)\n+    )\n+\n+    val expectedAuthorizeResult = Seq(AuthorizationResult.DENIED, AuthorizationResult.ALLOWED).asJava\n+\n+    EasyMock.expect(authorizer.authorize(anyObject[RequestContext], EasyMock.eq(expectedActions.asJava)))\n+      .andReturn(expectedAuthorizeResult)\n+      .times(2)\n+\n+    // 3. Set up MetadataCache\n+    val authorizedTopicId = Uuid.randomUuid();\n+    val unauthorizedTopicId = Uuid.randomUuid();\n+\n+    val topicIds = new util.HashMap[String, Uuid]()\n+    topicIds.put(authorizedTopic, authorizedTopicId)\n+    topicIds.put(unauthorizedTopic, unauthorizedTopicId)\n+\n+    def createDummyPartitionStates(topic: String) = {\n+      new UpdateMetadataPartitionState()\n+        .setTopicName(topic)\n+        .setPartitionIndex(0)\n+        .setControllerEpoch(1)\n+        .setLeader(0)\n+        .setLeaderEpoch(1)\n+        .setReplicas(Collections.singletonList(0))\n+        .setZkVersion(0)\n+        .setIsr(Collections.singletonList(0))\n+    }\n+\n+    // Send UpdateMetadataReq to update MetadataCache\n+    val partitionStates = Seq(unauthorizedTopic, authorizedTopic).map(createDummyPartitionStates)\n+\n+    val updateMetadataRequest = new UpdateMetadataRequest.Builder(ApiKeys.UPDATE_METADATA.latestVersion, 0,\n+      0, 0, partitionStates.asJava, Seq(broker).asJava, topicIds).build()\n+    metadataCache.updateMetadata(correlationId = 0, updateMetadataRequest)\n+\n+    // 4. Send TopicMetadataReq using topicId\n+    val capturedMetadataByTopicIdResp = expectNoThrottling()\n+    EasyMock.replay(clientRequestQuotaManager, requestChannel, authorizer)\n+\n+    val metadataReqByTopicId = new MetadataRequest.Builder(util.Arrays.asList(authorizedTopicId, unauthorizedTopicId)).build()\n+    createKafkaApis(authorizer = Some(authorizer)).handleTopicMetadataRequest(buildRequest(metadataReqByTopicId, plaintextListener))\n+    val metadataByTopicIdResp = readResponse(metadataReqByTopicId, capturedMetadataByTopicIdResp).asInstanceOf[MetadataResponse]\n+\n+    val metadataByTopicId = metadataByTopicIdResp.data().topics().asScala.groupBy(_.topicId()).view.mapValues(_.head).toMap", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1854a1ad82310ec556bdccfbc2188295183e2aef"}, "originalPosition": 71}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0e1b85d001cd7aa1391bb229787c2a08c21c850b", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/0e1b85d001cd7aa1391bb229787c2a08c21c850b", "committedDate": "2021-01-29T03:06:34Z", "message": "Fix scala 2.12 build problem"}, "afterCommit": {"oid": "8a4bc643e4fb3176d6df54764922bbc2907f6572", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/8a4bc643e4fb3176d6df54764922bbc2907f6572", "committedDate": "2021-01-29T09:58:00Z", "message": "Add Unauthorized unit test\n\nFix scala 2.12 build problem"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e6c58df7e15941f2ef5ecf5e46ae29ec86de9e2f", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/e6c58df7e15941f2ef5ecf5e46ae29ec86de9e2f", "committedDate": "2021-01-29T16:34:42Z", "message": "fix NEP"}, "afterCommit": {"oid": "d179ba46568869a2b507cd2a3805f9ba3d1a7a27", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/d179ba46568869a2b507cd2a3805f9ba3d1a7a27", "committedDate": "2021-01-29T16:58:09Z", "message": "fix NEP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d179ba46568869a2b507cd2a3805f9ba3d1a7a27", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/d179ba46568869a2b507cd2a3805f9ba3d1a7a27", "committedDate": "2021-01-29T16:58:09Z", "message": "fix NEP"}, "afterCommit": {"oid": "3b35d76eb8741bf4b5acbf843c76dd868f00e590", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/3b35d76eb8741bf4b5acbf843c76dd868f00e590", "committedDate": "2021-01-30T00:04:28Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3b35d76eb8741bf4b5acbf843c76dd868f00e590", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/3b35d76eb8741bf4b5acbf843c76dd868f00e590", "committedDate": "2021-01-30T00:04:28Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP"}, "afterCommit": {"oid": "9a3e53cb868814a68c02842eae29ee5f622c7599", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/9a3e53cb868814a68c02842eae29ee5f622c7599", "committedDate": "2021-01-30T00:00:54Z", "message": "fix NEP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9a3e53cb868814a68c02842eae29ee5f622c7599", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/9a3e53cb868814a68c02842eae29ee5f622c7599", "committedDate": "2021-01-30T00:00:54Z", "message": "fix NEP"}, "afterCommit": {"oid": "3b35d76eb8741bf4b5acbf843c76dd868f00e590", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/3b35d76eb8741bf4b5acbf843c76dd868f00e590", "committedDate": "2021-01-30T00:04:28Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dbdf698288b43ef1d186a181e35c54ebddb153c9", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/dbdf698288b43ef1d186a181e35c54ebddb153c9", "committedDate": "2021-01-30T00:31:03Z", "message": "checkStyle"}, "afterCommit": {"oid": "a48e9df0709576d0453bd897ede6c798d81500ad", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/a48e9df0709576d0453bd897ede6c798d81500ad", "committedDate": "2021-01-30T04:35:28Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgwMTI5Njk4", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-580129698", "createdAt": "2021-02-01T08:57:15Z", "commit": {"oid": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMVQwODo1NzoxNVrOIdW6bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMVQwOTowOToxM1rOIdXWhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY1NTAyMg==", "bodyText": "Could you add topic id to toString?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567655022", "createdAt": "2021-02-01T08:57:15Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicListing.java", "diffHunk": "@@ -17,24 +17,36 @@\n \n package org.apache.kafka.clients.admin;\n \n+import org.apache.kafka.common.Uuid;\n+\n /**\n  * A listing of a topic in the cluster.\n  */\n public class TopicListing {\n     private final String name;\n+    private final Uuid topicId;\n     private final boolean internal;\n \n     /**\n      * Create an instance with the specified parameters.\n      *\n      * @param name The topic name\n+     * @param topicId The topic id.\n      * @param internal Whether the topic is internal to Kafka\n      */\n-    public TopicListing(String name, boolean internal) {\n+    public TopicListing(String name, Uuid topicId, boolean internal) {\n+        this.topicId = topicId;\n         this.name = name;\n         this.internal = internal;\n     }\n \n+    /**\n+     * The id of the topic.\n+     */\n+    public Uuid topicId() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY2MTE3Mw==", "bodyText": "val unsupportedVersionTopicMetadata = unsupportedVersionTopicIds.map(topicId =>\n        metadataResponseTopic(Errors.UNSUPPORTED_VERSION, null, topicId, false, util.Collections.emptyList())).toSeq\nIs above code more simple?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567661173", "createdAt": "2021-02-01T09:07:36Z", "author": {"login": "chia7712"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1191,8 +1192,35 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val useTopicId = topicIds.nonEmpty\n+\n+    val (supportedVersionTopicIds, unsupportedVersionTopicIds) = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1)\n+      (topicIds, Set.empty[Uuid])\n+    else\n+      (Set.empty[Uuid], topicIds)\n+\n+    val unsupportedVersionTopicMetadata = if (unsupportedVersionTopicIds.isEmpty)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY2MTgwMw==", "bodyText": "val unknownTopicIdsTopicMetadata = unknownTopicIds.map(topicId =>\n        metadataResponseTopic(Errors.UNKNOWN_TOPIC_ID, null, topicId, false, util.Collections.emptyList())).toSeq\nIs above code more simple?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567661803", "createdAt": "2021-02-01T09:08:35Z", "author": {"login": "chia7712"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1191,8 +1192,35 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val useTopicId = topicIds.nonEmpty\n+\n+    val (supportedVersionTopicIds, unsupportedVersionTopicIds) = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1)\n+      (topicIds, Set.empty[Uuid])\n+    else\n+      (Set.empty[Uuid], topicIds)\n+\n+    val unsupportedVersionTopicMetadata = if (unsupportedVersionTopicIds.isEmpty)\n+      Seq.empty[MetadataResponseTopic]\n+    else\n+      unsupportedVersionTopicIds.map(topicId =>\n+        metadataResponseTopic(Errors.UNSUPPORTED_VERSION, null, topicId, false, util.Collections.emptyList())).toSeq\n+\n+    // Only get topicIds and topicNames when supporting topicId\n+    val unknownTopicIds = supportedVersionTopicIds.filter(metadataCache.getTopicName(_).isEmpty)\n+    val knownTopicNames = supportedVersionTopicIds.flatMap(metadataCache.getTopicName)\n+\n+    val unknownTopicIdsTopicMetadata = if (unknownTopicIds.isEmpty)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY2MjIxMw==", "bodyText": "Should we reject the requests carrying both topic id and topic name?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567662213", "createdAt": "2021-02-01T09:09:13Z", "author": {"login": "chia7712"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1191,8 +1192,35 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val useTopicId = topicIds.nonEmpty\n+\n+    val (supportedVersionTopicIds, unsupportedVersionTopicIds) = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1)\n+      (topicIds, Set.empty[Uuid])\n+    else\n+      (Set.empty[Uuid], topicIds)\n+\n+    val unsupportedVersionTopicMetadata = if (unsupportedVersionTopicIds.isEmpty)\n+      Seq.empty[MetadataResponseTopic]\n+    else\n+      unsupportedVersionTopicIds.map(topicId =>\n+        metadataResponseTopic(Errors.UNSUPPORTED_VERSION, null, topicId, false, util.Collections.emptyList())).toSeq\n+\n+    // Only get topicIds and topicNames when supporting topicId\n+    val unknownTopicIds = supportedVersionTopicIds.filter(metadataCache.getTopicName(_).isEmpty)\n+    val knownTopicNames = supportedVersionTopicIds.flatMap(metadataCache.getTopicName)\n+\n+    val unknownTopicIdsTopicMetadata = if (unknownTopicIds.isEmpty)\n+      Seq.empty[MetadataResponseTopic]\n+    else\n+      unknownTopicIds.map(topicId =>\n+        metadataResponseTopic(Errors.UNKNOWN_TOPIC_ID, null, topicId, false, util.Collections.emptyList())).toSeq\n+\n     val topics = if (metadataRequest.isAllTopics)\n       metadataCache.getAllTopics()\n+    else if (useTopicId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a"}, "originalPosition": 102}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/022a0eb4324d787a6a956599d3dc06a9d6eedc9a", "committedDate": "2021-01-30T05:20:29Z", "message": "use matchSameElements replace EasyMock.eq since the order of the request is unknown"}, "afterCommit": {"oid": "60616f56f39f7ec6ec2eea41dcf1061932cc8bd3", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/60616f56f39f7ec6ec2eea41dcf1061932cc8bd3", "committedDate": "2021-02-01T09:51:14Z", "message": "resolve comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "60616f56f39f7ec6ec2eea41dcf1061932cc8bd3", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/60616f56f39f7ec6ec2eea41dcf1061932cc8bd3", "committedDate": "2021-02-01T09:51:14Z", "message": "resolve comments"}, "afterCommit": {"oid": "488debccc73c8ce0972e03adc112d2d3ee6a0539", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/488debccc73c8ce0972e03adc112d2d3ee6a0539", "committedDate": "2021-02-01T12:28:09Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "488debccc73c8ce0972e03adc112d2d3ee6a0539", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/488debccc73c8ce0972e03adc112d2d3ee6a0539", "committedDate": "2021-02-01T12:28:09Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown"}, "afterCommit": {"oid": "3f3cd349e6235e444d618abe736c8639a9771700", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/3f3cd349e6235e444d618abe736c8639a9771700", "committedDate": "2021-02-02T01:29:15Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3f3cd349e6235e444d618abe736c8639a9771700", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/3f3cd349e6235e444d618abe736c8639a9771700", "committedDate": "2021-02-02T01:29:15Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown"}, "afterCommit": {"oid": "86fc15b86bc3d32137a3c1c7bcf3de38342f910d", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/86fc15b86bc3d32137a3c1c7bcf3de38342f910d", "committedDate": "2021-03-25T03:17:24Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\nmerge trunk"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "86fc15b86bc3d32137a3c1c7bcf3de38342f910d", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/86fc15b86bc3d32137a3c1c7bcf3de38342f910d", "committedDate": "2021-03-25T03:17:24Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\nmerge trunk"}, "afterCommit": {"oid": "603fe902adf08f6a32a0bd21fbfdd01302f22027", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/603fe902adf08f6a32a0bd21fbfdd01302f22027", "committedDate": "2021-03-31T02:40:14Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\nmerge trunk"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "603fe902adf08f6a32a0bd21fbfdd01302f22027", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/603fe902adf08f6a32a0bd21fbfdd01302f22027", "committedDate": "2021-03-31T02:40:14Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\nmerge trunk"}, "afterCommit": {"oid": "7fb8ea403cf4f8ea02c66835c46abe8e873c16ce", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/7fb8ea403cf4f8ea02c66835c46abe8e873c16ce", "committedDate": "2021-04-02T02:09:45Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\nmerge trunk"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7fb8ea403cf4f8ea02c66835c46abe8e873c16ce", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/7fb8ea403cf4f8ea02c66835c46abe8e873c16ce", "committedDate": "2021-04-02T02:09:45Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\nmerge trunk"}, "afterCommit": {"oid": "b2d1574760aadbfe626c98240097f4671ecae2e3", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/b2d1574760aadbfe626c98240097f4671ecae2e3", "committedDate": "2021-04-10T01:35:58Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\nadd ITCase of metadata request edge case between different ipb\nAdd Unauthorized unit test\nFix scala 2.12 build problem\nfix NEP\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjMzMDMxOTQz", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-633031943", "createdAt": "2021-04-11T16:38:44Z", "commit": {"oid": "b2d1574760aadbfe626c98240097f4671ecae2e3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0xMVQxNjozODo0NFrOJG5jgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0xMVQxNjozODo0NFrOJG5jgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxMTIxNDIwOQ==", "bodyText": "In the time since we last looked at this, we decided that it is ok to acknowledge existence of the topic ID and return TOPIC_AUTHORIZATION_FAILED. This is so the client knows it is not a retriable error. Please see https://issues.apache.org/jira/browse/KAFKA-12394 for more details.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r611214209", "createdAt": "2021-04-11T16:38:44Z", "author": {"login": "jolshan"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1165,16 +1189,23 @@ class KafkaApis(val requestChannel: RequestChannel,\n     }\n \n     val unauthorizedForCreateTopicMetadata = unauthorizedForCreateTopics.map(topic =>\n-      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, isInternal(topic), util.Collections.emptyList()))\n+      // Set topicId to zero since we will never create topic which topicId\n+      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, Uuid.ZERO_UUID, isInternal(topic), util.Collections.emptyList()))\n \n     // do not disclose the existence of topics unauthorized for Describe, so we've not even checked if they exist or not\n     val unauthorizedForDescribeTopicMetadata =\n       // In case of all topics, don't include topics unauthorized for Describe\n       if ((requestVersion == 0 && (metadataRequest.topics == null || metadataRequest.topics.isEmpty)) || metadataRequest.isAllTopics)\n         Set.empty[MetadataResponseTopic]\n-      else\n+      else if (useTopicId) {\n+        // We should not return information about existence of a topic on unauthorized error, so we return an UNKNOWN_TOPIC_ID\n+        unauthorizedForDescribeTopics.map(topic =>\n+          metadataResponseTopic(Errors.UNKNOWN_TOPIC_ID, null, metadataCache.getTopicId(topic), false, util.Collections.emptyList()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2d1574760aadbfe626c98240097f4671ecae2e3"}, "originalPosition": 93}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b2d1574760aadbfe626c98240097f4671ecae2e3", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/b2d1574760aadbfe626c98240097f4671ecae2e3", "committedDate": "2021-04-10T01:35:58Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\nadd ITCase of metadata request edge case between different ipb\nAdd Unauthorized unit test\nFix scala 2.12 build problem\nfix NEP\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts"}, "afterCommit": {"oid": "1a66be89f91b163fbd1ecf912fb49c0a8e199d6e", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/1a66be89f91b163fbd1ecf912fb49c0a8e199d6e", "committedDate": "2021-04-12T08:54:14Z", "message": "check KAFKA-12394"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1a66be89f91b163fbd1ecf912fb49c0a8e199d6e", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/1a66be89f91b163fbd1ecf912fb49c0a8e199d6e", "committedDate": "2021-04-12T08:54:14Z", "message": "check KAFKA-12394"}, "afterCommit": {"oid": "687aa318b58d0073c85b3f600168e6ce7e67d235", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/687aa318b58d0073c85b3f600168e6ce7e67d235", "committedDate": "2021-06-17T09:34:13Z", "message": "check KAFKA-12701"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "687aa318b58d0073c85b3f600168e6ce7e67d235", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/687aa318b58d0073c85b3f600168e6ce7e67d235", "committedDate": "2021-06-17T09:34:13Z", "message": "check KAFKA-12701"}, "afterCommit": {"oid": "ec2a79bd743c17f48290db940d3373ee2839689a", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/ec2a79bd743c17f48290db940d3373ee2839689a", "committedDate": "2021-06-17T13:08:07Z", "message": "check KAFKA-12701"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ec2a79bd743c17f48290db940d3373ee2839689a", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/ec2a79bd743c17f48290db940d3373ee2839689a", "committedDate": "2021-06-17T13:08:07Z", "message": "check KAFKA-12701"}, "afterCommit": {"oid": "80e392990ae787a35a072db0a13c9143a30c2471", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/80e392990ae787a35a072db0a13c9143a30c2471", "committedDate": "2021-06-29T11:26:57Z", "message": "check KAFKA-12976"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0726f944a9200d46efc55d1229d659cc853e6c8f", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/0726f944a9200d46efc55d1229d659cc853e6c8f", "committedDate": "2021-07-02T07:55:13Z", "message": "reword"}, "afterCommit": {"oid": "9e2f648f7cc7091b47ac86f7ac9b215bddca2ca6", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/9e2f648f7cc7091b47ac86f7ac9b215bddca2ca6", "committedDate": "2021-07-02T08:21:41Z", "message": "check KAFKA-13011: using TopicCollection"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9e2f648f7cc7091b47ac86f7ac9b215bddca2ca6", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/9e2f648f7cc7091b47ac86f7ac9b215bddca2ca6", "committedDate": "2021-07-02T08:21:41Z", "message": "check KAFKA-13011: using TopicCollection"}, "afterCommit": {"oid": "710276924ad313f0a7a5cb67637feff540c69398", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/710276924ad313f0a7a5cb67637feff540c69398", "committedDate": "2021-07-02T09:18:58Z", "message": "check KAFKA-13011: using TopicCollection"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "710276924ad313f0a7a5cb67637feff540c69398", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/710276924ad313f0a7a5cb67637feff540c69398", "committedDate": "2021-07-02T09:18:58Z", "message": "check KAFKA-13011: using TopicCollection"}, "afterCommit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/37f56f34a1cf8865537199e383dc2f1ca7b4181c", "committedDate": "2021-07-03T02:32:18Z", "message": "check KAFKA-13011: using TopicCollection"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk5MzU5ODI2", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-699359826", "createdAt": "2021-07-05T18:04:25Z", "commit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNVQxODowNDoyNlrOJ5T-HA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNVQxODowNDoyNlrOJ5T-HA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3NTgwNA==", "bodyText": "We should deprecate this one too I believe.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664075804", "createdAt": "2021-07-05T18:04:26Z", "author": {"login": "jolshan"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,87 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n     }\n \n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n+    }\n+\n+\n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated\n     public Map<String, KafkaFuture<TopicDescription>> values() {\n-        return futures;\n+        return nameFutures;\n     }\n \n     /**\n      * Return a future which succeeds only if all the topic descriptions succeed.\n      */\n     public KafkaFuture<Map<String, TopicDescription>> all() {\n-        return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).\n+        return all(nameFutures);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk5MzYxMDYw", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-699361060", "createdAt": "2021-07-05T18:07:51Z", "commit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNVQxODowNzo1MVrOJ5UCIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNVQxODowNzo1MVrOJ5UCIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3NjgzMw==", "bodyText": "Is there a reason this is setting the name to empty and not null? (or no name set at all?)", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664076833", "createdAt": "2021-07-05T18:07:51Z", "author": {"login": "jolshan"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataRequest.java", "diffHunk": "@@ -65,6 +65,20 @@ public Builder(List<String> topics, boolean allowAutoTopicCreation) {\n             this(topics, allowAutoTopicCreation, ApiKeys.METADATA.oldestVersion(),  ApiKeys.METADATA.latestVersion());\n         }\n \n+        public Builder(List<Uuid> topicIds) {\n+            super(ApiKeys.METADATA, ApiKeys.METADATA.oldestVersion(), ApiKeys.METADATA.latestVersion());\n+            MetadataRequestData data = new MetadataRequestData();\n+            if (topicIds == null)\n+                data.setTopics(null);\n+            else {\n+                topicIds.forEach(topicId -> data.topics().add(new MetadataRequestTopic().setTopicId(topicId).setName(\"\")));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c"}, "originalPosition": 10}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk5MzYxNjI4", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-699361628", "createdAt": "2021-07-05T18:09:30Z", "commit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNVQxODowOTozMFrOJ5UEKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNVQxODowOTozMFrOJ5UEKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3NzM1NA==", "bodyText": "can we set a previous version to be nullable? Or does this need to be 12+", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664077354", "createdAt": "2021-07-05T18:09:30Z", "author": {"login": "jolshan"}, "path": "clients/src/main/resources/common/message/MetadataResponse.json", "diffHunk": "@@ -65,7 +66,7 @@\n       \"about\": \"Each topic in the response.\", \"fields\": [\n       { \"name\": \"ErrorCode\", \"type\": \"int16\", \"versions\": \"0+\",\n         \"about\": \"The topic error, or 0 if there was no error.\" },\n-      { \"name\": \"Name\", \"type\": \"string\", \"versions\": \"0+\", \"mapKey\": true, \"entityType\": \"topicName\",\n+      { \"name\": \"Name\", \"type\": \"string\", \"versions\": \"0+\", \"mapKey\": true, \"entityType\": \"topicName\", \"nullableVersions\": \"10+\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk5MzYyNTY5", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-699362569", "createdAt": "2021-07-05T18:12:17Z", "commit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNVQxODoxMjoxOFrOJ5UHUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNVQxODoxMjoxOFrOJ5UHUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3ODE2MQ==", "bodyText": "Why are we bumping IBP? Metadata is not an inter-broker protocol, so I think bumping the metadata protocol suffices.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664078161", "createdAt": "2021-07-05T18:12:18Z", "author": {"login": "jolshan"}, "path": "core/src/main/scala/kafka/api/ApiVersion.scala", "diffHunk": "@@ -116,7 +116,9 @@ object ApiVersion {\n     // Introduce AllocateProducerIds (KIP-730)\n     KAFKA_3_0_IV0,\n     // Introduce ListOffsets V7 which supports listing offsets by max timestamp (KIP-734)\n-    KAFKA_3_0_IV1\n+    KAFKA_3_0_IV1,\n+    // Introduced topic IDs to MetadataRequest", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c"}, "originalPosition": 6}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/37f56f34a1cf8865537199e383dc2f1ca7b4181c", "committedDate": "2021-07-03T02:32:18Z", "message": "check KAFKA-13011: using TopicCollection"}, "afterCommit": {"oid": "4074a215ecf284f64ab9f6fcbae96517ec1e8a41", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/4074a215ecf284f64ab9f6fcbae96517ec1e8a41", "committedDate": "2021-07-06T07:26:15Z", "message": "resolve comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4074a215ecf284f64ab9f6fcbae96517ec1e8a41", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/4074a215ecf284f64ab9f6fcbae96517ec1e8a41", "committedDate": "2021-07-06T07:26:15Z", "message": "resolve comments"}, "afterCommit": {"oid": "988c493be558b44d0dec97ca84a58ee3faea013a", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/988c493be558b44d0dec97ca84a58ee3faea013a", "committedDate": "2021-07-06T07:30:43Z", "message": "resolve comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "988c493be558b44d0dec97ca84a58ee3faea013a", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/988c493be558b44d0dec97ca84a58ee3faea013a", "committedDate": "2021-07-06T07:30:43Z", "message": "resolve comments"}, "afterCommit": {"oid": "a94256dd75eb467c3d2b4435573621a4e83d3341", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/a94256dd75eb467c3d2b4435573621a4e83d3341", "committedDate": "2021-07-07T01:56:08Z", "message": "resolve comments and rebase trunk"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bf4517ccb16339209bceade8fba67c679b65a7ae", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/bf4517ccb16339209bceade8fba67c679b65a7ae", "committedDate": "2021-07-07T03:06:29Z", "message": "rebase trunk and resolve conflicts"}, "afterCommit": {"oid": "7394bf8b95e057512e5836e1fe6b8b09093f5608", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/7394bf8b95e057512e5836e1fe6b8b09093f5608", "committedDate": "2021-07-07T05:53:58Z", "message": "rebase trunk and resolve conflicts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAxMTQ2MjY4", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-701146268", "createdAt": "2021-07-07T15:22:28Z", "commit": {"oid": "7394bf8b95e057512e5836e1fe6b8b09093f5608"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QxNToyMjoyOFrOJ6pcew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QxNToyMjoyOFrOJ6pcew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTQ3NjIxOQ==", "bodyText": "Since we are past the feature freeze date, I think this will need to be 3.1 now. Same above.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r665476219", "createdAt": "2021-07-07T15:22:28Z", "author": {"login": "jolshan"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -303,7 +303,33 @@ default DescribeTopicsResult describeTopics(Collection<String> topicNames) {\n      * @param options    The options to use when describing the topic.\n      * @return The DescribeTopicsResult.\n      */\n-    DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options);\n+    default DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options) {\n+        return describeTopics(TopicCollection.ofTopicNames(topicNames), options);\n+    }\n+\n+    /**\n+     * This is a convenience method for {@link #describeTopics(TopicCollection, DescribeTopicsOptions)}\n+     * with default options. See the overload for more details.\n+     * <p>\n+     * When using topic IDs, this operation is supported by brokers with version 3.0.0 or higher.\n+     *\n+     * @param topics The topics to delete.\n+     * @return The DescribeTopicsResult.\n+     */\n+    default DescribeTopicsResult describeTopics(TopicCollection topics) {\n+        return describeTopics(topics, new DescribeTopicsOptions());\n+    }\n+\n+    /**\n+     * describe a batch of topics.\n+     *\n+     * When using topic IDs, this operation is supported by brokers with version 3.0.0 or higher.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7394bf8b95e057512e5836e1fe6b8b09093f5608"}, "originalPosition": 55}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAxMTUxNDQx", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-701151441", "createdAt": "2021-07-07T15:26:46Z", "commit": {"oid": "7394bf8b95e057512e5836e1fe6b8b09093f5608"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QxNToyNjo0NlrOJ6prKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QxNToyNjo0NlrOJ6prKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTQ3OTk3Nw==", "bodyText": "I'm not sure this comment is correct since we don't use this version.\nJust to confirm my understanding, what is this test showing? First we can get description when controller is high enough IBP (2_8_IV1+) and then we can't when controller is lower than that?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r665479977", "createdAt": "2021-07-07T15:26:46Z", "author": {"login": "jolshan"}, "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,103 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_3_0_IV1}\n+import kafka.network.SocketServer\n+import kafka.utils.TestUtils\n+import kafka.zk.ZkVersion\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_3_0_IV1),\n+      createConfig(2, KAFKA_3_0_IV1)\n+    )\n+  }\n+\n+  @Test\n+  def testUnknownTopicId(): Unit = {\n+    val topic = \"topic\"\n+\n+    // Kill controller and restart until broker 2 become controller\n+    ensureControllerIn(Seq(1, 2))\n+    createTopic(topic, Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 12.toShort), controllerSocketServer)\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+\n+    // We could still get topic metadata by topicId\n+   val topicMetadata = sendMetadataRequest(new MetadataRequest(requestData(null, topicId), 12.toShort), controllerSocketServer)\n+      .topicMetadata.iterator().next()\n+    assertEquals(topicId, topicMetadata.topicId())\n+    assertEquals(topic, topicMetadata.topic())\n+\n+    // Make the broker whose version=KAFKA_3_0_IV0 controller", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7394bf8b95e057512e5836e1fe6b8b09093f5608"}, "originalPosition": 61}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7394bf8b95e057512e5836e1fe6b8b09093f5608", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/7394bf8b95e057512e5836e1fe6b8b09093f5608", "committedDate": "2021-07-07T05:53:58Z", "message": "rebase trunk and resolve conflicts"}, "afterCommit": {"oid": "6556a4572ab914df46f78ec8e72ca5d1f439c30d", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/6556a4572ab914df46f78ec8e72ca5d1f439c30d", "committedDate": "2021-07-08T02:24:27Z", "message": "more feedback from comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6556a4572ab914df46f78ec8e72ca5d1f439c30d", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/6556a4572ab914df46f78ec8e72ca5d1f439c30d", "committedDate": "2021-07-08T02:24:27Z", "message": "more feedback from comments"}, "afterCommit": {"oid": "ca32ef409673686ea3499eb359a1e631e698df4d", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/ca32ef409673686ea3499eb359a1e631e698df4d", "committedDate": "2021-07-10T05:23:42Z", "message": "more feedback from comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ca32ef409673686ea3499eb359a1e631e698df4d", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/ca32ef409673686ea3499eb359a1e631e698df4d", "committedDate": "2021-07-10T05:23:42Z", "message": "more feedback from comments"}, "afterCommit": {"oid": "3aa7a04096d2fe878578e54cbf6b9e513d8609b7", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/3aa7a04096d2fe878578e54cbf6b9e513d8609b7", "committedDate": "2021-07-13T01:40:26Z", "message": "more feedback from comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3aa7a04096d2fe878578e54cbf6b9e513d8609b7", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/3aa7a04096d2fe878578e54cbf6b9e513d8609b7", "committedDate": "2021-07-13T01:40:26Z", "message": "more feedback from comments"}, "afterCommit": {"oid": "3d7d81df30f9e5b7b3e656990d916d038404bf51", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/3d7d81df30f9e5b7b3e656990d916d038404bf51", "committedDate": "2021-07-23T13:39:12Z", "message": "more feedback from comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8da4a395990e2eba29e3a24bd4501f991963da7d", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/8da4a395990e2eba29e3a24bd4501f991963da7d", "committedDate": "2021-07-23T13:54:54Z", "message": "remove usage of deprecated methods"}, "afterCommit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/83c3f0da62d5a983b678be1aa69669a2f285fb67", "committedDate": "2021-07-24T12:49:13Z", "message": "remove usage of deprecated methods"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE2NTMzNzgw", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-716533780", "createdAt": "2021-07-28T02:44:43Z", "commit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yOFQwMjo0NDo0M1rOKGhtSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yOFQwMjo0NDo0M1rOKGhtSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NzkzMjM2MQ==", "bodyText": "nit: is there a reason we moved these imports?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r677932361", "createdAt": "2021-07-28T02:44:43Z", "author": {"login": "jolshan"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -42,6 +34,14 @@\n import org.apache.kafka.common.quota.ClientQuotaFilter;\n import org.apache.kafka.common.requests.LeaveGroupResponse;\n \n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE2NTM0NDIz", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-716534423", "createdAt": "2021-07-28T02:46:32Z", "commit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yOFQwMjo0NjozMlrOKGhvmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yOFQwMjo0NjozMlrOKGhvmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NzkzMjk1NA==", "bodyText": "Can we adjust this javadoc to be Describe some topics in the cluster. like the previous API?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r677932954", "createdAt": "2021-07-28T02:46:32Z", "author": {"login": "jolshan"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -303,7 +303,33 @@ default DescribeTopicsResult describeTopics(Collection<String> topicNames) {\n      * @param options    The options to use when describing the topic.\n      * @return The DescribeTopicsResult.\n      */\n-    DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options);\n+    default DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options) {\n+        return describeTopics(TopicCollection.ofTopicNames(topicNames), options);\n+    }\n+\n+    /**\n+     * This is a convenience method for {@link #describeTopics(TopicCollection, DescribeTopicsOptions)}\n+     * with default options. See the overload for more details.\n+     * <p>\n+     * When using topic IDs, this operation is supported by brokers with version 3.1.0 or higher.\n+     *\n+     * @param topics The topics to describe.\n+     * @return The DescribeTopicsResult.\n+     */\n+    default DescribeTopicsResult describeTopics(TopicCollection topics) {\n+        return describeTopics(topics, new DescribeTopicsOptions());\n+    }\n+\n+    /**\n+     * describe a batch of topics.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE2NTM1Mzg3", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-716535387", "createdAt": "2021-07-28T02:49:14Z", "commit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yOFQwMjo0OToxNVrOKGhzPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yOFQwMjo0OToxNVrOKGhzPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NzkzMzg4NQ==", "bodyText": "nit: extra newline here", "url": "https://github.com/apache/kafka/pull/9769#discussion_r677933885", "createdAt": "2021-07-28T02:49:15Z", "author": {"login": "jolshan"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,87 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n     }\n \n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated\n     public Map<String, KafkaFuture<TopicDescription>> values() {\n-        return futures;\n+        return nameFutures;\n     }\n \n     /**\n      * Return a future which succeeds only if all the topic descriptions succeed.\n      */\n+    @Deprecated\n     public KafkaFuture<Map<String, TopicDescription>> all() {\n-        return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).\n+        return all(nameFutures);\n+    }\n+\n+    /**\n+     * Return a future which succeeds only if all the topic descriptions succeed.\n+     */\n+    public KafkaFuture<Map<String, TopicDescription>> allTopicNames() {\n+        return all(nameFutures);\n+    }\n+\n+    /**\n+     * Return a future which succeeds only if all the topic descriptions succeed.\n+     */\n+    public KafkaFuture<Map<Uuid, TopicDescription>> allTopicIds() {\n+        return all(topicIdFutures);\n+    }\n+\n+    /**\n+     * Return a future which succeeds only if all the topic descriptions succeed.\n+     */\n+    private static <T> KafkaFuture<Map<T, TopicDescription>> all(Map<T, KafkaFuture<TopicDescription>> futures) {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67"}, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE2NTQzNzk4", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-716543798", "createdAt": "2021-07-28T03:12:02Z", "commit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yOFQwMzoxMjowMlrOKGiPIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0yOFQwMzoxMjowMlrOKGiPIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3Nzk0MTAyNw==", "bodyText": "I think this was discussed briefly before, but is there a reason KAFKA_3_0_IV1 was chosen? Should we just use the most recent IBP? (meaning, not even specify in the properties -- just pick up the default?)", "url": "https://github.com/apache/kafka/pull/9769#discussion_r677941027", "createdAt": "2021-07-28T03:12:02Z", "author": {"login": "jolshan"}, "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_3_0_IV1}\n+import kafka.network.SocketServer\n+import kafka.utils.TestUtils\n+import kafka.zk.ZkVersion\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_3_0_IV1),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67"}, "originalPosition": 39}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/83c3f0da62d5a983b678be1aa69669a2f285fb67", "committedDate": "2021-07-24T12:49:13Z", "message": "remove usage of deprecated methods"}, "afterCommit": {"oid": "cedaec45b7ff0b679e50712b6475752b2d5e84dc", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/cedaec45b7ff0b679e50712b6475752b2d5e84dc", "committedDate": "2021-07-31T08:11:23Z", "message": "more feedbacks from comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cedaec45b7ff0b679e50712b6475752b2d5e84dc", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/cedaec45b7ff0b679e50712b6475752b2d5e84dc", "committedDate": "2021-07-31T08:11:23Z", "message": "more feedbacks from comments"}, "afterCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/140ade867813302014765010cc78d9b1b92af821", "committedDate": "2021-07-31T08:41:12Z", "message": "more feedbacks from comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQwMjIyNzY3", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-740222767", "createdAt": "2021-08-27T07:31:03Z", "commit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0yN1QwNzozMTowM1rOKY6yhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wOC0yN1QxMjoxMToyMVrOKZFWFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIxNzY3MQ==", "bodyText": "Since this is a protected method in a public API, we should probably keep the method and deprecate. It can just invoke the method below.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697217671", "createdAt": "2021-08-27T07:31:03Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIxODA1Nw==", "bodyText": "Make this package-private?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697218057", "createdAt": "2021-08-27T07:31:39Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIyMDQ3OA==", "bodyText": "Can we add  @deprecated Since 3.1. Use xxx in the javadoc above?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697220478", "createdAt": "2021-08-27T07:35:45Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n     }\n \n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIyMDU3MQ==", "bodyText": "Can we add  @deprecated Since 3.1. Use xxx in the javadoc above?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697220571", "createdAt": "2021-08-27T07:35:53Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n     }\n \n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated\n     public Map<String, KafkaFuture<TopicDescription>> values() {\n-        return futures;\n+        return nameFutures;\n     }\n \n     /**\n      * Return a future which succeeds only if all the topic descriptions succeed.\n      */\n+    @Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIyMjc4Mg==", "bodyText": "Also mention that this returns by topic name if the request used topic names. otherwise returns null.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697222782", "createdAt": "2021-08-27T07:39:39Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n     }\n \n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated\n     public Map<String, KafkaFuture<TopicDescription>> values() {\n-        return futures;\n+        return nameFutures;\n     }\n \n     /**\n      * Return a future which succeeds only if all the topic descriptions succeed.\n      */\n+    @Deprecated\n     public KafkaFuture<Map<String, TopicDescription>> all() {\n-        return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).\n+        return all(nameFutures);\n+    }\n+\n+    /**\n+     * Return a future which succeeds only if all the topic descriptions succeed.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM3MjkzMQ==", "bodyText": "Since this is part of the public API, we should keep the original constructor and deprecate.", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697372931", "createdAt": "2021-08-27T11:39:51Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicListing.java", "diffHunk": "@@ -17,24 +17,36 @@\n \n package org.apache.kafka.clients.admin;\n \n+import org.apache.kafka.common.Uuid;\n+\n /**\n  * A listing of a topic in the cluster.\n  */\n public class TopicListing {\n     private final String name;\n+    private final Uuid topicId;\n     private final boolean internal;\n \n     /**\n      * Create an instance with the specified parameters.\n      *\n      * @param name The topic name\n+     * @param topicId The topic id.\n      * @param internal Whether the topic is internal to Kafka\n      */\n-    public TopicListing(String name, boolean internal) {\n+    public TopicListing(String name, Uuid topicId, boolean internal) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM3NDI3OA==", "bodyText": "when manage => when managing", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697374278", "createdAt": "2021-08-27T11:42:24Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,12 +91,31 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.name() == null) {\n+                throw new IllegalStateException(\"Use errorsByTopicId() when manage topic using topic id\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM3NjMxOA==", "bodyText": "As before, when manage =>when managing", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697376318", "createdAt": "2021-08-27T11:46:20Z", "author": {"login": "rajinisivaram"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,12 +91,31 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.name() == null) {\n+                throw new IllegalStateException(\"Use errorsByTopicId() when manage topic using topic id\");\n+            }\n             if (metadata.errorCode() != Errors.NONE.code())\n                 errors.put(metadata.name(), Errors.forCode(metadata.errorCode()));\n         }\n         return errors;\n     }\n \n+    /**\n+     * Get a map of the topicIds which had metadata errors\n+     * @return the map\n+     */\n+    public Map<Uuid, Errors> errorsByTopicId() {\n+        Map<Uuid, Errors> errors = new HashMap<>();\n+        for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.topicId() == Uuid.ZERO_UUID) {\n+                throw new IllegalStateException(\"Use errors() when manage topic using topic name\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM4MDU1OA==", "bodyText": "we => returning?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697380558", "createdAt": "2021-08-27T11:53:56Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1222,16 +1238,23 @@ class KafkaApis(val requestChannel: RequestChannel,\n     }\n \n     val unauthorizedForCreateTopicMetadata = unauthorizedForCreateTopics.map(topic =>\n-      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, isInternal(topic), util.Collections.emptyList()))\n+      // Set topicId to zero since we will never create topic which topicId\n+      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, Uuid.ZERO_UUID, isInternal(topic), util.Collections.emptyList()))\n \n     // do not disclose the existence of topics unauthorized for Describe, so we've not even checked if they exist or not\n     val unauthorizedForDescribeTopicMetadata =\n       // In case of all topics, don't include topics unauthorized for Describe\n       if ((requestVersion == 0 && (metadataRequest.topics == null || metadataRequest.topics.isEmpty)) || metadataRequest.isAllTopics)\n         Set.empty[MetadataResponseTopic]\n-      else\n+      else if (useTopicId) {\n+        // Topic IDs are not considered sensitive information, so we TOPIC_AUTHORIZATION_FAILED is OK", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM4OTA5NA==", "bodyText": "Maybe just say ZERO_UUID (Or change case to Uuid", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697389094", "createdAt": "2021-08-27T12:08:54Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -568,6 +619,10 @@ object TopicCommand extends Logging {\n         throw new IllegalArgumentException(\"--bootstrap-server must be specified\")\n       if (has(describeOpt) && has(ifExistsOpt))\n         CommandLineUtils.checkRequiredArgs(parser, options, topicOpt)\n+      if(has(describeOpt) && has(ifExistsOpt)) {\n+        if (has(topicOpt) == has(topicIdOpt))\n+          println(\"Only topic id will be used when both --topic and --topic-id are specified and topicId is not UUID.ZERO_UUID\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM5MDYxNA==", "bodyText": "Should this be && since the error below refers to both being specified? And should there an error for both not being specified?", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697390614", "createdAt": "2021-08-27T12:11:21Z", "author": {"login": "rajinisivaram"}, "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -568,6 +619,10 @@ object TopicCommand extends Logging {\n         throw new IllegalArgumentException(\"--bootstrap-server must be specified\")\n       if (has(describeOpt) && has(ifExistsOpt))\n         CommandLineUtils.checkRequiredArgs(parser, options, topicOpt)\n+      if(has(describeOpt) && has(ifExistsOpt)) {\n+        if (has(topicOpt) == has(topicIdOpt))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821"}, "originalPosition": 187}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "562316205eab5f90f37626ea6e185f920423e450", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/562316205eab5f90f37626ea6e185f920423e450", "committedDate": "2021-08-27T14:17:33Z", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nGate  topic IDs behind IBP 2.8.1\nadd ITCase of metadata request edge case between different ipb\nAdd Unauthorized unit test\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\ncheck KAFKA-12394\n\ncheck KAFKA-12701"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "605259eb30cabe505c908a882e66db4ab898e8a8", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/605259eb30cabe505c908a882e66db4ab898e8a8", "committedDate": "2021-08-27T14:17:33Z", "message": "check KAFKA-12976"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e3ae1b209efd98423417b4e964bd02fe949e9dca", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/e3ae1b209efd98423417b4e964bd02fe949e9dca", "committedDate": "2021-08-27T14:17:33Z", "message": "check KAFKA-13011: using TopicCollection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "97b45f64eaf931cf0ecd12c42f4a14dfef4fb5ec", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/97b45f64eaf931cf0ecd12c42f4a14dfef4fb5ec", "committedDate": "2021-08-27T14:17:33Z", "message": "resolve comments and rebase trunk"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0965346b078103da3ecd3f70d5cef75ada680dd1", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/0965346b078103da3ecd3f70d5cef75ada680dd1", "committedDate": "2021-08-27T14:17:34Z", "message": "rebase trunk and resolve conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ced95b09c0b581f35911b36944e00ba514fa1963", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/ced95b09c0b581f35911b36944e00ba514fa1963", "committedDate": "2021-08-27T14:17:34Z", "message": "more feedback from comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "acc8ba9bcc77f280e33d68976cf0bf03456d65fc", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/acc8ba9bcc77f280e33d68976cf0bf03456d65fc", "committedDate": "2021-08-27T14:17:34Z", "message": "remove usage of deprecated methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a7a3953d5ecb8b22082bbf38312a4866e340076", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/9a7a3953d5ecb8b22082bbf38312a4866e340076", "committedDate": "2021-08-27T14:17:34Z", "message": "more feedbacks from comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d0bc3cd349dcc356f90f343bb57c9e6ed478e62f", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/d0bc3cd349dcc356f90f343bb57c9e6ed478e62f", "committedDate": "2021-08-27T15:22:52Z", "message": "more feedbacks from rajinisivaram"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "140ade867813302014765010cc78d9b1b92af821", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/140ade867813302014765010cc78d9b1b92af821", "committedDate": "2021-07-31T08:41:12Z", "message": "more feedbacks from comments"}, "afterCommit": {"oid": "d0bc3cd349dcc356f90f343bb57c9e6ed478e62f", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/d0bc3cd349dcc356f90f343bb57c9e6ed478e62f", "committedDate": "2021-08-27T15:22:52Z", "message": "more feedbacks from rajinisivaram"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a443b4f7fec883ecb9cb51fb919f910fc661344c", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/a443b4f7fec883ecb9cb51fb919f910fc661344c", "committedDate": "2021-08-27T16:24:19Z", "message": "fix error version"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQxMDAwMDA2", "url": "https://github.com/apache/kafka/pull/9769#pullrequestreview-741000006", "createdAt": "2021-08-28T07:56:37Z", "commit": {"oid": "a443b4f7fec883ecb9cb51fb919f910fc661344c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2348, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}