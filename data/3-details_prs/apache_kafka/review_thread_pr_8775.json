{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI2MzU3NjAy", "number": 8775, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNDozMTozNFrOEBxdqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzozOToxOFrOECqjPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMjk0NDQyOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNDozMTozNFrOGd0kMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNDozMTozNFrOGd0kMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzkyMzEyMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * @return true if a followup rebalance will be required due to revoekd tasks\n          \n          \n            \n                 * @return true if a followup rebalance will be required due to revoked tasks", "url": "https://github.com/apache/kafka/pull/8775#discussion_r433923120", "createdAt": "2020-06-02T14:31:34Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -938,57 +930,9 @@ private void populatePartitionsByHostMaps(final Map<HostInfo, Set<TopicPartition\n         return assignment;\n     }\n \n-    /**\n-     * Computes the assignment of tasks to threads within each client and assembles the final assignment to send out,\n-     * in the special case of version probing where some members are on different versions and have sent different\n-     * subscriptions.\n-     *\n-     * @return the final assignment for each StreamThread consumer\n-     */\n-    private Map<String, Assignment> versionProbingAssignment(final Map<UUID, ClientMetadata> clientsMetadata,\n-                                                             final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n-                                                             final Map<HostInfo, Set<TopicPartition>> partitionsByHost,\n-                                                             final Map<HostInfo, Set<TopicPartition>> standbyPartitionsByHost,\n-                                                             final Set<TopicPartition> allOwnedPartitions,\n-                                                             final int minUserMetadataVersion,\n-                                                             final int minSupportedMetadataVersion) {\n-        final Map<String, Assignment> assignment = new HashMap<>();\n-\n-        // Since we know another rebalance will be triggered anyway, just try and generate a balanced assignment\n-        // (without violating cooperative protocol) now so that on the second rebalance we can just give tasks\n-        // back to their previous owners\n-        // within the client, distribute tasks to its owned consumers\n-        for (final ClientMetadata clientMetadata : clientsMetadata.values()) {\n-            final ClientState state = clientMetadata.state;\n-\n-            final Map<String, List<TaskId>> interleavedActive =\n-                interleaveConsumerTasksByGroupId(state.activeTasks(), clientMetadata.consumers);\n-            final Map<String, List<TaskId>> interleavedStandby =\n-                interleaveConsumerTasksByGroupId(state.standbyTasks(), clientMetadata.consumers);\n-\n-            addClientAssignments(\n-                assignment,\n-                clientMetadata,\n-                partitionsForTask,\n-                partitionsByHost,\n-                standbyPartitionsByHost,\n-                allOwnedPartitions,\n-                interleavedActive,\n-                interleavedStandby,\n-                minUserMetadataVersion,\n-                minSupportedMetadataVersion,\n-                true,\n-                false);\n-        }\n-\n-        log.info(\"Finished unstable assignment of tasks, a followup rebalance will be scheduled due to version probing.\");\n-\n-        return assignment;\n-    }\n-\n     /**\n      * Adds the encoded assignment for each StreamThread consumer in the client to the overall assignment map\n-     * @return true if this client has been told to schedule a followup rebalance\n+     * @return true if a followup rebalance will be required due to revoekd tasks", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 227}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMzQ5NTAxOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjozMDozMVrOGd6Gog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjozODoxNlrOGd6aCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxMzg1OA==", "bodyText": "We have several new methods, and also this new book-kept collection (consumerToPreviousTaskIds), but no new tests for them in ClientStateTest. Can you add the missing coverage?\nThe new methods are more a matter of principle; I'm really concerned that we should have good coverage on the bookkeeping aspect of consumerToPreviousTaskIds because I fear future regressions when we have to maintain two data structures in a consistent fashion", "url": "https://github.com/apache/kafka/pull/8775#discussion_r434013858", "createdAt": "2020-06-02T16:30:31Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -242,8 +250,9 @@ public void addOwnedPartitions(final Collection<TopicPartition> ownedPartitions,\n         }\n     }\n \n-    public void addPreviousTasksAndOffsetSums(final Map<TaskId, Long> taskOffsetSums) {\n+    public void addPreviousTasksAndOffsetSums(final String consumerId, final Map<TaskId, Long> taskOffsetSums) {\n         this.taskOffsetSums.putAll(taskOffsetSums);\n+        consumerToPreviousTaskIds.put(consumerId, taskOffsetSums.keySet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxODgyNg==", "bodyText": "Definitely. I meant to write tests but then I took Luna for a walk and forgot \ud83d\ude04", "url": "https://github.com/apache/kafka/pull/8775#discussion_r434018826", "createdAt": "2020-06-02T16:38:16Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -242,8 +250,9 @@ public void addOwnedPartitions(final Collection<TopicPartition> ownedPartitions,\n         }\n     }\n \n-    public void addPreviousTasksAndOffsetSums(final Map<TaskId, Long> taskOffsetSums) {\n+    public void addPreviousTasksAndOffsetSums(final String consumerId, final Map<TaskId, Long> taskOffsetSums) {\n         this.taskOffsetSums.putAll(taskOffsetSums);\n+        consumerToPreviousTaskIds.put(consumerId, taskOffsetSums.keySet());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxMzg1OA=="}, "originalCommit": null, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwODkzNTM1OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/ClientStateTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QyMjoyOTowNlrOGevwOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNjowMzoyNFrOGfNILQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg5Mjg1Nw==", "bodyText": "I missed the extra sort on my last review. It really seems like too much fanciness for the ClientState to sort the tasks in lag order. Would it be too messy to move the sort aspect out to the balancing code that needs it?", "url": "https://github.com/apache/kafka/pull/8775#discussion_r434892857", "createdAt": "2020-06-03T22:29:06Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/ClientStateTest.java", "diffHunk": "@@ -300,20 +302,71 @@ public void shouldNotHaveUnfulfilledQuotaWhenActiveTaskSizeGreaterEqualThanCapac\n     @Test\n     public void shouldAddTasksWithLatestOffsetToPrevActiveTasks() {\n         final Map<TaskId, Long> taskOffsetSums = Collections.singletonMap(TASK_0_1, Task.LATEST_OFFSET);\n-        client.addPreviousTasksAndOffsetSums(taskOffsetSums);\n+        client.addPreviousTasksAndOffsetSums(\"c1\", taskOffsetSums);\n         client.initializePrevTasks(Collections.emptyMap());\n         assertThat(client.prevActiveTasks(), equalTo(Collections.singleton(TASK_0_1)));\n         assertThat(client.previousAssignedTasks(), equalTo(Collections.singleton(TASK_0_1)));\n         assertTrue(client.prevStandbyTasks().isEmpty());\n     }\n \n+    @Test\n+    public void shouldReturnPreviousStatefulTasksForConsumer() {\n+        client.addPreviousTasksAndOffsetSums(\"c1\", Collections.singletonMap(TASK_0_1, Task.LATEST_OFFSET));\n+        client.addPreviousTasksAndOffsetSums(\"c2\", Collections.singletonMap(TASK_0_2, 0L));\n+        client.addPreviousTasksAndOffsetSums(\"c3\", Collections.emptyMap());\n+\n+        client.initializePrevTasks(Collections.emptyMap());\n+        client.computeTaskLags(\n+            UUID_1,\n+            mkMap(\n+                mkEntry(TASK_0_1, 1_000L),\n+                mkEntry(TASK_0_2, 1_000L)\n+            )\n+        );\n+\n+        assertThat(client.previousTasksForConsumer(\"c1\"), equalTo(mkSortedSet(TASK_0_1)));\n+        assertThat(client.previousTasksForConsumer(\"c2\"), equalTo(mkSortedSet(TASK_0_2)));\n+        assertTrue(client.previousTasksForConsumer(\"c3\").isEmpty());\n+    }\n+\n+    @Test\n+    public void shouldReturnPreviousStatefulTasksForConsumerWhenLagIsNotComputed() {\n+        client.addPreviousTasksAndOffsetSums(\"c1\", Collections.singletonMap(TASK_0_1, 1000L));\n+        client.initializePrevTasks(Collections.emptyMap());\n+\n+        assertThat(client.previousTasksForConsumer(\"c1\"), equalTo(mkSortedSet(TASK_0_1)));\n+    }\n+\n+    @Test\n+    public void shouldReturnPreviousStatefulTasksForConsumerInIncreasingLagOrder() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f580e63fb889115ef66987656459baefcce3473c"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM3NDEyNQ==", "bodyText": "You didn't miss it, I just snuck it in there after your review :P\nSorry, should have called out that I made some more changes. I think that was the only significant logical change though. I'll try pulling the sort out into the assignment code", "url": "https://github.com/apache/kafka/pull/8775#discussion_r435374125", "createdAt": "2020-06-04T16:03:24Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/ClientStateTest.java", "diffHunk": "@@ -300,20 +302,71 @@ public void shouldNotHaveUnfulfilledQuotaWhenActiveTaskSizeGreaterEqualThanCapac\n     @Test\n     public void shouldAddTasksWithLatestOffsetToPrevActiveTasks() {\n         final Map<TaskId, Long> taskOffsetSums = Collections.singletonMap(TASK_0_1, Task.LATEST_OFFSET);\n-        client.addPreviousTasksAndOffsetSums(taskOffsetSums);\n+        client.addPreviousTasksAndOffsetSums(\"c1\", taskOffsetSums);\n         client.initializePrevTasks(Collections.emptyMap());\n         assertThat(client.prevActiveTasks(), equalTo(Collections.singleton(TASK_0_1)));\n         assertThat(client.previousAssignedTasks(), equalTo(Collections.singleton(TASK_0_1)));\n         assertTrue(client.prevStandbyTasks().isEmpty());\n     }\n \n+    @Test\n+    public void shouldReturnPreviousStatefulTasksForConsumer() {\n+        client.addPreviousTasksAndOffsetSums(\"c1\", Collections.singletonMap(TASK_0_1, Task.LATEST_OFFSET));\n+        client.addPreviousTasksAndOffsetSums(\"c2\", Collections.singletonMap(TASK_0_2, 0L));\n+        client.addPreviousTasksAndOffsetSums(\"c3\", Collections.emptyMap());\n+\n+        client.initializePrevTasks(Collections.emptyMap());\n+        client.computeTaskLags(\n+            UUID_1,\n+            mkMap(\n+                mkEntry(TASK_0_1, 1_000L),\n+                mkEntry(TASK_0_2, 1_000L)\n+            )\n+        );\n+\n+        assertThat(client.previousTasksForConsumer(\"c1\"), equalTo(mkSortedSet(TASK_0_1)));\n+        assertThat(client.previousTasksForConsumer(\"c2\"), equalTo(mkSortedSet(TASK_0_2)));\n+        assertTrue(client.previousTasksForConsumer(\"c3\").isEmpty());\n+    }\n+\n+    @Test\n+    public void shouldReturnPreviousStatefulTasksForConsumerWhenLagIsNotComputed() {\n+        client.addPreviousTasksAndOffsetSums(\"c1\", Collections.singletonMap(TASK_0_1, 1000L));\n+        client.initializePrevTasks(Collections.emptyMap());\n+\n+        assertThat(client.previousTasksForConsumer(\"c1\"), equalTo(mkSortedSet(TASK_0_1)));\n+    }\n+\n+    @Test\n+    public void shouldReturnPreviousStatefulTasksForConsumerInIncreasingLagOrder() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg5Mjg1Nw=="}, "originalCommit": {"oid": "f580e63fb889115ef66987656459baefcce3473c"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjI5NzU4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzozOToxOFrOGfQveQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMjoyNDo0M1rOGfaCSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQzMzMzNw==", "bodyText": "Is this the right constant to represent \"we don't know the lag\"? Or did I mistake how this is going to be used?", "url": "https://github.com/apache/kafka/pull/8775#discussion_r435433337", "createdAt": "2020-06-04T17:39:18Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -302,14 +300,19 @@ public void computeTaskLags(final UUID uuid, final Map<TaskId, Long> allTaskEndO\n      * @return end offset sum - offset sum\n      *          Task.LATEST_OFFSET if this was previously an active running task on this client\n      */\n-    long lagFor(final TaskId task) {\n-        final Long totalLag = taskLagTotals.get(task);\n+    public long lagFor(final TaskId task) {\n+        final Long totalLag;\n+        if (taskLagTotals.isEmpty()) {\n+            // If we couldn't compute the task lags due to failure to fetch offsets, just return a flat constant\n+            totalLag = 0L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96a6c23d23b4c8b4018f4bb1bf044ce924f73f90"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4NTYwOQ==", "bodyText": "The value itself doesn't matter, just that it's constant across all tasks.\nBut I'm guessing you meant, why not use the existing UNKNOWN_OFFSET_SUM sentinel, in which case the answer is probably just that I forgot about it. Anyway I did a slight additional refactoring beyond this, just fyi: instead of skipping the lag computation when we fail to fetch offsets, we now always initialize the lags and just pass in the UNKNOWN_OFFSET_SUM for all stateful tasks when the offset fetch fails.", "url": "https://github.com/apache/kafka/pull/8775#discussion_r435585609", "createdAt": "2020-06-04T22:24:43Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ClientState.java", "diffHunk": "@@ -302,14 +300,19 @@ public void computeTaskLags(final UUID uuid, final Map<TaskId, Long> allTaskEndO\n      * @return end offset sum - offset sum\n      *          Task.LATEST_OFFSET if this was previously an active running task on this client\n      */\n-    long lagFor(final TaskId task) {\n-        final Long totalLag = taskLagTotals.get(task);\n+    public long lagFor(final TaskId task) {\n+        final Long totalLag;\n+        if (taskLagTotals.isEmpty()) {\n+            // If we couldn't compute the task lags due to failure to fetch offsets, just return a flat constant\n+            totalLag = 0L;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQzMzMzNw=="}, "originalCommit": {"oid": "96a6c23d23b4c8b4018f4bb1bf044ce924f73f90"}, "originalPosition": 26}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2489, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}