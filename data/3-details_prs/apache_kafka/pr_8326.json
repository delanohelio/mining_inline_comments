{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkxODgwNjgx", "number": 8326, "title": "KAFKA-8639: Replace AddPartitionsToTxn with Automated Protocol ", "bodyText": "Part of the protocol automation effort.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-03-21T16:32:28Z", "url": "https://github.com/apache/kafka/pull/8326", "merged": true, "mergeCommit": {"oid": "f3c8bff311b0e4c4d0e316ac949fe4491f9b107f"}, "closed": true, "closedAt": "2020-04-24T04:39:12Z", "author": {"login": "abbccdda"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcP4zfIAFqTM3ODkzNjk4OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcaU5zWgH2gAyMzkxODgwNjgxOjMyOTgwYzdlMzIzNTNkMTk1MDgxZjhkMDI3ZGQ3MWIwOWE2ZmJmYzc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4OTM2OTg4", "url": "https://github.com/apache/kafka/pull/8326#pullrequestreview-378936988", "createdAt": "2020-03-21T17:45:51Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQxNzo0NTo1MlrOF5qtgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQxNzo0NTo1MlrOF5qtgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjAxMjkzMQ==", "bodyText": "Mostly side cleanup", "url": "https://github.com/apache/kafka/pull/8326#discussion_r396012931", "createdAt": "2020-03-21T17:45:52Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1130,13 +1126,14 @@ private void lookupCoordinator(FindCoordinatorRequest.CoordinatorType type, Stri\n         enqueueRequest(new FindCoordinatorHandler(builder));\n     }\n \n-\n-\n     private TxnRequestHandler addPartitionsToTransactionHandler() {\n         pendingPartitionsInTransaction.addAll(newPartitionsInTransaction);\n         newPartitionsInTransaction.clear();\n-        AddPartitionsToTxnRequest.Builder builder = new AddPartitionsToTxnRequest.Builder(transactionalId,\n-                producerIdAndEpoch.producerId, producerIdAndEpoch.epoch, new ArrayList<>(pendingPartitionsInTransaction));\n+        AddPartitionsToTxnRequest.Builder builder =", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5MDYwOTQ1", "url": "https://github.com/apache/kafka/pull/8326#pullrequestreview-379060945", "createdAt": "2020-03-22T23:05:26Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMlQyMzowNToyN1rOF5zW1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMlQyMzowNToyN1rOF5zW1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE1NDU4MA==", "bodyText": "Only side cleanups in this file", "url": "https://github.com/apache/kafka/pull/8326#discussion_r396154580", "createdAt": "2020-03-22T23:05:27Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java", "diffHunk": "@@ -184,18 +183,15 @@ public void testMessageFormatDownConversion() throws Exception {\n         // now the partition leader supports only v2\n         apiVersions.update(\"0\", NodeApiVersions.create(ApiKeys.PRODUCE.id, (short) 0, (short) 2));\n \n-        client.prepareResponse(new MockClient.RequestMatcher() {\n-            @Override\n-            public boolean matches(AbstractRequest body) {\n-                ProduceRequest request = (ProduceRequest) body;\n-                if (request.version() != 2)\n-                    return false;\n+        client.prepareResponse(body -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzgzMTM4", "url": "https://github.com/apache/kafka/pull/8326#pullrequestreview-391783138", "createdAt": "2020-04-11T17:02:32Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNzowMjozMlrOGEOlNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNzowMjozMlrOGEOlNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA4NjM4OA==", "bodyText": "Simplify boolean logic", "url": "https://github.com/apache/kafka/pull/8326#discussion_r407086388", "createdAt": "2020-04-11T17:02:32Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -509,13 +509,9 @@ ProducerIdAndEpoch producerIdAndEpoch() {\n         return producerIdAndEpoch;\n     }\n \n-    boolean hasProducerId(long producerId) {\n-        return producerIdAndEpoch.producerId == producerId;\n-    }\n-\n-    boolean matchesProducerIdAndEpoch(ProducerBatch batch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzgzMTY5", "url": "https://github.com/apache/kafka/pull/8326#pullrequestreview-391783169", "createdAt": "2020-04-11T17:02:49Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNzowMjo1MFrOGEOlaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNzowMjo1MFrOGEOlaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA4NjQ0MA==", "bodyText": "Fix the alignment", "url": "https://github.com/apache/kafka/pull/8326#discussion_r407086440", "createdAt": "2020-04-11T17:02:50Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/ApiKeys.java", "diffHunk": "@@ -196,22 +196,28 @@ public Struct parseResponse(short version, ByteBuffer buffer) {\n             SaslAuthenticateResponseData.SCHEMAS),\n     CREATE_PARTITIONS(37, \"CreatePartitions\", CreatePartitionsRequestData.SCHEMAS,\n             CreatePartitionsResponseData.SCHEMAS),\n-    CREATE_DELEGATION_TOKEN(38, \"CreateDelegationToken\", CreateDelegationTokenRequestData.SCHEMAS, CreateDelegationTokenResponseData.SCHEMAS),\n-    RENEW_DELEGATION_TOKEN(39, \"RenewDelegationToken\", RenewDelegationTokenRequestData.SCHEMAS, RenewDelegationTokenResponseData.SCHEMAS),\n-    EXPIRE_DELEGATION_TOKEN(40, \"ExpireDelegationToken\", ExpireDelegationTokenRequestData.SCHEMAS, ExpireDelegationTokenResponseData.SCHEMAS),\n-    DESCRIBE_DELEGATION_TOKEN(41, \"DescribeDelegationToken\", DescribeDelegationTokenRequestData.SCHEMAS, DescribeDelegationTokenResponseData.SCHEMAS),\n+    CREATE_DELEGATION_TOKEN(38, \"CreateDelegationToken\", CreateDelegationTokenRequestData.SCHEMAS,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzgzNjAy", "url": "https://github.com/apache/kafka/pull/8326#pullrequestreview-391783602", "createdAt": "2020-04-11T17:08:53Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNzowODo1M1rOGEOnqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNzowODo1M1rOGEOnqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA4NzAxOQ==", "bodyText": "The test only checks partition 0, no need for 3 partitions", "url": "https://github.com/apache/kafka/pull/8326#discussion_r407087019", "createdAt": "2020-04-11T17:08:53Z", "author": {"login": "abbccdda"}, "path": "core/src/test/scala/unit/kafka/server/AddPartitionsToTxnRequestServerTest.scala", "diffHunk": "@@ -27,9 +27,9 @@ import org.junit.{Before, Test}\n \n import scala.jdk.CollectionConverters._\n \n-class AddPartitionsToTxnRequestTest extends BaseRequestTest {\n-  private val topic1 = \"foobartopic\"\n-  val numPartitions = 3\n+class AddPartitionsToTxnRequestServerTest extends BaseRequestTest {\n+  private val topic1 = \"topic1\"\n+  val numPartitions = 1", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 9}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e2c2839303eb3e1c8c010e93d752510aa7995ae", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/1e2c2839303eb3e1c8c010e93d752510aa7995ae", "committedDate": "2020-04-11T17:16:33Z", "message": "replace AddPartition"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "1e2c2839303eb3e1c8c010e93d752510aa7995ae", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/1e2c2839303eb3e1c8c010e93d752510aa7995ae", "committedDate": "2020-04-11T17:16:33Z", "message": "replace AddPartition"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk4NjI2NDMw", "url": "https://github.com/apache/kafka/pull/8326#pullrequestreview-398626430", "createdAt": "2020-04-22T22:11:24Z", "commit": {"oid": "1e2c2839303eb3e1c8c010e93d752510aa7995ae"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQyMjoxMToyNVrOGKN9pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQyMjo1MjoyNVrOGKPGHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM2NzcxOQ==", "bodyText": "nit: we can use map#compute to replace getOrDefault + put.", "url": "https://github.com/apache/kafka/pull/8326#discussion_r413367719", "createdAt": "2020-04-22T22:11:25Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AddPartitionsToTxnRequest.java", "diffHunk": "@@ -17,157 +17,109 @@\n package org.apache.kafka.common.requests;\n \n import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.AddPartitionsToTxnRequestData;\n+import org.apache.kafka.common.message.AddPartitionsToTxnRequestData.AddPartitionsToTxnTopic;\n+import org.apache.kafka.common.message.AddPartitionsToTxnRequestData.AddPartitionsToTxnTopicCollection;\n import org.apache.kafka.common.protocol.ApiKeys;\n import org.apache.kafka.common.protocol.Errors;\n-import org.apache.kafka.common.protocol.types.ArrayOf;\n-import org.apache.kafka.common.protocol.types.Field;\n-import org.apache.kafka.common.protocol.types.Schema;\n import org.apache.kafka.common.protocol.types.Struct;\n-import org.apache.kafka.common.utils.CollectionUtils;\n \n import java.nio.ByteBuffer;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n \n-import static org.apache.kafka.common.protocol.CommonFields.PRODUCER_EPOCH;\n-import static org.apache.kafka.common.protocol.CommonFields.PRODUCER_ID;\n-import static org.apache.kafka.common.protocol.CommonFields.TOPIC_NAME;\n-import static org.apache.kafka.common.protocol.CommonFields.TRANSACTIONAL_ID;\n-import static org.apache.kafka.common.protocol.types.Type.INT32;\n-\n public class AddPartitionsToTxnRequest extends AbstractRequest {\n-    private static final String TOPICS_KEY_NAME = \"topics\";\n-    private static final String PARTITIONS_KEY_NAME = \"partitions\";\n-\n-    private static final Schema ADD_PARTITIONS_TO_TXN_REQUEST_V0 = new Schema(\n-            TRANSACTIONAL_ID,\n-            PRODUCER_ID,\n-            PRODUCER_EPOCH,\n-            new Field(TOPICS_KEY_NAME, new ArrayOf(new Schema(\n-                    TOPIC_NAME,\n-                    new Field(PARTITIONS_KEY_NAME, new ArrayOf(INT32)))),\n-                    \"The partitions to add to the transaction.\"));\n-\n-    /**\n-     * The version number is bumped to indicate that on quota violation brokers send out responses before throttling.\n-     */\n-    private static final Schema ADD_PARTITIONS_TO_TXN_REQUEST_V1 = ADD_PARTITIONS_TO_TXN_REQUEST_V0;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{ADD_PARTITIONS_TO_TXN_REQUEST_V0, ADD_PARTITIONS_TO_TXN_REQUEST_V1};\n-    }\n+\n+    public final AddPartitionsToTxnRequestData data;\n \n     public static class Builder extends AbstractRequest.Builder<AddPartitionsToTxnRequest> {\n-        private final String transactionalId;\n-        private final long producerId;\n-        private final short producerEpoch;\n-        private final List<TopicPartition> partitions;\n+        public final AddPartitionsToTxnRequestData data;\n \n-        public Builder(String transactionalId, long producerId, short producerEpoch, List<TopicPartition> partitions) {\n+        public Builder(final AddPartitionsToTxnRequestData data) {\n             super(ApiKeys.ADD_PARTITIONS_TO_TXN);\n-            this.transactionalId = transactionalId;\n-            this.producerId = producerId;\n-            this.producerEpoch = producerEpoch;\n-            this.partitions = partitions;\n+            this.data = data;\n+        }\n+\n+        public Builder(final String transactionalId,\n+                       final long producerId,\n+                       final short producerEpoch,\n+                       final List<TopicPartition> partitions) {\n+            super(ApiKeys.ADD_PARTITIONS_TO_TXN);\n+\n+            Map<String, List<Integer>> partitionMap = new HashMap<>();\n+            for (TopicPartition topicPartition : partitions) {\n+                String topicName = topicPartition.topic();\n+\n+                List<Integer> subPartitions = partitionMap.getOrDefault(topicName,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e2c2839303eb3e1c8c010e93d752510aa7995ae"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM3NDM1NQ==", "bodyText": "Although today we are only calling this func once, if in the future we call it multiple times we'd pay the cycles each time to parse the map into the list. Could we cache the parsed list locally and when it is called again we can avoid Builder.getPartitions?", "url": "https://github.com/apache/kafka/pull/8326#discussion_r413374355", "createdAt": "2020-04-22T22:25:25Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AddPartitionsToTxnRequest.java", "diffHunk": "@@ -17,157 +17,109 @@\n package org.apache.kafka.common.requests;\n \n import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.AddPartitionsToTxnRequestData;\n+import org.apache.kafka.common.message.AddPartitionsToTxnRequestData.AddPartitionsToTxnTopic;\n+import org.apache.kafka.common.message.AddPartitionsToTxnRequestData.AddPartitionsToTxnTopicCollection;\n import org.apache.kafka.common.protocol.ApiKeys;\n import org.apache.kafka.common.protocol.Errors;\n-import org.apache.kafka.common.protocol.types.ArrayOf;\n-import org.apache.kafka.common.protocol.types.Field;\n-import org.apache.kafka.common.protocol.types.Schema;\n import org.apache.kafka.common.protocol.types.Struct;\n-import org.apache.kafka.common.utils.CollectionUtils;\n \n import java.nio.ByteBuffer;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n \n-import static org.apache.kafka.common.protocol.CommonFields.PRODUCER_EPOCH;\n-import static org.apache.kafka.common.protocol.CommonFields.PRODUCER_ID;\n-import static org.apache.kafka.common.protocol.CommonFields.TOPIC_NAME;\n-import static org.apache.kafka.common.protocol.CommonFields.TRANSACTIONAL_ID;\n-import static org.apache.kafka.common.protocol.types.Type.INT32;\n-\n public class AddPartitionsToTxnRequest extends AbstractRequest {\n-    private static final String TOPICS_KEY_NAME = \"topics\";\n-    private static final String PARTITIONS_KEY_NAME = \"partitions\";\n-\n-    private static final Schema ADD_PARTITIONS_TO_TXN_REQUEST_V0 = new Schema(\n-            TRANSACTIONAL_ID,\n-            PRODUCER_ID,\n-            PRODUCER_EPOCH,\n-            new Field(TOPICS_KEY_NAME, new ArrayOf(new Schema(\n-                    TOPIC_NAME,\n-                    new Field(PARTITIONS_KEY_NAME, new ArrayOf(INT32)))),\n-                    \"The partitions to add to the transaction.\"));\n-\n-    /**\n-     * The version number is bumped to indicate that on quota violation brokers send out responses before throttling.\n-     */\n-    private static final Schema ADD_PARTITIONS_TO_TXN_REQUEST_V1 = ADD_PARTITIONS_TO_TXN_REQUEST_V0;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{ADD_PARTITIONS_TO_TXN_REQUEST_V0, ADD_PARTITIONS_TO_TXN_REQUEST_V1};\n-    }\n+\n+    public final AddPartitionsToTxnRequestData data;\n \n     public static class Builder extends AbstractRequest.Builder<AddPartitionsToTxnRequest> {\n-        private final String transactionalId;\n-        private final long producerId;\n-        private final short producerEpoch;\n-        private final List<TopicPartition> partitions;\n+        public final AddPartitionsToTxnRequestData data;\n \n-        public Builder(String transactionalId, long producerId, short producerEpoch, List<TopicPartition> partitions) {\n+        public Builder(final AddPartitionsToTxnRequestData data) {\n             super(ApiKeys.ADD_PARTITIONS_TO_TXN);\n-            this.transactionalId = transactionalId;\n-            this.producerId = producerId;\n-            this.producerEpoch = producerEpoch;\n-            this.partitions = partitions;\n+            this.data = data;\n+        }\n+\n+        public Builder(final String transactionalId,\n+                       final long producerId,\n+                       final short producerEpoch,\n+                       final List<TopicPartition> partitions) {\n+            super(ApiKeys.ADD_PARTITIONS_TO_TXN);\n+\n+            Map<String, List<Integer>> partitionMap = new HashMap<>();\n+            for (TopicPartition topicPartition : partitions) {\n+                String topicName = topicPartition.topic();\n+\n+                List<Integer> subPartitions = partitionMap.getOrDefault(topicName,\n+                    new ArrayList<>());\n+                subPartitions.add(topicPartition.partition());\n+                partitionMap.put(topicName, subPartitions);\n+            }\n+\n+            AddPartitionsToTxnTopicCollection topics = new AddPartitionsToTxnTopicCollection();\n+            for (Map.Entry<String, List<Integer>> partitionEntry : partitionMap.entrySet()) {\n+                topics.add(new AddPartitionsToTxnTopic()\n+                               .setName(partitionEntry.getKey())\n+                               .setPartitions(partitionEntry.getValue()));\n+            }\n+\n+            this.data = new AddPartitionsToTxnRequestData()\n+                            .setTransactionalId(transactionalId)\n+                            .setProducerId(producerId)\n+                            .setProducerEpoch(producerEpoch)\n+                            .setTopics(topics);\n         }\n \n         @Override\n         public AddPartitionsToTxnRequest build(short version) {\n-            return new AddPartitionsToTxnRequest(version, transactionalId, producerId, producerEpoch, partitions);\n+            return new AddPartitionsToTxnRequest(data, version);\n         }\n \n         public List<TopicPartition> partitions() {\n+            return getPartitions(data);\n+        }\n+\n+        static List<TopicPartition> getPartitions(AddPartitionsToTxnRequestData data) {\n+            List<TopicPartition> partitions = new ArrayList<>();\n+            for (AddPartitionsToTxnTopic topicCollection : data.topics()) {\n+                for (Integer partition : topicCollection.partitions()) {\n+                    partitions.add(new TopicPartition(topicCollection.name(), partition));\n+                }\n+            }\n             return partitions;\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"(type=AddPartitionsToTxnRequest\").\n-                    append(\", transactionalId=\").append(transactionalId).\n-                    append(\", producerId=\").append(producerId).\n-                    append(\", producerEpoch=\").append(producerEpoch).\n-                    append(\", partitions=\").append(partitions).\n-                    append(\")\");\n-            return bld.toString();\n+            return data.toString();\n         }\n     }\n \n-    private final String transactionalId;\n-    private final long producerId;\n-    private final short producerEpoch;\n-    private final List<TopicPartition> partitions;\n-\n-    private AddPartitionsToTxnRequest(short version, String transactionalId, long producerId, short producerEpoch,\n-                                      List<TopicPartition> partitions) {\n+    public AddPartitionsToTxnRequest(final AddPartitionsToTxnRequestData data, short version) {\n         super(ApiKeys.ADD_PARTITIONS_TO_TXN, version);\n-        this.transactionalId = transactionalId;\n-        this.producerId = producerId;\n-        this.producerEpoch = producerEpoch;\n-        this.partitions = partitions;\n+        this.data = data;\n     }\n \n     public AddPartitionsToTxnRequest(Struct struct, short version) {\n         super(ApiKeys.ADD_PARTITIONS_TO_TXN, version);\n-        this.transactionalId = struct.get(TRANSACTIONAL_ID);\n-        this.producerId = struct.get(PRODUCER_ID);\n-        this.producerEpoch = struct.get(PRODUCER_EPOCH);\n-\n-        List<TopicPartition> partitions = new ArrayList<>();\n-        Object[] topicPartitionsArray = struct.getArray(TOPICS_KEY_NAME);\n-        for (Object topicPartitionObj : topicPartitionsArray) {\n-            Struct topicPartitionStruct = (Struct) topicPartitionObj;\n-            String topic = topicPartitionStruct.get(TOPIC_NAME);\n-            for (Object partitionObj : topicPartitionStruct.getArray(PARTITIONS_KEY_NAME)) {\n-                partitions.add(new TopicPartition(topic, (Integer) partitionObj));\n-            }\n-        }\n-        this.partitions = partitions;\n-    }\n-\n-    public String transactionalId() {\n-        return transactionalId;\n-    }\n-\n-    public long producerId() {\n-        return producerId;\n-    }\n-\n-    public short producerEpoch() {\n-        return producerEpoch;\n+        this.data = new AddPartitionsToTxnRequestData(struct, version);\n     }\n \n     public List<TopicPartition> partitions() {\n-        return partitions;\n+        return Builder.getPartitions(data);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e2c2839303eb3e1c8c010e93d752510aa7995ae"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM3NDgxOQ==", "bodyText": "Same here, we can cache the result of Builder.getPartitions(data) for re-use.", "url": "https://github.com/apache/kafka/pull/8326#discussion_r413374819", "createdAt": "2020-04-22T22:26:22Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AddPartitionsToTxnRequest.java", "diffHunk": "@@ -17,157 +17,109 @@\n package org.apache.kafka.common.requests;\n \n import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.AddPartitionsToTxnRequestData;\n+import org.apache.kafka.common.message.AddPartitionsToTxnRequestData.AddPartitionsToTxnTopic;\n+import org.apache.kafka.common.message.AddPartitionsToTxnRequestData.AddPartitionsToTxnTopicCollection;\n import org.apache.kafka.common.protocol.ApiKeys;\n import org.apache.kafka.common.protocol.Errors;\n-import org.apache.kafka.common.protocol.types.ArrayOf;\n-import org.apache.kafka.common.protocol.types.Field;\n-import org.apache.kafka.common.protocol.types.Schema;\n import org.apache.kafka.common.protocol.types.Struct;\n-import org.apache.kafka.common.utils.CollectionUtils;\n \n import java.nio.ByteBuffer;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n \n-import static org.apache.kafka.common.protocol.CommonFields.PRODUCER_EPOCH;\n-import static org.apache.kafka.common.protocol.CommonFields.PRODUCER_ID;\n-import static org.apache.kafka.common.protocol.CommonFields.TOPIC_NAME;\n-import static org.apache.kafka.common.protocol.CommonFields.TRANSACTIONAL_ID;\n-import static org.apache.kafka.common.protocol.types.Type.INT32;\n-\n public class AddPartitionsToTxnRequest extends AbstractRequest {\n-    private static final String TOPICS_KEY_NAME = \"topics\";\n-    private static final String PARTITIONS_KEY_NAME = \"partitions\";\n-\n-    private static final Schema ADD_PARTITIONS_TO_TXN_REQUEST_V0 = new Schema(\n-            TRANSACTIONAL_ID,\n-            PRODUCER_ID,\n-            PRODUCER_EPOCH,\n-            new Field(TOPICS_KEY_NAME, new ArrayOf(new Schema(\n-                    TOPIC_NAME,\n-                    new Field(PARTITIONS_KEY_NAME, new ArrayOf(INT32)))),\n-                    \"The partitions to add to the transaction.\"));\n-\n-    /**\n-     * The version number is bumped to indicate that on quota violation brokers send out responses before throttling.\n-     */\n-    private static final Schema ADD_PARTITIONS_TO_TXN_REQUEST_V1 = ADD_PARTITIONS_TO_TXN_REQUEST_V0;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{ADD_PARTITIONS_TO_TXN_REQUEST_V0, ADD_PARTITIONS_TO_TXN_REQUEST_V1};\n-    }\n+\n+    public final AddPartitionsToTxnRequestData data;\n \n     public static class Builder extends AbstractRequest.Builder<AddPartitionsToTxnRequest> {\n-        private final String transactionalId;\n-        private final long producerId;\n-        private final short producerEpoch;\n-        private final List<TopicPartition> partitions;\n+        public final AddPartitionsToTxnRequestData data;\n \n-        public Builder(String transactionalId, long producerId, short producerEpoch, List<TopicPartition> partitions) {\n+        public Builder(final AddPartitionsToTxnRequestData data) {\n             super(ApiKeys.ADD_PARTITIONS_TO_TXN);\n-            this.transactionalId = transactionalId;\n-            this.producerId = producerId;\n-            this.producerEpoch = producerEpoch;\n-            this.partitions = partitions;\n+            this.data = data;\n+        }\n+\n+        public Builder(final String transactionalId,\n+                       final long producerId,\n+                       final short producerEpoch,\n+                       final List<TopicPartition> partitions) {\n+            super(ApiKeys.ADD_PARTITIONS_TO_TXN);\n+\n+            Map<String, List<Integer>> partitionMap = new HashMap<>();\n+            for (TopicPartition topicPartition : partitions) {\n+                String topicName = topicPartition.topic();\n+\n+                List<Integer> subPartitions = partitionMap.getOrDefault(topicName,\n+                    new ArrayList<>());\n+                subPartitions.add(topicPartition.partition());\n+                partitionMap.put(topicName, subPartitions);\n+            }\n+\n+            AddPartitionsToTxnTopicCollection topics = new AddPartitionsToTxnTopicCollection();\n+            for (Map.Entry<String, List<Integer>> partitionEntry : partitionMap.entrySet()) {\n+                topics.add(new AddPartitionsToTxnTopic()\n+                               .setName(partitionEntry.getKey())\n+                               .setPartitions(partitionEntry.getValue()));\n+            }\n+\n+            this.data = new AddPartitionsToTxnRequestData()\n+                            .setTransactionalId(transactionalId)\n+                            .setProducerId(producerId)\n+                            .setProducerEpoch(producerEpoch)\n+                            .setTopics(topics);\n         }\n \n         @Override\n         public AddPartitionsToTxnRequest build(short version) {\n-            return new AddPartitionsToTxnRequest(version, transactionalId, producerId, producerEpoch, partitions);\n+            return new AddPartitionsToTxnRequest(data, version);\n         }\n \n         public List<TopicPartition> partitions() {\n+            return getPartitions(data);\n+        }\n+\n+        static List<TopicPartition> getPartitions(AddPartitionsToTxnRequestData data) {\n+            List<TopicPartition> partitions = new ArrayList<>();\n+            for (AddPartitionsToTxnTopic topicCollection : data.topics()) {\n+                for (Integer partition : topicCollection.partitions()) {\n+                    partitions.add(new TopicPartition(topicCollection.name(), partition));\n+                }\n+            }\n             return partitions;\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"(type=AddPartitionsToTxnRequest\").\n-                    append(\", transactionalId=\").append(transactionalId).\n-                    append(\", producerId=\").append(producerId).\n-                    append(\", producerEpoch=\").append(producerEpoch).\n-                    append(\", partitions=\").append(partitions).\n-                    append(\")\");\n-            return bld.toString();\n+            return data.toString();\n         }\n     }\n \n-    private final String transactionalId;\n-    private final long producerId;\n-    private final short producerEpoch;\n-    private final List<TopicPartition> partitions;\n-\n-    private AddPartitionsToTxnRequest(short version, String transactionalId, long producerId, short producerEpoch,\n-                                      List<TopicPartition> partitions) {\n+    public AddPartitionsToTxnRequest(final AddPartitionsToTxnRequestData data, short version) {\n         super(ApiKeys.ADD_PARTITIONS_TO_TXN, version);\n-        this.transactionalId = transactionalId;\n-        this.producerId = producerId;\n-        this.producerEpoch = producerEpoch;\n-        this.partitions = partitions;\n+        this.data = data;\n     }\n \n     public AddPartitionsToTxnRequest(Struct struct, short version) {\n         super(ApiKeys.ADD_PARTITIONS_TO_TXN, version);\n-        this.transactionalId = struct.get(TRANSACTIONAL_ID);\n-        this.producerId = struct.get(PRODUCER_ID);\n-        this.producerEpoch = struct.get(PRODUCER_EPOCH);\n-\n-        List<TopicPartition> partitions = new ArrayList<>();\n-        Object[] topicPartitionsArray = struct.getArray(TOPICS_KEY_NAME);\n-        for (Object topicPartitionObj : topicPartitionsArray) {\n-            Struct topicPartitionStruct = (Struct) topicPartitionObj;\n-            String topic = topicPartitionStruct.get(TOPIC_NAME);\n-            for (Object partitionObj : topicPartitionStruct.getArray(PARTITIONS_KEY_NAME)) {\n-                partitions.add(new TopicPartition(topic, (Integer) partitionObj));\n-            }\n-        }\n-        this.partitions = partitions;\n-    }\n-\n-    public String transactionalId() {\n-        return transactionalId;\n-    }\n-\n-    public long producerId() {\n-        return producerId;\n-    }\n-\n-    public short producerEpoch() {\n-        return producerEpoch;\n+        this.data = new AddPartitionsToTxnRequestData(struct, version);\n     }\n \n     public List<TopicPartition> partitions() {\n-        return partitions;\n+        return Builder.getPartitions(data);\n     }\n \n     @Override\n     protected Struct toStruct() {\n-        Struct struct = new Struct(ApiKeys.ADD_PARTITIONS_TO_TXN.requestSchema(version()));\n-        struct.set(TRANSACTIONAL_ID, transactionalId);\n-        struct.set(PRODUCER_ID, producerId);\n-        struct.set(PRODUCER_EPOCH, producerEpoch);\n-\n-        Map<String, List<Integer>> mappedPartitions = CollectionUtils.groupPartitionsByTopic(partitions);\n-        Object[] partitionsArray = new Object[mappedPartitions.size()];\n-        int i = 0;\n-        for (Map.Entry<String, List<Integer>> topicAndPartitions : mappedPartitions.entrySet()) {\n-            Struct topicPartitionsStruct = struct.instance(TOPICS_KEY_NAME);\n-            topicPartitionsStruct.set(TOPIC_NAME, topicAndPartitions.getKey());\n-            topicPartitionsStruct.set(PARTITIONS_KEY_NAME, topicAndPartitions.getValue().toArray());\n-            partitionsArray[i++] = topicPartitionsStruct;\n-        }\n-\n-        struct.set(TOPICS_KEY_NAME, partitionsArray);\n-        return struct;\n+        return data.toStruct(version());\n     }\n \n     @Override\n     public AddPartitionsToTxnResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n         final HashMap<TopicPartition, Errors> errors = new HashMap<>();\n-        for (TopicPartition partition : partitions) {\n+        for (TopicPartition partition : Builder.getPartitions(data)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e2c2839303eb3e1c8c010e93d752510aa7995ae"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM3NTk5NA==", "bodyText": "Similar here, we can cache the result in case to be reused.", "url": "https://github.com/apache/kafka/pull/8326#discussion_r413375994", "createdAt": "2020-04-22T22:29:03Z", "author": {"login": "guozhangwang"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AddPartitionsToTxnResponse.java", "diffHunk": "@@ -17,129 +17,108 @@\n package org.apache.kafka.common.requests;\n \n import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.AddPartitionsToTxnResponseData;\n+import org.apache.kafka.common.message.AddPartitionsToTxnResponseData.AddPartitionsToTxnPartitionResult;\n+import org.apache.kafka.common.message.AddPartitionsToTxnResponseData.AddPartitionsToTxnPartitionResultCollection;\n+import org.apache.kafka.common.message.AddPartitionsToTxnResponseData.AddPartitionsToTxnTopicResult;\n+import org.apache.kafka.common.message.AddPartitionsToTxnResponseData.AddPartitionsToTxnTopicResultCollection;\n import org.apache.kafka.common.protocol.ApiKeys;\n import org.apache.kafka.common.protocol.Errors;\n-import org.apache.kafka.common.protocol.types.ArrayOf;\n-import org.apache.kafka.common.protocol.types.Field;\n-import org.apache.kafka.common.protocol.types.Schema;\n import org.apache.kafka.common.protocol.types.Struct;\n-import org.apache.kafka.common.utils.CollectionUtils;\n \n import java.nio.ByteBuffer;\n-import java.util.ArrayList;\n import java.util.HashMap;\n-import java.util.List;\n import java.util.Map;\n \n-import static org.apache.kafka.common.protocol.CommonFields.ERROR_CODE;\n-import static org.apache.kafka.common.protocol.CommonFields.PARTITION_ID;\n-import static org.apache.kafka.common.protocol.CommonFields.THROTTLE_TIME_MS;\n-import static org.apache.kafka.common.protocol.CommonFields.TOPIC_NAME;\n-\n+/**\n+ * Possible error codes:\n+ *\n+ *   - {@link Errors#NOT_COORDINATOR}\n+ *   - {@link Errors#COORDINATOR_NOT_AVAILABLE}\n+ *   - {@link Errors#COORDINATOR_LOAD_IN_PROGRESS}\n+ *   - {@link Errors#INVALID_TXN_STATE}\n+ *   - {@link Errors#INVALID_PRODUCER_ID_MAPPING}\n+ *   - {@link Errors#INVALID_PRODUCER_EPOCH}\n+ *   - {@link Errors#TOPIC_AUTHORIZATION_FAILED}\n+ *   - {@link Errors#TRANSACTIONAL_ID_AUTHORIZATION_FAILED}\n+ *   - {@link Errors#UNKNOWN_TOPIC_OR_PARTITION}\n+ */\n public class AddPartitionsToTxnResponse extends AbstractResponse {\n-    private static final String ERRORS_KEY_NAME = \"errors\";\n-    private static final String PARTITION_ERRORS = \"partition_errors\";\n-\n-    private static final Schema ADD_PARTITIONS_TO_TXN_RESPONSE_V0 = new Schema(\n-            THROTTLE_TIME_MS,\n-            new Field(ERRORS_KEY_NAME, new ArrayOf(new Schema(\n-                    TOPIC_NAME,\n-                    new Field(PARTITION_ERRORS, new ArrayOf(new Schema(\n-                            PARTITION_ID,\n-                            ERROR_CODE)))))));\n-\n-    /**\n-     * The version number is bumped to indicate that on quota violation brokers send out responses before throttling.\n-     */\n-    private static final Schema ADD_PARTITIONS_TO_TXN_RESPONSE_V1 = ADD_PARTITIONS_TO_TXN_RESPONSE_V0;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{ADD_PARTITIONS_TO_TXN_RESPONSE_V0, ADD_PARTITIONS_TO_TXN_RESPONSE_V1};\n-    }\n \n-    private final int throttleTimeMs;\n-\n-    // Possible error codes:\n-    //   NotCoordinator\n-    //   CoordinatorNotAvailable\n-    //   CoordinatorLoadInProgress\n-    //   InvalidTxnState\n-    //   InvalidProducerIdMapping\n-    //   TopicAuthorizationFailed\n-    //   InvalidProducerEpoch\n-    //   UnknownTopicOrPartition\n-    //   TopicAuthorizationFailed\n-    //   TransactionalIdAuthorizationFailed\n-    private final Map<TopicPartition, Errors> errors;\n+    public final AddPartitionsToTxnResponseData data;\n \n-    public AddPartitionsToTxnResponse(int throttleTimeMs, Map<TopicPartition, Errors> errors) {\n-        this.throttleTimeMs = throttleTimeMs;\n-        this.errors = errors;\n+    public AddPartitionsToTxnResponse(Struct struct, short version) {\n+        this.data = new AddPartitionsToTxnResponseData(struct, version);\n     }\n \n-    public AddPartitionsToTxnResponse(Struct struct) {\n-        this.throttleTimeMs = struct.get(THROTTLE_TIME_MS);\n-        errors = new HashMap<>();\n-        for (Object topic : struct.getArray(ERRORS_KEY_NAME)) {\n-            Struct topicStruct = (Struct) topic;\n-            final String topicName = topicStruct.get(TOPIC_NAME);\n-            for (Object partition : topicStruct.getArray(PARTITION_ERRORS)) {\n-                Struct partitionStruct = (Struct) partition;\n-                TopicPartition topicPartition = new TopicPartition(topicName, partitionStruct.get(PARTITION_ID));\n-                errors.put(topicPartition, Errors.forCode(partitionStruct.get(ERROR_CODE)));\n-            }\n+    public AddPartitionsToTxnResponse(int throttleTimeMs, Map<TopicPartition, Errors> errors) {\n+\n+        Map<String, AddPartitionsToTxnPartitionResultCollection> resultMap = new HashMap<>();\n+\n+        for (Map.Entry<TopicPartition, Errors> entry : errors.entrySet()) {\n+            TopicPartition topicPartition = entry.getKey();\n+            String topicName = topicPartition.topic();\n+\n+            AddPartitionsToTxnPartitionResult partitionResult =\n+                new AddPartitionsToTxnPartitionResult()\n+                    .setErrorCode(entry.getValue().code())\n+                    .setPartitionIndex(topicPartition.partition());\n+\n+            AddPartitionsToTxnPartitionResultCollection partitionResultCollection = resultMap.getOrDefault(\n+                topicName, new AddPartitionsToTxnPartitionResultCollection()\n+            );\n+\n+            partitionResultCollection.add(partitionResult);\n+            resultMap.put(topicName, partitionResultCollection);\n+        }\n+\n+        AddPartitionsToTxnTopicResultCollection topicCollection = new AddPartitionsToTxnTopicResultCollection();\n+        for (Map.Entry<String, AddPartitionsToTxnPartitionResultCollection> entry : resultMap.entrySet()) {\n+            topicCollection.add(new AddPartitionsToTxnTopicResult()\n+                                    .setName(entry.getKey())\n+                                    .setResults(entry.getValue()));\n         }\n+\n+        this.data = new AddPartitionsToTxnResponseData()\n+                        .setThrottleTimeMs(throttleTimeMs)\n+                        .setResults(topicCollection);\n     }\n \n     @Override\n     public int throttleTimeMs() {\n-        return throttleTimeMs;\n+        return data.throttleTimeMs();\n     }\n \n     public Map<TopicPartition, Errors> errors() {\n-        return errors;\n+        Map<TopicPartition, Errors> errorsMap = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e2c2839303eb3e1c8c010e93d752510aa7995ae"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM4NjI2OQ==", "bodyText": "Why we want to change the test name?", "url": "https://github.com/apache/kafka/pull/8326#discussion_r413386269", "createdAt": "2020-04-22T22:52:25Z", "author": {"login": "guozhangwang"}, "path": "core/src/test/scala/unit/kafka/server/AddPartitionsToTxnRequestServerTest.scala", "diffHunk": "@@ -27,9 +27,9 @@ import org.junit.{Before, Test}\n \n import scala.jdk.CollectionConverters._\n \n-class AddPartitionsToTxnRequestTest extends BaseRequestTest {\n-  private val topic1 = \"foobartopic\"\n-  val numPartitions = 3\n+class AddPartitionsToTxnRequestServerTest extends BaseRequestTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e2c2839303eb3e1c8c010e93d752510aa7995ae"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4cb06d77b368276acc88df339ac456105af76e53", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/4cb06d77b368276acc88df339ac456105af76e53", "committedDate": "2020-04-23T03:01:17Z", "message": "add cached partitions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32980c7e32353d195081f8d027dd71b09a6fbfc7", "author": {"user": {"login": "abbccdda", "name": "Boyang Chen"}}, "url": "https://github.com/apache/kafka/commit/32980c7e32353d195081f8d027dd71b09a6fbfc7", "committedDate": "2020-04-23T04:09:21Z", "message": "address comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 344, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}