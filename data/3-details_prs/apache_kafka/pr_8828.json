{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMwNDIwNjIx", "number": 8828, "title": "KAFKA-9216: Enforce that Connect\u2019s internal topics use `compact` cleanup policy", "bodyText": "Supplements #8270\nThis change adds a check to the KafkaConfigBackingStore, KafkaOffsetBackingStore, and KafkaStatusBackingStore to use the admin client to verify that the internal topics are compacted and do not use the delete cleanup policy.\nConnect already will create the internal topics with cleanup.policy=compact if the topics do not yet exist when the Connect workers are started; the new topics are created always as compacted, overwriting any user-specified cleanup.policy. However, if the topics already exist the worker did not previously verify the internal topics were compacted, such as when a user manually creates the internal topics before starting Connect or manually changes the topic settings after the fact.\nThe current change helps guard against users running Connect with topics that have delete cleanup policy enabled, which will remove all connector configurations, source offsets, and connector & task statuses that are older than the retention time. This means that, for example, the configuation for a long-running connector could be deleted by the broker, and this will cause restart issues upon a subsequent rebalance or restarting of Connect worker(s).\nConnect behavior requires that its internal topics are compacted and not deleted after some retention time. Therefore, this additional check is simply enforcing the existing expectations, and therefore does not need a KIP.\nAdded unit tests for the new logic, and added an integration test that verifies that the worker will fail to start if each of the three internal topics does not use only cleanup.policy=compact.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-06-07T22:02:48Z", "url": "https://github.com/apache/kafka/pull/8828", "merged": true, "mergeCommit": {"oid": "48b56e533b3ff22ae0e2cf7fcc649e7df19f2b06"}, "closed": true, "closedAt": "2020-06-11T03:39:53Z", "author": {"login": "rhauch"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcpDM6oAH2gAyNDMwNDIwNjIxOjg1NWYwMTZjMDdiMWYzN2FiMjVmNjc5NTQyZGM4YTk3MmI0MjU0NGQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcqF0wXgH2gAyNDMwNDIwNjIxOmVmNGM5OTRlNTdhMzIxY2NkNTYyZDMxYWQ1ZmIzMmZmODEzZTlmYjk=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "855f016c07b1f37ab25f679542dc8a972b42544d", "author": {"user": {"login": "rhauch", "name": "Randall Hauch"}}, "url": "https://github.com/apache/kafka/commit/855f016c07b1f37ab25f679542dc8a972b42544d", "committedDate": "2020-06-07T22:00:48Z", "message": "KAFKA-9216: Enforce that Connect\u2019s internal topics use `compact` cleanup policy\n\nThis change adds a check to the KafkaConfigBackingStore, KafkaOffsetBackingStore, and KafkaStatusBackingStore to use the admin client to verify that the internal topics are compacted and do not use the `delete` cleanup policy.\n\nConnect already will create the internal topics with `cleanup.policy=compact` if the topics do not yet exist when the Connect workers are started; the new topics are created always as compacted, overwriting any user-specified `cleanup.policy`. However, if the topics already exist the worker did not previously verify the internal topics were compacted, such as when a user manually creates the internal topics before starting Connect or manually changes the topic settings after the fact.\n\nThe current change helps guard against users running Connect with topics that have delete cleanup policy enabled, which will remove all connector configurations, source offsets, and connector & task statuses that are older than the retention time. This means that, for example, the configuation for a long-running connector could be deleted by the broker, and this will cause restart issues upon a subsequent rebalance or restarting of Connect worker(s).\n\nConnect behavior requires that its internal topics are compacted and not deleted after some retention time. Therefore, this additional check is simply enforcing the existing expectations, and therefore does not need a KIP."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb2f4c323856d0f35c4628df08bdb37d121d4613", "author": {"user": {"login": "rhauch", "name": "Randall Hauch"}}, "url": "https://github.com/apache/kafka/commit/eb2f4c323856d0f35c4628df08bdb37d121d4613", "committedDate": "2020-06-07T22:48:24Z", "message": "KAFKA-9216: Added logic to skip this check if the topic cleanup policy could not be returned\n\nIf the Kafka principal that Connect uses for internal topics does not have proper ACLs or the Kafka broker is older than 0.11.0.0, the worker will not be able to validate the cleanup policy for the internal topics. This should not cause the worker to fail."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1ODY1Njk5", "url": "https://github.com/apache/kafka/pull/8828#pullrequestreview-425865699", "createdAt": "2020-06-08T00:15:10Z", "commit": {"oid": "eb2f4c323856d0f35c4628df08bdb37d121d4613"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwMDoxNToxMFrOGgMr_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwMToyNjoxN1rOGgNH0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQxNTQ4Ng==", "bodyText": "volatile boolean is equivalent to AtomicBoolean and if we are not going to use any of the compare-and-set/get-and-set capabilities of the atomic class, maybe you'd want to consider using volatile instead to avoid the boilerplate of calling get/set on that boolean variable. But of course, the decision is a matter of style too.", "url": "https://github.com/apache/kafka/pull/8828#discussion_r436415486", "createdAt": "2020-06-08T00:15:10Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/AbstractHerder.java", "diffHunk": "@@ -94,6 +95,7 @@\n     protected final StatusBackingStore statusBackingStore;\n     protected final ConfigBackingStore configBackingStore;\n     private final ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy;\n+    protected final AtomicBoolean running = new AtomicBoolean(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb2f4c323856d0f35c4628df08bdb37d121d4613"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQyMTE2OQ==", "bodyText": "Vararg gives some unintended consequences in naming. Should we stick to singular given that we expect at most a single topic to be created?", "url": "https://github.com/apache/kafka/pull/8828#discussion_r436421169", "createdAt": "2020-06-08T01:14:28Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaConfigBackingStore.java", "diffHunk": "@@ -492,7 +493,14 @@ public void putSessionKey(SessionKey sessionKey) {\n             public void run() {\n                 log.debug(\"Creating admin client to manage Connect internal config topic\");\n                 try (TopicAdmin admin = new TopicAdmin(adminProps)) {\n-                    admin.createTopics(topicDescription);\n+                    // Create the topic if it doesn't exist\n+                    Set<String> newTopics = admin.createTopics(topicDescription);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb2f4c323856d0f35c4628df08bdb37d121d4613"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQyMTY0Nw==", "bodyText": "nit: should we keep 2 tabs alignment for everything?", "url": "https://github.com/apache/kafka/pull/8828#discussion_r436421647", "createdAt": "2020-06-08T01:18:32Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/TopicAdmin.java", "diffHunk": "@@ -375,6 +383,152 @@ public boolean createTopic(NewTopic topic) {\n         return existingTopics;\n     }\n \n+    /**\n+     * Verify the named topic uses only compaction for the cleanup policy.\n+     *\n+     * @param topic             the name of the topic\n+     * @param workerTopicConfig the name of the worker configuration that specifies the topic name\n+     * @return true if the admin client could be used to verify the topic setting, or false if\n+     *         the verification could not be performed, likely because the admin client principal\n+     *         did not have the required permissions or because the broker was older than 0.11.0.0\n+     * @throws ConfigException if the actual topic setting did not match the required setting\n+     */\n+    public boolean verifyTopicCleanupPolicyOnlyCompact(String topic, String workerTopicConfig,\n+            String topicPurpose) {\n+        Set<String> cleanupPolicies = topicCleanupPolicy(topic);\n+        if (cleanupPolicies == null || cleanupPolicies.isEmpty()) {\n+            log.debug(\"Unable to use admin client to verify the cleanup policy of '{}' \"\n+                      + \"topic is '{}', either because the broker is an older \"\n+                      + \"version or because the Kafka principal used for Connect \"\n+                      + \"internal topics does not have the required permission to \"\n+                      + \"describe topic configurations.\", topic, TopicConfig.CLEANUP_POLICY_COMPACT);\n+            return false;\n+        }\n+        String cleanupPolicyStr = String.join(\",\", cleanupPolicies);\n+        log.debug(\"Found cleanup policy for '{}' topic is '{}'\", topic, cleanupPolicyStr);\n+        Set<String> expectedPolicies = Collections.singleton(TopicConfig.CLEANUP_POLICY_COMPACT);\n+        String expectedPolicyStr = String.join(\",\", expectedPolicies);\n+        if (cleanupPolicies != null && !cleanupPolicies.equals(expectedPolicies)) {\n+            String msg = String.format(\"Topic '%s' supplied via the '%s' property is required \"\n+                                       + \"to have '%s=%s' to guarantee consistency and durability of \"\n+                                       + \"%s, but found '%s'. \"\n+                                       + \"Correct the topic before restarting Connect.\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb2f4c323856d0f35c4628df08bdb37d121d4613"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQyMjE3Mw==", "bodyText": "I wonder if distinguishing like that, with null and empty pays off.\nWhy not return an empty collection in both cases and simplify the checks on the return values of this method?\nThis method doesn't seem to be the one to use when somebody wants to determine whether a topic exists or not.", "url": "https://github.com/apache/kafka/pull/8828#discussion_r436422173", "createdAt": "2020-06-08T01:22:35Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/TopicAdmin.java", "diffHunk": "@@ -375,6 +383,152 @@ public boolean createTopic(NewTopic topic) {\n         return existingTopics;\n     }\n \n+    /**\n+     * Verify the named topic uses only compaction for the cleanup policy.\n+     *\n+     * @param topic             the name of the topic\n+     * @param workerTopicConfig the name of the worker configuration that specifies the topic name\n+     * @return true if the admin client could be used to verify the topic setting, or false if\n+     *         the verification could not be performed, likely because the admin client principal\n+     *         did not have the required permissions or because the broker was older than 0.11.0.0\n+     * @throws ConfigException if the actual topic setting did not match the required setting\n+     */\n+    public boolean verifyTopicCleanupPolicyOnlyCompact(String topic, String workerTopicConfig,\n+            String topicPurpose) {\n+        Set<String> cleanupPolicies = topicCleanupPolicy(topic);\n+        if (cleanupPolicies == null || cleanupPolicies.isEmpty()) {\n+            log.debug(\"Unable to use admin client to verify the cleanup policy of '{}' \"\n+                      + \"topic is '{}', either because the broker is an older \"\n+                      + \"version or because the Kafka principal used for Connect \"\n+                      + \"internal topics does not have the required permission to \"\n+                      + \"describe topic configurations.\", topic, TopicConfig.CLEANUP_POLICY_COMPACT);\n+            return false;\n+        }\n+        String cleanupPolicyStr = String.join(\",\", cleanupPolicies);\n+        log.debug(\"Found cleanup policy for '{}' topic is '{}'\", topic, cleanupPolicyStr);\n+        Set<String> expectedPolicies = Collections.singleton(TopicConfig.CLEANUP_POLICY_COMPACT);\n+        String expectedPolicyStr = String.join(\",\", expectedPolicies);\n+        if (cleanupPolicies != null && !cleanupPolicies.equals(expectedPolicies)) {\n+            String msg = String.format(\"Topic '%s' supplied via the '%s' property is required \"\n+                                       + \"to have '%s=%s' to guarantee consistency and durability of \"\n+                                       + \"%s, but found '%s'. \"\n+                                       + \"Correct the topic before restarting Connect.\",\n+                    topic, workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr,\n+                    topicPurpose, cleanupPolicyStr);\n+            throw new ConfigException(msg);\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Get the cleanup policy for a topic.\n+     *\n+     * @param topic the name of the topic\n+     * @return the set of cleanup policies set for the topic; may be empty if the topic exists", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb2f4c323856d0f35c4628df08bdb37d121d4613"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQyMjYwOA==", "bodyText": "nit: don't we need a space between the varargs type and the variable name? I'm surprised mainly at checkstyle here.", "url": "https://github.com/apache/kafka/pull/8828#discussion_r436422608", "createdAt": "2020-06-08T01:26:17Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/TopicAdmin.java", "diffHunk": "@@ -375,6 +383,152 @@ public boolean createTopic(NewTopic topic) {\n         return existingTopics;\n     }\n \n+    /**\n+     * Verify the named topic uses only compaction for the cleanup policy.\n+     *\n+     * @param topic             the name of the topic\n+     * @param workerTopicConfig the name of the worker configuration that specifies the topic name\n+     * @return true if the admin client could be used to verify the topic setting, or false if\n+     *         the verification could not be performed, likely because the admin client principal\n+     *         did not have the required permissions or because the broker was older than 0.11.0.0\n+     * @throws ConfigException if the actual topic setting did not match the required setting\n+     */\n+    public boolean verifyTopicCleanupPolicyOnlyCompact(String topic, String workerTopicConfig,\n+            String topicPurpose) {\n+        Set<String> cleanupPolicies = topicCleanupPolicy(topic);\n+        if (cleanupPolicies == null || cleanupPolicies.isEmpty()) {\n+            log.debug(\"Unable to use admin client to verify the cleanup policy of '{}' \"\n+                      + \"topic is '{}', either because the broker is an older \"\n+                      + \"version or because the Kafka principal used for Connect \"\n+                      + \"internal topics does not have the required permission to \"\n+                      + \"describe topic configurations.\", topic, TopicConfig.CLEANUP_POLICY_COMPACT);\n+            return false;\n+        }\n+        String cleanupPolicyStr = String.join(\",\", cleanupPolicies);\n+        log.debug(\"Found cleanup policy for '{}' topic is '{}'\", topic, cleanupPolicyStr);\n+        Set<String> expectedPolicies = Collections.singleton(TopicConfig.CLEANUP_POLICY_COMPACT);\n+        String expectedPolicyStr = String.join(\",\", expectedPolicies);\n+        if (cleanupPolicies != null && !cleanupPolicies.equals(expectedPolicies)) {\n+            String msg = String.format(\"Topic '%s' supplied via the '%s' property is required \"\n+                                       + \"to have '%s=%s' to guarantee consistency and durability of \"\n+                                       + \"%s, but found '%s'. \"\n+                                       + \"Correct the topic before restarting Connect.\",\n+                    topic, workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr,\n+                    topicPurpose, cleanupPolicyStr);\n+            throw new ConfigException(msg);\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Get the cleanup policy for a topic.\n+     *\n+     * @param topic the name of the topic\n+     * @return the set of cleanup policies set for the topic; may be empty if the topic exists\n+     *         but has no cleanup policy, or may be null if the topic does not exist\n+     */\n+    public Set<String> topicCleanupPolicy(String topic) {\n+        Config topicConfig = describeTopicConfig(topic);\n+        if (topicConfig == null) {\n+            return null;\n+        }\n+        ConfigEntry entry = topicConfig.get(CLEANUP_POLICY_CONFIG);\n+        if (entry != null && entry.value() != null) {\n+            String policyStr = entry.value();\n+            return Arrays.stream(policyStr.split(\",\"))\n+                         .map(String::trim)\n+                         .map(String::toLowerCase)\n+                         .collect(Collectors.toSet());\n+        }\n+        return Collections.emptySet();\n+    }\n+\n+    /**\n+     * Attempt to fetch the topic configuration for the given topic.\n+     * Apache Kafka added support for describing topic configurations in 0.11.0.0, so this method\n+     * works as expected with that and later versions. With brokers older than 0.11.0.0, this method\n+     * is unable get the topic configurations and always returns a null value.\n+     *\n+     * <p>If the topic does not exist, a null value is returned.\n+     *\n+     * @param topic the name of the topic for which the topic configuration should be obtained\n+     * @return true if the operation was successful, or false if no topics were described\n+     * @throws RetriableException if a retriable error occurs, the operation takes too long, or the\n+     *         thread is interrupted while attempting to perform this operation\n+     * @throws ConnectException if a non retriable error occurs\n+     */\n+    public Config describeTopicConfig(String topic) {\n+        return describeTopicConfigs(topic).get(topic);\n+    }\n+\n+    /**\n+     * Attempt to fetch the topic configurations for the given topics.\n+     * Apache Kafka added support for describing topic configurations in 0.11.0.0, so this method\n+     * works as expected with that and later versions. With brokers older than 0.11.0.0, this method\n+     * is unable get the topic configurations and always returns an empty set.\n+     *\n+     * <p>An entry with a null Config is placed into the resulting map for any topic that does\n+     * not exist on the brokers.\n+     *\n+     * @param topicNames the topics to obtain configurations\n+     * @return true if the operation was successful, or false if no topics were described\n+     * @throws RetriableException if a retriable error occurs, the operation takes too long, or the\n+     *         thread is interrupted while attempting to perform this operation\n+     * @throws ConnectException if a non retriable error occurs\n+     */\n+    public Map<String, Config> describeTopicConfigs(String...topicNames) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb2f4c323856d0f35c4628df08bdb37d121d4613"}, "originalPosition": 131}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NDY5Mzk0", "url": "https://github.com/apache/kafka/pull/8828#pullrequestreview-426469394", "createdAt": "2020-06-08T17:39:47Z", "commit": {"oid": "eb2f4c323856d0f35c4628df08bdb37d121d4613"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzozOTo0N1rOGgpGgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxNzozOTo0N1rOGgpGgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg4MTAyNg==", "bodyText": "Is it possible that this will also be true if there isn't a cleanup policy configured on the topic?", "url": "https://github.com/apache/kafka/pull/8828#discussion_r436881026", "createdAt": "2020-06-08T17:39:47Z", "author": {"login": "C0urante"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/TopicAdmin.java", "diffHunk": "@@ -375,6 +383,152 @@ public boolean createTopic(NewTopic topic) {\n         return existingTopics;\n     }\n \n+    /**\n+     * Verify the named topic uses only compaction for the cleanup policy.\n+     *\n+     * @param topic             the name of the topic\n+     * @param workerTopicConfig the name of the worker configuration that specifies the topic name\n+     * @return true if the admin client could be used to verify the topic setting, or false if\n+     *         the verification could not be performed, likely because the admin client principal\n+     *         did not have the required permissions or because the broker was older than 0.11.0.0\n+     * @throws ConfigException if the actual topic setting did not match the required setting\n+     */\n+    public boolean verifyTopicCleanupPolicyOnlyCompact(String topic, String workerTopicConfig,\n+            String topicPurpose) {\n+        Set<String> cleanupPolicies = topicCleanupPolicy(topic);\n+        if (cleanupPolicies == null || cleanupPolicies.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb2f4c323856d0f35c4628df08bdb37d121d4613"}, "originalPosition": 51}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ead451a41e10ecfe2e824293351a8e2836556d3b", "author": {"user": {"login": "rhauch", "name": "Randall Hauch"}}, "url": "https://github.com/apache/kafka/commit/ead451a41e10ecfe2e824293351a8e2836556d3b", "committedDate": "2020-06-10T20:57:17Z", "message": "KAFKA-9216: Used volatile instead of AtomicBoolean"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e9322cbe157cbe41fbd384e9d8eb30424d95f96", "author": {"user": {"login": "rhauch", "name": "Randall Hauch"}}, "url": "https://github.com/apache/kafka/commit/5e9322cbe157cbe41fbd384e9d8eb30424d95f96", "committedDate": "2020-06-10T21:09:26Z", "message": "KAFKA-9216: Incorporated review feedback by improving semantics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5612e697fe0a031a10b8d6c53a0bab3f8c2b4de8", "author": {"user": {"login": "rhauch", "name": "Randall Hauch"}}, "url": "https://github.com/apache/kafka/commit/5612e697fe0a031a10b8d6c53a0bab3f8c2b4de8", "committedDate": "2020-06-10T21:10:47Z", "message": "KAFKA-9216: Corrected test case"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NTI2NjEz", "url": "https://github.com/apache/kafka/pull/8828#pullrequestreview-428526613", "createdAt": "2020-06-11T01:08:12Z", "commit": {"oid": "5612e697fe0a031a10b8d6c53a0bab3f8c2b4de8"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQwMTowODoxMlrOGiLMvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQwMTowOTowNFrOGiLNiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ4ODI1NQ==", "bodyText": "Should we consider info? It's a one time message right?", "url": "https://github.com/apache/kafka/pull/8828#discussion_r438488255", "createdAt": "2020-06-11T01:08:12Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/TopicAdmin.java", "diffHunk": "@@ -375,6 +383,162 @@ public boolean createTopic(NewTopic topic) {\n         return existingTopics;\n     }\n \n+    /**\n+     * Verify the named topic uses only compaction for the cleanup policy.\n+     *\n+     * @param topic             the name of the topic\n+     * @param workerTopicConfig the name of the worker configuration that specifies the topic name\n+     * @return true if the admin client could be used to verify the topic setting, or false if\n+     *         the verification could not be performed, likely because the admin client principal\n+     *         did not have the required permissions or because the broker was older than 0.11.0.0\n+     * @throws ConfigException if the actual topic setting did not match the required setting\n+     */\n+    public boolean verifyTopicCleanupPolicyOnlyCompact(String topic, String workerTopicConfig,\n+            String topicPurpose) {\n+        Set<String> cleanupPolicies = topicCleanupPolicy(topic);\n+        if (cleanupPolicies.isEmpty()) {\n+            log.debug(\"Unable to use admin client to verify the cleanup policy of '{}' \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5612e697fe0a031a10b8d6c53a0bab3f8c2b4de8"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ4ODQ0NA==", "bodyText": "same question around log level as above", "url": "https://github.com/apache/kafka/pull/8828#discussion_r438488444", "createdAt": "2020-06-11T01:09:00Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/TopicAdmin.java", "diffHunk": "@@ -375,6 +383,162 @@ public boolean createTopic(NewTopic topic) {\n         return existingTopics;\n     }\n \n+    /**\n+     * Verify the named topic uses only compaction for the cleanup policy.\n+     *\n+     * @param topic             the name of the topic\n+     * @param workerTopicConfig the name of the worker configuration that specifies the topic name\n+     * @return true if the admin client could be used to verify the topic setting, or false if\n+     *         the verification could not be performed, likely because the admin client principal\n+     *         did not have the required permissions or because the broker was older than 0.11.0.0\n+     * @throws ConfigException if the actual topic setting did not match the required setting\n+     */\n+    public boolean verifyTopicCleanupPolicyOnlyCompact(String topic, String workerTopicConfig,\n+            String topicPurpose) {\n+        Set<String> cleanupPolicies = topicCleanupPolicy(topic);\n+        if (cleanupPolicies.isEmpty()) {\n+            log.debug(\"Unable to use admin client to verify the cleanup policy of '{}' \"\n+                      + \"topic is '{}', either because the broker is an older \"\n+                      + \"version or because the Kafka principal used for Connect \"\n+                      + \"internal topics does not have the required permission to \"\n+                      + \"describe topic configurations.\", topic, TopicConfig.CLEANUP_POLICY_COMPACT);\n+            return false;\n+        }\n+        Set<String> expectedPolicies = Collections.singleton(TopicConfig.CLEANUP_POLICY_COMPACT);\n+        if (!cleanupPolicies.equals(expectedPolicies)) {\n+            String expectedPolicyStr = String.join(\",\", expectedPolicies);\n+            String cleanupPolicyStr = String.join(\",\", cleanupPolicies);\n+            String msg = String.format(\"Topic '%s' supplied via the '%s' property is required \"\n+                    + \"to have '%s=%s' to guarantee consistency and durability of \"\n+                    + \"%s, but found the topic currently has '%s=%s'. Continuing would likely \"\n+                    + \"result in eventually losing %s and problems restarting this Connect \"\n+                    + \"cluster in the future. Change the '%s' property in the \"\n+                    + \"Connect worker configurations to use a topic with '%s=%s'.\",\n+                    topic, workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr,\n+                    topicPurpose, TopicConfig.CLEANUP_POLICY_CONFIG, cleanupPolicyStr, topicPurpose,\n+                    workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr);\n+            throw new ConfigException(msg);\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Get the cleanup policy for a topic.\n+     *\n+     * @param topic the name of the topic\n+     * @return the set of cleanup policies set for the topic; may be empty if the topic does not\n+     *         exist or the topic's cleanup policy could not be retrieved\n+     */\n+    public Set<String> topicCleanupPolicy(String topic) {\n+        Config topicConfig = describeTopicConfig(topic);\n+        if (topicConfig == null) {\n+            // The topic must not exist\n+            log.debug(\"Unable to find topic '{}' when getting cleanup policy\", topic);\n+            return Collections.emptySet();\n+        }\n+        ConfigEntry entry = topicConfig.get(CLEANUP_POLICY_CONFIG);\n+        if (entry != null && entry.value() != null) {\n+            String policyStr = entry.value();\n+            log.debug(\"Found cleanup.policy={} for topic '{}'\", policyStr, topic);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5612e697fe0a031a10b8d6c53a0bab3f8c2b4de8"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ4ODQ1OQ==", "bodyText": "same question around log level as above", "url": "https://github.com/apache/kafka/pull/8828#discussion_r438488459", "createdAt": "2020-06-11T01:09:04Z", "author": {"login": "kkonstantine"}, "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/TopicAdmin.java", "diffHunk": "@@ -375,6 +383,162 @@ public boolean createTopic(NewTopic topic) {\n         return existingTopics;\n     }\n \n+    /**\n+     * Verify the named topic uses only compaction for the cleanup policy.\n+     *\n+     * @param topic             the name of the topic\n+     * @param workerTopicConfig the name of the worker configuration that specifies the topic name\n+     * @return true if the admin client could be used to verify the topic setting, or false if\n+     *         the verification could not be performed, likely because the admin client principal\n+     *         did not have the required permissions or because the broker was older than 0.11.0.0\n+     * @throws ConfigException if the actual topic setting did not match the required setting\n+     */\n+    public boolean verifyTopicCleanupPolicyOnlyCompact(String topic, String workerTopicConfig,\n+            String topicPurpose) {\n+        Set<String> cleanupPolicies = topicCleanupPolicy(topic);\n+        if (cleanupPolicies.isEmpty()) {\n+            log.debug(\"Unable to use admin client to verify the cleanup policy of '{}' \"\n+                      + \"topic is '{}', either because the broker is an older \"\n+                      + \"version or because the Kafka principal used for Connect \"\n+                      + \"internal topics does not have the required permission to \"\n+                      + \"describe topic configurations.\", topic, TopicConfig.CLEANUP_POLICY_COMPACT);\n+            return false;\n+        }\n+        Set<String> expectedPolicies = Collections.singleton(TopicConfig.CLEANUP_POLICY_COMPACT);\n+        if (!cleanupPolicies.equals(expectedPolicies)) {\n+            String expectedPolicyStr = String.join(\",\", expectedPolicies);\n+            String cleanupPolicyStr = String.join(\",\", cleanupPolicies);\n+            String msg = String.format(\"Topic '%s' supplied via the '%s' property is required \"\n+                    + \"to have '%s=%s' to guarantee consistency and durability of \"\n+                    + \"%s, but found the topic currently has '%s=%s'. Continuing would likely \"\n+                    + \"result in eventually losing %s and problems restarting this Connect \"\n+                    + \"cluster in the future. Change the '%s' property in the \"\n+                    + \"Connect worker configurations to use a topic with '%s=%s'.\",\n+                    topic, workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr,\n+                    topicPurpose, TopicConfig.CLEANUP_POLICY_CONFIG, cleanupPolicyStr, topicPurpose,\n+                    workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr);\n+            throw new ConfigException(msg);\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Get the cleanup policy for a topic.\n+     *\n+     * @param topic the name of the topic\n+     * @return the set of cleanup policies set for the topic; may be empty if the topic does not\n+     *         exist or the topic's cleanup policy could not be retrieved\n+     */\n+    public Set<String> topicCleanupPolicy(String topic) {\n+        Config topicConfig = describeTopicConfig(topic);\n+        if (topicConfig == null) {\n+            // The topic must not exist\n+            log.debug(\"Unable to find topic '{}' when getting cleanup policy\", topic);\n+            return Collections.emptySet();\n+        }\n+        ConfigEntry entry = topicConfig.get(CLEANUP_POLICY_CONFIG);\n+        if (entry != null && entry.value() != null) {\n+            String policyStr = entry.value();\n+            log.debug(\"Found cleanup.policy={} for topic '{}'\", policyStr, topic);\n+            return Arrays.stream(policyStr.split(\",\"))\n+                         .map(String::trim)\n+                         .filter(s -> !s.isEmpty())\n+                         .map(String::toLowerCase)\n+                         .collect(Collectors.toSet());\n+        }\n+        // This is unexpected, as the topic config should include the cleanup.policy even if\n+        // the topic settings don't override the broker's log.cleanup.policy. But just to be safe.\n+        log.debug(\"Found no cleanup.policy for topic '{}'\", topic);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5612e697fe0a031a10b8d6c53a0bab3f8c2b4de8"}, "originalPosition": 103}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef4c994e57a321ccd562d31ad5fb32ff813e9fb9", "author": {"user": {"login": "rhauch", "name": "Randall Hauch"}}, "url": "https://github.com/apache/kafka/commit/ef4c994e57a321ccd562d31ad5fb32ff813e9fb9", "committedDate": "2020-06-11T03:38:03Z", "message": "KAFKA-9216: Changed one log message to info"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 911, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}