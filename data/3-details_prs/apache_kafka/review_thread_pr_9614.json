{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIzMzc5Nzk5", "number": 9614, "reviewThreads": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxODozNzoyOVrOE6th8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzoyMDozMFrOE_Qfng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5OTk4ODMzOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxODozNzoyOVrOH18skQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxNDoyMjo0NlrOH3RvMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ==", "bodyText": "We also need to verify that the metric works when there is a failed stream thread. Options are (1) to create a custom processor now and (IIRC) run the test suite twice, once with failing stream threads and once without to confirm that the metric works. I'm not sure if the custom processor will let us just fail one stream thread right before closing the app. Or (2) wait until add/remove stream threads is implemented and remove threads and test the metric after removing some threads before closing the app. WDYT?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526331025", "createdAt": "2020-11-18T18:37:29Z", "author": {"login": "lct45"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java", "diffHunk": "@@ -377,7 +378,7 @@ private void shouldAddMetricsOnAllLevels(final String builtInMetricsVersion) thr\n             builtInMetricsVersion\n         );\n         checkCacheMetrics(builtInMetricsVersion);\n-\n+        verifyFailedStreamThreadsSensor(0.0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1Mjc5Ng==", "bodyText": "I think you should try using the custom processor. You can find an example in StreamsUncaughtExceptionHandlerIntegrationTest.java", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526352796", "createdAt": "2020-11-18T19:12:47Z", "author": {"login": "wcarlson5"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java", "diffHunk": "@@ -377,7 +378,7 @@ private void shouldAddMetricsOnAllLevels(final String builtInMetricsVersion) thr\n             builtInMetricsVersion\n         );\n         checkCacheMetrics(builtInMetricsVersion);\n-\n+        verifyFailedStreamThreadsSensor(0.0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ=="}, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkzNTU4Ng==", "bodyText": "I would put the test whether the metric is recorded correctly in StreamThreadTest. An example for such a test is shouldLogAndRecordSkippedRecordsForInvalidTimestamps(). I do not think an integration test is needed. The test regarding the existence of the metric, i.e., checkMetricByName(listMetricThread, FAILED_STREAM_THREADS, 1); should stay here.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526935586", "createdAt": "2020-11-19T14:37:06Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java", "diffHunk": "@@ -377,7 +378,7 @@ private void shouldAddMetricsOnAllLevels(final String builtInMetricsVersion) thr\n             builtInMetricsVersion\n         );\n         checkCacheMetrics(builtInMetricsVersion);\n-\n+        verifyFailedStreamThreadsSensor(0.0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ=="}, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcyNDMzOA==", "bodyText": "After looking at both test classes, I think it actually might make the most sense to put the test for this metric in StreamsUncaughtExceptionHandlerIntegrationTest, since the metric is so closely aligned with the exception handler anyways and the setup works nicely with what we're trying to test with the metric. From the size + complexity of the other test classes, I think creating an overloaded processor for one test out of 20+ tests seems tricky.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r527724338", "createdAt": "2020-11-20T14:22:46Z", "author": {"login": "lct45"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java", "diffHunk": "@@ -377,7 +378,7 @@ private void shouldAddMetricsOnAllLevels(final String builtInMetricsVersion) thr\n             builtInMetricsVersion\n         );\n         checkCacheMetrics(builtInMetricsVersion);\n-\n+        verifyFailedStreamThreadsSensor(0.0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ=="}, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMDA5MjA5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOTowMzozOFrOH19sXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOToxNzo1MlrOH1-Nfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM0NzM1OQ==", "bodyText": "This seems wrong. There are a few duplicate calls here", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526347359", "createdAt": "2020-11-18T19:03:38Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -1070,6 +1070,10 @@ private Thread shutdownHelper(final boolean error) {\n             adminClient.close();\n \n             streamsMetrics.removeAllClientLevelMetrics();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1NTgzOA==", "bodyText": "Ahh, got mixed up when I rebased trunk", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526355838", "createdAt": "2020-11-18T19:17:52Z", "author": {"login": "lct45"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -1070,6 +1070,10 @@ private Thread shutdownHelper(final boolean error) {\n             adminClient.close();\n \n             streamsMetrics.removeAllClientLevelMetrics();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM0NzM1OQ=="}, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMDA5OTgyOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOTowNTo0NVrOH19xIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOTowNTo0NVrOH19xIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM0ODU3OA==", "bodyText": "We probably don't want to skip this log. Can you move the sensor in here?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526348578", "createdAt": "2020-11-18T19:05:45Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -219,6 +220,8 @@ State setState(final State newState) {\n             } else if (!state.isValidTransition(newState)) {\n                 log.error(\"Unexpected state transition from {} to {}\", oldState, newState);\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n+            } else if (newState == State.DEAD) {\n+                failedStreamThreadSensor.record();\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMzU1MDg5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzoyOTozMVrOH2eOnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzoyOTozMVrOH2eOnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg4MDQxMg==", "bodyText": "Could you please add a public method to StreamsMetricsImpl named removeAllClientLevelSensorsAndMetrics() that calls removeAllClientLevelMetrics() and removeAllClientLevelSensors() and make the latter two methods private?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526880412", "createdAt": "2020-11-19T13:29:31Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -1070,7 +1070,9 @@ private Thread shutdownHelper(final boolean error) {\n             adminClient.close();\n \n             streamsMetrics.removeAllClientLevelMetrics();\n+            streamsMetrics.removeAllClientLevelSensors();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMzU4NDYzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzozMzo0M1rOH2el4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzozMzo0M1rOH2el4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg4NjM2OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads so far for a given Kafka Streams client\";\n          \n          \n            \n                private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads since the start of the Kafka Streams client\";", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526886369", "createdAt": "2020-11-19T13:33:43Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java", "diffHunk": "@@ -60,6 +65,7 @@ private ClientMetrics() {}\n         \"The description of the topology executed in the Kafka Streams client\";\n     private static final String STATE_DESCRIPTION = \"The state of the Kafka Streams client\";\n     private static final String ALIVE_STREAM_THREADS_DESCRIPTION = \"The current number of alive stream threads that are running or participating in rebalance\";\n+    private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads so far for a given Kafka Streams client\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMzYzNzU4OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzo0MjoxMVrOH2fJVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzo0MjoxMVrOH2fJVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg5NTQ0Nw==", "bodyText": "nit: I like to insert a blank line after the call to test to visually separate setup, call, and verification.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526895447", "createdAt": "2020-11-19T13:42:11Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java", "diffHunk": "@@ -99,6 +121,27 @@ public void shouldAddAliveStreamThreadsMetric() {\n         );\n     }\n \n+    @Test\n+    public void shouldGetFailedStreamThreadsSensor() {\n+        final String name = \"failed-stream-threads\";\n+        final String description = \"The number of failed stream threads so far for a given Kafka Streams client\";\n+        expect(streamsMetrics.clientLevelSensor(name, RecordingLevel.INFO)).andReturn(expectedSensor);\n+        expect(streamsMetrics.clientLevelTagMap()).andReturn(tagMap);\n+        StreamsMetricsImpl.addSumMetricToSensor(\n+            expectedSensor,\n+            CLIENT_LEVEL_GROUP,\n+            tagMap,\n+            name,\n+            false,\n+            description\n+        );\n+        replay(StreamsMetricsImpl.class, streamsMetrics);\n+\n+        final Sensor sensor = ClientMetrics.failedStreamThreadSensor(streamsMetrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMzY0Nzk3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzo0NDozOFrOH2fP7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzo0NDozOFrOH2fP7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg5NzEzNQ==", "bodyText": "Unit tests for this method are missing.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526897135", "createdAt": "2020-11-19T13:44:38Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMzY0ODY5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzo0NDo0NlrOH2fQUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxMzo0NDo0NlrOH2fQUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg5NzIzNA==", "bodyText": "Unit tests for this method are missing. Please also consider my comment in class KafkaStreams for these unit tests.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526897234", "createdAt": "2020-11-19T13:44:46Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -253,6 +268,16 @@ public final void removeAllClientLevelMetrics() {\n         }\n     }\n \n+    public final void removeAllClientLevelSensors() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMzczMDM4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNDowMjo0MFrOH2gB5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNDowMjo0MFrOH2gB5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkwOTkyNw==", "bodyText": "Here you should just need a queue as for clientLevelMetrics. We need a map for the other levels because there can be multiple objects for each level, e.g., there might be multiple stream thread and each one manages its sensors under a key in the map. However, there is only one client on client level.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526909927", "createdAt": "2020-11-19T14:02:40Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -93,6 +93,7 @@ public int hashCode() {\n \n     private final Version version;\n     private final Deque<MetricName> clientLevelMetrics = new LinkedList<>();\n+    private final Map<String, Deque<String>> clientLevelSensors = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMzc2MDU4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNDowOTozNFrOH2gUbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxODo1NDo0MVrOH2tBVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkxNDY2OA==", "bodyText": "Not every dead stream thread is a failed stream thread. You should record this metric where the uncaught exception handler is called because there we now that a stream thread died unexpectedly.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526914668", "createdAt": "2020-11-19T14:09:34Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -221,6 +221,9 @@ State setState(final State newState) {\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);\n+                if (newState == State.DEAD) {\n+                    failedStreamThreadSensor.record();\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzExNzY4NQ==", "bodyText": "Would that just be in run() of the GlobalStreamThread then?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r527117685", "createdAt": "2020-11-19T18:46:27Z", "author": {"login": "lct45"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -221,6 +221,9 @@ State setState(final State newState) {\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);\n+                if (newState == State.DEAD) {\n+                    failedStreamThreadSensor.record();\n+                }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkxNDY2OA=="}, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzEyMjc3Mg==", "bodyText": "No, that would be in StreamThread#runLoop().", "url": "https://github.com/apache/kafka/pull/9614#discussion_r527122772", "createdAt": "2020-11-19T18:54:41Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -221,6 +221,9 @@ State setState(final State newState) {\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);\n+                if (newState == State.DEAD) {\n+                    failedStreamThreadSensor.record();\n+                }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkxNDY2OA=="}, "originalCommit": {"oid": "44db7af16b663dba85e2d126947e239f475f63fe"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxOTYyMTkyOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTowMDowM1rOH4ydEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTowMDowM1rOH4ydEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMwODk0Ng==", "bodyText": "You can inline the value of variable key here and remove key.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n          \n          \n            \n                        final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529308946", "createdAt": "2020-11-24T09:00:03Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        final String key = CLIENT_LEVEL_GROUP;\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxOTY0NjEzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTowMzoyMlrOH4ys_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTowMzoyMlrOH4ys_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMxMzAyMg==", "bodyText": "Although, we use this in other methods, I think the following is a bit simpler to read:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        return Optional.ofNullable(metrics.getSensor(fullSensorName))\n          \n          \n            \n                            .orElseGet(() -> {\n          \n          \n            \n                                clientLevelSensors.push(fullSensorName);\n          \n          \n            \n                                return metrics.sensor(fullSensorName, recordingLevel, parents);\n          \n          \n            \n                            });\n          \n          \n            \n                    final Sensor sensor = metrics.getSensor(fullSensorName);\n          \n          \n            \n                    if (sensor == null) {\n          \n          \n            \n                        clientLevelSensors.push(fullSensorName);\n          \n          \n            \n                        return metrics.sensor(fullSensorName, recordingLevel, parents);\n          \n          \n            \n                    }\n          \n          \n            \n                    return sensor;", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529313022", "createdAt": "2020-11-24T09:03:22Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        final String key = CLIENT_LEVEL_GROUP;\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n+            return Optional.ofNullable(metrics.getSensor(fullSensorName))\n+                .orElseGet(() -> {\n+                    clientLevelSensors.push(fullSensorName);\n+                    return metrics.sensor(fullSensorName, recordingLevel, parents);\n+                });", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxOTY3MTk3OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTowNzowOFrOH4y-Fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTowNzowOFrOH4y-Fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMxNzM5OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n          \n          \n            \n                        SENSOR_NAME_1,\n          \n          \n            \n                        recordingLevel\n          \n          \n            \n                    );\n          \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(SENSOR_NAME_1, recordingLevel);", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529317398", "createdAt": "2020-11-24T09:07:08Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -577,6 +579,38 @@ public void shouldGetExistingCacheLevelSensor() {\n         assertThat(actualSensor, is(equalToObject(sensor)));\n     }\n \n+    @Test\n+    public void shouldGetNewClientLevelSensor() {\n+        final Metrics metrics = mock(Metrics.class);\n+        final RecordingLevel recordingLevel = RecordingLevel.INFO;\n+        setupGetNewSensorTest(metrics, recordingLevel);\n+        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n+\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n+            SENSOR_NAME_1,\n+            recordingLevel\n+        );\n+\n+        verify(metrics);\n+        assertThat(actualSensor, is(equalToObject(sensor)));\n+    }\n+\n+    @Test\n+    public void shouldGetExistingClientLevelSensor() {\n+        final Metrics metrics = mock(Metrics.class);\n+        final RecordingLevel recordingLevel = RecordingLevel.INFO;\n+        setupGetExistingSensorTest(metrics);\n+        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n+\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n+            SENSOR_NAME_1,\n+            recordingLevel\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxOTcwNTc0OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOToxMTozN1rOH4zT1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOToxMTozN1rOH4zT1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMyMjk2Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n          \n          \n            \n                        SENSOR_NAME_1,\n          \n          \n            \n                        recordingLevel\n          \n          \n            \n                    );\n          \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(SENSOR_NAME_1, recordingLevel);", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529322966", "createdAt": "2020-11-24T09:11:37Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -577,6 +579,38 @@ public void shouldGetExistingCacheLevelSensor() {\n         assertThat(actualSensor, is(equalToObject(sensor)));\n     }\n \n+    @Test\n+    public void shouldGetNewClientLevelSensor() {\n+        final Metrics metrics = mock(Metrics.class);\n+        final RecordingLevel recordingLevel = RecordingLevel.INFO;\n+        setupGetNewSensorTest(metrics, recordingLevel);\n+        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n+\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n+            SENSOR_NAME_1,\n+            recordingLevel\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxOTgwMzEzOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOToyNDozNFrOH40TiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOToyNDozNFrOH40TiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMzOTI3Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(0));\n          \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(1));\n          \n          \n            \n            \n          \n          \n            \n                    expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    replay(metrics);\n          \n          \n            \n            \n          \n          \n            \n                    streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n          \n          \n            \n                    verify(metrics);\n          \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(0));\n          \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(1));\n          \n          \n            \n                    expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    replay(metrics);\n          \n          \n            \n            \n          \n          \n            \n                    streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n          \n          \n            \n            \n          \n          \n            \n                    verify(metrics);", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529339272", "createdAt": "2020-11-24T09:24:34Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,17 +663,20 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n \n-        streamsMetrics.removeAllClientLevelMetrics();\n+        metrics.removeSensor(sensorKeys.getValues().get(0));\n+        metrics.removeSensor(sensorKeys.getValues().get(1));\n+\n+        expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n+        expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n+        replay(metrics);\n \n+        streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n         verify(metrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxOTgwNDkwOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOToyNDo0OFrOH40Uvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOToyNDo0OFrOH40Uvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMzOTU4Mg==", "bodyText": "Please remove this empty line.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529339582", "createdAt": "2020-11-24T09:24:48Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,17 +663,20 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxOTgxMzIxOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOToyNTo1MlrOH40aMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOToyNTo1MlrOH40aMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM0MDk3Ng==", "bodyText": "Please remove empty line.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529340976", "createdAt": "2020-11-24T09:25:52Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java", "diffHunk": "@@ -99,6 +121,29 @@ public void shouldAddAliveStreamThreadsMetric() {\n         );\n     }\n \n+    @Test\n+    public void shouldGetFailedStreamThreadsSensor() {\n+        final String name = \"failed-stream-threads\";\n+        final String description = \"The number of failed stream threads since the start of the Kafka Streams client\";\n+        expect(streamsMetrics.clientLevelSensor(name, RecordingLevel.INFO)).andReturn(expectedSensor);\n+        expect(streamsMetrics.clientLevelTagMap()).andReturn(tagMap);\n+        StreamsMetricsImpl.addSumMetricToSensor(\n+            expectedSensor,\n+            CLIENT_LEVEL_GROUP,\n+            tagMap,\n+            name,\n+            false,\n+            description\n+        );\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxOTk0ODkyOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTo0NDowM1rOH41zVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTo0NDowM1rOH41zVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM2Mzc5Ng==", "bodyText": "You can remove these lines. They are dead code.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529363796", "createdAt": "2020-11-24T09:44:03Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }\n+\n+    public void verifyFailedStreamThread(final boolean shouldFail) {\n+        final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n+        final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n+        final StreamsMetricsImpl streamsMetrics =\n+            new StreamsMetricsImpl(metrics, CLIENT_ID, StreamsConfig.METRICS_LATEST, mockTime);\n+        final StreamThread thread = new StreamThread(\n+            mockTime,\n+            config,\n+            null,\n+            consumer,\n+            consumer,\n+            null,\n+            null,\n+            taskManager,\n+            streamsMetrics,\n+            internalTopologyBuilder,\n+            CLIENT_ID,\n+            new LogContext(\"\"),\n+            new AtomicInteger(),\n+            new AtomicLong(Long.MAX_VALUE),\n+            null,\n+            e -> { }\n+        ) {\n+            @Override\n+            void runOnce() {\n+                setState(StreamThread.State.PENDING_SHUTDOWN);\n+                if (shouldFail) {\n+                    throw new StreamsException(Thread.currentThread().getName());\n+                }\n+            }\n+        };\n+        expect(taskManager.activeTaskMap()).andReturn(Collections.emptyMap());\n+        expect(taskManager.standbyTaskMap()).andReturn(Collections.emptyMap());\n+\n+        taskManager.process(anyInt(), anyObject());\n+        EasyMock.expectLastCall().andThrow(new StreamsException(Thread.currentThread().getName()));\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxOTk4MDgyOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTo0ODozMFrOH42I4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTo0ODozMFrOH42I4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM2OTMxMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                    EasyMock.replay(taskManager);\n          \n          \n            \n            \n          \n          \n            \n                    thread.updateThreadMetadata(\"metadata\");\n          \n          \n            \n                    thread.setState(StreamThread.State.STARTING);\n          \n          \n            \n                    thread.runLoop();\n          \n          \n            \n            \n          \n          \n            \n                    final Metric failedThreads = StreamsTestUtils.getMetricByName(metrics.metrics(), \"failed-stream-threads\", \"stream-metrics\");\n          \n          \n            \n            \n          \n          \n            \n                    assertEquals(shouldFail ? 1.0 : 0.0, failedThreads.metricValue());\n          \n          \n            \n                    EasyMock.replay(taskManager);\n          \n          \n            \n                    thread.updateThreadMetadata(\"metadata\");\n          \n          \n            \n                    thread.setState(StreamThread.State.STARTING);\n          \n          \n            \n                    \n          \n          \n            \n                    thread.runLoop();\n          \n          \n            \n            \n          \n          \n            \n                    final Metric failedThreads = StreamsTestUtils.getMetricByName(metrics.metrics(), \"failed-stream-threads\", \"stream-metrics\");\n          \n          \n            \n                    assertThat(failedThreads.metricValue(), is(shouldFail ? 1.0 : 0.0));", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529369313", "createdAt": "2020-11-24T09:48:30Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }\n+\n+    public void verifyFailedStreamThread(final boolean shouldFail) {\n+        final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n+        final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n+        final StreamsMetricsImpl streamsMetrics =\n+            new StreamsMetricsImpl(metrics, CLIENT_ID, StreamsConfig.METRICS_LATEST, mockTime);\n+        final StreamThread thread = new StreamThread(\n+            mockTime,\n+            config,\n+            null,\n+            consumer,\n+            consumer,\n+            null,\n+            null,\n+            taskManager,\n+            streamsMetrics,\n+            internalTopologyBuilder,\n+            CLIENT_ID,\n+            new LogContext(\"\"),\n+            new AtomicInteger(),\n+            new AtomicLong(Long.MAX_VALUE),\n+            null,\n+            e -> { }\n+        ) {\n+            @Override\n+            void runOnce() {\n+                setState(StreamThread.State.PENDING_SHUTDOWN);\n+                if (shouldFail) {\n+                    throw new StreamsException(Thread.currentThread().getName());\n+                }\n+            }\n+        };\n+        expect(taskManager.activeTaskMap()).andReturn(Collections.emptyMap());\n+        expect(taskManager.standbyTaskMap()).andReturn(Collections.emptyMap());\n+\n+        taskManager.process(anyInt(), anyObject());\n+        EasyMock.expectLastCall().andThrow(new StreamsException(Thread.currentThread().getName()));\n+\n+        EasyMock.replay(taskManager);\n+\n+        thread.updateThreadMetadata(\"metadata\");\n+        thread.setState(StreamThread.State.STARTING);\n+        thread.runLoop();\n+\n+        final Metric failedThreads = StreamsTestUtils.getMetricByName(metrics.metrics(), \"failed-stream-threads\", \"stream-metrics\");\n+\n+        assertEquals(shouldFail ? 1.0 : 0.0, failedThreads.metricValue());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDA3MDY0OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTo1OTo1NVrOH43Dqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwOTo1OTo1NVrOH43Dqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NDM2Mg==", "bodyText": "I would rename this method to runAndVerifyFailedStreamThreadRecording().", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529384362", "createdAt": "2020-11-24T09:59:55Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }\n+\n+    public void verifyFailedStreamThread(final boolean shouldFail) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDA3MjYyOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMDowMDoxNVrOH43E-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMDowMDoxNVrOH43E-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NDY5Nw==", "bodyText": "Could you please specify two separate unit tests? One could be named shouldRecordFailedStreamThread() and the other shouldNotRecordFailedStreamThread().", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529384697", "createdAt": "2020-11-24T10:00:15Z", "author": {"login": "cadonna"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDA2NDM3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo0NDo0NFrOH8U17Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo0NDo0NFrOH8U17Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxODA5Mw==", "bodyText": "nit: missing empty line", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533018093", "createdAt": "2020-12-01T01:44:44Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java", "diffHunk": "@@ -125,4 +131,16 @@ public static void addNumAliveStreamThreadMetric(final StreamsMetricsImpl stream\n             stateProvider\n         );\n     }\n+    public static Sensor failedStreamThreadSensor(final StreamsMetricsImpl streamsMetrics) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDA4MDI1OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo1MTo0OFrOH8U_IQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNToyODoxNFrOH9gb3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ==", "bodyText": "Should we rewrite this the same way threadLevelSensor is written (ie, using orElseGet) for consistency?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533020449", "createdAt": "2020-12-01T01:51:48Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE0ODMzNQ==", "bodyText": "I requested this. See my comment #9614 (comment)", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533148335", "createdAt": "2020-12-01T08:22:27Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU3MDUzNQ==", "bodyText": "I'm good either way (:", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533570535", "createdAt": "2020-12-01T16:57:40Z", "author": {"login": "lct45"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzOTkyMg==", "bodyText": "I am fine either way, too, but I prefer consistency... So should we rewrite the other method as a side cleanup?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533639922", "createdAt": "2020-12-01T18:43:47Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY0MTU0MA==", "bodyText": "I am fine with consistency and clean-up, but I would like to have the clean-up in a separate PR.", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533641540", "createdAt": "2020-12-01T18:46:19Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI1NjYwNQ==", "bodyText": "I changed it back for consistency and will open up a fix PR to update both of them to the new syntax", "url": "https://github.com/apache/kafka/pull/9614#discussion_r534256605", "createdAt": "2020-12-02T15:28:14Z", "author": {"login": "lct45"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDA5OTkzOnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjowMDo0MFrOH8VKfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzoxOToxMVrOH83e5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMzM1Nw==", "bodyText": "Why did we change this from andStubReturn(null) to andReturn(mock(KafkaMetric.class))?", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533023357", "createdAt": "2020-12-01T02:00:40Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,16 +657,18 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n \n-        streamsMetrics.removeAllClientLevelMetrics();\n+        metrics.removeSensor(sensorKeys.getValues().get(0));\n+        metrics.removeSensor(sensorKeys.getValues().get(1));\n+        expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n+        expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU4NTYzOQ==", "bodyText": "Must've been an accidental change when trying to get the test to work. shouldRemoveStateStoreLevelSensors uses andReturn(mock(KafkaMetric.class)) so that's where it came from, but this test works with andStubReturn(null) so I changed it back to that", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533585639", "createdAt": "2020-12-01T17:19:11Z", "author": {"login": "lct45"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,16 +657,18 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n \n-        streamsMetrics.removeAllClientLevelMetrics();\n+        metrics.removeSensor(sensorKeys.getValues().get(0));\n+        metrics.removeSensor(sensorKeys.getValues().get(1));\n+        expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n+        expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMzM1Nw=="}, "originalCommit": {"oid": "e395ba706e59f13af996c83177e5846878adb3e8"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NzY1OTgyOnYy", "diffSide": "LEFT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzoyMDozMFrOH83ilg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzoyMDozMFrOH83ilg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU4NjU4Mg==", "bodyText": "This wasn't being used so I went ahead and took it out", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533586582", "createdAt": "2020-12-01T17:20:30Z", "author": {"login": "lct45"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -619,8 +647,7 @@ public void shouldProvideCorrectStrings() {\n     }\n \n     private void setupRemoveSensorsTest(final Metrics metrics,\n-                                        final String level,\n-                                        final RecordingLevel recordingLevel) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc6cf529d9e4becb5871913a34711a37dd6916dc"}, "originalPosition": 58}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3888, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}