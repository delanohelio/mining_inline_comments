{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc0MDQ2ODU0", "number": 9224, "title": "KAFKA-10304: refactor MM2 integration tests", "bodyText": "The main proposals of this PR:\n(1) extract the common functions into a base class MirrorConnectorsIntegrationBaseTest\n(2) test in SSL-enabled cluster", "createdAt": "2020-08-26T17:20:07Z", "url": "https://github.com/apache/kafka/pull/9224", "merged": true, "mergeCommit": {"oid": "2cde6f61b8a3b4a13a771099c2a35f3013c46e70"}, "closed": true, "closedAt": "2021-01-14T14:48:17Z", "author": {"login": "ning2008wisc"}, "timelineItems": {"totalCount": 43, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdGFDUiABqjM3MzM0NjkwMzA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdwFbs7gFqTU2ODMwMDk2MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0NjU5ODY2", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-484659866", "createdAt": "2020-09-09T04:54:37Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNDo1NDozN1rOHO2o5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNDo1NDozN1rOHO2o5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTMzNzMxNg==", "bodyText": "propose TestUtils to be the central place to host common functions that will be used by integration tests", "url": "https://github.com/apache/kafka/pull/9224#discussion_r485337316", "createdAt": "2020-09-09T04:54:37Z", "author": {"login": "ning2008wisc"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/TestUtils.java", "diffHunk": "@@ -16,12 +16,51 @@\n  */\n package org.apache.kafka.connect.mirror;\n \n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.NUM_WORKERS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.junit.Assert.assertTrue;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n public class TestUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0NjYwMjcz", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-484660273", "createdAt": "2020-09-09T04:55:55Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNDo1NTo1NVrOHO2qaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNDo1NTo1NVrOHO2qaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTMzNzcwNQ==", "bodyText": "This is the simple move from MirrorConnectorsIntegrationTest with generalization of connector class", "url": "https://github.com/apache/kafka/pull/9224#discussion_r485337705", "createdAt": "2020-09-09T04:55:55Z", "author": {"login": "ning2008wisc"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/TestUtils.java", "diffHunk": "@@ -32,4 +71,141 @@\n         }\n         return props;\n     }\n+    \n+    public static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, List<Class> mirrorClasses,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 58}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0Njg3ODcy", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-484687872", "createdAt": "2020-09-09T06:11:51Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNjoxMTo1MVrOHO4Faw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNjoxMTo1MVrOHO4Faw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTM2MTAwMw==", "bodyText": "this is mostly copy-paste from MirrorConnectorsIntegrationTest", "url": "https://github.com/apache/kafka/pull/9224#discussion_r485361003", "createdAt": "2020-09-09T06:11:51Z", "author": {"login": "ning2008wisc"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/TestUtils.java", "diffHunk": "@@ -32,4 +73,166 @@\n         }\n         return props;\n     }\n+    \n+    /*\n+     * launch the connectors on kafka connect cluster, then check if they are running\n+     */\n+    public static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, List<Class> connectorClasses,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0Njg5Njg3", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-484689687", "createdAt": "2020-09-09T06:15:54Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNjoxNTo1NFrOHO4LGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNjoxNTo1NFrOHO4LGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTM2MjQ1OA==", "bodyText": "Add a check for topic config sync, since the topic created on primary cluster has a \"cleanup.policy\" config", "url": "https://github.com/apache/kafka/pull/9224#discussion_r485362458", "createdAt": "2020-09-09T06:15:54Z", "author": {"login": "ning2008wisc"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -207,13 +173,16 @@ public void testReplication() throws InterruptedException {\n \n         mm2Config = new MirrorMakerConfig(mm2Props);\n \n-        waitUntilMirrorMakerIsRunning(backup, mm2Config, \"primary\", \"backup\");\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, \"primary\", \"backup\");\n \n-        waitUntilMirrorMakerIsRunning(primary, mm2Config, \"backup\", \"primary\");\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, \"backup\", \"primary\");   \n \n         MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(\"primary\"));\n         MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(\"backup\"));\n-\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 207}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0NjkwNjg3", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-484690687", "createdAt": "2020-09-09T06:18:01Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNjoxODowMVrOHO4OBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwNjoxODowMVrOHO4OBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTM2MzIwNA==", "bodyText": "when creating test-topic-1 topic on primary cluster, add a topic config. Later on, we will check if the config is synced from primary to backup cluster.", "url": "https://github.com/apache/kafka/pull/9224#discussion_r485363204", "createdAt": "2020-09-09T06:18:01Z", "author": {"login": "ning2008wisc"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -396,27 +330,67 @@ public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedExceptio\n         try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n             \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n             // we need to wait for consuming all the records for MM2 replicating the expected offsets\n-            waitForConsumingAllRecords(consumer1);\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n         }\n \n         // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n         consumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n             \"group.id\", \"consumer-group-1\"), \"primary.test-topic-1\", \"primary.test-topic-2\");\n \n-        waitForConsumerGroupOffsetSync(consumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \"consumer-group-1\");\n+        waitForConsumerGroupOffsetSync(backup, consumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            \"consumer-group-1\", NUM_RECORDS_PRODUCED);\n \n         records = consumer.poll(Duration.ofMillis(500));\n         // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n         assertEquals(\"consumer record size is not zero\", 0, records.count());\n         consumer.close();\n-\n     }\n+    \n+    @Test\n+    public void testWithBrokerRestart() throws InterruptedException {\n+        // test with a higher number of records\n+        int numRecords = NUM_RECORDS_PRODUCED * 100;\n+        \n+        produceRecords(Arrays.asList(primary), Arrays.asList(\"test-topic-1\"), numRecords);\n \n-    private void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n-        Admin client = cluster.createAdminClient();\n-        try {\n-            client.deleteTopics(client.listTopics().names().get());\n-        } catch (Throwable e) {\n-        }\n+        // one way replication from primary to backup\n+        mm2Props.put(\"backup->primary.enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+       \n+        waitUntilMirrorMakerIsRunning(backup, SOURCE_CONNECTOR, mm2Config, \"primary\", \"backup\");\n+        \n+        // have to sleep a little for MM to be ready for the following the kafka broker restart\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(1));\n+\n+        // restart kafka broker at backup cluster\n+        restartKafkaBroker(backup);\n+        \n+        Consumer<byte[], byte[]> consumer = backup.kafka().createConsumerAndSubscribeTo(\n+                Collections.singletonMap(\"group.id\", \"consumer-group-1\"), \"primary.test-topic-1\");\n+        // verify the consumption equals to produce\n+        waitForConsumingAllRecords(consumer, numRecords);\n+        consumer.commitAsync();\n+        \n+        // produce another set of records\n+        produceRecords(Arrays.asList(primary), Arrays.asList(\"test-topic-1\"), numRecords);\n+        // restart kafka broker at primary cluster\n+        restartKafkaBroker(primary);\n+        // verify the consumption equals to produce\n+        waitForConsumingAllRecords(consumer, numRecords);\n+        \n+        consumer.close();\n+    }\n+    \n+    void createTopics() {\n+        // to verify topic config will be sync-ed across clusters\n+        Map<String, String> topicConfig = new HashMap<>();\n+        topicConfig.put(TopicConfig.CLEANUP_POLICY_CONFIG, TopicConfig.CLEANUP_POLICY_COMPACT);\n+        // create these topics before starting the connectors so we don't need to wait for discovery\n+        primary.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS, 1, topicConfig);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 364}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "08bd90651971370051ca9923bf8cb101d1acedcd", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/08bd90651971370051ca9923bf8cb101d1acedcd", "committedDate": "2020-09-12T18:03:01Z", "message": "refactor MM2 integration tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "08bd90651971370051ca9923bf8cb101d1acedcd", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/08bd90651971370051ca9923bf8cb101d1acedcd", "committedDate": "2020-09-12T18:03:01Z", "message": "refactor MM2 integration tests"}, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0NTI3MjU4", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-514527258", "createdAt": "2020-10-22T09:22:37Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwOToyMjozN1rOHmYpFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNDoxNjo0OVrOHmkDkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAxMTY3MA==", "bodyText": "We can remove this", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510011670", "createdAt": "2020-10-22T09:22:37Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAxMjEwMQ==", "bodyText": "This can go with the other org.junit imports below", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510012101", "createdAt": "2020-10-22T09:23:16Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAyNzIzOA==", "bodyText": "Iterator-> Iterator<ConfigEntry>", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510027238", "createdAt": "2020-10-22T09:45:45Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\")));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(\"primary-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(\"backup-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of primary-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of backup-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n+        // run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator configIterator = allConfigs.entries().iterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAyODE3NA==", "bodyText": "It looks like this is not used, can we remove it?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510028174", "createdAt": "2020-10-22T09:47:15Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.utils.ThreadedConsumer;\n+import org.apache.kafka.connect.mirror.utils.ThreadedProducer;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationTest.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAyODM5Mw==", "bodyText": "We can use List<Class<? extends Connector> to avoid the warning", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510028393", "createdAt": "2020-10-22T09:47:38Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.utils.ThreadedConsumer;\n+import org.apache.kafka.connect.mirror.utils.ThreadedProducer;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = ", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAyODgxNg==", "bodyText": "This is not used, can we remove it?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510028816", "createdAt": "2020-10-22T09:48:20Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.utils.ThreadedConsumer;\n+import org.apache.kafka.connect.mirror.utils.ThreadedProducer;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        startClusters();\n+    }\n+\n+    @After\n+    public void close() {\n+        shutdownClusters();\n+    }\n+\n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, \"primary\", \"backup\");\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, \"backup\", \"primary\");   \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(\"primary\"));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(\"backup\"));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(\"primary\"));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(\"primary\"));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(\"backup\"));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(\"backup\"));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, \"primary\",\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(500));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        backupConsumer.assign(primaryOffsets.keySet());\n+        primaryOffsets.forEach(backupConsumer::seek);\n+        backupConsumer.poll(Duration.ofMillis(500));\n+        backupConsumer.commitAsync();\n+        \n+        assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        \n+        backupConsumer.close();\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(\"backup->primary.enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, \"primary\", \"backup\");\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"primary.\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(\"primary.\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(\"backup->primary.enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, \"primary\", \"backup\");\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords records = backupConsumer.poll(Duration.ofMillis(500));\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(Duration.ofMillis(500));\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * This test is to validate MirrorSourceConnector follows \"at most once\" delivery guarantee\n+     * under broker restart / failure\n+     */\n+    @Test\n+    public void testWithBrokerRestart() throws InterruptedException {\n+        String consumerGroupName = \"consumer-group-testWithBrokerRestart\";\n+        // test with a higher number of records\n+        int numRecords = NUM_RECORDS_PRODUCED * 8;\n+        // the sleep time between two produces used by background producer \n+        int sleepMs = 50;\n+        int joinTimeoutMs = 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 335}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAzMDE0OA==", "bodyText": "ConsumerRecords -> ConsumerRecords<byte[], byte[]>", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510030148", "createdAt": "2020-10-22T09:50:27Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.utils.ThreadedConsumer;\n+import org.apache.kafka.connect.mirror.utils.ThreadedProducer;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        startClusters();\n+    }\n+\n+    @After\n+    public void close() {\n+        shutdownClusters();\n+    }\n+\n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, \"primary\", \"backup\");\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, \"backup\", \"primary\");   \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(\"primary\"));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(\"backup\"));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(\"primary\"));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(\"primary\"));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(\"backup\"));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(\"backup\"));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, \"primary\",\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(500));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        backupConsumer.assign(primaryOffsets.keySet());\n+        primaryOffsets.forEach(backupConsumer::seek);\n+        backupConsumer.poll(Duration.ofMillis(500));\n+        backupConsumer.commitAsync();\n+        \n+        assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        \n+        backupConsumer.close();\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(\"backup->primary.enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, \"primary\", \"backup\");\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"primary.\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(\"primary.\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(\"backup->primary.enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, \"primary\", \"backup\");\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords records = backupConsumer.poll(Duration.ofMillis(500));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 291}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAzMDc4MA==", "bodyText": "What do we do if there's an exception? If it's expected, let's make it clear", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510030780", "createdAt": "2020-10-22T09:51:34Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\")));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(\"primary-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(\"backup-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of primary-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of backup-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n+        // run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAzMTU2Mw==", "bodyText": "It looks like this is not used anywhere", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510031563", "createdAt": "2020-10-22T09:52:52Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationSSLTest.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAzNDg3Mg==", "bodyText": "Is this needed at compile time? As far as I can tell, it's only needed when running the SSL test, so it could be testRuntime libs.bcpkix", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510034872", "createdAt": "2020-10-22T09:57:57Z", "author": {"login": "mimaison"}, "path": "build.gradle", "diffHunk": "@@ -2058,6 +2058,7 @@ project(':connect:mirror') {\n     testCompile libs.junitJupiterApi\n     testCompile libs.junitVintageEngine\n     testCompile libs.mockitoCore\n+    testCompile libs.bcpkix", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExMjgyNw==", "bodyText": "I find having a method specific for SSL strange. Callers should not have to know, this should be retrieved automatically based on the cluster being targeted", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510112827", "createdAt": "2020-10-22T12:17:18Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\")));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(\"primary-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(\"backup-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of primary-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of backup-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n+        // run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = (ConfigEntry) configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and  topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    protected static Map<String, String> basicMM2Config() {\n+        Map<String, String> mm2Props = new HashMap<>();\n+        mm2Props.put(\"clusters\", \"primary, backup\");\n+        mm2Props.put(\"max.tasks\", \"10\");\n+        mm2Props.put(\"topics\", \"test-topic-.*, primary.test-topic-.*, backup.test-topic-.*\");\n+        mm2Props.put(\"groups\", \"consumer-group-.*\");\n+        mm2Props.put(\"primary->backup.enabled\", \"true\");\n+        mm2Props.put(\"backup->primary.enabled\", \"true\");\n+        mm2Props.put(\"sync.topic.acls.enabled\", \"false\");\n+        mm2Props.put(\"emit.checkpoints.interval.seconds\", \"1\");\n+        mm2Props.put(\"emit.heartbeats.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.topics.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.groups.interval.seconds\", \"1\");\n+        mm2Props.put(\"checkpoints.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"heartbeats.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"offset-syncs.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"config.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"offset.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"status.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"replication.factor\", \"1\");\n+        \n+        return mm2Props;\n+    }\n+    \n+    /*\n+     * restart kafka broker and make sure it is successful\n+     */\n+    protected static void restartKafkaBroker(EmbeddedConnectCluster connect) throws InterruptedException {\n+\n+        connect.kafka().stopOnlyKafka();\n+        log.trace(\"issue kafka stop\");\n+        connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n+                \"Group of workers did not remain the same after broker shutdown\");\n+\n+        // Allow for the workers to discover that the coordinator is unavailable, if the connector\n+        // is set up on this current EmbeddedConnectCluster\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        // Wait for the broker to be stopped\n+        assertTrue(\"Failed to stop kafka broker within \" + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n+                connect.kafka().runningBrokers().size() == 0);\n+\n+        connect.kafka().startOnlyKafkaOnSamePorts();\n+        log.trace(\"issue kafka start\");\n+        // Allow for the kafka brokers to come back online\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n+                \"Group of workers did not remain the same within the designated time.\");\n+\n+        // Allow for the workers to rebalance and reach a steady state\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        // Expect that the broker has started again\n+        assertTrue(\"Failed to start kafka broker within \" + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n+                connect.kafka().runningBrokers().size() > 0);\n+    }\n+    \n+    protected void createTopics() {\n+        // to verify topic config will be sync-ed across clusters\n+        Map<String, String> topicConfig = new HashMap<>();\n+        topicConfig.put(TopicConfig.CLEANUP_POLICY_CONFIG, TopicConfig.CLEANUP_POLICY_COMPACT);\n+        // create these topics before starting the connectors so we don't need to wait for discovery\n+        primary.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS, 1, topicConfig);\n+        primary.kafka().createTopic(\"backup.test-topic-1\", 1);\n+        primary.kafka().createTopic(\"heartbeats\", 1);\n+        backup.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-1\", 1);\n+        backup.kafka().createTopic(\"heartbeats\", 1);\n+    }\n+    \n+    protected KafkaConsumer<String, String> createSslConsumer(Map<String, Object> consumerProps, String... topics) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 385}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExNDk5NQ==", "bodyText": "Why are we rethrowing as RuntimeException?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510114995", "createdAt": "2020-10-22T12:20:51Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationSSLTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        try {\n+            Map<String, Object> sslConfig = TestSslUtils.createSslConfig(false, true, Mode.SERVER, TestUtils.tempFile(), \"testCert\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.ListenersProp(), \"SSL://localhost:0\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.InterBrokerListenerNameProp(), \"SSL\");\n+            backupBrokerProps.putAll(sslConfig);\n+        } catch (final Exception e) {\n+            throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExNTY2NA==", "bodyText": "That looks pretty brittle? Is there a condition we can wait on?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510115664", "createdAt": "2020-10-22T12:21:56Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationSSLTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        try {\n+            Map<String, Object> sslConfig = TestSslUtils.createSslConfig(false, true, Mode.SERVER, TestUtils.tempFile(), \"testCert\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.ListenersProp(), \"SSL://localhost:0\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.InterBrokerListenerNameProp(), \"SSL\");\n+            backupBrokerProps.putAll(sslConfig);\n+        } catch (final Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+        startClusters();\n+    }\n+    \n+    @After\n+    public void close() {\n+        shutdownClusters();\n+    }\n+    \n+    @Test\n+    public void testReplicationSSL() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(\n+            Collections.singletonMap(\"group.id\", \"consumer-group-1\"), \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // one-way replication from primary -> backup\n+        mm2Props.put(\"backup->primary.enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, \"primary\", \"backup\");\n+\n+        // sleep few seconds to let MM2 replicate some records for \"end\" consumer to consume them\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExNzAwMA==", "bodyText": "Could the cluster aliases be constant as these are used all over the place", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510117000", "createdAt": "2020-10-22T12:23:54Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\")));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(\"primary-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(\"backup-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of primary-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of backup-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n+        // run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = (ConfigEntry) configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and  topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    protected static Map<String, String> basicMM2Config() {\n+        Map<String, String> mm2Props = new HashMap<>();\n+        mm2Props.put(\"clusters\", \"primary, backup\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 316}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExODEyNA==", "bodyText": "We can use putIfAbstent()", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510118124", "createdAt": "2020-10-22T12:25:39Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\")));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(\"primary-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(\"backup-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of primary-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of backup-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n+        // run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = (ConfigEntry) configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and  topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    protected static Map<String, String> basicMM2Config() {\n+        Map<String, String> mm2Props = new HashMap<>();\n+        mm2Props.put(\"clusters\", \"primary, backup\");\n+        mm2Props.put(\"max.tasks\", \"10\");\n+        mm2Props.put(\"topics\", \"test-topic-.*, primary.test-topic-.*, backup.test-topic-.*\");\n+        mm2Props.put(\"groups\", \"consumer-group-.*\");\n+        mm2Props.put(\"primary->backup.enabled\", \"true\");\n+        mm2Props.put(\"backup->primary.enabled\", \"true\");\n+        mm2Props.put(\"sync.topic.acls.enabled\", \"false\");\n+        mm2Props.put(\"emit.checkpoints.interval.seconds\", \"1\");\n+        mm2Props.put(\"emit.heartbeats.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.topics.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.groups.interval.seconds\", \"1\");\n+        mm2Props.put(\"checkpoints.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"heartbeats.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"offset-syncs.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"config.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"offset.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"status.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"replication.factor\", \"1\");\n+        \n+        return mm2Props;\n+    }\n+    \n+    /*\n+     * restart kafka broker and make sure it is successful\n+     */\n+    protected static void restartKafkaBroker(EmbeddedConnectCluster connect) throws InterruptedException {\n+\n+        connect.kafka().stopOnlyKafka();\n+        log.trace(\"issue kafka stop\");\n+        connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n+                \"Group of workers did not remain the same after broker shutdown\");\n+\n+        // Allow for the workers to discover that the coordinator is unavailable, if the connector\n+        // is set up on this current EmbeddedConnectCluster\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        // Wait for the broker to be stopped\n+        assertTrue(\"Failed to stop kafka broker within \" + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n+                connect.kafka().runningBrokers().size() == 0);\n+\n+        connect.kafka().startOnlyKafkaOnSamePorts();\n+        log.trace(\"issue kafka start\");\n+        // Allow for the kafka brokers to come back online\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n+                \"Group of workers did not remain the same within the designated time.\");\n+\n+        // Allow for the workers to rebalance and reach a steady state\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        // Expect that the broker has started again\n+        assertTrue(\"Failed to start kafka broker within \" + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n+                connect.kafka().runningBrokers().size() > 0);\n+    }\n+    \n+    protected void createTopics() {\n+        // to verify topic config will be sync-ed across clusters\n+        Map<String, String> topicConfig = new HashMap<>();\n+        topicConfig.put(TopicConfig.CLEANUP_POLICY_CONFIG, TopicConfig.CLEANUP_POLICY_COMPACT);\n+        // create these topics before starting the connectors so we don't need to wait for discovery\n+        primary.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS, 1, topicConfig);\n+        primary.kafka().createTopic(\"backup.test-topic-1\", 1);\n+        primary.kafka().createTopic(\"heartbeats\", 1);\n+        backup.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-1\", 1);\n+        backup.kafka().createTopic(\"heartbeats\", 1);\n+    }\n+    \n+    protected KafkaConsumer<String, String> createSslConsumer(Map<String, Object> consumerProps, String... topics) {\n+        Map<String, Object> props = new HashMap<>(consumerProps);\n+\n+        if (props.get(ConsumerConfig.GROUP_ID_CONFIG) == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 388}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExODkwNQ==", "bodyText": "Why are we rethrowing as ConnectException?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510118905", "createdAt": "2020-10-22T12:26:53Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\")));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(\"primary-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(\"backup-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of primary-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of backup-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n+        // run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = (ConfigEntry) configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and  topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    protected static Map<String, String> basicMM2Config() {\n+        Map<String, String> mm2Props = new HashMap<>();\n+        mm2Props.put(\"clusters\", \"primary, backup\");\n+        mm2Props.put(\"max.tasks\", \"10\");\n+        mm2Props.put(\"topics\", \"test-topic-.*, primary.test-topic-.*, backup.test-topic-.*\");\n+        mm2Props.put(\"groups\", \"consumer-group-.*\");\n+        mm2Props.put(\"primary->backup.enabled\", \"true\");\n+        mm2Props.put(\"backup->primary.enabled\", \"true\");\n+        mm2Props.put(\"sync.topic.acls.enabled\", \"false\");\n+        mm2Props.put(\"emit.checkpoints.interval.seconds\", \"1\");\n+        mm2Props.put(\"emit.heartbeats.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.topics.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.groups.interval.seconds\", \"1\");\n+        mm2Props.put(\"checkpoints.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"heartbeats.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"offset-syncs.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"config.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"offset.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"status.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"replication.factor\", \"1\");\n+        \n+        return mm2Props;\n+    }\n+    \n+    /*\n+     * restart kafka broker and make sure it is successful\n+     */\n+    protected static void restartKafkaBroker(EmbeddedConnectCluster connect) throws InterruptedException {\n+\n+        connect.kafka().stopOnlyKafka();\n+        log.trace(\"issue kafka stop\");\n+        connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n+                \"Group of workers did not remain the same after broker shutdown\");\n+\n+        // Allow for the workers to discover that the coordinator is unavailable, if the connector\n+        // is set up on this current EmbeddedConnectCluster\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        // Wait for the broker to be stopped\n+        assertTrue(\"Failed to stop kafka broker within \" + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n+                connect.kafka().runningBrokers().size() == 0);\n+\n+        connect.kafka().startOnlyKafkaOnSamePorts();\n+        log.trace(\"issue kafka start\");\n+        // Allow for the kafka brokers to come back online\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n+                \"Group of workers did not remain the same within the designated time.\");\n+\n+        // Allow for the workers to rebalance and reach a steady state\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        // Expect that the broker has started again\n+        assertTrue(\"Failed to start kafka broker within \" + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n+                connect.kafka().runningBrokers().size() > 0);\n+    }\n+    \n+    protected void createTopics() {\n+        // to verify topic config will be sync-ed across clusters\n+        Map<String, String> topicConfig = new HashMap<>();\n+        topicConfig.put(TopicConfig.CLEANUP_POLICY_CONFIG, TopicConfig.CLEANUP_POLICY_COMPACT);\n+        // create these topics before starting the connectors so we don't need to wait for discovery\n+        primary.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS, 1, topicConfig);\n+        primary.kafka().createTopic(\"backup.test-topic-1\", 1);\n+        primary.kafka().createTopic(\"heartbeats\", 1);\n+        backup.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-1\", 1);\n+        backup.kafka().createTopic(\"heartbeats\", 1);\n+    }\n+    \n+    protected KafkaConsumer<String, String> createSslConsumer(Map<String, Object> consumerProps, String... topics) {\n+        Map<String, Object> props = new HashMap<>(consumerProps);\n+\n+        if (props.get(ConsumerConfig.GROUP_ID_CONFIG) == null) {\n+            props.put(ConsumerConfig.GROUP_ID_CONFIG, UUID.randomUUID().toString());\n+        }\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, backup.kafka().bootstrapServers());\n+        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"false\");\n+        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\");\n+        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\");\n+\n+        // ssl config\n+        props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        \n+        KafkaConsumer<String, String> consumer;\n+        try {\n+            consumer = new KafkaConsumer<>(props);\n+        } catch (Throwable t) {\n+            throw new ConnectException(\"Failed to create consumer\", t);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 405}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDEyMTU0MQ==", "bodyText": "We seem to use poll(Duration.ofMillis(500)) in many places, can we have a constant?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510121541", "createdAt": "2020-10-22T12:31:06Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.utils.ThreadedConsumer;\n+import org.apache.kafka.connect.mirror.utils.ThreadedProducer;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        startClusters();\n+    }\n+\n+    @After\n+    public void close() {\n+        shutdownClusters();\n+    }\n+\n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, \"primary\", \"backup\");\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, \"backup\", \"primary\");   \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(\"primary\"));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(\"backup\"));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(\"primary\"));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(\"primary\"));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(\"backup\"));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(\"backup\"));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, \"primary\",\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(500));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        backupConsumer.assign(primaryOffsets.keySet());\n+        primaryOffsets.forEach(backupConsumer::seek);\n+        backupConsumer.poll(Duration.ofMillis(500));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDE1NTYyMA==", "bodyText": "Why is this field protected while primaryBrokerProps is private?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510155620", "createdAt": "2020-10-22T13:20:51Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDE1NjAwNQ==", "bodyText": "Should we do new HashMap<>(); like the line below? Why is it different?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510156005", "createdAt": "2020-10-22T13:21:22Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDE2MTAzNA==", "bodyText": "This restarts all brokers. I find it strange this takes a EmbeddedConnectCluster. Also I wonder why this is static.", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510161034", "createdAt": "2020-10-22T13:28:15Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\")));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(\"primary-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(\"backup-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of primary-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of backup-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n+        // run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = (ConfigEntry) configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and  topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    protected static Map<String, String> basicMM2Config() {\n+        Map<String, String> mm2Props = new HashMap<>();\n+        mm2Props.put(\"clusters\", \"primary, backup\");\n+        mm2Props.put(\"max.tasks\", \"10\");\n+        mm2Props.put(\"topics\", \"test-topic-.*, primary.test-topic-.*, backup.test-topic-.*\");\n+        mm2Props.put(\"groups\", \"consumer-group-.*\");\n+        mm2Props.put(\"primary->backup.enabled\", \"true\");\n+        mm2Props.put(\"backup->primary.enabled\", \"true\");\n+        mm2Props.put(\"sync.topic.acls.enabled\", \"false\");\n+        mm2Props.put(\"emit.checkpoints.interval.seconds\", \"1\");\n+        mm2Props.put(\"emit.heartbeats.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.topics.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.groups.interval.seconds\", \"1\");\n+        mm2Props.put(\"checkpoints.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"heartbeats.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"offset-syncs.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"config.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"offset.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"status.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"replication.factor\", \"1\");\n+        \n+        return mm2Props;\n+    }\n+    \n+    /*\n+     * restart kafka broker and make sure it is successful\n+     */\n+    protected static void restartKafkaBroker(EmbeddedConnectCluster connect) throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 341}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDE2MTcyOA==", "bodyText": "Should we use this check as a condition to wait? Sleeping 10 secs feels pretty brittle", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510161728", "createdAt": "2020-10-22T13:29:11Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\")));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(\"primary-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(\"backup-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of primary-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of backup-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n+        // run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = (ConfigEntry) configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and  topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    protected static Map<String, String> basicMM2Config() {\n+        Map<String, String> mm2Props = new HashMap<>();\n+        mm2Props.put(\"clusters\", \"primary, backup\");\n+        mm2Props.put(\"max.tasks\", \"10\");\n+        mm2Props.put(\"topics\", \"test-topic-.*, primary.test-topic-.*, backup.test-topic-.*\");\n+        mm2Props.put(\"groups\", \"consumer-group-.*\");\n+        mm2Props.put(\"primary->backup.enabled\", \"true\");\n+        mm2Props.put(\"backup->primary.enabled\", \"true\");\n+        mm2Props.put(\"sync.topic.acls.enabled\", \"false\");\n+        mm2Props.put(\"emit.checkpoints.interval.seconds\", \"1\");\n+        mm2Props.put(\"emit.heartbeats.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.topics.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.groups.interval.seconds\", \"1\");\n+        mm2Props.put(\"checkpoints.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"heartbeats.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"offset-syncs.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"config.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"offset.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"status.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"replication.factor\", \"1\");\n+        \n+        return mm2Props;\n+    }\n+    \n+    /*\n+     * restart kafka broker and make sure it is successful\n+     */\n+    protected static void restartKafkaBroker(EmbeddedConnectCluster connect) throws InterruptedException {\n+\n+        connect.kafka().stopOnlyKafka();\n+        log.trace(\"issue kafka stop\");\n+        connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n+                \"Group of workers did not remain the same after broker shutdown\");\n+\n+        // Allow for the workers to discover that the coordinator is unavailable, if the connector\n+        // is set up on this current EmbeddedConnectCluster\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        // Wait for the broker to be stopped\n+        assertTrue(\"Failed to stop kafka broker within \" + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n+                connect.kafka().runningBrokers().size() == 0);\n+\n+        connect.kafka().startOnlyKafkaOnSamePorts();\n+        log.trace(\"issue kafka start\");\n+        // Allow for the kafka brokers to come back online\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n+                \"Group of workers did not remain the same within the designated time.\");\n+\n+        // Allow for the workers to rebalance and reach a steady state\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n+\n+        // Expect that the broker has started again\n+        assertTrue(\"Failed to start kafka broker within \" + CONNECTOR_SETUP_DURATION_MS + \"ms\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 368}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDE2NjQ5MA==", "bodyText": "Can we move this in the base class?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510166490", "createdAt": "2020-10-22T13:35:37Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationSSLTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        try {\n+            Map<String, Object> sslConfig = TestSslUtils.createSslConfig(false, true, Mode.SERVER, TestUtils.tempFile(), \"testCert\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.ListenersProp(), \"SSL://localhost:0\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.InterBrokerListenerNameProp(), \"SSL\");\n+            backupBrokerProps.putAll(sslConfig);\n+        } catch (final Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+        startClusters();\n+    }\n+    \n+    @After\n+    public void close() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDE2NjY5MQ==", "bodyText": "Can we move this in the base class?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510166691", "createdAt": "2020-10-22T13:35:52Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.utils.ThreadedConsumer;\n+import org.apache.kafka.connect.mirror.utils.ThreadedProducer;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDE5ODY3Mw==", "bodyText": "Can this be private?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r510198673", "createdAt": "2020-10-22T14:16:49Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+import static org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.CONNECTOR_SETUP_DURATION_MS;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertFalse;\n+//import org.junit.After;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+\n+    \n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps;\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> \"backup.producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\")));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(\"primary-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(\"backup-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of primary-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of backup-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n+        // run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = (ConfigEntry) configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and  topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    protected static Map<String, String> basicMM2Config() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 314}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0NjEzNzcx", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-534613771", "createdAt": "2020-11-19T16:16:35Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNjoxNjozNVrOH2mbQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzozMjoyN1rOH2p3HA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAxNDcyMA==", "bodyText": "Why do we have SSL specific methods here? Could we move all the SSL bits into the SSL class?\nWe have fields for the configurations. So we could set them accordingly (without or without SSL) in each concrete class. Then in the base class, we just use the fields to create the clusters without having to know if it's SSL or not.", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527014720", "createdAt": "2020-11-19T16:16:35Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertFalse;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+    protected static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    protected static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+\n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       ", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAxNTkzNQ==", "bodyText": "By catching Throwable, aren't we silencing the error and not immediately failing the test?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527015935", "createdAt": "2020-11-19T16:18:12Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertFalse;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+    protected static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    protected static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+\n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAxNzI2Ng==", "bodyText": "Is there a reason we are only enabling SSL in one of the 2 clusters?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527017266", "createdAt": "2020-11-19T16:20:01Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import org.junit.experimental.categories.Category;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+    \n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        try {\n+            Map<String, Object> sslConfig = TestSslUtils.createSslConfig(false, true, Mode.SERVER, TestUtils.tempFile(), \"testCert\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.ListenersProp(), \"SSL://localhost:0\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAxODE2MA==", "bodyText": "We have this field in both concrete class. Can we move it to the base class instead?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527018160", "createdAt": "2020-11-19T16:21:10Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import org.junit.experimental.categories.Category;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+    \n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = ", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAxODcwMg==", "bodyText": "Should this class be abstract?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527018702", "createdAt": "2020-11-19T16:21:56Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertFalse;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAxOTM1NA==", "bodyText": "By catching Throwable, aren't we silencing the error and not immediately failing the test?\nAlso we should not be catching Throwable, if the JVM throws an Error we want it to fail the test and never want to handle it. There're a bunch of them in these files", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527019354", "createdAt": "2020-11-19T16:22:46Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertFalse;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+    protected static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    protected static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+\n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator<ConfigEntry> configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, ", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 243}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyMjI5MQ==", "bodyText": "Can we find a better name?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527022291", "createdAt": "2020-11-19T16:26:33Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/TestUtils.java", "diffHunk": "@@ -32,4 +32,15 @@\n         }\n         return props;\n     }\n-}\n+    \n+    /*\n+     * return records with different but predictable key and value \n+     */\n+    public static Map<String, String> expectedRecords(int numRecords) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyMzczMQ==", "bodyText": "nit: we tend to have a new line at the end of files", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527023731", "createdAt": "2020-11-19T16:28:38Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/TestUtils.java", "diffHunk": "@@ -32,4 +32,15 @@\n         }\n         return props;\n     }\n-}\n+    \n+    /*\n+     * return records with different but predictable key and value \n+     */\n+    public static Map<String, String> expectedRecords(int numRecords) {\n+        Map<String, String> expectedRecords = new HashMap<>();\n+        for (int i = 0; i < numRecords; i++) {\n+            expectedRecords.put(\"key-\" + i, \"message-\" + i);\n+        }\n+        return expectedRecords;\n+    }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNTIzMA==", "bodyText": "Can we find a better name?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527025230", "createdAt": "2020-11-19T16:30:39Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertFalse;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+    protected static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    protected static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+\n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator<ConfigEntry> configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    private static Map<String, String> basicMM2Config() {\n+        Map<String, String> mm2Props = new HashMap<>();\n+        mm2Props.put(\"clusters\", PRIMARY_CLUSTER_ALIAS + \", \" + BACKUP_CLUSTER_ALIAS);\n+        mm2Props.put(\"max.tasks\", \"10\");\n+        mm2Props.put(\"topics\", \"test-topic-.*, primary.test-topic-.*, backup.test-topic-.*\");\n+        mm2Props.put(\"groups\", \"consumer-group-.*\");\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \"->\" + BACKUP_CLUSTER_ALIAS + \".enabled\", \"true\");\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"true\");\n+        mm2Props.put(\"sync.topic.acls.enabled\", \"false\");\n+        mm2Props.put(\"emit.checkpoints.interval.seconds\", \"1\");\n+        mm2Props.put(\"emit.heartbeats.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.topics.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.groups.interval.seconds\", \"1\");\n+        mm2Props.put(\"checkpoints.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"heartbeats.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"offset-syncs.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"config.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"offset.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"status.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"replication.factor\", \"1\");\n+        \n+        return mm2Props;\n+    }\n+    \n+    /*\n+     * restart kafka broker and make sure it is successful\n+     */\n+    protected void restartKafkaBroker(EmbeddedKafkaCluster kafkaCluster) throws InterruptedException {\n+\n+        kafkaCluster.stopOnlyKafka();\n+        log.trace(\"issue kafka stop\");\n+        \n+        // wait for the broker to be stopped        \n+        waitForCondition(() -> {\n+            return kafkaCluster.runningBrokers().size() == 0;\n+        }, BROKER_RESTART_TIMEOUT_MS, \"Failed to stop kafka broker within\");\n+\n+        kafkaCluster.startOnlyKafkaOnSamePorts();\n+        log.trace(\"issue kafka start\");\n+        \n+        // wait for the kafka brokers to come back online\n+        waitForCondition(() -> {\n+            return kafkaCluster.runningBrokers().size() > 0;\n+        }, BROKER_RESTART_TIMEOUT_MS, \"Failed to start kafka broker within\");\n+    }\n+    \n+    protected void createTopics() {\n+        // to verify topic config will be sync-ed across clusters\n+        Map<String, String> topicConfig = new HashMap<>();\n+        topicConfig.put(TopicConfig.CLEANUP_POLICY_CONFIG, TopicConfig.CLEANUP_POLICY_COMPACT);\n+        // create these topics before starting the connectors so we don't need to wait for discovery\n+        primary.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS, 1, topicConfig);\n+        primary.kafka().createTopic(\"backup.test-topic-1\", 1);\n+        primary.kafka().createTopic(\"heartbeats\", 1);\n+        backup.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-1\", 1);\n+        backup.kafka().createTopic(\"heartbeats\", 1);\n+    }\n+    \n+    protected KafkaConsumer<String, String> createConsumer(EmbeddedConnectCluster connect, Map<String, Object> consumerProps, String... topics) {\n+        Map<String, Object> props = new HashMap<>(consumerProps);\n+\n+        props.putIfAbsent(ConsumerConfig.GROUP_ID_CONFIG, UUID.randomUUID().toString());\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, connect.kafka().bootstrapServers());\n+        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"false\");\n+        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\");\n+        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\");\n+\n+        // ssl config\n+        if (connect.kafka().sslEnabled()) {\n+            props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        }\n+        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n+        consumer.subscribe(Arrays.asList(topics));\n+        return consumer;\n+    }\n+    \n+    /*\n+     * Generate some consumer activity on both clusters to ensure the checkpoint connector always starts promptly\n+     */\n+    protected void dummyConsumption() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 398}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNTY5Mw==", "bodyText": "We can use Collections.singletonMap()", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527025693", "createdAt": "2020-11-19T16:31:17Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertFalse;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+    protected static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    protected static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+\n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator<ConfigEntry> configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    private static Map<String, String> basicMM2Config() {\n+        Map<String, String> mm2Props = new HashMap<>();\n+        mm2Props.put(\"clusters\", PRIMARY_CLUSTER_ALIAS + \", \" + BACKUP_CLUSTER_ALIAS);\n+        mm2Props.put(\"max.tasks\", \"10\");\n+        mm2Props.put(\"topics\", \"test-topic-.*, primary.test-topic-.*, backup.test-topic-.*\");\n+        mm2Props.put(\"groups\", \"consumer-group-.*\");\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \"->\" + BACKUP_CLUSTER_ALIAS + \".enabled\", \"true\");\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"true\");\n+        mm2Props.put(\"sync.topic.acls.enabled\", \"false\");\n+        mm2Props.put(\"emit.checkpoints.interval.seconds\", \"1\");\n+        mm2Props.put(\"emit.heartbeats.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.topics.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.groups.interval.seconds\", \"1\");\n+        mm2Props.put(\"checkpoints.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"heartbeats.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"offset-syncs.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"config.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"offset.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"status.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"replication.factor\", \"1\");\n+        \n+        return mm2Props;\n+    }\n+    \n+    /*\n+     * restart kafka broker and make sure it is successful\n+     */\n+    protected void restartKafkaBroker(EmbeddedKafkaCluster kafkaCluster) throws InterruptedException {\n+\n+        kafkaCluster.stopOnlyKafka();\n+        log.trace(\"issue kafka stop\");\n+        \n+        // wait for the broker to be stopped        \n+        waitForCondition(() -> {\n+            return kafkaCluster.runningBrokers().size() == 0;\n+        }, BROKER_RESTART_TIMEOUT_MS, \"Failed to stop kafka broker within\");\n+\n+        kafkaCluster.startOnlyKafkaOnSamePorts();\n+        log.trace(\"issue kafka start\");\n+        \n+        // wait for the kafka brokers to come back online\n+        waitForCondition(() -> {\n+            return kafkaCluster.runningBrokers().size() > 0;\n+        }, BROKER_RESTART_TIMEOUT_MS, \"Failed to start kafka broker within\");\n+    }\n+    \n+    protected void createTopics() {\n+        // to verify topic config will be sync-ed across clusters\n+        Map<String, String> topicConfig = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 364}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNjIyMg==", "bodyText": "We can use StringDeserializer.class.getName()", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527026222", "createdAt": "2020-11-19T16:32:02Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertFalse;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+    protected static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    protected static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+\n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    protected static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator<ConfigEntry> configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = expectedRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    protected static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(500));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    protected static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(500));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();\n+    }\n+   \n+    /*\n+     * MM2 config to use in integration tests\n+     */\n+    private static Map<String, String> basicMM2Config() {\n+        Map<String, String> mm2Props = new HashMap<>();\n+        mm2Props.put(\"clusters\", PRIMARY_CLUSTER_ALIAS + \", \" + BACKUP_CLUSTER_ALIAS);\n+        mm2Props.put(\"max.tasks\", \"10\");\n+        mm2Props.put(\"topics\", \"test-topic-.*, primary.test-topic-.*, backup.test-topic-.*\");\n+        mm2Props.put(\"groups\", \"consumer-group-.*\");\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \"->\" + BACKUP_CLUSTER_ALIAS + \".enabled\", \"true\");\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"true\");\n+        mm2Props.put(\"sync.topic.acls.enabled\", \"false\");\n+        mm2Props.put(\"emit.checkpoints.interval.seconds\", \"1\");\n+        mm2Props.put(\"emit.heartbeats.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.topics.interval.seconds\", \"1\");\n+        mm2Props.put(\"refresh.groups.interval.seconds\", \"1\");\n+        mm2Props.put(\"checkpoints.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"heartbeats.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"offset-syncs.topic.replication.factor\", \"1\");\n+        mm2Props.put(\"config.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"offset.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"status.storage.replication.factor\", \"1\");\n+        mm2Props.put(\"replication.factor\", \"1\");\n+        \n+        return mm2Props;\n+    }\n+    \n+    /*\n+     * restart kafka broker and make sure it is successful\n+     */\n+    protected void restartKafkaBroker(EmbeddedKafkaCluster kafkaCluster) throws InterruptedException {\n+\n+        kafkaCluster.stopOnlyKafka();\n+        log.trace(\"issue kafka stop\");\n+        \n+        // wait for the broker to be stopped        \n+        waitForCondition(() -> {\n+            return kafkaCluster.runningBrokers().size() == 0;\n+        }, BROKER_RESTART_TIMEOUT_MS, \"Failed to stop kafka broker within\");\n+\n+        kafkaCluster.startOnlyKafkaOnSamePorts();\n+        log.trace(\"issue kafka start\");\n+        \n+        // wait for the kafka brokers to come back online\n+        waitForCondition(() -> {\n+            return kafkaCluster.runningBrokers().size() > 0;\n+        }, BROKER_RESTART_TIMEOUT_MS, \"Failed to start kafka broker within\");\n+    }\n+    \n+    protected void createTopics() {\n+        // to verify topic config will be sync-ed across clusters\n+        Map<String, String> topicConfig = new HashMap<>();\n+        topicConfig.put(TopicConfig.CLEANUP_POLICY_CONFIG, TopicConfig.CLEANUP_POLICY_COMPACT);\n+        // create these topics before starting the connectors so we don't need to wait for discovery\n+        primary.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS, 1, topicConfig);\n+        primary.kafka().createTopic(\"backup.test-topic-1\", 1);\n+        primary.kafka().createTopic(\"heartbeats\", 1);\n+        backup.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-1\", 1);\n+        backup.kafka().createTopic(\"heartbeats\", 1);\n+    }\n+    \n+    protected KafkaConsumer<String, String> createConsumer(EmbeddedConnectCluster connect, Map<String, Object> consumerProps, String... topics) {\n+        Map<String, Object> props = new HashMap<>(consumerProps);\n+\n+        props.putIfAbsent(ConsumerConfig.GROUP_ID_CONFIG, UUID.randomUUID().toString());\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, connect.kafka().bootstrapServers());\n+        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"false\");\n+        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 382}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAzMDA0MQ==", "bodyText": "This test is not specific to SSL, why do we have it ?\nShould instead all tests in MirrorConnectorsIntegrationTest go to the base class so we run them both with and without SSL?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527030041", "createdAt": "2020-11-19T16:37:05Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import org.junit.experimental.categories.Category;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+    \n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        try {\n+            Map<String, Object> sslConfig = TestSslUtils.createSslConfig(false, true, Mode.SERVER, TestUtils.tempFile(), \"testCert\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.ListenersProp(), \"SSL://localhost:0\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.InterBrokerListenerNameProp(), \"SSL\");\n+            backupBrokerProps.putAll(sslConfig);\n+        } catch (final Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+        startClusters();\n+    }\n+    \n+    @After\n+    public void close() {\n+        shutdownClusters();\n+    }\n+    \n+    @Test\n+    public void testReplicationSSL() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA2Njg1NQ==", "bodyText": "Isn't MM2/Connect using at least once by default? ie, the producer in the runtime can cause duplicates.", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527066855", "createdAt": "2020-11-19T17:26:19Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,370 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.utils.ThreadedConsumer;\n+import org.apache.kafka.connect.mirror.utils.ThreadedProducer;\n+\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+    \n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        startClusters();\n+    }\n+\n+    @After\n+    public void close() {\n+        shutdownClusters();\n+    }\n+\n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        backupConsumer.assign(primaryOffsets.keySet());\n+        primaryOffsets.forEach(backupConsumer::seek);\n+        backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        backupConsumer.commitAsync();\n+        \n+        assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        \n+        backupConsumer.close();\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                PRIMARY_CLUSTER_ALIAS + \".\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(PRIMARY_CLUSTER_ALIAS + \".\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * This test is to validate MirrorSourceConnector follows \"at most once\" delivery guarantee", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 324}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA3MTAwNA==", "bodyText": "I don't understand what this test is doing.\nWhy do we need background clients instead of producing upfront and consuming the data mirrorred at the end of the test?\nIt looks like we are testing the primary->backup scenario but we are restarting the backup cluster. The source connector should not interact with the backup cluster.", "url": "https://github.com/apache/kafka/pull/9224#discussion_r527071004", "createdAt": "2020-11-19T17:32:27Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,370 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.utils.ThreadedConsumer;\n+import org.apache.kafka.connect.mirror.utils.ThreadedProducer;\n+\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+    \n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        startClusters();\n+    }\n+\n+    @After\n+    public void close() {\n+        shutdownClusters();\n+    }\n+\n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        backupConsumer.assign(primaryOffsets.keySet());\n+        primaryOffsets.forEach(backupConsumer::seek);\n+        backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        backupConsumer.commitAsync();\n+        \n+        assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        \n+        backupConsumer.close();\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                PRIMARY_CLUSTER_ALIAS + \".\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(PRIMARY_CLUSTER_ALIAS + \".\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * This test is to validate MirrorSourceConnector follows \"at most once\" delivery guarantee\n+     * under broker restart / failure\n+     */\n+    @Test\n+    public void testWithBrokerRestart() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 328}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a", "committedDate": "2020-11-23T05:00:59Z", "message": "refactor MM2 integration tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzODMyMzg3", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-543832387", "createdAt": "2020-12-03T10:52:57Z", "commit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMDo1Mjo1N1rOH-Togg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjozMzoyMFrOH-ZbYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTA5NTQyNg==", "bodyText": "This constant is unused. Should we use it instead of hardcoding 3 below when we create connect workers?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535095426", "createdAt": "2020-12-03T10:52:57Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTA5NTc1Nw==", "bodyText": "This is unused too", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535095757", "createdAt": "2020-12-03T10:53:22Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    private static final long DEFAULT_PRODUCE_SEND_DURATION_MS = TimeUnit.SECONDS.toMillis(120); ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTA5ODAyMQ==", "bodyText": "Ideally we want to get rid of this method as it makes no sense in tests that are not SSL.", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535098021", "createdAt": "2020-12-03T10:55:28Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    private static final long DEFAULT_PRODUCE_SEND_DURATION_MS = TimeUnit.SECONDS.toMillis(120); \n+    private static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    private static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    private Map<String, String> mm2Props;\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>(); \n+    abstract Map<String, Object> getSslConfig();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTEwMDQxOQ==", "bodyText": "This should be done in the SSL class. The base class should not be aware of SSL and just use configurations from the concrete classes", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535100419", "createdAt": "2020-12-03T10:58:01Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    private static final long DEFAULT_PRODUCE_SEND_DURATION_MS = TimeUnit.SECONDS.toMillis(120); \n+    private static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    private static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    private Map<String, String> mm2Props;\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>(); \n+    abstract Map<String, Object> getSslConfig();\n+\n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        final Map<String, Object> sslConfig = getSslConfig();\n+        if (sslConfig != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTEwMjY0NQ==", "bodyText": "Can we move this method to the base class?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535102645", "createdAt": "2020-12-03T11:00:27Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.experimental.categories.Category;\n+\n+import java.util.Map;\n+\n+import org.apache.kafka.test.IntegrationTest;\n+\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        startClusters();\n+    }\n+\n+    @After", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTEwMzY1NQ==", "bodyText": "Well in MirrorConnectorsIntegrationSSLTest, we can override it, but we should put the default implementation in the base class", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535103655", "createdAt": "2020-12-03T11:01:24Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.errors.TimeoutException;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.utils.ThreadedConsumer;\n+import org.apache.kafka.connect.mirror.utils.ThreadedProducer;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDE2NjY5MQ=="}, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE2OTU5MQ==", "bodyText": "Do we really need to cast to Password and call value()? Can't we just pass brokerConfig.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535169591", "createdAt": "2020-12-03T12:06:43Z", "author": {"login": "mimaison"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedKafkaCluster.java", "diffHunk": "@@ -161,6 +161,11 @@ private void start(int[] brokerPorts, String[] logDirs) {\n         producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers());\n         producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n         producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n+        if (sslEnabled()) {\n+        \tproducerProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, brokerConfig.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        \tproducerProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) brokerConfig.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE3MjIzNg==", "bodyText": "brokerConfig is a Properties, so we can call getProperty() to get back a String directly", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535172236", "createdAt": "2020-12-03T12:09:26Z", "author": {"login": "mimaison"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedKafkaCluster.java", "diffHunk": "@@ -278,6 +283,14 @@ protected boolean hasState(KafkaServer server, Predicate<BrokerState> desiredSta\n             return false;\n         }\n     }\n+    \n+    public boolean sslEnabled() {\n+        final Object listeners = brokerConfig.get(KafkaConfig$.MODULE$.ListenersProp());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE3MzU2MA==", "bodyText": "Instead of doing:\nif (condition) {\n  return true;\n} else {\n  return false;\n}\n\nYou can do:\nreturn condition;", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535173560", "createdAt": "2020-12-03T12:10:38Z", "author": {"login": "mimaison"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedKafkaCluster.java", "diffHunk": "@@ -278,6 +283,14 @@ protected boolean hasState(KafkaServer server, Predicate<BrokerState> desiredSta\n             return false;\n         }\n     }\n+    \n+    public boolean sslEnabled() {\n+        final Object listeners = brokerConfig.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE3NDMzMA==", "bodyText": "Same as above, I think we can just pass brokerConfig.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535174330", "createdAt": "2020-12-03T12:11:20Z", "author": {"login": "mimaison"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedKafkaCluster.java", "diffHunk": "@@ -444,7 +457,11 @@ public Admin createAdminClient() {\n         putIfAbsent(props, AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n         putIfAbsent(props, KEY_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n         putIfAbsent(props, VALUE_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n-\n+        if (sslEnabled()) {\n+        \tputIfAbsent(props,SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, brokerConfig.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        \tputIfAbsent(props,SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) brokerConfig.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE3NjEwNQ==", "bodyText": "A few lines in this file (like this one) contain tabs, we use spaces in Kafka", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535176105", "createdAt": "2020-12-03T12:13:05Z", "author": {"login": "mimaison"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedKafkaCluster.java", "diffHunk": "@@ -161,6 +161,11 @@ private void start(int[] brokerPorts, String[] logDirs) {\n         producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers());\n         producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n         producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n+        if (sslEnabled()) {\n+        \tproducerProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, brokerConfig.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE3OTM1OQ==", "bodyText": "But why is this needed here? I don't know what the other test is doing but I don't understand why it's used here", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535179359", "createdAt": "2020-12-03T12:16:19Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationSSLTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        try {\n+            Map<String, Object> sslConfig = TestSslUtils.createSslConfig(false, true, Mode.SERVER, TestUtils.tempFile(), \"testCert\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.ListenersProp(), \"SSL://localhost:0\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.InterBrokerListenerNameProp(), \"SSL\");\n+            backupBrokerProps.putAll(sslConfig);\n+        } catch (final Exception e) {\n+            throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExNDk5NQ=="}, "originalCommit": null, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4MjM1NA==", "bodyText": "I find it strange that this method closes the consumer it received.", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535182354", "createdAt": "2020-12-03T12:20:16Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    private static final long DEFAULT_PRODUCE_SEND_DURATION_MS = TimeUnit.SECONDS.toMillis(120); \n+    private static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    private static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    private Map<String, String> mm2Props;\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>(); \n+    abstract Map<String, Object> getSslConfig();\n+\n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        final Map<String, Object> sslConfig = getSslConfig();\n+        if (sslConfig != null) {\n+            Properties sslProps = new Properties();\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, sslConfig.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) sslConfig.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+            sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+            \n+            // set SSL config for kafka connect worker\n+            backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            \n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            // set SSL config for producer used by source task in MM2\n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        warmUpConsumer();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    \n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        backupConsumer.assign(primaryOffsets.keySet());\n+        primaryOffsets.forEach(backupConsumer::seek);\n+        backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        backupConsumer.commitAsync();\n+        \n+        assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        \n+        backupConsumer.close();\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                PRIMARY_CLUSTER_ALIAS + \".\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(PRIMARY_CLUSTER_ALIAS + \".\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    private static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    private static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    private static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator<ConfigEntry> configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = generateRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    private static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    private static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 563}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4NTI1NA==", "bodyText": "Can we use allConfigs.get() to find the configs we want instead of searching for them?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535185254", "createdAt": "2020-12-03T12:24:50Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    private static final long DEFAULT_PRODUCE_SEND_DURATION_MS = TimeUnit.SECONDS.toMillis(120); \n+    private static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    private static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    private Map<String, String> mm2Props;\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>(); \n+    abstract Map<String, Object> getSslConfig();\n+\n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        final Map<String, Object> sslConfig = getSslConfig();\n+        if (sslConfig != null) {\n+            Properties sslProps = new Properties();\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, sslConfig.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) sslConfig.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+            sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+            \n+            // set SSL config for kafka connect worker\n+            backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            \n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            // set SSL config for producer used by source task in MM2\n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        warmUpConsumer();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    \n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        backupConsumer.assign(primaryOffsets.keySet());\n+        primaryOffsets.forEach(backupConsumer::seek);\n+        backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        backupConsumer.commitAsync();\n+        \n+        assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        \n+        backupConsumer.close();\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                PRIMARY_CLUSTER_ALIAS + \".\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(PRIMARY_CLUSTER_ALIAS + \".\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    private static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    private static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    private static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator<ConfigEntry> configIterator = allConfigs.entries().iterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 488}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4NTg0Mw==", "bodyText": "Just let the Exception flow, that will automatically fail the test", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535185843", "createdAt": "2020-12-03T12:25:44Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import static org.apache.kafka.connect.mirror.TestUtils.expectedRecords;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import org.apache.kafka.test.IntegrationTest;\n+import kafka.server.KafkaConfig$;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import static org.junit.Assert.assertFalse;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Common Test functions for MM2 integration tests\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    protected static final int NUM_RECORDS_PER_PARTITION = 10;\n+    public static final int NUM_PARTITIONS = 10;\n+    protected static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    protected static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    protected static final int CHECKPOINT_DURATION_MS = 20_000;\n+    protected static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    protected static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    protected static final int NUM_WORKERS = 3;\n+    protected static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    protected static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+\n+    protected Map<String, String> mm2Props;\n+    protected MirrorMakerConfig mm2Config; \n+    protected EmbeddedConnectCluster primary;\n+    protected EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    private Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>();\n+    private Properties sslProps = new Properties();\n+    \n+    private void loadSslPropsFromBrokerConfig() {       \n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+        sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) backupBrokerProps.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+        sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+    }\n+    \n+    protected void setSslConfig() {\n+        // set SSL config for kafka connect worker\n+        backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        // set SSL config for producer used by source task in MM2\n+        mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+            e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+    }\n+    \n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        // if backup kafka cluster contains ssl config, enable ssl of kafka connect and mm2\n+        final Object listeners = backupBrokerProps.get(KafkaConfig$.MODULE$.ListenersProp());\n+        if (listeners != null && listeners.toString().contains(\"SSL\")) {\n+            loadSslPropsFromBrokerConfig();\n+            setSslConfig();\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        dummyConsumption();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    protected static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    protected static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAxNTkzNQ=="}, "originalCommit": null, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4NjkyMg==", "bodyText": "This is always used with Duration.ofMillis(). Should we store the Duration object directly?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535186922", "createdAt": "2020-12-03T12:27:28Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final int CONSUMER_POLL_TIMEOUT_MS = 500;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4OTM1NA==", "bodyText": "I understand this was probably already there but we should avoid catching Throwable. I'm not sure the try/catch block is necessarily helping in this cases", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535189354", "createdAt": "2020-12-03T12:31:38Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    private static final long DEFAULT_PRODUCE_SEND_DURATION_MS = TimeUnit.SECONDS.toMillis(120); \n+    private static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    private static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    private Map<String, String> mm2Props;\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>(); \n+    abstract Map<String, Object> getSslConfig();\n+\n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        final Map<String, Object> sslConfig = getSslConfig();\n+        if (sslConfig != null) {\n+            Properties sslProps = new Properties();\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, sslConfig.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) sslConfig.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+            sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+            \n+            // set SSL config for kafka connect worker\n+            backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            \n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            // set SSL config for producer used by source task in MM2\n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        warmUpConsumer();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    \n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+            } catch (Throwable e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE5MDM3MA==", "bodyText": "Closing a client in the middle of a test can be confusing. I wonder if we could wrap this whole block about primaryConsumer in a try with resource block. WDYT?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r535190370", "createdAt": "2020-12-03T12:33:20Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    private static final long DEFAULT_PRODUCE_SEND_DURATION_MS = TimeUnit.SECONDS.toMillis(120); \n+    private static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    private static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    private Map<String, String> mm2Props;\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>(); \n+    abstract Map<String, Object> getSslConfig();\n+\n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        final Map<String, Object> sslConfig = getSslConfig();\n+        if (sslConfig != null) {\n+            Properties sslProps = new Properties();\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, sslConfig.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) sslConfig.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+            sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+            \n+            // set SSL config for kafka connect worker\n+            backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            \n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            // set SSL config for producer used by source task in MM2\n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        warmUpConsumer();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    \n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 274}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a", "committedDate": "2020-11-23T05:00:59Z", "message": "refactor MM2 integration tests"}, "afterCommit": {"oid": "ff7de40fcd6d370354d032b00f6d9ea656d15e22", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/ff7de40fcd6d370354d032b00f6d9ea656d15e22", "committedDate": "2020-12-04T06:26:01Z", "message": "refactor MM2 integration tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NzA3ODk2", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-547707896", "createdAt": "2020-12-08T23:06:56Z", "commit": {"oid": "ff7de40fcd6d370354d032b00f6d9ea656d15e22"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMzowNjo1NlrOIB6Yuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMzozNzo0OFrOIB7V2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg3NjA5MQ==", "bodyText": "We can return listeners != null && listeners.contains(\"SSL\")", "url": "https://github.com/apache/kafka/pull/9224#discussion_r538876091", "createdAt": "2020-12-08T23:06:56Z", "author": {"login": "mimaison"}, "path": "connect/runtime/src/test/java/org/apache/kafka/connect/util/clusters/EmbeddedKafkaCluster.java", "diffHunk": "@@ -278,6 +283,11 @@ protected boolean hasState(KafkaServer server, Predicate<BrokerState> desiredSta\n             return false;\n         }\n     }\n+    \n+    public boolean sslEnabled() {\n+        final String listeners = brokerConfig.getProperty(KafkaConfig$.MODULE$.ListenersProp());\n+        return (listeners != null && listeners.contains(\"SSL\")) ? true : false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ff7de40fcd6d370354d032b00f6d9ea656d15e22"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg3NzA4Ng==", "bodyText": "Yes but the code that created the consumer should close it. If I call waitForConsumingAllRecords(), I'd not expect it to close my consumer instance.", "url": "https://github.com/apache/kafka/pull/9224#discussion_r538877086", "createdAt": "2020-12-08T23:09:01Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,617 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final int CONSUMER_POLL_TIMEOUT_MS = 500;\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    private static final long DEFAULT_PRODUCE_SEND_DURATION_MS = TimeUnit.SECONDS.toMillis(120); \n+    private static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    private static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    private Map<String, String> mm2Props;\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    private Map<String, String> primaryWorkerProps = new HashMap<>();\n+    private Map<String, String> backupWorkerProps = new HashMap<>(); \n+    abstract Map<String, Object> getSslConfig();\n+\n+    protected void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props = basicMM2Config();\n+        \n+        final Map<String, Object> sslConfig = getSslConfig();\n+        if (sslConfig != null) {\n+            Properties sslProps = new Properties();\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, sslConfig.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));\n+            sslProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ((Password) sslConfig.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG)).value());\n+            sslProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SSL\");\n+            \n+            // set SSL config for kafka connect worker\n+            backupWorkerProps.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            \n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+            // set SSL config for producer used by source task in MM2\n+            mm2Props.putAll(sslProps.entrySet().stream().collect(Collectors.toMap(\n+                e -> BACKUP_CLUSTER_ALIAS + \".producer.\" + String.valueOf(e.getKey()), e ->  String.valueOf(e.getValue()))));\n+        }\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(3)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        warmUpConsumer();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    public void shutdownClusters() {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    \n+    @Test\n+    public void testReplication() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(primaryConsumer, 0);\n+\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n+        waitForConsumingAllRecords(backupConsumer, 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        primaryConsumer.assign(backupOffsets.keySet());\n+        backupOffsets.forEach(primaryConsumer::seek);\n+        primaryConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        primaryConsumer.commitAsync();\n+\n+        assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+\n+        primaryConsumer.close();\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            try {\n+                return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+            } catch (Throwable e) {\n+                return false;\n+            }\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName));\n+        backupConsumer.assign(primaryOffsets.keySet());\n+        primaryOffsets.forEach(backupConsumer::seek);\n+        backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        backupConsumer.commitAsync();\n+        \n+        assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+        assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+            new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        \n+        backupConsumer.close();\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                PRIMARY_CLUSTER_ALIAS + \".\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(PRIMARY_CLUSTER_ALIAS + \".\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    private static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    private static void deleteAllTopics(EmbeddedKafkaCluster cluster) {\n+        Admin client = cluster.createAdminClient();\n+        try {\n+            client.deleteTopics(client.listTopics().names().get());\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    private static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+        try {\n+            DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+            Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];\n+            Iterator<ConfigEntry> configIterator = allConfigs.entries().iterator();\n+            while (configIterator.hasNext()) {\n+                ConfigEntry currentConfig = configIterator.next();     \n+                if (currentConfig.name().equals(configName)) {\n+                    return currentConfig.value();\n+                }\n+            }\n+        } catch (Throwable e) {\n+            // should not run into exception normally. In case of Exception, \n+            // simply fail the test and investigate\n+        }\n+        return null;\n+    }\n+    \n+    /*\n+     *  produce messages to the cluster and topic \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName) {\n+        Map<String, String> recordSent = generateRecords(NUM_RECORDS_PRODUCED);\n+        for (Map.Entry<String, String> entry : recordSent.entrySet()) {\n+            cluster.kafka().produce(topicName, entry.getKey(), entry.getValue());\n+        }\n+    }\n+\n+    /*\n+     * produce messages to the cluster and topic partition less than numPartitions \n+     */\n+    protected void produceMessages(EmbeddedConnectCluster cluster, String topicName, int numPartitions) {\n+        int cnt = 0;\n+        for (int r = 0; r < NUM_RECORDS_PER_PARTITION; r++)\n+            for (int p = 0; p < numPartitions; p++)\n+                cluster.kafka().produce(topicName, p, \"key\", \"value-\" + cnt++);\n+    }\n+    \n+    /*\n+     * given consumer group, topics and expected number of records, make sure the consumer group\n+     * offsets are eventually synced to the expected offset numbers\n+     */\n+    private static <T> void waitForConsumerGroupOffsetSync(EmbeddedConnectCluster connect, \n+            Consumer<T, T> consumer, List<String> topics, String consumerGroupId, int numRecords)\n+            throws InterruptedException {\n+        Admin adminClient = connect.kafka().createAdminClient();\n+        List<TopicPartition> tps = new ArrayList<>(NUM_PARTITIONS * topics.size());\n+        for (int partitionIndex = 0; partitionIndex < NUM_PARTITIONS; partitionIndex++) {\n+            for (String topic : topics) {\n+                tps.add(new TopicPartition(topic, partitionIndex));\n+            }\n+        }\n+        long expectedTotalOffsets = numRecords * topics.size();\n+\n+        waitForCondition(() -> {\n+            Map<TopicPartition, OffsetAndMetadata> consumerGroupOffsets =\n+                    adminClient.listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();\n+            long consumerGroupOffsetTotal = consumerGroupOffsets.values().stream()\n+                    .mapToLong(metadata -> metadata.offset()).sum();\n+\n+            Map<TopicPartition, Long> offsets = consumer.endOffsets(tps, Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+            long totalOffsets = offsets.values().stream().mapToLong(l -> l).sum();\n+\n+            // make sure the consumer group offsets are synced to expected number\n+            return totalOffsets == expectedTotalOffsets && consumerGroupOffsetTotal > 0;\n+        }, OFFSET_SYNC_DURATION_MS, \"Consumer group offset sync is not complete in time\");\n+    }\n+\n+    /*\n+     * make sure the consumer to consume expected number of records\n+     */\n+    private static <T> void waitForConsumingAllRecords(Consumer<T, T> consumer, int numExpectedRecords) \n+            throws InterruptedException {\n+        final AtomicInteger totalConsumedRecords = new AtomicInteger(0);\n+        waitForCondition(() -> {\n+            ConsumerRecords<T, T> records = consumer.poll(Duration.ofMillis(CONSUMER_POLL_TIMEOUT_MS));\n+            return numExpectedRecords == totalConsumedRecords.addAndGet(records.count());\n+        }, RECORD_CONSUME_DURATION_MS, \"Consumer cannot consume all records in time\");\n+        consumer.commitSync();\n+        consumer.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4MjM1NA=="}, "originalCommit": {"oid": "bd6ee1a200438b938d0a2a1e8ccc501e7171eb0a"}, "originalPosition": 563}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg4MzMwMQ==", "bodyText": "We can use Config.get() to directly access the configuration we want, see https://kafka.apache.org/26/javadoc/org/apache/kafka/clients/admin/Config.html#get-java.lang.String-", "url": "https://github.com/apache/kafka/pull/9224#discussion_r538883301", "createdAt": "2020-12-08T23:19:44Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,577 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final Duration CONSUMER_POLL_TIMEOUT_MS = Duration.ofMillis(500);\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    protected Map<String, String> mm2Props = new HashMap<>();\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    protected Map<String, String> primaryWorkerProps = new HashMap<>();\n+    protected Map<String, String> backupWorkerProps = new HashMap<>(); \n+    \n+    @Before\n+    public void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props.putAll(basicMM2Config());\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        warmUpConsumer();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    @After\n+    public void shutdownClusters() throws Exception {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    \n+    @Test\n+    public void testReplication() throws Exception {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        waitForConsumingAllRecords(primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\"), 0);\n+        waitForConsumingAllRecords(backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\"), 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        try (Consumer<byte[], byte[]> primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName))) {\n+            primaryConsumer.assign(backupOffsets.keySet());\n+            backupOffsets.forEach(primaryConsumer::seek);\n+            primaryConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+            primaryConsumer.commitAsync();\n+\n+            assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+                new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+                CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+        }\n+\n+        waitForCondition(() -> {\n+            return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName))) {\n+            backupConsumer.assign(primaryOffsets.keySet());\n+            primaryOffsets.forEach(backupConsumer::seek);\n+            backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+            backupConsumer.commitAsync();\n+        \n+            assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+                new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+                new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        }\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                PRIMARY_CLUSTER_ALIAS + \".\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(PRIMARY_CLUSTER_ALIAS + \".\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    private static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())\n+                .collect(Collectors.toList());\n+        for (String connector : connectorNames) {\n+            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n+                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n+        }\n+    }\n+ \n+    /*\n+     * delete all topics of the input kafka cluster\n+     */\n+    private static void deleteAllTopics(EmbeddedKafkaCluster cluster) throws Exception {\n+        Admin client = cluster.createAdminClient();\n+        client.deleteTopics(client.listTopics().names().get());\n+    }\n+    \n+    /*\n+     * retrieve the config value based on the input cluster, topic and config name\n+     */\n+    private static String getTopicConfig(EmbeddedKafkaCluster cluster, String topic, String configName) \n+        throws Exception {\n+        Admin client = cluster.createAdminClient();\n+        Collection<ConfigResource> cr =  Collections.singleton(\n+                new ConfigResource(ConfigResource.Type.TOPIC, topic)); \n+\n+        DescribeConfigsResult configsResult = client.describeConfigs(cr);\n+        Config allConfigs = (Config) configsResult.all().get().values().toArray()[0];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ff7de40fcd6d370354d032b00f6d9ea656d15e22"}, "originalPosition": 451}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg4NTY1MQ==", "bodyText": "We could use a \"for each\" loop here, something like:\nfor (Class<? extends Connector> connector : connectorClasses) {\n    connectCluster.configureConnector(connector.getSimpleName(), mm2Config.connectorBaseConfig(\n        new SourceAndTarget(primary, backup), connector));\n}", "url": "https://github.com/apache/kafka/pull/9224#discussion_r538885651", "createdAt": "2020-12-08T23:24:54Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,577 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final Duration CONSUMER_POLL_TIMEOUT_MS = Duration.ofMillis(500);\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    protected Map<String, String> mm2Props = new HashMap<>();\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    protected Map<String, String> primaryWorkerProps = new HashMap<>();\n+    protected Map<String, String> backupWorkerProps = new HashMap<>(); \n+    \n+    @Before\n+    public void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props.putAll(basicMM2Config());\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        warmUpConsumer();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    @After\n+    public void shutdownClusters() throws Exception {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    \n+    @Test\n+    public void testReplication() throws Exception {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        waitForConsumingAllRecords(primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\"), 0);\n+        waitForConsumingAllRecords(backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\"), 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        try (Consumer<byte[], byte[]> primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName))) {\n+            primaryConsumer.assign(backupOffsets.keySet());\n+            backupOffsets.forEach(primaryConsumer::seek);\n+            primaryConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+            primaryConsumer.commitAsync();\n+\n+            assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+                new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+                CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+        }\n+\n+        waitForCondition(() -> {\n+            return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName))) {\n+            backupConsumer.assign(primaryOffsets.keySet());\n+            primaryOffsets.forEach(backupConsumer::seek);\n+            backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+            backupConsumer.commitAsync();\n+        \n+            assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+                new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+                new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        }\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                PRIMARY_CLUSTER_ALIAS + \".\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(PRIMARY_CLUSTER_ALIAS + \".\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    private static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ff7de40fcd6d370354d032b00f6d9ea656d15e22"}, "originalPosition": 416}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg4NzI2MA==", "bodyText": "This intermediate List is not really useful. We could just change the loop below to iterate over the connector classes and call getSimpleName() on each of them", "url": "https://github.com/apache/kafka/pull/9224#discussion_r538887260", "createdAt": "2020-12-08T23:27:17Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,577 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final Duration CONSUMER_POLL_TIMEOUT_MS = Duration.ofMillis(500);\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    protected Map<String, String> mm2Props = new HashMap<>();\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    protected Map<String, String> primaryWorkerProps = new HashMap<>();\n+    protected Map<String, String> backupWorkerProps = new HashMap<>(); \n+    \n+    @Before\n+    public void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props.putAll(basicMM2Config());\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        warmUpConsumer();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    @After\n+    public void shutdownClusters() throws Exception {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    \n+    @Test\n+    public void testReplication() throws Exception {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        waitForConsumingAllRecords(primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\"), 0);\n+        waitForConsumingAllRecords(backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\"), 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        try (Consumer<byte[], byte[]> primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName))) {\n+            primaryConsumer.assign(backupOffsets.keySet());\n+            backupOffsets.forEach(primaryConsumer::seek);\n+            primaryConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+            primaryConsumer.commitAsync();\n+\n+            assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+                new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+                CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+        }\n+\n+        waitForCondition(() -> {\n+            return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName))) {\n+            backupConsumer.assign(primaryOffsets.keySet());\n+            primaryOffsets.forEach(backupConsumer::seek);\n+            backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+            backupConsumer.commitAsync();\n+        \n+            assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+                new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+                new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        }\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                PRIMARY_CLUSTER_ALIAS + \".\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(PRIMARY_CLUSTER_ALIAS + \".\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    private static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ff7de40fcd6d370354d032b00f6d9ea656d15e22"}, "originalPosition": 425}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg4NzkwOA==", "bodyText": "I'm assuming it's worth keeping this 2nd loop separate from the first one for performance reasons. At first glance it looks strange to iterate over the same collection twice in a row", "url": "https://github.com/apache/kafka/pull/9224#discussion_r538887908", "createdAt": "2020-12-08T23:28:54Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,577 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.ConfigEntry;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final Duration CONSUMER_POLL_TIMEOUT_MS = Duration.ofMillis(500);\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;\n+    protected static final String PRIMARY_CLUSTER_ALIAS = \"primary\";\n+    protected static final String BACKUP_CLUSTER_ALIAS = \"backup\";\n+    private static final List<Class<? extends Connector>> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+\n+    protected Map<String, String> mm2Props = new HashMap<>();\n+    private MirrorMakerConfig mm2Config; \n+    private EmbeddedConnectCluster primary;\n+    private EmbeddedConnectCluster backup;\n+    \n+    private final AtomicBoolean exited = new AtomicBoolean(false);\n+    protected Properties primaryBrokerProps = new Properties();\n+    protected Properties backupBrokerProps = new Properties();\n+    protected Map<String, String> primaryWorkerProps = new HashMap<>();\n+    protected Map<String, String> backupWorkerProps = new HashMap<>(); \n+    \n+    @Before\n+    public void startClusters() throws InterruptedException {\n+        primaryBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        backupBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+        \n+        mm2Props.putAll(basicMM2Config());\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props); \n+        primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS));\n+        backupWorkerProps.putAll(mm2Config.workerConfig(new SourceAndTarget(PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS)));\n+        \n+        primary = new EmbeddedConnectCluster.Builder()\n+                .name(PRIMARY_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .brokerProps(primaryBrokerProps)\n+                .workerProps(primaryWorkerProps)\n+                .build();\n+\n+        backup = new EmbeddedConnectCluster.Builder()\n+                .name(BACKUP_CLUSTER_ALIAS + \"-connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .brokerProps(backupBrokerProps)\n+                .workerProps(backupWorkerProps)\n+                .build();\n+        \n+        primary.start();\n+        primary.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n+                \"Workers of \" + PRIMARY_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+        \n+        backup.start();\n+        backup.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n+                \"Workers of \" + BACKUP_CLUSTER_ALIAS + \"-connect-cluster did not start in time.\");\n+\n+        createTopics();\n+ \n+        warmUpConsumer();\n+        \n+        log.info(PRIMARY_CLUSTER_ALIAS + \" REST service: {}\", primary.endpointForResource(\"connectors\"));\n+        log.info(BACKUP_CLUSTER_ALIAS + \" REST service: {}\", backup.endpointForResource(\"connectors\"));\n+        log.info(PRIMARY_CLUSTER_ALIAS + \" brokers: {}\", primary.kafka().bootstrapServers());\n+        log.info(BACKUP_CLUSTER_ALIAS + \" brokers: {}\", backup.kafka().bootstrapServers());\n+        \n+        // now that the brokers are running, we can finish setting up the Connectors\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \".bootstrap.servers\", primary.kafka().bootstrapServers());\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \".bootstrap.servers\", backup.kafka().bootstrapServers());\n+        \n+        Exit.setExitProcedure((status, errorCode) -> exited.set(true));\n+    }\n+    \n+    @After\n+    public void shutdownClusters() throws Exception {\n+        for (String x : primary.connectors()) {\n+            primary.deleteConnector(x);\n+        }\n+        for (String x : backup.connectors()) {\n+            backup.deleteConnector(x);\n+        }\n+        deleteAllTopics(primary.kafka());\n+        deleteAllTopics(backup.kafka());\n+        primary.stop();\n+        backup.stop();\n+        try {\n+            assertFalse(exited.get());\n+        } finally {\n+            Exit.resetExitProcedure();\n+        }\n+    }\n+    \n+    @Test\n+    public void testReplication() throws Exception {\n+        produceMessages(primary, \"test-topic-1\");\n+        produceMessages(backup, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testReplication\";\n+        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"latest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        waitForConsumingAllRecords(primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\"), 0);\n+        waitForConsumingAllRecords(backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\"), 0);\n+        \n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        waitUntilMirrorMakerIsRunning(primary, CONNECTOR_LIST, mm2Config, BACKUP_CLUSTER_ALIAS, PRIMARY_CLUSTER_ALIAS); \n+\n+        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(PRIMARY_CLUSTER_ALIAS));\n+        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(BACKUP_CLUSTER_ALIAS));\n+        \n+        assertEquals(\"topic config was not synced\", TopicConfig.CLEANUP_POLICY_COMPACT, \n+                getTopicConfig(backup.kafka(), \"primary.test-topic-1\", TopicConfig.CLEANUP_POLICY_CONFIG));\n+        \n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        \n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n+        \n+        assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\", backup.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n+        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\", primary.kafka().consume(1,\n+            RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n+        \n+        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(PRIMARY_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(PRIMARY_CLUSTER_ALIAS));\n+        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(BACKUP_CLUSTER_ALIAS));\n+        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(BACKUP_CLUSTER_ALIAS));\n+        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\", backup.kafka().consume(1,\n+            CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n+\n+        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, PRIMARY_CLUSTER_ALIAS,\n+            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+\n+        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n+            new TopicPartition(\"primary.test-topic-1\", 0)));\n+\n+        // Failover consumer group to backup cluster.\n+        try (Consumer<byte[], byte[]> primaryConsumer = backup.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName))) {\n+            primaryConsumer.assign(backupOffsets.keySet());\n+            backupOffsets.forEach(primaryConsumer::seek);\n+            primaryConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+            primaryConsumer.commitAsync();\n+\n+            assertTrue(\"Consumer failedover to zero offset.\", primaryConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedover beyond expected offset.\", primaryConsumer.position(\n+                new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n+                CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n+        }\n+\n+        waitForCondition(() -> {\n+            return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n+\n+        waitForCondition(() -> {\n+            return primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n+        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n+\n+        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, BACKUP_CLUSTER_ALIAS,\n+                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n+ \n+        // Failback consumer group to primary cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = primary.kafka().createConsumer(Collections.singletonMap(\"group.id\", consumerGroupName))) {\n+            backupConsumer.assign(primaryOffsets.keySet());\n+            primaryOffsets.forEach(backupConsumer::seek);\n+            backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+            backupConsumer.commitAsync();\n+        \n+            assertTrue(\"Consumer failedback to zero upstream offset.\", backupConsumer.position(new TopicPartition(\"test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedback to zero downstream offset.\", backupConsumer.position(new TopicPartition(\"backup.test-topic-1\", 0)) > 0);\n+            assertTrue(\"Consumer failedback beyond expected upstream offset.\", backupConsumer.position(\n+                new TopicPartition(\"test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+            assertTrue(\"Consumer failedback beyond expected downstream offset.\", backupConsumer.position(\n+                new TopicPartition(\"backup.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n+        }\n+      \n+        // create more matching topics\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"test-topic-3\", NUM_PARTITIONS);\n+\n+        // only produce messages to the first partition\n+        produceMessages(primary, \"test-topic-2\", 1);\n+        produceMessages(backup, \"test-topic-3\", 1);\n+        \n+        // expect total consumed messages equals to NUM_RECORDS_PER_PARTITION\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-2\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, RECORD_TRANSFER_DURATION_MS, \"test-topic-3\").count());\n+\n+        assertEquals(\"New topic was not replicated to primary cluster.\", NUM_RECORDS_PER_PARTITION,\n+            primary.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-3\").count());\n+        assertEquals(\"New topic was not replicated to backup cluster.\", NUM_RECORDS_PER_PARTITION,\n+            backup.kafka().consume(NUM_RECORDS_PER_PARTITION, 2 * RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-2\").count());\n+\n+    }\n+    \n+    @Test\n+    public void testReplicationWithEmptyPartition() throws Exception {\n+        String consumerGroupName = \"consumer-group-testReplicationWithEmptyPartition\";\n+        Map<String, Object> consumerProps  = Collections.singletonMap(\"group.id\", consumerGroupName);\n+\n+        // create topic\n+        String topic = \"test-topic-with-empty-partition\";\n+        primary.kafka().createTopic(topic, NUM_PARTITIONS);\n+\n+        // produce to all test-topic-empty's partitions, except the last partition\n+        produceMessages(primary, topic, NUM_PARTITIONS - 1);\n+        \n+        // consume before starting the connectors so we don't need to wait for discovery\n+        int expectedRecords = NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1);\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic)) {\n+            waitForConsumingAllRecords(primaryConsumer, expectedRecords);\n+        }\n+        \n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+        \n+        // sleep few seconds to have MM2 finish replication so that \"end\" consumer will consume some record\n+        Thread.sleep(TimeUnit.SECONDS.toMillis(3));\n+\n+        // consume all records from backup cluster\n+        try (Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                PRIMARY_CLUSTER_ALIAS + \".\" + topic)) {\n+            waitForConsumingAllRecords(backupConsumer, expectedRecords);\n+        }\n+        \n+        Admin backupClient = backup.kafka().createAdminClient();\n+        // retrieve the consumer group offset from backup cluster\n+        Map<TopicPartition, OffsetAndMetadata> remoteOffsets =\n+                backupClient.listConsumerGroupOffsets(consumerGroupName).partitionsToOffsetAndMetadata().get();\n+        // pinpoint the offset of the last partition which does not receive records \n+        OffsetAndMetadata offset = remoteOffsets.get(new TopicPartition(PRIMARY_CLUSTER_ALIAS + \".\" + topic, NUM_PARTITIONS - 1));\n+        // offset of the last partition should exist, but its value should be 0\n+        assertNotNull(\"Offset of last partition was not replicated\", offset);\n+        assertEquals(\"Offset of last partition is not zero\", 0, offset.offset());\n+    }\n+    \n+    @Test\n+    public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedException {\n+        produceMessages(primary, \"test-topic-1\");\n+        String consumerGroupName = \"consumer-group-testOneWayReplicationWithAutoOffsetSync\";\n+        Map<String, Object> consumerProps  = new HashMap<String, Object>() {{\n+                put(\"group.id\", consumerGroupName);\n+                put(\"auto.offset.reset\", \"earliest\");\n+            }};\n+        // create consumers before starting the connectors so we don't need to wait for discovery\n+        try (Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \n+                \"test-topic-1\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(primaryConsumer, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // enable automated consumer group offset sync\n+        mm2Props.put(\"sync.group.offsets.enabled\", \"true\");\n+        mm2Props.put(\"sync.group.offsets.interval.seconds\", \"1\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume 1 topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(\n+            consumerProps, \"primary.test-topic-1\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Collections.singletonList(\"primary.test-topic-1\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+\n+        // the size of consumer record should be zero, because the offsets of the same consumer group\n+        // have been automatically synchronized from primary to backup by the background job, so no\n+        // more records to consume from the replicated topic by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+\n+        // now create a new topic in primary cluster\n+        primary.kafka().createTopic(\"test-topic-2\", NUM_PARTITIONS);\n+        backup.kafka().createTopic(\"primary.test-topic-2\", 1);\n+        // produce some records to the new topic in primary cluster\n+        produceMessages(primary, \"test-topic-2\");\n+\n+        // create a consumer at primary cluster to consume the new topic\n+        try (Consumer<byte[], byte[]> consumer1 = primary.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"group.id\", \"consumer-group-1\"), \"test-topic-2\")) {\n+            // we need to wait for consuming all the records for MM2 replicating the expected offsets\n+            waitForConsumingAllRecords(consumer1, NUM_RECORDS_PRODUCED);\n+        }\n+\n+        // create a consumer at backup cluster with same consumer group Id to consume old and new topic\n+        backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+            \"group.id\", consumerGroupName), \"primary.test-topic-1\", \"primary.test-topic-2\");\n+\n+        waitForConsumerGroupOffsetSync(backup, backupConsumer, Arrays.asList(\"primary.test-topic-1\", \"primary.test-topic-2\"), \n+            consumerGroupName, NUM_RECORDS_PRODUCED);\n+\n+        records = backupConsumer.poll(CONSUMER_POLL_TIMEOUT_MS);\n+        // similar reasoning as above, no more records to consume by the same consumer group at backup cluster\n+        assertEquals(\"consumer record size is not zero\", 0, records.count());\n+        backupConsumer.close();\n+    }\n+    \n+    /*\n+     * launch the connectors on kafka connect cluster and check if they are running\n+     */\n+    private static void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster, \n+            List<Class<? extends Connector>> connectorClasses, MirrorMakerConfig mm2Config, \n+            String primary, String backup) throws InterruptedException {\n+        for (int i = 0; i < connectorClasses.size(); i++) {\n+            String connector = connectorClasses.get(i).getSimpleName();\n+            connectCluster.configureConnector(connector, mm2Config.connectorBaseConfig(\n+                new SourceAndTarget(primary, backup), connectorClasses.get(i)));\n+        }\n+        \n+        // we wait for the connector and tasks to come up for each connector, so that when we do the\n+        // actual testing, we are certain that the tasks are up and running; this will prevent\n+        // flaky tests where the connector and tasks didn't start up in time for the tests to be run\n+        List<String> connectorNames = connectorClasses.stream().map(x -> x.getSimpleName())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg4NzI2MA=="}, "originalCommit": {"oid": "ff7de40fcd6d370354d032b00f6d9ea656d15e22"}, "originalPosition": 425}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg5MTczNw==", "bodyText": "This still needs to be addressed", "url": "https://github.com/apache/kafka/pull/9224#discussion_r538891737", "createdAt": "2020-12-08T23:37:48Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import org.junit.experimental.categories.Category;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.junit.Before;\n+import org.junit.After;\n+import org.junit.Test;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationSSLTest.class);\n+    \n+    private static final List<Class> CONNECTOR_LIST = \n+            Arrays.asList(MirrorSourceConnector.class, MirrorCheckpointConnector.class, MirrorHeartbeatConnector.class);\n+    \n+    @Before\n+    public void setup() throws InterruptedException {\n+        try {\n+            Map<String, Object> sslConfig = TestSslUtils.createSslConfig(false, true, Mode.SERVER, TestUtils.tempFile(), \"testCert\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.ListenersProp(), \"SSL://localhost:0\");\n+            backupBrokerProps.put(KafkaConfig$.MODULE$.InterBrokerListenerNameProp(), \"SSL\");\n+            backupBrokerProps.putAll(sslConfig);\n+        } catch (final Exception e) {\n+            throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExNDk5NQ=="}, "originalCommit": null, "originalPosition": 63}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ff7de40fcd6d370354d032b00f6d9ea656d15e22", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/ff7de40fcd6d370354d032b00f6d9ea656d15e22", "committedDate": "2020-12-04T06:26:01Z", "message": "refactor MM2 integration tests"}, "afterCommit": {"oid": "80019cf4bd61f08f452dc6032f3201dda884feda", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/80019cf4bd61f08f452dc6032f3201dda884feda", "committedDate": "2020-12-09T00:37:43Z", "message": "refactor MM2 integration tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "80019cf4bd61f08f452dc6032f3201dda884feda", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/80019cf4bd61f08f452dc6032f3201dda884feda", "committedDate": "2020-12-09T00:37:43Z", "message": "refactor MM2 integration tests"}, "afterCommit": {"oid": "a4af47b3f582ca86f9720057768e60f1632613a4", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/a4af47b3f582ca86f9720057768e60f1632613a4", "committedDate": "2020-12-09T01:27:52Z", "message": "refactor MM2 integration tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a4af47b3f582ca86f9720057768e60f1632613a4", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/a4af47b3f582ca86f9720057768e60f1632613a4", "committedDate": "2020-12-09T01:27:52Z", "message": "refactor MM2 integration tests"}, "afterCommit": {"oid": "cd77b18a39f39926291cf53ab595805b1dee2a56", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/cd77b18a39f39926291cf53ab595805b1dee2a56", "committedDate": "2020-12-09T01:36:21Z", "message": "refactor MM2 integration tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cd77b18a39f39926291cf53ab595805b1dee2a56", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/cd77b18a39f39926291cf53ab595805b1dee2a56", "committedDate": "2020-12-09T01:36:21Z", "message": "refactor MM2 integration tests"}, "afterCommit": {"oid": "7b8957abcd82571fd7677f3abedf2ffc2ff0075d", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/7b8957abcd82571fd7677f3abedf2ffc2ff0075d", "committedDate": "2020-12-09T23:24:19Z", "message": "refactor MM2 integration tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5MjY4MzQy", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-549268342", "createdAt": "2020-12-10T14:46:30Z", "commit": {"oid": "7b8957abcd82571fd7677f3abedf2ffc2ff0075d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNDo0NjozMVrOIDMzVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNDo1MTozMFrOIDNDcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNjM4OQ==", "bodyText": "We don't need this field, this could be a local in startClusters()", "url": "https://github.com/apache/kafka/pull/9224#discussion_r540226389", "createdAt": "2020-12-10T14:46:31Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationSSLTest.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.stream.Collectors;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.config.types.Password;\n+import org.apache.kafka.common.network.Mode;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestSslUtils;\n+import org.apache.kafka.test.TestUtils;\n+import kafka.server.KafkaConfig$;\n+\n+import org.junit.experimental.categories.Category;\n+import org.junit.Before;\n+\n+/**\n+ * Tests MM2 replication with SSL enabled at backup kafka cluster\n+ */\n+@Category(IntegrationTest.class)\n+public class MirrorConnectorsIntegrationSSLTest extends MirrorConnectorsIntegrationBaseTest {\n+    \n+    private static Map<String, Object> sslConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b8957abcd82571fd7677f3abedf2ffc2ff0075d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNjYxMQ==", "bodyText": "This field is unused", "url": "https://github.com/apache/kafka/pull/9224#discussion_r540226611", "createdAt": "2020-12-10T14:46:51Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java", "diffHunk": "@@ -0,0 +1,599 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.mirror.integration;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.admin.Config;\n+import org.apache.kafka.clients.admin.DescribeConfigsResult;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.apache.kafka.common.utils.Exit;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.connect.connector.Connector;\n+import org.apache.kafka.connect.mirror.MirrorClient;\n+import org.apache.kafka.connect.mirror.MirrorHeartbeatConnector;\n+import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n+import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n+import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n+import org.apache.kafka.connect.util.clusters.UngracefulShutdownException;\n+import org.apache.kafka.test.IntegrationTest;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertNotNull;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import static org.apache.kafka.connect.mirror.TestUtils.generateRecords;\n+\n+/**\n+ * Tests MM2 replication and failover/failback logic.\n+ *\n+ * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n+ * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n+ * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n+ * between clusters during this failover and failback.\n+ */\n+@Category(IntegrationTest.class)\n+public abstract class MirrorConnectorsIntegrationBaseTest {\n+    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationBaseTest.class);\n+    \n+    private static final int NUM_RECORDS_PER_PARTITION = 10;\n+    private static final int NUM_PARTITIONS = 10;\n+    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n+    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n+    private static final int CHECKPOINT_DURATION_MS = 20_000;\n+    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n+    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n+    private static final int NUM_WORKERS = 3;\n+    private static final Duration CONSUMER_POLL_TIMEOUT_MS = Duration.ofMillis(500);\n+    private static final int BROKER_RESTART_TIMEOUT_MS = 10_000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b8957abcd82571fd7677f3abedf2ffc2ff0075d"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzMDUxNA==", "bodyText": "It looks like we lost these lines and maybe some others too. These came from #9698. Can you make sure we don't miss any existing logic?", "url": "https://github.com/apache/kafka/pull/9224#discussion_r540230514", "createdAt": "2020-12-10T14:51:30Z", "author": {"login": "mimaison"}, "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -1,595 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License. You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.kafka.connect.mirror;\n-\n-import org.apache.kafka.clients.admin.Admin;\n-import org.apache.kafka.clients.consumer.Consumer;\n-import org.apache.kafka.clients.consumer.ConsumerRecord;\n-import org.apache.kafka.clients.consumer.ConsumerRecords;\n-import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n-import org.apache.kafka.common.TopicPartition;\n-import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n-import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n-import org.apache.kafka.connect.util.clusters.UngracefulShutdownException;\n-import org.apache.kafka.test.IntegrationTest;\n-import org.apache.kafka.common.utils.Exit;\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.TimeoutException;\n-import java.util.stream.Collectors;\n-import java.util.stream.IntStream;\n-\n-import static org.apache.kafka.test.TestUtils.waitForCondition;\n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.assertNotNull;\n-import static org.junit.Assert.assertTrue;\n-\n-/**\n- * Tests MM2 replication and failover/failback logic.\n- *\n- * MM2 is configured with active/active replication between two Kafka clusters. Tests validate that\n- * records sent to either cluster arrive at the other cluster. Then, a consumer group is migrated from\n- * one cluster to the other and back. Tests validate that consumer offsets are translated and replicated\n- * between clusters during this failover and failback.\n- */\n-@Category(IntegrationTest.class)\n-public class MirrorConnectorsIntegrationTest {\n-\n-    private static final Logger log = LoggerFactory.getLogger(MirrorConnectorsIntegrationTest.class);\n-\n-    private static final int NUM_RECORDS_PER_PARTITION = 10;\n-    private static final int NUM_PARTITIONS = 10;\n-    private static final int NUM_RECORDS_PRODUCED = NUM_PARTITIONS * NUM_RECORDS_PER_PARTITION;\n-    private static final int RECORD_TRANSFER_DURATION_MS = 30_000;\n-    private static final int CHECKPOINT_DURATION_MS = 20_000;\n-    private static final int RECORD_CONSUME_DURATION_MS = 20_000;\n-    private static final int OFFSET_SYNC_DURATION_MS = 30_000;\n-\n-    private volatile boolean shuttingDown;\n-    private Map<String, String> mm2Props;\n-    private MirrorMakerConfig mm2Config;\n-    private EmbeddedConnectCluster primary;\n-    private EmbeddedConnectCluster backup;\n-\n-    private Exit.Procedure exitProcedure;\n-    private Exit.Procedure haltProcedure;\n-\n-    @Before\n-    public void setup() throws InterruptedException {\n-        shuttingDown = false;\n-        exitProcedure = (code, message) -> {\n-            if (shuttingDown) {\n-                // ignore this since we're shutting down Connect and Kafka and timing isn't always great\n-                return;\n-            }\n-            if (code != 0) {\n-                String exitMessage = \"Abrupt service exit with code \" + code + \" and message \" + message;\n-                log.warn(exitMessage);\n-                throw new UngracefulShutdownException(exitMessage);\n-            }\n-        };\n-        haltProcedure = (code, message) -> {\n-            if (shuttingDown) {\n-                // ignore this since we're shutting down Connect and Kafka and timing isn't always great\n-                return;\n-            }\n-            if (code != 0) {\n-                String haltMessage = \"Abrupt service halt with code \" + code + \" and message \" + message;\n-                log.warn(haltMessage);\n-                throw new UngracefulShutdownException(haltMessage);\n-            }\n-        };\n-        // Override the exit and halt procedure that Connect and Kafka will use. For these integration tests,\n-        // we don't want to exit the JVM and instead simply want to fail the test\n-        Exit.setExitProcedure(exitProcedure);\n-        Exit.setHaltProcedure(haltProcedure);\n-\n-        Properties brokerProps = new Properties();\n-        brokerProps.put(\"auto.create.topics.enable\", \"false\");\n-\n-        mm2Props = new HashMap<>();\n-        mm2Props.put(\"clusters\", \"primary, backup\");\n-        mm2Props.put(\"max.tasks\", \"10\");\n-        mm2Props.put(\"topics\", \"test-topic-.*, primary.test-topic-.*, backup.test-topic-.*\");\n-        mm2Props.put(\"groups\", \"consumer-group-.*\");\n-        mm2Props.put(\"primary->backup.enabled\", \"true\");\n-        mm2Props.put(\"backup->primary.enabled\", \"true\");\n-        mm2Props.put(\"sync.topic.acls.enabled\", \"false\");\n-        mm2Props.put(\"emit.checkpoints.interval.seconds\", \"1\");\n-        mm2Props.put(\"emit.heartbeats.interval.seconds\", \"1\");\n-        mm2Props.put(\"refresh.topics.interval.seconds\", \"1\");\n-        mm2Props.put(\"refresh.groups.interval.seconds\", \"1\");\n-        mm2Props.put(\"checkpoints.topic.replication.factor\", \"1\");\n-        mm2Props.put(\"heartbeats.topic.replication.factor\", \"1\");\n-        mm2Props.put(\"offset-syncs.topic.replication.factor\", \"1\");\n-        mm2Props.put(\"config.storage.replication.factor\", \"1\");\n-        mm2Props.put(\"offset.storage.replication.factor\", \"1\");\n-        mm2Props.put(\"status.storage.replication.factor\", \"1\");\n-        mm2Props.put(\"replication.factor\", \"1\");\n-        \n-        mm2Config = new MirrorMakerConfig(mm2Props); \n-        Map<String, String> primaryWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"backup\", \"primary\"));\n-        Map<String, String> backupWorkerProps = mm2Config.workerConfig(new SourceAndTarget(\"primary\", \"backup\"));\n-\n-        primary = new EmbeddedConnectCluster.Builder()\n-                .name(\"primary-connect-cluster\")\n-                .numWorkers(3)\n-                .numBrokers(1)\n-                .brokerProps(brokerProps)\n-                .workerProps(primaryWorkerProps)\n-                .maskExitProcedures(false)\n-                .build();\n-\n-        backup = new EmbeddedConnectCluster.Builder()\n-                .name(\"backup-connect-cluster\")\n-                .numWorkers(3)\n-                .numBrokers(1)\n-                .brokerProps(brokerProps)\n-                .workerProps(backupWorkerProps)\n-                .maskExitProcedures(false)\n-                .build();\n-\n-        primary.start();\n-        primary.assertions().assertAtLeastNumWorkersAreUp(3,\n-                \"Workers of primary-connect-cluster did not start in time.\");\n-        backup.start();\n-        backup.assertions().assertAtLeastNumWorkersAreUp(3,\n-                \"Workers of backup-connect-cluster did not start in time.\");\n-\n-        // create these topics before starting the connectors so we don't need to wait for discovery\n-        primary.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS);\n-        primary.kafka().createTopic(\"backup.test-topic-1\", 1);\n-        primary.kafka().createTopic(\"heartbeats\", 1);\n-        backup.kafka().createTopic(\"test-topic-1\", NUM_PARTITIONS);\n-        backup.kafka().createTopic(\"primary.test-topic-1\", 1);\n-        backup.kafka().createTopic(\"heartbeats\", 1);\n-\n-        // produce to all partitions of test-topic-1\n-        produceMessages(primary, \"test-topic-1\", \"message-1-\");\n-        produceMessages(backup, \"test-topic-1\", \"message-2-\");\n-\n-        // Generate some consumer activity on both clusters to ensure the checkpoint connector always starts promptly\n-        Map<String, Object> dummyProps = Collections.singletonMap(\"group.id\", \"consumer-group-dummy\");\n-        Consumer<byte[], byte[]> dummyConsumer = primary.kafka().createConsumerAndSubscribeTo(dummyProps, \"test-topic-1\");\n-        consumeAllMessages(dummyConsumer);\n-        dummyConsumer.close();\n-        dummyConsumer = backup.kafka().createConsumerAndSubscribeTo(dummyProps, \"test-topic-1\");\n-        consumeAllMessages(dummyConsumer);\n-        dummyConsumer.close();\n-\n-        log.info(\"primary REST service: {}\", primary.endpointForResource(\"connectors\"));\n-        log.info(\"backup REST service: {}\", backup.endpointForResource(\"connectors\"));\n- \n-        log.info(\"primary brokers: {}\", primary.kafka().bootstrapServers());\n-        log.info(\"backup brokers: {}\", backup.kafka().bootstrapServers());\n-        \n-        // now that the brokers are running, we can finish setting up the Connectors\n-        mm2Props.put(\"primary.bootstrap.servers\", primary.kafka().bootstrapServers());\n-        mm2Props.put(\"backup.bootstrap.servers\", backup.kafka().bootstrapServers());\n-        mm2Config = new MirrorMakerConfig(mm2Props);\n-    }\n-\n-\n-    private void waitUntilMirrorMakerIsRunning(EmbeddedConnectCluster connectCluster,\n-        MirrorMakerConfig mm2Config, String primary, String backup) throws InterruptedException {\n-\n-        connectCluster.configureConnector(\"MirrorSourceConnector\",\n-                mm2Config.connectorBaseConfig(new SourceAndTarget(primary, backup), MirrorSourceConnector.class));\n-        connectCluster.configureConnector(\"MirrorCheckpointConnector\",\n-                mm2Config.connectorBaseConfig(new SourceAndTarget(primary, backup), MirrorCheckpointConnector.class));\n-        connectCluster.configureConnector(\"MirrorHeartbeatConnector\",\n-                mm2Config.connectorBaseConfig(new SourceAndTarget(primary, backup), MirrorHeartbeatConnector.class));\n-\n-        // we wait for the connector and tasks to come up for each connector, so that when we do the\n-        // actual testing, we are certain that the tasks are up and running; this will prevent\n-        // flaky tests where the connector and tasks didn't start up in time for the tests to be\n-        // run\n-        Set<String> connectorNames = new HashSet<>(Arrays.asList(\"MirrorSourceConnector\",\n-                                                                 \"MirrorCheckpointConnector\", \"MirrorHeartbeatConnector\"));\n-\n-        for (String connector : connectorNames) {\n-            connectCluster.assertions().assertConnectorAndAtLeastNumTasksAreRunning(connector, 1,\n-                    \"Connector \" + connector + \" tasks did not start in time on cluster: \" + connectCluster);\n-        }\n-    }\n-\n-    @After\n-    public void close() {\n-        try {\n-            for (String x : primary.connectors()) {\n-                primary.deleteConnector(x);\n-            }\n-            for (String x : backup.connectors()) {\n-                backup.deleteConnector(x);\n-            }\n-            deleteAllTopics(primary.kafka());\n-            deleteAllTopics(backup.kafka());\n-        } finally {\n-            shuttingDown = true;\n-            try {\n-                try {\n-                    primary.stop();\n-                } finally {\n-                    backup.stop();\n-                }\n-            } finally {\n-                Exit.resetExitProcedure();\n-                Exit.resetHaltProcedure();\n-            }\n-        }\n-    }\n-\n-    @Test\n-    public void testReplication() throws InterruptedException {\n-        String consumerGroupName = \"consumer-group-testReplication\";\n-        Map<String, Object> consumerProps = new HashMap<String, Object>() {{\n-                put(\"group.id\", consumerGroupName);\n-                put(\"auto.offset.reset\", \"latest\");\n-            }};\n-\n-        // create consumers before starting the connectors so we don't need to wait for discovery\n-        Consumer<byte[], byte[]> primaryConsumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n-        consumeAllMessages(primaryConsumer, 0);\n-        primaryConsumer.close();\n-\n-        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(consumerProps, \"test-topic-1\");\n-        consumeAllMessages(backupConsumer, 0);\n-        backupConsumer.close();\n-\n-        waitUntilMirrorMakerIsRunning(backup, mm2Config, \"primary\", \"backup\");\n-        waitUntilMirrorMakerIsRunning(primary, mm2Config, \"backup\", \"primary\");\n-        MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(\"primary\"));\n-        MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(\"backup\"));\n-\n-        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n-            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n-        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n-            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n-        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n-            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n-        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n-            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n-\n-        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n-            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n-        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n-            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n-\n-        assertTrue(\"Heartbeats were not emitted to primary cluster.\",\n-            primary.kafka().consume(1, RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n-        assertTrue(\"Heartbeats were not emitted to backup cluster.\",\n-            backup.kafka().consume(1, RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n-        assertTrue(\"Heartbeats were not replicated downstream to backup cluster.\",\n-            backup.kafka().consume(1, RECORD_TRANSFER_DURATION_MS, \"primary.heartbeats\").count() > 0);\n-        assertTrue(\"Heartbeats were not replicated downstream to primary cluster.\",\n-            primary.kafka().consume(1, RECORD_TRANSFER_DURATION_MS, \"backup.heartbeats\").count() > 0);\n-\n-        assertTrue(\"Did not find upstream primary cluster.\", backupClient.upstreamClusters().contains(\"primary\"));\n-        assertEquals(\"Did not calculate replication hops correctly.\", 1, backupClient.replicationHops(\"primary\"));\n-        assertTrue(\"Did not find upstream backup cluster.\", primaryClient.upstreamClusters().contains(\"backup\"));\n-        assertEquals(\"Did not calculate replication hops correctly.\", 1, primaryClient.replicationHops(\"backup\"));\n-\n-        assertTrue(\"Checkpoints were not emitted downstream to backup cluster.\",\n-            backup.kafka().consume(1, CHECKPOINT_DURATION_MS, \"primary.checkpoints.internal\").count() > 0);\n-\n-        Map<TopicPartition, OffsetAndMetadata> backupOffsets = backupClient.remoteConsumerOffsets(consumerGroupName, \"primary\",\n-            Duration.ofMillis(CHECKPOINT_DURATION_MS));\n-\n-        assertTrue(\"Offsets not translated downstream to backup cluster. Found: \" + backupOffsets, backupOffsets.containsKey(\n-            new TopicPartition(\"primary.test-topic-1\", 0)));\n-\n-        // Failover consumer group to backup cluster.\n-        backupConsumer = backup.kafka().createConsumer(consumerProps);\n-        backupConsumer.assign(allPartitions(\"test-topic-1\", \"primary.test-topic-1\"));\n-        seek(backupConsumer, backupOffsets);\n-        consumeAllMessages(backupConsumer, 0);\n-\n-        assertTrue(\"Consumer failedover to zero offset.\", backupConsumer.position(new TopicPartition(\"primary.test-topic-1\", 0)) > 0);\n-        assertTrue(\"Consumer failedover beyond expected offset.\", backupConsumer.position(\n-            new TopicPartition(\"primary.test-topic-1\", 0)) <= NUM_RECORDS_PRODUCED);\n-        assertTrue(\"Checkpoints were not emitted upstream to primary cluster.\", primary.kafka().consume(1,\n-            CHECKPOINT_DURATION_MS, \"backup.checkpoints.internal\").count() > 0);\n-\n-        backupConsumer.close();\n-\n-        waitForCondition(() -> {\n-            try {\n-                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n-                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"backup.test-topic-1\", 0));\n-            } catch (Throwable e) {\n-                return false;\n-            }\n-        }, CHECKPOINT_DURATION_MS, \"Offsets not translated downstream to primary cluster.\");\n-\n-        waitForCondition(() -> {\n-            try {\n-                return primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n-                    Duration.ofMillis(CHECKPOINT_DURATION_MS)).containsKey(new TopicPartition(\"test-topic-1\", 0));\n-            } catch (Throwable e) {\n-                return false;\n-            }\n-        }, CHECKPOINT_DURATION_MS, \"Offsets not translated upstream to primary cluster.\");\n-\n-        Map<TopicPartition, OffsetAndMetadata> primaryOffsets = primaryClient.remoteConsumerOffsets(consumerGroupName, \"backup\",\n-                Duration.ofMillis(CHECKPOINT_DURATION_MS));\n-\n-        primaryClient.close();\n-        backupClient.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b8957abcd82571fd7677f3abedf2ffc2ff0075d"}, "originalPosition": 346}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f57a8c9a494e10811068be1d4f26bbb6816292ee", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/f57a8c9a494e10811068be1d4f26bbb6816292ee", "committedDate": "2020-12-10T15:19:32Z", "message": "refactor MM2 integration tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7b8957abcd82571fd7677f3abedf2ffc2ff0075d", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/7b8957abcd82571fd7677f3abedf2ffc2ff0075d", "committedDate": "2020-12-09T23:24:19Z", "message": "refactor MM2 integration tests"}, "afterCommit": {"oid": "f57a8c9a494e10811068be1d4f26bbb6816292ee", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/f57a8c9a494e10811068be1d4f26bbb6816292ee", "committedDate": "2020-12-10T15:19:32Z", "message": "refactor MM2 integration tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4MzAwOTYx", "url": "https://github.com/apache/kafka/pull/9224#pullrequestreview-568300961", "createdAt": "2021-01-14T14:45:24Z", "commit": {"oid": "f57a8c9a494e10811068be1d4f26bbb6816292ee"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 832, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}