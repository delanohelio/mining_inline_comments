{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkwNjE5NTI4", "number": 8313, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQxOTo1ODo1MFrODpQjdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQxOTo1ODo1MFrODpQjdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0NTg5NDI5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsProducer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQxOTo1ODo1MFrOF4Uw2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQyMDowMDozN1rOF4U0Yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYwNDc2MA==", "bodyText": "I'm not sure this will actually log as it looks like because debug log could reserve one slot for error. Could we have a unit test to check the log appender capturing result?", "url": "https://github.com/apache/kafka/pull/8313#discussion_r394604760", "createdAt": "2020-03-18T19:58:50Z", "author": {"login": "abbccdda"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsProducer.java", "diffHunk": "@@ -193,15 +193,16 @@ public void abortTransaction() throws ProducerFencedException {\n         if (transactionInFlight) {\n             try {\n                 producer.abortTransaction();\n-            } catch (final ProducerFencedException ignore) {\n-                /* TODO\n-                 * this should actually never happen atm as we guard the call to #abortTransaction\n-                 * -> the reason for the guard is a \"bug\" in the Producer -- it throws IllegalStateException\n-                 * instead of ProducerFencedException atm. We can remove the isZombie flag after KAFKA-5604 got\n-                 * fixed and fall-back to this catch-and-swallow code\n-                 */\n-\n-                // can be ignored: transaction got already aborted by brokers/transactional-coordinator if this happens\n+            } catch (final ProducerFencedException error) {\n+                // The producer is aborting the txn when there's still an ongoing one,\n+                // which means that we did not commit the task while closing it, which\n+                // means that it is a dirty close. Therefore it is possible that the dirty\n+                // close is due to an fenced exception already thrown previously, and hence\n+                // when calling abortTxn here the same exception would be thrown again.\n+                // Even if the dirty close was not due to an observed fencing exception but\n+                // something else (e.g. task corrupted) we can still ignore the exception here\n+                // since transaction already got aborted by brokers/transactional-coordinator if this happens\n+                log.debug(\"Encountered {} while aborting the transaction; this is expected and hence swallowed\", error.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97360bcd8e16c08b2af54ffc2e6e7c8e69273f9d"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYwNTY2Ng==", "bodyText": "In log4j, if there's one more parameter than the {} in string which is an exception, it would log the exception trace.\nHere we do not want the trace to be logged and hence we just log the message as {}.", "url": "https://github.com/apache/kafka/pull/8313#discussion_r394605666", "createdAt": "2020-03-18T20:00:37Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsProducer.java", "diffHunk": "@@ -193,15 +193,16 @@ public void abortTransaction() throws ProducerFencedException {\n         if (transactionInFlight) {\n             try {\n                 producer.abortTransaction();\n-            } catch (final ProducerFencedException ignore) {\n-                /* TODO\n-                 * this should actually never happen atm as we guard the call to #abortTransaction\n-                 * -> the reason for the guard is a \"bug\" in the Producer -- it throws IllegalStateException\n-                 * instead of ProducerFencedException atm. We can remove the isZombie flag after KAFKA-5604 got\n-                 * fixed and fall-back to this catch-and-swallow code\n-                 */\n-\n-                // can be ignored: transaction got already aborted by brokers/transactional-coordinator if this happens\n+            } catch (final ProducerFencedException error) {\n+                // The producer is aborting the txn when there's still an ongoing one,\n+                // which means that we did not commit the task while closing it, which\n+                // means that it is a dirty close. Therefore it is possible that the dirty\n+                // close is due to an fenced exception already thrown previously, and hence\n+                // when calling abortTxn here the same exception would be thrown again.\n+                // Even if the dirty close was not due to an observed fencing exception but\n+                // something else (e.g. task corrupted) we can still ignore the exception here\n+                // since transaction already got aborted by brokers/transactional-coordinator if this happens\n+                log.debug(\"Encountered {} while aborting the transaction; this is expected and hence swallowed\", error.getMessage());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYwNDc2MA=="}, "originalCommit": {"oid": "97360bcd8e16c08b2af54ffc2e6e7c8e69273f9d"}, "originalPosition": 22}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3360, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}