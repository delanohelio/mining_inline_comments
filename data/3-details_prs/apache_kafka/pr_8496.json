{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA0MTAxODQ0", "number": 8496, "title": "KAFKA-9748: Add Streams eos-beta integration test", "bodyText": "Call for review @abbccdda @guozhangwang", "createdAt": "2020-04-16T03:52:52Z", "url": "https://github.com/apache/kafka/pull/8496", "merged": true, "mergeCommit": {"oid": "1daa8f638bfc8034d8499525d569660a050194f8"}, "closed": true, "closedAt": "2020-05-05T05:45:54Z", "author": {"login": "mjsax"}, "timelineItems": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcYP45LgFqTM5NDgwNjQyOQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcdIuj5gBqjMyOTQ1NTIwNjA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0ODA2NDI5", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-394806429", "createdAt": "2020-04-16T16:33:11Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjozMzoxMVrOGGtrtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjo1NzowMFrOGGunRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY5MzEwOQ==", "bodyText": "nit: we could define this transition list in a variable to be reused.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409693109", "createdAt": "2020-04-16T16:33:11Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY5MzU2Mw==", "bodyText": "What about having separate wait condition, or at least have a way to detect which instance gets stuck?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409693563", "createdAt": "2020-04-16T16:33:54Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 202}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY5NjQxOA==", "bodyText": "Could we define 10 as a constant COMMIT_MARKER value, so that people understand that it has a special meaning to indicate a commit request?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409696418", "createdAt": "2020-04-16T16:38:21Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+\n+            // phase 2:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT\n+            // p-1: 10 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade = prepareData(0L, 10L, 0L, 1L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY5Nzc3MA==", "bodyText": "Could we just use a boolean flag as parameter to determine whether to only read committed data?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409697770", "createdAt": "2020-04-16T16:40:22Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+\n+            // phase 2:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT\n+            // p-1: 10 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade = prepareData(0L, 10L, 0L, 1L);\n+\n+            final List<KeyValue<Long, Long>> allData = new ArrayList<>(committedInputDataBeforeUpgrade);\n+\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeUpgrade = readResult(committedInputDataBeforeUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeUpgrade, computeExpectedResult(committedInputDataBeforeUpgrade, new HashMap<>()));\n+\n+            // capture committed state for later\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneBeforeUpgrade =\n+                streams1Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateOne = new HashMap<>();\n+            final long keyFilterFirstUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeOneBeforeUpgrade.all()) {\n+                keyFilterFirstUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            final ReadOnlyKeyValueStore<Long, Long> storeTwoBeforeUpgrade =\n+                streams2Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateTwo = new HashMap<>();\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 3:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records (pending)\n+            stateTransitions2.clear();\n+            final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient2;\n+            if (injectError) {\n+                errorInjectedClient1.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeUpgrade = prepareData(10L, 15L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataBeforeUpgrade);\n+\n+            writeInputData(uncommittedInputDataBeforeUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 4:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            if (!injectError) {\n+                streams1Alpha.close();\n+            }\n+            waitForCondition(\n+                () -> stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not stabilize on time.\"\n+            );\n+            errorInjected = null;\n+\n+            final List<KeyValue<Long, Long>> allOutputDataAfterFirstUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataAfterFirstUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataAfterFirstUpgrade =\n+                    uncommittedInputDataBeforeUpgrade.stream().filter(pair -> pair.key == keyFilterFirstUpgrade).collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> committedOutputDataAfterFirstUpgrade = readResult(committedInputDataAfterFirstUpgrade.size(), CONSUMER_GROUP_ID);\n+                checkResultPerKey(committedOutputDataAfterFirstUpgrade, computeExpectedResult(committedInputDataAfterFirstUpgrade, currentStateOne));\n+            }\n+\n+            // phase 5:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records (+ maybe commit if tasks would have been switch; we don't care and don't verify)\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams1Beta.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+            // capture committed state for later\n+            final Map<Long, Long> currentStateAfterFirstUpgrade = new HashMap<>(currentStateTwo);\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneAfterUpgrade =\n+                streams1Beta.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterFirstUpgrade) {\n+                        currentStateAfterFirstUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterFirstUpgrade) {\n+                        currentStateAfterFirstUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+\n+            // phase 6:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records + (maybe COMMIT) + 5 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade = prepareData(15L, 20L, 0L, 1L);\n+            allData.addAll(committedInputDataDuringUpgrade);\n+\n+            writeInputData(committedInputDataDuringUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\");\n+\n+            final List<KeyValue<Long, Long>> allCommittedInputDataDuringUpgrade = new ArrayList<>();\n+            final Map<Long, Long> currentStateBeforeSecondUpgrade = new HashMap<>();\n+            if (!injectError) {\n+                allCommittedInputDataDuringUpgrade.addAll(\n+                    uncommittedInputDataBeforeUpgrade.stream().filter(pair -> pair.key != keyFilterFirstUpgrade).collect(Collectors.toList())\n+                );\n+                currentStateBeforeSecondUpgrade.putAll(currentStateAfterFirstUpgrade);\n+            } else {\n+                allCommittedInputDataDuringUpgrade.addAll(uncommittedInputDataBeforeUpgrade);\n+                currentStateBeforeSecondUpgrade.putAll(currentStateOne);\n+                currentStateBeforeSecondUpgrade.putAll(currentStateTwo);\n+            }\n+            allCommittedInputDataDuringUpgrade.addAll(committedInputDataDuringUpgrade);\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeSecondUpgrade = readResult(allCommittedInputDataDuringUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeSecondUpgrade, computeExpectedResult(allCommittedInputDataDuringUpgrade, currentStateBeforeSecondUpgrade));\n+\n+            // capture committed state for later\n+            currentStateOne.clear();\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            currentStateTwo.clear();\n+            final long keyFilterSecondUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                keyFilterSecondUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 7:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records (pending)\n+            stateTransitions1.clear();\n+            if (injectError) {\n+                errorInjectedClient2.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataDuringUpgrade = prepareData(20L, 25L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataDuringUpgrade);\n+\n+            writeInputData(uncommittedInputDataDuringUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeSecondUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeSecondUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 8:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records (pending)\n+            if (!injectError) {\n+                streams2Alpha.close();\n+            }\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                        KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                        KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not stabilize on time.\"\n+            );\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataAfterSecondUpgrade =\n+                    uncommittedInputDataDuringUpgrade.stream().filter(pair -> pair.key == keyFilterSecondUpgrade).collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> committedOutputDataAfterSecondUpgrade = readResult(committedInputDataAfterSecondUpgrade.size(), CONSUMER_GROUP_ID);\n+                checkResultPerKey(committedOutputDataAfterSecondUpgrade, computeExpectedResult(committedInputDataAfterSecondUpgrade, currentStateTwo));\n+            }\n+\n+            final List<KeyValue<Long, Long>> allOutputDataAfterSecondUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataAfterSecondUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 9:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (+ maybe commit if tasks would have been switch; we don't care and don't verify)\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams2Beta.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+            // capture committed state\n+            final Map<Long, Long> currentStateAfterSecondUpgrade = new HashMap<>(currentStateOne);\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterSecondUpgrade) {\n+                        currentStateAfterSecondUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+            final ReadOnlyKeyValueStore<Long, Long> storeTwoAfterUpgrade =\n+                streams2Beta.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            try (final KeyValueIterator<Long, Long> it = storeTwoAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterSecondUpgrade) {\n+                        currentStateAfterSecondUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+\n+            // phase 10:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT + 5 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataAfterUpgrade = prepareData(25L, 30L, 0L, 1L);\n+            allData.addAll(committedInputDataAfterUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allCommittedInputDataAfterUpgrade = new ArrayList<>();\n+            final Map<Long, Long> lastCommittedState;\n+            if (!injectError) {\n+                allCommittedInputDataAfterUpgrade.addAll(\n+                    uncommittedInputDataDuringUpgrade.stream().filter(pair -> pair.key != keyFilterSecondUpgrade).collect(Collectors.toList())\n+                );\n+                lastCommittedState = currentStateAfterSecondUpgrade;\n+            } else {\n+                allCommittedInputDataAfterUpgrade.addAll(uncommittedInputDataDuringUpgrade);\n+                lastCommittedState = currentStateBeforeSecondUpgrade;\n+            }\n+            allCommittedInputDataAfterUpgrade.addAll(committedInputDataAfterUpgrade);\n+\n+            writeInputData(committedInputDataAfterUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\");\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataAfterUpgrade = readResult(allCommittedInputDataAfterUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataAfterUpgrade, computeExpectedResult(allCommittedInputDataAfterUpgrade, lastCommittedState));\n+        }\n+    }\n+\n+    private KafkaStreams getKafkaStreams(final String appDir,\n+                                         final String processingGuarantee) {\n+        commitRequested = new AtomicInteger(0);\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final String[] storeNames = new String[] {storeName};\n+        final StoreBuilder<KeyValueStore<Long, Long>> storeBuilder = Stores\n+            .keyValueStoreBuilder(Stores.persistentKeyValueStore(storeName), Serdes.Long(), Serdes.Long())\n+            .withCachingEnabled();\n+\n+        builder.addStateStore(storeBuilder);\n+\n+        final KStream<Long, Long> input = builder.stream(MULTI_PARTITION_INPUT_TOPIC);\n+        input.transform(new TransformerSupplier<Long, Long, KeyValue<Long, Long>>() {\n+            @SuppressWarnings(\"unchecked\")\n+            @Override\n+            public Transformer<Long, Long, KeyValue<Long, Long>> get() {\n+                return new Transformer<Long, Long, KeyValue<Long, Long>>() {\n+                    ProcessorContext<Object, Object> context;\n+                    KeyValueStore<Long, Long> state = null;\n+                    AtomicBoolean crash;\n+\n+                    @Override\n+                    public void init(final ProcessorContext<Object, Object> context) {\n+                        this.context = context;\n+                        state = (KeyValueStore<Long, Long>) context.getStateStore(storeName);\n+                        crash = errorInjected;\n+                    }\n+\n+                    @Override\n+                    public KeyValue<Long, Long> transform(final Long key, final Long value) {\n+                        if ((value + 1) % 10 == 0) {\n+                            context.commit();\n+                            commitRequested.incrementAndGet();\n+                        }\n+\n+                        Long sum = state.get(key);\n+                        if (sum == null) {\n+                            sum = value;\n+                        } else {\n+                            sum += value;\n+                        }\n+                        state.put(key, sum);\n+                        state.flush();\n+\n+                        if (crash != null && crash.compareAndSet(true, false)) {\n+                            // only tries to fail once on one of the task\n+                            throw new RuntimeException(\"Injected test exception.\");\n+                        }\n+\n+                        return new KeyValue<>(key, state.get(key));\n+                    }\n+\n+                    @Override\n+                    public void close() { }\n+                };\n+            } }, storeNames)\n+            .to(MULTI_PARTITION_OUTPUT_TOPIC);\n+\n+        final Properties properties = new Properties();\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n+        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, Long.MAX_VALUE);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.METADATA_MAX_AGE_CONFIG), \"1000\");\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG), \"earliest\");\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG), 5 * 1000);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG), 5 * 1000 - 1);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG), MAX_POLL_INTERVAL_MS);\n+        properties.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        properties.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath() + File.separator + appDir);\n+\n+        final Properties config = StreamsTestUtils.getStreamsConfig(\n+            applicationId,\n+            CLUSTER.bootstrapServers(),\n+            Serdes.LongSerde.class.getName(),\n+            Serdes.LongSerde.class.getName(),\n+            properties\n+        );\n+\n+        final KafkaStreams streams = new KafkaStreams(builder.build(), config);\n+\n+        streams.setUncaughtExceptionHandler((t, e) -> {\n+            if (uncaughtException != null) {\n+                e.printStackTrace(System.err);\n+                fail(\"Should only get one uncaught exception from Streams.\");\n+            }\n+            uncaughtException = e;\n+        });\n+\n+        return streams;\n+    }\n+\n+    private List<KeyValue<Long, Long>> prepareData(final long fromInclusive,\n+                                                   final long toExclusive,\n+                                                   final Long... keys) {\n+        final List<KeyValue<Long, Long>> data = new ArrayList<>();\n+\n+        for (final Long k : keys) {\n+            for (long v = fromInclusive; v < toExclusive; ++v) {\n+                data.add(new KeyValue<>(k, v));\n+            }\n+        }\n+\n+        return data;\n+    }\n+\n+    private void writeInputData(final List<KeyValue<Long, Long>> records) throws Exception {\n+        IntegrationTestUtils.produceKeyValuesSynchronously(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            records,\n+            TestUtils.producerConfig(CLUSTER.bootstrapServers(), LongSerializer.class, LongSerializer.class),\n+            CLUSTER.time\n+        );\n+    }\n+\n+    private List<KeyValue<Long, Long>> readResult(final int numberOfRecords,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 626}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY5ODczOA==", "bodyText": "Could we pass a Collections.emptyMap() here instead?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409698738", "createdAt": "2020-04-16T16:41:53Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+\n+            // phase 2:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT\n+            // p-1: 10 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade = prepareData(0L, 10L, 0L, 1L);\n+\n+            final List<KeyValue<Long, Long>> allData = new ArrayList<>(committedInputDataBeforeUpgrade);\n+\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeUpgrade = readResult(committedInputDataBeforeUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeUpgrade, computeExpectedResult(committedInputDataBeforeUpgrade, new HashMap<>()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 222}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY5OTE0Mw==", "bodyText": "nit: s/state/states", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409699143", "createdAt": "2020-04-16T16:42:26Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+\n+            // phase 2:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT\n+            // p-1: 10 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade = prepareData(0L, 10L, 0L, 1L);\n+\n+            final List<KeyValue<Long, Long>> allData = new ArrayList<>(committedInputDataBeforeUpgrade);\n+\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeUpgrade = readResult(committedInputDataBeforeUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeUpgrade, computeExpectedResult(committedInputDataBeforeUpgrade, new HashMap<>()));\n+\n+            // capture committed state for later", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 224}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTcwODM1OQ==", "bodyText": "nit: extra space after second COMMIT", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409708359", "createdAt": "2020-04-16T16:57:00Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+\n+            // phase 2:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT\n+            // p-1: 10 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade = prepareData(0L, 10L, 0L, 1L);\n+\n+            final List<KeyValue<Long, Long>> allData = new ArrayList<>(committedInputDataBeforeUpgrade);\n+\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeUpgrade = readResult(committedInputDataBeforeUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeUpgrade, computeExpectedResult(committedInputDataBeforeUpgrade, new HashMap<>()));\n+\n+            // capture committed state for later\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneBeforeUpgrade =\n+                streams1Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateOne = new HashMap<>();\n+            final long keyFilterFirstUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeOneBeforeUpgrade.all()) {\n+                keyFilterFirstUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            final ReadOnlyKeyValueStore<Long, Long> storeTwoBeforeUpgrade =\n+                streams2Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateTwo = new HashMap<>();\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 3:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records (pending)\n+            stateTransitions2.clear();\n+            final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient2;\n+            if (injectError) {\n+                errorInjectedClient1.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeUpgrade = prepareData(10L, 15L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataBeforeUpgrade);\n+\n+            writeInputData(uncommittedInputDataBeforeUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 4:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            if (!injectError) {\n+                streams1Alpha.close();\n+            }\n+            waitForCondition(\n+                () -> stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not stabilize on time.\"\n+            );\n+            errorInjected = null;\n+\n+            final List<KeyValue<Long, Long>> allOutputDataAfterFirstUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataAfterFirstUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataAfterFirstUpgrade =\n+                    uncommittedInputDataBeforeUpgrade.stream().filter(pair -> pair.key == keyFilterFirstUpgrade).collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> committedOutputDataAfterFirstUpgrade = readResult(committedInputDataAfterFirstUpgrade.size(), CONSUMER_GROUP_ID);\n+                checkResultPerKey(committedOutputDataAfterFirstUpgrade, computeExpectedResult(committedInputDataAfterFirstUpgrade, currentStateOne));\n+            }\n+\n+            // phase 5:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records (+ maybe commit if tasks would have been switch; we don't care and don't verify)\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams1Beta.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+            // capture committed state for later\n+            final Map<Long, Long> currentStateAfterFirstUpgrade = new HashMap<>(currentStateTwo);\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneAfterUpgrade =\n+                streams1Beta.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterFirstUpgrade) {\n+                        currentStateAfterFirstUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterFirstUpgrade) {\n+                        currentStateAfterFirstUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+\n+            // phase 6:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records + (maybe COMMIT) + 5 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade = prepareData(15L, 20L, 0L, 1L);\n+            allData.addAll(committedInputDataDuringUpgrade);\n+\n+            writeInputData(committedInputDataDuringUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\");\n+\n+            final List<KeyValue<Long, Long>> allCommittedInputDataDuringUpgrade = new ArrayList<>();\n+            final Map<Long, Long> currentStateBeforeSecondUpgrade = new HashMap<>();\n+            if (!injectError) {\n+                allCommittedInputDataDuringUpgrade.addAll(\n+                    uncommittedInputDataBeforeUpgrade.stream().filter(pair -> pair.key != keyFilterFirstUpgrade).collect(Collectors.toList())\n+                );\n+                currentStateBeforeSecondUpgrade.putAll(currentStateAfterFirstUpgrade);\n+            } else {\n+                allCommittedInputDataDuringUpgrade.addAll(uncommittedInputDataBeforeUpgrade);\n+                currentStateBeforeSecondUpgrade.putAll(currentStateOne);\n+                currentStateBeforeSecondUpgrade.putAll(currentStateTwo);\n+            }\n+            allCommittedInputDataDuringUpgrade.addAll(committedInputDataDuringUpgrade);\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeSecondUpgrade = readResult(allCommittedInputDataDuringUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeSecondUpgrade, computeExpectedResult(allCommittedInputDataDuringUpgrade, currentStateBeforeSecondUpgrade));\n+\n+            // capture committed state for later\n+            currentStateOne.clear();\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            currentStateTwo.clear();\n+            final long keyFilterSecondUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                keyFilterSecondUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 7:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records (pending)\n+            stateTransitions1.clear();\n+            if (injectError) {\n+                errorInjectedClient2.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataDuringUpgrade = prepareData(20L, 25L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataDuringUpgrade);\n+\n+            writeInputData(uncommittedInputDataDuringUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeSecondUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeSecondUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 8:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records (pending)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 412}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk1MDI4MjQy", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-395028242", "createdAt": "2020-04-16T21:57:44Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMTo1Nzo0NFrOGG4oBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMjo0MjoxNVrOGG5txA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg3MjM4OA==", "bodyText": "Why the second client will have two pending transactions? Upon migrated the task the initTxn should cause the pending transaction failed.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409872388", "createdAt": "2020-04-16T21:57:44Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg3MzUzMg==", "bodyText": "Not sure why it's the case? I think the previous pending txn should have aborted in step 4.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409873532", "createdAt": "2020-04-16T22:00:10Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg3OTQ3Mw==", "bodyText": "In the current settings, with either alpha or beta, we will have one producer per thread since each thread would host one task only, right? Should we have 4 partitions so that under alpha we will have two producers and two txns per thread?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409879473", "createdAt": "2020-04-16T22:14:06Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg4MTYwMQ==", "bodyText": "Should we make this a concurrent linked list since concurrent threads may be adding at the same time?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409881601", "createdAt": "2020-04-16T22:19:27Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg4MjE2Mw==", "bodyText": "Seems we can just keep errorInjected to null in phase 1 since we do not need to inject failures?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409882163", "createdAt": "2020-04-16T22:20:54Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg4MzYxNw==", "bodyText": "+1 It seems we do not need the actual groupId here, just a boolean flag.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409883617", "createdAt": "2020-04-16T22:24:32Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+\n+            // phase 2:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT\n+            // p-1: 10 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade = prepareData(0L, 10L, 0L, 1L);\n+\n+            final List<KeyValue<Long, Long>> allData = new ArrayList<>(committedInputDataBeforeUpgrade);\n+\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeUpgrade = readResult(committedInputDataBeforeUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeUpgrade, computeExpectedResult(committedInputDataBeforeUpgrade, new HashMap<>()));\n+\n+            // capture committed state for later\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneBeforeUpgrade =\n+                streams1Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateOne = new HashMap<>();\n+            final long keyFilterFirstUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeOneBeforeUpgrade.all()) {\n+                keyFilterFirstUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            final ReadOnlyKeyValueStore<Long, Long> storeTwoBeforeUpgrade =\n+                streams2Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateTwo = new HashMap<>();\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 3:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records (pending)\n+            stateTransitions2.clear();\n+            final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient2;\n+            if (injectError) {\n+                errorInjectedClient1.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeUpgrade = prepareData(10L, 15L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataBeforeUpgrade);\n+\n+            writeInputData(uncommittedInputDataBeforeUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 4:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            if (!injectError) {\n+                streams1Alpha.close();\n+            }\n+            waitForCondition(\n+                () -> stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not stabilize on time.\"\n+            );\n+            errorInjected = null;\n+\n+            final List<KeyValue<Long, Long>> allOutputDataAfterFirstUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataAfterFirstUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataAfterFirstUpgrade =\n+                    uncommittedInputDataBeforeUpgrade.stream().filter(pair -> pair.key == keyFilterFirstUpgrade).collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> committedOutputDataAfterFirstUpgrade = readResult(committedInputDataAfterFirstUpgrade.size(), CONSUMER_GROUP_ID);\n+                checkResultPerKey(committedOutputDataAfterFirstUpgrade, computeExpectedResult(committedInputDataAfterFirstUpgrade, currentStateOne));\n+            }\n+\n+            // phase 5:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records (+ maybe commit if tasks would have been switch; we don't care and don't verify)\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams1Beta.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+            // capture committed state for later\n+            final Map<Long, Long> currentStateAfterFirstUpgrade = new HashMap<>(currentStateTwo);\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneAfterUpgrade =\n+                streams1Beta.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterFirstUpgrade) {\n+                        currentStateAfterFirstUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterFirstUpgrade) {\n+                        currentStateAfterFirstUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+\n+            // phase 6:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records + (maybe COMMIT) + 5 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade = prepareData(15L, 20L, 0L, 1L);\n+            allData.addAll(committedInputDataDuringUpgrade);\n+\n+            writeInputData(committedInputDataDuringUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\");\n+\n+            final List<KeyValue<Long, Long>> allCommittedInputDataDuringUpgrade = new ArrayList<>();\n+            final Map<Long, Long> currentStateBeforeSecondUpgrade = new HashMap<>();\n+            if (!injectError) {\n+                allCommittedInputDataDuringUpgrade.addAll(\n+                    uncommittedInputDataBeforeUpgrade.stream().filter(pair -> pair.key != keyFilterFirstUpgrade).collect(Collectors.toList())\n+                );\n+                currentStateBeforeSecondUpgrade.putAll(currentStateAfterFirstUpgrade);\n+            } else {\n+                allCommittedInputDataDuringUpgrade.addAll(uncommittedInputDataBeforeUpgrade);\n+                currentStateBeforeSecondUpgrade.putAll(currentStateOne);\n+                currentStateBeforeSecondUpgrade.putAll(currentStateTwo);\n+            }\n+            allCommittedInputDataDuringUpgrade.addAll(committedInputDataDuringUpgrade);\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeSecondUpgrade = readResult(allCommittedInputDataDuringUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeSecondUpgrade, computeExpectedResult(allCommittedInputDataDuringUpgrade, currentStateBeforeSecondUpgrade));\n+\n+            // capture committed state for later\n+            currentStateOne.clear();\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            currentStateTwo.clear();\n+            final long keyFilterSecondUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                keyFilterSecondUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 7:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records (pending)\n+            stateTransitions1.clear();\n+            if (injectError) {\n+                errorInjectedClient2.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataDuringUpgrade = prepareData(20L, 25L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataDuringUpgrade);\n+\n+            writeInputData(uncommittedInputDataDuringUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeSecondUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeSecondUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 8:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records (pending)\n+            if (!injectError) {\n+                streams2Alpha.close();\n+            }\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                        KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                        KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not stabilize on time.\"\n+            );\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataAfterSecondUpgrade =\n+                    uncommittedInputDataDuringUpgrade.stream().filter(pair -> pair.key == keyFilterSecondUpgrade).collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> committedOutputDataAfterSecondUpgrade = readResult(committedInputDataAfterSecondUpgrade.size(), CONSUMER_GROUP_ID);\n+                checkResultPerKey(committedOutputDataAfterSecondUpgrade, computeExpectedResult(committedInputDataAfterSecondUpgrade, currentStateTwo));\n+            }\n+\n+            final List<KeyValue<Long, Long>> allOutputDataAfterSecondUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataAfterSecondUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 9:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (+ maybe commit if tasks would have been switch; we don't care and don't verify)\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams2Beta.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+            // capture committed state\n+            final Map<Long, Long> currentStateAfterSecondUpgrade = new HashMap<>(currentStateOne);\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterSecondUpgrade) {\n+                        currentStateAfterSecondUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+            final ReadOnlyKeyValueStore<Long, Long> storeTwoAfterUpgrade =\n+                streams2Beta.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            try (final KeyValueIterator<Long, Long> it = storeTwoAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterSecondUpgrade) {\n+                        currentStateAfterSecondUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+\n+            // phase 10:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT + 5 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataAfterUpgrade = prepareData(25L, 30L, 0L, 1L);\n+            allData.addAll(committedInputDataAfterUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allCommittedInputDataAfterUpgrade = new ArrayList<>();\n+            final Map<Long, Long> lastCommittedState;\n+            if (!injectError) {\n+                allCommittedInputDataAfterUpgrade.addAll(\n+                    uncommittedInputDataDuringUpgrade.stream().filter(pair -> pair.key != keyFilterSecondUpgrade).collect(Collectors.toList())\n+                );\n+                lastCommittedState = currentStateAfterSecondUpgrade;\n+            } else {\n+                allCommittedInputDataAfterUpgrade.addAll(uncommittedInputDataDuringUpgrade);\n+                lastCommittedState = currentStateBeforeSecondUpgrade;\n+            }\n+            allCommittedInputDataAfterUpgrade.addAll(committedInputDataAfterUpgrade);\n+\n+            writeInputData(committedInputDataAfterUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\");\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataAfterUpgrade = readResult(allCommittedInputDataAfterUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataAfterUpgrade, computeExpectedResult(allCommittedInputDataAfterUpgrade, lastCommittedState));\n+        }\n+    }\n+\n+    private KafkaStreams getKafkaStreams(final String appDir,\n+                                         final String processingGuarantee) {\n+        commitRequested = new AtomicInteger(0);\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final String[] storeNames = new String[] {storeName};\n+        final StoreBuilder<KeyValueStore<Long, Long>> storeBuilder = Stores\n+            .keyValueStoreBuilder(Stores.persistentKeyValueStore(storeName), Serdes.Long(), Serdes.Long())\n+            .withCachingEnabled();\n+\n+        builder.addStateStore(storeBuilder);\n+\n+        final KStream<Long, Long> input = builder.stream(MULTI_PARTITION_INPUT_TOPIC);\n+        input.transform(new TransformerSupplier<Long, Long, KeyValue<Long, Long>>() {\n+            @SuppressWarnings(\"unchecked\")\n+            @Override\n+            public Transformer<Long, Long, KeyValue<Long, Long>> get() {\n+                return new Transformer<Long, Long, KeyValue<Long, Long>>() {\n+                    ProcessorContext<Object, Object> context;\n+                    KeyValueStore<Long, Long> state = null;\n+                    AtomicBoolean crash;\n+\n+                    @Override\n+                    public void init(final ProcessorContext<Object, Object> context) {\n+                        this.context = context;\n+                        state = (KeyValueStore<Long, Long>) context.getStateStore(storeName);\n+                        crash = errorInjected;\n+                    }\n+\n+                    @Override\n+                    public KeyValue<Long, Long> transform(final Long key, final Long value) {\n+                        if ((value + 1) % 10 == 0) {\n+                            context.commit();\n+                            commitRequested.incrementAndGet();\n+                        }\n+\n+                        Long sum = state.get(key);\n+                        if (sum == null) {\n+                            sum = value;\n+                        } else {\n+                            sum += value;\n+                        }\n+                        state.put(key, sum);\n+                        state.flush();\n+\n+                        if (crash != null && crash.compareAndSet(true, false)) {\n+                            // only tries to fail once on one of the task\n+                            throw new RuntimeException(\"Injected test exception.\");\n+                        }\n+\n+                        return new KeyValue<>(key, state.get(key));\n+                    }\n+\n+                    @Override\n+                    public void close() { }\n+                };\n+            } }, storeNames)\n+            .to(MULTI_PARTITION_OUTPUT_TOPIC);\n+\n+        final Properties properties = new Properties();\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n+        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, Long.MAX_VALUE);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.METADATA_MAX_AGE_CONFIG), \"1000\");\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG), \"earliest\");\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG), 5 * 1000);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG), 5 * 1000 - 1);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG), MAX_POLL_INTERVAL_MS);\n+        properties.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        properties.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath() + File.separator + appDir);\n+\n+        final Properties config = StreamsTestUtils.getStreamsConfig(\n+            applicationId,\n+            CLUSTER.bootstrapServers(),\n+            Serdes.LongSerde.class.getName(),\n+            Serdes.LongSerde.class.getName(),\n+            properties\n+        );\n+\n+        final KafkaStreams streams = new KafkaStreams(builder.build(), config);\n+\n+        streams.setUncaughtExceptionHandler((t, e) -> {\n+            if (uncaughtException != null) {\n+                e.printStackTrace(System.err);\n+                fail(\"Should only get one uncaught exception from Streams.\");\n+            }\n+            uncaughtException = e;\n+        });\n+\n+        return streams;\n+    }\n+\n+    private List<KeyValue<Long, Long>> prepareData(final long fromInclusive,\n+                                                   final long toExclusive,\n+                                                   final Long... keys) {\n+        final List<KeyValue<Long, Long>> data = new ArrayList<>();\n+\n+        for (final Long k : keys) {\n+            for (long v = fromInclusive; v < toExclusive; ++v) {\n+                data.add(new KeyValue<>(k, v));\n+            }\n+        }\n+\n+        return data;\n+    }\n+\n+    private void writeInputData(final List<KeyValue<Long, Long>> records) throws Exception {\n+        IntegrationTestUtils.produceKeyValuesSynchronously(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            records,\n+            TestUtils.producerConfig(CLUSTER.bootstrapServers(), LongSerializer.class, LongSerializer.class),\n+            CLUSTER.time\n+        );\n+    }\n+\n+    private List<KeyValue<Long, Long>> readResult(final int numberOfRecords,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY5Nzc3MA=="}, "originalCommit": null, "originalPosition": 626}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg4NDE1NA==", "bodyText": "After it resumes to running, p-0 should be aborted right?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409884154", "createdAt": "2020-04-16T22:25:54Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+\n+            // phase 2:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT\n+            // p-1: 10 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade = prepareData(0L, 10L, 0L, 1L);\n+\n+            final List<KeyValue<Long, Long>> allData = new ArrayList<>(committedInputDataBeforeUpgrade);\n+\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeUpgrade = readResult(committedInputDataBeforeUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeUpgrade, computeExpectedResult(committedInputDataBeforeUpgrade, new HashMap<>()));\n+\n+            // capture committed state for later\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneBeforeUpgrade =\n+                streams1Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateOne = new HashMap<>();\n+            final long keyFilterFirstUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeOneBeforeUpgrade.all()) {\n+                keyFilterFirstUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            final ReadOnlyKeyValueStore<Long, Long> storeTwoBeforeUpgrade =\n+                streams2Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateTwo = new HashMap<>();\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 3:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records (pending)\n+            stateTransitions2.clear();\n+            final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient2;\n+            if (injectError) {\n+                errorInjectedClient1.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeUpgrade = prepareData(10L, 15L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataBeforeUpgrade);\n+\n+            writeInputData(uncommittedInputDataBeforeUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 4:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            if (!injectError) {\n+                streams1Alpha.close();\n+            }\n+            waitForCondition(\n+                () -> stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 278}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg4NTA3Mw==", "bodyText": "Here p-0 may end with COMMIT (close) or ABORT (crash) right?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409885073", "createdAt": "2020-04-16T22:28:24Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+\n+            // phase 2:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT\n+            // p-1: 10 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade = prepareData(0L, 10L, 0L, 1L);\n+\n+            final List<KeyValue<Long, Long>> allData = new ArrayList<>(committedInputDataBeforeUpgrade);\n+\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeUpgrade = readResult(committedInputDataBeforeUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeUpgrade, computeExpectedResult(committedInputDataBeforeUpgrade, new HashMap<>()));\n+\n+            // capture committed state for later\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneBeforeUpgrade =\n+                streams1Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateOne = new HashMap<>();\n+            final long keyFilterFirstUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeOneBeforeUpgrade.all()) {\n+                keyFilterFirstUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            final ReadOnlyKeyValueStore<Long, Long> storeTwoBeforeUpgrade =\n+                streams2Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateTwo = new HashMap<>();\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 3:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records (pending)\n+            stateTransitions2.clear();\n+            final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient2;\n+            if (injectError) {\n+                errorInjectedClient1.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeUpgrade = prepareData(10L, 15L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataBeforeUpgrade);\n+\n+            writeInputData(uncommittedInputDataBeforeUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 4:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            if (!injectError) {\n+                streams1Alpha.close();\n+            }\n+            waitForCondition(\n+                () -> stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not stabilize on time.\"\n+            );\n+            errorInjected = null;\n+\n+            final List<KeyValue<Long, Long>> allOutputDataAfterFirstUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataAfterFirstUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataAfterFirstUpgrade =\n+                    uncommittedInputDataBeforeUpgrade.stream().filter(pair -> pair.key == keyFilterFirstUpgrade).collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> committedOutputDataAfterFirstUpgrade = readResult(committedInputDataAfterFirstUpgrade.size(), CONSUMER_GROUP_ID);\n+                checkResultPerKey(committedOutputDataAfterFirstUpgrade, computeExpectedResult(committedInputDataAfterFirstUpgrade, currentStateOne));\n+            }\n+\n+            // phase 5:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 298}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg5MDI0NA==", "bodyText": "This is a meta comment: I think the key here is to check that the offsets sent via \"sendOffsetsToTxn\" would not be seen to the new owner of the task, i.e. the fencing would take effects. But here since we do not commit (only 5 out of 10 records) this logic would never be checked.\nOn the other hand, inside StreamsProducer we always call\n            producer.sendOffsetsToTransaction(offsets, consumerGroupMetadata);\n            producer.commitTransaction();\n\ntogether, it is a bit hard to check with the given producer.\nI'd suggest doing a bit different here: we use a customized client-supplier that generate an extended producer which, depending on the failure injection boolean, throws an exception in commitTransaction immediately, so that we made sure the sendOffsetsToTransaction completes (i.e. the request acked from group coordinator already) before we crash, instead of crashing in the middle of the processing where we'd not send any offsets to group coordinator anyways.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r409890244", "createdAt": "2020-04-16T22:42:15Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,691 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 5 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 2;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private AtomicBoolean errorInjected;\n+    private AtomicInteger commitRequested;\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 2 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - both pending transactions are based on task producers\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have an pending transaction\n+        //      - crash case:\n+        //        * the second client will have two pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - crash only: the rebalance should result in a commit\n+        // 6.  write 5 record per input topic partition and verify that the result was committed\n+        // 7.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - one transaction is base on a task producer; the other transaction is based on a thread producer\n+        // 8.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only: verify that the stopped client did commit its pending transaction during shutdown\n+        //      - the first client will still have an pending transaction\n+        // 9.  restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        // 10. write 5 record per input topic partition and verify that the result was committed\n+\n+        try (final KafkaStreams streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            final KafkaStreams streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            final KafkaStreams streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA)) {\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+            streams1Alpha.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+\n+            final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+            streams2Alpha.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+            streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+            // phase 1:\n+            final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient1;\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                    )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+            stateTransitions1.clear();\n+            errorInjected = null;\n+\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+\n+            // phase 2:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT\n+            // p-1: 10 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade = prepareData(0L, 10L, 0L, 1L);\n+\n+            final List<KeyValue<Long, Long>> allData = new ArrayList<>(committedInputDataBeforeUpgrade);\n+\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeUpgrade = readResult(committedInputDataBeforeUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeUpgrade, computeExpectedResult(committedInputDataBeforeUpgrade, new HashMap<>()));\n+\n+            // capture committed state for later\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneBeforeUpgrade =\n+                streams1Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateOne = new HashMap<>();\n+            final long keyFilterFirstUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeOneBeforeUpgrade.all()) {\n+                keyFilterFirstUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            final ReadOnlyKeyValueStore<Long, Long> storeTwoBeforeUpgrade =\n+                streams2Alpha.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            final Map<Long, Long> currentStateTwo = new HashMap<>();\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 3:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records (pending)\n+            stateTransitions2.clear();\n+            final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+            errorInjected = errorInjectedClient2;\n+            if (injectError) {\n+                errorInjectedClient1.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeUpgrade = prepareData(10L, 15L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataBeforeUpgrade);\n+\n+            writeInputData(uncommittedInputDataBeforeUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 4:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records (pending)\n+            if (!injectError) {\n+                streams1Alpha.close();\n+            }\n+            waitForCondition(\n+                () -> stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not stabilize on time.\"\n+            );\n+            errorInjected = null;\n+\n+            final List<KeyValue<Long, Long>> allOutputDataAfterFirstUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataAfterFirstUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataAfterFirstUpgrade =\n+                    uncommittedInputDataBeforeUpgrade.stream().filter(pair -> pair.key == keyFilterFirstUpgrade).collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> committedOutputDataAfterFirstUpgrade = readResult(committedInputDataAfterFirstUpgrade.size(), CONSUMER_GROUP_ID);\n+                checkResultPerKey(committedOutputDataAfterFirstUpgrade, computeExpectedResult(committedInputDataAfterFirstUpgrade, currentStateOne));\n+            }\n+\n+            // phase 5:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records (+ maybe commit if tasks would have been switch; we don't care and don't verify)\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams1Beta.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+            // capture committed state for later\n+            final Map<Long, Long> currentStateAfterFirstUpgrade = new HashMap<>(currentStateTwo);\n+            final ReadOnlyKeyValueStore<Long, Long> storeOneAfterUpgrade =\n+                streams1Beta.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterFirstUpgrade) {\n+                        currentStateAfterFirstUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterFirstUpgrade) {\n+                        currentStateAfterFirstUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+\n+            // phase 6:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records + (maybe COMMIT) + 5 records + COMMIT\n+            final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade = prepareData(15L, 20L, 0L, 1L);\n+            allData.addAll(committedInputDataDuringUpgrade);\n+\n+            writeInputData(committedInputDataDuringUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 2, MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\");\n+\n+            final List<KeyValue<Long, Long>> allCommittedInputDataDuringUpgrade = new ArrayList<>();\n+            final Map<Long, Long> currentStateBeforeSecondUpgrade = new HashMap<>();\n+            if (!injectError) {\n+                allCommittedInputDataDuringUpgrade.addAll(\n+                    uncommittedInputDataBeforeUpgrade.stream().filter(pair -> pair.key != keyFilterFirstUpgrade).collect(Collectors.toList())\n+                );\n+                currentStateBeforeSecondUpgrade.putAll(currentStateAfterFirstUpgrade);\n+            } else {\n+                allCommittedInputDataDuringUpgrade.addAll(uncommittedInputDataBeforeUpgrade);\n+                currentStateBeforeSecondUpgrade.putAll(currentStateOne);\n+                currentStateBeforeSecondUpgrade.putAll(currentStateTwo);\n+            }\n+            allCommittedInputDataDuringUpgrade.addAll(committedInputDataDuringUpgrade);\n+\n+            final List<KeyValue<Long, Long>> committedOutputDataBeforeSecondUpgrade = readResult(allCommittedInputDataDuringUpgrade.size(), CONSUMER_GROUP_ID);\n+            checkResultPerKey(committedOutputDataBeforeSecondUpgrade, computeExpectedResult(allCommittedInputDataDuringUpgrade, currentStateBeforeSecondUpgrade));\n+\n+            // capture committed state for later\n+            currentStateOne.clear();\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateOne.put(row.key, row.value);\n+                }\n+            }\n+            currentStateTwo.clear();\n+            final long keyFilterSecondUpgrade;\n+            try (final KeyValueIterator<Long, Long> it = storeTwoBeforeUpgrade.all()) {\n+                keyFilterSecondUpgrade = it.peekNextKey();\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    currentStateTwo.put(row.key, row.value);\n+                }\n+            }\n+\n+            // phase 7:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records (pending)\n+            stateTransitions1.clear();\n+            if (injectError) {\n+                errorInjectedClient2.set(true);\n+            }\n+            final List<KeyValue<Long, Long>> uncommittedInputDataDuringUpgrade = prepareData(20L, 25L, 0L, 1L);\n+            allData.addAll(uncommittedInputDataDuringUpgrade);\n+\n+            writeInputData(uncommittedInputDataDuringUpgrade);\n+\n+            final List<KeyValue<Long, Long>> allOutputDataBeforeSecondUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataBeforeSecondUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 8:\n+            // expected end state per output partition:\n+            // stop case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT\n+            // crash case:\n+            //   p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (pending)\n+            //   p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records (pending)\n+            if (!injectError) {\n+                streams2Alpha.close();\n+            }\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                        KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                        KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not stabilize on time.\"\n+            );\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataAfterSecondUpgrade =\n+                    uncommittedInputDataDuringUpgrade.stream().filter(pair -> pair.key == keyFilterSecondUpgrade).collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> committedOutputDataAfterSecondUpgrade = readResult(committedInputDataAfterSecondUpgrade.size(), CONSUMER_GROUP_ID);\n+                checkResultPerKey(committedOutputDataAfterSecondUpgrade, computeExpectedResult(committedInputDataAfterSecondUpgrade, currentStateTwo));\n+            }\n+\n+            final List<KeyValue<Long, Long>> allOutputDataAfterSecondUpgrade = readResult(allData.size(), null);\n+            checkResultPerKey(allOutputDataAfterSecondUpgrade, computeExpectedResult(allData, new HashMap<>()));\n+\n+            // phase 9:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records (+ maybe commit if tasks would have been switch; we don't care and don't verify)\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams2Beta.start();\n+            waitForCondition(\n+                () -> stateTransitions1.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )) && stateTransitions2.equals(Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                    KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+\n+            // capture committed state\n+            final Map<Long, Long> currentStateAfterSecondUpgrade = new HashMap<>(currentStateOne);\n+            try (final KeyValueIterator<Long, Long> it = storeOneAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterSecondUpgrade) {\n+                        currentStateAfterSecondUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+            final ReadOnlyKeyValueStore<Long, Long> storeTwoAfterUpgrade =\n+                streams2Beta.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n+            try (final KeyValueIterator<Long, Long> it = storeTwoAfterUpgrade.all()) {\n+                while (it.hasNext()) {\n+                    final KeyValue<Long, Long> row = it.next();\n+                    if (row.key == keyFilterSecondUpgrade) {\n+                        currentStateAfterSecondUpgrade.put(row.key, row.value);\n+                    }\n+                }\n+            }\n+\n+            // phase 10:\n+            // expected end state per output partition:\n+            // p-0: 10 records + COMMIT + 5 records + COMMIT + 5 records + COMMIT + 5 records + 5 records + COMMIT\n+            // p-1: 10 records + COMMIT + 5 records + 5 records + COMMIT  + 5 records + COMMIT + 5 records + COMMIT", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 484}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTgzMTIz", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403183123", "createdAt": "2020-04-30T03:49:35Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo0OTozNVrOGOYs4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo0OTozNVrOGOYs4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzczNzk1Mg==", "bodyText": "Minor bug: this value was hard coded and it was not possible to overwrite it.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r417737952", "createdAt": "2020-04-30T03:49:35Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -1283,9 +1284,6 @@ private void verifyMaxInFlightRequestPerConnection(final Object maxInFlightReque\n         // add client id with stream client id prefix\n         props.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId);\n \n-        // Reduce the transaction timeout for quicker pending offset expiration on broker side.\n-        props.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, 10000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTgzMjUz", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403183253", "createdAt": "2020-04-30T03:50:10Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1MDoxMVrOGOYtWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1MDoxMVrOGOYtWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzczODA3Mw==", "bodyText": "The test fails here... (cf. over TODO)", "url": "https://github.com/apache/kafka/pull/8496#discussion_r417738073", "createdAt": "2020-04-30T03:50:11Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -388,6 +388,7 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n \n                 final List<KeyValue<Long, Long>> expectedCommittedResult =\n                     computeExpectedResult(committedInputDataDuringFirstUpgrade, committedState);\n+                // TODO: if we don't use the custom partitioner, the test hangs here until TX times out and is aborted\n                 verifyCommitted(expectedCommittedResult);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTgzMzk4", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403183398", "createdAt": "2020-04-30T03:50:51Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1MDo1MVrOGOYt0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1MDo1MVrOGOYt0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzczODE5Mw==", "bodyText": "This is the workaround that make the test (clean run) pass. For the error injection run, the test passed w/ and w/o this partitioner.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r417738193", "createdAt": "2020-04-30T03:50:51Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -881,6 +882,10 @@ public void close() { }\n         properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG), 5 * 1000);\n         properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG), 5 * 1000 - 1);\n         properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG), MAX_POLL_INTERVAL_MS);\n+        // TODO\n+        //   if we don't use this custom partitioner the test fails for the non-error case\n+        //   unclear why -- see other TODO\n+        properties.put(StreamsConfig.producerPrefix(ProducerConfig.PARTITIONER_CLASS_CONFIG), KeyPartitioner.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTgzNTc2", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403183576", "createdAt": "2020-04-30T03:51:38Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1MTozOFrOGOYugw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1MTozOFrOGOYugw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzczODM3MQ==", "bodyText": "This is just needed to make the partitioner work for writing into input topics and to use within KS to write into output topic.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r417738371", "createdAt": "2020-04-30T03:51:38Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -1064,14 +1071,16 @@ private void addAllKeys(final Set<Long> allKeys, final List<KeyValue<Long, Long>\n \n     // must be public to allow KafkaProducer to instantiate it\n     public static class KeyPartitioner implements Partitioner {\n+        private final static LongDeserializer LONG_DESERIALIZER = new LongDeserializer();\n+\n         @Override\n         public int partition(final String topic,\n                              final Object key,\n                              final byte[] keyBytes,\n                              final Object value,\n                              final byte[] valueBytes,\n                              final Cluster cluster) {\n-            return ((Long) key).intValue() % NUM_TOPIC_PARTITIONS;\n+            return LONG_DESERIALIZER.deserialize(topic, keyBytes).intValue() % NUM_TOPIC_PARTITIONS;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTg0MDYz", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403184063", "createdAt": "2020-04-30T03:53:51Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1Mzo1MVrOGOYwMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1Mzo1MVrOGOYwMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzczODgwMQ==", "bodyText": "We use 6 clients now, to do some error injection in \"mixed mode\". To avoid JXM warnings, we cannot create all clients at the same time and thus cannot use try-with-resources...", "url": "https://github.com/apache/kafka/pull/8496#discussion_r417738801", "createdAt": "2020-04-30T03:53:51Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,1123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Partitioner;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.ProducerFencedException;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 100 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_STARTUP =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_RUNNING =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> SINGLE_REBALANCE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CRASH =\n+        Collections.unmodifiableList(\n+            Collections.singletonList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.ERROR)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE_CRASHED =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.ERROR, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 4;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicInteger commitCounterClient1 = new AtomicInteger(-1);\n+    private final AtomicInteger commitCounterClient2 = new AtomicInteger(-1);\n+    private final AtomicInteger commitRequested = new AtomicInteger(0);\n+\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // Additionally, we inject errors while one client is on eos-alpha while the other client is on eos-beta:\n+        // For this case, we inject the error during task commit phase, i.e., after offsets are appended to a TX,\n+        // and before the TX is committed. The goal is to verify that the written but uncommitted offsets are not\n+        // picked up, i.e., GroupCoordinator fencing works correctly.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 4 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - all 4 pending transactions are based on task producers\n+        //      - we will get only 4 pending writes for one partition for the crash case as we crash processing the 5th record\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have two pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the second client will have four pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 6.  write 5 record per input topic partition\n+        //       - stop case:\n+        //         * verify that the result was committed\n+        //       - crash case:\n+        //         * fail the second (i.e., eos-alpha) client during commit\n+        //         * the eos-beta client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        // 7.  only for crash case:\n+        //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+        //     7b. write 10 records per input topic partition\n+        //         * fail the first (i.e., eos-beta) client during commit\n+        //         * the eos-alpha client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        //     7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n+        // 8.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - 2 transaction are base on a task producer; one transaction is based on a thread producer\n+        //      - we will get 4 pending writes for the crash case as we crash processing the 5th record\n+        // 9.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the first client will still have one pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the first client will have one pending transactions\n+        // 10. restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 11. write 5 record per input topic partition and verify that the result was committed\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+        KafkaStreams streams1Alpha = null;\n+        KafkaStreams streams1Beta = null;\n+        KafkaStreams streams1BetaTwo = null;\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+        KafkaStreams streams2Alpha = null;\n+        KafkaStreams streams2AlphaTwo = null;\n+        KafkaStreams streams2Beta = null;\n+//        streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA);\n+//        streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+        try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 258}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTg0MzEw", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403184310", "createdAt": "2020-04-30T03:55:03Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1NTowM1rOGOYxPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1NTowM1rOGOYxPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzczOTA2OA==", "bodyText": "This is new: for the crash case, in inject more errors in mixed mode, after we called sendOffsetsToTransaction() but before actually committing.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r417739068", "createdAt": "2020-04-30T03:55:03Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,1123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Partitioner;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.ProducerFencedException;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 100 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_STARTUP =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_RUNNING =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> SINGLE_REBALANCE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CRASH =\n+        Collections.unmodifiableList(\n+            Collections.singletonList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.ERROR)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE_CRASHED =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.ERROR, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 4;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicInteger commitCounterClient1 = new AtomicInteger(-1);\n+    private final AtomicInteger commitCounterClient2 = new AtomicInteger(-1);\n+    private final AtomicInteger commitRequested = new AtomicInteger(0);\n+\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // Additionally, we inject errors while one client is on eos-alpha while the other client is on eos-beta:\n+        // For this case, we inject the error during task commit phase, i.e., after offsets are appended to a TX,\n+        // and before the TX is committed. The goal is to verify that the written but uncommitted offsets are not\n+        // picked up, i.e., GroupCoordinator fencing works correctly.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 4 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - all 4 pending transactions are based on task producers\n+        //      - we will get only 4 pending writes for one partition for the crash case as we crash processing the 5th record\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have two pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the second client will have four pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 6.  write 5 record per input topic partition\n+        //       - stop case:\n+        //         * verify that the result was committed\n+        //       - crash case:\n+        //         * fail the second (i.e., eos-alpha) client during commit\n+        //         * the eos-beta client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        // 7.  only for crash case:\n+        //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+        //     7b. write 10 records per input topic partition\n+        //         * fail the first (i.e., eos-beta) client during commit\n+        //         * the eos-alpha client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        //     7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n+        // 8.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - 2 transaction are base on a task producer; one transaction is based on a thread producer\n+        //      - we will get 4 pending writes for the crash case as we crash processing the 5th record\n+        // 9.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the first client will still have one pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the first client will have one pending transactions\n+        // 10. restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 11. write 5 record per input topic partition and verify that the result was committed\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+        KafkaStreams streams1Alpha = null;\n+        KafkaStreams streams1Beta = null;\n+        KafkaStreams streams1BetaTwo = null;\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+        KafkaStreams streams2Alpha = null;\n+        KafkaStreams streams2AlphaTwo = null;\n+        KafkaStreams streams2Beta = null;\n+//        streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA);\n+//        streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+        try {\n+            // phase 1: start both clients\n+            streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            streams1Alpha.setStateListener(\n+                (newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForStateTransition(\n+                stateTransitions1,\n+                Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )\n+            );\n+\n+            stateTransitions1.clear();\n+            streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            streams2Alpha.setStateListener(\n+                (newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_RUNNING, stateTransitions2, TWO_REBALANCES_STARTUP);\n+\n+            // in all phases, we write comments that assume that p-0/p-1 are assigned to the first client\n+            // and p-2/p-3 are assigned to the second client (in reality the assignment might be different though)\n+\n+            // phase 2: (write first batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // p-0: ---> 10 rec + C\n+            // p-1: ---> 10 rec + C\n+            // p-2: ---> 10 rec + C\n+            // p-3: ---> 10 rec + C\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade =\n+                prepareData(0L, 10L, 0L, 1L, 2L, 3L);\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 4,\n+                MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final Map<Long, Long> committedState = new HashMap<>();\n+            final List<KeyValue<Long, Long>> expectedUncommittedResult =\n+                computeExpectedResult(committedInputDataBeforeUpgrade, committedState);\n+            verifyCommitted(expectedUncommittedResult);\n+\n+            // phase 3: (write partial second batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C ---> 5 rec (pending)\n+            //   p-1: 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C ---> 5 rec (pending)\n+            // crash case: (we just assumes that we inject the error for p-0; in reality it might be a different partition)\n+            //   p-0: 10 rec + C ---> 4 rec (pending)\n+            //   p-1: 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C ---> 5 rec (pending)\n+            final Set<Long> cleanKeys = mkSet(0L, 1L, 2L, 3L);\n+            final Set<Long> keyFilterFirstClient = keysFromInstance(streams1Alpha);\n+            final long potentiallyFirstFailingKey = keyFilterFirstClient.iterator().next();\n+            cleanKeys.remove(potentiallyFirstFailingKey);\n+\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeFirstUpgrade = new LinkedList<>();\n+            if (!injectError) {\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(\n+                    prepareData(10L, 15L, 0L, 1L, 2L, 3L)\n+                );\n+                writeInputData(uncommittedInputDataBeforeFirstUpgrade);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataBeforeFirstUpgrade, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            } else {\n+                final List<KeyValue<Long, Long>> uncommittedInputDataWithoutFailingKey = new LinkedList<>();\n+                for (final long key : cleanKeys) {\n+                    uncommittedInputDataWithoutFailingKey.addAll(prepareData(10L, 15L, key));\n+                }\n+                uncommittedInputDataWithoutFailingKey.addAll(\n+                    prepareData(10L, 14L, potentiallyFirstFailingKey)\n+                );\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(uncommittedInputDataWithoutFailingKey);\n+                writeInputData(uncommittedInputDataWithoutFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataWithoutFailingKey, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            }\n+\n+            // phase 4: (stop/crash first client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec (pending)\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec ---> A + 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec ---> A + 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec (pending)\n+            stateTransitions2.clear();\n+            if (!injectError) {\n+                stateTransitions1.clear();\n+                streams1Alpha.close();\n+                waitForStateTransition(stateTransitions1, CLOSE);\n+            } else {\n+                errorInjectedClient1.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataPotentiallyFirstFailingKey =\n+                    prepareData(14L, 15L, potentiallyFirstFailingKey);\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(dataPotentiallyFirstFailingKey);\n+                writeInputData(dataPotentiallyFirstFailingKey);\n+            }\n+            waitForStateTransition(stateTransitions2, SINGLE_REBALANCE);\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataDuringFirstUpgrade =\n+                    uncommittedInputDataBeforeFirstUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterFirstClient.contains(pair.key))\n+                        .collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                    computeExpectedResult(committedInputDataDuringFirstUpgrade, committedState);\n+                // TODO: if we don't use the custom partitioner, the test hangs here until TX times out and is aborted\n+                verifyCommitted(expectedCommittedResult);\n+            } else {\n+                // retrying TX\n+                expectedUncommittedResult.addAll(computeExpectedResult(\n+                    uncommittedInputDataBeforeFirstUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterFirstClient.contains(pair.key))\n+                        .collect(Collectors.toList()),\n+                    new HashMap<>(committedState)\n+                ));\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                errorInjectedClient1.set(false);\n+                stateTransitions1.clear();\n+                streams1Alpha.close();\n+                waitForStateTransition(stateTransitions1, CLOSE_CRASHED);\n+            }\n+\n+            // phase 5: (restart first client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec ---> C\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec ---> C\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_STARTUP, stateTransitions2, TWO_REBALANCES_RUNNING);\n+\n+            final Set<Long> committedKeys = mkSet(0L, 1L, 2L, 3L);\n+            if (!injectError) {\n+                committedKeys.removeAll(keyFilterFirstClient);\n+            }\n+\n+            final List<KeyValue<Long, Long>> expectedCommittedResultAfterRestartFirstClient = computeExpectedResult(\n+                uncommittedInputDataBeforeFirstUpgrade\n+                    .stream()\n+                    .filter(pair -> committedKeys.contains(pair.key))\n+                    .collect(Collectors.toList()),\n+                committedState\n+            );\n+            verifyCommitted(expectedCommittedResultAfterRestartFirstClient);\n+\n+            // phase 6: (complete second batch of data; crash: let second client fail on commit)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 445}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTg0NzEx", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403184711", "createdAt": "2020-04-30T03:56:49Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1Njo0OVrOGOYysw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1Njo0OVrOGOYysw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzczOTQ0Mw==", "bodyText": "This is the second part of the \"mixed mode\" test: client1 is on eos-beta and client2 is on eoa-alpha. In the first part above, we crashed the second client and restarted it in eos-alpha mode. In this second part, we crash client1 and restart it in eos-beta mode.\nThe actual upgrade continues in the next phase.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r417739443", "createdAt": "2020-04-30T03:56:49Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,1123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Partitioner;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.ProducerFencedException;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 100 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_STARTUP =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_RUNNING =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> SINGLE_REBALANCE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CRASH =\n+        Collections.unmodifiableList(\n+            Collections.singletonList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.ERROR)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE_CRASHED =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.ERROR, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 4;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicInteger commitCounterClient1 = new AtomicInteger(-1);\n+    private final AtomicInteger commitCounterClient2 = new AtomicInteger(-1);\n+    private final AtomicInteger commitRequested = new AtomicInteger(0);\n+\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // Additionally, we inject errors while one client is on eos-alpha while the other client is on eos-beta:\n+        // For this case, we inject the error during task commit phase, i.e., after offsets are appended to a TX,\n+        // and before the TX is committed. The goal is to verify that the written but uncommitted offsets are not\n+        // picked up, i.e., GroupCoordinator fencing works correctly.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 4 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - all 4 pending transactions are based on task producers\n+        //      - we will get only 4 pending writes for one partition for the crash case as we crash processing the 5th record\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have two pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the second client will have four pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 6.  write 5 record per input topic partition\n+        //       - stop case:\n+        //         * verify that the result was committed\n+        //       - crash case:\n+        //         * fail the second (i.e., eos-alpha) client during commit\n+        //         * the eos-beta client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        // 7.  only for crash case:\n+        //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+        //     7b. write 10 records per input topic partition\n+        //         * fail the first (i.e., eos-beta) client during commit\n+        //         * the eos-alpha client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        //     7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n+        // 8.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - 2 transaction are base on a task producer; one transaction is based on a thread producer\n+        //      - we will get 4 pending writes for the crash case as we crash processing the 5th record\n+        // 9.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the first client will still have one pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the first client will have one pending transactions\n+        // 10. restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 11. write 5 record per input topic partition and verify that the result was committed\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+        KafkaStreams streams1Alpha = null;\n+        KafkaStreams streams1Beta = null;\n+        KafkaStreams streams1BetaTwo = null;\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+        KafkaStreams streams2Alpha = null;\n+        KafkaStreams streams2AlphaTwo = null;\n+        KafkaStreams streams2Beta = null;\n+//        streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA);\n+//        streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+        try {\n+            // phase 1: start both clients\n+            streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            streams1Alpha.setStateListener(\n+                (newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForStateTransition(\n+                stateTransitions1,\n+                Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )\n+            );\n+\n+            stateTransitions1.clear();\n+            streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            streams2Alpha.setStateListener(\n+                (newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_RUNNING, stateTransitions2, TWO_REBALANCES_STARTUP);\n+\n+            // in all phases, we write comments that assume that p-0/p-1 are assigned to the first client\n+            // and p-2/p-3 are assigned to the second client (in reality the assignment might be different though)\n+\n+            // phase 2: (write first batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // p-0: ---> 10 rec + C\n+            // p-1: ---> 10 rec + C\n+            // p-2: ---> 10 rec + C\n+            // p-3: ---> 10 rec + C\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade =\n+                prepareData(0L, 10L, 0L, 1L, 2L, 3L);\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 4,\n+                MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final Map<Long, Long> committedState = new HashMap<>();\n+            final List<KeyValue<Long, Long>> expectedUncommittedResult =\n+                computeExpectedResult(committedInputDataBeforeUpgrade, committedState);\n+            verifyCommitted(expectedUncommittedResult);\n+\n+            // phase 3: (write partial second batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C ---> 5 rec (pending)\n+            //   p-1: 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C ---> 5 rec (pending)\n+            // crash case: (we just assumes that we inject the error for p-0; in reality it might be a different partition)\n+            //   p-0: 10 rec + C ---> 4 rec (pending)\n+            //   p-1: 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C ---> 5 rec (pending)\n+            final Set<Long> cleanKeys = mkSet(0L, 1L, 2L, 3L);\n+            final Set<Long> keyFilterFirstClient = keysFromInstance(streams1Alpha);\n+            final long potentiallyFirstFailingKey = keyFilterFirstClient.iterator().next();\n+            cleanKeys.remove(potentiallyFirstFailingKey);\n+\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeFirstUpgrade = new LinkedList<>();\n+            if (!injectError) {\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(\n+                    prepareData(10L, 15L, 0L, 1L, 2L, 3L)\n+                );\n+                writeInputData(uncommittedInputDataBeforeFirstUpgrade);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataBeforeFirstUpgrade, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            } else {\n+                final List<KeyValue<Long, Long>> uncommittedInputDataWithoutFailingKey = new LinkedList<>();\n+                for (final long key : cleanKeys) {\n+                    uncommittedInputDataWithoutFailingKey.addAll(prepareData(10L, 15L, key));\n+                }\n+                uncommittedInputDataWithoutFailingKey.addAll(\n+                    prepareData(10L, 14L, potentiallyFirstFailingKey)\n+                );\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(uncommittedInputDataWithoutFailingKey);\n+                writeInputData(uncommittedInputDataWithoutFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataWithoutFailingKey, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            }\n+\n+            // phase 4: (stop/crash first client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec (pending)\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec ---> A + 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec ---> A + 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec (pending)\n+            stateTransitions2.clear();\n+            if (!injectError) {\n+                stateTransitions1.clear();\n+                streams1Alpha.close();\n+                waitForStateTransition(stateTransitions1, CLOSE);\n+            } else {\n+                errorInjectedClient1.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataPotentiallyFirstFailingKey =\n+                    prepareData(14L, 15L, potentiallyFirstFailingKey);\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(dataPotentiallyFirstFailingKey);\n+                writeInputData(dataPotentiallyFirstFailingKey);\n+            }\n+            waitForStateTransition(stateTransitions2, SINGLE_REBALANCE);\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataDuringFirstUpgrade =\n+                    uncommittedInputDataBeforeFirstUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterFirstClient.contains(pair.key))\n+                        .collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                    computeExpectedResult(committedInputDataDuringFirstUpgrade, committedState);\n+                // TODO: if we don't use the custom partitioner, the test hangs here until TX times out and is aborted\n+                verifyCommitted(expectedCommittedResult);\n+            } else {\n+                // retrying TX\n+                expectedUncommittedResult.addAll(computeExpectedResult(\n+                    uncommittedInputDataBeforeFirstUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterFirstClient.contains(pair.key))\n+                        .collect(Collectors.toList()),\n+                    new HashMap<>(committedState)\n+                ));\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                errorInjectedClient1.set(false);\n+                stateTransitions1.clear();\n+                streams1Alpha.close();\n+                waitForStateTransition(stateTransitions1, CLOSE_CRASHED);\n+            }\n+\n+            // phase 5: (restart first client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec ---> C\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec ---> C\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_STARTUP, stateTransitions2, TWO_REBALANCES_RUNNING);\n+\n+            final Set<Long> committedKeys = mkSet(0L, 1L, 2L, 3L);\n+            if (!injectError) {\n+                committedKeys.removeAll(keyFilterFirstClient);\n+            }\n+\n+            final List<KeyValue<Long, Long>> expectedCommittedResultAfterRestartFirstClient = computeExpectedResult(\n+                uncommittedInputDataBeforeFirstUpgrade\n+                    .stream()\n+                    .filter(pair -> committedKeys.contains(pair.key))\n+                    .collect(Collectors.toList()),\n+                committedState\n+            );\n+            verifyCommitted(expectedCommittedResultAfterRestartFirstClient);\n+\n+            // phase 6: (complete second batch of data; crash: let second client fail on commit)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n+            commitCounterClient1.set(0);\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade =\n+                    prepareData(15L, 20L, 0L, 1L, 2L, 3L);\n+                writeInputData(committedInputDataDuringUpgrade);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                    computeExpectedResult(committedInputDataDuringUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResult);\n+                expectedUncommittedResult.addAll(expectedCommittedResult);\n+            } else {\n+                final Set<Long> keysFirstClient = keysFromInstance(streams1Beta);\n+                final Set<Long> keysSecondClient = keysFromInstance(streams2Alpha);\n+\n+                final List<KeyValue<Long, Long>> committedInputDataAfterFirstUpgrade =\n+                    prepareData(15L, 20L, keysFirstClient.toArray(new Long[0]));\n+                writeInputData(committedInputDataAfterFirstUpgrade);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultBeforeFailure =\n+                    computeExpectedResult(committedInputDataAfterFirstUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResultBeforeFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultBeforeFailure);\n+\n+                commitCounterClient2.set(0);\n+\n+                final Iterator<Long> it = keysSecondClient.iterator();\n+                final Long otherKey = it.next();\n+                final Long failingKey = it.next();\n+\n+                final List<KeyValue<Long, Long>> uncommittedInputDataAfterFirstUpgrade =\n+                    prepareData(15L, 19L, keysSecondClient.toArray(new Long[0]));\n+                uncommittedInputDataAfterFirstUpgrade.addAll(prepareData(19L, 20L, otherKey));\n+                writeInputData(uncommittedInputDataAfterFirstUpgrade);\n+\n+                final Map<Long, Long> uncommittedState = new HashMap<>(committedState);\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataAfterFirstUpgrade, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                stateTransitions1.clear();\n+                stateTransitions2.clear();\n+                commitCounterClient1.set(0);\n+                commitErrorInjectedClient2.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataFailingKey = prepareData(19L, 20L, failingKey);\n+                uncommittedInputDataAfterFirstUpgrade.addAll(dataFailingKey);\n+                writeInputData(dataFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(dataFailingKey, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                waitForStateTransition(stateTransitions1, SINGLE_REBALANCE, stateTransitions2, CRASH);\n+\n+                commitErrorInjectedClient2.set(false);\n+                stateTransitions2.clear();\n+                streams2Alpha.close();\n+                waitForStateTransition(stateTransitions2, CLOSE_CRASHED);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultAfterFailure =\n+                    computeExpectedResult(uncommittedInputDataAfterFirstUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResultAfterFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultAfterFailure);\n+            }\n+\n+            // 7. only for crash case:", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 526}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTg1MTcz", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403185173", "createdAt": "2020-04-30T03:58:54Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1ODo1NFrOGOY0Qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMzo1ODo1NFrOGOY0Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzczOTg0Mw==", "bodyText": "To get the correct observed state transition, we need to add them after waitForCondition failed... Originally, we just called:\nwaitForCondition(\n                () -> observed.equals(expected),\n                MAX_WAIT_TIME_MS,\n                \"Client did not startup on time.\" + observed\n            );\n\nbut this creates the error string with observed when started and thus the error message is miss-leading and useless", "url": "https://github.com/apache/kafka/pull/8496#discussion_r417739843", "createdAt": "2020-04-30T03:58:54Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,1123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Partitioner;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.ProducerFencedException;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 100 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_STARTUP =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_RUNNING =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> SINGLE_REBALANCE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CRASH =\n+        Collections.unmodifiableList(\n+            Collections.singletonList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.ERROR)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE_CRASHED =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.ERROR, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 4;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicInteger commitCounterClient1 = new AtomicInteger(-1);\n+    private final AtomicInteger commitCounterClient2 = new AtomicInteger(-1);\n+    private final AtomicInteger commitRequested = new AtomicInteger(0);\n+\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // Additionally, we inject errors while one client is on eos-alpha while the other client is on eos-beta:\n+        // For this case, we inject the error during task commit phase, i.e., after offsets are appended to a TX,\n+        // and before the TX is committed. The goal is to verify that the written but uncommitted offsets are not\n+        // picked up, i.e., GroupCoordinator fencing works correctly.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 4 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - all 4 pending transactions are based on task producers\n+        //      - we will get only 4 pending writes for one partition for the crash case as we crash processing the 5th record\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have two pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the second client will have four pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 6.  write 5 record per input topic partition\n+        //       - stop case:\n+        //         * verify that the result was committed\n+        //       - crash case:\n+        //         * fail the second (i.e., eos-alpha) client during commit\n+        //         * the eos-beta client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        // 7.  only for crash case:\n+        //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+        //     7b. write 10 records per input topic partition\n+        //         * fail the first (i.e., eos-beta) client during commit\n+        //         * the eos-alpha client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        //     7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n+        // 8.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - 2 transaction are base on a task producer; one transaction is based on a thread producer\n+        //      - we will get 4 pending writes for the crash case as we crash processing the 5th record\n+        // 9.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the first client will still have one pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the first client will have one pending transactions\n+        // 10. restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 11. write 5 record per input topic partition and verify that the result was committed\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+        KafkaStreams streams1Alpha = null;\n+        KafkaStreams streams1Beta = null;\n+        KafkaStreams streams1BetaTwo = null;\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+        KafkaStreams streams2Alpha = null;\n+        KafkaStreams streams2AlphaTwo = null;\n+        KafkaStreams streams2Beta = null;\n+//        streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA);\n+//        streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+        try {\n+            // phase 1: start both clients\n+            streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            streams1Alpha.setStateListener(\n+                (newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForStateTransition(\n+                stateTransitions1,\n+                Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )\n+            );\n+\n+            stateTransitions1.clear();\n+            streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            streams2Alpha.setStateListener(\n+                (newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_RUNNING, stateTransitions2, TWO_REBALANCES_STARTUP);\n+\n+            // in all phases, we write comments that assume that p-0/p-1 are assigned to the first client\n+            // and p-2/p-3 are assigned to the second client (in reality the assignment might be different though)\n+\n+            // phase 2: (write first batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // p-0: ---> 10 rec + C\n+            // p-1: ---> 10 rec + C\n+            // p-2: ---> 10 rec + C\n+            // p-3: ---> 10 rec + C\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade =\n+                prepareData(0L, 10L, 0L, 1L, 2L, 3L);\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 4,\n+                MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final Map<Long, Long> committedState = new HashMap<>();\n+            final List<KeyValue<Long, Long>> expectedUncommittedResult =\n+                computeExpectedResult(committedInputDataBeforeUpgrade, committedState);\n+            verifyCommitted(expectedUncommittedResult);\n+\n+            // phase 3: (write partial second batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C ---> 5 rec (pending)\n+            //   p-1: 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C ---> 5 rec (pending)\n+            // crash case: (we just assumes that we inject the error for p-0; in reality it might be a different partition)\n+            //   p-0: 10 rec + C ---> 4 rec (pending)\n+            //   p-1: 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C ---> 5 rec (pending)\n+            final Set<Long> cleanKeys = mkSet(0L, 1L, 2L, 3L);\n+            final Set<Long> keyFilterFirstClient = keysFromInstance(streams1Alpha);\n+            final long potentiallyFirstFailingKey = keyFilterFirstClient.iterator().next();\n+            cleanKeys.remove(potentiallyFirstFailingKey);\n+\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeFirstUpgrade = new LinkedList<>();\n+            if (!injectError) {\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(\n+                    prepareData(10L, 15L, 0L, 1L, 2L, 3L)\n+                );\n+                writeInputData(uncommittedInputDataBeforeFirstUpgrade);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataBeforeFirstUpgrade, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            } else {\n+                final List<KeyValue<Long, Long>> uncommittedInputDataWithoutFailingKey = new LinkedList<>();\n+                for (final long key : cleanKeys) {\n+                    uncommittedInputDataWithoutFailingKey.addAll(prepareData(10L, 15L, key));\n+                }\n+                uncommittedInputDataWithoutFailingKey.addAll(\n+                    prepareData(10L, 14L, potentiallyFirstFailingKey)\n+                );\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(uncommittedInputDataWithoutFailingKey);\n+                writeInputData(uncommittedInputDataWithoutFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataWithoutFailingKey, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            }\n+\n+            // phase 4: (stop/crash first client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec (pending)\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec ---> A + 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec ---> A + 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec (pending)\n+            stateTransitions2.clear();\n+            if (!injectError) {\n+                stateTransitions1.clear();\n+                streams1Alpha.close();\n+                waitForStateTransition(stateTransitions1, CLOSE);\n+            } else {\n+                errorInjectedClient1.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataPotentiallyFirstFailingKey =\n+                    prepareData(14L, 15L, potentiallyFirstFailingKey);\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(dataPotentiallyFirstFailingKey);\n+                writeInputData(dataPotentiallyFirstFailingKey);\n+            }\n+            waitForStateTransition(stateTransitions2, SINGLE_REBALANCE);\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataDuringFirstUpgrade =\n+                    uncommittedInputDataBeforeFirstUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterFirstClient.contains(pair.key))\n+                        .collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                    computeExpectedResult(committedInputDataDuringFirstUpgrade, committedState);\n+                // TODO: if we don't use the custom partitioner, the test hangs here until TX times out and is aborted\n+                verifyCommitted(expectedCommittedResult);\n+            } else {\n+                // retrying TX\n+                expectedUncommittedResult.addAll(computeExpectedResult(\n+                    uncommittedInputDataBeforeFirstUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterFirstClient.contains(pair.key))\n+                        .collect(Collectors.toList()),\n+                    new HashMap<>(committedState)\n+                ));\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                errorInjectedClient1.set(false);\n+                stateTransitions1.clear();\n+                streams1Alpha.close();\n+                waitForStateTransition(stateTransitions1, CLOSE_CRASHED);\n+            }\n+\n+            // phase 5: (restart first client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec ---> C\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec ---> C\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_STARTUP, stateTransitions2, TWO_REBALANCES_RUNNING);\n+\n+            final Set<Long> committedKeys = mkSet(0L, 1L, 2L, 3L);\n+            if (!injectError) {\n+                committedKeys.removeAll(keyFilterFirstClient);\n+            }\n+\n+            final List<KeyValue<Long, Long>> expectedCommittedResultAfterRestartFirstClient = computeExpectedResult(\n+                uncommittedInputDataBeforeFirstUpgrade\n+                    .stream()\n+                    .filter(pair -> committedKeys.contains(pair.key))\n+                    .collect(Collectors.toList()),\n+                committedState\n+            );\n+            verifyCommitted(expectedCommittedResultAfterRestartFirstClient);\n+\n+            // phase 6: (complete second batch of data; crash: let second client fail on commit)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n+            commitCounterClient1.set(0);\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade =\n+                    prepareData(15L, 20L, 0L, 1L, 2L, 3L);\n+                writeInputData(committedInputDataDuringUpgrade);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                    computeExpectedResult(committedInputDataDuringUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResult);\n+                expectedUncommittedResult.addAll(expectedCommittedResult);\n+            } else {\n+                final Set<Long> keysFirstClient = keysFromInstance(streams1Beta);\n+                final Set<Long> keysSecondClient = keysFromInstance(streams2Alpha);\n+\n+                final List<KeyValue<Long, Long>> committedInputDataAfterFirstUpgrade =\n+                    prepareData(15L, 20L, keysFirstClient.toArray(new Long[0]));\n+                writeInputData(committedInputDataAfterFirstUpgrade);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultBeforeFailure =\n+                    computeExpectedResult(committedInputDataAfterFirstUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResultBeforeFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultBeforeFailure);\n+\n+                commitCounterClient2.set(0);\n+\n+                final Iterator<Long> it = keysSecondClient.iterator();\n+                final Long otherKey = it.next();\n+                final Long failingKey = it.next();\n+\n+                final List<KeyValue<Long, Long>> uncommittedInputDataAfterFirstUpgrade =\n+                    prepareData(15L, 19L, keysSecondClient.toArray(new Long[0]));\n+                uncommittedInputDataAfterFirstUpgrade.addAll(prepareData(19L, 20L, otherKey));\n+                writeInputData(uncommittedInputDataAfterFirstUpgrade);\n+\n+                final Map<Long, Long> uncommittedState = new HashMap<>(committedState);\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataAfterFirstUpgrade, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                stateTransitions1.clear();\n+                stateTransitions2.clear();\n+                commitCounterClient1.set(0);\n+                commitErrorInjectedClient2.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataFailingKey = prepareData(19L, 20L, failingKey);\n+                uncommittedInputDataAfterFirstUpgrade.addAll(dataFailingKey);\n+                writeInputData(dataFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(dataFailingKey, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                waitForStateTransition(stateTransitions1, SINGLE_REBALANCE, stateTransitions2, CRASH);\n+\n+                commitErrorInjectedClient2.set(false);\n+                stateTransitions2.clear();\n+                streams2Alpha.close();\n+                waitForStateTransition(stateTransitions2, CLOSE_CRASHED);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultAfterFailure =\n+                    computeExpectedResult(uncommittedInputDataAfterFirstUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResultAfterFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultAfterFailure);\n+            }\n+\n+            // 7. only for crash case:\n+            //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+            //     7b. write third batch of input data\n+            //         * fail the first (i.e., eos-beta) client during commit\n+            //         * the eos-alpha client should not pickup the pending offsets\n+            //         * verify uncommitted and committed result\n+            //     7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n+            //\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C ---> 10 rec + A + 10 rec + C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C ---> 10 rec + A + 10 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C ---> 10 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C ---> 10 rec + C\n+            if (!injectError) {\n+                streams2AlphaTwo = streams2Alpha;\n+            } else {\n+                // 7a restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+                commitCounterClient1.set(0);\n+                commitCounterClient2.set(-1);\n+                stateTransitions1.clear();\n+                stateTransitions2.clear();\n+                streams2AlphaTwo = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+                streams2AlphaTwo.setStateListener(\n+                    (newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState))\n+                );\n+                streams2AlphaTwo.start();\n+                waitForStateTransition(stateTransitions1, TWO_REBALANCES_RUNNING, stateTransitions2, TWO_REBALANCES_STARTUP);\n+\n+                // 7b. write third batch of input data\n+                final Set<Long> keysFirstClient = keysFromInstance(streams1Beta);\n+                final Set<Long> keysSecondClient = keysFromInstance(streams2AlphaTwo);\n+\n+                final List<KeyValue<Long, Long>> committedInputDataBetweenUpgrades =\n+                    prepareData(20L, 30L, keysSecondClient.toArray(new Long[0]));\n+                writeInputData(committedInputDataBetweenUpgrades);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultBeforeFailure =\n+                    computeExpectedResult(committedInputDataBetweenUpgrades, committedState);\n+                verifyCommitted(expectedCommittedResultBeforeFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultBeforeFailure);\n+\n+                commitCounterClient2.set(0);\n+\n+                final Iterator<Long> it = keysFirstClient.iterator();\n+                final Long otherKey = it.next();\n+                final Long failingKey = it.next();\n+\n+                final List<KeyValue<Long, Long>> uncommittedInputDataBetweenUpgrade =\n+                    prepareData(20L, 29L, keysFirstClient.toArray(new Long[0]));\n+                uncommittedInputDataBetweenUpgrade.addAll(prepareData(29L, 30L, otherKey));\n+                writeInputData(uncommittedInputDataBetweenUpgrade);\n+\n+                final Map<Long, Long> uncommittedState = new HashMap<>(committedState);\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataBetweenUpgrade, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                stateTransitions1.clear();\n+                stateTransitions2.clear();\n+                commitCounterClient2.set(0);\n+                commitErrorInjectedClient1.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataFailingKey = prepareData(29L, 30L, failingKey);\n+                uncommittedInputDataBetweenUpgrade.addAll(dataFailingKey);\n+                writeInputData(dataFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(dataFailingKey, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                waitForStateTransition(stateTransitions1, CRASH, stateTransitions2, SINGLE_REBALANCE);\n+\n+                commitErrorInjectedClient1.set(false);\n+                stateTransitions1.clear();\n+                streams1Beta.close();\n+                waitForStateTransition(stateTransitions1, CLOSE_CRASHED);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultAfterFailure =\n+                    computeExpectedResult(uncommittedInputDataBetweenUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResultAfterFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultAfterFailure);\n+\n+                // 7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n+                stateTransitions1.clear();\n+                stateTransitions2.clear();\n+                streams1BetaTwo = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+                streams1BetaTwo.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+                streams1BetaTwo.start();\n+                waitForStateTransition(stateTransitions1, TWO_REBALANCES_STARTUP, stateTransitions2, TWO_REBALANCES_RUNNING);\n+            }\n+\n+            // phase 8: (write partial fourth batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C + 5 rec + C ---> 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec + C + 5 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + C ---> 5 rec (pending)\n+            // crash case:  (we just assumes that we inject the error for p-2; in reality it might be a different partition)\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C ---> 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C ---> 4 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C ---> 5 rec (pending)\n+            cleanKeys.addAll(mkSet(0L, 1L, 2L, 3L));\n+            final Set<Long> keyFilterSecondClient = keysFromInstance(streams2AlphaTwo);\n+            final long potentiallySecondFailingKey = keyFilterSecondClient.iterator().next();\n+            cleanKeys.remove(potentiallySecondFailingKey);\n+\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeSecondUpgrade = new LinkedList<>();\n+            if (!injectError) {\n+                uncommittedInputDataBeforeSecondUpgrade.addAll(\n+                    prepareData(30L, 35L, 0L, 1L, 2L, 3L)\n+                );\n+                writeInputData(uncommittedInputDataBeforeSecondUpgrade);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataBeforeSecondUpgrade, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            } else {\n+                final List<KeyValue<Long, Long>> uncommittedInputDataWithoutFailingKey = new LinkedList<>();\n+                for (final long key : cleanKeys) {\n+                    uncommittedInputDataWithoutFailingKey.addAll(prepareData(30L, 35L, key));\n+                }\n+                uncommittedInputDataWithoutFailingKey.addAll(\n+                    prepareData(30L, 34L, potentiallySecondFailingKey)\n+                );\n+                uncommittedInputDataBeforeSecondUpgrade.addAll(uncommittedInputDataWithoutFailingKey);\n+                writeInputData(uncommittedInputDataWithoutFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataWithoutFailingKey, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            }\n+\n+            // phase 9: (stop/crash second client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec ---> C\n+            // crash case:  (we just assumes that we inject the error for p-2; in reality it might be a different partition)\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 4 rec ---> A + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 5 rec ---> A + 5 rec (pending)\n+            stateTransitions1.clear();\n+            if (!injectError) {\n+                stateTransitions2.clear();\n+                streams2AlphaTwo.close();\n+                waitForStateTransition(stateTransitions2, CLOSE);\n+            } else {\n+                errorInjectedClient2.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataPotentiallySecondFailingKey =\n+                    prepareData(34L, 35L, potentiallySecondFailingKey);\n+                uncommittedInputDataBeforeSecondUpgrade.addAll(dataPotentiallySecondFailingKey);\n+                writeInputData(dataPotentiallySecondFailingKey);\n+            }\n+            waitForStateTransition(stateTransitions1, SINGLE_REBALANCE);\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataDuringSecondUpgrade =\n+                    uncommittedInputDataBeforeSecondUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterSecondClient.contains(pair.key))\n+                        .collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                    computeExpectedResult(committedInputDataDuringSecondUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResult);\n+            } else {\n+                // retrying TX\n+                expectedUncommittedResult.addAll(computeExpectedResult(\n+                    uncommittedInputDataBeforeSecondUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterSecondClient.contains(pair.key))\n+                        .collect(Collectors.toList()),\n+                    new HashMap<>(committedState)\n+                ));\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                errorInjectedClient2.set(false);\n+                stateTransitions2.clear();\n+                streams2AlphaTwo.close();\n+                waitForStateTransition(stateTransitions2, CLOSE_CRASHED);\n+            }\n+\n+            // phase 10: (restart second client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // the state below indicate the case for which the \"original\" tasks of client2 are migrated back to client2\n+            // if a task \"switch\" happens, we might get additional commits (omitted in the comment for brevity)\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C\n+            // crash case:  (we just assumes that we inject the error for p-2; in reality it might be a different partition)\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 4 rec + A + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 5 rec + A + 5 rec ---> C\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams2Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            streams2Beta.setStateListener(\n+                (newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams2Beta.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_RUNNING, stateTransitions2, TWO_REBALANCES_STARTUP);\n+\n+            committedKeys.addAll(mkSet(0L, 1L, 2L, 3L));\n+            if (!injectError) {\n+                committedKeys.removeAll(keyFilterSecondClient);\n+            }\n+\n+            final List<KeyValue<Long, Long>> expectedCommittedResultAfterRestartSecondClient = computeExpectedResult(\n+                uncommittedInputDataBeforeSecondUpgrade\n+                    .stream()\n+                    .filter(pair -> committedKeys.contains(pair.key))\n+                    .collect(Collectors.toList()),\n+                committedState\n+            );\n+            verifyCommitted(expectedCommittedResultAfterRestartSecondClient);\n+\n+            // phase 11: (complete fourth batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n+            // crash case:  (we just assumes that we inject the error for p-2; in reality it might be a different partition)\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 4 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 5 rec + A + 5 rec + C ---> 5 rec + C\n+            commitCounterClient1.set(-1);\n+            commitCounterClient2.set(-1);\n+\n+            final List<KeyValue<Long, Long>> committedInputDataAfterUpgrade =\n+                prepareData(35L, 40L, 0L, 1L, 2L, 3L);\n+            writeInputData(committedInputDataAfterUpgrade);\n+\n+            final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                computeExpectedResult(committedInputDataAfterUpgrade, committedState);\n+            verifyCommitted(expectedCommittedResult);\n+        } finally {\n+            if (streams1Alpha != null) {\n+                streams1Alpha.close();\n+            }\n+            if (streams1Beta != null) {\n+                streams1Beta.close();\n+            }\n+            if (streams1BetaTwo != null) {\n+                streams1BetaTwo.close();\n+            }\n+            if (streams2Alpha != null) {\n+                streams2Alpha.close();\n+            }\n+            if (streams2AlphaTwo != null) {\n+                streams2AlphaTwo.close();\n+            }\n+            if (streams2Beta != null) {\n+                streams2Beta.close();\n+            }\n+        }\n+    }\n+\n+    private KafkaStreams getKafkaStreams(final String appDir,\n+                                         final String processingGuarantee) {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final String[] storeNames = new String[] {storeName};\n+        final StoreBuilder<KeyValueStore<Long, Long>> storeBuilder = Stores\n+            .keyValueStoreBuilder(Stores.persistentKeyValueStore(storeName), Serdes.Long(), Serdes.Long())\n+            .withCachingEnabled();\n+\n+        builder.addStateStore(storeBuilder);\n+\n+        final KStream<Long, Long> input = builder.stream(MULTI_PARTITION_INPUT_TOPIC);\n+        input.transform(new TransformerSupplier<Long, Long, KeyValue<Long, Long>>() {\n+            @SuppressWarnings(\"unchecked\")\n+            @Override\n+            public Transformer<Long, Long, KeyValue<Long, Long>> get() {\n+                return new Transformer<Long, Long, KeyValue<Long, Long>>() {\n+                    ProcessorContext<Object, Object> context;\n+                    KeyValueStore<Long, Long> state = null;\n+                    AtomicBoolean crash;\n+                    AtomicInteger sharedCommit;\n+\n+                    @Override\n+                    public void init(final ProcessorContext<Object, Object> context) {\n+                        this.context = context;\n+                        state = (KeyValueStore<Long, Long>) context.getStateStore(storeName);\n+                        final String clientId = context.appConfigs().get(StreamsConfig.CLIENT_ID_CONFIG).toString();\n+                        if (\"appDir1\".equals(clientId)) {\n+                            crash = errorInjectedClient1;\n+                            sharedCommit = commitCounterClient1;\n+                        } else {\n+                            crash = errorInjectedClient2;\n+                            sharedCommit = commitCounterClient2;\n+                        }\n+                    }\n+\n+                    @Override\n+                    public KeyValue<Long, Long> transform(final Long key, final Long value) {\n+                        if ((value + 1) % 10 == 0) {\n+                            if (sharedCommit.get() < 0 ||\n+                                sharedCommit.incrementAndGet() == 2) {\n+\n+                                context.commit();\n+                            }\n+                            commitRequested.incrementAndGet();\n+                        }\n+\n+                        Long sum = state.get(key);\n+                        if (sum == null) {\n+                            sum = value;\n+                        } else {\n+                            sum += value;\n+                        }\n+                        state.put(key, sum);\n+                        state.flush();\n+\n+                        if (value % 10 == 4 && // potentially crash when processing 5th, 15th, or 25th record (etc.)\n+                            crash != null && crash.compareAndSet(true, false)) {\n+                            // only crash a single task\n+                            throw new RuntimeException(\"Injected test exception.\");\n+                        }\n+\n+                        return new KeyValue<>(key, state.get(key));\n+                    }\n+\n+                    @Override\n+                    public void close() { }\n+                };\n+            } }, storeNames)\n+            .to(MULTI_PARTITION_OUTPUT_TOPIC);\n+\n+        final Properties properties = new Properties();\n+        properties.put(StreamsConfig.CLIENT_ID_CONFIG, appDir);\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n+        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, Long.MAX_VALUE);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.METADATA_MAX_AGE_CONFIG), \"1000\");\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG), \"earliest\");\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG), 5 * 1000);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG), 5 * 1000 - 1);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG), MAX_POLL_INTERVAL_MS);\n+        // TODO\n+        //   if we don't use this custom partitioner the test fails for the non-error case\n+        //   unclear why -- see other TODO\n+        properties.put(StreamsConfig.producerPrefix(ProducerConfig.PARTITIONER_CLASS_CONFIG), KeyPartitioner.class);\n+        properties.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        properties.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath() + File.separator + appDir);\n+\n+        final Properties config = StreamsTestUtils.getStreamsConfig(\n+            applicationId,\n+            CLUSTER.bootstrapServers(),\n+            Serdes.LongSerde.class.getName(),\n+            Serdes.LongSerde.class.getName(),\n+            properties\n+        );\n+\n+        final KafkaStreams streams = new KafkaStreams(builder.build(), config, new TestKafkaClientSupplier());\n+\n+        streams.setUncaughtExceptionHandler((t, e) -> {\n+            if (uncaughtException != null) {\n+                e.printStackTrace(System.err);\n+                fail(\"Should only get one uncaught exception from Streams.\");\n+            }\n+            uncaughtException = e;\n+        });\n+\n+        return streams;\n+    }\n+\n+    private void waitForStateTransition(final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> observed,\n+                                        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> expected)\n+        throws Exception {\n+\n+        try {\n+            waitForCondition(\n+                () -> observed.equals(expected),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+        } catch (final AssertionError error) {\n+            final AssertionError newError = new AssertionError(\"Client transitions: \" + observed);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 924}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTg1NjQ5", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403185649", "createdAt": "2020-04-30T04:00:48Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNDowMDo0OFrOGOY2Ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNDowMDo0OFrOGOY2Ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc0MDI5MA==", "bodyText": "With 4 partitions, we need a custom partitioner to make sure we write the 4 different keys into 4 different partitions -- the default partitioner would only write data to 2 partitions (this behavior, ie, empty partitions vs. non-empty partitions, seems to be related to the bug when the test fails -- ensuring that data is written into all partitions avoids the issue).", "url": "https://github.com/apache/kafka/pull/8496#discussion_r417740290", "createdAt": "2020-04-30T04:00:48Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -0,0 +1,1123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Partitioner;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.ProducerFencedException;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StoreQueryParameters;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Transformer;\n+import org.apache.kafka.streams.kstream.TransformerSupplier;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.QueryableStoreTypes;\n+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@RunWith(Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class EosBetaUpgradeIntegrationTest {\n+\n+    @Parameterized.Parameters(name = \"{0}\")\n+    public static Collection<Boolean[]> data() {\n+        return Arrays.asList(new Boolean[][] {\n+            {false},\n+            {true}\n+        });\n+    }\n+\n+    @Parameterized.Parameter\n+    public boolean injectError;\n+\n+    private static final int NUM_BROKERS = 3;\n+    private static final int MAX_POLL_INTERVAL_MS = 100 * 1000;\n+    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_STARTUP =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> TWO_REBALANCES_RUNNING =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING),\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> SINGLE_REBALANCE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.REBALANCING),\n+                KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CRASH =\n+        Collections.unmodifiableList(\n+            Collections.singletonList(\n+                KeyValue.pair(KafkaStreams.State.RUNNING, KafkaStreams.State.ERROR)\n+            )\n+        );\n+    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE_CRASHED =\n+        Collections.unmodifiableList(\n+            Arrays.asList(\n+                KeyValue.pair(KafkaStreams.State.ERROR, KafkaStreams.State.PENDING_SHUTDOWN),\n+                KeyValue.pair(KafkaStreams.State.PENDING_SHUTDOWN, KafkaStreams.State.NOT_RUNNING)\n+            )\n+        );\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(\n+        NUM_BROKERS,\n+        Utils.mkProperties(Collections.singletonMap(\"auto.create.topics.enable\", \"false\"))\n+    );\n+\n+    private static String applicationId;\n+    private final static int NUM_TOPIC_PARTITIONS = 4;\n+    private final static String CONSUMER_GROUP_ID = \"readCommitted\";\n+    private final static String MULTI_PARTITION_INPUT_TOPIC = \"multiPartitionInputTopic\";\n+    private final static String MULTI_PARTITION_OUTPUT_TOPIC = \"multiPartitionOutputTopic\";\n+    private final String storeName = \"store\";\n+\n+    private final AtomicBoolean errorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean errorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient1 = new AtomicBoolean(false);\n+    private final AtomicBoolean commitErrorInjectedClient2 = new AtomicBoolean(false);\n+    private final AtomicInteger commitCounterClient1 = new AtomicInteger(-1);\n+    private final AtomicInteger commitCounterClient2 = new AtomicInteger(-1);\n+    private final AtomicInteger commitRequested = new AtomicInteger(0);\n+\n+    private Throwable uncaughtException;\n+\n+    private int testNumber = 0;\n+\n+    @Before\n+    public void createTopics() throws Exception {\n+        applicationId = \"appId-\" + ++testNumber;\n+        CLUSTER.deleteTopicsAndWait(\n+            MULTI_PARTITION_INPUT_TOPIC,\n+            MULTI_PARTITION_OUTPUT_TOPIC,\n+            applicationId + \"-\" + storeName + \"-changelog\"\n+        );\n+\n+        CLUSTER.createTopic(MULTI_PARTITION_INPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+        CLUSTER.createTopic(MULTI_PARTITION_OUTPUT_TOPIC, NUM_TOPIC_PARTITIONS, 1);\n+    }\n+\n+    @Test\n+    public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n+        // We use two KafkaStreams clients that we upgrade from eos-alpha to eos-beta. During the upgrade,\n+        // we ensure that there are pending transaction and verify that data is processed correctly.\n+        //\n+        // We either close clients cleanly (`injectError = false`) or let them crash (`injectError = true`) during\n+        // the upgrade. For both cases, EOS should not be violated.\n+        //\n+        // Additionally, we inject errors while one client is on eos-alpha while the other client is on eos-beta:\n+        // For this case, we inject the error during task commit phase, i.e., after offsets are appended to a TX,\n+        // and before the TX is committed. The goal is to verify that the written but uncommitted offsets are not\n+        // picked up, i.e., GroupCoordinator fencing works correctly.\n+        //\n+        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n+        // control when a commit actually happens. We use an input topic with 4 partitions and each task will request\n+        // a commit after processing 10 records.\n+        //\n+        // 1.  start both clients and wait until rebalance stabilizes\n+        // 2.  write 10 records per input topic partition and verify that the result was committed\n+        // 3.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - all 4 pending transactions are based on task producers\n+        //      - we will get only 4 pending writes for one partition for the crash case as we crash processing the 5th record\n+        // 4.  stop/crash the first client, wait until rebalance stabilizes:\n+        //      - stop case:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the second client will still have two pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the second client will have four pending transactions\n+        // 5.  restart the first client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 6.  write 5 record per input topic partition\n+        //       - stop case:\n+        //         * verify that the result was committed\n+        //       - crash case:\n+        //         * fail the second (i.e., eos-alpha) client during commit\n+        //         * the eos-beta client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        // 7.  only for crash case:\n+        //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+        //     7b. write 10 records per input topic partition\n+        //         * fail the first (i.e., eos-beta) client during commit\n+        //         * the eos-alpha client should not pickup the pending offsets\n+        //         * verify uncommitted and committed result\n+        //     7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n+        // 8.  write 5 records per input topic partition to get pending transactions (verified via \"read_uncommitted\" mode)\n+        //      - 2 transaction are base on a task producer; one transaction is based on a thread producer\n+        //      - we will get 4 pending writes for the crash case as we crash processing the 5th record\n+        // 9.  stop/crash the second client and wait until rebalance stabilizes:\n+        //      - stop only:\n+        //        * verify that the stopped client did commit its pending transaction during shutdown\n+        //        * the first client will still have one pending transaction\n+        //      - crash case:\n+        //        * the pending transactions of the crashed client got aborted\n+        //        * the first client will have one pending transactions\n+        // 10. restart the second client with eos-beta enabled and wait until rebalance stabilizes\n+        //       - the rebalance should result in a commit of all tasks\n+        // 11. write 5 record per input topic partition and verify that the result was committed\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions1 = new LinkedList<>();\n+        KafkaStreams streams1Alpha = null;\n+        KafkaStreams streams1Beta = null;\n+        KafkaStreams streams1BetaTwo = null;\n+\n+        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> stateTransitions2 = new LinkedList<>();\n+        KafkaStreams streams2Alpha = null;\n+        KafkaStreams streams2AlphaTwo = null;\n+        KafkaStreams streams2Beta = null;\n+//        streams2Beta = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE_BETA);\n+//        streams2Beta.setStateListener((newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState)));\n+\n+        try {\n+            // phase 1: start both clients\n+            streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);\n+            streams1Alpha.setStateListener(\n+                (newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams1Alpha.cleanUp();\n+            streams1Alpha.start();\n+            waitForStateTransition(\n+                stateTransitions1,\n+                Arrays.asList(\n+                    KeyValue.pair(KafkaStreams.State.CREATED, KafkaStreams.State.REBALANCING),\n+                    KeyValue.pair(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING)\n+                )\n+            );\n+\n+            stateTransitions1.clear();\n+            streams2Alpha = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+            streams2Alpha.setStateListener(\n+                (newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams2Alpha.cleanUp();\n+            streams2Alpha.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_RUNNING, stateTransitions2, TWO_REBALANCES_STARTUP);\n+\n+            // in all phases, we write comments that assume that p-0/p-1 are assigned to the first client\n+            // and p-2/p-3 are assigned to the second client (in reality the assignment might be different though)\n+\n+            // phase 2: (write first batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // p-0: ---> 10 rec + C\n+            // p-1: ---> 10 rec + C\n+            // p-2: ---> 10 rec + C\n+            // p-3: ---> 10 rec + C\n+            final List<KeyValue<Long, Long>> committedInputDataBeforeUpgrade =\n+                prepareData(0L, 10L, 0L, 1L, 2L, 3L);\n+            writeInputData(committedInputDataBeforeUpgrade);\n+\n+            waitForCondition(\n+                () -> commitRequested.get() == 4,\n+                MAX_WAIT_TIME_MS,\n+                \"SteamsTasks did not request commit.\"\n+            );\n+\n+            final Map<Long, Long> committedState = new HashMap<>();\n+            final List<KeyValue<Long, Long>> expectedUncommittedResult =\n+                computeExpectedResult(committedInputDataBeforeUpgrade, committedState);\n+            verifyCommitted(expectedUncommittedResult);\n+\n+            // phase 3: (write partial second batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C ---> 5 rec (pending)\n+            //   p-1: 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C ---> 5 rec (pending)\n+            // crash case: (we just assumes that we inject the error for p-0; in reality it might be a different partition)\n+            //   p-0: 10 rec + C ---> 4 rec (pending)\n+            //   p-1: 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C ---> 5 rec (pending)\n+            final Set<Long> cleanKeys = mkSet(0L, 1L, 2L, 3L);\n+            final Set<Long> keyFilterFirstClient = keysFromInstance(streams1Alpha);\n+            final long potentiallyFirstFailingKey = keyFilterFirstClient.iterator().next();\n+            cleanKeys.remove(potentiallyFirstFailingKey);\n+\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeFirstUpgrade = new LinkedList<>();\n+            if (!injectError) {\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(\n+                    prepareData(10L, 15L, 0L, 1L, 2L, 3L)\n+                );\n+                writeInputData(uncommittedInputDataBeforeFirstUpgrade);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataBeforeFirstUpgrade, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            } else {\n+                final List<KeyValue<Long, Long>> uncommittedInputDataWithoutFailingKey = new LinkedList<>();\n+                for (final long key : cleanKeys) {\n+                    uncommittedInputDataWithoutFailingKey.addAll(prepareData(10L, 15L, key));\n+                }\n+                uncommittedInputDataWithoutFailingKey.addAll(\n+                    prepareData(10L, 14L, potentiallyFirstFailingKey)\n+                );\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(uncommittedInputDataWithoutFailingKey);\n+                writeInputData(uncommittedInputDataWithoutFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataWithoutFailingKey, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            }\n+\n+            // phase 4: (stop/crash first client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec (pending)\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec ---> A + 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec ---> A + 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec (pending)\n+            stateTransitions2.clear();\n+            if (!injectError) {\n+                stateTransitions1.clear();\n+                streams1Alpha.close();\n+                waitForStateTransition(stateTransitions1, CLOSE);\n+            } else {\n+                errorInjectedClient1.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataPotentiallyFirstFailingKey =\n+                    prepareData(14L, 15L, potentiallyFirstFailingKey);\n+                uncommittedInputDataBeforeFirstUpgrade.addAll(dataPotentiallyFirstFailingKey);\n+                writeInputData(dataPotentiallyFirstFailingKey);\n+            }\n+            waitForStateTransition(stateTransitions2, SINGLE_REBALANCE);\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataDuringFirstUpgrade =\n+                    uncommittedInputDataBeforeFirstUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterFirstClient.contains(pair.key))\n+                        .collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                    computeExpectedResult(committedInputDataDuringFirstUpgrade, committedState);\n+                // TODO: if we don't use the custom partitioner, the test hangs here until TX times out and is aborted\n+                verifyCommitted(expectedCommittedResult);\n+            } else {\n+                // retrying TX\n+                expectedUncommittedResult.addAll(computeExpectedResult(\n+                    uncommittedInputDataBeforeFirstUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterFirstClient.contains(pair.key))\n+                        .collect(Collectors.toList()),\n+                    new HashMap<>(committedState)\n+                ));\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                errorInjectedClient1.set(false);\n+                stateTransitions1.clear();\n+                streams1Alpha.close();\n+                waitForStateTransition(stateTransitions1, CLOSE_CRASHED);\n+            }\n+\n+            // phase 5: (restart first client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec ---> C\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec ---> C\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams1Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            streams1Beta.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+            streams1Beta.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_STARTUP, stateTransitions2, TWO_REBALANCES_RUNNING);\n+\n+            final Set<Long> committedKeys = mkSet(0L, 1L, 2L, 3L);\n+            if (!injectError) {\n+                committedKeys.removeAll(keyFilterFirstClient);\n+            }\n+\n+            final List<KeyValue<Long, Long>> expectedCommittedResultAfterRestartFirstClient = computeExpectedResult(\n+                uncommittedInputDataBeforeFirstUpgrade\n+                    .stream()\n+                    .filter(pair -> committedKeys.contains(pair.key))\n+                    .collect(Collectors.toList()),\n+                committedState\n+            );\n+            verifyCommitted(expectedCommittedResultAfterRestartFirstClient);\n+\n+            // phase 6: (complete second batch of data; crash: let second client fail on commit)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + C\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n+            commitCounterClient1.set(0);\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade =\n+                    prepareData(15L, 20L, 0L, 1L, 2L, 3L);\n+                writeInputData(committedInputDataDuringUpgrade);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                    computeExpectedResult(committedInputDataDuringUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResult);\n+                expectedUncommittedResult.addAll(expectedCommittedResult);\n+            } else {\n+                final Set<Long> keysFirstClient = keysFromInstance(streams1Beta);\n+                final Set<Long> keysSecondClient = keysFromInstance(streams2Alpha);\n+\n+                final List<KeyValue<Long, Long>> committedInputDataAfterFirstUpgrade =\n+                    prepareData(15L, 20L, keysFirstClient.toArray(new Long[0]));\n+                writeInputData(committedInputDataAfterFirstUpgrade);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultBeforeFailure =\n+                    computeExpectedResult(committedInputDataAfterFirstUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResultBeforeFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultBeforeFailure);\n+\n+                commitCounterClient2.set(0);\n+\n+                final Iterator<Long> it = keysSecondClient.iterator();\n+                final Long otherKey = it.next();\n+                final Long failingKey = it.next();\n+\n+                final List<KeyValue<Long, Long>> uncommittedInputDataAfterFirstUpgrade =\n+                    prepareData(15L, 19L, keysSecondClient.toArray(new Long[0]));\n+                uncommittedInputDataAfterFirstUpgrade.addAll(prepareData(19L, 20L, otherKey));\n+                writeInputData(uncommittedInputDataAfterFirstUpgrade);\n+\n+                final Map<Long, Long> uncommittedState = new HashMap<>(committedState);\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataAfterFirstUpgrade, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                stateTransitions1.clear();\n+                stateTransitions2.clear();\n+                commitCounterClient1.set(0);\n+                commitErrorInjectedClient2.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataFailingKey = prepareData(19L, 20L, failingKey);\n+                uncommittedInputDataAfterFirstUpgrade.addAll(dataFailingKey);\n+                writeInputData(dataFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(dataFailingKey, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                waitForStateTransition(stateTransitions1, SINGLE_REBALANCE, stateTransitions2, CRASH);\n+\n+                commitErrorInjectedClient2.set(false);\n+                stateTransitions2.clear();\n+                streams2Alpha.close();\n+                waitForStateTransition(stateTransitions2, CLOSE_CRASHED);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultAfterFailure =\n+                    computeExpectedResult(uncommittedInputDataAfterFirstUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResultAfterFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultAfterFailure);\n+            }\n+\n+            // 7. only for crash case:\n+            //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+            //     7b. write third batch of input data\n+            //         * fail the first (i.e., eos-beta) client during commit\n+            //         * the eos-alpha client should not pickup the pending offsets\n+            //         * verify uncommitted and committed result\n+            //     7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n+            //\n+            // crash case:\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C ---> 10 rec + A + 10 rec + C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C ---> 10 rec + A + 10 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C ---> 10 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C ---> 10 rec + C\n+            if (!injectError) {\n+                streams2AlphaTwo = streams2Alpha;\n+            } else {\n+                // 7a restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+                commitCounterClient1.set(0);\n+                commitCounterClient2.set(-1);\n+                stateTransitions1.clear();\n+                stateTransitions2.clear();\n+                streams2AlphaTwo = getKafkaStreams(\"appDir2\", StreamsConfig.EXACTLY_ONCE);\n+                streams2AlphaTwo.setStateListener(\n+                    (newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState))\n+                );\n+                streams2AlphaTwo.start();\n+                waitForStateTransition(stateTransitions1, TWO_REBALANCES_RUNNING, stateTransitions2, TWO_REBALANCES_STARTUP);\n+\n+                // 7b. write third batch of input data\n+                final Set<Long> keysFirstClient = keysFromInstance(streams1Beta);\n+                final Set<Long> keysSecondClient = keysFromInstance(streams2AlphaTwo);\n+\n+                final List<KeyValue<Long, Long>> committedInputDataBetweenUpgrades =\n+                    prepareData(20L, 30L, keysSecondClient.toArray(new Long[0]));\n+                writeInputData(committedInputDataBetweenUpgrades);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultBeforeFailure =\n+                    computeExpectedResult(committedInputDataBetweenUpgrades, committedState);\n+                verifyCommitted(expectedCommittedResultBeforeFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultBeforeFailure);\n+\n+                commitCounterClient2.set(0);\n+\n+                final Iterator<Long> it = keysFirstClient.iterator();\n+                final Long otherKey = it.next();\n+                final Long failingKey = it.next();\n+\n+                final List<KeyValue<Long, Long>> uncommittedInputDataBetweenUpgrade =\n+                    prepareData(20L, 29L, keysFirstClient.toArray(new Long[0]));\n+                uncommittedInputDataBetweenUpgrade.addAll(prepareData(29L, 30L, otherKey));\n+                writeInputData(uncommittedInputDataBetweenUpgrade);\n+\n+                final Map<Long, Long> uncommittedState = new HashMap<>(committedState);\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataBetweenUpgrade, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                stateTransitions1.clear();\n+                stateTransitions2.clear();\n+                commitCounterClient2.set(0);\n+                commitErrorInjectedClient1.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataFailingKey = prepareData(29L, 30L, failingKey);\n+                uncommittedInputDataBetweenUpgrade.addAll(dataFailingKey);\n+                writeInputData(dataFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(dataFailingKey, uncommittedState)\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                waitForStateTransition(stateTransitions1, CRASH, stateTransitions2, SINGLE_REBALANCE);\n+\n+                commitErrorInjectedClient1.set(false);\n+                stateTransitions1.clear();\n+                streams1Beta.close();\n+                waitForStateTransition(stateTransitions1, CLOSE_CRASHED);\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResultAfterFailure =\n+                    computeExpectedResult(uncommittedInputDataBetweenUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResultAfterFailure);\n+                expectedUncommittedResult.addAll(expectedCommittedResultAfterFailure);\n+\n+                // 7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n+                stateTransitions1.clear();\n+                stateTransitions2.clear();\n+                streams1BetaTwo = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+                streams1BetaTwo.setStateListener((newState, oldState) -> stateTransitions1.add(KeyValue.pair(oldState, newState)));\n+                streams1BetaTwo.start();\n+                waitForStateTransition(stateTransitions1, TWO_REBALANCES_STARTUP, stateTransitions2, TWO_REBALANCES_RUNNING);\n+            }\n+\n+            // phase 8: (write partial fourth batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C + 5 rec + C ---> 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec + C + 5 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + C ---> 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + C ---> 5 rec (pending)\n+            // crash case:  (we just assumes that we inject the error for p-2; in reality it might be a different partition)\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C ---> 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C ---> 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C ---> 4 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C ---> 5 rec (pending)\n+            cleanKeys.addAll(mkSet(0L, 1L, 2L, 3L));\n+            final Set<Long> keyFilterSecondClient = keysFromInstance(streams2AlphaTwo);\n+            final long potentiallySecondFailingKey = keyFilterSecondClient.iterator().next();\n+            cleanKeys.remove(potentiallySecondFailingKey);\n+\n+            final List<KeyValue<Long, Long>> uncommittedInputDataBeforeSecondUpgrade = new LinkedList<>();\n+            if (!injectError) {\n+                uncommittedInputDataBeforeSecondUpgrade.addAll(\n+                    prepareData(30L, 35L, 0L, 1L, 2L, 3L)\n+                );\n+                writeInputData(uncommittedInputDataBeforeSecondUpgrade);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataBeforeSecondUpgrade, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            } else {\n+                final List<KeyValue<Long, Long>> uncommittedInputDataWithoutFailingKey = new LinkedList<>();\n+                for (final long key : cleanKeys) {\n+                    uncommittedInputDataWithoutFailingKey.addAll(prepareData(30L, 35L, key));\n+                }\n+                uncommittedInputDataWithoutFailingKey.addAll(\n+                    prepareData(30L, 34L, potentiallySecondFailingKey)\n+                );\n+                uncommittedInputDataBeforeSecondUpgrade.addAll(uncommittedInputDataWithoutFailingKey);\n+                writeInputData(uncommittedInputDataWithoutFailingKey);\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(uncommittedInputDataWithoutFailingKey, new HashMap<>(committedState))\n+                );\n+                verifyUncommitted(expectedUncommittedResult);\n+            }\n+\n+            // phase 9: (stop/crash second client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec ---> C\n+            // crash case:  (we just assumes that we inject the error for p-2; in reality it might be a different partition)\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec (pending)\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec (pending)\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 4 rec ---> A + 5 rec (pending)\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 5 rec ---> A + 5 rec (pending)\n+            stateTransitions1.clear();\n+            if (!injectError) {\n+                stateTransitions2.clear();\n+                streams2AlphaTwo.close();\n+                waitForStateTransition(stateTransitions2, CLOSE);\n+            } else {\n+                errorInjectedClient2.set(true);\n+\n+                final List<KeyValue<Long, Long>> dataPotentiallySecondFailingKey =\n+                    prepareData(34L, 35L, potentiallySecondFailingKey);\n+                uncommittedInputDataBeforeSecondUpgrade.addAll(dataPotentiallySecondFailingKey);\n+                writeInputData(dataPotentiallySecondFailingKey);\n+            }\n+            waitForStateTransition(stateTransitions1, SINGLE_REBALANCE);\n+\n+            if (!injectError) {\n+                final List<KeyValue<Long, Long>> committedInputDataDuringSecondUpgrade =\n+                    uncommittedInputDataBeforeSecondUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterSecondClient.contains(pair.key))\n+                        .collect(Collectors.toList());\n+\n+                final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                    computeExpectedResult(committedInputDataDuringSecondUpgrade, committedState);\n+                verifyCommitted(expectedCommittedResult);\n+            } else {\n+                // retrying TX\n+                expectedUncommittedResult.addAll(computeExpectedResult(\n+                    uncommittedInputDataBeforeSecondUpgrade\n+                        .stream()\n+                        .filter(pair -> keyFilterSecondClient.contains(pair.key))\n+                        .collect(Collectors.toList()),\n+                    new HashMap<>(committedState)\n+                ));\n+                verifyUncommitted(expectedUncommittedResult);\n+\n+                errorInjectedClient2.set(false);\n+                stateTransitions2.clear();\n+                streams2AlphaTwo.close();\n+                waitForStateTransition(stateTransitions2, CLOSE_CRASHED);\n+            }\n+\n+            // phase 10: (restart second client)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // the state below indicate the case for which the \"original\" tasks of client2 are migrated back to client2\n+            // if a task \"switch\" happens, we might get additional commits (omitted in the comment for brevity)\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C\n+            // crash case:  (we just assumes that we inject the error for p-2; in reality it might be a different partition)\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec ---> C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec ---> C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 4 rec + A + 5 rec ---> C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 5 rec + A + 5 rec ---> C\n+            commitRequested.set(0);\n+            stateTransitions1.clear();\n+            stateTransitions2.clear();\n+            streams2Beta = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE_BETA);\n+            streams2Beta.setStateListener(\n+                (newState, oldState) -> stateTransitions2.add(KeyValue.pair(oldState, newState))\n+            );\n+            streams2Beta.start();\n+            waitForStateTransition(stateTransitions1, TWO_REBALANCES_RUNNING, stateTransitions2, TWO_REBALANCES_STARTUP);\n+\n+            committedKeys.addAll(mkSet(0L, 1L, 2L, 3L));\n+            if (!injectError) {\n+                committedKeys.removeAll(keyFilterSecondClient);\n+            }\n+\n+            final List<KeyValue<Long, Long>> expectedCommittedResultAfterRestartSecondClient = computeExpectedResult(\n+                uncommittedInputDataBeforeSecondUpgrade\n+                    .stream()\n+                    .filter(pair -> committedKeys.contains(pair.key))\n+                    .collect(Collectors.toList()),\n+                committedState\n+            );\n+            verifyCommitted(expectedCommittedResultAfterRestartSecondClient);\n+\n+            // phase 11: (complete fourth batch of data)\n+            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n+            //\n+            // stop case:\n+            //   p-0: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n+            // crash case:  (we just assumes that we inject the error for p-2; in reality it might be a different partition)\n+            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 4 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 5 rec + A + 5 rec + C ---> 5 rec + C\n+            commitCounterClient1.set(-1);\n+            commitCounterClient2.set(-1);\n+\n+            final List<KeyValue<Long, Long>> committedInputDataAfterUpgrade =\n+                prepareData(35L, 40L, 0L, 1L, 2L, 3L);\n+            writeInputData(committedInputDataAfterUpgrade);\n+\n+            final List<KeyValue<Long, Long>> expectedCommittedResult =\n+                computeExpectedResult(committedInputDataAfterUpgrade, committedState);\n+            verifyCommitted(expectedCommittedResult);\n+        } finally {\n+            if (streams1Alpha != null) {\n+                streams1Alpha.close();\n+            }\n+            if (streams1Beta != null) {\n+                streams1Beta.close();\n+            }\n+            if (streams1BetaTwo != null) {\n+                streams1BetaTwo.close();\n+            }\n+            if (streams2Alpha != null) {\n+                streams2Alpha.close();\n+            }\n+            if (streams2AlphaTwo != null) {\n+                streams2AlphaTwo.close();\n+            }\n+            if (streams2Beta != null) {\n+                streams2Beta.close();\n+            }\n+        }\n+    }\n+\n+    private KafkaStreams getKafkaStreams(final String appDir,\n+                                         final String processingGuarantee) {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final String[] storeNames = new String[] {storeName};\n+        final StoreBuilder<KeyValueStore<Long, Long>> storeBuilder = Stores\n+            .keyValueStoreBuilder(Stores.persistentKeyValueStore(storeName), Serdes.Long(), Serdes.Long())\n+            .withCachingEnabled();\n+\n+        builder.addStateStore(storeBuilder);\n+\n+        final KStream<Long, Long> input = builder.stream(MULTI_PARTITION_INPUT_TOPIC);\n+        input.transform(new TransformerSupplier<Long, Long, KeyValue<Long, Long>>() {\n+            @SuppressWarnings(\"unchecked\")\n+            @Override\n+            public Transformer<Long, Long, KeyValue<Long, Long>> get() {\n+                return new Transformer<Long, Long, KeyValue<Long, Long>>() {\n+                    ProcessorContext<Object, Object> context;\n+                    KeyValueStore<Long, Long> state = null;\n+                    AtomicBoolean crash;\n+                    AtomicInteger sharedCommit;\n+\n+                    @Override\n+                    public void init(final ProcessorContext<Object, Object> context) {\n+                        this.context = context;\n+                        state = (KeyValueStore<Long, Long>) context.getStateStore(storeName);\n+                        final String clientId = context.appConfigs().get(StreamsConfig.CLIENT_ID_CONFIG).toString();\n+                        if (\"appDir1\".equals(clientId)) {\n+                            crash = errorInjectedClient1;\n+                            sharedCommit = commitCounterClient1;\n+                        } else {\n+                            crash = errorInjectedClient2;\n+                            sharedCommit = commitCounterClient2;\n+                        }\n+                    }\n+\n+                    @Override\n+                    public KeyValue<Long, Long> transform(final Long key, final Long value) {\n+                        if ((value + 1) % 10 == 0) {\n+                            if (sharedCommit.get() < 0 ||\n+                                sharedCommit.incrementAndGet() == 2) {\n+\n+                                context.commit();\n+                            }\n+                            commitRequested.incrementAndGet();\n+                        }\n+\n+                        Long sum = state.get(key);\n+                        if (sum == null) {\n+                            sum = value;\n+                        } else {\n+                            sum += value;\n+                        }\n+                        state.put(key, sum);\n+                        state.flush();\n+\n+                        if (value % 10 == 4 && // potentially crash when processing 5th, 15th, or 25th record (etc.)\n+                            crash != null && crash.compareAndSet(true, false)) {\n+                            // only crash a single task\n+                            throw new RuntimeException(\"Injected test exception.\");\n+                        }\n+\n+                        return new KeyValue<>(key, state.get(key));\n+                    }\n+\n+                    @Override\n+                    public void close() { }\n+                };\n+            } }, storeNames)\n+            .to(MULTI_PARTITION_OUTPUT_TOPIC);\n+\n+        final Properties properties = new Properties();\n+        properties.put(StreamsConfig.CLIENT_ID_CONFIG, appDir);\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n+        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, Long.MAX_VALUE);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.METADATA_MAX_AGE_CONFIG), \"1000\");\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG), \"earliest\");\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG), 5 * 1000);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG), 5 * 1000 - 1);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG), MAX_POLL_INTERVAL_MS);\n+        // TODO\n+        //   if we don't use this custom partitioner the test fails for the non-error case\n+        //   unclear why -- see other TODO\n+        properties.put(StreamsConfig.producerPrefix(ProducerConfig.PARTITIONER_CLASS_CONFIG), KeyPartitioner.class);\n+        properties.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        properties.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath() + File.separator + appDir);\n+\n+        final Properties config = StreamsTestUtils.getStreamsConfig(\n+            applicationId,\n+            CLUSTER.bootstrapServers(),\n+            Serdes.LongSerde.class.getName(),\n+            Serdes.LongSerde.class.getName(),\n+            properties\n+        );\n+\n+        final KafkaStreams streams = new KafkaStreams(builder.build(), config, new TestKafkaClientSupplier());\n+\n+        streams.setUncaughtExceptionHandler((t, e) -> {\n+            if (uncaughtException != null) {\n+                e.printStackTrace(System.err);\n+                fail(\"Should only get one uncaught exception from Streams.\");\n+            }\n+            uncaughtException = e;\n+        });\n+\n+        return streams;\n+    }\n+\n+    private void waitForStateTransition(final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> observed,\n+                                        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> expected)\n+        throws Exception {\n+\n+        try {\n+            waitForCondition(\n+                () -> observed.equals(expected),\n+                MAX_WAIT_TIME_MS,\n+                \"Client did not startup on time.\"\n+            );\n+        } catch (final AssertionError error) {\n+            final AssertionError newError = new AssertionError(\"Client transitions: \" + observed);\n+            newError.addSuppressed(error);\n+            throw newError;\n+        }\n+    }\n+\n+    private void waitForStateTransition(final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> observed1,\n+                                        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> expected1,\n+                                        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> observed2,\n+                                        final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> expected2)\n+        throws Exception {\n+\n+        try {\n+            waitForCondition(\n+                () -> observed1.equals(expected1) && observed2.equals(expected2),\n+                MAX_WAIT_TIME_MS,\n+                \"Clients did not startup and stabilize on time.\"\n+            );\n+        } catch (final AssertionError error) {\n+            final AssertionError newError = new AssertionError(\"Client transitions: \" +\n+                \"\\n  client-1 transitions: \" + observed1 +\n+                \"\\n  client-2 transitions: \" + observed2);\n+            newError.addSuppressed(error);\n+            throw newError;\n+        }\n+    }\n+\n+    private List<KeyValue<Long, Long>> prepareData(final long fromInclusive,\n+                                                   final long toExclusive,\n+                                                   final Long... keys) {\n+        final List<KeyValue<Long, Long>> data = new ArrayList<>();\n+\n+        for (final Long k : keys) {\n+            for (long v = fromInclusive; v < toExclusive; ++v) {\n+                data.add(new KeyValue<>(k, v));\n+            }\n+        }\n+\n+        return data;\n+    }\n+\n+    private void writeInputData(final List<KeyValue<Long, Long>> records) {\n+        final Properties config = TestUtils.producerConfig(\n+            CLUSTER.bootstrapServers(),\n+            LongSerializer.class,\n+            LongSerializer.class\n+        );\n+        config.setProperty(ProducerConfig.PARTITIONER_CLASS_CONFIG, KeyPartitioner.class.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 971}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzNzY2MjA3", "url": "https://github.com/apache/kafka/pull/8496#pullrequestreview-403766207", "createdAt": "2020-04-30T18:18:04Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQxODoxODowNFrOGO0_Ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQxODoyNToxNVrOGO1O5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIwMTM5OA==", "bodyText": "nit: Could you add the original comment explaining why we set it to smaller value too?", "url": "https://github.com/apache/kafka/pull/8496#discussion_r418201398", "createdAt": "2020-04-30T18:18:04Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -838,6 +838,7 @@\n     static {\n         final Map<String, Object> tempProducerDefaultOverrides = new HashMap<>();\n         tempProducerDefaultOverrides.put(ProducerConfig.LINGER_MS_CONFIG, \"100\");\n+        tempProducerDefaultOverrides.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, 10000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIwNTQxMw==", "bodyText": "Hmm, this sounds to me that the StreamProducer's own partitionsFor did not return the num.partitions so we ended up calling send with partition == null, since otherwise we will get the partition as\npartition = partitioner.partition(topic, key, value, partitions.size());\n\nwhere partitioner is the StreamsPartitioner and the producer's own partitioner should not be used.", "url": "https://github.com/apache/kafka/pull/8496#discussion_r418205413", "createdAt": "2020-04-30T18:25:15Z", "author": {"login": "guozhangwang"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -1064,14 +1071,16 @@ private void addAllKeys(final Set<Long> allKeys, final List<KeyValue<Long, Long>\n \n     // must be public to allow KafkaProducer to instantiate it\n     public static class KeyPartitioner implements Partitioner {\n+        private final static LongDeserializer LONG_DESERIALIZER = new LongDeserializer();\n+\n         @Override\n         public int partition(final String topic,\n                              final Object key,\n                              final byte[] keyBytes,\n                              final Object value,\n                              final byte[] valueBytes,\n                              final Cluster cluster) {\n-            return ((Long) key).intValue() % NUM_TOPIC_PARTITIONS;\n+            return LONG_DESERIALIZER.deserialize(topic, keyBytes).intValue() % NUM_TOPIC_PARTITIONS;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzczODM3MQ=="}, "originalCommit": null, "originalPosition": 53}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "969512eae43ef042f7d1ebc7c2b2562e5e9ed145", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/969512eae43ef042f7d1ebc7c2b2562e5e9ed145", "committedDate": "2020-05-01T21:35:25Z", "message": "KAFKA-9748: Add Streams eos-beta integration test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0acaa580b03b48de1466668f7fd14647b5e11961", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/0acaa580b03b48de1466668f7fd14647b5e11961", "committedDate": "2020-05-01T21:35:25Z", "message": "Fix for unclear issue..."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "603f4f44ac6b5c29f3f6326c67c9b0c1e5c31946", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/603f4f44ac6b5c29f3f6326c67c9b0c1e5c31946", "committedDate": "2020-05-01T21:35:25Z", "message": "cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ee531024576de2f499479a86c88ef5553cab986", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/9ee531024576de2f499479a86c88ef5553cab986", "committedDate": "2020-05-01T21:35:25Z", "message": "Github comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "346c7b4fe34cf6870cd6f6d28365d10ef39a141d", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/346c7b4fe34cf6870cd6f6d28365d10ef39a141d", "committedDate": "2020-05-01T21:39:33Z", "message": "simplify error handling"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "346c7b4fe34cf6870cd6f6d28365d10ef39a141d", "author": {"user": {"login": "mjsax", "name": "Matthias J. Sax"}}, "url": "https://github.com/apache/kafka/commit/346c7b4fe34cf6870cd6f6d28365d10ef39a141d", "committedDate": "2020-05-01T21:39:33Z", "message": "simplify error handling"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1535, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}