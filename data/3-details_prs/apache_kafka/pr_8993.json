{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ2MzE3NDAx", "number": 8993, "title": "KAFKA-10173: Use SmokeTest for upgrade system tests (#8938)", "bodyText": "Replaces the previous upgrade test's trivial Streams app\nwith the commonly used SmokeTest, exercising many more\nfeatures. Also adjust the test matrix to test upgrading\nfrom each released version since 2.0 to the current branch.\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-07-08T15:25:10Z", "url": "https://github.com/apache/kafka/pull/8993", "merged": true, "mergeCommit": {"oid": "2601c67203e50e5ac066c5e62e9e6e51faef6e07"}, "closed": true, "closedAt": "2020-07-31T16:28:50Z", "author": {"login": "vvcephei"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcy8gB1gFqTQ0NDg4MzU1NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABczsgFKgFqTQ0Njc1MjgxNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ0ODgzNTU1", "url": "https://github.com/apache/kafka/pull/8993#pullrequestreview-444883555", "createdAt": "2020-07-08T15:30:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxNTozMDoxNVrOGutlgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxNTo0ODoyN1rOGuuVng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYzNDU2Mg==", "bodyText": "I realized this just now. We really should test upgrading from 2.5.0 to 2.5.1, and similar for every bugfix release. In other words, we should add/update \"LATEST_X_Y\" to the test matrix of the X.Y branch after each release.", "url": "https://github.com/apache/kafka/pull/8993#discussion_r451634562", "createdAt": "2020-07-08T15:30:15Z", "author": {"login": "vvcephei"}, "path": "build.gradle", "diffHunk": "@@ -1508,6 +1508,18 @@ project(':streams:upgrade-system-tests-24') {\n   }\n }\n \n+project(':streams:upgrade-system-tests-25') {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYzNTc1OA==", "bodyText": "I'm not sure exactly what it was, but the integration test was failing after the (backported) change to move the property definitions into python. I'll send a new PR to trunk to add these configs to the integration test, just in case not having them is a source of flakiness.", "url": "https://github.com/apache/kafka/pull/8993#discussion_r451635758", "createdAt": "2020-07-08T15:31:58Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/SmokeTestDriverIntegrationTest.java", "diffHunk": "@@ -92,6 +94,13 @@ public void shouldWorkWithRebalance() throws InterruptedException {\n \n         final Properties props = new Properties();\n         props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n+        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 3);\n+        props.put(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, 2);\n+        props.put(StreamsConfig.BUFFERED_RECORDS_PER_PARTITION_CONFIG, 100);\n+        props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 1000);\n+        props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 3);\n+        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        props.put(ProducerConfig.ACKS_CONFIG, \"all\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0MDkzNA==", "bodyText": "For 2.0, I had to make a few changes to the app:\n\nConvert the \"Duration\" APIs to the equivalent \"long\" or \"TimeUnit\" APIs in 2.0\nDrop the suppress/grace/retention features. This technically breaks the application upgrade, because of the topology numbering clashes, but since we're not verifying the results, the tests pass anyway. Realistically, a real person would do the upgrade first and then add suppression in a separate upgrade, in conjunction with an app reset. Or, following the upgrade guide, they would name the suppression nodes. I'd like to defer simulating this until we add validation to this test. Since it passes right now anyway, there's really no way to tell if any further compatibility work I might do now is actually functioning properly.", "url": "https://github.com/apache/kafka/pull/8993#discussion_r451640934", "createdAt": "2020-07-08T15:39:35Z", "author": {"login": "vvcephei"}, "path": "streams/upgrade-system-tests-20/src/test/java/org/apache/kafka/streams/tests/SmokeTestClient.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.tests;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.common.utils.KafkaThread;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.KGroupedStream;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Produced;\n+import org.apache.kafka.streams.kstream.Serialized;\n+import org.apache.kafka.streams.kstream.TimeWindows;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.state.Stores;\n+import org.apache.kafka.streams.state.WindowStore;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.time.Instant;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+public class SmokeTestClient extends SmokeTestUtil {\n+\n+    public static final int ONE_DAY = 24 * 60 * 60 * 1000;\n+    public static final long TWO_DAYS = 2L * ONE_DAY;\n+    private final String name;\n+\n+    private KafkaStreams streams;\n+    private boolean uncaughtException = false;\n+    private boolean started;\n+    private volatile boolean closed;\n+\n+    private static void addShutdownHook(final String name, final Runnable runnable) {\n+        if (name != null) {\n+            Runtime.getRuntime().addShutdownHook(KafkaThread.nonDaemon(name, runnable));\n+        } else {\n+            Runtime.getRuntime().addShutdownHook(new Thread(runnable));\n+        }\n+    }\n+\n+    private static File tempDirectory() {\n+        final String prefix = \"kafka-\";\n+        final File file;\n+        try {\n+            file = Files.createTempDirectory(prefix).toFile();\n+        } catch (final IOException ex) {\n+            throw new RuntimeException(\"Failed to create a temp dir\", ex);\n+        }\n+        file.deleteOnExit();\n+\n+        addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n+            try {\n+                Utils.delete(file);\n+            } catch (final IOException e) {\n+                System.out.println(\"Error deleting \" + file.getAbsolutePath());\n+                e.printStackTrace(System.out);\n+            }\n+        });\n+\n+        return file;\n+    }\n+\n+    public SmokeTestClient(final String name) {\n+        this.name = name;\n+    }\n+\n+    public boolean started() {\n+        return started;\n+    }\n+\n+    public boolean closed() {\n+        return closed;\n+    }\n+\n+    public void start(final Properties streamsProperties) {\n+        final Topology build = getTopology();\n+        streams = new KafkaStreams(build, getStreamsConfig(streamsProperties));\n+\n+        final CountDownLatch countDownLatch = new CountDownLatch(1);\n+        streams.setStateListener((newState, oldState) -> {\n+            System.out.printf(\"%s %s: %s -> %s%n\", name, Instant.now(), oldState, newState);\n+            if (oldState == KafkaStreams.State.REBALANCING && newState == KafkaStreams.State.RUNNING) {\n+                started = true;\n+                countDownLatch.countDown();\n+            }\n+\n+            if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                closed = true;\n+            }\n+        });\n+\n+        streams.setUncaughtExceptionHandler((t, e) -> {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+            System.out.println(name + \": FATAL: An unexpected exception is encountered on thread \" + t + \": \" + e);\n+            e.printStackTrace(System.out);\n+            uncaughtException = true;\n+            streams.close(30, TimeUnit.SECONDS);\n+        });\n+\n+        addShutdownHook(\"streams-shutdown-hook\", this::close);\n+\n+        streams.start();\n+        try {\n+            if (!countDownLatch.await(1, TimeUnit.MINUTES)) {\n+                System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't start in one minute\");\n+            }\n+        } catch (final InterruptedException e) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: \" + e);\n+            e.printStackTrace(System.out);\n+        }\n+        System.out.println(name + \": SMOKE-TEST-CLIENT-STARTED\");\n+        System.out.println(name + \" started at \" + Instant.now());\n+    }\n+\n+    public void close() {\n+        final boolean closed = streams.close(1, TimeUnit.MINUTES);\n+\n+        if (closed && !uncaughtException) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-CLOSED\");\n+        } else if (closed) {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION\");\n+        } else {\n+            System.out.println(name + \": SMOKE-TEST-CLIENT-EXCEPTION: Didn't close\");\n+        }\n+    }\n+\n+    private Properties getStreamsConfig(final Properties props) {\n+        final Properties fullProps = new Properties(props);\n+        fullProps.put(StreamsConfig.APPLICATION_ID_CONFIG, \"SmokeTest\");\n+        fullProps.put(StreamsConfig.CLIENT_ID_CONFIG, \"SmokeTest-\" + name);\n+        fullProps.put(StreamsConfig.STATE_DIR_CONFIG, tempDirectory().getAbsolutePath());\n+        fullProps.putAll(props);\n+        return fullProps;\n+    }\n+\n+    public Topology getTopology() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0NDEyNA==", "bodyText": "Note, in 2.5, I was able to add 2.0 and 2.1 to the upgrade matrix. This means we did break upgradability from anything 2.1- to 2.6+ in the 2.6 release. People would have to upgrade to 2.5 first and then upgrade to 2.6.\nShould we block the release and fix this for 2.6.0?", "url": "https://github.com/apache/kafka/pull/8993#discussion_r451644124", "createdAt": "2020-07-08T15:44:24Z", "author": {"login": "vvcephei"}, "path": "tests/kafkatest/tests/streams/streams_application_upgrade_test.py", "diffHunk": "@@ -0,0 +1,297 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import random\n+from ducktape.mark import matrix\n+from ducktape.tests.test import Test\n+from ducktape.utils.util import wait_until\n+from kafkatest.services.kafka import KafkaService\n+from kafkatest.services.streams import StreamsSmokeTestDriverService, StreamsSmokeTestJobRunnerService\n+from kafkatest.services.zookeeper import ZookeeperService\n+from kafkatest.version import LATEST_2_0, LATEST_2_1, LATEST_2_2, LATEST_2_3, LATEST_2_4, LATEST_2_5, DEV_VERSION, KafkaVersion\n+\n+smoke_test_versions = [str(LATEST_2_0), str(LATEST_2_1), str(LATEST_2_2), str(LATEST_2_3), str(LATEST_2_4), str(LATEST_2_5)]", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0Njg3OA==", "bodyText": "I had to take this out to make the upgrade test pass. The problem was that after upgrading, not all the instances would get a task for the input topic (data). When an instance has only to process repartition topics, it doesn't have very high throughput, and wouldn't even see 100 records in a partition before the test timed out and failed, since it never saw the \"processed\" message in stdout.\nThis is mildly concerning, but since this is a new mode of operation for this test, and since people have been complaining for a while about skewed assignments in 2.5 and before, I think we can just accept it in older branches.\nTo clarify, by removing this condition, we print to stdout on every record we process, so when an instance only has the min repartition topic, for example, it'll still print something, even if it only gets two records to process within the time limit.", "url": "https://github.com/apache/kafka/pull/8993#discussion_r451646878", "createdAt": "2020-07-08T15:48:27Z", "author": {"login": "vvcephei"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestUtil.java", "diffHunk": "@@ -45,21 +47,48 @@\n             public Processor<Object, Object> get() {\n                 return new AbstractProcessor<Object, Object>() {\n                     private int numRecordsProcessed = 0;\n+                    private long smallestOffset = Long.MAX_VALUE;\n+                    private long largestOffset = Long.MIN_VALUE;\n \n                     @Override\n                     public void init(final ProcessorContext context) {\n                         super.init(context);\n+                        LOG.info(\"[DEV] initializing processor: topic=\" + topic + \" taskId=\" + context.taskId());\n                         System.out.println(\"[DEV] initializing processor: topic=\" + topic + \" taskId=\" + context.taskId());\n+                        System.out.flush();\n                         numRecordsProcessed = 0;\n+                        smallestOffset = Long.MAX_VALUE;\n+                        largestOffset = Long.MIN_VALUE;\n                     }\n \n                     @Override\n                     public void process(final Object key, final Object value) {\n                         numRecordsProcessed++;\n-                        if (numRecordsProcessed % 100 == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c87801aa970f960a9c072fbc03b2a2d2a19d7a30", "author": {"user": null}, "url": "https://github.com/apache/kafka/commit/c87801aa970f960a9c072fbc03b2a2d2a19d7a30", "committedDate": "2020-07-10T14:57:21Z", "message": "KAFKA-10173: Use SmokeTest for upgrade system tests (#8938)\n\nReplaces the previous upgrade test's trivial Streams app\nwith the commonly used SmokeTest, exercising many more\nfeatures. Also adjust the test matrix to test upgrading\nfrom each released version since 2.0 to the current branch."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzUyODE2", "url": "https://github.com/apache/kafka/pull/8993#pullrequestreview-446752816", "createdAt": "2020-07-10T23:47:05Z", "commit": {"oid": "c87801aa970f960a9c072fbc03b2a2d2a19d7a30"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1199, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}