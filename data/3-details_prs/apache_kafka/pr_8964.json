{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQyNDE1MDMw", "number": 8964, "title": "KAFKA-9450: Decouple flushing state from commiting", "bodyText": "In Kafka Streams the source-of-truth of a state store is in its changelog, therefore when committing a state store we only need to make sure its changelog records are all flushed and committed, but we do not actually need to make sure that the materialized state have to be flushed and persisted since they can always be restored from changelog when necessary.\nOn the other hand, flushing a state store too frequently may have side effects, e.g. rocksDB flushing would gets the memtable into an L0 sstable, leaving many small L0 files to be compacted later, which introduces larger overhead.\nTherefore this PR decouples flushing from committing, such that we do not always flush the state store upon committing, but only when sufficient data has been written since last time flushed. The checkpoint file would then also be overwritten only along with flushing the state store indicating its current known snapshot. This is okay since: a) if EOS is not enabled, then it is fine if the local persisted state is actually ahead of the checkpoint, b) if EOS is enabled, then we would never write a checkpoint file until close.\nHere's a more detailed change list of this PR:\n\n\nDo not always flush state stores when calling pre-commit; move stateMgr.flush into post-commit to couple together with checkpointing.\n\n\nIn post-commit, we checkpoint when: a) The state store's snapshot has progressed much further compared to the previous checkpoint, b) When the task is being closed (but as a minor optimization, we would avoid checkpointing on closing if it is exactly the same as the previous one).\n\n\nThere are some tricky obstacles that I'd have to work around in a bit hacky way: for cache / suppression buffer, we still need to flush them in pre-commit to make sure all records sent via producers, while the underlying state store should not be flushed. I've decided to introduce a new API in CachingStateStore to be triggered in pre-commit.\n\n\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-07-01T03:20:48Z", "url": "https://github.com/apache/kafka/pull/8964", "merged": true, "mergeCommit": {"oid": "7915d5e5f826a71c11e1c9183c84702410f7209a"}, "closed": true, "closedAt": "2020-08-12T03:21:42Z", "author": {"login": "guozhangwang"}, "timelineItems": {"totalCount": 40, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcwLGiygH2gAyNDQyNDE1MDMwOmE0Yzk0OWY3YTNmNDJkZDc5MjgwMzEwMGIwNjFmY2JhYjViZjk3NmQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc99pRUgH2gAyNDQyNDE1MDMwOmE0ZjIyNzI5ODYzNTdkZTljNDgwMzJkMWZkMGQ5YjE0ODJkNWE5NzQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a4c949f7a3f42dd792803100b061fcbab5bf976d", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/a4c949f7a3f42dd792803100b061fcbab5bf976d", "committedDate": "2020-06-30T01:10:33Z", "message": "first commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "36fa307009d3326153a58e702d3598eb7a73a80a", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/36fa307009d3326153a58e702d3598eb7a73a80a", "committedDate": "2020-06-30T23:21:55Z", "message": "major fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1952371dc840c3a70fe246956a1b0285b78390b1", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/1952371dc840c3a70fe246956a1b0285b78390b1", "committedDate": "2020-07-01T01:34:24Z", "message": "flush cache before commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0713dd346101eb098958619b580406b5af6517d", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/e0713dd346101eb098958619b580406b5af6517d", "committedDate": "2020-07-01T01:42:02Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/cea36626a4e104823dd81775d2efef40d96f7ea5", "committedDate": "2020-07-01T02:33:06Z", "message": "suppression buffer needs to be flushed too"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwNTIxMDc3", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-440521077", "createdAt": "2020-07-01T03:23:53Z", "commit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwMzoyMzo1M1rOGrVelg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwMzoyNTozMlrOGrVgLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA5Mzg0Ng==", "bodyText": "I'm a bit torn about this optimization to avoid double checkpointing, because on the other hand, even if we have not made any progress since loaded the checkpoint, we'd still need to make a checkpoint upon closing if we have never made one before -- and I use emptyMap as an indicator for that.\nGiven that upon suspending we are now less likely to checkpoint, the chance that we would double checkpointing (when transiting to suspended, and when transiting to closed) is smaller, and hence I'm thinking maybe I'd just remove this optimization to make the logic a bit simpler. LMK WDYT.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r448093846", "createdAt": "2020-07-01T03:23:53Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -38,13 +41,39 @@\n  */\n final class StateManagerUtil {\n     static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+    static final long OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT = 10_000L;\n \n     private StateManagerUtil() {}\n \n     static RecordConverter converterForStore(final StateStore store) {\n         return isTimestamped(store) ? rawValueToTimestampedValue() : identity();\n     }\n \n+    static boolean checkpointNeeded(final boolean enforceCheckpoint,\n+                                    final Map<TopicPartition, Long> oldOffsetSnapshot,\n+                                    final Map<TopicPartition, Long> newOffsetSnapshot) {\n+        // we should always have the old snapshot post completing the register state stores;\n+        // if it is null it means the registration is not done and hence we should not overwrite the checkpoint\n+        if (oldOffsetSnapshot == null)\n+            return false;\n+\n+        // if the previous snapshot is empty while the current snapshot is not then we should always checkpoint;\n+        // note if the task is stateless or stateful but no stores logged, the snapshot would also be empty\n+        // and hence it's okay to not checkpoint\n+        if (oldOffsetSnapshot.isEmpty() && !newOffsetSnapshot.isEmpty())\n+            return true;\n+\n+        // we can checkpoint if the the difference between the current and the previous snapshot is large enough\n+        long totalOffsetDelta = 0L;\n+        for (final Map.Entry<TopicPartition, Long> entry : newOffsetSnapshot.entrySet()) {\n+            totalOffsetDelta += Math.abs(oldOffsetSnapshot.getOrDefault(entry.getKey(), 0L) - entry.getValue());\n+        }\n+\n+        // when enforcing checkpoint is required, we should overwrite the checkpoint if it is different from the old one;\n+        // otherwise, we only overwrite the checkpoint if it is largely different from the old one\n+        return enforceCheckpoint ? totalOffsetDelta > 0 : totalOffsetDelta > OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA5NDI1NA==", "bodyText": "I decided to extract out the update of the changelog offsets from actually writing the offsets since even if we do not want to write the file, we still need to update the offsets.\nThe reason I did not yet remove the parameter from checkpoint is that global-task is still using it. I plan to remove it when consolidating the global task.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r448094254", "createdAt": "2020-07-01T03:25:32Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -542,13 +530,22 @@ public void closeCleanAndRecycleState() {\n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    private void writeCheckpoint() {\n+    /**\n+     * The following exceptions maybe thrown from the state manager flushing call\n+     *\n+     * @throws TaskMigratedException recoverable error sending changelog records that would cause the task to be removed\n+     * @throws StreamsException fatal error when flushing the state store, for example sending changelog records failed\n+     *                          or flushing state store get IO errors; such error should cause the thread to die\n+     */\n+    @Override\n+    protected void maybeWriteCheckpoint(final boolean enforceCheckpoint) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "originalPosition": 177}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxMjgyMjI0", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-441282224", "createdAt": "2020-07-02T00:55:05Z", "commit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMDo1NTowNVrOGr53Zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMDo1NTowNVrOGr53Zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY5MDAyMg==", "bodyText": "Inspired by https://github.com/apache/kafka/pull/8962/files#diff-f0037ae2fd44bdd0d84f3ef37b43bc05R277, I think we should actually enforce checkpoint (i.e. set to true) when suspending since the suspended task may not be closed but recycled. cc @ableegoldman\nI will push a new commit changing to true.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r448690022", "createdAt": "2020-07-02T00:55:05Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -478,9 +479,11 @@ void handleRevocation(final Collection<TopicPartition> revokedPartitions) {\n \n         commitOffsetsOrTransaction(consumedOffsetsAndMetadataPerTask);\n \n+        // We do not need to enforce checkpointing upon suspending a task: if it is resumed later we just\n+        // proceed normally; if it is closed we would checkpoint then\n         for (final Task task : revokedTasks) {\n             try {\n-                task.postCommit();\n+                task.postCommit(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2158381e553706f1facbd21989eafef06d73f5b4", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/2158381e553706f1facbd21989eafef06d73f5b4", "committedDate": "2020-07-07T00:29:41Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/4394dd2316783c286d1b8c042863b558b53fdec7", "committedDate": "2020-07-07T02:20:46Z", "message": "rebased on trunk"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzNDk1MTY3", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-443495167", "createdAt": "2020-07-07T01:03:52Z", "commit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwMTowMzo1MlrOGtruSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwMjoyODowMlrOGttDJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDU1NTQ2NQ==", "bodyText": "Actually after rebased on latest trunk I think upon suspending we can still not enforcing the checkpointing, but only enforce upon closing / recycling in handleAssignment.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r450555465", "createdAt": "2020-07-07T01:03:52Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -478,9 +479,11 @@ void handleRevocation(final Collection<TopicPartition> revokedPartitions) {\n \n         commitOffsetsOrTransaction(consumedOffsetsAndMetadataPerTask);\n \n+        // We do not need to enforce checkpointing upon suspending a task: if it is resumed later we just\n+        // proceed normally; if it is closed we would checkpoint then\n         for (final Task task : revokedTasks) {\n             try {\n-                task.postCommit();\n+                task.postCommit(false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY5MDAyMg=="}, "originalCommit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDU3NjEwMw==", "bodyText": "This is just a placeholder for making less frequent flushing than commits, currently I'm making it num.records based, but it's open for better proposal to decide when flushing should be executed.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r450576103", "createdAt": "2020-07-07T02:23:55Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -38,13 +41,39 @@\n  */\n final class StateManagerUtil {\n     static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+    static final long OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT = 10_000L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDU3NzE5MQ==", "bodyText": "Admit this is kinda hacky, but I'd have to do this for cached store and suppression buffer. Moving forward I think the first can be removed when we decouple caching with emitting, but for suppression buffer maybe we can have a more general way to fix it, for example maybe we could just have changelogger to always buffer itself so that suppression buffers do not need to buffer itself to changelogger. cc @vvcephei", "url": "https://github.com/apache/kafka/pull/8964#discussion_r450577191", "createdAt": "2020-07-07T02:28:02Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -454,6 +456,41 @@ public void flush() {\n         }\n     }\n \n+    public void flushCache() {\n+        RuntimeException firstException = null;\n+        // attempting to flush the stores\n+        if (!stores.isEmpty()) {\n+            log.debug(\"Flushing all store caches registered in the state manager: {}\", stores);\n+            for (final StateStoreMetadata metadata : stores.values()) {\n+                final StateStore store = metadata.stateStore;\n+\n+                try {\n+                    // buffer should be flushed to send all records to changelog\n+                    if (store instanceof TimeOrderedKeyValueBuffer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 25}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ0MDk1ODcw", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-444095870", "createdAt": "2020-07-07T17:16:13Z", "commit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNzoxNjoxM1rOGuIJqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNzoxNjoxM1rOGuIJqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTAyMTIyNQ==", "bodyText": "As we discussed in the other PR, I'm removing the logic for TM to check on task state and replaced it with checking that there should be nothing to commit (since suspend / pre-commit / post-commit are not all idempotent).", "url": "https://github.com/apache/kafka/pull/8964#discussion_r451021225", "createdAt": "2020-07-07T17:16:13Z", "author": {"login": "guozhangwang"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -243,18 +242,24 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n \n         for (final Task task : tasksToClose) {\n             try {\n-                if (task.isActive()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyNjk1OTMz", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-452695933", "createdAt": "2020-07-21T17:52:34Z", "commit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNzo1MjozNVrOG1DVtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQyMzowMzo0N1rOG1M23g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI4MjQyMQ==", "bodyText": "nit: can you use braces here?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r458282421", "createdAt": "2020-07-21T17:52:35Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -454,6 +456,41 @@ public void flush() {\n         }\n     }\n \n+    public void flushCache() {\n+        RuntimeException firstException = null;\n+        // attempting to flush the stores\n+        if (!stores.isEmpty()) {\n+            log.debug(\"Flushing all store caches registered in the state manager: {}\", stores);\n+            for (final StateStoreMetadata metadata : stores.values()) {\n+                final StateStore store = metadata.stateStore;\n+\n+                try {\n+                    // buffer should be flushed to send all records to changelog\n+                    if (store instanceof TimeOrderedKeyValueBuffer) {\n+                        store.flush();\n+                    } else if (store instanceof CachedStateStore) {\n+                        ((CachedStateStore) store).flushCache();\n+                    }\n+                    log.trace(\"Flushed cache or buffer {}\", store.name());\n+                } catch (final RuntimeException exception) {\n+                    if (firstException == null) {\n+                        // do NOT wrap the error if it is actually caused by Streams itself\n+                        if (exception instanceof StreamsException)\n+                            firstException = exception;\n+                        else\n+                            firstException = new ProcessorStateException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI4NDgyMQ==", "bodyText": "TODO: we still need to keep it as part of the checkpoint for global tasks\n\nTook me a while to realize that \"it\" refers to the argument here -- can you clarify the comment?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r458284821", "createdAt": "2020-07-21T17:56:31Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -520,20 +557,27 @@ void transitionTaskType(final TaskType newType, final LogContext logContext) {\n         log.debug(\"Transitioning state manager for {} task {} to {}\", oldType, taskId, newType);\n     }\n \n-    @Override\n-    public void checkpoint(final Map<TopicPartition, Long> writtenOffsets) {\n-        // first update each state store's current offset, then checkpoint\n-        // those stores that are only logged and persistent to the checkpoint file\n+    void updateChangelogOffsets(final Map<TopicPartition, Long> writtenOffsets) {\n         for (final Map.Entry<TopicPartition, Long> entry : writtenOffsets.entrySet()) {\n             final StateStoreMetadata store = findStore(entry.getKey());\n \n             if (store != null) {\n                 store.setOffset(entry.getValue());\n \n                 log.debug(\"State store {} updated to written offset {} at changelog {}\",\n-                    store.stateStore.name(), store.offset, store.changelogPartition);\n+                        store.stateStore.name(), store.offset, store.changelogPartition);\n             }\n         }\n+    }\n+\n+    @Override\n+    public void checkpoint(final Map<TopicPartition, Long> writtenOffsets) {\n+        // first update each state store's current offset, then checkpoint\n+        // those stores that are only logged and persistent to the checkpoint file\n+        // TODO: we still need to keep it as part of the checkpoint for global tasks; this could be\n+        //       removed though when we consolidate global tasks / state managers into this one", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQyMTE3Ng==", "bodyText": "Happy to see this go \ud83d\ude42", "url": "https://github.com/apache/kafka/pull/8964#discussion_r458421176", "createdAt": "2020-07-21T22:18:01Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -120,14 +120,12 @@ public void suspend() {\n         switch (state()) {\n             case CREATED:\n                 log.info(\"Suspended created\");\n-                checkpointNeededForSuspended = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQyMzk0Mw==", "bodyText": "Should we add an assertion to ProcessorStateManager#checkpoint that the passed in offsets are always empty?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r458423943", "createdAt": "2020-07-21T22:24:39Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -49,6 +61,31 @@\n         this.stateDirectory = stateDirectory;\n     }\n \n+    protected void initializeCheckpoint() {\n+        // we will delete the local checkpoint file after registering the state stores and loading them into the\n+        // state manager, therefore we should initialize the snapshot as empty to indicate over-write checkpoint needed\n+        offsetSnapshotSinceLastFlush = Collections.emptyMap();\n+    }\n+\n+    /**\n+     * The following exceptions maybe thrown from the state manager flushing call\n+     *\n+     * @throws TaskMigratedException recoverable error sending changelog records that would cause the task to be removed\n+     * @throws StreamsException fatal error when flushing the state store, for example sending changelog records failed\n+     *                          or flushing state store get IO errors; such error should cause the thread to die\n+     */\n+    protected void maybeWriteCheckpoint(final boolean enforceCheckpoint) {\n+        final Map<TopicPartition, Long> offsetSnapshot = stateMgr.changelogOffsets();\n+        if (StateManagerUtil.checkpointNeeded(enforceCheckpoint, offsetSnapshotSinceLastFlush, offsetSnapshot)) {\n+            // since there's no written offsets we can checkpoint with empty map,\n+            // and the state's current offset would be used to checkpoint\n+            stateMgr.flush();\n+            stateMgr.checkpoint(Collections.emptyMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQyNTM5MQ==", "bodyText": "Was there a reason to not just add #updateChangelogOffsets to the StateManager interface and remove the checkpointable offsets argument from #checkpoint?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r458425391", "createdAt": "2020-07-21T22:28:11Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -542,13 +530,22 @@ public void closeCleanAndRecycleState() {\n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    private void writeCheckpoint() {\n+    /**\n+     * The following exceptions maybe thrown from the state manager flushing call\n+     *\n+     * @throws TaskMigratedException recoverable error sending changelog records that would cause the task to be removed\n+     * @throws StreamsException fatal error when flushing the state store, for example sending changelog records failed\n+     *                          or flushing state store get IO errors; such error should cause the thread to die\n+     */\n+    @Override\n+    protected void maybeWriteCheckpoint(final boolean enforceCheckpoint) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA5NDI1NA=="}, "originalCommit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQyODU0MA==", "bodyText": "Hm. What if we hit a TaskMigratedException during handleRevocation? We would never finish committing them so commitNeeded would still return true and prepareCommit would return non-empty offsets right?\nIt's kind of a bummer that we can't enforce that the task was committed. What we really need to do is enforce that we attempted to commit the task -- regardless of whether or not it was successful. If the commit failed we know that either it was fatal or it was due to TaskMigrated, in which case the task will have to be closed as dirty anyways.\nThis might be beyond the scope of this PR, but just to throw out one hacky idea we could add a commitSuccessful parameter to postCommit and then always invoke that after a commit so that commitNeeded is set to false. (If commitSuccessful is false we just skip everything else in postCommit)", "url": "https://github.com/apache/kafka/pull/8964#discussion_r458428540", "createdAt": "2020-07-21T22:36:10Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -243,18 +242,24 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n \n         for (final Task task : tasksToClose) {\n             try {\n-                if (task.isActive()) {\n-                    // Active tasks are revoked and suspended/committed during #handleRevocation\n-                    if (!task.state().equals(State.SUSPENDED)) {\n-                        log.error(\"Active task {} should be suspended prior to attempting to close but was in {}\",\n-                                  task.id(), task.state());\n-                        throw new IllegalStateException(\"Active task \" + task.id() + \" should have been suspended\");\n-                    }\n-                } else {\n-                    task.suspend();\n-                    task.prepareCommit();\n-                    task.postCommit();\n+                // Always try to first suspend and commit the task before closing it;\n+                // some tasks may already be suspended which should be a no-op.\n+                //\n+                // Also since active tasks should already be suspended / committed and\n+                // standby tasks should have no offsets to commit, we should expect nothing to commit\n+                task.suspend();\n+\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();\n+\n+                if (!offsets.isEmpty()) {\n+                    log.error(\"Task {} should has been committed prior to attempting to close, but it reports non-empty offsets {} to commit\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQzNTgyNA==", "bodyText": "This is also maybe beyond the scope of this PR, but it seems like there's no reason to do things like this anymore. Specifically, today we enforce the order suspend -> pre/postCommit -> close where suspend only closes the topology and we only use the SUSPENDED state to enforce that we suspended before closing. Why not swap the order so that we pre/postCommit -> suspend -> close and then we can move this call from postCommit to suspend where it makes more sense. Thoughts?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r458435824", "createdAt": "2020-07-21T22:56:13Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -466,15 +458,8 @@ public void postCommit() {\n                  */\n                 partitionGroup.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQzNjg5Mw==", "bodyText": "Is this out of date? It seems like we now never checkpoint during suspension so we don't have to bother with this optimization", "url": "https://github.com/apache/kafka/pull/8964#discussion_r458436893", "createdAt": "2020-07-21T22:59:32Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -38,13 +41,39 @@\n  */\n final class StateManagerUtil {\n     static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+    static final long OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT = 10_000L;\n \n     private StateManagerUtil() {}\n \n     static RecordConverter converterForStore(final StateStore store) {\n         return isTimestamped(store) ? rawValueToTimestampedValue() : identity();\n     }\n \n+    static boolean checkpointNeeded(final boolean enforceCheckpoint,\n+                                    final Map<TopicPartition, Long> oldOffsetSnapshot,\n+                                    final Map<TopicPartition, Long> newOffsetSnapshot) {\n+        // we should always have the old snapshot post completing the register state stores;\n+        // if it is null it means the registration is not done and hence we should not overwrite the checkpoint\n+        if (oldOffsetSnapshot == null)\n+            return false;\n+\n+        // if the previous snapshot is empty while the current snapshot is not then we should always checkpoint;\n+        // note if the task is stateless or stateful but no stores logged, the snapshot would also be empty\n+        // and hence it's okay to not checkpoint\n+        if (oldOffsetSnapshot.isEmpty() && !newOffsetSnapshot.isEmpty())\n+            return true;\n+\n+        // we can checkpoint if the the difference between the current and the previous snapshot is large enough\n+        long totalOffsetDelta = 0L;\n+        for (final Map.Entry<TopicPartition, Long> entry : newOffsetSnapshot.entrySet()) {\n+            totalOffsetDelta += Math.abs(oldOffsetSnapshot.getOrDefault(entry.getKey(), 0L) - entry.getValue());\n+        }\n+\n+        // when enforcing checkpoint is required, we should overwrite the checkpoint if it is different from the old one;\n+        // otherwise, we only overwrite the checkpoint if it is largely different from the old one\n+        return enforceCheckpoint ? totalOffsetDelta > 0 : totalOffsetDelta > OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA5Mzg0Ng=="}, "originalCommit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQzODM2Ng==", "bodyText": "Can you move this comment down a line? We should avoid confusion since we actually don't initialize the (flush) snapshot with the current offsets, just the (commit) snapshot.\nTo be honest, it's already pretty confusing that we initialize the two snapshots differently. Maybe you could add a quick sentence explaining why for our own future reference", "url": "https://github.com/apache/kafka/pull/8964#discussion_r458438366", "createdAt": "2020-07-21T23:03:47Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -93,8 +93,8 @@ public boolean isActive() {\n     public void initializeIfNeeded() {\n         if (state() == State.CREATED) {\n             StateManagerUtil.registerStateStores(log, logPrefix, topology, stateMgr, stateDirectory, processorContext);\n-\n             // initialize the snapshot with the current offsets as we don't need to commit then until they change", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 23}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8bef6e1f6289f1c34d6b77336df1abbe91c1102", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/c8bef6e1f6289f1c34d6b77336df1abbe91c1102", "committedDate": "2020-07-24T01:09:31Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b49c2a39872b7065b821e0434018ac6dc3fc8d9", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/3b49c2a39872b7065b821e0434018ac6dc3fc8d9", "committedDate": "2020-07-24T18:10:50Z", "message": "github comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9137d40e2dab98ae5b943f796ffe35ea13e5cbf0", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/9137d40e2dab98ae5b943f796ffe35ea13e5cbf0", "committedDate": "2020-07-26T23:46:21Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bae8bb5a1118aad6890c60102283ddc463f6c179", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/bae8bb5a1118aad6890c60102283ddc463f6c179", "committedDate": "2020-07-27T04:41:30Z", "message": "re-order commit and suspend"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0da4bce957cf5cb9497623b0da01328f77156424", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/0da4bce957cf5cb9497623b0da01328f77156424", "committedDate": "2020-07-27T23:13:41Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "579b141434f8d3b9bd1972ccb04a4cea74171cd0", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/579b141434f8d3b9bd1972ccb04a4cea74171cd0", "committedDate": "2020-07-27T23:21:01Z", "message": "use list not set to preserve ordering"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0dc73fe813b77130858222426eb5bc0f8ba3d35", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/c0dc73fe813b77130858222426eb5bc0f8ba3d35", "committedDate": "2020-07-29T01:15:25Z", "message": "enforce checkpoint during suspension"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4OTA0NjU0", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-458904654", "createdAt": "2020-07-31T04:10:09Z", "commit": {"oid": "c0dc73fe813b77130858222426eb5bc0f8ba3d35"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQwNDoxMDowOVrOG57ZRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQwNDoxMDowOVrOG57ZRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzM5NTE0MA==", "bodyText": "It's still making me a bit uncomfortable that we call prepare/postCommit during handleRevocation. and handleAssignment. Maybe I'm being paranoid but experience has shown it's been difficult for us to keep track of which methods need to be called when, and in what order.\nIt seems like, now that we've decoupled flushing from committing, the only reason for calling pre/postCommit in handleRevocation is so that the record collector is flushed before committing offsets. So what if we extract the record collector flushing out into a separate StreamTask method that is only ever called in TaskManager#commitOffsetsOrTransaction? I haven't thought this all the way through but it just seems like we may as well go all the way in decoupling flushing from committing and split them out into separate methods. Maybe preCommit and postCommit have become relics of the past", "url": "https://github.com/apache/kafka/pull/8964#discussion_r463395140", "createdAt": "2020-07-31T04:10:09Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +313,96 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }\n+\n+        // for all tasks to close or recycle, we should first right a checkpoint as in post-commit\n+        final List<Task> tasksToCheckpoint = new ArrayList<>(tasksToCloseClean);\n+        tasksToCheckpoint.addAll(tasksToRecycle);\n+        for (final Task task : tasksToCheckpoint) {\n+            try {\n+                // Always try to first suspend and commit the task before checkpointing it;\n+                // some tasks may already be suspended which should be a no-op.\n+                //\n+                // Also since active tasks should already be suspended / committed and\n+                // standby tasks should have no offsets to commit, we should expect nothing to commit\n+                task.suspend();\n+\n+                // Note that we are not actually committing here but just check if we need to write checkpoint file:\n+                // 1) for active tasks prepareCommit should return empty if it has committed during suspension successfully,\n+                //    and their changelog positions should not change at all postCommit would not write the checkpoint again.\n+                // 2) for standby tasks prepareCommit should always return empty, and then in postCommit we would probably\n+                //    write the checkpoint file.\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0dc73fe813b77130858222426eb5bc0f8ba3d35"}, "originalPosition": 161}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1ea8905e5259d669128e980fe84071368d2263b8", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/1ea8905e5259d669128e980fe84071368d2263b8", "committedDate": "2020-07-31T19:02:27Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b70fc0025aac54ab564f2250e50a92aa2fb65b4a", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/b70fc0025aac54ab564f2250e50a92aa2fb65b4a", "committedDate": "2020-07-31T19:23:16Z", "message": "minor tweaks"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5NTAzNzYx", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-459503761", "createdAt": "2020-07-31T22:14:01Z", "commit": {"oid": "b70fc0025aac54ab564f2250e50a92aa2fb65b4a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5NTAxOTEx", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-459501911", "createdAt": "2020-07-31T22:08:16Z", "commit": {"oid": "b70fc0025aac54ab564f2250e50a92aa2fb65b4a"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQyMjowODoxNlrOG6YM2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQyMjozNDozNlrOG6YmrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg2NzA5OA==", "bodyText": "Seems like there's the missing possibility that it's not TimeOrdered or Cached. Should we log a different message than \"Flushed cache or buffer\" in that case, to indicate we didn't flush it?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r463867098", "createdAt": "2020-07-31T22:08:16Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -461,6 +463,42 @@ public void flush() {\n         }\n     }\n \n+    public void flushCache() {\n+        RuntimeException firstException = null;\n+        // attempting to flush the stores\n+        if (!stores.isEmpty()) {\n+            log.debug(\"Flushing all store caches registered in the state manager: {}\", stores);\n+            for (final StateStoreMetadata metadata : stores.values()) {\n+                final StateStore store = metadata.stateStore;\n+\n+                try {\n+                    // buffer should be flushed to send all records to changelog\n+                    if (store instanceof TimeOrderedKeyValueBuffer) {\n+                        store.flush();\n+                    } else if (store instanceof CachedStateStore) {\n+                        ((CachedStateStore) store).flushCache();\n+                    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b70fc0025aac54ab564f2250e50a92aa2fb65b4a"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg3MDA2Mg==", "bodyText": "What's the rationale for subtracting the larger value from the smaller one and then taking the absolute value?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r463870062", "createdAt": "2020-07-31T22:19:25Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -38,13 +41,39 @@\n  */\n final class StateManagerUtil {\n     static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+    static final long OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT = 10_000L;\n \n     private StateManagerUtil() {}\n \n     static RecordConverter converterForStore(final StateStore store) {\n         return isTimestamped(store) ? rawValueToTimestampedValue() : identity();\n     }\n \n+    static boolean checkpointNeeded(final boolean enforceCheckpoint,\n+                                    final Map<TopicPartition, Long> oldOffsetSnapshot,\n+                                    final Map<TopicPartition, Long> newOffsetSnapshot) {\n+        // we should always have the old snapshot post completing the register state stores;\n+        // if it is null it means the registration is not done and hence we should not overwrite the checkpoint\n+        if (oldOffsetSnapshot == null)\n+            return false;\n+\n+        // if the previous snapshot is empty while the current snapshot is not then we should always checkpoint;\n+        // note if the task is stateless or stateful but no stores logged, the snapshot would also be empty\n+        // and hence it's okay to not checkpoint\n+        if (oldOffsetSnapshot.isEmpty() && !newOffsetSnapshot.isEmpty())\n+            return true;\n+\n+        // we can checkpoint if the the difference between the current and the previous snapshot is large enough\n+        long totalOffsetDelta = 0L;\n+        for (final Map.Entry<TopicPartition, Long> entry : newOffsetSnapshot.entrySet()) {\n+            totalOffsetDelta += Math.abs(oldOffsetSnapshot.getOrDefault(entry.getKey(), 0L) - entry.getValue());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b70fc0025aac54ab564f2250e50a92aa2fb65b4a"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg3MzcwOA==", "bodyText": "It seems a little odd to have handleCloseAndRecycle not do this but just update the taskToCloseDirty list, since it handles everything else.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r463873708", "createdAt": "2020-07-31T22:34:36Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -267,80 +266,26 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 // check for tasks that were owned previously but have changed active/standby status\n                 tasksToRecycle.add(task);\n             } else {\n-                tasksToClose.add(task);\n-            }\n-        }\n-\n-        for (final Task task : tasksToClose) {\n-            try {\n-                if (task.isActive()) {\n-                    // Active tasks are revoked and suspended/committed during #handleRevocation\n-                    if (!task.state().equals(State.SUSPENDED)) {\n-                        log.error(\"Active task {} should be suspended prior to attempting to close but was in {}\",\n-                                  task.id(), task.state());\n-                        throw new IllegalStateException(\"Active task \" + task.id() + \" should have been suspended\");\n-                    }\n-                } else {\n-                    task.suspend();\n-                    task.prepareCommit();\n-                    task.postCommit();\n-                }\n-                completeTaskCloseClean(task);\n-                cleanUpTaskProducer(task, taskCloseExceptions);\n-                tasks.remove(task.id());\n-            } catch (final RuntimeException e) {\n-                final String uncleanMessage = String.format(\n-                    \"Failed to close task %s cleanly. Attempting to close remaining tasks before re-throwing:\",\n-                    task.id());\n-                log.error(uncleanMessage, e);\n-                taskCloseExceptions.put(task.id(), e);\n-                // We've already recorded the exception (which is the point of clean).\n-                // Now, we should go ahead and complete the close because a half-closed task is no good to anyone.\n-                dirtyTasks.add(task);\n+                tasksToCloseClean.add(task);\n             }\n         }\n \n-        for (final Task oldTask : tasksToRecycle) {\n-            final Task newTask;\n-            try {\n-                if (oldTask.isActive()) {\n-                    if (!oldTask.state().equals(State.SUSPENDED)) {\n-                        // Active tasks are revoked and suspended/committed during #handleRevocation\n-                        log.error(\"Active task {} should be suspended prior to attempting to close but was in {}\",\n-                                  oldTask.id(), oldTask.state());\n-                        throw new IllegalStateException(\"Active task \" + oldTask.id() + \" should have been suspended\");\n-                    }\n-                    final Set<TopicPartition> partitions = standbyTasksToCreate.remove(oldTask.id());\n-                    newTask = standbyTaskCreator.createStandbyTaskFromActive((StreamTask) oldTask, partitions);\n-                    cleanUpTaskProducer(oldTask, taskCloseExceptions);\n-                } else {\n-                    oldTask.suspend();\n-                    oldTask.prepareCommit();\n-                    oldTask.postCommit();\n-                    final Set<TopicPartition> partitions = activeTasksToCreate.remove(oldTask.id());\n-                    newTask = activeTaskCreator.createActiveTaskFromStandby((StandbyTask) oldTask, partitions, mainConsumer);\n-                }\n-                tasks.remove(oldTask.id());\n-                addNewTask(newTask);\n-            } catch (final RuntimeException e) {\n-                final String uncleanMessage = String.format(\"Failed to recycle task %s cleanly. Attempting to close remaining tasks before re-throwing:\", oldTask.id());\n-                log.error(uncleanMessage, e);\n-                taskCloseExceptions.put(oldTask.id(), e);\n-                dirtyTasks.add(oldTask);\n-            }\n-        }\n+        // close and recycle those tasks\n+        handleCloseAndRecycle(tasksToRecycle, tasksToCloseClean, tasksToCloseDirty, activeTasksToCreate, standbyTasksToCreate, taskCloseExceptions);\n \n-        for (final Task task : dirtyTasks) {\n+        // for tasks that cannot be cleanly closed or recycled, close them dirty\n+        for (final Task task : tasksToCloseDirty) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b70fc0025aac54ab564f2250e50a92aa2fb65b4a"}, "originalPosition": 102}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c632c3dc2581a13dd882ebc293313f9438cba339", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/c632c3dc2581a13dd882ebc293313f9438cba339", "committedDate": "2020-08-03T21:51:57Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "906e067af14301919758243c7666e54830633a71", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/906e067af14301919758243c7666e54830633a71", "committedDate": "2020-08-03T23:01:27Z", "message": "github comment, plus a fix for system test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e9b54624fd831b6affb13d45279b96804b91010", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/4e9b54624fd831b6affb13d45279b96804b91010", "committedDate": "2020-08-04T04:31:24Z", "message": "fix unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "19b10055fdaf04ebe7b8434741afc3c1a21440bb", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/19b10055fdaf04ebe7b8434741afc3c1a21440bb", "committedDate": "2020-08-04T05:09:28Z", "message": "improved eos test driver"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6f2d692434a556dcdcf91b38e593138a8a334513", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/6f2d692434a556dcdcf91b38e593138a8a334513", "committedDate": "2020-08-04T06:31:39Z", "message": "minor fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f463d8f368f8dd2a81d25a2c64c308151216bc96", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/f463d8f368f8dd2a81d25a2c64c308151216bc96", "committedDate": "2020-08-04T17:06:26Z", "message": "tweak unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "335a3459aac9b3b4df825786cef0f30c214210a8", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/335a3459aac9b3b4df825786cef0f30c214210a8", "committedDate": "2020-08-04T22:06:43Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "122ff1d0bc85a25e40c526ecdf10dbf985560e98", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/122ff1d0bc85a25e40c526ecdf10dbf985560e98", "committedDate": "2020-08-04T23:53:20Z", "message": "commit first then suspend in closing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "913031f247f0591bba4b5dc4c9e8b664d7298fa5", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/913031f247f0591bba4b5dc4c9e8b664d7298fa5", "committedDate": "2020-08-04T23:58:18Z", "message": "first commit then suspend in closing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/aa95e1367eb31660a156eb484e2d455ca35029a1", "committedDate": "2020-08-05T16:52:02Z", "message": "remove debugging info"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYyMDc5NDU2", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-462079456", "createdAt": "2020-08-05T22:59:14Z", "commit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "state": "COMMENTED", "comments": {"totalCount": 28, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQyMjo1OToxNVrOG8dadg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMDoyNTo1OVrOG8fA8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA0OTY1NA==", "bodyText": "Why do we actually delete the checkpoint file after registering? For non-eos, it seems we only need to delete the checkopint file if we wipe out the whole store?\nOr is it a \"simplification\" do not distinguish between eos/non-eos for this case?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466049654", "createdAt": "2020-08-05T22:59:15Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -49,6 +61,30 @@\n         this.stateDirectory = stateDirectory;\n     }\n \n+    protected void initializeCheckpoint() {\n+        // we will delete the local checkpoint file after registering the state stores and loading them into the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA1MTk5MQ==", "bodyText": "I agree. IMHO, we should get rid of KTable/store cache all together and only have a \"changelog-writer-cache\" that regular stores and suppress() can use to reduce the write load on the changelog topic. For downstream rate control, users should use suppress() (and we might want to try to unify suppress() and the upstream store somehow eventually to avoid the current redundancy)", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466051991", "createdAt": "2020-08-05T23:06:22Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -454,6 +456,41 @@ public void flush() {\n         }\n     }\n \n+    public void flushCache() {\n+        RuntimeException firstException = null;\n+        // attempting to flush the stores\n+        if (!stores.isEmpty()) {\n+            log.debug(\"Flushing all store caches registered in the state manager: {}\", stores);\n+            for (final StateStoreMetadata metadata : stores.values()) {\n+                final StateStore store = metadata.stateStore;\n+\n+                try {\n+                    // buffer should be flushed to send all records to changelog\n+                    if (store instanceof TimeOrderedKeyValueBuffer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDU3NzE5MQ=="}, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA1NjIzNQ==", "bodyText": "Nit: add { }", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466056235", "createdAt": "2020-08-05T23:19:27Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java", "diffHunk": "@@ -390,9 +399,12 @@ private static void verifyReceivedAllRecords(final Map<TopicPartition, List<Cons\n                 final int expectedValue = integerDeserializer.deserialize(expected.topic(), expected.value());\n \n                 if (!receivedKey.equals(expectedKey) || receivedValue != expectedValue) {\n-                    throw new RuntimeException(\"Result verification failed for \" + receivedRecord + \" expected <\" + expectedKey + \",\" + expectedValue + \"> but was <\" + receivedKey + \",\" + receivedValue + \">\");\n+                    exception = new RuntimeException(\"Result verification failed for \" + receivedRecord + \" expected <\" + expectedKey + \",\" + expectedValue + \"> but was <\" + receivedKey + \",\" + receivedValue + \">\");\n                 }\n             }\n+\n+            if (exception != null)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA1NjQ4MQ==", "bodyText": "Nit: add { }", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466056481", "createdAt": "2020-08-05T23:20:12Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java", "diffHunk": "@@ -379,9 +379,18 @@ private static void verifyReceivedAllRecords(final Map<TopicPartition, List<Cons\n         final IntegerDeserializer integerDeserializer = new IntegerDeserializer();\n         for (final Map.Entry<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> partitionRecords : receivedRecords.entrySet()) {\n             final TopicPartition inputTopicPartition = new TopicPartition(\"data\", partitionRecords.getKey().partition());\n-            final Iterator<ConsumerRecord<byte[], byte[]>> expectedRecord = expectedRecords.get(inputTopicPartition).iterator();\n+            final List<ConsumerRecord<byte[], byte[]>> receivedRecordsForPartition = partitionRecords.getValue();\n+            final List<ConsumerRecord<byte[], byte[]>> expectedRecordsForPartition = expectedRecords.get(inputTopicPartition);\n+\n+            System.out.println(partitionRecords.getKey() + \" with \" + receivedRecordsForPartition.size() + \", \" +\n+                    inputTopicPartition + \" with \" + expectedRecordsForPartition.size());\n+\n+            final Iterator<ConsumerRecord<byte[], byte[]>> expectedRecord = expectedRecordsForPartition.iterator();\n+            RuntimeException exception = null;\n+            for (final ConsumerRecord<byte[], byte[]> receivedRecord : receivedRecordsForPartition) {\n+                if (!expectedRecord.hasNext())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA1NjY3Mw==", "bodyText": "Should be break for this case?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466056673", "createdAt": "2020-08-05T23:20:42Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java", "diffHunk": "@@ -379,9 +379,18 @@ private static void verifyReceivedAllRecords(final Map<TopicPartition, List<Cons\n         final IntegerDeserializer integerDeserializer = new IntegerDeserializer();\n         for (final Map.Entry<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> partitionRecords : receivedRecords.entrySet()) {\n             final TopicPartition inputTopicPartition = new TopicPartition(\"data\", partitionRecords.getKey().partition());\n-            final Iterator<ConsumerRecord<byte[], byte[]>> expectedRecord = expectedRecords.get(inputTopicPartition).iterator();\n+            final List<ConsumerRecord<byte[], byte[]>> receivedRecordsForPartition = partitionRecords.getValue();\n+            final List<ConsumerRecord<byte[], byte[]>> expectedRecordsForPartition = expectedRecords.get(inputTopicPartition);\n+\n+            System.out.println(partitionRecords.getKey() + \" with \" + receivedRecordsForPartition.size() + \", \" +\n+                    inputTopicPartition + \" with \" + expectedRecordsForPartition.size());\n+\n+            final Iterator<ConsumerRecord<byte[], byte[]>> expectedRecord = expectedRecordsForPartition.iterator();\n+            RuntimeException exception = null;\n+            for (final ConsumerRecord<byte[], byte[]> receivedRecord : receivedRecordsForPartition) {\n+                if (!expectedRecord.hasNext())\n+                    exception = new RuntimeException(\"Result verification failed for \" + receivedRecord + \" since there's no more expected record\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA1NjgyMw==", "bodyText": "Should be break here?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466056823", "createdAt": "2020-08-05T23:21:06Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java", "diffHunk": "@@ -390,9 +399,12 @@ private static void verifyReceivedAllRecords(final Map<TopicPartition, List<Cons\n                 final int expectedValue = integerDeserializer.deserialize(expected.topic(), expected.value());\n \n                 if (!receivedKey.equals(expectedKey) || receivedValue != expectedValue) {\n-                    throw new RuntimeException(\"Result verification failed for \" + receivedRecord + \" expected <\" + expectedKey + \",\" + expectedValue + \"> but was <\" + receivedKey + \",\" + receivedValue + \">\");\n+                    exception = new RuntimeException(\"Result verification failed for \" + receivedRecord + \" expected <\" + expectedKey + \",\" + expectedValue + \"> but was <\" + receivedKey + \",\" + receivedValue + \">\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA1NzYwMA==", "bodyText": "nit: formatting:\nfirstException = new ProcessorStateException(\n    format(\"%sFailed to flush cache of store %s\", logPrefix, store.name()),\n    exception\n);", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466057600", "createdAt": "2020-08-05T23:23:35Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -461,6 +463,42 @@ public void flush() {\n         }\n     }\n \n+    public void flushCache() {\n+        RuntimeException firstException = null;\n+        // attempting to flush the stores\n+        if (!stores.isEmpty()) {\n+            log.debug(\"Flushing all store caches registered in the state manager: {}\", stores);\n+            for (final StateStoreMetadata metadata : stores.values()) {\n+                final StateStore store = metadata.stateStore;\n+\n+                try {\n+                    // buffer should be flushed to send all records to changelog\n+                    if (store instanceof TimeOrderedKeyValueBuffer) {\n+                        store.flush();\n+                    } else if (store instanceof CachedStateStore) {\n+                        ((CachedStateStore) store).flushCache();\n+                    }\n+                    log.trace(\"Flushed cache or buffer {}\", store.name());\n+                } catch (final RuntimeException exception) {\n+                    if (firstException == null) {\n+                        // do NOT wrap the error if it is actually caused by Streams itself\n+                        if (exception instanceof StreamsException) {\n+                            firstException = exception;\n+                        } else {\n+                            firstException = new ProcessorStateException(\n+                                    format(\"%sFailed to flush cache of store %s\", logPrefix, store.name()), exception);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2MjUxMA==", "bodyText": "I would expect that writing the checkpoint file should be cheap anyway (it's just some metadata, how bad can it be?) -- or are you worried about the blocking flush to the file system? Thus, I don't consider double-checkpointing as a real issue? Might be a case of pre-mature optimization? It might simplify our code if we just blindly write the checkpoint data even if it did not change? -- But I am fine either way.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466062510", "createdAt": "2020-08-05T23:39:08Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -38,13 +41,39 @@\n  */\n final class StateManagerUtil {\n     static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+    static final long OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT = 10_000L;\n \n     private StateManagerUtil() {}\n \n     static RecordConverter converterForStore(final StateStore store) {\n         return isTimestamped(store) ? rawValueToTimestampedValue() : identity();\n     }\n \n+    static boolean checkpointNeeded(final boolean enforceCheckpoint,\n+                                    final Map<TopicPartition, Long> oldOffsetSnapshot,\n+                                    final Map<TopicPartition, Long> newOffsetSnapshot) {\n+        // we should always have the old snapshot post completing the register state stores;\n+        // if it is null it means the registration is not done and hence we should not overwrite the checkpoint\n+        if (oldOffsetSnapshot == null)\n+            return false;\n+\n+        // if the previous snapshot is empty while the current snapshot is not then we should always checkpoint;\n+        // note if the task is stateless or stateful but no stores logged, the snapshot would also be empty\n+        // and hence it's okay to not checkpoint\n+        if (oldOffsetSnapshot.isEmpty() && !newOffsetSnapshot.isEmpty())\n+            return true;\n+\n+        // we can checkpoint if the the difference between the current and the previous snapshot is large enough\n+        long totalOffsetDelta = 0L;\n+        for (final Map.Entry<TopicPartition, Long> entry : newOffsetSnapshot.entrySet()) {\n+            totalOffsetDelta += Math.abs(oldOffsetSnapshot.getOrDefault(entry.getKey(), 0L) - entry.getValue());\n+        }\n+\n+        // when enforcing checkpoint is required, we should overwrite the checkpoint if it is different from the old one;\n+        // otherwise, we only overwrite the checkpoint if it is largely different from the old one\n+        return enforceCheckpoint ? totalOffsetDelta > 0 : totalOffsetDelta > OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA5Mzg0Ng=="}, "originalCommit": {"oid": "cea36626a4e104823dd81775d2efef40d96f7ea5"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2MjcyMg==", "bodyText": "nit: add { }", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466062722", "createdAt": "2020-08-05T23:39:49Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -38,13 +41,39 @@\n  */\n final class StateManagerUtil {\n     static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+    static final long OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT = 10_000L;\n \n     private StateManagerUtil() {}\n \n     static RecordConverter converterForStore(final StateStore store) {\n         return isTimestamped(store) ? rawValueToTimestampedValue() : identity();\n     }\n \n+    static boolean checkpointNeeded(final boolean enforceCheckpoint,\n+                                    final Map<TopicPartition, Long> oldOffsetSnapshot,\n+                                    final Map<TopicPartition, Long> newOffsetSnapshot) {\n+        // we should always have the old snapshot post completing the register state stores;\n+        // if it is null it means the registration is not done and hence we should not overwrite the checkpoint\n+        if (oldOffsetSnapshot == null)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2Mjc0Mg==", "bodyText": "nit: add { }", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466062742", "createdAt": "2020-08-05T23:39:53Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -38,13 +41,39 @@\n  */\n final class StateManagerUtil {\n     static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+    static final long OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT = 10_000L;\n \n     private StateManagerUtil() {}\n \n     static RecordConverter converterForStore(final StateStore store) {\n         return isTimestamped(store) ? rawValueToTimestampedValue() : identity();\n     }\n \n+    static boolean checkpointNeeded(final boolean enforceCheckpoint,\n+                                    final Map<TopicPartition, Long> oldOffsetSnapshot,\n+                                    final Map<TopicPartition, Long> newOffsetSnapshot) {\n+        // we should always have the old snapshot post completing the register state stores;\n+        // if it is null it means the registration is not done and hence we should not overwrite the checkpoint\n+        if (oldOffsetSnapshot == null)\n+            return false;\n+\n+        // if the previous snapshot is empty while the current snapshot is not then we should always checkpoint;\n+        // note if the task is stateless or stateful but no stores logged, the snapshot would also be empty\n+        // and hence it's okay to not checkpoint\n+        if (oldOffsetSnapshot.isEmpty() && !newOffsetSnapshot.isEmpty())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2NTIzOQ==", "bodyText": "This line just says what the code say itself. The question seem to be, \"why\" and this question is not answered in the comment.\nFrom my understanding, because we delete the checkpoint file when the task is initialized, we want to write the checkpoint file again as soon as possible (ie, on first commit) instead of waiting until we hit the OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT to keep the time frame in which we have consistent state but not checkpoint file low?\nThus, I am wondering if we should just not delete the checkpoint file when we init the task for non-eos instead? And just remove this additional condition?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466065239", "createdAt": "2020-08-05T23:48:11Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -38,13 +41,39 @@\n  */\n final class StateManagerUtil {\n     static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+    static final long OFFSET_DELTA_THRESHOLD_FOR_CHECKPOINT = 10_000L;\n \n     private StateManagerUtil() {}\n \n     static RecordConverter converterForStore(final StateStore store) {\n         return isTimestamped(store) ? rawValueToTimestampedValue() : identity();\n     }\n \n+    static boolean checkpointNeeded(final boolean enforceCheckpoint,\n+                                    final Map<TopicPartition, Long> oldOffsetSnapshot,\n+                                    final Map<TopicPartition, Long> newOffsetSnapshot) {\n+        // we should always have the old snapshot post completing the register state stores;\n+        // if it is null it means the registration is not done and hence we should not overwrite the checkpoint\n+        if (oldOffsetSnapshot == null)\n+            return false;\n+\n+        // if the previous snapshot is empty while the current snapshot is not then we should always checkpoint;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2NjE5OA==", "bodyText": "It seems like almost every method might throw StreamsException and/or TaskMigratedExcetpion -- is it really worth to have those comments all over the place?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466066198", "createdAt": "2020-08-05T23:51:27Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -344,40 +343,41 @@ public void resume() {\n     }\n \n     /**\n+     * @throws StreamsException fatal error that should cause the thread to die\n+     * @throws TaskMigratedException recoverable error that would cause the task to be removed", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2NjY4MQ==", "bodyText": "Why do we remove this? It might be personal preference, but the old code was \"cleaner\" IMHO? (Feel free to ignore  this comment.)", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466066681", "createdAt": "2020-08-05T23:53:19Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -344,40 +343,41 @@ public void resume() {\n     }\n \n     /**\n+     * @throws StreamsException fatal error that should cause the thread to die\n+     * @throws TaskMigratedException recoverable error that would cause the task to be removed\n      * @return offsets that should be committed for this task\n      */\n     @Override\n     public Map<TopicPartition, OffsetAndMetadata> prepareCommit() {\n-        final Map<TopicPartition, OffsetAndMetadata> offsetsToCommit;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2Njg3MQ==", "bodyText": "nit: Why this? We know that we are in state created ?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466066871", "createdAt": "2020-08-05T23:53:57Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -428,53 +428,28 @@ public void resume() {\n         return committableOffsets;\n     }\n \n-    /**\n-     * This should only be called if the attempted commit succeeded for this task\n-     */\n     @Override\n-    public void postCommit() {\n-        commitRequested = false;\n-\n+    public void postCommit(final boolean enforceCheckpoint) {\n         switch (state()) {\n             case CREATED:\n                 // We should never write a checkpoint for a CREATED task as we may overwrite an existing checkpoint\n                 // with empty uninitialized offsets\n-                log.debug(\"Skipped writing checkpoint for created task\");\n+                log.debug(\"Skipped writing checkpoint for {} task\", state());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2Nzc3Ng==", "bodyText": "Nit: Can we keep SUSPENDED after RUNNING case? We use the same order in all methods and always follow the \"natural\" state transition order, that is CREATE, RESTORING, RUNNING, SUSPENDED, CLOSED.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466067776", "createdAt": "2020-08-05T23:56:56Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -428,53 +428,28 @@ public void resume() {\n         return committableOffsets;\n     }\n \n-    /**\n-     * This should only be called if the attempted commit succeeded for this task\n-     */\n     @Override\n-    public void postCommit() {\n-        commitRequested = false;\n-\n+    public void postCommit(final boolean enforceCheckpoint) {\n         switch (state()) {\n             case CREATED:\n                 // We should never write a checkpoint for a CREATED task as we may overwrite an existing checkpoint\n                 // with empty uninitialized offsets\n-                log.debug(\"Skipped writing checkpoint for created task\");\n+                log.debug(\"Skipped writing checkpoint for {} task\", state());\n \n                 break;\n \n             case RESTORING:\n-                writeCheckpoint();\n-                log.debug(\"Finalized commit for restoring task\");\n+            case SUSPENDED:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2OTIwNQ==", "bodyText": "Why do we maintain List instead of Set ? It seem more natural to me to have a Set (ie, should we instead switch tasksToRecyle to use a Set, too)?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466069205", "createdAt": "2020-08-06T00:01:36Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -248,12 +248,11 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n         );\n \n         final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions = new LinkedHashMap<>();\n-\n         final Map<TaskId, Set<TopicPartition>> activeTasksToCreate = new HashMap<>(activeTasks);\n         final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate = new HashMap<>(standbyTasks);\n-        final List<Task> tasksToClose = new LinkedList<>();\n-        final Set<Task> tasksToRecycle = new HashSet<>();\n-        final Set<Task> dirtyTasks = new HashSet<>();\n+        final List<Task> tasksToRecycle = new LinkedList<>();\n+        final List<Task> tasksToCloseClean = new LinkedList<>();\n+        final List<Task> tasksToCloseDirty = new LinkedList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA2OTYwNA==", "bodyText": "What other PR?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466069604", "createdAt": "2020-08-06T00:03:05Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -243,18 +242,24 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n \n         for (final Task task : tasksToClose) {\n             try {\n-                if (task.isActive()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTAyMTIyNQ=="}, "originalCommit": {"oid": "4394dd2316783c286d1b8c042863b558b53fdec7"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MDEzMw==", "bodyText": "Seems like double logging? We have a log.error each time before taskCloseExceptions.put() is called in handleCloseAndRecycle", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466070133", "createdAt": "2020-08-06T00:05:09Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -267,80 +266,19 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 // check for tasks that were owned previously but have changed active/standby status\n                 tasksToRecycle.add(task);\n             } else {\n-                tasksToClose.add(task);\n-            }\n-        }\n-\n-        for (final Task task : tasksToClose) {\n-            try {\n-                if (task.isActive()) {\n-                    // Active tasks are revoked and suspended/committed during #handleRevocation\n-                    if (!task.state().equals(State.SUSPENDED)) {\n-                        log.error(\"Active task {} should be suspended prior to attempting to close but was in {}\",\n-                                  task.id(), task.state());\n-                        throw new IllegalStateException(\"Active task \" + task.id() + \" should have been suspended\");\n-                    }\n-                } else {\n-                    task.suspend();\n-                    task.prepareCommit();\n-                    task.postCommit();\n-                }\n-                completeTaskCloseClean(task);\n-                cleanUpTaskProducer(task, taskCloseExceptions);\n-                tasks.remove(task.id());\n-            } catch (final RuntimeException e) {\n-                final String uncleanMessage = String.format(\n-                    \"Failed to close task %s cleanly. Attempting to close remaining tasks before re-throwing:\",\n-                    task.id());\n-                log.error(uncleanMessage, e);\n-                taskCloseExceptions.put(task.id(), e);\n-                // We've already recorded the exception (which is the point of clean).\n-                // Now, we should go ahead and complete the close because a half-closed task is no good to anyone.\n-                dirtyTasks.add(task);\n-            }\n-        }\n-\n-        for (final Task oldTask : tasksToRecycle) {\n-            final Task newTask;\n-            try {\n-                if (oldTask.isActive()) {\n-                    if (!oldTask.state().equals(State.SUSPENDED)) {\n-                        // Active tasks are revoked and suspended/committed during #handleRevocation\n-                        log.error(\"Active task {} should be suspended prior to attempting to close but was in {}\",\n-                                  oldTask.id(), oldTask.state());\n-                        throw new IllegalStateException(\"Active task \" + oldTask.id() + \" should have been suspended\");\n-                    }\n-                    final Set<TopicPartition> partitions = standbyTasksToCreate.remove(oldTask.id());\n-                    newTask = standbyTaskCreator.createStandbyTaskFromActive((StreamTask) oldTask, partitions);\n-                    cleanUpTaskProducer(oldTask, taskCloseExceptions);\n-                } else {\n-                    oldTask.suspend();\n-                    oldTask.prepareCommit();\n-                    oldTask.postCommit();\n-                    final Set<TopicPartition> partitions = activeTasksToCreate.remove(oldTask.id());\n-                    newTask = activeTaskCreator.createActiveTaskFromStandby((StandbyTask) oldTask, partitions, mainConsumer);\n-                }\n-                tasks.remove(oldTask.id());\n-                addNewTask(newTask);\n-            } catch (final RuntimeException e) {\n-                final String uncleanMessage = String.format(\"Failed to recycle task %s cleanly. Attempting to close remaining tasks before re-throwing:\", oldTask.id());\n-                log.error(uncleanMessage, e);\n-                taskCloseExceptions.put(oldTask.id(), e);\n-                dirtyTasks.add(oldTask);\n+                tasksToCloseClean.add(task);\n             }\n         }\n \n-        for (final Task task : dirtyTasks) {\n-            closeTaskDirty(task);\n-            cleanUpTaskProducer(task, taskCloseExceptions);\n-            tasks.remove(task.id());\n-        }\n+        // close and recycle those tasks\n+        handleCloseAndRecycle(tasksToRecycle, tasksToCloseClean, tasksToCloseDirty, activeTasksToCreate, standbyTasksToCreate, taskCloseExceptions);\n \n         if (!taskCloseExceptions.isEmpty()) {\n+            log.error(\"Hit exceptions while closing / recycling tasks: {}\", taskCloseExceptions);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MDQxOQ==", "bodyText": "should it be putIfAbsent (cf cleanUpTaskProducer())", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466070419", "createdAt": "2020-08-06T00:06:10Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +306,102 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }\n+\n+        // for all tasks to close or recycle, we should first right a checkpoint as in post-commit\n+        final List<Task> tasksToCheckpoint = new ArrayList<>(tasksToCloseClean);\n+        tasksToCheckpoint.addAll(tasksToRecycle);\n+        for (final Task task : tasksToCheckpoint) {\n+            try {\n+                // Note that we are not actually committing here but just check if we need to write checkpoint file:\n+                // 1) for active tasks prepareCommit should return empty if it has committed during suspension successfully,\n+                //    and their changelog positions should not change at all postCommit would not write the checkpoint again.\n+                // 2) for standby tasks prepareCommit should always return empty, and then in postCommit we would probably\n+                //    write the checkpoint file.\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();\n+                if (!offsets.isEmpty()) {\n+                    log.error(\"Task {} should has been committed when it was suspended, but it reports non-empty \" +\n+                                    \"offsets {} to commit; it means it fails during last commit and hence should be closed dirty\",\n+                            task.id(), offsets);\n+\n+                    tasksToCloseDirty.add(task);\n+                } else if (!task.isActive()) {\n+                    // For standby tasks, always try to first suspend before committing (checkpointing) it;\n+                    // Since standby tasks do not actually need to commit offsets but only need to\n+                    // flush / checkpoint state stores, so we only need to call postCommit here.\n+                    task.suspend();\n+\n+                    task.postCommit(true);\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to checkpoint task %s. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);\n+                // We've already recorded the exception (which is the point of clean).\n+                // Now, we should go ahead and complete the close because a half-closed task is no good to anyone.\n+                tasksToCloseDirty.add(task);\n+            }\n+        }\n \n+        for (final Task task : tasksToCloseClean) {\n+            try {\n+                if (!tasksToCloseDirty.contains(task)) {\n+                    completeTaskCloseClean(task);\n+                    cleanUpTaskProducer(task, taskCloseExceptions);\n+                    tasks.remove(task.id());\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to close task %s cleanly. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);\n+                tasksToCloseDirty.add(task);\n+            }\n+        }\n+\n+        for (final Task task : tasksToRecycle) {\n+            final Task newTask;\n+            try {\n+                if (!tasksToCloseDirty.contains(task)) {\n+                    if (task.isActive()) {\n+                        final Set<TopicPartition> partitions = standbyTasksToCreate.remove(task.id());\n+                        newTask = standbyTaskCreator.createStandbyTaskFromActive((StreamTask) task, partitions);\n+                        cleanUpTaskProducer(task, taskCloseExceptions);\n+                    } else {\n+                        final Set<TopicPartition> partitions = activeTasksToCreate.remove(task.id());\n+                        newTask = activeTaskCreator.createActiveTaskFromStandby((StandbyTask) task, partitions, mainConsumer);\n+                    }\n+                    tasks.remove(task.id());\n+                    addNewTask(newTask);\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\"Failed to recycle task %s cleanly. Attempting to close remaining tasks before re-throwing:\", task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 214}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MDUwMw==", "bodyText": "should it be putIfAbsent (cf cleanUpTaskProducer())", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466070503", "createdAt": "2020-08-06T00:06:32Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +306,102 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }\n+\n+        // for all tasks to close or recycle, we should first right a checkpoint as in post-commit\n+        final List<Task> tasksToCheckpoint = new ArrayList<>(tasksToCloseClean);\n+        tasksToCheckpoint.addAll(tasksToRecycle);\n+        for (final Task task : tasksToCheckpoint) {\n+            try {\n+                // Note that we are not actually committing here but just check if we need to write checkpoint file:\n+                // 1) for active tasks prepareCommit should return empty if it has committed during suspension successfully,\n+                //    and their changelog positions should not change at all postCommit would not write the checkpoint again.\n+                // 2) for standby tasks prepareCommit should always return empty, and then in postCommit we would probably\n+                //    write the checkpoint file.\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();\n+                if (!offsets.isEmpty()) {\n+                    log.error(\"Task {} should has been committed when it was suspended, but it reports non-empty \" +\n+                                    \"offsets {} to commit; it means it fails during last commit and hence should be closed dirty\",\n+                            task.id(), offsets);\n+\n+                    tasksToCloseDirty.add(task);\n+                } else if (!task.isActive()) {\n+                    // For standby tasks, always try to first suspend before committing (checkpointing) it;\n+                    // Since standby tasks do not actually need to commit offsets but only need to\n+                    // flush / checkpoint state stores, so we only need to call postCommit here.\n+                    task.suspend();\n+\n+                    task.postCommit(true);\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to checkpoint task %s. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);\n+                // We've already recorded the exception (which is the point of clean).\n+                // Now, we should go ahead and complete the close because a half-closed task is no good to anyone.\n+                tasksToCloseDirty.add(task);\n+            }\n+        }\n \n+        for (final Task task : tasksToCloseClean) {\n+            try {\n+                if (!tasksToCloseDirty.contains(task)) {\n+                    completeTaskCloseClean(task);\n+                    cleanUpTaskProducer(task, taskCloseExceptions);\n+                    tasks.remove(task.id());\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to close task %s cleanly. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MDU0Mw==", "bodyText": "should it be putIfAbsent (cf cleanUpTaskProducer())", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466070543", "createdAt": "2020-08-06T00:06:40Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +306,102 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }\n+\n+        // for all tasks to close or recycle, we should first right a checkpoint as in post-commit\n+        final List<Task> tasksToCheckpoint = new ArrayList<>(tasksToCloseClean);\n+        tasksToCheckpoint.addAll(tasksToRecycle);\n+        for (final Task task : tasksToCheckpoint) {\n+            try {\n+                // Note that we are not actually committing here but just check if we need to write checkpoint file:\n+                // 1) for active tasks prepareCommit should return empty if it has committed during suspension successfully,\n+                //    and their changelog positions should not change at all postCommit would not write the checkpoint again.\n+                // 2) for standby tasks prepareCommit should always return empty, and then in postCommit we would probably\n+                //    write the checkpoint file.\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();\n+                if (!offsets.isEmpty()) {\n+                    log.error(\"Task {} should has been committed when it was suspended, but it reports non-empty \" +\n+                                    \"offsets {} to commit; it means it fails during last commit and hence should be closed dirty\",\n+                            task.id(), offsets);\n+\n+                    tasksToCloseDirty.add(task);\n+                } else if (!task.isActive()) {\n+                    // For standby tasks, always try to first suspend before committing (checkpointing) it;\n+                    // Since standby tasks do not actually need to commit offsets but only need to\n+                    // flush / checkpoint state stores, so we only need to call postCommit here.\n+                    task.suspend();\n+\n+                    task.postCommit(true);\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to checkpoint task %s. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MjU1OQ==", "bodyText": "This seems to be a \"hack\" -- IMHO, as task should be only in either one set/list, but never in both... Can we change the first loop to use an explicit iterator and remove a task from tasksToCloseClean when we add it to tasksToCloseDirty", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466072559", "createdAt": "2020-08-06T00:14:25Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +306,102 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }\n+\n+        // for all tasks to close or recycle, we should first right a checkpoint as in post-commit\n+        final List<Task> tasksToCheckpoint = new ArrayList<>(tasksToCloseClean);\n+        tasksToCheckpoint.addAll(tasksToRecycle);\n+        for (final Task task : tasksToCheckpoint) {\n+            try {\n+                // Note that we are not actually committing here but just check if we need to write checkpoint file:\n+                // 1) for active tasks prepareCommit should return empty if it has committed during suspension successfully,\n+                //    and their changelog positions should not change at all postCommit would not write the checkpoint again.\n+                // 2) for standby tasks prepareCommit should always return empty, and then in postCommit we would probably\n+                //    write the checkpoint file.\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();\n+                if (!offsets.isEmpty()) {\n+                    log.error(\"Task {} should has been committed when it was suspended, but it reports non-empty \" +\n+                                    \"offsets {} to commit; it means it fails during last commit and hence should be closed dirty\",\n+                            task.id(), offsets);\n+\n+                    tasksToCloseDirty.add(task);\n+                } else if (!task.isActive()) {\n+                    // For standby tasks, always try to first suspend before committing (checkpointing) it;\n+                    // Since standby tasks do not actually need to commit offsets but only need to\n+                    // flush / checkpoint state stores, so we only need to call postCommit here.\n+                    task.suspend();\n+\n+                    task.postCommit(true);\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to checkpoint task %s. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);\n+                // We've already recorded the exception (which is the point of clean).\n+                // Now, we should go ahead and complete the close because a half-closed task is no good to anyone.\n+                tasksToCloseDirty.add(task);\n+            }\n+        }\n \n+        for (final Task task : tasksToCloseClean) {\n+            try {\n+                if (!tasksToCloseDirty.contains(task)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MzEzNQ==", "bodyText": "While I usually prefer checks like this, it seems unnecessary here? (Feel free to ignore.)", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466073135", "createdAt": "2020-08-06T00:16:24Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +306,102 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MzQ0Nw==", "bodyText": "We should remove task from taskToCloseClean/taskToRecycle here to maintain the invariant that a task is only in either one of the three sets/list but never in multiple at the same time. (cf. my comment below)\nI understand that you want to share this loop for \"cleanClose\" and \"recycle\" we can extract it into its own method to achieve this.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466073447", "createdAt": "2020-08-06T00:17:27Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +306,102 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }\n+\n+        // for all tasks to close or recycle, we should first right a checkpoint as in post-commit\n+        final List<Task> tasksToCheckpoint = new ArrayList<>(tasksToCloseClean);\n+        tasksToCheckpoint.addAll(tasksToRecycle);\n+        for (final Task task : tasksToCheckpoint) {\n+            try {\n+                // Note that we are not actually committing here but just check if we need to write checkpoint file:\n+                // 1) for active tasks prepareCommit should return empty if it has committed during suspension successfully,\n+                //    and their changelog positions should not change at all postCommit would not write the checkpoint again.\n+                // 2) for standby tasks prepareCommit should always return empty, and then in postCommit we would probably\n+                //    write the checkpoint file.\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();\n+                if (!offsets.isEmpty()) {\n+                    log.error(\"Task {} should has been committed when it was suspended, but it reports non-empty \" +\n+                                    \"offsets {} to commit; it means it fails during last commit and hence should be closed dirty\",\n+                            task.id(), offsets);\n+\n+                    tasksToCloseDirty.add(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MzQ4MQ==", "bodyText": "as above.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466073481", "createdAt": "2020-08-06T00:17:36Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +306,102 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }\n+\n+        // for all tasks to close or recycle, we should first right a checkpoint as in post-commit\n+        final List<Task> tasksToCheckpoint = new ArrayList<>(tasksToCloseClean);\n+        tasksToCheckpoint.addAll(tasksToRecycle);\n+        for (final Task task : tasksToCheckpoint) {\n+            try {\n+                // Note that we are not actually committing here but just check if we need to write checkpoint file:\n+                // 1) for active tasks prepareCommit should return empty if it has committed during suspension successfully,\n+                //    and their changelog positions should not change at all postCommit would not write the checkpoint again.\n+                // 2) for standby tasks prepareCommit should always return empty, and then in postCommit we would probably\n+                //    write the checkpoint file.\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();\n+                if (!offsets.isEmpty()) {\n+                    log.error(\"Task {} should has been committed when it was suspended, but it reports non-empty \" +\n+                                    \"offsets {} to commit; it means it fails during last commit and hence should be closed dirty\",\n+                            task.id(), offsets);\n+\n+                    tasksToCloseDirty.add(task);\n+                } else if (!task.isActive()) {\n+                    // For standby tasks, always try to first suspend before committing (checkpointing) it;\n+                    // Since standby tasks do not actually need to commit offsets but only need to\n+                    // flush / checkpoint state stores, so we only need to call postCommit here.\n+                    task.suspend();\n+\n+                    task.postCommit(true);\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to checkpoint task %s. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);\n+                // We've already recorded the exception (which is the point of clean).\n+                // Now, we should go ahead and complete the close because a half-closed task is no good to anyone.\n+                tasksToCloseDirty.add(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MzUxMA==", "bodyText": "as above", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466073510", "createdAt": "2020-08-06T00:17:44Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +306,102 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }\n+\n+        // for all tasks to close or recycle, we should first right a checkpoint as in post-commit\n+        final List<Task> tasksToCheckpoint = new ArrayList<>(tasksToCloseClean);\n+        tasksToCheckpoint.addAll(tasksToRecycle);\n+        for (final Task task : tasksToCheckpoint) {\n+            try {\n+                // Note that we are not actually committing here but just check if we need to write checkpoint file:\n+                // 1) for active tasks prepareCommit should return empty if it has committed during suspension successfully,\n+                //    and their changelog positions should not change at all postCommit would not write the checkpoint again.\n+                // 2) for standby tasks prepareCommit should always return empty, and then in postCommit we would probably\n+                //    write the checkpoint file.\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();\n+                if (!offsets.isEmpty()) {\n+                    log.error(\"Task {} should has been committed when it was suspended, but it reports non-empty \" +\n+                                    \"offsets {} to commit; it means it fails during last commit and hence should be closed dirty\",\n+                            task.id(), offsets);\n+\n+                    tasksToCloseDirty.add(task);\n+                } else if (!task.isActive()) {\n+                    // For standby tasks, always try to first suspend before committing (checkpointing) it;\n+                    // Since standby tasks do not actually need to commit offsets but only need to\n+                    // flush / checkpoint state stores, so we only need to call postCommit here.\n+                    task.suspend();\n+\n+                    task.postCommit(true);\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to checkpoint task %s. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);\n+                // We've already recorded the exception (which is the point of clean).\n+                // Now, we should go ahead and complete the close because a half-closed task is no good to anyone.\n+                tasksToCloseDirty.add(task);\n+            }\n+        }\n \n+        for (final Task task : tasksToCloseClean) {\n+            try {\n+                if (!tasksToCloseDirty.contains(task)) {\n+                    completeTaskCloseClean(task);\n+                    cleanUpTaskProducer(task, taskCloseExceptions);\n+                    tasks.remove(task.id());\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to close task %s cleanly. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);\n+                tasksToCloseDirty.add(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3MzU3MQ==", "bodyText": "as above.", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466073571", "createdAt": "2020-08-06T00:17:56Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -368,7 +306,102 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 addNewTask(task);\n             }\n         }\n+    }\n+\n+    private void handleCloseAndRecycle(final List<Task> tasksToRecycle,\n+                                       final List<Task> tasksToCloseClean,\n+                                       final List<Task> tasksToCloseDirty,\n+                                       final Map<TaskId, Set<TopicPartition>> activeTasksToCreate,\n+                                       final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate,\n+                                       final LinkedHashMap<TaskId, RuntimeException> taskCloseExceptions) {\n+        if (!tasksToCloseDirty.isEmpty()) {\n+            throw new IllegalArgumentException(\"Tasks to close-dirty should be empty\");\n+        }\n+\n+        // for all tasks to close or recycle, we should first right a checkpoint as in post-commit\n+        final List<Task> tasksToCheckpoint = new ArrayList<>(tasksToCloseClean);\n+        tasksToCheckpoint.addAll(tasksToRecycle);\n+        for (final Task task : tasksToCheckpoint) {\n+            try {\n+                // Note that we are not actually committing here but just check if we need to write checkpoint file:\n+                // 1) for active tasks prepareCommit should return empty if it has committed during suspension successfully,\n+                //    and their changelog positions should not change at all postCommit would not write the checkpoint again.\n+                // 2) for standby tasks prepareCommit should always return empty, and then in postCommit we would probably\n+                //    write the checkpoint file.\n+                final Map<TopicPartition, OffsetAndMetadata> offsets = task.prepareCommit();\n+                if (!offsets.isEmpty()) {\n+                    log.error(\"Task {} should has been committed when it was suspended, but it reports non-empty \" +\n+                                    \"offsets {} to commit; it means it fails during last commit and hence should be closed dirty\",\n+                            task.id(), offsets);\n+\n+                    tasksToCloseDirty.add(task);\n+                } else if (!task.isActive()) {\n+                    // For standby tasks, always try to first suspend before committing (checkpointing) it;\n+                    // Since standby tasks do not actually need to commit offsets but only need to\n+                    // flush / checkpoint state stores, so we only need to call postCommit here.\n+                    task.suspend();\n+\n+                    task.postCommit(true);\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to checkpoint task %s. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);\n+                // We've already recorded the exception (which is the point of clean).\n+                // Now, we should go ahead and complete the close because a half-closed task is no good to anyone.\n+                tasksToCloseDirty.add(task);\n+            }\n+        }\n \n+        for (final Task task : tasksToCloseClean) {\n+            try {\n+                if (!tasksToCloseDirty.contains(task)) {\n+                    completeTaskCloseClean(task);\n+                    cleanUpTaskProducer(task, taskCloseExceptions);\n+                    tasks.remove(task.id());\n+                }\n+            } catch (final RuntimeException e) {\n+                final String uncleanMessage = String.format(\n+                        \"Failed to close task %s cleanly. Attempting to close remaining tasks before re-throwing:\",\n+                        task.id());\n+                log.error(uncleanMessage, e);\n+                taskCloseExceptions.put(task.id(), e);\n+                tasksToCloseDirty.add(task);\n+            }\n+        }\n+\n+        for (final Task task : tasksToRecycle) {\n+            final Task newTask;\n+            try {\n+                if (!tasksToCloseDirty.contains(task)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3NTg5MQ==", "bodyText": "Why this renaming? -- the set does not contain \"all\" non-revoked active tasks -- only those, that need committing?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r466075891", "createdAt": "2020-08-06T00:25:59Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -479,24 +512,20 @@ boolean tryToCompleteRestoration() {\n     void handleRevocation(final Collection<TopicPartition> revokedPartitions) {\n         final Set<TopicPartition> remainingRevokedPartitions = new HashSet<>(revokedPartitions);\n \n-        final Set<Task> revokedTasks = new HashSet<>();\n-        final Set<Task> additionalTasksForCommitting = new HashSet<>();\n-        final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsAndMetadataPerTask = new HashMap<>();\n-\n+        final Set<Task> revokedActiveTasks = new HashSet<>();\n+        final Set<Task> nonRevokedActiveTasks = new HashSet<>();\n+        final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsPerTask = new HashMap<>();\n         final AtomicReference<RuntimeException> firstException = new AtomicReference<>(null);\n+\n         for (final Task task : activeTaskIterable()) {\n             if (remainingRevokedPartitions.containsAll(task.inputPartitions())) {\n-                try {\n-                    task.suspend();\n-                    revokedTasks.add(task);\n-                } catch (final RuntimeException e) {\n-                    log.error(\"Caught the following exception while trying to suspend revoked task \" + task.id(), e);\n-                    firstException.compareAndSet(null, new StreamsException(\"Failed to suspend \" + task.id(), e));\n-                }\n+                // when the task input partitions are included in the revoked list,\n+                // this is an active task and should be revoked\n+                revokedActiveTasks.add(task);\n+                remainingRevokedPartitions.removeAll(task.inputPartitions());\n             } else if (task.commitNeeded()) {\n-                additionalTasksForCommitting.add(task);\n+                nonRevokedActiveTasks.add(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa95e1367eb31660a156eb484e2d455ca35029a1"}, "originalPosition": 270}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db2c1e30adc6aed42879781184aacede6b88778b", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/db2c1e30adc6aed42879781184aacede6b88778b", "committedDate": "2020-08-06T00:45:36Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/2503a74c5e025ad21835928d690c2fbc22bd3e69", "committedDate": "2020-08-06T03:35:32Z", "message": "do not delete upon loading without eos"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYzNjU1Mzg0", "url": "https://github.com/apache/kafka/pull/8964#pullrequestreview-463655384", "createdAt": "2020-08-07T21:42:27Z", "commit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QyMTo0MjoyN1rOG9pGKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQwNDoyNTowOFrOG9tYpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI4OTY0MA==", "bodyText": "Seems the comment is outdated? we should initialize the snapshot as empty", "url": "https://github.com/apache/kafka/pull/8964#discussion_r467289640", "createdAt": "2020-08-07T21:42:27Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -49,6 +59,30 @@\n         this.stateDirectory = stateDirectory;\n     }\n \n+    protected void initializeCheckpoint() {\n+        // we will delete the local checkpoint file after registering the state stores and loading them into the\n+        // state manager, therefore we should initialize the snapshot as empty to indicate over-write checkpoint needed", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI5MTM0Ng==", "bodyText": "In the old code, we actually get a copy of the Map, while within initializeCheckpoint(); don't -- is this on purpose? It it safe?\nAlso, do we actually need the method? The old code was just doing the exact some thing? It's just one-liner method -- what do we gain?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r467291346", "createdAt": "2020-08-07T21:44:44Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -93,9 +90,7 @@ public boolean isActive() {\n     public void initializeIfNeeded() {\n         if (state() == State.CREATED) {\n             StateManagerUtil.registerStateStores(log, logPrefix, topology, stateMgr, stateDirectory, processorContext);\n-\n-            // initialize the snapshot with the current offsets as we don't need to commit then until they change\n-            offsetSnapshotSinceLastCommit = new HashMap<>(stateMgr.changelogOffsets());\n+            initializeCheckpoint();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI5NjMzNQ==", "bodyText": "Should we add a test for EOS, that the checkpoint file is deleted?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r467296335", "createdAt": "2020-08-07T21:51:06Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java", "diffHunk": "@@ -412,7 +412,7 @@ public void shouldInitializeOffsetsFromCheckpointFile() throws IOException {\n             stateMgr.registerStore(nonPersistentStore, nonPersistentStore.stateRestoreCallback);\n             stateMgr.initializeStoreOffsetsFromCheckpoint(true);\n \n-            assertFalse(checkpointFile.exists());\n+            assertTrue(checkpointFile.exists());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI5NzM5NA==", "bodyText": "It's unclear to me, how we actually verify that the checkpointing happened? Above, we have\nstateManager.checkpoint();\nEasyMock.expectLastCall();\n\nbut it only help to verify that we checkpoint a single time, but not which of the three calls does the checkpointing?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r467297394", "createdAt": "2020-08-07T21:52:28Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java", "diffHunk": "@@ -207,15 +207,25 @@ public void shouldFlushAndCheckpointStateManagerOnCommit() {\n         EasyMock.expect(stateManager.changelogOffsets()).andStubReturn(Collections.emptyMap());\n         stateManager.flush();\n         EasyMock.expectLastCall();\n-        stateManager.checkpoint(EasyMock.eq(Collections.emptyMap()));\n-        EasyMock.expect(stateManager.changelogOffsets()).andReturn(Collections.singletonMap(partition, 50L));\n+        stateManager.checkpoint();\n+        EasyMock.expectLastCall();\n+        EasyMock.expect(stateManager.changelogOffsets())\n+                .andReturn(Collections.singletonMap(partition, 50L))\n+                .andReturn(Collections.singletonMap(partition, 11000L))\n+                .andReturn(Collections.singletonMap(partition, 11000L));\n         EasyMock.expect(stateManager.changelogPartitions()).andReturn(Collections.singleton(partition)).anyTimes();\n         EasyMock.replay(stateManager);\n \n         task = createStandbyTask();\n         task.initializeIfNeeded();\n         task.prepareCommit();\n-        task.postCommit();\n+        task.postCommit(false);  // this should not checkpoint", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM1OTY4OA==", "bodyText": "Should we verify stateManager, too?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r467359688", "createdAt": "2020-08-08T04:22:21Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -1259,13 +1262,47 @@ public void shouldReInitializeTopologyWhenResuming() throws IOException {\n     }\n \n     @Test\n-    public void shouldCheckpointOffsetsOnCommit() {\n+    public void shouldNotCheckpointOffsetsAgainOnCommitIfSnapshotNotChangedMuch() {\n         final Long offset = 543L;\n \n         EasyMock.expect(recordCollector.offsets()).andReturn(Collections.singletonMap(changelogPartition, offset)).anyTimes();\n-        stateManager.checkpoint(EasyMock.eq(Collections.singletonMap(changelogPartition, offset)));\n+        stateManager.checkpoint();\n+        EasyMock.expectLastCall().once();\n+        EasyMock.expect(stateManager.changelogPartitions()).andReturn(Collections.singleton(changelogPartition));\n+        EasyMock.expect(stateManager.changelogOffsets())\n+                .andReturn(Collections.singletonMap(changelogPartition, 0L))\n+                .andReturn(Collections.singletonMap(changelogPartition, 10L))\n+                .andReturn(Collections.singletonMap(changelogPartition, 20L));\n+        stateManager.registerStore(stateStore, stateStore.stateRestoreCallback);\n         EasyMock.expectLastCall();\n+        EasyMock.replay(stateManager, recordCollector);\n+\n+        task = createStatefulTask(createConfig(false, \"100\"), true);\n+\n+        task.initializeIfNeeded();\n+        task.completeRestoration();\n+\n+        task.prepareCommit();\n+        task.postCommit(true);\n+\n+        task.prepareCommit();\n+        task.postCommit(false);\n+\n+        EasyMock.verify(recordCollector);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM1OTc3Ng==", "bodyText": "Why do we need to setup an exception? If we don't setup any expected call at all, it should fail automatically?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r467359776", "createdAt": "2020-08-08T04:23:40Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -1458,50 +1498,91 @@ public void shouldThrowIfPostCommittingOnIllegalState() {\n \n         task.transitionTo(Task.State.SUSPENDED);\n         task.transitionTo(Task.State.CLOSED);\n-        assertThrows(IllegalStateException.class, task::postCommit);\n+        assertThrows(IllegalStateException.class, () -> task.postCommit(true));\n     }\n \n     @Test\n     public void shouldSkipCheckpointingSuspendedCreatedTask() {\n-        stateManager.checkpoint(EasyMock.anyObject());\n+        stateManager.checkpoint();\n         EasyMock.expectLastCall().andThrow(new AssertionError(\"Should not have tried to checkpoint\"));\n         EasyMock.replay(stateManager);\n \n         task = createStatefulTask(createConfig(false, \"100\"), true);\n         task.suspend();\n-        task.postCommit();\n+        task.postCommit(true);\n     }\n \n     @Test\n-    public void shouldCheckpointWithEmptyOffsetsForSuspendedRestoringTask() {\n-        stateManager.checkpoint(emptyMap());\n+    public void shouldCheckpointForSuspendedTask() {\n+        stateManager.checkpoint();\n+        EasyMock.expectLastCall().once();\n+        EasyMock.expect(stateManager.changelogOffsets())\n+                .andReturn(Collections.singletonMap(partition1, 0L))\n+                .andReturn(Collections.singletonMap(partition1, 1L));\n         EasyMock.replay(stateManager);\n \n         task = createStatefulTask(createConfig(false, \"100\"), true);\n         task.initializeIfNeeded();\n         task.suspend();\n-        task.postCommit();\n+        task.postCommit(true);\n         EasyMock.verify(stateManager);\n     }\n \n     @Test\n-    public void shouldCheckpointWithEmptyOffsetsForSuspendedRunningTaskWithNoCommitNeeded() {\n-        stateManager.checkpoint(emptyMap());\n+    public void shouldNotCheckpointForSuspendedRunningTaskWithSmallProgress() {\n+        EasyMock.expect(stateManager.changelogOffsets())\n+                .andReturn(Collections.singletonMap(partition1, 1L))\n+                .andReturn(Collections.singletonMap(partition1, 2L))\n+                .andReturn(Collections.singletonMap(partition1, 3L));\n+        stateManager.checkpoint();\n+        EasyMock.expectLastCall().andThrow(new AssertionError(\"Checkpoint should not be called\")).anyTimes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM1OTgzOQ==", "bodyText": "Similar to above: instead of throwing, it should be sufficient to just not register any expected calll?", "url": "https://github.com/apache/kafka/pull/8964#discussion_r467359839", "createdAt": "2020-08-08T04:24:51Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -1560,42 +1641,13 @@ public void shouldCheckpointWithCreatedStateOnClose() {\n     }\n \n     @Test\n-    public void shouldNotCommitAndThrowOnCloseDirty() {\n-        EasyMock.expect(stateManager.changelogPartitions()).andReturn(Collections.emptySet()).anyTimes();\n-        stateManager.close();\n-        EasyMock.expectLastCall().andThrow(new ProcessorStateException(\"KABOOM!\")).anyTimes();\n-        stateManager.checkpoint(EasyMock.anyObject());\n-        EasyMock.expectLastCall().andThrow(new AssertionError(\"Checkpoint should not be called\")).anyTimes();\n-        EasyMock.expect(recordCollector.offsets()).andReturn(Collections.emptyMap()).anyTimes();\n-        EasyMock.replay(stateManager, recordCollector);\n-\n-        final MetricName metricName = setupCloseTaskMetric();\n-\n-        task = createOptimizedStatefulTask(createConfig(false, \"100\"), consumer);\n-\n-        task.initializeIfNeeded();\n-        task.completeRestoration();\n-\n-        task.suspend();\n-        task.closeDirty();\n-\n-        assertEquals(Task.State.CLOSED, task.state());\n-        assertTrue(source1.initialized);\n-        assertTrue(source1.closed);\n-\n-        final double expectedCloseTaskMetric = 1.0;\n-        verifyCloseTaskMetric(expectedCloseTaskMetric, streamsMetrics, metricName);\n-\n-        EasyMock.verify(stateManager);\n-    }\n-\n-    @Test\n-    public void shouldCheckpointOnCloseRestoring() {\n+    public void shouldNotCheckpointOnCloseRestoringIfNoProgress() {\n         stateManager.flush();\n-        EasyMock.expectLastCall();\n-        stateManager.checkpoint(EasyMock.eq(Collections.emptyMap()));\n-        EasyMock.expectLastCall();\n+        EasyMock.expectLastCall().andThrow(new AssertionError(\"Flush should not be called\")).anyTimes();\n+        stateManager.checkpoint();\n+        EasyMock.expectLastCall().andThrow(new AssertionError(\"Checkpoint should not be called\")).anyTimes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69"}, "originalPosition": 287}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM1OTkxMA==", "bodyText": "as above? (more below... won't add comments each time)", "url": "https://github.com/apache/kafka/pull/8964#discussion_r467359910", "createdAt": "2020-08-08T04:25:08Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -1638,21 +1689,22 @@ public void shouldCheckpointOffsetsOnPostCommitIfCommitNeeded() {\n \n         task.suspend();\n         task.prepareCommit();\n-        task.postCommit();\n+        task.postCommit(false);\n \n         assertEquals(Task.State.SUSPENDED, task.state());\n \n         EasyMock.verify(stateManager);\n     }\n \n     @Test\n-    public void shouldSwallowExceptionOnCloseCleanError() {\n+    public void shouldThrowExceptionOnCloseCleanError() {\n         final long offset = 543L;\n \n         EasyMock.expect(recordCollector.offsets()).andReturn(emptyMap()).anyTimes();\n-        stateManager.checkpoint(EasyMock.eq(Collections.singletonMap(partition1, offset)));\n-        EasyMock.expectLastCall();\n+        stateManager.checkpoint();\n+        EasyMock.expectLastCall().andThrow(new AssertionError(\"Checkpoint should not be called\")).anyTimes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2503a74c5e025ad21835928d690c2fbc22bd3e69"}, "originalPosition": 348}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8a0379dc3c720ef06e7e64444b26ce2e1fee650", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/c8a0379dc3c720ef06e7e64444b26ce2e1fee650", "committedDate": "2020-08-11T18:21:03Z", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9450-decouple-flush-state-from-commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4f2272986357de9c48032d1fd0d9b1482d5a974", "author": {"user": {"login": "guozhangwang", "name": "Guozhang Wang"}}, "url": "https://github.com/apache/kafka/commit/a4f2272986357de9c48032d1fd0d9b1482d5a974", "committedDate": "2020-08-11T21:24:45Z", "message": "github comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1426, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}