{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQxNjE5MzEy", "number": 8953, "title": "MINOR: re-enable EosBetaUpgradeIntegrationTest", "bodyText": "", "createdAt": "2020-06-29T20:00:25Z", "url": "https://github.com/apache/kafka/pull/8953", "merged": true, "mergeCommit": {"oid": "7db52a46b00eed652e791dd4eae809d590626a1f"}, "closed": true, "closedAt": "2020-06-29T20:31:33Z", "author": {"login": "ableegoldman"}, "timelineItems": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcwGp_2gH2gAyNDQxNjE5MzEyOjI2YWQzNjljZTkzMmJmNGM1MjE2MTUxMzRhYWRmNjFjMzRiODI1MzQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcwHEVZgFqTQzOTQ3NTc2MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "26ad369ce932bf4c521615134aadf61c34b82534", "author": {"user": {"login": "ableegoldman", "name": "A. Sophie Blee-Goldman"}}, "url": "https://github.com/apache/kafka/commit/26ad369ce932bf4c521615134aadf61c34b82534", "committedDate": "2020-06-29T19:59:45Z", "message": "re-enable and add logging"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NDc1NzYw", "url": "https://github.com/apache/kafka/pull/8953#pullrequestreview-439475760", "createdAt": "2020-06-29T20:28:27Z", "commit": {"oid": "26ad369ce932bf4c521615134aadf61c34b82534"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMDoyODoyN1rOGqhAAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMDoyODoyN1rOGqhAAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzNDA0OA==", "bodyText": "nit: should we also log expected records then?", "url": "https://github.com/apache/kafka/pull/8953#discussion_r447234048", "createdAt": "2020-06-29T20:28:27Z", "author": {"login": "abbccdda"}, "path": "streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java", "diffHunk": "@@ -594,7 +594,7 @@ public static void waitForStandbyCompletion(final KafkaStreams streams,\n                 final List<KeyValue<K, V>> readData =\n                     readKeyValues(topic, consumer, waitTime, expectedNumRecords);\n                 accumData.addAll(readData);\n-                assertThat(reason, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords)));\n+                assertThat(reason + \",  currently accumulated data is \" + accumData, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26ad369ce932bf4c521615134aadf61c34b82534"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1407, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}