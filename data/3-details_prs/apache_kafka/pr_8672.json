{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE4NDc5NTg0", "number": 8672, "title": "KAFKA-10002; Improve performances of StopReplicaRequest with large number of partitions to be deleted", "bodyText": "Update checkpoint files once for all deleted partitions instead of updating them for each deleted partitions. With this, a stop replica requests with 2000 partitions to be deleted takes ~2 secs instead of ~40 secs previously.\nRefactor the checkpointing methods to not compute the logsByDir all the time. It is now reused as much as possible.\nRefactor the exception handling. Some checkpointing methods were handling IOException but the underlying write process already catches them and throws KafkaStorageException instead.\nReduce the logging in the log cleaner manager. It does not log anymore when a partition is deleted as it is not a useful information.\n\nCommitter Checklist (excluded from commit message)\n\n Verify design and implementation\n Verify test coverage and CI build status\n Verify documentation (including upgrade notes)", "createdAt": "2020-05-15T09:27:45Z", "url": "https://github.com/apache/kafka/pull/8672", "merged": true, "mergeCommit": {"oid": "43d43e6c7bbfbc87d0288f7b934d5b6e0ebf1913"}, "closed": true, "closedAt": "2020-07-14T00:49:14Z", "author": {"login": "dajac"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABchqakcgFqTQxMzAxMjk4NA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc0jKwNAFqTQ0NzM1OTI3Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzMDEyOTg0", "url": "https://github.com/apache/kafka/pull/8672#pullrequestreview-413012984", "createdAt": "2020-05-15T23:10:37Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMzoxMDozN1rOGWWE_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMzoxMDozN1rOGWWE_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjA4MzU4MQ==", "bodyText": "Nit: typo ofr.", "url": "https://github.com/apache/kafka/pull/8672#discussion_r426083581", "createdAt": "2020-05-15T23:10:37Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -324,8 +324,17 @@ class ReplicaManager(val config: KafkaConfig,\n       brokerTopicStats.removeMetrics(topic)\n   }\n \n-  def stopReplica(topicPartition: TopicPartition, deletePartition: Boolean): Unit  = {\n+  def stopReplica(topicPartition: TopicPartition,\n+                  deletePartition: Boolean,\n+                  logDirs: mutable.Set[File]): Unit  = {\n     if (deletePartition) {\n+      val log = logManager.getLog(topicPartition)\n+      val futureLog = logManager.getLog(topicPartition, isFuture = true)\n+\n+      // Collect log dirs ofr the partition for future checkpointing", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 12}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NTU5NzM5", "url": "https://github.com/apache/kafka/pull/8672#pullrequestreview-425559739", "createdAt": "2020-06-05T19:15:02Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxOToxNTowMlrOGf6Zdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQyMDowNjowNVrOGf74AQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExNTgzMQ==", "bodyText": "nit: remove Logs from name?", "url": "https://github.com/apache/kafka/pull/8672#discussion_r436115831", "createdAt": "2020-06-05T19:15:02Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -465,12 +465,15 @@ class LogManager(logDirs: Seq[File],\n       for ((dir, dirJobs) <- jobs) {\n         dirJobs.foreach(_.get)\n \n+        val logsInDir = localLogsByDir.getOrElse(dir.getAbsolutePath, Map.empty)\n+\n         // update the last flush point\n         debug(s\"Updating recovery points at $dir\")\n-        checkpointRecoveryOffsetsAndCleanSnapshot(dir, localLogsByDir.getOrElse(dir.toString, Map()).values.toSeq)\n+        checkpointLogsRecoveryOffsetsInDir(logsInDir, dir)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyMDg0Mg==", "bodyText": "There are a couple place where we have this code. Maybe it make sense to have an overload which accepts the directory.\nBy the way, logsByDir can be private.", "url": "https://github.com/apache/kafka/pull/8672#discussion_r436120842", "createdAt": "2020-06-05T19:26:44Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -580,53 +586,105 @@ class LogManager(logDirs: Seq[File],\n    * to avoid exposing data that have been deleted by DeleteRecordsRequest\n    */\n   def checkpointLogStartOffsets(): Unit = {\n-    liveLogDirs.foreach(checkpointLogStartOffsetsInDir)\n+    val logsByDirCached = logsByDir\n+    liveLogDirs.foreach { logDir =>\n+      checkpointLogsStartOffsetsInDir(\n+        logsByDirCached.getOrElse(logDir.getAbsolutePath, Map.empty), logDir)\n+    }\n   }\n \n   /**\n-    * Write the recovery checkpoint file for all logs in provided directory and clean older snapshots for provided logs.\n-    *\n-    * @param dir the directory in which logs are checkpointed\n-    * @param logsToCleanSnapshot logs whose snapshots need to be cleaned\n-    */\n+   * Write the checkpoint files for all the provided directories. This is used to cleanup\n+   * checkpoints after having deleted partitions.\n+   */\n+  def checkpoint(logDirs: Set[File]): Unit = {\n+    val logsByDirCached = logsByDir\n+    logDirs.foreach { logDir =>\n+      val partitionToLog = logsByDirCached.getOrElse(logDir.getAbsolutePath, Map.empty)\n+      if (cleaner != null) {\n+        cleaner.updateCheckpoints(logDir)\n+      }\n+      checkpointLogsRecoveryOffsetsInDir(partitionToLog, logDir)\n+      checkpointLogsStartOffsetsInDir(partitionToLog, logDir)\n+    }\n+  }\n+\n+  /**\n+   * Clean snapshots of the provided logs in the provided directory.\n+   *\n+   * @param logsToCleanSnapshot the logs whose snapshots will be cleaned\n+   * @param dir the directory in which the logs are\n+   */\n   // Only for testing\n-  private[log] def checkpointRecoveryOffsetsAndCleanSnapshot(dir: File, logsToCleanSnapshot: Seq[Log]): Unit = {\n+  private[log] def cleanSnapshotsInDir(logsToCleanSnapshot: Seq[Log], dir: File): Unit = {\n     try {\n-      checkpointLogRecoveryOffsetsInDir(dir)\n       logsToCleanSnapshot.foreach(_.deleteSnapshotsAfterRecoveryPointCheckpoint())\n     } catch {\n       case e: IOException =>\n-        logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath, s\"Disk error while writing to recovery point \" +\n-          s\"file in directory $dir\", e)\n+        logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath,\n+          s\"Disk error while writing to recovery point file in directory $dir\", e)\n     }\n   }\n \n-  private def checkpointLogRecoveryOffsetsInDir(dir: File): Unit = {\n-    for {\n-      partitionToLog <- logsByDir.get(dir.getAbsolutePath)\n-      checkpoint <- recoveryPointCheckpoints.get(dir)\n-    } {\n-      checkpoint.write(partitionToLog.map { case (tp, log) => tp -> log.recoveryPoint })\n+  /**\n+   * Checkpoint log recovery offsets for all the logs in the provided directory.\n+   *\n+   * @param dir the directory in which logs are checkpointed\n+   */\n+  // Only for testing\n+  private[log] def checkpointRecoveryOffsetsInDir(dir: File): Unit = {\n+    val partitionToLog = logsByDir.getOrElse(dir.getAbsolutePath, Map.empty)\n+    checkpointLogsRecoveryOffsetsInDir(partitionToLog, dir)\n+  }\n+\n+  /**\n+   * Checkpoint log recovery and start offsets for all logs in the provided directory.\n+   *\n+   * @param dir the directory in which logs are checkpointed\n+   */\n+  private def checkpointRecoveryAndLogStartOffsetsInDir(dir: File): Unit = {\n+    val partitionToLog = logsByDir.getOrElse(dir.getAbsolutePath, Map.empty)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyNDU5NQ==", "bodyText": "Given that we split checkpointRecoveryOffsetsAndCleanSnapshot, I'm curious why we added this.", "url": "https://github.com/apache/kafka/pull/8672#discussion_r436124595", "createdAt": "2020-06-05T19:36:00Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -580,53 +586,105 @@ class LogManager(logDirs: Seq[File],\n    * to avoid exposing data that have been deleted by DeleteRecordsRequest\n    */\n   def checkpointLogStartOffsets(): Unit = {\n-    liveLogDirs.foreach(checkpointLogStartOffsetsInDir)\n+    val logsByDirCached = logsByDir\n+    liveLogDirs.foreach { logDir =>\n+      checkpointLogsStartOffsetsInDir(\n+        logsByDirCached.getOrElse(logDir.getAbsolutePath, Map.empty), logDir)\n+    }\n   }\n \n   /**\n-    * Write the recovery checkpoint file for all logs in provided directory and clean older snapshots for provided logs.\n-    *\n-    * @param dir the directory in which logs are checkpointed\n-    * @param logsToCleanSnapshot logs whose snapshots need to be cleaned\n-    */\n+   * Write the checkpoint files for all the provided directories. This is used to cleanup\n+   * checkpoints after having deleted partitions.\n+   */\n+  def checkpoint(logDirs: Set[File]): Unit = {\n+    val logsByDirCached = logsByDir\n+    logDirs.foreach { logDir =>\n+      val partitionToLog = logsByDirCached.getOrElse(logDir.getAbsolutePath, Map.empty)\n+      if (cleaner != null) {\n+        cleaner.updateCheckpoints(logDir)\n+      }\n+      checkpointLogsRecoveryOffsetsInDir(partitionToLog, logDir)\n+      checkpointLogsStartOffsetsInDir(partitionToLog, logDir)\n+    }\n+  }\n+\n+  /**\n+   * Clean snapshots of the provided logs in the provided directory.\n+   *\n+   * @param logsToCleanSnapshot the logs whose snapshots will be cleaned\n+   * @param dir the directory in which the logs are\n+   */\n   // Only for testing\n-  private[log] def checkpointRecoveryOffsetsAndCleanSnapshot(dir: File, logsToCleanSnapshot: Seq[Log]): Unit = {\n+  private[log] def cleanSnapshotsInDir(logsToCleanSnapshot: Seq[Log], dir: File): Unit = {\n     try {\n-      checkpointLogRecoveryOffsetsInDir(dir)\n       logsToCleanSnapshot.foreach(_.deleteSnapshotsAfterRecoveryPointCheckpoint())\n     } catch {\n       case e: IOException =>\n-        logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath, s\"Disk error while writing to recovery point \" +\n-          s\"file in directory $dir\", e)\n+        logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath,\n+          s\"Disk error while writing to recovery point file in directory $dir\", e)\n     }\n   }\n \n-  private def checkpointLogRecoveryOffsetsInDir(dir: File): Unit = {\n-    for {\n-      partitionToLog <- logsByDir.get(dir.getAbsolutePath)\n-      checkpoint <- recoveryPointCheckpoints.get(dir)\n-    } {\n-      checkpoint.write(partitionToLog.map { case (tp, log) => tp -> log.recoveryPoint })\n+  /**\n+   * Checkpoint log recovery offsets for all the logs in the provided directory.\n+   *\n+   * @param dir the directory in which logs are checkpointed\n+   */\n+  // Only for testing\n+  private[log] def checkpointRecoveryOffsetsInDir(dir: File): Unit = {\n+    val partitionToLog = logsByDir.getOrElse(dir.getAbsolutePath, Map.empty)\n+    checkpointLogsRecoveryOffsetsInDir(partitionToLog, dir)\n+  }\n+\n+  /**\n+   * Checkpoint log recovery and start offsets for all logs in the provided directory.\n+   *\n+   * @param dir the directory in which logs are checkpointed\n+   */\n+  private def checkpointRecoveryAndLogStartOffsetsInDir(dir: File): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyNzg0OA==", "bodyText": "nit: k -> tp?", "url": "https://github.com/apache/kafka/pull/8672#discussion_r436127848", "createdAt": "2020-06-05T19:43:57Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -580,53 +586,105 @@ class LogManager(logDirs: Seq[File],\n    * to avoid exposing data that have been deleted by DeleteRecordsRequest\n    */\n   def checkpointLogStartOffsets(): Unit = {\n-    liveLogDirs.foreach(checkpointLogStartOffsetsInDir)\n+    val logsByDirCached = logsByDir\n+    liveLogDirs.foreach { logDir =>\n+      checkpointLogsStartOffsetsInDir(\n+        logsByDirCached.getOrElse(logDir.getAbsolutePath, Map.empty), logDir)\n+    }\n   }\n \n   /**\n-    * Write the recovery checkpoint file for all logs in provided directory and clean older snapshots for provided logs.\n-    *\n-    * @param dir the directory in which logs are checkpointed\n-    * @param logsToCleanSnapshot logs whose snapshots need to be cleaned\n-    */\n+   * Write the checkpoint files for all the provided directories. This is used to cleanup\n+   * checkpoints after having deleted partitions.\n+   */\n+  def checkpoint(logDirs: Set[File]): Unit = {\n+    val logsByDirCached = logsByDir\n+    logDirs.foreach { logDir =>\n+      val partitionToLog = logsByDirCached.getOrElse(logDir.getAbsolutePath, Map.empty)\n+      if (cleaner != null) {\n+        cleaner.updateCheckpoints(logDir)\n+      }\n+      checkpointLogsRecoveryOffsetsInDir(partitionToLog, logDir)\n+      checkpointLogsStartOffsetsInDir(partitionToLog, logDir)\n+    }\n+  }\n+\n+  /**\n+   * Clean snapshots of the provided logs in the provided directory.\n+   *\n+   * @param logsToCleanSnapshot the logs whose snapshots will be cleaned\n+   * @param dir the directory in which the logs are\n+   */\n   // Only for testing\n-  private[log] def checkpointRecoveryOffsetsAndCleanSnapshot(dir: File, logsToCleanSnapshot: Seq[Log]): Unit = {\n+  private[log] def cleanSnapshotsInDir(logsToCleanSnapshot: Seq[Log], dir: File): Unit = {\n     try {\n-      checkpointLogRecoveryOffsetsInDir(dir)\n       logsToCleanSnapshot.foreach(_.deleteSnapshotsAfterRecoveryPointCheckpoint())\n     } catch {\n       case e: IOException =>\n-        logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath, s\"Disk error while writing to recovery point \" +\n-          s\"file in directory $dir\", e)\n+        logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath,\n+          s\"Disk error while writing to recovery point file in directory $dir\", e)\n     }\n   }\n \n-  private def checkpointLogRecoveryOffsetsInDir(dir: File): Unit = {\n-    for {\n-      partitionToLog <- logsByDir.get(dir.getAbsolutePath)\n-      checkpoint <- recoveryPointCheckpoints.get(dir)\n-    } {\n-      checkpoint.write(partitionToLog.map { case (tp, log) => tp -> log.recoveryPoint })\n+  /**\n+   * Checkpoint log recovery offsets for all the logs in the provided directory.\n+   *\n+   * @param dir the directory in which logs are checkpointed\n+   */\n+  // Only for testing\n+  private[log] def checkpointRecoveryOffsetsInDir(dir: File): Unit = {\n+    val partitionToLog = logsByDir.getOrElse(dir.getAbsolutePath, Map.empty)\n+    checkpointLogsRecoveryOffsetsInDir(partitionToLog, dir)\n+  }\n+\n+  /**\n+   * Checkpoint log recovery and start offsets for all logs in the provided directory.\n+   *\n+   * @param dir the directory in which logs are checkpointed\n+   */\n+  private def checkpointRecoveryAndLogStartOffsetsInDir(dir: File): Unit = {\n+    val partitionToLog = logsByDir.getOrElse(dir.getAbsolutePath, Map.empty)\n+    checkpointLogsRecoveryOffsetsInDir(partitionToLog, dir)\n+    checkpointLogsStartOffsetsInDir(partitionToLog, dir)\n+  }\n+\n+  /**\n+   * Checkpoint log recovery offsets for all the provided logs in the provided directory.\n+   *\n+   * @param logs the logs and logs to be checkpointed\n+   * @param dir the directory in which logs are checkpointed\n+   */\n+  private def checkpointLogsRecoveryOffsetsInDir(logs: Map[TopicPartition, Log],\n+                                                 dir: File): Unit = {\n+    try {\n+      recoveryPointCheckpoints.get(dir).foreach { checkpoint =>\n+        val recoveryOffsets = logs.map { case (tp, log) => tp -> log.recoveryPoint }\n+        checkpoint.write(recoveryOffsets)\n+      }\n+    } catch {\n+      case e: KafkaStorageException =>\n+        error(s\"Disk error while writing recovery offsets checkpoint in directory $dir: ${e.getMessage}\")\n     }\n   }\n \n   /**\n-   * Checkpoint log start offset for all logs in provided directory.\n+   * Checkpoint log start offsets for all the provided logs in the provided directory.\n+   *\n+   * @param logs the partitions and logs to be checkpointed\n+   * @param dir the directory in which logs are checkpointed\n    */\n-  private def checkpointLogStartOffsetsInDir(dir: File): Unit = {\n-    for {\n-      partitionToLog <- logsByDir.get(dir.getAbsolutePath)\n-      checkpoint <- logStartOffsetCheckpoints.get(dir)\n-    } {\n-      try {\n-        val logStartOffsets = partitionToLog.collect {\n+  private def checkpointLogsStartOffsetsInDir(logs: Map[TopicPartition, Log],\n+                                              dir: File): Unit = {\n+    try {\n+      logStartOffsetCheckpoints.get(dir).foreach { checkpoint =>\n+        val logStartOffsets = logs.collect {\n           case (k, log) if log.logStartOffset > log.logSegments.head.baseOffset => k -> log.logStartOffset", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzMTA3Mw==", "bodyText": "Previously we were cleaning snapshots here. I agree it was probably unnecessary, but there seems little harm in it. I guess the main thing is that logically it makes little sense to couple these operations together even if the events which trigger them are often the same. Is that what you were thinking?", "url": "https://github.com/apache/kafka/pull/8672#discussion_r436131073", "createdAt": "2020-06-05T19:50:27Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -878,8 +936,7 @@ class LogManager(logDirs: Seq[File],\n         // Now that replica in source log directory has been successfully renamed for deletion.\n         // Close the log, update checkpoint files, and enqueue this log to be deleted.\n         sourceLog.close()\n-        checkpointRecoveryOffsetsAndCleanSnapshot(sourceLog.parentDirFile, ArrayBuffer.empty)\n-        checkpointLogStartOffsetsInDir(sourceLog.parentDirFile)\n+        checkpointRecoveryAndLogStartOffsetsInDir(sourceLog.parentDirFile)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNTA4Nw==", "bodyText": "I believe it would be straightforward to update the uses of this method in the test case to use stopReplicas instead. Then we could make this private, which would make the side effect less annoying.", "url": "https://github.com/apache/kafka/pull/8672#discussion_r436135087", "createdAt": "2020-06-05T19:55:46Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -324,8 +324,17 @@ class ReplicaManager(val config: KafkaConfig,\n       brokerTopicStats.removeMetrics(topic)\n   }\n \n-  def stopReplica(topicPartition: TopicPartition, deletePartition: Boolean): Unit  = {\n+  def stopReplica(topicPartition: TopicPartition,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNjg1OA==", "bodyText": "It is a little weird to abort and pause cleaning if the partition is getting deleted. Maybe we should have a separate method like removePartition or something like that.", "url": "https://github.com/apache/kafka/pull/8672#discussion_r436136858", "createdAt": "2020-06-05T19:58:20Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/LogCleanerManager.scala", "diffHunk": "@@ -273,7 +272,7 @@ private[log] class LogCleanerManager(val logDirs: Seq[File],\n    *  6. If the partition is already paused, a new call to this function\n    *     will increase the paused count by one.\n    */\n-  def abortAndPauseCleaning(topicPartition: TopicPartition): Unit = {\n+  def abortAndPauseCleaning(topicPartition: TopicPartition, partitionDeleted: Boolean = false): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE0MDAzMw==", "bodyText": "With this change, it is up to the caller to ensure offsets are checkpointed correctly after a deletion. It would be better from an encapsulation perspective to keep LogManager in charge of that. One idea would be to offer a batched asyncDelete. The involvement of Partition may make this a bit complex though.", "url": "https://github.com/apache/kafka/pull/8672#discussion_r436140033", "createdAt": "2020-06-05T20:06:05Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -912,12 +969,9 @@ class LogManager(logDirs: Seq[File],\n     if (removedLog != null) {\n       //We need to wait until there is no more cleaning task on the log to be deleted before actually deleting it.\n       if (cleaner != null && !isFuture) {\n-        cleaner.abortCleaning(topicPartition)\n-        cleaner.updateCheckpoints(removedLog.parentDirFile)\n+        cleaner.abortCleaning(topicPartition, partitionDeleted = true)\n       }\n       removedLog.renameDir(Log.logDeleteDirName(topicPartition))\n-      checkpointRecoveryOffsetsAndCleanSnapshot(removedLog.parentDirFile, ArrayBuffer.empty)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 224}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3MDczMzU0", "url": "https://github.com/apache/kafka/pull/8672#pullrequestreview-427073354", "createdAt": "2020-06-09T12:11:10Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxMjoxMToxMVrOGhGQzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxMjoxMToxMVrOGhGQzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM1ODc5Nw==", "bodyText": "FYI: This block of code appears twice so it would merit its own method. I haven't done it because that I felt that it would mix too many things in one method and the method name would be too long. Therefore, I left the optimisation of computing and reusing the logsByDir on the caller side. I don't feel too strongly about this though.", "url": "https://github.com/apache/kafka/pull/8672#discussion_r437358797", "createdAt": "2020-06-09T12:11:11Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -869,17 +903,18 @@ class LogManager(logDirs: Seq[File],\n       currentLogs.put(topicPartition, destLog)\n       if (cleaner != null) {\n         cleaner.alterCheckpointDir(topicPartition, sourceLog.parentDirFile, destLog.parentDirFile)\n-        cleaner.resumeCleaning(Seq(topicPartition))\n-        info(s\"Compaction for partition $topicPartition is resumed\")\n+        resumeCleaning(topicPartition)\n       }\n \n       try {\n         sourceLog.renameDir(Log.logDeleteDirName(topicPartition))\n         // Now that replica in source log directory has been successfully renamed for deletion.\n         // Close the log, update checkpoint files, and enqueue this log to be deleted.\n         sourceLog.close()\n-        checkpointRecoveryOffsetsAndCleanSnapshot(sourceLog.parentDirFile, ArrayBuffer.empty)\n-        checkpointLogStartOffsetsInDir(sourceLog.parentDirFile)\n+        val logDir = sourceLog.parentDirFile\n+        val logsToCheckpoint = logsByDir(logDir)\n+        checkpointRecoveryOffsetsAndCleanSnapshotsInDir(logDir, logsToCheckpoint, ArrayBuffer.empty)\n+        checkpointLogStartOffsetsInDir(logDir, logsToCheckpoint)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 259}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ea6df3eb76cf4b7b5eb9f27cd099171ff428f57", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/4ea6df3eb76cf4b7b5eb9f27cd099171ff428f57", "committedDate": "2020-06-18T19:43:32Z", "message": "KAFKA-10002; Improve performances of StopReplicaRequest with large number of partitions to be deleted"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "affaff5becff5bd8d48279eb6f2cd917f6317d6b", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/affaff5becff5bd8d48279eb6f2cd917f6317d6b", "committedDate": "2020-06-18T19:43:32Z", "message": "Refactor based on feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "afb990a8dbc8075001f7b558ee5647ab0e0a8efe", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/afb990a8dbc8075001f7b558ee5647ab0e0a8efe", "committedDate": "2020-06-18T19:43:32Z", "message": "Few more refactor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "543536bee3bcb1910d957a7a80c412695e279f24", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/543536bee3bcb1910d957a7a80c412695e279f24", "committedDate": "2020-06-18T19:43:32Z", "message": "Add a new LogManager.asyncDelete that works on a batch of topic-partitions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "115ff6bb27ac6b3200a9316c4e8fed92f248d32f", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/115ff6bb27ac6b3200a9316c4e8fed92f248d32f", "committedDate": "2020-06-18T19:43:32Z", "message": "Rework checkpointing methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da7216dec5d8d18ab728004c77b87ebdbfa94ca3", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/da7216dec5d8d18ab728004c77b87ebdbfa94ca3", "committedDate": "2020-06-18T19:43:33Z", "message": "nits"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7cd1f6df32b5db4f78a470edb4a5f967476e16a", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/d7cd1f6df32b5db4f78a470edb4a5f967476e16a", "committedDate": "2020-06-18T19:48:55Z", "message": "fixup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "d7cd1f6df32b5db4f78a470edb4a5f967476e16a", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/d7cd1f6df32b5db4f78a470edb4a5f967476e16a", "committedDate": "2020-06-18T19:48:55Z", "message": "fixup"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3NjQ5Mzcw", "url": "https://github.com/apache/kafka/pull/8672#pullrequestreview-437649370", "createdAt": "2020-06-25T16:12:52Z", "commit": {"oid": "d7cd1f6df32b5db4f78a470edb4a5f967476e16a"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNjoxMjo1M1rOGpB30A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNjoyOTowMVrOGpChbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY3NTQ3Mg==", "bodyText": "The caller seems to always set deleteLogs to false. Could we just remove this param and the associated code?", "url": "https://github.com/apache/kafka/pull/8672#discussion_r445675472", "createdAt": "2020-06-25T16:12:53Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/cluster/Partition.scala", "diffHunk": "@@ -459,7 +459,12 @@ class Partition(val topicPartition: TopicPartition,\n     }\n   }\n \n-  def delete(): Unit = {\n+  /**\n+   * Delete the partition. The underlying logs are deleted by default but one can choose to not\n+   * delete them automatically and to delete them manually later one. For instance, we do this\n+   * in the handling of the StopReplicaRequest to batch the deletions and checkpoint only once.\n+   */\n+  def delete(deleteLogs: Boolean = true): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7cd1f6df32b5db4f78a470edb4a5f967476e16a"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY4MDkyNA==", "bodyText": "It's probably useful to log the class of the exception too.", "url": "https://github.com/apache/kafka/pull/8672#discussion_r445680924", "createdAt": "2020-06-25T16:21:03Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -433,29 +425,34 @@ class ReplicaManager(val config: KafkaConfig,\n             case HostedPartition.None =>\n               // Delete log and corresponding folders in case replica manager doesn't hold them anymore.\n               // This could happen when topic is being deleted while broker is down and recovers.\n-              stoppedPartitions += topicPartition -> partitionState\n+              stoppedPartitions += topicPartition\n+              if (deletePartition)\n+                deletedPartitions += topicPartition\n+              responseMap.put(topicPartition, Errors.NONE)\n           }\n         }\n \n         // First stop fetchers for all partitions, then stop the corresponding replicas\n-        val partitions = stoppedPartitions.keySet\n-        replicaFetcherManager.removeFetcherForPartitions(partitions)\n-        replicaAlterLogDirsManager.removeFetcherForPartitions(partitions)\n+        replicaFetcherManager.removeFetcherForPartitions(stoppedPartitions)\n+        replicaAlterLogDirsManager.removeFetcherForPartitions(stoppedPartitions)\n \n-        stoppedPartitions.foreach { case (topicPartition, partitionState) =>\n-          val deletePartition = partitionState.deletePartition\n-          try {\n-            stopReplica(topicPartition, deletePartition)\n-            responseMap.put(topicPartition, Errors.NONE)\n-          } catch {\n+        // Delete the logs and checkpoint\n+        logManager.asyncDelete(deletedPartitions, (topicPartition, exception) => {\n+          exception match {\n             case e: KafkaStorageException =>\n-              stateChangeLogger.error(s\"Ignoring StopReplica request (delete=$deletePartition) from \" +\n+              stateChangeLogger.error(s\"Ignoring StopReplica request (delete=true) from \" +\n                 s\"controller $controllerId with correlation id $correlationId \" +\n                 s\"epoch $controllerEpoch for partition $topicPartition as the local replica for the \" +\n-                \"partition is in an offline log directory\", e)\n+                \"partition is in an offline log directory\")\n               responseMap.put(topicPartition, Errors.KAFKA_STORAGE_ERROR)\n+\n+            case e =>\n+              stateChangeLogger.error(s\"Ignoring StopReplica request (delete=true) from \" +\n+                s\"controller $controllerId with correlation id $correlationId \" +\n+                s\"epoch $controllerEpoch for partition $topicPartition due to ${e.getMessage}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7cd1f6df32b5db4f78a470edb4a5f967476e16a"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY4MzY1Ng==", "bodyText": "This probably should be called logsInDir() ?", "url": "https://github.com/apache/kafka/pull/8672#discussion_r445683656", "createdAt": "2020-06-25T16:25:16Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -1018,6 +1097,15 @@ class LogManager(logDirs: Seq[File],\n     byDir\n   }\n \n+  private def logsByDir(dir: File): Map[TopicPartition, Log] = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7cd1f6df32b5db4f78a470edb4a5f967476e16a"}, "originalPosition": 357}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY4NjEyNA==", "bodyText": "This probably should be called logsInDir() ?", "url": "https://github.com/apache/kafka/pull/8672#discussion_r445686124", "createdAt": "2020-06-25T16:29:01Z", "author": {"login": "junrao"}, "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -1018,6 +1097,15 @@ class LogManager(logDirs: Seq[File],\n     byDir\n   }\n \n+  private def logsByDir(dir: File): Map[TopicPartition, Log] = {\n+    logsByDir.getOrElse(dir.getAbsolutePath, Map.empty)\n+  }\n+\n+  private def logsByDir(cachedLogsByDir: Map[String, Map[TopicPartition, Log]],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7cd1f6df32b5db4f78a470edb4a5f967476e16a"}, "originalPosition": 361}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7557c7e147d958ee2cfd0cc74ad5644b02052551", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/7557c7e147d958ee2cfd0cc74ad5644b02052551", "committedDate": "2020-06-26T13:50:31Z", "message": "Address Jun's comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzYxMjU3", "url": "https://github.com/apache/kafka/pull/8672#pullrequestreview-446761257", "createdAt": "2020-07-11T00:41:36Z", "commit": {"oid": "7557c7e147d958ee2cfd0cc74ad5644b02052551"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMVQwMDo0MTozNlrOGwJB4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMVQwMDo0MTo1N1rOGwJCDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzMjc2OQ==", "bodyText": "Could we verify the expected logStartOffset?", "url": "https://github.com/apache/kafka/pull/8672#discussion_r453132769", "createdAt": "2020-07-11T00:41:36Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala", "diffHunk": "@@ -2058,13 +2070,37 @@ class ReplicaManagerTest {\n     val partition = replicaManager.createPartition(tp0)\n     partition.createLogIfNotExists(isNew = false, isFutureReplica = false, offsetCheckpoints)\n \n+    val logDirFailureChannel = new LogDirFailureChannel(replicaManager.config.logDirs.size)\n+    val logDir = partition.log.get.parentDirFile\n+\n+    def readRecoveryPointCheckpoint(): Map[TopicPartition, Long] = {\n+      new OffsetCheckpointFile(new File(logDir, LogManager.RecoveryPointCheckpointFile),\n+        logDirFailureChannel).read()\n+    }\n+\n+    def readLogStartOffsetCheckpoint(): Map[TopicPartition, Long] = {\n+      new OffsetCheckpointFile(new File(logDir, LogManager.LogStartOffsetCheckpointFile),\n+        logDirFailureChannel).read()\n+    }\n+\n     val becomeLeaderRequest = new LeaderAndIsrRequest.Builder(ApiKeys.LEADER_AND_ISR.latestVersion, 0, 0, brokerEpoch,\n       Seq(leaderAndIsrPartitionState(tp0, 1, 0, Seq(0, 1), true)).asJava,\n       Set(new Node(0, \"host1\", 0), new Node(1, \"host2\", 1)).asJava\n     ).build()\n \n     replicaManager.becomeLeaderOrFollower(1, becomeLeaderRequest, (_, _) => ())\n \n+    val batch = TestUtils.records(records = List(\n+      new SimpleRecord(10, \"k1\".getBytes, \"v1\".getBytes),\n+      new SimpleRecord(11, \"k2\".getBytes, \"v2\".getBytes)))\n+    partition.appendRecordsToLeader(batch, AppendOrigin.Client, requiredAcks = 0)\n+    partition.log.get.updateHighWatermark(2L)\n+    partition.log.get.maybeIncrementLogStartOffset(1L, LeaderOffsetIncremented)\n+    replicaManager.logManager.checkpointLogRecoveryOffsets()\n+    replicaManager.logManager.checkpointLogStartOffsets()\n+    assertTrue(readRecoveryPointCheckpoint().contains(tp0))\n+    assertTrue(readLogStartOffsetCheckpoint().contains(tp0))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7557c7e147d958ee2cfd0cc74ad5644b02052551"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzMjgxNA==", "bodyText": "Could we verify the expected recovery offset?", "url": "https://github.com/apache/kafka/pull/8672#discussion_r453132814", "createdAt": "2020-07-11T00:41:57Z", "author": {"login": "junrao"}, "path": "core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala", "diffHunk": "@@ -2058,13 +2070,37 @@ class ReplicaManagerTest {\n     val partition = replicaManager.createPartition(tp0)\n     partition.createLogIfNotExists(isNew = false, isFutureReplica = false, offsetCheckpoints)\n \n+    val logDirFailureChannel = new LogDirFailureChannel(replicaManager.config.logDirs.size)\n+    val logDir = partition.log.get.parentDirFile\n+\n+    def readRecoveryPointCheckpoint(): Map[TopicPartition, Long] = {\n+      new OffsetCheckpointFile(new File(logDir, LogManager.RecoveryPointCheckpointFile),\n+        logDirFailureChannel).read()\n+    }\n+\n+    def readLogStartOffsetCheckpoint(): Map[TopicPartition, Long] = {\n+      new OffsetCheckpointFile(new File(logDir, LogManager.LogStartOffsetCheckpointFile),\n+        logDirFailureChannel).read()\n+    }\n+\n     val becomeLeaderRequest = new LeaderAndIsrRequest.Builder(ApiKeys.LEADER_AND_ISR.latestVersion, 0, 0, brokerEpoch,\n       Seq(leaderAndIsrPartitionState(tp0, 1, 0, Seq(0, 1), true)).asJava,\n       Set(new Node(0, \"host1\", 0), new Node(1, \"host2\", 1)).asJava\n     ).build()\n \n     replicaManager.becomeLeaderOrFollower(1, becomeLeaderRequest, (_, _) => ())\n \n+    val batch = TestUtils.records(records = List(\n+      new SimpleRecord(10, \"k1\".getBytes, \"v1\".getBytes),\n+      new SimpleRecord(11, \"k2\".getBytes, \"v2\".getBytes)))\n+    partition.appendRecordsToLeader(batch, AppendOrigin.Client, requiredAcks = 0)\n+    partition.log.get.updateHighWatermark(2L)\n+    partition.log.get.maybeIncrementLogStartOffset(1L, LeaderOffsetIncremented)\n+    replicaManager.logManager.checkpointLogRecoveryOffsets()\n+    replicaManager.logManager.checkpointLogStartOffsets()\n+    assertTrue(readRecoveryPointCheckpoint().contains(tp0))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7557c7e147d958ee2cfd0cc74ad5644b02052551"}, "originalPosition": 79}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e23b90f9ac98309c0ec88de9315ef90537aba7d", "author": {"user": {"login": "dajac", "name": "David Jacot"}}, "url": "https://github.com/apache/kafka/commit/3e23b90f9ac98309c0ec88de9315ef90537aba7d", "committedDate": "2020-07-13T13:18:34Z", "message": "Address Jun's comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3MzU5Mjc2", "url": "https://github.com/apache/kafka/pull/8672#pullrequestreview-447359276", "createdAt": "2020-07-13T15:28:34Z", "commit": {"oid": "3e23b90f9ac98309c0ec88de9315ef90537aba7d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1018, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}