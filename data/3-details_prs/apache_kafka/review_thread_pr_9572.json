{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE2OTE5NDQw", "number": 9572, "reviewThreads": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQyMzowOTo1MFrOE2RH5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMToyNDo0OVrOE6Pbqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1MzM5MTExOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQyMzowOTo1MFrOHvAQZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMzo1NToyNlrOHzDOhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw==", "bodyText": "I am not sure if I should just expose cache or pass it along. It is about 4 levels deep", "url": "https://github.com/apache/kafka/pull/9572#discussion_r519049317", "createdAt": "2020-11-06T23:09:50Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ5ODU2NA==", "bodyText": "I am in favour of keeping a reference to the thread cache in the StreamThread and do the re-sizing here. I think it makes the code a bit easier to follow.\nYou will need synchronization, because the thread that will add the new stream thread will also resize the thread caches.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520498564", "createdAt": "2020-11-10T11:41:05Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5OTc5Mw==", "bodyText": "Are the thread caches not independent of each other? Also I was not planning on having the new thread resize the cache but the calling thread do so", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520699793", "createdAt": "2020-11-10T16:30:50Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI1MTMwNA==", "bodyText": "I was not planning on having the new thread resize the cache but the calling thread do so\n\nThat is what I am saying \"the thread that will add the new stream thread\" is the calling thread. The new stream thread cannot resize the caches of the other stream threads because it is not aware of the other stream threads. Still we need synchronization because the calling thread will access and modify the thread caches of all stream threads and all stream threads will access and modify their own thread cache during normal processing.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521251304", "createdAt": "2020-11-11T10:10:25Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ0OTQxOQ==", "bodyText": "I'm not sure I follow. If we make it so that each thread is responsible for resizing their own independent cache then why would the method need to synchronized as each call should not affect the others. And if one thread does all the work there should only be one call. Unless you are thinking about multiple threads adding threads at the same time?\nMaybe I don't understand how the cache is set up well enough?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521449419", "createdAt": "2020-11-11T15:44:39Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI5MjI5NQ==", "bodyText": "Talked about off line. The named cache is already synchronized. Also made max cache size volatile", "url": "https://github.com/apache/kafka/pull/9572#discussion_r523292295", "createdAt": "2020-11-13T23:55:26Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MjY5Njk5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMDoxNDowM1rOHwVaBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjoxMjo1OFrOHwkK4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NDQyMA==", "bodyText": "I see that this check was there before, but I actually think it is not needed because the configs are validated and there CACHE_MAX_BYTES_BUFFERING_CONFIG is specified as at least 0.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520444420", "createdAt": "2020-11-10T10:14:03Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,21 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        if (totalCacheSize < 0) {\n+            totalCacheSize = 0L;\n+            log.warn(\"Negative cache size passed in. Reverting to cache size of 0 bytes.\");\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4NjMwNw==", "bodyText": "good to know", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520686307", "createdAt": "2020-11-10T16:12:58Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,21 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        if (totalCacheSize < 0) {\n+            totalCacheSize = 0L;\n+            log.warn(\"Negative cache size passed in. Reverting to cache size of 0 bytes.\");\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NDQyMA=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MjcwNTYyOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMDoxNjowM1rOHwVfWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjoxMzoxM1rOHwkLnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NTc4Nw==", "bodyText": "I think this can be a final long if we remove the check as I proposed below.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520445787", "createdAt": "2020-11-10T10:16:03Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -155,6 +155,7 @@\n     private final StreamsMetricsImpl streamsMetrics;\n     private final ProcessorTopology taskTopology;\n     private final ProcessorTopology globalTaskTopology;\n+    private Long totalCacheSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4NjQ5NQ==", "bodyText": "yes it can", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520686495", "createdAt": "2020-11-10T16:13:13Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -155,6 +155,7 @@\n     private final StreamsMetricsImpl streamsMetrics;\n     private final ProcessorTopology taskTopology;\n     private final ProcessorTopology globalTaskTopology;\n+    private Long totalCacheSize;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NTc4Nw=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MzA3OTM1OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMTo1MjozN1rOHwZFmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjoyMjowMVrOHwkljA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUwNDcyOQ==", "bodyText": "This loop has the disadvantage that it first evict entries of one named cache, if all entries are evicted and we still need to free space, it starts to evict entries of the next named cache etc. I guess it would be better to avoid such a skewed emission of records to downstream by continuously iterating over the named caches and evict one entry at a time from each named cache until enough space is freed.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520504729", "createdAt": "2020-11-10T11:52:37Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +71,16 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            for (final NamedCache cache : caches.values()) {\n+                maybeEvict(cache.name());\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5MzEzMg==", "bodyText": "I would expect it to take a bit to repopulate the cache to be balanced but you are right it probably better to do so evenly", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520693132", "createdAt": "2020-11-10T16:22:01Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +71,16 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            for (final NamedCache cache : caches.values()) {\n+                maybeEvict(cache.name());\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUwNDcyOQ=="}, "originalCommit": {"oid": "68113b842861d85bda4616ad3d5c2f3a5e4adab9"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2Nzc1NDUzOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxMDowNDo0NlrOHxGcog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxNTo0NDo0OFrOHxSwLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0NzkwNg==", "bodyText": "Why does this need to be a Long instead of a long? The numerical value of the variable is only immutable if we use a long here.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521247906", "createdAt": "2020-11-11T10:04:46Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -155,6 +155,7 @@\n     private final StreamsMetricsImpl streamsMetrics;\n     private final ProcessorTopology taskTopology;\n     private final ProcessorTopology globalTaskTopology;\n+    private final Long totalCacheSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ0OTUxOA==", "bodyText": "I think that its just what the ide defaulted to. Ill change it.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521449518", "createdAt": "2020-11-11T15:44:48Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -155,6 +155,7 @@\n     private final StreamsMetricsImpl streamsMetrics;\n     private final ProcessorTopology taskTopology;\n     private final ProcessorTopology globalTaskTopology;\n+    private final Long totalCacheSize;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0NzkwNg=="}, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2Nzc2MjExOnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxMDowNjo0MlrOHxGhMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxNTo0NDo1M1rOHxSwbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0OTA3NA==", "bodyText": "IMO, the code would be easier navigable if you inline this method. Without the removed check, there is not really a reason to have a method here.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521249074", "createdAt": "2020-11-11T10:06:42Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,17 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ0OTU4Mg==", "bodyText": "I think I agree with you. fixed", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521449582", "createdAt": "2020-11-11T15:44:53Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,17 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0OTA3NA=="}, "originalCommit": null, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDI0NzY0OnYy", "diffSide": "LEFT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODo0MToxOVrOH1Dz_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxOToyMToyNlrOH1Fb8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTAzOA==", "bodyText": "Why do we remove this guard?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525399038", "createdAt": "2020-11-17T18:41:19Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -728,12 +729,8 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 \"must subscribe to at least one source topic or global table.\");\n         }\n \n-        long totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n-        if (totalCacheSize < 0) {\n-            totalCacheSize = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyNTY1MA==", "bodyText": "#9572 (comment)\nIt seems it was not necessary", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525425650", "createdAt": "2020-11-17T19:21:26Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -728,12 +729,8 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 \"must subscribe to at least one source topic or global table.\");\n         }\n \n-        long totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n-        if (totalCacheSize < 0) {\n-            totalCacheSize = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTAzOA=="}, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDI0OTk3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODo0MTo1M1rOH1D1ZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxOToyNDoxMFrOH1FiMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTM5Ng==", "bodyText": "Why move off using hasGlobalTopology?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525399396", "createdAt": "2020-11-17T18:41:53Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -728,12 +729,8 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 \"must subscribe to at least one source topic or global table.\");\n         }\n \n-        long totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n-        if (totalCacheSize < 0) {\n-            totalCacheSize = 0;\n-            log.warn(\"Negative cache size passed in. Reverting to cache size of 0 bytes.\");\n-        }\n-        final long cacheSizePerThread = totalCacheSize / (numStreamThreads + (hasGlobalTopology ? 1 : 0));\n+        totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n+        final long cacheSizePerThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyNzI0OQ==", "bodyText": "It was in a separate method without access to hasGlobalTopology. I supposes if it stays we can move it back", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525427249", "createdAt": "2020-11-17T19:24:10Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -728,12 +729,8 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 \"must subscribe to at least one source topic or global table.\");\n         }\n \n-        long totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n-        if (totalCacheSize < 0) {\n-            totalCacheSize = 0;\n-            log.warn(\"Negative cache size passed in. Reverting to cache size of 0 bytes.\");\n-        }\n-        final long cacheSizePerThread = totalCacheSize / (numStreamThreads + (hasGlobalTopology ? 1 : 0));\n+        totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n+        final long cacheSizePerThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTM5Ng=="}, "originalCommit": null, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDI4MjE1OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODo0OTo0MFrOH1EIiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMToyMToyOVrOH1L8jA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng==", "bodyText": "Seems this duplicates L733. Might be good to extract into a small helper method.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525404296", "createdAt": "2020-11-17T18:49:40Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,13 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private void resizeThreadCache(final int numStreamThreads) {\n+        final long cacheSizePreThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyNjMxNw==", "bodyText": "I did have it in a separate method but helper but when removing the totalCacheSize < 0  check @cadonna thought it would be more readable inline", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525426317", "createdAt": "2020-11-17T19:22:36Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,13 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private void resizeThreadCache(final int numStreamThreads) {\n+        final long cacheSizePreThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQzNTQ1Mg==", "bodyText": "Not sure why the totalCacheSize check is relevant for avoiding code duplication?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525435452", "createdAt": "2020-11-17T19:35:39Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,13 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private void resizeThreadCache(final int numStreamThreads) {\n+        final long cacheSizePreThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ1OTM1Mg==", "bodyText": "I think it was about readability. I might be misremembering though, as it was a conversation we had last week", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525459352", "createdAt": "2020-11-17T19:55:15Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,13 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private void resizeThreadCache(final int numStreamThreads) {\n+        final long cacheSizePreThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ2MzY0NQ==", "bodyText": "If this line is duplicated, it should go in a method. When I proposed to move it inline, I was apparently not aware that the same line was used somewhere else.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525463645", "createdAt": "2020-11-17T19:58:45Z", "author": {"login": "cadonna"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,13 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private void resizeThreadCache(final int numStreamThreads) {\n+        final long cacheSizePreThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ4ODY2NA==", "bodyText": "Moved to a new method. Glad we got that cleared up. LGTM?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525488664", "createdAt": "2020-11-17T20:19:34Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,13 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private void resizeThreadCache(final int numStreamThreads) {\n+        final long cacheSizePreThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMjMwMA==", "bodyText": "LGTM?\n\nIf this is a question, should it be LGTY? \ud83d\ude02", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525532300", "createdAt": "2020-11-17T21:21:29Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,13 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private void resizeThreadCache(final int numStreamThreads) {\n+        final long cacheSizePreThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, "originalCommit": null, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDI5MDg2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODo1MTo0NVrOH1ENrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxOTo1ODoyMlrOH1HufQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNTYxNQ==", "bodyText": "Why do we need the cacheResizer? Can't we just call cache.resize(size) here?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525405615", "createdAt": "2020-11-17T18:51:45Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +593,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        cacheResizer.accept(size);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyNzk0Mw==", "bodyText": "The cache is not exposed in stream thread. Since I was only using one method I thought it best to only expose that.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525427943", "createdAt": "2020-11-17T19:25:13Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +593,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        cacheResizer.accept(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNTYxNQ=="}, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQzNzY0Nw==", "bodyText": "Ah. I see. -- Should we pass java.util.function.Consumer<Long> cacheResizer into StreamThread constructor for this case instead?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525437647", "createdAt": "2020-11-17T19:37:34Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +593,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        cacheResizer.accept(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNTYxNQ=="}, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ2MzE2NQ==", "bodyText": "I think we can, thats probably a good idea.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525463165", "createdAt": "2020-11-17T19:58:22Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +593,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        cacheResizer.accept(size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNTYxNQ=="}, "originalCommit": null, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDI5Njg3OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODo1MzoxMlrOH1ERMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxOToyNToyOFrOH1Flhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNjUxNQ==", "bodyText": "nit: newCachSizeBytes ? (To avoid the \"clash\" with this.maxCachSizeBytes.)", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525406515", "createdAt": "2020-11-17T18:53:12Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyODEwMg==", "bodyText": "sure, that works", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525428102", "createdAt": "2020-11-17T19:25:28Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNjUxNQ=="}, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDMwNDA5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODo1NTowMFrOH1EVvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxOTo1OToyNlrOH1Hzrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNzY3Nw==", "bodyText": "Could this ever happen? If we the max cache size is smaller than a single entry, would we not evict the entry and the used cache size would always shrink to zero?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525407677", "createdAt": "2020-11-17T18:55:00Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            final CircularIterator<NamedCache> circularIterator = new CircularIterator<>(caches.values());\n+            while (sizeBytes() > maxCacheSizeBytes) {\n+                if (!circularIterator.hasNext()) {\n+                    log.error(\"Unable to remove any more entries as all caches are empty\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQzMDI1MQ==", "bodyText": "If we add a check to make sure the number of threads is positive then probably not. Ill add that check then remove this one", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525430251", "createdAt": "2020-11-17T19:28:57Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            final CircularIterator<NamedCache> circularIterator = new CircularIterator<>(caches.values());\n+            while (sizeBytes() > maxCacheSizeBytes) {\n+                if (!circularIterator.hasNext()) {\n+                    log.error(\"Unable to remove any more entries as all caches are empty\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNzY3Nw=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQzOTgxOQ==", "bodyText": "I see. -- I guess the miss-leading fact was, that this check was done inside the while-loop.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525439819", "createdAt": "2020-11-17T19:39:21Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            final CircularIterator<NamedCache> circularIterator = new CircularIterator<>(caches.values());\n+            while (sizeBytes() > maxCacheSizeBytes) {\n+                if (!circularIterator.hasNext()) {\n+                    log.error(\"Unable to remove any more entries as all caches are empty\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNzY3Nw=="}, "originalCommit": null, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ2NDQ5NQ==", "bodyText": "Yeah, in retrospect it was not very clear. Hopefully its better this way now", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525464495", "createdAt": "2020-11-17T19:59:26Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            final CircularIterator<NamedCache> circularIterator = new CircularIterator<>(caches.values());\n+            while (sizeBytes() > maxCacheSizeBytes) {\n+                if (!circularIterator.hasNext()) {\n+                    log.error(\"Unable to remove any more entries as all caches are empty\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNzY3Nw=="}, "originalCommit": null, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTA1MzM4OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMToyMzo1NFrOH1MBmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzowMDowM1rOH1O_2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw==", "bodyText": "Can it be smaller than 0 ? Should the test be <= 0 or < 1 instead?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525533593", "createdAt": "2020-11-17T21:23:54Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,20 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }\n+\n+    private void resizeThreadCache(final int numStreamThreads) {\n+        if (numStreamThreads < 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzNjk0NA==", "bodyText": "It can be zero if you have a global thread, but since this is internal the check might not be entirely necessary", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525536944", "createdAt": "2020-11-17T21:29:55Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,20 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }\n+\n+    private void resizeThreadCache(final int numStreamThreads) {\n+        if (numStreamThreads < 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0MDQxOA==", "bodyText": "Yes, it can be zero, but the check says < 0, so it would always evaluate to false?\nAnd if we have zero threads, we should not resize the cache as we might end up in an infinite loop? But we would only call this method if we \"shrink\", ie, if the thread count grows, but it can never grow from negative to zero, right?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525540418", "createdAt": "2020-11-17T21:36:24Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,20 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }\n+\n+    private void resizeThreadCache(final int numStreamThreads) {\n+        if (numStreamThreads < 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2MTE3OA==", "bodyText": "That is a good point. Maybe what we need to do it put a minimum size of cache to limit how many stream threads an instance can have?", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525561178", "createdAt": "2020-11-17T22:16:04Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,20 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }\n+\n+    private void resizeThreadCache(final int numStreamThreads) {\n+        if (numStreamThreads < 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2MjE1Ng==", "bodyText": "Well, getCacheSizePerThread would eventually return zero (with growing number of threads), what means that every put() into the cache would result in an immediate eviction. So I don't think we need to do anything for this corner case.", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525562156", "createdAt": "2020-11-17T22:18:07Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,20 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }\n+\n+    private void resizeThreadCache(final int numStreamThreads) {\n+        if (numStreamThreads < 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4MjI5OA==", "bodyText": "that is a good point", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525582298", "createdAt": "2020-11-17T23:00:03Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,20 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }\n+\n+    private void resizeThreadCache(final int numStreamThreads) {\n+        if (numStreamThreads < 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}, "originalCommit": null, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTA1NzA2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMToyNDo0OVrOH1MD1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMTozODozM1rOH1Mgkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzNDE2Nw==", "bodyText": "nit: we can remove this. now (same next line)", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525534167", "createdAt": "2020-11-17T21:24:49Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,22 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long newCacheSizeBytes) {\n+        final boolean shrink = newCacheSizeBytes < this.maxCacheSizeBytes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0MTUyMw==", "bodyText": "yep", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525541523", "createdAt": "2020-11-17T21:38:33Z", "author": {"login": "wcarlson5"}, "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,22 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long newCacheSizeBytes) {\n+        final boolean shrink = newCacheSizeBytes < this.maxCacheSizeBytes;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzNDE2Nw=="}, "originalCommit": null, "originalPosition": 22}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3823, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}