{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIxNTk5NDAz", "number": 8709, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNFQxNjozODo0OVrOD_NbfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowNzozOVrOD_2QZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NjA2OTA5OnYy", "diffSide": "LEFT", "path": "core/src/main/scala/kafka/server/DelayedFetch.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNFQxNjozODo0OVrOGZv_ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxNjoyODoyMFrOGamd1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY1Mzk0Ng==", "bodyText": "Interesting. This could cause an early return for the leader case too, right?", "url": "https://github.com/apache/kafka/pull/8709#discussion_r429653946", "createdAt": "2020-05-24T16:38:49Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/DelayedFetch.scala", "diffHunk": "@@ -120,14 +119,6 @@ class DelayedFetch(delayMs: Long,\n                   accumulatedSize += bytesAvailable\n               }\n             }\n-\n-            if (fetchMetadata.isFromFollower) {\n-              // Case H check if the follower has the latest HW from the leader\n-              if (partition.getReplica(fetchMetadata.replicaId)\n-                .exists(r => offsetSnapshot.highWatermark.messageOffset > r.lastSentHighWatermark)) {\n-                return forceComplete()\n-              }\n-            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd0858dcdc648a1615b7299b370d0d93f0e400d5"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU0NjM5MQ==", "bodyText": "Yeah, we missed this in the other patch.", "url": "https://github.com/apache/kafka/pull/8709#discussion_r430546391", "createdAt": "2020-05-26T16:28:20Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/DelayedFetch.scala", "diffHunk": "@@ -120,14 +119,6 @@ class DelayedFetch(delayMs: Long,\n                   accumulatedSize += bytesAvailable\n               }\n             }\n-\n-            if (fetchMetadata.isFromFollower) {\n-              // Case H check if the follower has the latest HW from the leader\n-              if (partition.getReplica(fetchMetadata.replicaId)\n-                .exists(r => offsetSnapshot.highWatermark.messageOffset > r.lastSentHighWatermark)) {\n-                return forceComplete()\n-              }\n-            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY1Mzk0Ng=="}, "originalCommit": {"oid": "bd0858dcdc648a1615b7299b370d0d93f0e400d5"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mjc1MzgwOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowNjoxNlrOGawUKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNjo1OTozNVrOGbUfBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNzc1Mw==", "bodyText": "Could we use the toString from the case class?", "url": "https://github.com/apache/kafka/pull/8709#discussion_r430707753", "createdAt": "2020-05-26T21:06:16Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -109,9 +109,19 @@ case class LogReadResult(info: FetchDataInfo,\n   def withEmptyFetchInfo: LogReadResult =\n     copy(info = FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY))\n \n-  override def toString =\n-    s\"Fetch Data: [$info], HW: [$highWatermark], leaderLogStartOffset: [$leaderLogStartOffset], leaderLogEndOffset: [$leaderLogEndOffset], \" +\n-    s\"followerLogStartOffset: [$followerLogStartOffset], fetchTimeMs: [$fetchTimeMs], readSize: [$readSize], lastStableOffset: [$lastStableOffset], error: [$error]\"\n+  override def toString = {\n+    \"LogReadResult(\" +\n+      s\"info=$info, \" +\n+      s\"highWatermark=$highWatermark, \" +\n+      s\"leaderLogStartOffset=$leaderLogStartOffset, \" +\n+      s\"leaderLogEndOffset=$leaderLogEndOffset, \" +\n+      s\"followerLogStartOffset=$followerLogStartOffset, \" +\n+      s\"fetchTimeMs=$fetchTimeMs, \" +\n+      s\"preferredReadReplica=$preferredReadReplica, \" +\n+      s\"lastStableOffset=$lastStableOffset, \" +\n+      s\"error=$error\" +\n+      \")\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b1dd8a335f3ce082601b0609ac16d1ada0706d96"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc0MDc2NA==", "bodyText": "Do we get the labels from the default toString? In the past, I thought it would only show the values.", "url": "https://github.com/apache/kafka/pull/8709#discussion_r430740764", "createdAt": "2020-05-26T22:24:22Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -109,9 +109,19 @@ case class LogReadResult(info: FetchDataInfo,\n   def withEmptyFetchInfo: LogReadResult =\n     copy(info = FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY))\n \n-  override def toString =\n-    s\"Fetch Data: [$info], HW: [$highWatermark], leaderLogStartOffset: [$leaderLogStartOffset], leaderLogEndOffset: [$leaderLogEndOffset], \" +\n-    s\"followerLogStartOffset: [$followerLogStartOffset], fetchTimeMs: [$fetchTimeMs], readSize: [$readSize], lastStableOffset: [$lastStableOffset], error: [$error]\"\n+  override def toString = {\n+    \"LogReadResult(\" +\n+      s\"info=$info, \" +\n+      s\"highWatermark=$highWatermark, \" +\n+      s\"leaderLogStartOffset=$leaderLogStartOffset, \" +\n+      s\"leaderLogEndOffset=$leaderLogEndOffset, \" +\n+      s\"followerLogStartOffset=$followerLogStartOffset, \" +\n+      s\"fetchTimeMs=$fetchTimeMs, \" +\n+      s\"preferredReadReplica=$preferredReadReplica, \" +\n+      s\"lastStableOffset=$lastStableOffset, \" +\n+      s\"error=$error\" +\n+      \")\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNzc1Mw=="}, "originalCommit": {"oid": "b1dd8a335f3ce082601b0609ac16d1ada0706d96"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc0ODA5OQ==", "bodyText": "That's true. You have to write toString yourself if you want labels. We could write a utility method like so (didn't try too compile it and skipped some details like commas):\ndef productToString(product: Product): String = {\n  val builder = new StringBuilder\n  sb.append(product.prefix)\n  for (i <- 0 until product.productArity) {\n    builder.append(product.productElementName(i))\n      .append(\"=\")\n      .append(product.productElement(i))\n  }\n  sb.build()\n}\nThen we can call that method from any case class toString where we want this format. Avoids some duplication and forgetting to update toString when new fields are added.", "url": "https://github.com/apache/kafka/pull/8709#discussion_r430748099", "createdAt": "2020-05-26T22:45:47Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -109,9 +109,19 @@ case class LogReadResult(info: FetchDataInfo,\n   def withEmptyFetchInfo: LogReadResult =\n     copy(info = FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY))\n \n-  override def toString =\n-    s\"Fetch Data: [$info], HW: [$highWatermark], leaderLogStartOffset: [$leaderLogStartOffset], leaderLogEndOffset: [$leaderLogEndOffset], \" +\n-    s\"followerLogStartOffset: [$followerLogStartOffset], fetchTimeMs: [$fetchTimeMs], readSize: [$readSize], lastStableOffset: [$lastStableOffset], error: [$error]\"\n+  override def toString = {\n+    \"LogReadResult(\" +\n+      s\"info=$info, \" +\n+      s\"highWatermark=$highWatermark, \" +\n+      s\"leaderLogStartOffset=$leaderLogStartOffset, \" +\n+      s\"leaderLogEndOffset=$leaderLogEndOffset, \" +\n+      s\"followerLogStartOffset=$followerLogStartOffset, \" +\n+      s\"fetchTimeMs=$fetchTimeMs, \" +\n+      s\"preferredReadReplica=$preferredReadReplica, \" +\n+      s\"lastStableOffset=$lastStableOffset, \" +\n+      s\"error=$error\" +\n+      \")\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNzc1Mw=="}, "originalCommit": {"oid": "b1dd8a335f3ce082601b0609ac16d1ada0706d96"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4ODExMA==", "bodyText": "Ok, I added something like that.", "url": "https://github.com/apache/kafka/pull/8709#discussion_r431288110", "createdAt": "2020-05-27T16:42:43Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -109,9 +109,19 @@ case class LogReadResult(info: FetchDataInfo,\n   def withEmptyFetchInfo: LogReadResult =\n     copy(info = FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY))\n \n-  override def toString =\n-    s\"Fetch Data: [$info], HW: [$highWatermark], leaderLogStartOffset: [$leaderLogStartOffset], leaderLogEndOffset: [$leaderLogEndOffset], \" +\n-    s\"followerLogStartOffset: [$followerLogStartOffset], fetchTimeMs: [$fetchTimeMs], readSize: [$readSize], lastStableOffset: [$lastStableOffset], error: [$error]\"\n+  override def toString = {\n+    \"LogReadResult(\" +\n+      s\"info=$info, \" +\n+      s\"highWatermark=$highWatermark, \" +\n+      s\"leaderLogStartOffset=$leaderLogStartOffset, \" +\n+      s\"leaderLogEndOffset=$leaderLogEndOffset, \" +\n+      s\"followerLogStartOffset=$followerLogStartOffset, \" +\n+      s\"fetchTimeMs=$fetchTimeMs, \" +\n+      s\"preferredReadReplica=$preferredReadReplica, \" +\n+      s\"lastStableOffset=$lastStableOffset, \" +\n+      s\"error=$error\" +\n+      \")\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNzc1Mw=="}, "originalCommit": {"oid": "b1dd8a335f3ce082601b0609ac16d1ada0706d96"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMwMDM1Nw==", "bodyText": "Sweet!", "url": "https://github.com/apache/kafka/pull/8709#discussion_r431300357", "createdAt": "2020-05-27T16:59:35Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -109,9 +109,19 @@ case class LogReadResult(info: FetchDataInfo,\n   def withEmptyFetchInfo: LogReadResult =\n     copy(info = FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY))\n \n-  override def toString =\n-    s\"Fetch Data: [$info], HW: [$highWatermark], leaderLogStartOffset: [$leaderLogStartOffset], leaderLogEndOffset: [$leaderLogEndOffset], \" +\n-    s\"followerLogStartOffset: [$followerLogStartOffset], fetchTimeMs: [$fetchTimeMs], readSize: [$readSize], lastStableOffset: [$lastStableOffset], error: [$error]\"\n+  override def toString = {\n+    \"LogReadResult(\" +\n+      s\"info=$info, \" +\n+      s\"highWatermark=$highWatermark, \" +\n+      s\"leaderLogStartOffset=$leaderLogStartOffset, \" +\n+      s\"leaderLogEndOffset=$leaderLogEndOffset, \" +\n+      s\"followerLogStartOffset=$followerLogStartOffset, \" +\n+      s\"fetchTimeMs=$fetchTimeMs, \" +\n+      s\"preferredReadReplica=$preferredReadReplica, \" +\n+      s\"lastStableOffset=$lastStableOffset, \" +\n+      s\"error=$error\" +\n+      \")\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNzc1Mw=="}, "originalCommit": {"oid": "b1dd8a335f3ce082601b0609ac16d1ada0706d96"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mjc1ODE0OnYy", "diffSide": "LEFT", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowNzozOVrOGawW0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMjozOToxMlrOGaypZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwODQzMw==", "bodyText": "Do we still need to compute adjustedMaxBytes? Also, do you know why we don't need readSize anymore? What change made it unnecessary?", "url": "https://github.com/apache/kafka/pull/8709#discussion_r430708433", "createdAt": "2020-05-26T21:07:39Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1100,10 +1100,8 @@ class ReplicaManager(val config: KafkaConfig,\n             leaderLogEndOffset = readInfo.logEndOffset,\n             followerLogStartOffset = followerLogStartOffset,\n             fetchTimeMs = fetchTimeMs,\n-            readSize = adjustedMaxBytes,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b1dd8a335f3ce082601b0609ac16d1ada0706d96"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc0MDYyOA==", "bodyText": "We can get the read size already from the Records object. The code must have been changed at some point to use this. It looks like adjustedMaxBytes is still sent through in the call to Partition.readRecords.", "url": "https://github.com/apache/kafka/pull/8709#discussion_r430740628", "createdAt": "2020-05-26T22:24:01Z", "author": {"login": "hachikuji"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1100,10 +1100,8 @@ class ReplicaManager(val config: KafkaConfig,\n             leaderLogEndOffset = readInfo.logEndOffset,\n             followerLogStartOffset = followerLogStartOffset,\n             fetchTimeMs = fetchTimeMs,\n-            readSize = adjustedMaxBytes,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwODQzMw=="}, "originalCommit": {"oid": "b1dd8a335f3ce082601b0609ac16d1ada0706d96"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc0NTk1OQ==", "bodyText": "Thanks, makes sense.", "url": "https://github.com/apache/kafka/pull/8709#discussion_r430745959", "createdAt": "2020-05-26T22:39:12Z", "author": {"login": "ijuma"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1100,10 +1100,8 @@ class ReplicaManager(val config: KafkaConfig,\n             leaderLogEndOffset = readInfo.logEndOffset,\n             followerLogStartOffset = followerLogStartOffset,\n             fetchTimeMs = fetchTimeMs,\n-            readSize = adjustedMaxBytes,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwODQzMw=="}, "originalCommit": {"oid": "b1dd8a335f3ce082601b0609ac16d1ada0706d96"}, "originalPosition": 105}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2710, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}