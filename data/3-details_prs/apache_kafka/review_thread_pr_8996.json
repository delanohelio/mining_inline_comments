{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ2NTA1NjY3", "number": 8996, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQwMDozOTowNlrOEMs3Wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxOToxMTo1OFrOENBZ9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNzUzNDM0OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQwMDozOTowNlrOGu9xTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQwMzozODo1MVrOGvAkFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5OTcyNg==", "bodyText": "Don't we need to call store.setOffset(null) or this case?", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451899726", "createdAt": "2020-07-09T00:39:06Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -224,6 +224,9 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n             for (final StateStoreMetadata store : stores.values()) {\n                 if (store.changelogPartition == null) {\n                     log.info(\"State store {} is not logged and hence would not be restored\", store.stateStore.name());\n+                } else if (!store.stateStore.persistent()) {\n+                    log.info(\"Initializing to the starting offset for changelog {} of in-memory state store {}\",\n+                             store.changelogPartition, store.stateStore.name());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkwMDY4Ng==", "bodyText": "Just wondering about https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java#L769-L802 (can't comment below).\nFor this case, if should hold that store.offset() == changelogOffsetFromCheckpointedOffset(loadedCheckpoints.remove(store.changelogPartition)) ?\nOr maybe >=?\nShould we add a sanity check? (Not related to this PR itself actually. -- Just wondering.)", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451900686", "createdAt": "2020-07-09T00:42:50Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -224,6 +224,9 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n             for (final StateStoreMetadata store : stores.values()) {\n                 if (store.changelogPartition == null) {\n                     log.info(\"State store {} is not logged and hence would not be restored\", store.stateStore.name());\n+                } else if (!store.stateStore.persistent()) {\n+                    log.info(\"Initializing to the starting offset for changelog {} of in-memory state store {}\",\n+                             store.changelogPartition, store.stateStore.name());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5OTcyNg=="}, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkyMjA0MA==", "bodyText": "Don't we need to call store.setOffset(null) or this case?\n\nWell, either it's a recycled task in which case no, we don't want to wipe out the existing offset, or it's a new task in which case it's initialized to null anyway.\nI'm also not sure what you mean in the second comment. Did you maybe paste the link to the wrong code? (just guessing since you linked to that same code earlier in John's PR)", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451922040", "createdAt": "2020-07-09T02:04:32Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -224,6 +224,9 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n             for (final StateStoreMetadata store : stores.values()) {\n                 if (store.changelogPartition == null) {\n                     log.info(\"State store {} is not logged and hence would not be restored\", store.stateStore.name());\n+                } else if (!store.stateStore.persistent()) {\n+                    log.info(\"Initializing to the starting offset for changelog {} of in-memory state store {}\",\n+                             store.changelogPartition, store.stateStore.name());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5OTcyNg=="}, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkyNjY2NQ==", "bodyText": "Ups. Wrong link. This one: https://github.com/apache/kafka/pull/8996/files#diff-cc98a6c20f2a8483e1849aea6921c34dL251-L255", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451926665", "createdAt": "2020-07-09T02:22:06Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -224,6 +224,9 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n             for (final StateStoreMetadata store : stores.values()) {\n                 if (store.changelogPartition == null) {\n                     log.info(\"State store {} is not logged and hence would not be restored\", store.stateStore.name());\n+                } else if (!store.stateStore.persistent()) {\n+                    log.info(\"Initializing to the starting offset for changelog {} of in-memory state store {}\",\n+                             store.changelogPartition, store.stateStore.name());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5OTcyNg=="}, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkyNzA5Nw==", "bodyText": "Well, either it's a recycled task in which case no,\n\nSo a active->standby or standby->active conversion. I was wondering about corrupted tasks? So we don't call initializeStoreOffsetsFromCheckpoint when reviving a corrupted task?", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451927097", "createdAt": "2020-07-09T02:23:54Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -224,6 +224,9 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n             for (final StateStoreMetadata store : stores.values()) {\n                 if (store.changelogPartition == null) {\n                     log.info(\"State store {} is not logged and hence would not be restored\", store.stateStore.name());\n+                } else if (!store.stateStore.persistent()) {\n+                    log.info(\"Initializing to the starting offset for changelog {} of in-memory state store {}\",\n+                             store.changelogPartition, store.stateStore.name());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5OTcyNg=="}, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTk0NTQ5NQ==", "bodyText": "No, because we close the state manager completely and clear all this data before reviving a corrupted task.\nI've had to re-convince myself of this several times already. Maybe we can also add a check that none of them are marked corrupted while initializing offsets", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451945495", "createdAt": "2020-07-09T03:38:51Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -224,6 +224,9 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n             for (final StateStoreMetadata store : stores.values()) {\n                 if (store.changelogPartition == null) {\n                     log.info(\"State store {} is not logged and hence would not be restored\", store.stateStore.name());\n+                } else if (!store.stateStore.persistent()) {\n+                    log.info(\"Initializing to the starting offset for changelog {} of in-memory state store {}\",\n+                             store.changelogPartition, store.stateStore.name());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5OTcyNg=="}, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNzU0OTE2OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQwMDo0Nzo1NVrOGu96Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxNzoxOToxNFrOGvanhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkwMTk3NQ==", "bodyText": "Not sure if I understand the test: don't we write a checkpoint in L795 for the persistent store?", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451901975", "createdAt": "2020-07-09T00:47:55Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java", "diffHunk": "@@ -784,7 +784,7 @@ public void close() {\n     }\n \n     @Test\n-    public void shouldThrowTaskCorruptedWithoutCheckpointNonEmptyDir() throws IOException {\n+    public void shouldThrowTaskCorruptedWithoutPersistentStoreCheckpointAndNonEmptyDir() throws IOException {\n         final long checkpointOffset = 10L;\n \n         final Map<TopicPartition, Long> offsets = mkMap(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkyMjQyMQ==", "bodyText": "Yeah, I think that's the point of the test: we wrote a checkpoint but it was missing the offset for one of the persistent stores, thus, we should throw a TaskCorruptedException  in initializeStoreOffsetsFromCheckpoint", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451922421", "createdAt": "2020-07-09T02:05:51Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java", "diffHunk": "@@ -784,7 +784,7 @@ public void close() {\n     }\n \n     @Test\n-    public void shouldThrowTaskCorruptedWithoutCheckpointNonEmptyDir() throws IOException {\n+    public void shouldThrowTaskCorruptedWithoutPersistentStoreCheckpointAndNonEmptyDir() throws IOException {\n         final long checkpointOffset = 10L;\n \n         final Map<TopicPartition, Long> offsets = mkMap(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkwMTk3NQ=="}, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkyODE3MA==", "bodyText": "Not clear from the context of the code snipped (maybe need to go back to IntelliJ and read the full test setup) that there are multiple partitions. Also wondering why we include nonPersistentStorePartition and irrelevantPartition? How do we ensure that those don't case the TaskCorruptedException?", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451928170", "createdAt": "2020-07-09T02:27:59Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java", "diffHunk": "@@ -784,7 +784,7 @@ public void close() {\n     }\n \n     @Test\n-    public void shouldThrowTaskCorruptedWithoutCheckpointNonEmptyDir() throws IOException {\n+    public void shouldThrowTaskCorruptedWithoutPersistentStoreCheckpointAndNonEmptyDir() throws IOException {\n         final long checkpointOffset = 10L;\n \n         final Map<TopicPartition, Long> offsets = mkMap(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkwMTk3NQ=="}, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM3MjM1Nw==", "bodyText": "Sorry yeah the relevant part doesn't show up on github. Basically we register\nstateMgr.registerStore(persistentStore, persistentStore.stateRestoreCallback);\t            \nstateMgr.registerStore(persistentStoreTwo, persistentStoreTwo.stateRestoreCallback);\t            \nstateMgr.registerStore(nonPersistentStore, nonPersistentStore.stateRestoreCallback);\n\nbut only write the checkpoint for the persistentStorePartition, nonPersistentStorePartition and irrelevantPartition . I think the point of the irrelevantPartition is to make sure that we detect that the persistentStoreTwoPartition offset is missing even though the checkpoint technically has the correct number of offsets in total. ie, that we actually map the offsets to a registered changelog", "url": "https://github.com/apache/kafka/pull/8996#discussion_r452372357", "createdAt": "2020-07-09T17:19:14Z", "author": {"login": "ableegoldman"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java", "diffHunk": "@@ -784,7 +784,7 @@ public void close() {\n     }\n \n     @Test\n-    public void shouldThrowTaskCorruptedWithoutCheckpointNonEmptyDir() throws IOException {\n+    public void shouldThrowTaskCorruptedWithoutPersistentStoreCheckpointAndNonEmptyDir() throws IOException {\n         final long checkpointOffset = 10L;\n \n         final Map<TopicPartition, Long> offsets = mkMap(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkwMTk3NQ=="}, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNzU1MDE5OnYy", "diffSide": "RIGHT", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQwMDo0ODozNVrOGu96sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQwMDo0ODozNVrOGu96sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkwMjEzMQ==", "bodyText": "WithWithout ?", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451902131", "createdAt": "2020-07-09T00:48:35Z", "author": {"login": "mjsax"}, "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java", "diffHunk": "@@ -813,6 +813,62 @@ public void shouldThrowTaskCorruptedWithoutCheckpointNonEmptyDir() throws IOExce\n         }\n     }\n \n+    @Test\n+    public void shouldNotThrowTaskCorruptedWithWithoutInMemoryStoreCheckpointAndNonEmptyDir() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c209e8f9deaab42f1687e5b5ad6f1540322d4517"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNzcwNTE2OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQwMjoxNzo1OFrOGu_Weg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxNzoxNTo1OFrOGvagVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkyNTYyNg==", "bodyText": "Seems weird to skip deleting the dirty state on a dirty close just because we caught an exception while closing the state (probably in most cases a dirty close would mean something would throw, for example calling flush when we've dropped out of the group)", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451925626", "createdAt": "2020-07-09T02:17:58Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -104,17 +104,16 @@ static void closeStateManager(final Logger log,\n             if (stateDirectory.lock(id)) {\n                 try {\n                     stateMgr.close();\n-\n+                } catch (final ProcessorStateException e) {\n+                    firstException.compareAndSet(null, e);\n+                } finally {\n                     if (wipeStateStore) {\n                         log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n                         // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n                         // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n                         // need to re-bootstrap the restoration from the beginning\n                         Utils.delete(stateMgr.baseDir());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e272df4f05a2e33199a9999dda8546231d171653"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkyNzcxNA==", "bodyText": "Well, it could be some other issue and we would wipe the state on \"resuming\" the task anyway. Not sure if there are other things to consider? \\cc @guozhangwang", "url": "https://github.com/apache/kafka/pull/8996#discussion_r451927714", "createdAt": "2020-07-09T02:26:08Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -104,17 +104,16 @@ static void closeStateManager(final Logger log,\n             if (stateDirectory.lock(id)) {\n                 try {\n                     stateMgr.close();\n-\n+                } catch (final ProcessorStateException e) {\n+                    firstException.compareAndSet(null, e);\n+                } finally {\n                     if (wipeStateStore) {\n                         log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n                         // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n                         // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n                         // need to re-bootstrap the restoration from the beginning\n                         Utils.delete(stateMgr.baseDir());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkyNTYyNg=="}, "originalCommit": {"oid": "e272df4f05a2e33199a9999dda8546231d171653"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM3MDUxNw==", "bodyText": "Right, it's not a correctness issue but it's additional needless overhead to go through the whole cycle of initializing a task, getting a TaskCorrupted, wiping it then, and finally restarting it. Of course if we keep hitting an issue during closeDirty then we might never wipe the state, which does seem like a real problem. For example if there's some issue with the state, like the files are actually corrupted or something", "url": "https://github.com/apache/kafka/pull/8996#discussion_r452370517", "createdAt": "2020-07-09T17:15:58Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -104,17 +104,16 @@ static void closeStateManager(final Logger log,\n             if (stateDirectory.lock(id)) {\n                 try {\n                     stateMgr.close();\n-\n+                } catch (final ProcessorStateException e) {\n+                    firstException.compareAndSet(null, e);\n+                } finally {\n                     if (wipeStateStore) {\n                         log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n                         // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n                         // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n                         // need to re-bootstrap the restoration from the beginning\n                         Utils.delete(stateMgr.baseDir());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkyNTYyNg=="}, "originalCommit": {"oid": "e272df4f05a2e33199a9999dda8546231d171653"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMDg4NDc5OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxOTowNzowNFrOGveLsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQyMTowMDowMVrOGvhnow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQzMDc3MQ==", "bodyText": "I think we should also remove the changelogPartition from loadedCheckpoints, if it exists. Otherwise, we'll spuriously warn in L267.", "url": "https://github.com/apache/kafka/pull/8996#discussion_r452430771", "createdAt": "2020-07-09T19:07:04Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -222,8 +222,16 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n             log.trace(\"Loaded offsets from the checkpoint file: {}\", loadedCheckpoints);\n \n             for (final StateStoreMetadata store : stores.values()) {\n+                if (store.corrupted) {\n+                    log.error(\"Tried to initialize store offsets for corrupted store {}\", store);\n+                    throw new IllegalStateException(\"Should not initialize offsets for a corrupted task\");\n+                }\n+\n                 if (store.changelogPartition == null) {\n                     log.info(\"State store {} is not logged and hence would not be restored\", store.stateStore.name());\n+                } else if (!store.stateStore.persistent()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f6db6d6dea1a2164ee59895e46ccc268e6a477d"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQ4MzUyNQ==", "bodyText": "I'm not sure I'd call it a spurious warning -- if we don't expect to have checkpointed in-memory stores, and we happen to have an offset for one in the checkpoint file, it seems reasonable to log a warning", "url": "https://github.com/apache/kafka/pull/8996#discussion_r452483525", "createdAt": "2020-07-09T20:53:16Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -222,8 +222,16 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n             log.trace(\"Loaded offsets from the checkpoint file: {}\", loadedCheckpoints);\n \n             for (final StateStoreMetadata store : stores.values()) {\n+                if (store.corrupted) {\n+                    log.error(\"Tried to initialize store offsets for corrupted store {}\", store);\n+                    throw new IllegalStateException(\"Should not initialize offsets for a corrupted task\");\n+                }\n+\n                 if (store.changelogPartition == null) {\n                     log.info(\"State store {} is not logged and hence would not be restored\", store.stateStore.name());\n+                } else if (!store.stateStore.persistent()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQzMDc3MQ=="}, "originalCommit": {"oid": "6f6db6d6dea1a2164ee59895e46ccc268e6a477d"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQ4NzA3NQ==", "bodyText": "Fair enough.", "url": "https://github.com/apache/kafka/pull/8996#discussion_r452487075", "createdAt": "2020-07-09T21:00:01Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java", "diffHunk": "@@ -222,8 +222,16 @@ void initializeStoreOffsetsFromCheckpoint(final boolean storeDirIsEmpty) {\n             log.trace(\"Loaded offsets from the checkpoint file: {}\", loadedCheckpoints);\n \n             for (final StateStoreMetadata store : stores.values()) {\n+                if (store.corrupted) {\n+                    log.error(\"Tried to initialize store offsets for corrupted store {}\", store);\n+                    throw new IllegalStateException(\"Should not initialize offsets for a corrupted task\");\n+                }\n+\n                 if (store.changelogPartition == null) {\n                     log.info(\"State store {} is not logged and hence would not be restored\", store.stateStore.name());\n+                } else if (!store.stateStore.persistent()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQzMDc3MQ=="}, "originalCommit": {"oid": "6f6db6d6dea1a2164ee59895e46ccc268e6a477d"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMDg5OTc1OnYy", "diffSide": "RIGHT", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxOToxMTo1OFrOGveVJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQyMToxNDo0NFrOGviC-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQzMzE4OA==", "bodyText": "I take it this block can also throw an exception? We shouldn't throw exceptions inside a finally block because it's not defined when the exception will be thrown, or in the case where the first try block threw, which exception is ultimately thrown is also undefined.\nTo make this simpler to grapple with, we added org.apache.kafka.streams.state.internals.ExceptionUtils#executeAll", "url": "https://github.com/apache/kafka/pull/8996#discussion_r452433188", "createdAt": "2020-07-09T19:11:58Z", "author": {"login": "vvcephei"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -104,26 +104,27 @@ static void closeStateManager(final Logger log,\n             if (stateDirectory.lock(id)) {\n                 try {\n                     stateMgr.close();\n-\n-                    if (wipeStateStore) {\n-                        log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n-                        // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n-                        // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n-                        // need to re-bootstrap the restoration from the beginning\n-                        Utils.delete(stateMgr.baseDir());\n-                    }\n                 } catch (final ProcessorStateException e) {\n                     firstException.compareAndSet(null, e);\n                 } finally {\n-                    stateDirectory.unlock(id);\n+                    try {\n+                        if (wipeStateStore) {\n+                            log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n+                            // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n+                            // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n+                            // need to re-bootstrap the restoration from the beginning\n+                            Utils.delete(stateMgr.baseDir());\n+                        }\n+                    } finally {\n+                        stateDirectory.unlock(id);\n+                    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f6db6d6dea1a2164ee59895e46ccc268e6a477d"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQ3ODg4Mg==", "bodyText": "Well, I figured it didn't matter since these both just throw IOException which we catch in the outer block. The point was to make sure we unlock it. But I'll check out ExceptionUtils#executeAll", "url": "https://github.com/apache/kafka/pull/8996#discussion_r452478882", "createdAt": "2020-07-09T20:43:56Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -104,26 +104,27 @@ static void closeStateManager(final Logger log,\n             if (stateDirectory.lock(id)) {\n                 try {\n                     stateMgr.close();\n-\n-                    if (wipeStateStore) {\n-                        log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n-                        // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n-                        // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n-                        // need to re-bootstrap the restoration from the beginning\n-                        Utils.delete(stateMgr.baseDir());\n-                    }\n                 } catch (final ProcessorStateException e) {\n                     firstException.compareAndSet(null, e);\n                 } finally {\n-                    stateDirectory.unlock(id);\n+                    try {\n+                        if (wipeStateStore) {\n+                            log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n+                            // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n+                            // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n+                            // need to re-bootstrap the restoration from the beginning\n+                            Utils.delete(stateMgr.baseDir());\n+                        }\n+                    } finally {\n+                        stateDirectory.unlock(id);\n+                    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQzMzE4OA=="}, "originalCommit": {"oid": "6f6db6d6dea1a2164ee59895e46ccc268e6a477d"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQ5MTE3Mw==", "bodyText": "I can't use ExceptionUtils#executeAll because the compiler complains that we don't handle the IOException unless we surround each Runnable with its own try-catch block, at which point #executeAll isn't really doing anything", "url": "https://github.com/apache/kafka/pull/8996#discussion_r452491173", "createdAt": "2020-07-09T21:08:30Z", "author": {"login": "ableegoldman"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -104,26 +104,27 @@ static void closeStateManager(final Logger log,\n             if (stateDirectory.lock(id)) {\n                 try {\n                     stateMgr.close();\n-\n-                    if (wipeStateStore) {\n-                        log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n-                        // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n-                        // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n-                        // need to re-bootstrap the restoration from the beginning\n-                        Utils.delete(stateMgr.baseDir());\n-                    }\n                 } catch (final ProcessorStateException e) {\n                     firstException.compareAndSet(null, e);\n                 } finally {\n-                    stateDirectory.unlock(id);\n+                    try {\n+                        if (wipeStateStore) {\n+                            log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n+                            // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n+                            // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n+                            // need to re-bootstrap the restoration from the beginning\n+                            Utils.delete(stateMgr.baseDir());\n+                        }\n+                    } finally {\n+                        stateDirectory.unlock(id);\n+                    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQzMzE4OA=="}, "originalCommit": {"oid": "6f6db6d6dea1a2164ee59895e46ccc268e6a477d"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQ5NDA3Mw==", "bodyText": "IMHO, the code is good as-is.\nThanks for rewriting to a nested try-final structure!", "url": "https://github.com/apache/kafka/pull/8996#discussion_r452494073", "createdAt": "2020-07-09T21:14:44Z", "author": {"login": "mjsax"}, "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java", "diffHunk": "@@ -104,26 +104,27 @@ static void closeStateManager(final Logger log,\n             if (stateDirectory.lock(id)) {\n                 try {\n                     stateMgr.close();\n-\n-                    if (wipeStateStore) {\n-                        log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n-                        // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n-                        // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n-                        // need to re-bootstrap the restoration from the beginning\n-                        Utils.delete(stateMgr.baseDir());\n-                    }\n                 } catch (final ProcessorStateException e) {\n                     firstException.compareAndSet(null, e);\n                 } finally {\n-                    stateDirectory.unlock(id);\n+                    try {\n+                        if (wipeStateStore) {\n+                            log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n+                            // we can just delete the whole dir of the task, including the state store images and the checkpoint files,\n+                            // and then we write an empty checkpoint file indicating that the previous close is graceful and we just\n+                            // need to re-bootstrap the restoration from the beginning\n+                            Utils.delete(stateMgr.baseDir());\n+                        }\n+                    } finally {\n+                        stateDirectory.unlock(id);\n+                    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQzMzE4OA=="}, "originalCommit": {"oid": "6f6db6d6dea1a2164ee59895e46ccc268e6a477d"}, "originalPosition": 26}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2200, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}