{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE1ODEwMDYw", "number": 9563, "reviewThreads": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwNjo0MjozOVrOE1hHlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMjo1Nzo0OVrOE3NsiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NTUyNTk5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/resources/common/message/EnvelopeRequest.json", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwNjo0MjozOVrOHt1YDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQyMzoyOTo1OVrOHuapbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzgyMjQ3OA==", "bodyText": "Is ```nullableVersions`` required? It seems there is no null handle/check in production for this field.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r517822478", "createdAt": "2020-11-05T06:42:39Z", "author": {"login": "chia7712"}, "path": "clients/src/main/resources/common/message/EnvelopeRequest.json", "diffHunk": "@@ -23,7 +23,7 @@\n   \"fields\": [\n     { \"name\": \"RequestData\", \"type\": \"bytes\", \"versions\": \"0+\", \"zeroCopy\": true,\n       \"about\": \"The embedded request header and data.\"},\n-    { \"name\": \"RequestPrincipal\", \"type\": \"bytes\", \"versions\": \"0+\", \"zeroCopy\": true, \"nullableVersions\": \"0+\",\n+    { \"name\": \"RequestPrincipal\", \"type\": \"bytes\", \"versions\": \"0+\", \"nullableVersions\": \"0+\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQzMzEzNQ==", "bodyText": "I agree it should not be nullable. Will fix it.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518433135", "createdAt": "2020-11-05T23:29:59Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/resources/common/message/EnvelopeRequest.json", "diffHunk": "@@ -23,7 +23,7 @@\n   \"fields\": [\n     { \"name\": \"RequestData\", \"type\": \"bytes\", \"versions\": \"0+\", \"zeroCopy\": true,\n       \"about\": \"The embedded request header and data.\"},\n-    { \"name\": \"RequestPrincipal\", \"type\": \"bytes\", \"versions\": \"0+\", \"zeroCopy\": true, \"nullableVersions\": \"0+\",\n+    { \"name\": \"RequestPrincipal\", \"type\": \"bytes\", \"versions\": \"0+\", \"nullableVersions\": \"0+\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzgyMjQ3OA=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NTUzODg1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/network/SendBuilder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwNjo0ODoxMlrOHt1fRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwNjo0ODoxMlrOHt1fRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzgyNDMyNA==", "bodyText": "The buffer is used/owned by SendBuilder only. It seems to me this constructor should accept capacity(int type) rather than ByteBuffer. (SendBuilder should create ByteBuffer in construction)", "url": "https://github.com/apache/kafka/pull/9563#discussion_r517824324", "createdAt": "2020-11-05T06:48:12Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/network/SendBuilder.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.network;\n+\n+import org.apache.kafka.common.protocol.ObjectSerializationCache;\n+import org.apache.kafka.common.protocol.Writable;\n+import org.apache.kafka.common.requests.RequestHeader;\n+import org.apache.kafka.common.utils.ByteUtils;\n+\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * This class provides a way to build {@link Send} objects for network\n+ * transmission from generated {@link org.apache.kafka.common.protocol.ApiMessage}\n+ * types. Its main advantage over direct {@link ByteBuffer} allocation based on\n+ * {@link org.apache.kafka.common.protocol.ApiMessage#size(ObjectSerializationCache, short)}\n+ * is that it avoids copying \"bytes\" fields. The downside is that it is up to the caller\n+ * to allocate a buffer which accounts only for the additional request overhead.\n+ *\n+ * See {@link org.apache.kafka.common.requests.EnvelopeRequest#toSend(String, RequestHeader)}\n+ * for example usage.\n+ */\n+public class SendBuilder implements Writable {\n+    private final List<ByteBuffer> buffers = new ArrayList<>();\n+    private final ByteBuffer buffer;\n+\n+    public SendBuilder(ByteBuffer buffer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0OTE2MTA0OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/RequestHeader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQyMjowMTo1NVrOHuYZ9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQyMjo0MTo0NFrOHuZgQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM5NjQwNw==", "bodyText": "Is this specifically for Envelope case?", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518396407", "createdAt": "2020-11-05T22:01:55Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/RequestHeader.java", "diffHunk": "@@ -89,10 +89,11 @@ public ResponseHeader toResponseHeader() {\n     public static RequestHeader parse(ByteBuffer buffer) {\n         short apiKey = -1;\n         try {\n+            int position = buffer.position();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQxNDQwMA==", "bodyText": "This was a bug. This logic assumes that the buffer is at position 0. Let me add a test case.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518414400", "createdAt": "2020-11-05T22:41:44Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/RequestHeader.java", "diffHunk": "@@ -89,10 +89,11 @@ public ResponseHeader toResponseHeader() {\n     public static RequestHeader parse(ByteBuffer buffer) {\n         short apiKey = -1;\n         try {\n+            int position = buffer.position();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM5NjQwNw=="}, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0OTkzOTgxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/protocol/Writable.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNDoxMDo1MlrOHufgvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNTozMzowMFrOHugshA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUxMjgyOA==", "bodyText": "Does it need null check (maybe no-op)?", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518512828", "createdAt": "2020-11-06T04:10:52Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/Writable.java", "diffHunk": "@@ -33,6 +35,23 @@\n     void writeVarint(int i);\n     void writeVarlong(long i);\n \n+    default void writeApiMessage(\n+        ApiMessage message,\n+        ObjectSerializationCache serializationCache,\n+        short version\n+    ) {\n+        message.write(this, serializationCache, version);\n+    }\n+\n+    default void writeRecords(BaseRecords records) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUzMjIyOA==", "bodyText": "I was concerned about this also, but the generated code adds its own null check.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518532228", "createdAt": "2020-11-06T05:33:00Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/Writable.java", "diffHunk": "@@ -33,6 +35,23 @@\n     void writeVarint(int i);\n     void writeVarlong(long i);\n \n+    default void writeApiMessage(\n+        ApiMessage message,\n+        ObjectSerializationCache serializationCache,\n+        short version\n+    ) {\n+        message.write(this, serializationCache, version);\n+    }\n+\n+    default void writeRecords(BaseRecords records) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUxMjgyOA=="}, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0OTk0MzA4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/protocol/Writable.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNDoxMzowNVrOHufixw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNjozNzoxNVrOHuhxMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUxMzM1MQ==", "bodyText": "It is used by only SendBuilder. How about moving it to SendBuilder?", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518513351", "createdAt": "2020-11-06T04:13:05Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/Writable.java", "diffHunk": "@@ -33,6 +35,23 @@\n     void writeVarint(int i);\n     void writeVarlong(long i);\n \n+    default void writeApiMessage(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU0OTgwOQ==", "bodyText": "Fair enough.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518549809", "createdAt": "2020-11-06T06:37:15Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/Writable.java", "diffHunk": "@@ -33,6 +35,23 @@\n     void writeVarint(int i);\n     void writeVarlong(long i);\n \n+    default void writeApiMessage(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUxMzM1MQ=="}, "originalCommit": null, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0OTk4OTUwOnYy", "diffSide": "RIGHT", "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNDo0Mzo0MlrOHuf-GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNDo1NToyN1rOHugJdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUyMDM0NQ==", "bodyText": "Why it is not addZeroCopyBytes?", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518520345", "createdAt": "2020-11-06T04:43:42Z", "author": {"login": "chia7712"}, "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "diffHunk": "@@ -1581,56 +1570,56 @@ private void generateVariableLengthFieldSize(FieldSpec field,\n                         headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n                         buffer.printf(\"_cache.setArraySizeInBytes(%s, _arraySize);%n\",\n                             field.camelCaseName());\n-                        buffer.printf(\"_size += _arraySize + ByteUtils.sizeOfUnsignedVarint(_arraySize);%n\");\n+                        buffer.printf(\"_size.addBytes(ByteUtils.sizeOfUnsignedVarint(_arraySize.totalSize()));%n\");\n+                        buffer.printf(\"_size.add(_arraySize);%n\");\n                     } else {\n-                        buffer.printf(\"_size += _arraySize;%n\");\n+                        buffer.printf(\"_size.add(_arraySize);%n\");\n                     }\n                 } else if (field.type().isBytes()) {\n+                    buffer.printf(\"MessageSize _bytesSize = new MessageSize();%n\");\n                     if (field.zeroCopy()) {\n-                        buffer.printf(\"int _bytesSize = %s.remaining();%n\", field.camelCaseName());\n+                        buffer.printf(\"_bytesSize.addZeroCopyBytes(%s.remaining());%n\", field.camelCaseName());\n                     } else {\n-                        buffer.printf(\"int _bytesSize = %s.length;%n\", field.camelCaseName());\n+                        buffer.printf(\"_bytesSize.addBytes(%s.length);%n\", field.camelCaseName());\n                     }\n                     VersionConditional.forVersions(fieldFlexibleVersions(field), possibleVersions).\n                         ifMember(__ -> {\n                             headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n                             if (field.zeroCopy()) {\n-                                buffer.printf(\"_bytesSize += \" +\n-                                        \"ByteUtils.sizeOfUnsignedVarint(%s.remaining() + 1);%n\", field.camelCaseName());\n+                                buffer.printf(\"_bytesSize.addBytes(\" +\n+                                        \"ByteUtils.sizeOfUnsignedVarint(%s.remaining() + 1));%n\", field.camelCaseName());\n                             } else {\n-                                buffer.printf(\"_bytesSize += ByteUtils.sizeOfUnsignedVarint(%s.length + 1);%n\",\n+                                buffer.printf(\"_bytesSize.addBytes(ByteUtils.sizeOfUnsignedVarint(%s.length + 1));%n\",\n                                     field.camelCaseName());\n                             }\n                         }).\n                         ifNotMember(__ -> {\n-                            buffer.printf(\"_bytesSize += 4;%n\");\n+                            buffer.printf(\"_bytesSize.addBytes(4);%n\");\n                         }).\n                         generate(buffer);\n                     if (tagged) {\n                         headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n-                        buffer.printf(\"_size += _bytesSize + ByteUtils.sizeOfUnsignedVarint(_bytesSize);%n\");\n-                    } else {\n-                        buffer.printf(\"_size += _bytesSize;%n\");\n+                        buffer.printf(\"_size.addBytes(ByteUtils.sizeOfUnsignedVarint(_bytesSize.totalSize()));%n\");\n                     }\n+                    buffer.printf(\"_size.add(_bytesSize);%n\");\n                 } else if (field.type().isRecords()) {\n-                    buffer.printf(\"int _recordsSize = %s.sizeInBytes();%n\", field.camelCaseName());\n+                    buffer.printf(\"_size.addBytes(%s.sizeInBytes());%n\", field.camelCaseName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 308}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUyMzI1Mw==", "bodyText": "Yeah, my bad. Probably messed this up after renaming.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518523253", "createdAt": "2020-11-06T04:55:27Z", "author": {"login": "hachikuji"}, "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "diffHunk": "@@ -1581,56 +1570,56 @@ private void generateVariableLengthFieldSize(FieldSpec field,\n                         headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n                         buffer.printf(\"_cache.setArraySizeInBytes(%s, _arraySize);%n\",\n                             field.camelCaseName());\n-                        buffer.printf(\"_size += _arraySize + ByteUtils.sizeOfUnsignedVarint(_arraySize);%n\");\n+                        buffer.printf(\"_size.addBytes(ByteUtils.sizeOfUnsignedVarint(_arraySize.totalSize()));%n\");\n+                        buffer.printf(\"_size.add(_arraySize);%n\");\n                     } else {\n-                        buffer.printf(\"_size += _arraySize;%n\");\n+                        buffer.printf(\"_size.add(_arraySize);%n\");\n                     }\n                 } else if (field.type().isBytes()) {\n+                    buffer.printf(\"MessageSize _bytesSize = new MessageSize();%n\");\n                     if (field.zeroCopy()) {\n-                        buffer.printf(\"int _bytesSize = %s.remaining();%n\", field.camelCaseName());\n+                        buffer.printf(\"_bytesSize.addZeroCopyBytes(%s.remaining());%n\", field.camelCaseName());\n                     } else {\n-                        buffer.printf(\"int _bytesSize = %s.length;%n\", field.camelCaseName());\n+                        buffer.printf(\"_bytesSize.addBytes(%s.length);%n\", field.camelCaseName());\n                     }\n                     VersionConditional.forVersions(fieldFlexibleVersions(field), possibleVersions).\n                         ifMember(__ -> {\n                             headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n                             if (field.zeroCopy()) {\n-                                buffer.printf(\"_bytesSize += \" +\n-                                        \"ByteUtils.sizeOfUnsignedVarint(%s.remaining() + 1);%n\", field.camelCaseName());\n+                                buffer.printf(\"_bytesSize.addBytes(\" +\n+                                        \"ByteUtils.sizeOfUnsignedVarint(%s.remaining() + 1));%n\", field.camelCaseName());\n                             } else {\n-                                buffer.printf(\"_bytesSize += ByteUtils.sizeOfUnsignedVarint(%s.length + 1);%n\",\n+                                buffer.printf(\"_bytesSize.addBytes(ByteUtils.sizeOfUnsignedVarint(%s.length + 1));%n\",\n                                     field.camelCaseName());\n                             }\n                         }).\n                         ifNotMember(__ -> {\n-                            buffer.printf(\"_bytesSize += 4;%n\");\n+                            buffer.printf(\"_bytesSize.addBytes(4);%n\");\n                         }).\n                         generate(buffer);\n                     if (tagged) {\n                         headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n-                        buffer.printf(\"_size += _bytesSize + ByteUtils.sizeOfUnsignedVarint(_bytesSize);%n\");\n-                    } else {\n-                        buffer.printf(\"_size += _bytesSize;%n\");\n+                        buffer.printf(\"_size.addBytes(ByteUtils.sizeOfUnsignedVarint(_bytesSize.totalSize()));%n\");\n                     }\n+                    buffer.printf(\"_size.add(_bytesSize);%n\");\n                 } else if (field.type().isRecords()) {\n-                    buffer.printf(\"int _recordsSize = %s.sizeInBytes();%n\", field.camelCaseName());\n+                    buffer.printf(\"_size.addBytes(%s.sizeInBytes());%n\", field.camelCaseName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUyMDM0NQ=="}, "originalCommit": null, "originalPosition": 308}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1MDI4OTk4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNzoyMjo1MVrOHuiqvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxNzowNjoxN1rOHu2QeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU2NDU0Mw==", "bodyText": "not sure whether it is ok to ignore the version of EnvelopeRequest.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518564543", "createdAt": "2020-11-06T07:22:51Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "diffHunk": "@@ -91,4 +91,14 @@ public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n     public static EnvelopeRequest parse(ByteBuffer buffer, short version) {\n         return new EnvelopeRequest(ApiKeys.ENVELOPE.parseRequest(version, buffer), version);\n     }\n+\n+    public EnvelopeRequestData data() {\n+        return data;\n+    }\n+\n+    @Override\n+    public Send toSend(String destination, RequestHeader header) {\n+        return SendBuilder.buildRequestSend(destination, header, this.data);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg4NTQ5Nw==", "bodyText": "The version is contained in RequestHeader. This pattern was probably started before AbstractRequest included the version as well.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518885497", "createdAt": "2020-11-06T17:06:17Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "diffHunk": "@@ -91,4 +91,14 @@ public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n     public static EnvelopeRequest parse(ByteBuffer buffer, short version) {\n         return new EnvelopeRequest(ApiKeys.ENVELOPE.parseRequest(version, buffer), version);\n     }\n+\n+    public EnvelopeRequestData data() {\n+        return data;\n+    }\n+\n+    @Override\n+    public Send toSend(String destination, RequestHeader header) {\n+        return SendBuilder.buildRequestSend(destination, header, this.data);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU2NDU0Mw=="}, "originalCommit": null, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NTQ5NzY2OnYy", "diffSide": "RIGHT", "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOFQxMDo0MDoxNlrOHvSNSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNzowMTo0NVrOHv4jZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTM0MzQzNA==", "bodyText": "if (tagged) {\n  buffer.printf(\"int _sizeBeforeBytes = _size.totalSize();%n\");\n}", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519343434", "createdAt": "2020-11-08T10:40:16Z", "author": {"login": "chia7712"}, "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "diffHunk": "@@ -1579,58 +1566,58 @@ private void generateVariableLengthFieldSize(FieldSpec field,\n                     }\n                     if (tagged) {\n                         headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n+                        buffer.printf(\"int _arraySize = _size.totalSize() - _sizeBeforeArray;%n\");\n                         buffer.printf(\"_cache.setArraySizeInBytes(%s, _arraySize);%n\",\n                             field.camelCaseName());\n-                        buffer.printf(\"_size += _arraySize + ByteUtils.sizeOfUnsignedVarint(_arraySize);%n\");\n-                    } else {\n-                        buffer.printf(\"_size += _arraySize;%n\");\n+                        buffer.printf(\"_size.addBytes(ByteUtils.sizeOfUnsignedVarint(_arraySize));%n\");\n                     }\n                 } else if (field.type().isBytes()) {\n+                    buffer.printf(\"int _sizeBeforeBytes = _size.totalSize();%n\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 265}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3MTY4Ng==", "bodyText": "Good catch", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519971686", "createdAt": "2020-11-09T17:01:45Z", "author": {"login": "hachikuji"}, "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "diffHunk": "@@ -1579,58 +1566,58 @@ private void generateVariableLengthFieldSize(FieldSpec field,\n                     }\n                     if (tagged) {\n                         headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n+                        buffer.printf(\"int _arraySize = _size.totalSize() - _sizeBeforeArray;%n\");\n                         buffer.printf(\"_cache.setArraySizeInBytes(%s, _arraySize);%n\",\n                             field.camelCaseName());\n-                        buffer.printf(\"_size += _arraySize + ByteUtils.sizeOfUnsignedVarint(_arraySize);%n\");\n-                    } else {\n-                        buffer.printf(\"_size += _arraySize;%n\");\n+                        buffer.printf(\"_size.addBytes(ByteUtils.sizeOfUnsignedVarint(_arraySize));%n\");\n                     }\n                 } else if (field.type().isBytes()) {\n+                    buffer.printf(\"int _sizeBeforeBytes = _size.totalSize();%n\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTM0MzQzNA=="}, "originalCommit": null, "originalPosition": 265}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NjAxMTI2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOFQxNTowNDoyNVrOHvXU1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNzoxOTowMVrOHv5RnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTQyNzI4Ng==", "bodyText": "If all requests are using auto-generated data, should this be default implementation of AbstractRequest?", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519427286", "createdAt": "2020-11-08T15:04:25Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "diffHunk": "@@ -91,4 +91,14 @@ public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n     public static EnvelopeRequest parse(ByteBuffer buffer, short version) {\n         return new EnvelopeRequest(ApiKeys.ENVELOPE.parseRequest(version, buffer), version);\n     }\n+\n+    public EnvelopeRequestData data() {\n+        return data;\n+    }\n+\n+    @Override\n+    public Send toSend(String destination, RequestHeader header) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk1NTE5OQ==", "bodyText": "Yeah, I think so. And looks like we're almost there. After your patch for Produce, the only remaining unconverted API that I see is OffsetsForLeaderEpoch.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519955199", "createdAt": "2020-11-09T16:43:56Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "diffHunk": "@@ -91,4 +91,14 @@ public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n     public static EnvelopeRequest parse(ByteBuffer buffer, short version) {\n         return new EnvelopeRequest(ApiKeys.ENVELOPE.parseRequest(version, buffer), version);\n     }\n+\n+    public EnvelopeRequestData data() {\n+        return data;\n+    }\n+\n+    @Override\n+    public Send toSend(String destination, RequestHeader header) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTQyNzI4Ng=="}, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk4MzUxNw==", "bodyText": "#7409 might be a good opportunity to complete this. What do you think @ijuma ?", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519983517", "createdAt": "2020-11-09T17:19:01Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "diffHunk": "@@ -91,4 +91,14 @@ public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n     public static EnvelopeRequest parse(ByteBuffer buffer, short version) {\n         return new EnvelopeRequest(ApiKeys.ENVELOPE.parseRequest(version, buffer), version);\n     }\n+\n+    public EnvelopeRequestData data() {\n+        return data;\n+    }\n+\n+    @Override\n+    public Send toSend(String destination, RequestHeader header) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTQyNzI4Ng=="}, "originalCommit": null, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NjA2ODAxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/protocol/Message.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOFQxNTozMToyNlrOHvX4jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOFQxNTozMToyNlrOHvX4jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTQzNjQzMQ==", "bodyText": "I'm thinking about how to simplify this process.\nCould we reuse the method void write(Writable writable, ObjectSerializationCache cache, short version) ? Maybe we can create a Writable instance but it does not write data to any output. Instead, it calculate the size of buffer according to input data.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519436431", "createdAt": "2020-11-08T15:31:26Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/Message.java", "diffHunk": "@@ -47,7 +47,20 @@\n      *                      If the specified version is too new to be supported\n      *                      by this software.\n      */\n-    int size(ObjectSerializationCache cache, short version);\n+    default int size(ObjectSerializationCache cache, short version) {\n+        MessageSizeAccumulator size = new MessageSizeAccumulator();\n+        addSize(size, cache, version);\n+        return size.totalSize();\n+    }\n+\n+    /**\n+     * Add the size of this message to an accumulator.\n+     *\n+     * @param size          The size accumulator to add to\n+     * @param cache         The serialization size cache to populate.\n+     * @param version       The version to use.\n+     */\n+    void addSize(MessageSizeAccumulator size, ObjectSerializationCache cache, short version);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MzI0MjIxOnYy", "diffSide": "RIGHT", "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMjozODo1MlrOHwapNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMjozODo1MlrOHwapNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUzMDIyOA==", "bodyText": "if (tagged) {\n  buffer.printf(\"int _sizeBeforeArray = _size.totalSize();%n\");\n}", "url": "https://github.com/apache/kafka/pull/9563#discussion_r520530228", "createdAt": "2020-11-10T12:38:52Z", "author": {"login": "chia7712"}, "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "diffHunk": "@@ -1529,37 +1516,37 @@ private void generateVariableLengthFieldSize(FieldSpec field,\n                             if (tagged) {\n                                 buffer.printf(\"int _stringPrefixSize = \" +\n                                     \"ByteUtils.sizeOfUnsignedVarint(_stringBytes.length + 1);%n\");\n-                                buffer.printf(\"_size += _stringBytes.length + _stringPrefixSize + \" +\n-                                    \"ByteUtils.sizeOfUnsignedVarint(_stringPrefixSize);%n\");\n+                                buffer.printf(\"_size.addBytes(_stringBytes.length + _stringPrefixSize + \" +\n+                                    \"ByteUtils.sizeOfUnsignedVarint(_stringPrefixSize));%n\");\n                             } else {\n-                                buffer.printf(\"_size += _stringBytes.length + \" +\n-                                    \"ByteUtils.sizeOfUnsignedVarint(_stringBytes.length + 1);%n\");\n+                                buffer.printf(\"_size.addBytes(_stringBytes.length + \" +\n+                                    \"ByteUtils.sizeOfUnsignedVarint(_stringBytes.length + 1));%n\");\n                             }\n                         }).\n                         ifNotMember(__ -> {\n                             if (tagged) {\n                                 throw new RuntimeException(\"Tagged field \" + field.name() +\n                                     \" should not be present in non-flexible versions.\");\n                             }\n-                            buffer.printf(\"_size += _stringBytes.length + 2;%n\");\n+                            buffer.printf(\"_size.addBytes(_stringBytes.length + 2);%n\");\n                         }).\n                         generate(buffer);\n                 } else if (field.type().isArray()) {\n-                    buffer.printf(\"int _arraySize = 0;%n\");\n+                    buffer.printf(\"int _sizeBeforeArray = _size.totalSize();%n\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MzI4OTk1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMjo1MToxN1rOHwbGDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwMTozNToxNlrOHxl3BA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUzNzYxMw==", "bodyText": "Is this method equal to https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java#L727 ?", "url": "https://github.com/apache/kafka/pull/9563#discussion_r520537613", "createdAt": "2020-11-10T12:51:17Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -88,16 +80,11 @@ protected void updateErrorCounts(Map<Errors, Integer> errorCounts, Errors error)\n \n     protected abstract Struct toStruct(short version);\n \n-    public ByteBuffer serializeBody(short version) {\n-        Struct dataStruct = toStruct(version);\n-        ByteBuffer buffer = ByteBuffer.allocate(dataStruct.sizeOf());\n-        dataStruct.writeTo(buffer);\n-        buffer.flip();\n-\n-        return buffer;\n-    }\n-\n-    public static AbstractResponse deserializeBody(ByteBuffer byteBuffer, RequestHeader header) {\n+    /**\n+     * Parse a response from the provided buffer. The buffer is expected to hold both\n+     * the {@link ResponseHeader} as well as the response payload.\n+     */\n+    public static AbstractResponse parseResponse(ByteBuffer byteBuffer, RequestHeader header) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTc2MDA4Mw==", "bodyText": "If it's ok with you, I'd like to address this in a separate patch. The main difference is the presence of the correlation validation logic in NetworkClient, which has been tailored to a subtle case in SaslClientAuthenticator. I think the envelope parsing logic should also be checking the correlationId, but probably not with the same quirky behavior.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r521760083", "createdAt": "2020-11-12T01:26:21Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -88,16 +80,11 @@ protected void updateErrorCounts(Map<Errors, Integer> errorCounts, Errors error)\n \n     protected abstract Struct toStruct(short version);\n \n-    public ByteBuffer serializeBody(short version) {\n-        Struct dataStruct = toStruct(version);\n-        ByteBuffer buffer = ByteBuffer.allocate(dataStruct.sizeOf());\n-        dataStruct.writeTo(buffer);\n-        buffer.flip();\n-\n-        return buffer;\n-    }\n-\n-    public static AbstractResponse deserializeBody(ByteBuffer byteBuffer, RequestHeader header) {\n+    /**\n+     * Parse a response from the provided buffer. The buffer is expected to hold both\n+     * the {@link ResponseHeader} as well as the response payload.\n+     */\n+    public static AbstractResponse parseResponse(ByteBuffer byteBuffer, RequestHeader header) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUzNzYxMw=="}, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTc2MjU2NA==", "bodyText": "sure. Open a jira as follow-up :)", "url": "https://github.com/apache/kafka/pull/9563#discussion_r521762564", "createdAt": "2020-11-12T01:35:16Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -88,16 +80,11 @@ protected void updateErrorCounts(Map<Errors, Integer> errorCounts, Errors error)\n \n     protected abstract Struct toStruct(short version);\n \n-    public ByteBuffer serializeBody(short version) {\n-        Struct dataStruct = toStruct(version);\n-        ByteBuffer buffer = ByteBuffer.allocate(dataStruct.sizeOf());\n-        dataStruct.writeTo(buffer);\n-        buffer.flip();\n-\n-        return buffer;\n-    }\n-\n-    public static AbstractResponse deserializeBody(ByteBuffer byteBuffer, RequestHeader header) {\n+    /**\n+     * Parse a response from the provided buffer. The buffer is expected to hold both\n+     * the {@link ResponseHeader} as well as the response payload.\n+     */\n+    public static AbstractResponse parseResponse(ByteBuffer byteBuffer, RequestHeader header) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUzNzYxMw=="}, "originalCommit": null, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MzMxNTI5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/protocol/SendBuilder.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMjo1Nzo0OVrOHwbVmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwMjowNTo1MFrOHw4lGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDU0MTU5Mw==", "bodyText": "Is it worth wrapping the byte array to a new ByteBufferSend to avoid array coping?", "url": "https://github.com/apache/kafka/pull/9563#discussion_r520541593", "createdAt": "2020-11-10T12:57:49Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/SendBuilder.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.protocol;\n+\n+import org.apache.kafka.common.network.ByteBufferSend;\n+import org.apache.kafka.common.network.Send;\n+import org.apache.kafka.common.record.BaseRecords;\n+import org.apache.kafka.common.record.MultiRecordsSend;\n+import org.apache.kafka.common.requests.RequestHeader;\n+import org.apache.kafka.common.requests.ResponseHeader;\n+import org.apache.kafka.common.utils.ByteUtils;\n+\n+import java.nio.ByteBuffer;\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+/**\n+ * This class provides a way to build {@link Send} objects for network transmission\n+ * from generated {@link org.apache.kafka.common.protocol.ApiMessage} types without\n+ * allocating new space for \"zero-copy\" fields (see {@link #writeByteBuffer(ByteBuffer)}\n+ * and {@link #writeRecords(BaseRecords)}).\n+ *\n+ * See {@link org.apache.kafka.common.requests.EnvelopeRequest#toSend(String, RequestHeader)}\n+ * for example usage.\n+ */\n+public class SendBuilder implements Writable {\n+    private final Queue<Send> sends = new ArrayDeque<>();\n+    private final ByteBuffer buffer;\n+    private final String destinationId;\n+\n+    SendBuilder(String destinationId, int size) {\n+        this.destinationId = destinationId;\n+        this.buffer = ByteBuffer.allocate(size);\n+        this.buffer.mark();\n+    }\n+\n+    private void flushCurrentBuffer() {\n+        int latestPosition = buffer.position();\n+        buffer.reset();\n+\n+        if (latestPosition > buffer.position()) {\n+            buffer.limit(latestPosition);\n+            addByteBufferSend(buffer.slice());\n+            buffer.position(latestPosition);\n+            buffer.limit(buffer.capacity());\n+            buffer.mark();\n+        }\n+    }\n+\n+    private void addByteBufferSend(ByteBuffer buffer) {\n+        sends.add(new ByteBufferSend(destinationId, buffer));\n+    }\n+\n+    @Override\n+    public void writeByte(byte val) {\n+        buffer.put(val);\n+    }\n+\n+    @Override\n+    public void writeShort(short val) {\n+        buffer.putShort(val);\n+    }\n+\n+    @Override\n+    public void writeInt(int val) {\n+        buffer.putInt(val);\n+    }\n+\n+    @Override\n+    public void writeLong(long val) {\n+        buffer.putLong(val);\n+    }\n+\n+    @Override\n+    public void writeDouble(double val) {\n+        buffer.putDouble(val);\n+    }\n+\n+    @Override\n+    public void writeByteArray(byte[] arr) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0OTgzMg==", "bodyText": "I did that in an earlier iteration, but I wasn't sure if the overhead of the ByteBuffer and ByteBufferSend made it a net win in the end. I also thought about adding a heuristic, such as looking for a minimum size. In the end, it seemed simpler to rely on \"zeroCopy\" to let us know when we are likely to get a benefit.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r520849832", "createdAt": "2020-11-10T20:20:34Z", "author": {"login": "hachikuji"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/SendBuilder.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.protocol;\n+\n+import org.apache.kafka.common.network.ByteBufferSend;\n+import org.apache.kafka.common.network.Send;\n+import org.apache.kafka.common.record.BaseRecords;\n+import org.apache.kafka.common.record.MultiRecordsSend;\n+import org.apache.kafka.common.requests.RequestHeader;\n+import org.apache.kafka.common.requests.ResponseHeader;\n+import org.apache.kafka.common.utils.ByteUtils;\n+\n+import java.nio.ByteBuffer;\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+/**\n+ * This class provides a way to build {@link Send} objects for network transmission\n+ * from generated {@link org.apache.kafka.common.protocol.ApiMessage} types without\n+ * allocating new space for \"zero-copy\" fields (see {@link #writeByteBuffer(ByteBuffer)}\n+ * and {@link #writeRecords(BaseRecords)}).\n+ *\n+ * See {@link org.apache.kafka.common.requests.EnvelopeRequest#toSend(String, RequestHeader)}\n+ * for example usage.\n+ */\n+public class SendBuilder implements Writable {\n+    private final Queue<Send> sends = new ArrayDeque<>();\n+    private final ByteBuffer buffer;\n+    private final String destinationId;\n+\n+    SendBuilder(String destinationId, int size) {\n+        this.destinationId = destinationId;\n+        this.buffer = ByteBuffer.allocate(size);\n+        this.buffer.mark();\n+    }\n+\n+    private void flushCurrentBuffer() {\n+        int latestPosition = buffer.position();\n+        buffer.reset();\n+\n+        if (latestPosition > buffer.position()) {\n+            buffer.limit(latestPosition);\n+            addByteBufferSend(buffer.slice());\n+            buffer.position(latestPosition);\n+            buffer.limit(buffer.capacity());\n+            buffer.mark();\n+        }\n+    }\n+\n+    private void addByteBufferSend(ByteBuffer buffer) {\n+        sends.add(new ByteBufferSend(destinationId, buffer));\n+    }\n+\n+    @Override\n+    public void writeByte(byte val) {\n+        buffer.put(val);\n+    }\n+\n+    @Override\n+    public void writeShort(short val) {\n+        buffer.putShort(val);\n+    }\n+\n+    @Override\n+    public void writeInt(int val) {\n+        buffer.putInt(val);\n+    }\n+\n+    @Override\n+    public void writeLong(long val) {\n+        buffer.putLong(val);\n+    }\n+\n+    @Override\n+    public void writeDouble(double val) {\n+        buffer.putDouble(val);\n+    }\n+\n+    @Override\n+    public void writeByteArray(byte[] arr) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDU0MTU5Mw=="}, "originalCommit": null, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAyMDY5OA==", "bodyText": "Thanks for your explanation. make sense to me.", "url": "https://github.com/apache/kafka/pull/9563#discussion_r521020698", "createdAt": "2020-11-11T02:05:50Z", "author": {"login": "chia7712"}, "path": "clients/src/main/java/org/apache/kafka/common/protocol/SendBuilder.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.protocol;\n+\n+import org.apache.kafka.common.network.ByteBufferSend;\n+import org.apache.kafka.common.network.Send;\n+import org.apache.kafka.common.record.BaseRecords;\n+import org.apache.kafka.common.record.MultiRecordsSend;\n+import org.apache.kafka.common.requests.RequestHeader;\n+import org.apache.kafka.common.requests.ResponseHeader;\n+import org.apache.kafka.common.utils.ByteUtils;\n+\n+import java.nio.ByteBuffer;\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+/**\n+ * This class provides a way to build {@link Send} objects for network transmission\n+ * from generated {@link org.apache.kafka.common.protocol.ApiMessage} types without\n+ * allocating new space for \"zero-copy\" fields (see {@link #writeByteBuffer(ByteBuffer)}\n+ * and {@link #writeRecords(BaseRecords)}).\n+ *\n+ * See {@link org.apache.kafka.common.requests.EnvelopeRequest#toSend(String, RequestHeader)}\n+ * for example usage.\n+ */\n+public class SendBuilder implements Writable {\n+    private final Queue<Send> sends = new ArrayDeque<>();\n+    private final ByteBuffer buffer;\n+    private final String destinationId;\n+\n+    SendBuilder(String destinationId, int size) {\n+        this.destinationId = destinationId;\n+        this.buffer = ByteBuffer.allocate(size);\n+        this.buffer.mark();\n+    }\n+\n+    private void flushCurrentBuffer() {\n+        int latestPosition = buffer.position();\n+        buffer.reset();\n+\n+        if (latestPosition > buffer.position()) {\n+            buffer.limit(latestPosition);\n+            addByteBufferSend(buffer.slice());\n+            buffer.position(latestPosition);\n+            buffer.limit(buffer.capacity());\n+            buffer.mark();\n+        }\n+    }\n+\n+    private void addByteBufferSend(ByteBuffer buffer) {\n+        sends.add(new ByteBufferSend(destinationId, buffer));\n+    }\n+\n+    @Override\n+    public void writeByte(byte val) {\n+        buffer.put(val);\n+    }\n+\n+    @Override\n+    public void writeShort(short val) {\n+        buffer.putShort(val);\n+    }\n+\n+    @Override\n+    public void writeInt(int val) {\n+        buffer.putInt(val);\n+    }\n+\n+    @Override\n+    public void writeLong(long val) {\n+        buffer.putLong(val);\n+    }\n+\n+    @Override\n+    public void writeDouble(double val) {\n+        buffer.putDouble(val);\n+    }\n+\n+    @Override\n+    public void writeByteArray(byte[] arr) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDU0MTU5Mw=="}, "originalCommit": null, "originalPosition": 94}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3803, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}