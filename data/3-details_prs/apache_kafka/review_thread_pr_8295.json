{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg3NzM4ODI5", "number": 8295, "reviewThreads": {"totalCount": 51, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxMzowOTozOVrOELPuKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxOTozNjo0MVrOEksl7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjI3MzY5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxMzowOTozOVrOGsv6fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxMzowOTozOVrOGsv6fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU3NTU1MA==", "bodyText": "I just noticed that we don't ensure that all futures of the current broker are completed. It would be great to ensure it by using completeUnrealizedFutures method if retryTopicPartitionOffsets is empty. We already do this in alterReplicaLogDirs() if you want to see an example.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449575550", "createdAt": "2020-07-03T13:09:39Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3883,21 +3886,24 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n                     Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n-                    for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n-                        TopicPartition tp = result.getKey();\n-                        PartitionData partitionData = result.getValue();\n-\n-                        KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n-                        Errors error = partitionData.error;\n-                        OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n-                        if (offsetRequestSpec == null) {\n-                            future.completeExceptionally(new KafkaException(\"Unexpected topic partition \" + tp + \" in broker response!\"));\n-                        } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n-                            retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n-                        } else if (error == Errors.NONE) {\n-                            future.complete(new ListOffsetsResultInfo(partitionData.offset, partitionData.timestamp, partitionData.leaderEpoch));\n-                        } else {\n-                            future.completeExceptionally(error.exception());\n+                    for (ListOffsetTopicResponse topic : response.responseData()) {\n+                        for (ListOffsetPartitionResponse partition : topic.partitions()) {\n+                            TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                            KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n+                            Errors error = Errors.forCode(partition.errorCode());\n+                            OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n+                            if (offsetRequestSpec == null) {\n+                                future.completeExceptionally(new KafkaException(\"Unexpected topic partition \" + tp + \" in broker response!\"));\n+                            } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n+                                retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n+                            } else if (error == Errors.NONE) {\n+                                Optional<Integer> leaderEpoch = (partition.leaderEpoch() == ListOffsetResponse.UNKNOWN_EPOCH) \n+                                        ? Optional.empty() \n+                                        : Optional.of(partition.leaderEpoch());\n+                                future.complete(new ListOffsetsResultInfo(partition.offset(), partition.timestamp(), leaderEpoch));\n+                            } else {\n+                                future.completeExceptionally(error.exception());\n+                            }\n                         }\n                     }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjI4NzMzOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxMzoxNDoyN1rOGswCpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxMzoxNDoyN1rOGswCpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU3NzYzNg==", "bodyText": "This is not related to your PR at all. It seems that if offsetRequestSpec is null here, future will be null as well cause futures is initialised based on topicPartitionOffsets. If it turns out to be correct, it may be better to just log a warning here like we do in createTopics().", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449577636", "createdAt": "2020-07-03T13:14:27Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3883,21 +3886,24 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n                     Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n-                    for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n-                        TopicPartition tp = result.getKey();\n-                        PartitionData partitionData = result.getValue();\n-\n-                        KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n-                        Errors error = partitionData.error;\n-                        OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n-                        if (offsetRequestSpec == null) {\n-                            future.completeExceptionally(new KafkaException(\"Unexpected topic partition \" + tp + \" in broker response!\"));\n-                        } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n-                            retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n-                        } else if (error == Errors.NONE) {\n-                            future.complete(new ListOffsetsResultInfo(partitionData.offset, partitionData.timestamp, partitionData.leaderEpoch));\n-                        } else {\n-                            future.completeExceptionally(error.exception());\n+                    for (ListOffsetTopicResponse topic : response.responseData()) {\n+                        for (ListOffsetPartitionResponse partition : topic.partitions()) {\n+                            TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                            KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n+                            Errors error = Errors.forCode(partition.errorCode());\n+                            OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n+                            if (offsetRequestSpec == null) {\n+                                future.completeExceptionally(new KafkaException(\"Unexpected topic partition \" + tp + \" in broker response!\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjM1OTU4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxMzozOToyOFrOGswurg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNzozMDo1NVrOGxxzSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU4ODkxMA==", "bodyText": "This conversion is a bit unfortunate as we have to traverse all the partitions again to build the List<ListOffsetTopic>. Instead, we could compute it directly within groupListOffsetRequests and could receive Map<Node, List<ListOffsetTopic> directly here. That seems doable but I may have missed something.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449588910", "createdAt": "2020-07-03T13:39:28Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -965,11 +994,11 @@ public void onFailure(RuntimeException e) {\n      * @return A response which can be polled to obtain the corresponding timestamps and offsets.\n      */\n     private RequestFuture<ListOffsetResult> sendListOffsetRequest(final Node node,\n-                                                                  final Map<TopicPartition, ListOffsetRequest.PartitionData> timestampsToSearch,\n+                                                                  final Map<TopicPartition, ListOffsetPartition> timestampsToSearch,\n                                                                   boolean requireTimestamp) {\n         ListOffsetRequest.Builder builder = ListOffsetRequest.Builder\n                 .forConsumer(requireTimestamp, isolationLevel)\n-                .setTargetTimes(timestampsToSearch);\n+                .setTargetTimes(toListOffsetTopics(timestampsToSearch));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjMyNDA2OQ==", "bodyText": "I initially tried to do that but there's a couple of intermediate collections using TopicPartition in these methods and it makes it really hard to update them. For example:\n\nhttps://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L735\nhttps://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L880\nhttps://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L887", "url": "https://github.com/apache/kafka/pull/8295#discussion_r452324069", "createdAt": "2020-07-09T15:58:51Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -965,11 +994,11 @@ public void onFailure(RuntimeException e) {\n      * @return A response which can be polled to obtain the corresponding timestamps and offsets.\n      */\n     private RequestFuture<ListOffsetResult> sendListOffsetRequest(final Node node,\n-                                                                  final Map<TopicPartition, ListOffsetRequest.PartitionData> timestampsToSearch,\n+                                                                  final Map<TopicPartition, ListOffsetPartition> timestampsToSearch,\n                                                                   boolean requireTimestamp) {\n         ListOffsetRequest.Builder builder = ListOffsetRequest.Builder\n                 .forConsumer(requireTimestamp, isolationLevel)\n-                .setTargetTimes(timestampsToSearch);\n+                .setTargetTimes(toListOffsetTopics(timestampsToSearch));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU4ODkxMA=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg0OTM1NQ==", "bodyText": "I had a look at this and your are right. It seems that keeping TopicPartition is better and difficult to change. In this case, have you considered pushing the conversion to the Builder by providing an overload of setTargetTimes which accepts a Map<TopicPartition, ListOffsetPartition>? That could make the code in the Fetcher a bit cleaner.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r454849355", "createdAt": "2020-07-15T07:30:55Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -965,11 +994,11 @@ public void onFailure(RuntimeException e) {\n      * @return A response which can be polled to obtain the corresponding timestamps and offsets.\n      */\n     private RequestFuture<ListOffsetResult> sendListOffsetRequest(final Node node,\n-                                                                  final Map<TopicPartition, ListOffsetRequest.PartitionData> timestampsToSearch,\n+                                                                  final Map<TopicPartition, ListOffsetPartition> timestampsToSearch,\n                                                                   boolean requireTimestamp) {\n         ListOffsetRequest.Builder builder = ListOffsetRequest.Builder\n                 .forConsumer(requireTimestamp, isolationLevel)\n-                .setTargetTimes(timestampsToSearch);\n+                .setTargetTimes(toListOffsetTopics(timestampsToSearch));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU4ODkxMA=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQxODMyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxMzo1OTo0OFrOGsxSDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxMDowMDoyN1rOGyj9ZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU5Nzk2Nw==", "bodyText": "I wonder if grouping by TopicPartition is really necessary here. We iterate over timestampsToSearch to get the ListOffsetPartitionResponse for the current TopicPartition but we could also iterate over the response set directly and thus avoid grouping. Moreover, we always assume that the result set contains the TopicPartition that we are interested in so it would not change the semantic. Am I missing something? What do you think?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449597967", "createdAt": "2020-07-03T13:59:48Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -994,30 +1023,29 @@ public void onSuccess(ClientResponse response, RequestFuture<ListOffsetResult> f\n      *               value of each partition may be null only for v0. In v1 and later the ListOffset API would not\n      *               return a null timestamp (-1 is returned instead when necessary).\n      */\n-    private void handleListOffsetResponse(Map<TopicPartition, ListOffsetRequest.PartitionData> timestampsToSearch,\n+    private void handleListOffsetResponse(Map<TopicPartition, ListOffsetPartition> timestampsToSearch,\n                                           ListOffsetResponse listOffsetResponse,\n                                           RequestFuture<ListOffsetResult> future) {\n         Map<TopicPartition, ListOffsetData> fetchedOffsets = new HashMap<>();\n         Set<TopicPartition> partitionsToRetry = new HashSet<>();\n         Set<String> unauthorizedTopics = new HashSet<>();\n \n-        for (Map.Entry<TopicPartition, ListOffsetRequest.PartitionData> entry : timestampsToSearch.entrySet()) {\n+        Map<TopicPartition, ListOffsetPartitionResponse> partitionsData = byTopicPartitions(listOffsetResponse.responseData());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM3NDkyNQ==", "bodyText": "We now added logic in the AdminClient to handle partial responses from brokers (based on #8295 (comment)). Shouldn't we do the same here instead of assuming the response is always complete? I'm not even sure if we should retry if a resource is missing from the response but we could at least log it instead of hitting a NPE.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r452374925", "createdAt": "2020-07-09T17:23:38Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -994,30 +1023,29 @@ public void onSuccess(ClientResponse response, RequestFuture<ListOffsetResult> f\n      *               value of each partition may be null only for v0. In v1 and later the ListOffset API would not\n      *               return a null timestamp (-1 is returned instead when necessary).\n      */\n-    private void handleListOffsetResponse(Map<TopicPartition, ListOffsetRequest.PartitionData> timestampsToSearch,\n+    private void handleListOffsetResponse(Map<TopicPartition, ListOffsetPartition> timestampsToSearch,\n                                           ListOffsetResponse listOffsetResponse,\n                                           RequestFuture<ListOffsetResult> future) {\n         Map<TopicPartition, ListOffsetData> fetchedOffsets = new HashMap<>();\n         Set<TopicPartition> partitionsToRetry = new HashSet<>();\n         Set<String> unauthorizedTopics = new HashSet<>();\n \n-        for (Map.Entry<TopicPartition, ListOffsetRequest.PartitionData> entry : timestampsToSearch.entrySet()) {\n+        Map<TopicPartition, ListOffsetPartitionResponse> partitionsData = byTopicPartitions(listOffsetResponse.responseData());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU5Nzk2Nw=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg1MzQxOA==", "bodyText": "I agree that we should at minimum avoid hitting a NPE.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r454853418", "createdAt": "2020-07-15T07:38:56Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -994,30 +1023,29 @@ public void onSuccess(ClientResponse response, RequestFuture<ListOffsetResult> f\n      *               value of each partition may be null only for v0. In v1 and later the ListOffset API would not\n      *               return a null timestamp (-1 is returned instead when necessary).\n      */\n-    private void handleListOffsetResponse(Map<TopicPartition, ListOffsetRequest.PartitionData> timestampsToSearch,\n+    private void handleListOffsetResponse(Map<TopicPartition, ListOffsetPartition> timestampsToSearch,\n                                           ListOffsetResponse listOffsetResponse,\n                                           RequestFuture<ListOffsetResult> future) {\n         Map<TopicPartition, ListOffsetData> fetchedOffsets = new HashMap<>();\n         Set<TopicPartition> partitionsToRetry = new HashSet<>();\n         Set<String> unauthorizedTopics = new HashSet<>();\n \n-        for (Map.Entry<TopicPartition, ListOffsetRequest.PartitionData> entry : timestampsToSearch.entrySet()) {\n+        Map<TopicPartition, ListOffsetPartitionResponse> partitionsData = byTopicPartitions(listOffsetResponse.responseData());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU5Nzk2Nw=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY3MTE0MA==", "bodyText": "I actually switched logic to loop on the response as you initially suggested", "url": "https://github.com/apache/kafka/pull/8295#discussion_r455671140", "createdAt": "2020-07-16T10:00:27Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -994,30 +1023,29 @@ public void onSuccess(ClientResponse response, RequestFuture<ListOffsetResult> f\n      *               value of each partition may be null only for v0. In v1 and later the ListOffset API would not\n      *               return a null timestamp (-1 is returned instead when necessary).\n      */\n-    private void handleListOffsetResponse(Map<TopicPartition, ListOffsetRequest.PartitionData> timestampsToSearch,\n+    private void handleListOffsetResponse(Map<TopicPartition, ListOffsetPartition> timestampsToSearch,\n                                           ListOffsetResponse listOffsetResponse,\n                                           RequestFuture<ListOffsetResult> future) {\n         Map<TopicPartition, ListOffsetData> fetchedOffsets = new HashMap<>();\n         Set<TopicPartition> partitionsToRetry = new HashSet<>();\n         Set<String> unauthorizedTopics = new HashSet<>();\n \n-        for (Map.Entry<TopicPartition, ListOffsetRequest.PartitionData> entry : timestampsToSearch.entrySet()) {\n+        Map<TopicPartition, ListOffsetPartitionResponse> partitionsData = byTopicPartitions(listOffsetResponse.responseData());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU5Nzk2Nw=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQ1NDU5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMjoxOVrOGsxoZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMjoxOVrOGsxoZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzY4NA==", "bodyText": "It would be great if we could add unit tests for this method and perhaps others as well.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449603684", "createdAt": "2020-07-03T14:12:19Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "diffHunk": "@@ -156,145 +66,98 @@ private Builder(short oldestAllowedVersion,\n                         int replicaId,\n                         IsolationLevel isolationLevel) {\n             super(ApiKeys.LIST_OFFSETS, oldestAllowedVersion, latestAllowedVersion);\n-            this.replicaId = replicaId;\n-            this.isolationLevel = isolationLevel;\n+            data = new ListOffsetRequestData()\n+                    .setIsolationLevel(isolationLevel.id())\n+                    .setReplicaId(replicaId);\n         }\n \n-        public Builder setTargetTimes(Map<TopicPartition, PartitionData> partitionTimestamps) {\n-            this.partitionTimestamps = partitionTimestamps;\n+        public Builder setTargetTimes(List<ListOffsetTopic> topics) {\n+            data.setTopics(topics);\n             return this;\n         }\n \n         @Override\n         public ListOffsetRequest build(short version) {\n-            return new ListOffsetRequest(replicaId, partitionTimestamps, isolationLevel, version);\n+            return new ListOffsetRequest(version, data);\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"(type=ListOffsetRequest\")\n-               .append(\", replicaId=\").append(replicaId);\n-            if (partitionTimestamps != null) {\n-                bld.append(\", partitionTimestamps=\").append(partitionTimestamps);\n-            }\n-            bld.append(\", isolationLevel=\").append(isolationLevel);\n-            bld.append(\")\");\n-            return bld.toString();\n-        }\n-    }\n-\n-    public static final class PartitionData {\n-        public final long timestamp;\n-        public final int maxNumOffsets; // only supported in v0\n-        public final Optional<Integer> currentLeaderEpoch;\n-\n-        private PartitionData(long timestamp, int maxNumOffsets, Optional<Integer> currentLeaderEpoch) {\n-            this.timestamp = timestamp;\n-            this.maxNumOffsets = maxNumOffsets;\n-            this.currentLeaderEpoch = currentLeaderEpoch;\n-        }\n-\n-        // For V0\n-        public PartitionData(long timestamp, int maxNumOffsets) {\n-            this(timestamp, maxNumOffsets, Optional.empty());\n-        }\n-\n-        public PartitionData(long timestamp, Optional<Integer> currentLeaderEpoch) {\n-            this(timestamp, 1, currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public boolean equals(Object obj) {\n-            if (!(obj instanceof PartitionData)) return false;\n-            PartitionData other = (PartitionData) obj;\n-            return this.timestamp == other.timestamp &&\n-                this.currentLeaderEpoch.equals(other.currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return Objects.hash(timestamp, currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"{timestamp: \").append(timestamp).\n-                    append(\", maxNumOffsets: \").append(maxNumOffsets).\n-                    append(\", currentLeaderEpoch: \").append(currentLeaderEpoch).\n-                    append(\"}\");\n-            return bld.toString();\n+            return data.toString();\n         }\n     }\n \n     /**\n      * Private constructor with a specified version.\n      */\n-    private ListOffsetRequest(int replicaId,\n-                              Map<TopicPartition, PartitionData> targetTimes,\n-                              IsolationLevel isolationLevel,\n-                              short version) {\n+    private ListOffsetRequest(short version, ListOffsetRequestData data) {\n         super(ApiKeys.LIST_OFFSETS, version);\n-        this.replicaId = replicaId;\n-        this.isolationLevel = isolationLevel;\n-        this.partitionTimestamps = targetTimes;\n+        this.data = data;\n         this.duplicatePartitions = Collections.emptySet();\n     }\n \n     public ListOffsetRequest(Struct struct, short version) {\n         super(ApiKeys.LIST_OFFSETS, version);\n-        Set<TopicPartition> duplicatePartitions = new HashSet<>();\n-        replicaId = struct.get(REPLICA_ID);\n-        isolationLevel = struct.hasField(ISOLATION_LEVEL) ?\n-                IsolationLevel.forId(struct.get(ISOLATION_LEVEL)) :\n-                IsolationLevel.READ_UNCOMMITTED;\n-        partitionTimestamps = new HashMap<>();\n-        for (Object topicResponseObj : struct.get(TOPICS)) {\n-            Struct topicResponse = (Struct) topicResponseObj;\n-            String topic = topicResponse.get(TOPIC_NAME);\n-            for (Object partitionResponseObj : topicResponse.get(PARTITIONS)) {\n-                Struct partitionResponse = (Struct) partitionResponseObj;\n-                int partition = partitionResponse.get(PARTITION_ID);\n-                long timestamp = partitionResponse.get(TIMESTAMP);\n-                TopicPartition tp = new TopicPartition(topic, partition);\n-\n-                int maxNumOffsets = partitionResponse.getOrElse(MAX_NUM_OFFSETS, 1);\n-                Optional<Integer> currentLeaderEpoch = RequestUtils.getLeaderEpoch(partitionResponse, CURRENT_LEADER_EPOCH);\n-                PartitionData partitionData = new PartitionData(timestamp, maxNumOffsets, currentLeaderEpoch);\n-                if (partitionTimestamps.put(tp, partitionData) != null)\n+        data = new ListOffsetRequestData(struct, version);\n+        duplicatePartitions = new HashSet<>();\n+        Set<TopicPartition> partitions = new HashSet<>();\n+        for (ListOffsetTopic topic : data.topics()) {\n+            for (ListOffsetPartition partition : topic.partitions()) {\n+                TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                if (!partitions.add(tp)) {\n                     duplicatePartitions.add(tp);\n+                }\n             }\n         }\n-        this.duplicatePartitions = duplicatePartitions;\n     }\n \n     @Override\n-    @SuppressWarnings(\"deprecation\")\n     public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 276}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQ1NjMzOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetResponse.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMjo1N1rOGsxpaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMjo1N1rOGsxpaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzk0NQ==", "bodyText": "I would call this one topics() as you did already in the request.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449603945", "createdAt": "2020-07-03T14:12:57Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetResponse.java", "diffHunk": "@@ -58,239 +47,54 @@\n public class ListOffsetResponse extends AbstractResponse {\n     public static final long UNKNOWN_TIMESTAMP = -1L;\n     public static final long UNKNOWN_OFFSET = -1L;\n+    public static final int UNKNOWN_EPOCH = RecordBatch.NO_PARTITION_LEADER_EPOCH;\n \n-    // top level fields\n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"responses\",\n-            \"The listed offsets by topic\");\n-\n-    // topic level fields\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partition_responses\",\n-            \"The listed offsets by partition\");\n-\n-    // partition level fields\n-    // This key is only used by ListOffsetResponse v0\n-    @Deprecated\n-    private static final Field.Array OFFSETS = new Field.Array(\"offsets\", INT64, \"A list of offsets.\");\n-    private static final Field.Int64 TIMESTAMP = new Field.Int64(\"timestamp\",\n-            \"The timestamp associated with the returned offset\");\n-    private static final Field.Int64 OFFSET = new Field.Int64(\"offset\",\n-            \"The offset found\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            ERROR_CODE,\n-            OFFSETS);\n-\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-\n-    private static final Schema LIST_OFFSET_RESPONSE_V0 = new Schema(\n-            TOPICS_V0);\n-\n-    // V1 bumped for the removal of the offsets array\n-    private static final Field PARTITIONS_V1 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            ERROR_CODE,\n-            TIMESTAMP,\n-            OFFSET);\n-\n-    private static final Field TOPICS_V1 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V1);\n-\n-    private static final Schema LIST_OFFSET_RESPONSE_V1 = new Schema(\n-            TOPICS_V1);\n-\n-    // V2 bumped for the addition of the throttle time\n-    private static final Schema LIST_OFFSET_RESPONSE_V2 = new Schema(\n-            THROTTLE_TIME_MS,\n-            TOPICS_V1);\n-\n-    // V3 bumped to indicate that on quota violation brokers send out responses before throttling.\n-    private static final Schema LIST_OFFSET_RESPONSE_V3 = LIST_OFFSET_RESPONSE_V2;\n-\n-    // V4 bumped for the addition of the current leader epoch in the request schema and the\n-    // leader epoch in the response partition data\n-    private static final Field PARTITIONS_V4 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            ERROR_CODE,\n-            TIMESTAMP,\n-            OFFSET,\n-            LEADER_EPOCH);\n+    private final ListOffsetResponseData data;\n \n-    private static final Field TOPICS_V4 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V4);\n-\n-    private static final Schema LIST_OFFSET_RESPONSE_V4 = new Schema(\n-            THROTTLE_TIME_MS,\n-            TOPICS_V4);\n-\n-    private static final Schema LIST_OFFSET_RESPONSE_V5 = LIST_OFFSET_RESPONSE_V4;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[] {LIST_OFFSET_RESPONSE_V0, LIST_OFFSET_RESPONSE_V1, LIST_OFFSET_RESPONSE_V2,\n-            LIST_OFFSET_RESPONSE_V3, LIST_OFFSET_RESPONSE_V4, LIST_OFFSET_RESPONSE_V5};\n-    }\n-\n-    public static final class PartitionData {\n-        public final Errors error;\n-        // The offsets list is only used in ListOffsetResponse v0.\n-        public final List<Long> offsets;\n-        public final Long timestamp;\n-        public final Long offset;\n-        public final Optional<Integer> leaderEpoch;\n-\n-        /**\n-         * Constructor for ListOffsetResponse v0\n-         */\n-        public PartitionData(Errors error, List<Long> offsets) {\n-            this.error = error;\n-            this.offsets = offsets;\n-            this.timestamp = null;\n-            this.offset = null;\n-            this.leaderEpoch = Optional.empty();\n-        }\n-\n-        /**\n-         * Constructor for ListOffsetResponse v1\n-         */\n-        public PartitionData(Errors error, long timestamp, long offset, Optional<Integer> leaderEpoch) {\n-            this.error = error;\n-            this.timestamp = timestamp;\n-            this.offset = offset;\n-            this.offsets = null;\n-            this.leaderEpoch = leaderEpoch;\n-        }\n-\n-        @Override\n-        public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"PartitionData(\").\n-                    append(\"errorCode: \").append(error.code());\n-\n-            if (offsets == null) {\n-                bld.append(\", timestamp: \").append(timestamp).\n-                        append(\", offset: \").append(offset).\n-                        append(\", leaderEpoch: \").append(leaderEpoch);\n-            } else {\n-                bld.append(\", offsets: \").\n-                        append(\"[\").\n-                        append(Utils.join(this.offsets, \",\")).\n-                        append(\"]\");\n-            }\n-            bld.append(\")\");\n-            return bld.toString();\n-        }\n+    public ListOffsetResponse(ListOffsetResponseData data) {\n+        this.data = data;\n     }\n \n-    private final int throttleTimeMs;\n-    private final Map<TopicPartition, PartitionData> responseData;\n-\n-    /**\n-     * Constructor for all versions without throttle time\n-     */\n-    public ListOffsetResponse(Map<TopicPartition, PartitionData> responseData) {\n-        this(DEFAULT_THROTTLE_TIME, responseData);\n-    }\n-\n-    public ListOffsetResponse(int throttleTimeMs, Map<TopicPartition, PartitionData> responseData) {\n-        this.throttleTimeMs = throttleTimeMs;\n-        this.responseData = responseData;\n-    }\n-\n-    public ListOffsetResponse(Struct struct) {\n-        this.throttleTimeMs = struct.getOrElse(THROTTLE_TIME_MS, DEFAULT_THROTTLE_TIME);\n-        responseData = new HashMap<>();\n-        for (Object topicResponseObj : struct.get(TOPICS)) {\n-            Struct topicResponse = (Struct) topicResponseObj;\n-            String topic = topicResponse.get(TOPIC_NAME);\n-            for (Object partitionResponseObj : topicResponse.get(PARTITIONS)) {\n-                Struct partitionResponse = (Struct) partitionResponseObj;\n-                int partition = partitionResponse.get(PARTITION_ID);\n-                Errors error = Errors.forCode(partitionResponse.get(ERROR_CODE));\n-                PartitionData partitionData;\n-                if (partitionResponse.hasField(OFFSETS)) {\n-                    Object[] offsets = partitionResponse.get(OFFSETS);\n-                    List<Long> offsetsList = new ArrayList<>();\n-                    for (Object offset : offsets)\n-                        offsetsList.add((Long) offset);\n-                    partitionData = new PartitionData(error, offsetsList);\n-                } else {\n-                    long timestamp = partitionResponse.get(TIMESTAMP);\n-                    long offset = partitionResponse.get(OFFSET);\n-                    Optional<Integer> leaderEpoch = RequestUtils.getLeaderEpoch(partitionResponse, LEADER_EPOCH);\n-                    partitionData = new PartitionData(error, timestamp, offset, leaderEpoch);\n-                }\n-                responseData.put(new TopicPartition(topic, partition), partitionData);\n-            }\n-        }\n+    public ListOffsetResponse(Struct struct, short version) {\n+        data = new ListOffsetResponseData(struct, version);\n     }\n \n     @Override\n     public int throttleTimeMs() {\n-        return throttleTimeMs;\n+        return data.throttleTimeMs();\n     }\n \n-    public Map<TopicPartition, PartitionData> responseData() {\n-        return responseData;\n+    public ListOffsetResponseData data() {\n+        return data;\n+    }\n+\n+    public List<ListOffsetTopicResponse> responseData() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 227}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQ3NjI4OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoyMDoxNFrOGsx1pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoyMDoxNFrOGsx1pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwNzA3OA==", "bodyText": "nit: What about creating a small helper to create a ListOffsetTopicResponse for a given TopicPartition & co? That would reduce the boilerplate code.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449607078", "createdAt": "2020-07-03T14:20:14Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -3220,12 +3286,30 @@ public void testListOffsetsMetadataRetriableErrors() throws Exception {\n             env.kafkaClient().prepareResponse(prepareMetadataResponse(cluster, Errors.NONE));\n \n             // listoffsets response from broker 0\n-            Map<TopicPartition, PartitionData> responseData = new HashMap<>();\n-            responseData.put(tp0, new PartitionData(Errors.NONE, -1L, 345L, Optional.of(543)));\n+            ListOffsetTopicResponse t0 = new ListOffsetTopicResponse()\n+                    .setName(tp0.topic())\n+                    .setPartitions(Collections.singletonList(new ListOffsetPartitionResponse()\n+                            .setPartitionIndex(tp0.partition())\n+                            .setErrorCode(Errors.NONE.code())\n+                            .setTimestamp(-1L)\n+                            .setOffset(345L)\n+                            .setLeaderEpoch(543)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 248}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjUwODAzOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/security/authenticator/SaslAuthenticatorTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDozMTozOVrOGsyImw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDozMTozOVrOGsyImw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYxMTkzMQ==", "bodyText": "Can we remove these two?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449611931", "createdAt": "2020-07-03T14:31:39Z", "author": {"login": "dajac"}, "path": "clients/src/test/java/org/apache/kafka/common/security/authenticator/SaslAuthenticatorTest.java", "diffHunk": "@@ -1581,8 +1582,19 @@ SaslClient createSaslClient() {\n \n     @Test\n     public void testConvertListOffsetResponseToSaslHandshakeResponse() {\n-        ListOffsetResponse response = new ListOffsetResponse(0, Collections.singletonMap(new TopicPartition(\"topic\", 0),\n-            new ListOffsetResponse.PartitionData(Errors.NONE, 0, 0, Optional.empty())));\n+        ListOffsetResponseData data = new ListOffsetResponseData()\n+                .setThrottleTimeMs(0)\n+                .setTopics(Collections.singletonList(new ListOffsetTopicResponse()\n+                        .setName(\"topic\")\n+                        .setPartitions(Collections.singletonList(new ListOffsetPartitionResponse()\n+                                .setErrorCode(Errors.NONE.code())\n+                                .setLeaderEpoch(ListOffsetResponse.UNKNOWN_EPOCH)\n+                                .setPartitionIndex(0)\n+                                .setOffset(0)\n+                                .setTimestamp(0)))));\n+        ListOffsetResponse response = new ListOffsetResponse(data);\n+//        ListOffsetResponse response = new ListOffsetResponse(0, Collections.singletonMap(new TopicPartition(\"topic\", 0),\n+//            new ListOffsetResponse.PartitionData(Errors.NONE, 0, 0, Optional.empty())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjU3OTA2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDo1NzozM1rOGsyyzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDo1NzozM1rOGsyyzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyMjczNQ==", "bodyText": "nit: Could we split the line as before?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449622735", "createdAt": "2020-07-03T14:57:33Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjU4MDQ0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDo1ODowNlrOGsyzrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMTowOTo1M1rOGvMeqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyMjk1Nw==", "bodyText": "nit: The indentation looks weird.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449622957", "createdAt": "2020-07-03T14:58:06Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjE0MDcxNA==", "bodyText": "It looks weird but it's 2 to the right which should be \"correct\"", "url": "https://github.com/apache/kafka/pull/8295#discussion_r452140714", "createdAt": "2020-07-09T11:09:53Z", "author": {"login": "mimaison"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyMjk1Nw=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjU5MDYyOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowMTo0N1rOGsy5rA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowMTo0N1rOGsy5rA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNDQ5Mg==", "bodyText": "I think oldStyleOffsets is an empty array by default.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449624492", "createdAt": "2020-07-03T15:01:47Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 174}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjU5MzM5OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowMjo0N1rOGsy7XA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowMjo0N1rOGsy7XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNDkyNA==", "bodyText": "Same comment as above.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449624924", "createdAt": "2020-07-03T15:02:47Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 181}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjU5NDE1OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowMzowM1rOGsy7xA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowMzowM1rOGsy7xA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNTAyOA==", "bodyText": "nit: Could we split the line?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449625028", "createdAt": "2020-07-03T15:03:03Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 194}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjYwMTAwOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowNTozNFrOGsy_sQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowNTozNFrOGsy_sQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNjAzMw==", "bodyText": "I suggest to move this one up and ensure it is used everywhere.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449626033", "createdAt": "2020-07-03T15:05:34Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.INVALID_REQUEST.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+        } else {\n+  \n+          def buildErrorResponse(e: Errors): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 226}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjYwMTg0OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowNTo1NlrOGszANg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowNTo1NlrOGszANg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNjE2Ng==", "bodyText": "Replace by buildErrorResponse.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449626166", "createdAt": "2020-07-03T15:05:56Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          new ListOffsetPartitionResponse()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 213}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjYwMzY5OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowNjozMlrOGszBRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowNjozMlrOGszBRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNjQzNw==", "bodyText": "Replace by buildErrorResponse.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449626437", "createdAt": "2020-07-03T15:06:32Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.INVALID_REQUEST.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+        } else {\n+  \n+          def buildErrorResponse(e: Errors): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }\n+  \n+          try {\n+            val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n+            val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n+            val isolationLevelOpt = if (isClientRequest)\n+              Some(offsetRequest.isolationLevel)\n+            else\n+              None\n+  \n+            val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n+              partition.timestamp,\n+              isolationLevelOpt,\n+              if (partition.currentLeaderEpoch == ListOffsetResponse.UNKNOWN_EPOCH) Optional.empty() else Optional.of(partition.currentLeaderEpoch),\n+              fetchOnlyFromLeader)\n+  \n+            val response = foundOpt match {\n+              case Some(found) => {\n+                val partitionResponse = new ListOffsetPartitionResponse()\n+                  .setPartitionIndex(partition.partitionIndex)\n+                  .setErrorCode(Errors.NONE.code)\n+                  .setTimestamp(found.timestamp)\n+                  .setOffset(found.offset)\n+                if (found.leaderEpoch.isPresent)\n+                  partitionResponse.setLeaderEpoch(found.leaderEpoch.get)\n+                partitionResponse\n+              }\n+              case None =>\n+                new ListOffsetPartitionResponse()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 254}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjYxMTUxOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTowOToyNFrOGszF-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNDo1MjoyNFrOHAPPfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNzY0MA==", "bodyText": "We could use a scala Option now.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r449627640", "createdAt": "2020-07-03T15:09:24Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.INVALID_REQUEST.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+        } else {\n+  \n+          def buildErrorResponse(e: Errors): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }\n+  \n+          try {\n+            val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n+            val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n+            val isolationLevelOpt = if (isClientRequest)\n+              Some(offsetRequest.isolationLevel)\n+            else\n+              None\n+  \n+            val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n+              partition.timestamp,\n+              isolationLevelOpt,\n+              if (partition.currentLeaderEpoch == ListOffsetResponse.UNKNOWN_EPOCH) Optional.empty() else Optional.of(partition.currentLeaderEpoch),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5NjI1NQ==", "bodyText": "What do you mean here? @dajac", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463696255", "createdAt": "2020-07-31T16:00:51Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.INVALID_REQUEST.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+        } else {\n+  \n+          def buildErrorResponse(e: Errors): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }\n+  \n+          try {\n+            val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n+            val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n+            val isolationLevelOpt = if (isClientRequest)\n+              Some(offsetRequest.isolationLevel)\n+            else\n+              None\n+  \n+            val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n+              partition.timestamp,\n+              isolationLevelOpt,\n+              if (partition.currentLeaderEpoch == ListOffsetResponse.UNKNOWN_EPOCH) Optional.empty() else Optional.of(partition.currentLeaderEpoch),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNzY0MA=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkxMTY3Ng==", "bodyText": "I was asking if we could use a Scala Option instead of the Java Optional. Keeping the Optional as-is is the way to go as we will likely add support for it in the auto-generated protocol to avoid having to manually handle sentinel values.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r464911676", "createdAt": "2020-08-04T09:10:46Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.INVALID_REQUEST.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+        } else {\n+  \n+          def buildErrorResponse(e: Errors): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }\n+  \n+          try {\n+            val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n+            val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n+            val isolationLevelOpt = if (isClientRequest)\n+              Some(offsetRequest.isolationLevel)\n+            else\n+              None\n+  \n+            val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n+              partition.timestamp,\n+              isolationLevelOpt,\n+              if (partition.currentLeaderEpoch == ListOffsetResponse.UNKNOWN_EPOCH) Optional.empty() else Optional.of(partition.currentLeaderEpoch),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNzY0MA=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc2MTkzMA==", "bodyText": "@mimaison WDYT? I'm neutral.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468761930", "createdAt": "2020-08-11T17:55:45Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.INVALID_REQUEST.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+        } else {\n+  \n+          def buildErrorResponse(e: Errors): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }\n+  \n+          try {\n+            val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n+            val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n+            val isolationLevelOpt = if (isClientRequest)\n+              Some(offsetRequest.isolationLevel)\n+            else\n+              None\n+  \n+            val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n+              partition.timestamp,\n+              isolationLevelOpt,\n+              if (partition.currentLeaderEpoch == ListOffsetResponse.UNKNOWN_EPOCH) Optional.empty() else Optional.of(partition.currentLeaderEpoch),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNzY0MA=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAxMTc3NA==", "bodyText": "Yes let's keep Optional here", "url": "https://github.com/apache/kafka/pull/8295#discussion_r470011774", "createdAt": "2020-08-13T14:52:24Z", "author": {"login": "mimaison"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +894,175 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setOldStyleOffsets(Seq.empty[JLong].asJava)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+              .setOldStyleOffsets(List[JLong]().asJava)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.INVALID_REQUEST.code)\n+            .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+            .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+        } else {\n+  \n+          def buildErrorResponse(e: Errors): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }\n+  \n+          try {\n+            val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n+            val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n+            val isolationLevelOpt = if (isClientRequest)\n+              Some(offsetRequest.isolationLevel)\n+            else\n+              None\n+  \n+            val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n+              partition.timestamp,\n+              isolationLevelOpt,\n+              if (partition.currentLeaderEpoch == ListOffsetResponse.UNKNOWN_EPOCH) Optional.empty() else Optional.of(partition.currentLeaderEpoch),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYyNzY0MA=="}, "originalCommit": {"oid": "65ac2f1501fd6ee863a873cd93b64a1534d09461"}, "originalPosition": 239}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzAwODY1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNzoxOTozM1rOGxxa9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNzoxOTozM1rOGxxa9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg0MzEyNg==", "bodyText": "nit: We usually put a space before and after :.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r454843126", "createdAt": "2020-07-15T07:19:33Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3870,12 +3873,13 @@ public ListOffsetsResult listOffsets(Map<TopicPartition, OffsetSpec> topicPartit\n             }\n         }\n \n-        for (final Map.Entry<Node, Map<TopicPartition, ListOffsetRequest.PartitionData>> entry: leaders.entrySet()) {\n+        for (final Map.Entry<Node, Map<String, ListOffsetTopic>> entry: leaders.entrySet()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzAyNDg2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNzoyNDowM1rOGxxksA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNzoyNDowM1rOGxxksA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg0NTYxNg==", "bodyText": "As we don't have the list of TopicPartition available to filter the list of futures, we could actually directly complete the future within the loop instead of populating the HashSet. It avoids building the HashSet and having to traverse the futures.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r454845616", "createdAt": "2020-07-15T07:24:03Z", "author": {"login": "dajac"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3888,25 +3892,40 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n                     Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n-                    for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n-                        TopicPartition tp = result.getKey();\n-                        PartitionData partitionData = result.getValue();\n-\n-                        KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n-                        Errors error = partitionData.error;\n-                        OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n-                        if (offsetRequestSpec == null) {\n-                            future.completeExceptionally(new KafkaException(\"Unexpected topic partition \" + tp + \" in broker response!\"));\n-                        } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n-                            retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n-                        } else if (error == Errors.NONE) {\n-                            future.complete(new ListOffsetsResultInfo(partitionData.offset, partitionData.timestamp, partitionData.leaderEpoch));\n-                        } else {\n-                            future.completeExceptionally(error.exception());\n+                    for (ListOffsetTopicResponse topic : response.topics()) {\n+                        for (ListOffsetPartitionResponse partition : topic.partitions()) {\n+                            TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                            KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n+                            Errors error = Errors.forCode(partition.errorCode());\n+                            OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n+                            if (offsetRequestSpec == null) {\n+                                log.warn(\"Server response mentioned unknown topic partition {}\", tp);\n+                            } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n+                                retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n+                            } else if (error == Errors.NONE) {\n+                                Optional<Integer> leaderEpoch = (partition.leaderEpoch() == ListOffsetResponse.UNKNOWN_EPOCH)\n+                                        ? Optional.empty() \n+                                        : Optional.of(partition.leaderEpoch());\n+                                future.complete(new ListOffsetsResultInfo(partition.offset(), partition.timestamp(), leaderEpoch));\n+                            } else {\n+                                future.completeExceptionally(error.exception());\n+                            }\n                         }\n                     }\n \n-                    if (!retryTopicPartitionOffsets.isEmpty()) {\n+                    if (retryTopicPartitionOffsets.isEmpty()) {\n+                        // The server should send back a response for every topic partition. But do a sanity check anyway.\n+                        Set<TopicPartition> tpsOnBroker = new HashSet<>();\n+                        for (ListOffsetTopic topic : partitionsToQuery) {\n+                            for (ListOffsetPartition partition : topic.partitions()) {\n+                                tpsOnBroker.add(new TopicPartition(topic.name(), partition.partitionIndex()));\n+                            }\n+                        }\n+                        completeUnrealizedFutures(\n+                            futures.entrySet().stream().filter(entry -> tpsOnBroker.contains(entry.getKey())),\n+                            tp -> \"The response from broker \" + brokerId +\n+                                \" did not contain a result for topic partition \" + tp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzE4MDMwOnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODowODozOVrOGxzDAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxMzoyNDozMFrOGyqxNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg2OTc2Mw==", "bodyText": "I did not realize that changing to a Scala Option would be that pervasive when I suggested it. It may be better to keep your original code that used a Java Option and refactor this once #9008 is completed.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r454869763", "createdAt": "2020-07-15T08:08:39Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1077,7 +1077,7 @@ class ReplicaManager(val config: KafkaConfig,\n           // Try the read first, this tells us whether we need all of adjustedFetchSize for this partition\n           val readInfo: LogReadInfo = partition.readRecords(\n             fetchOffset = fetchInfo.fetchOffset,\n-            currentLeaderEpoch = fetchInfo.currentLeaderEpoch,\n+            currentLeaderEpoch = toScalaOption(fetchInfo.currentLeaderEpoch),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY3MTk1MQ==", "bodyText": "I think it's ok to keep the Scala Option here. #9008 can just update the field if it changes name.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r455671951", "createdAt": "2020-07-16T10:01:39Z", "author": {"login": "mimaison"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1077,7 +1077,7 @@ class ReplicaManager(val config: KafkaConfig,\n           // Try the read first, this tells us whether we need all of adjustedFetchSize for this partition\n           val readInfo: LogReadInfo = partition.readRecords(\n             fetchOffset = fetchInfo.fetchOffset,\n-            currentLeaderEpoch = fetchInfo.currentLeaderEpoch,\n+            currentLeaderEpoch = toScalaOption(fetchInfo.currentLeaderEpoch),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg2OTc2Mw=="}, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc2NTM3NA==", "bodyText": "Btw, you can use .asScala on a Java Option to convert it directly.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r455765374", "createdAt": "2020-07-16T12:57:54Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1077,7 +1077,7 @@ class ReplicaManager(val config: KafkaConfig,\n           // Try the read first, this tells us whether we need all of adjustedFetchSize for this partition\n           val readInfo: LogReadInfo = partition.readRecords(\n             fetchOffset = fetchInfo.fetchOffset,\n-            currentLeaderEpoch = fetchInfo.currentLeaderEpoch,\n+            currentLeaderEpoch = toScalaOption(fetchInfo.currentLeaderEpoch),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg2OTc2Mw=="}, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc4MjcxMA==", "bodyText": "Yes but it give us a Option[java.lang.Integer] oject while we want Option[Int]", "url": "https://github.com/apache/kafka/pull/8295#discussion_r455782710", "createdAt": "2020-07-16T13:24:30Z", "author": {"login": "mimaison"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1077,7 +1077,7 @@ class ReplicaManager(val config: KafkaConfig,\n           // Try the read first, this tells us whether we need all of adjustedFetchSize for this partition\n           val readInfo: LogReadInfo = partition.readRecords(\n             fetchOffset = fetchInfo.fetchOffset,\n-            currentLeaderEpoch = fetchInfo.currentLeaderEpoch,\n+            currentLeaderEpoch = toScalaOption(fetchInfo.currentLeaderEpoch),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg2OTc2Mw=="}, "originalCommit": null, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzE5MDI2OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODoxMToxOFrOGxzJDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxMzozNzo0OVrOGyrUrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3MTMxMA==", "bodyText": "nit: Indentation seems wrong here.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r454871310", "createdAt": "2020-07-15T08:11:18Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +895,162 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    def buildErrorResponse(e: Errors, partition: ListOffsetPartition): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY2OTY2Mw==", "bodyText": "It's 2 spaces in", "url": "https://github.com/apache/kafka/pull/8295#discussion_r455669663", "createdAt": "2020-07-16T09:58:03Z", "author": {"login": "mimaison"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +895,162 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    def buildErrorResponse(e: Errors, partition: ListOffsetPartition): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3MTMxMA=="}, "originalCommit": null, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc2MzAxMA==", "bodyText": "Shouldn't the closing curly brace be aligned with def at L967?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r455763010", "createdAt": "2020-07-16T12:54:10Z", "author": {"login": "dajac"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +895,162 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    def buildErrorResponse(e: Errors, partition: ListOffsetPartition): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3MTMxMA=="}, "originalCommit": null, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc5MTc4OQ==", "bodyText": "ah, yes! Fixed", "url": "https://github.com/apache/kafka/pull/8295#discussion_r455791789", "createdAt": "2020-07-16T13:37:49Z", "author": {"login": "mimaison"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -892,136 +895,162 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderForPartitionException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n-\n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n-\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderForPartitionException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderForPartitionException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    def buildErrorResponse(e: Errors, partition: ListOffsetPartition): ListOffsetPartitionResponse = {\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(e.code)\n+              .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+              .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+          }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3MTMxMA=="}, "originalCommit": null, "originalPosition": 199}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTEwNzc3OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNToyNzo1MlrOG6MrSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwODoyNTowOFrOG7WT2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY3ODI4Mw==", "bodyText": "Could we use completeUnrealizedFutures here?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463678283", "createdAt": "2020-07-31T15:27:52Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3973,25 +3977,38 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n                     Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n-                    for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n-                        TopicPartition tp = result.getKey();\n-                        PartitionData partitionData = result.getValue();\n-\n-                        KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n-                        Errors error = partitionData.error;\n-                        OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n-                        if (offsetRequestSpec == null) {\n-                            future.completeExceptionally(new KafkaException(\"Unexpected topic partition \" + tp + \" in broker response!\"));\n-                        } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n-                            retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n-                        } else if (error == Errors.NONE) {\n-                            future.complete(new ListOffsetsResultInfo(partitionData.offset, partitionData.timestamp, partitionData.leaderEpoch));\n-                        } else {\n-                            future.completeExceptionally(error.exception());\n+                    for (ListOffsetTopicResponse topic : response.topics()) {\n+                        for (ListOffsetPartitionResponse partition : topic.partitions()) {\n+                            TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                            KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n+                            Errors error = Errors.forCode(partition.errorCode());\n+                            OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n+                            if (offsetRequestSpec == null) {\n+                                log.warn(\"Server response mentioned unknown topic partition {}\", tp);\n+                            } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n+                                retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n+                            } else if (error == Errors.NONE) {\n+                                Optional<Integer> leaderEpoch = (partition.leaderEpoch() == ListOffsetResponse.UNKNOWN_EPOCH)\n+                                        ? Optional.empty()\n+                                        : Optional.of(partition.leaderEpoch());\n+                                future.complete(new ListOffsetsResultInfo(partition.offset(), partition.timestamp(), leaderEpoch));\n+                            } else {\n+                                future.completeExceptionally(error.exception());\n+                            }\n                         }\n                     }\n \n-                    if (!retryTopicPartitionOffsets.isEmpty()) {\n+                    if (retryTopicPartitionOffsets.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDg4NDY5Nw==", "bodyText": "@dajac suggested that earlier too but here we need to get the unrealized future for the current broker. So it turned out it's easier to do the current logic than use completeUnrealizedFutures() here", "url": "https://github.com/apache/kafka/pull/8295#discussion_r464884697", "createdAt": "2020-08-04T08:25:08Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3973,25 +3977,38 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n                     Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n-                    for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n-                        TopicPartition tp = result.getKey();\n-                        PartitionData partitionData = result.getValue();\n-\n-                        KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n-                        Errors error = partitionData.error;\n-                        OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n-                        if (offsetRequestSpec == null) {\n-                            future.completeExceptionally(new KafkaException(\"Unexpected topic partition \" + tp + \" in broker response!\"));\n-                        } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n-                            retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n-                        } else if (error == Errors.NONE) {\n-                            future.complete(new ListOffsetsResultInfo(partitionData.offset, partitionData.timestamp, partitionData.leaderEpoch));\n-                        } else {\n-                            future.completeExceptionally(error.exception());\n+                    for (ListOffsetTopicResponse topic : response.topics()) {\n+                        for (ListOffsetPartitionResponse partition : topic.partitions()) {\n+                            TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                            KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n+                            Errors error = Errors.forCode(partition.errorCode());\n+                            OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n+                            if (offsetRequestSpec == null) {\n+                                log.warn(\"Server response mentioned unknown topic partition {}\", tp);\n+                            } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n+                                retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n+                            } else if (error == Errors.NONE) {\n+                                Optional<Integer> leaderEpoch = (partition.leaderEpoch() == ListOffsetResponse.UNKNOWN_EPOCH)\n+                                        ? Optional.empty()\n+                                        : Optional.of(partition.leaderEpoch());\n+                                future.complete(new ListOffsetsResultInfo(partition.offset(), partition.timestamp(), leaderEpoch));\n+                            } else {\n+                                future.completeExceptionally(error.exception());\n+                            }\n                         }\n                     }\n \n-                    if (!retryTopicPartitionOffsets.isEmpty()) {\n+                    if (retryTopicPartitionOffsets.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY3ODI4Mw=="}, "originalCommit": null, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTExNzU4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTozMDo1MVrOG6MxZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTozMDo1MVrOG6MxZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY3OTg0Nw==", "bodyText": "nit: replace with <>", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463679847", "createdAt": "2020-07-31T15:30:51Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -949,13 +953,27 @@ public void onFailure(RuntimeException e) {\n                             leader, tp);\n                     partitionsToRetry.add(tp);\n                 } else {\n-                    partitionDataMap.put(tp, new ListOffsetRequest.PartitionData(offset, leaderAndEpoch.epoch));\n+                    int currentLeaderEpoch = leaderAndEpoch.epoch.orElse(ListOffsetResponse.UNKNOWN_EPOCH);\n+                    partitionDataMap.put(tp, new ListOffsetPartition()\n+                            .setPartitionIndex(tp.partition())\n+                            .setTimestamp(offset)\n+                            .setCurrentLeaderEpoch(currentLeaderEpoch));\n                 }\n             }\n         }\n         return regroupPartitionMapByNode(partitionDataMap);\n     }\n \n+    private static List<ListOffsetTopic> toListOffsetTopics(Map<TopicPartition, ListOffsetPartition> timestampsToSearch) {\n+        Map<String, ListOffsetTopic> topics = new HashMap<>();\n+        for (Map.Entry<TopicPartition, ListOffsetPartition> entry : timestampsToSearch.entrySet()) {\n+            TopicPartition tp = entry.getKey();\n+            ListOffsetTopic topic = topics.computeIfAbsent(tp.topic(), k -> new ListOffsetTopic().setName(tp.topic()));\n+            topic.partitions().add(entry.getValue());\n+        }\n+        return new ArrayList<ListOffsetTopic>(topics.values());", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTEyMTcxOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTozMjowNlrOG6M0Ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTozMjowNlrOG6M0Ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4MDUxNA==", "bodyText": "Let's move this helper into ListOffsetRequest", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463680514", "createdAt": "2020-07-31T15:32:06Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -949,13 +953,27 @@ public void onFailure(RuntimeException e) {\n                             leader, tp);\n                     partitionsToRetry.add(tp);\n                 } else {\n-                    partitionDataMap.put(tp, new ListOffsetRequest.PartitionData(offset, leaderAndEpoch.epoch));\n+                    int currentLeaderEpoch = leaderAndEpoch.epoch.orElse(ListOffsetResponse.UNKNOWN_EPOCH);\n+                    partitionDataMap.put(tp, new ListOffsetPartition()\n+                            .setPartitionIndex(tp.partition())\n+                            .setTimestamp(offset)\n+                            .setCurrentLeaderEpoch(currentLeaderEpoch));\n                 }\n             }\n         }\n         return regroupPartitionMapByNode(partitionDataMap);\n     }\n \n+    private static List<ListOffsetTopic> toListOffsetTopics(Map<TopicPartition, ListOffsetPartition> timestampsToSearch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTEzNDMzOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTozNTozNVrOG6M70w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTozNTozNVrOG6M70w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4MjUxNQ==", "bodyText": "Good coverage", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463682515", "createdAt": "2020-07-31T15:35:35Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -4068,6 +4093,58 @@ public void testListOffsetsMetadataNonRetriableErrors() throws Exception {\n         }\n     }\n \n+    @Test\n+    public void testListOffsetsPartialResponse() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 273}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTE0MzI2OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTozODoxNVrOG6NBZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTozODoxNVrOG6NBZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4Mzk0MQ==", "bodyText": "nit: space 4 after =", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463683941", "createdAt": "2020-07-31T15:38:15Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "diffHunk": "@@ -156,145 +66,98 @@ private Builder(short oldestAllowedVersion,\n                         int replicaId,\n                         IsolationLevel isolationLevel) {\n             super(ApiKeys.LIST_OFFSETS, oldestAllowedVersion, latestAllowedVersion);\n-            this.replicaId = replicaId;\n-            this.isolationLevel = isolationLevel;\n+            data = new ListOffsetRequestData()\n+                    .setIsolationLevel(isolationLevel.id())", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTE1NTU5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0MTo1MVrOG6NJDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwODoyODoxNlrOG7Wa2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4NTkwMg==", "bodyText": "I think this check is redundant and should be removed, otherwise we should have it for all general RPCs with topic => partition structure.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463685902", "createdAt": "2020-07-31T15:41:51Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "diffHunk": "@@ -47,96 +42,11 @@\n     public static final int CONSUMER_REPLICA_ID = -1;\n     public static final int DEBUGGING_REPLICA_ID = -2;\n \n-    // top level fields\n-    private static final Field.Int32 REPLICA_ID = new Field.Int32(\"replica_id\",\n-            \"Broker id of the follower. For normal consumers, use -1.\");\n-    private static final Field.Int8 ISOLATION_LEVEL = new Field.Int8(\"isolation_level\",\n-            \"This setting controls the visibility of transactional records. \" +\n-                    \"Using READ_UNCOMMITTED (isolation_level = 0) makes all records visible. With READ_COMMITTED \" +\n-                    \"(isolation_level = 1), non-transactional and COMMITTED transactional records are visible. \" +\n-                    \"To be more concrete, READ_COMMITTED returns all data from offsets smaller than the current \" +\n-                    \"LSO (last stable offset), and enables the inclusion of the list of aborted transactions in the \" +\n-                    \"result, which allows consumers to discard ABORTED transactional records\");\n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"Topics to list offsets.\");\n-\n-    // topic level fields\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"Partitions to list offsets.\");\n-\n-    // partition level fields\n-    private static final Field.Int64 TIMESTAMP = new Field.Int64(\"timestamp\",\n-            \"The target timestamp for the partition.\");\n-    private static final Field.Int32 MAX_NUM_OFFSETS = new Field.Int32(\"max_num_offsets\",\n-            \"Maximum offsets to return.\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            TIMESTAMP,\n-            MAX_NUM_OFFSETS);\n-\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-\n-    private static final Schema LIST_OFFSET_REQUEST_V0 = new Schema(\n-            REPLICA_ID,\n-            TOPICS_V0);\n-\n-    // V1 removes max_num_offsets\n-    private static final Field PARTITIONS_V1 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            TIMESTAMP);\n-\n-    private static final Field TOPICS_V1 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V1);\n-\n-    private static final Schema LIST_OFFSET_REQUEST_V1 = new Schema(\n-            REPLICA_ID,\n-            TOPICS_V1);\n-\n-    // V2 adds a field for the isolation level\n-    private static final Schema LIST_OFFSET_REQUEST_V2 = new Schema(\n-            REPLICA_ID,\n-            ISOLATION_LEVEL,\n-            TOPICS_V1);\n-\n-    // V3 bump used to indicate that on quota violation brokers send out responses before throttling.\n-    private static final Schema LIST_OFFSET_REQUEST_V3 = LIST_OFFSET_REQUEST_V2;\n-\n-    // V4 introduces the current leader epoch, which is used for fencing\n-    private static final Field PARTITIONS_V4 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            CURRENT_LEADER_EPOCH,\n-            TIMESTAMP);\n-\n-    private static final Field TOPICS_V4 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V4);\n-\n-    private static final Schema LIST_OFFSET_REQUEST_V4 = new Schema(\n-            REPLICA_ID,\n-            ISOLATION_LEVEL,\n-            TOPICS_V4);\n-\n-    // V5 bump to include new possible error code (OFFSET_NOT_AVAILABLE)\n-    private static final Schema LIST_OFFSET_REQUEST_V5 = LIST_OFFSET_REQUEST_V4;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[] {LIST_OFFSET_REQUEST_V0, LIST_OFFSET_REQUEST_V1, LIST_OFFSET_REQUEST_V2,\n-            LIST_OFFSET_REQUEST_V3, LIST_OFFSET_REQUEST_V4, LIST_OFFSET_REQUEST_V5};\n-    }\n-\n-    private final int replicaId;\n-    private final IsolationLevel isolationLevel;\n-    private final Map<TopicPartition, PartitionData> partitionTimestamps;\n+    private final ListOffsetRequestData data;\n     private final Set<TopicPartition> duplicatePartitions;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDg4NjQ4OQ==", "bodyText": "There's a check on duplicatePartitions in KafkaApis. I'd rather keep the existing logic for now. We can see if we can strip this in a follow up PR", "url": "https://github.com/apache/kafka/pull/8295#discussion_r464886489", "createdAt": "2020-08-04T08:28:16Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "diffHunk": "@@ -47,96 +42,11 @@\n     public static final int CONSUMER_REPLICA_ID = -1;\n     public static final int DEBUGGING_REPLICA_ID = -2;\n \n-    // top level fields\n-    private static final Field.Int32 REPLICA_ID = new Field.Int32(\"replica_id\",\n-            \"Broker id of the follower. For normal consumers, use -1.\");\n-    private static final Field.Int8 ISOLATION_LEVEL = new Field.Int8(\"isolation_level\",\n-            \"This setting controls the visibility of transactional records. \" +\n-                    \"Using READ_UNCOMMITTED (isolation_level = 0) makes all records visible. With READ_COMMITTED \" +\n-                    \"(isolation_level = 1), non-transactional and COMMITTED transactional records are visible. \" +\n-                    \"To be more concrete, READ_COMMITTED returns all data from offsets smaller than the current \" +\n-                    \"LSO (last stable offset), and enables the inclusion of the list of aborted transactions in the \" +\n-                    \"result, which allows consumers to discard ABORTED transactional records\");\n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"Topics to list offsets.\");\n-\n-    // topic level fields\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"Partitions to list offsets.\");\n-\n-    // partition level fields\n-    private static final Field.Int64 TIMESTAMP = new Field.Int64(\"timestamp\",\n-            \"The target timestamp for the partition.\");\n-    private static final Field.Int32 MAX_NUM_OFFSETS = new Field.Int32(\"max_num_offsets\",\n-            \"Maximum offsets to return.\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            TIMESTAMP,\n-            MAX_NUM_OFFSETS);\n-\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-\n-    private static final Schema LIST_OFFSET_REQUEST_V0 = new Schema(\n-            REPLICA_ID,\n-            TOPICS_V0);\n-\n-    // V1 removes max_num_offsets\n-    private static final Field PARTITIONS_V1 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            TIMESTAMP);\n-\n-    private static final Field TOPICS_V1 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V1);\n-\n-    private static final Schema LIST_OFFSET_REQUEST_V1 = new Schema(\n-            REPLICA_ID,\n-            TOPICS_V1);\n-\n-    // V2 adds a field for the isolation level\n-    private static final Schema LIST_OFFSET_REQUEST_V2 = new Schema(\n-            REPLICA_ID,\n-            ISOLATION_LEVEL,\n-            TOPICS_V1);\n-\n-    // V3 bump used to indicate that on quota violation brokers send out responses before throttling.\n-    private static final Schema LIST_OFFSET_REQUEST_V3 = LIST_OFFSET_REQUEST_V2;\n-\n-    // V4 introduces the current leader epoch, which is used for fencing\n-    private static final Field PARTITIONS_V4 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            CURRENT_LEADER_EPOCH,\n-            TIMESTAMP);\n-\n-    private static final Field TOPICS_V4 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V4);\n-\n-    private static final Schema LIST_OFFSET_REQUEST_V4 = new Schema(\n-            REPLICA_ID,\n-            ISOLATION_LEVEL,\n-            TOPICS_V4);\n-\n-    // V5 bump to include new possible error code (OFFSET_NOT_AVAILABLE)\n-    private static final Schema LIST_OFFSET_REQUEST_V5 = LIST_OFFSET_REQUEST_V4;\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[] {LIST_OFFSET_REQUEST_V0, LIST_OFFSET_REQUEST_V1, LIST_OFFSET_REQUEST_V2,\n-            LIST_OFFSET_REQUEST_V3, LIST_OFFSET_REQUEST_V4, LIST_OFFSET_REQUEST_V5};\n-    }\n-\n-    private final int replicaId;\n-    private final IsolationLevel isolationLevel;\n-    private final Map<TopicPartition, PartitionData> partitionTimestamps;\n+    private final ListOffsetRequestData data;\n     private final Set<TopicPartition> duplicatePartitions;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4NTkwMg=="}, "originalCommit": null, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTE1OTE5OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0Mjo1NFrOG6NLVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0Mjo1NFrOG6NLVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4NjQ4NA==", "bodyText": "s/partitionresponse/partitionResponse", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463686484", "createdAt": "2020-07-31T15:42:54Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "diffHunk": "@@ -156,145 +66,98 @@ private Builder(short oldestAllowedVersion,\n                         int replicaId,\n                         IsolationLevel isolationLevel) {\n             super(ApiKeys.LIST_OFFSETS, oldestAllowedVersion, latestAllowedVersion);\n-            this.replicaId = replicaId;\n-            this.isolationLevel = isolationLevel;\n+            data = new ListOffsetRequestData()\n+                    .setIsolationLevel(isolationLevel.id())\n+                    .setReplicaId(replicaId);\n         }\n \n-        public Builder setTargetTimes(Map<TopicPartition, PartitionData> partitionTimestamps) {\n-            this.partitionTimestamps = partitionTimestamps;\n+        public Builder setTargetTimes(List<ListOffsetTopic> topics) {\n+            data.setTopics(topics);\n             return this;\n         }\n \n         @Override\n         public ListOffsetRequest build(short version) {\n-            return new ListOffsetRequest(replicaId, partitionTimestamps, isolationLevel, version);\n+            return new ListOffsetRequest(version, data);\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"(type=ListOffsetRequest\")\n-               .append(\", replicaId=\").append(replicaId);\n-            if (partitionTimestamps != null) {\n-                bld.append(\", partitionTimestamps=\").append(partitionTimestamps);\n-            }\n-            bld.append(\", isolationLevel=\").append(isolationLevel);\n-            bld.append(\")\");\n-            return bld.toString();\n-        }\n-    }\n-\n-    public static final class PartitionData {\n-        public final long timestamp;\n-        public final int maxNumOffsets; // only supported in v0\n-        public final Optional<Integer> currentLeaderEpoch;\n-\n-        private PartitionData(long timestamp, int maxNumOffsets, Optional<Integer> currentLeaderEpoch) {\n-            this.timestamp = timestamp;\n-            this.maxNumOffsets = maxNumOffsets;\n-            this.currentLeaderEpoch = currentLeaderEpoch;\n-        }\n-\n-        // For V0\n-        public PartitionData(long timestamp, int maxNumOffsets) {\n-            this(timestamp, maxNumOffsets, Optional.empty());\n-        }\n-\n-        public PartitionData(long timestamp, Optional<Integer> currentLeaderEpoch) {\n-            this(timestamp, 1, currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public boolean equals(Object obj) {\n-            if (!(obj instanceof PartitionData)) return false;\n-            PartitionData other = (PartitionData) obj;\n-            return this.timestamp == other.timestamp &&\n-                this.currentLeaderEpoch.equals(other.currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return Objects.hash(timestamp, currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"{timestamp: \").append(timestamp).\n-                    append(\", maxNumOffsets: \").append(maxNumOffsets).\n-                    append(\", currentLeaderEpoch: \").append(currentLeaderEpoch).\n-                    append(\"}\");\n-            return bld.toString();\n+            return data.toString();\n         }\n     }\n \n     /**\n      * Private constructor with a specified version.\n      */\n-    private ListOffsetRequest(int replicaId,\n-                              Map<TopicPartition, PartitionData> targetTimes,\n-                              IsolationLevel isolationLevel,\n-                              short version) {\n+    private ListOffsetRequest(short version, ListOffsetRequestData data) {\n         super(ApiKeys.LIST_OFFSETS, version);\n-        this.replicaId = replicaId;\n-        this.isolationLevel = isolationLevel;\n-        this.partitionTimestamps = targetTimes;\n+        this.data = data;\n         this.duplicatePartitions = Collections.emptySet();\n     }\n \n     public ListOffsetRequest(Struct struct, short version) {\n         super(ApiKeys.LIST_OFFSETS, version);\n-        Set<TopicPartition> duplicatePartitions = new HashSet<>();\n-        replicaId = struct.get(REPLICA_ID);\n-        isolationLevel = struct.hasField(ISOLATION_LEVEL) ?\n-                IsolationLevel.forId(struct.get(ISOLATION_LEVEL)) :\n-                IsolationLevel.READ_UNCOMMITTED;\n-        partitionTimestamps = new HashMap<>();\n-        for (Object topicResponseObj : struct.get(TOPICS)) {\n-            Struct topicResponse = (Struct) topicResponseObj;\n-            String topic = topicResponse.get(TOPIC_NAME);\n-            for (Object partitionResponseObj : topicResponse.get(PARTITIONS)) {\n-                Struct partitionResponse = (Struct) partitionResponseObj;\n-                int partition = partitionResponse.get(PARTITION_ID);\n-                long timestamp = partitionResponse.get(TIMESTAMP);\n-                TopicPartition tp = new TopicPartition(topic, partition);\n-\n-                int maxNumOffsets = partitionResponse.getOrElse(MAX_NUM_OFFSETS, 1);\n-                Optional<Integer> currentLeaderEpoch = RequestUtils.getLeaderEpoch(partitionResponse, CURRENT_LEADER_EPOCH);\n-                PartitionData partitionData = new PartitionData(timestamp, maxNumOffsets, currentLeaderEpoch);\n-                if (partitionTimestamps.put(tp, partitionData) != null)\n+        data = new ListOffsetRequestData(struct, version);\n+        duplicatePartitions = new HashSet<>();\n+        Set<TopicPartition> partitions = new HashSet<>();\n+        for (ListOffsetTopic topic : data.topics()) {\n+            for (ListOffsetPartition partition : topic.partitions()) {\n+                TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                if (!partitions.add(tp)) {\n                     duplicatePartitions.add(tp);\n+                }\n             }\n         }\n-        this.duplicatePartitions = duplicatePartitions;\n     }\n \n     @Override\n-    @SuppressWarnings(\"deprecation\")\n     public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n-        Map<TopicPartition, ListOffsetResponse.PartitionData> responseData = new HashMap<>();\n         short versionId = version();\n-\n-        ListOffsetResponse.PartitionData partitionError = versionId == 0 ?\n-                new ListOffsetResponse.PartitionData(Errors.forException(e), Collections.emptyList()) :\n-                new ListOffsetResponse.PartitionData(Errors.forException(e), -1L, -1L, Optional.empty());\n-        for (TopicPartition partition : partitionTimestamps.keySet()) {\n-            responseData.put(partition, partitionError);\n+        short errorCode = Errors.forException(e).code();\n+\n+        List<ListOffsetTopicResponse> responses = new ArrayList<>();\n+        for (ListOffsetTopic topic : data.topics()) {\n+            ListOffsetTopicResponse topicResponse = new ListOffsetTopicResponse().setName(topic.name());\n+            List<ListOffsetPartitionResponse> partitions = new ArrayList<>();\n+            for (ListOffsetPartition partition : topic.partitions()) {\n+                ListOffsetPartitionResponse partitionresponse = new ListOffsetPartitionResponse()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 292}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTE2ODg3OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0NTozMlrOG6NRHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0NTozMlrOG6NRHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4Nzk2NQ==", "bodyText": "s/reponseData/responseData", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463687965", "createdAt": "2020-07-31T15:45:32Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "diffHunk": "@@ -156,145 +66,98 @@ private Builder(short oldestAllowedVersion,\n                         int replicaId,\n                         IsolationLevel isolationLevel) {\n             super(ApiKeys.LIST_OFFSETS, oldestAllowedVersion, latestAllowedVersion);\n-            this.replicaId = replicaId;\n-            this.isolationLevel = isolationLevel;\n+            data = new ListOffsetRequestData()\n+                    .setIsolationLevel(isolationLevel.id())\n+                    .setReplicaId(replicaId);\n         }\n \n-        public Builder setTargetTimes(Map<TopicPartition, PartitionData> partitionTimestamps) {\n-            this.partitionTimestamps = partitionTimestamps;\n+        public Builder setTargetTimes(List<ListOffsetTopic> topics) {\n+            data.setTopics(topics);\n             return this;\n         }\n \n         @Override\n         public ListOffsetRequest build(short version) {\n-            return new ListOffsetRequest(replicaId, partitionTimestamps, isolationLevel, version);\n+            return new ListOffsetRequest(version, data);\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"(type=ListOffsetRequest\")\n-               .append(\", replicaId=\").append(replicaId);\n-            if (partitionTimestamps != null) {\n-                bld.append(\", partitionTimestamps=\").append(partitionTimestamps);\n-            }\n-            bld.append(\", isolationLevel=\").append(isolationLevel);\n-            bld.append(\")\");\n-            return bld.toString();\n-        }\n-    }\n-\n-    public static final class PartitionData {\n-        public final long timestamp;\n-        public final int maxNumOffsets; // only supported in v0\n-        public final Optional<Integer> currentLeaderEpoch;\n-\n-        private PartitionData(long timestamp, int maxNumOffsets, Optional<Integer> currentLeaderEpoch) {\n-            this.timestamp = timestamp;\n-            this.maxNumOffsets = maxNumOffsets;\n-            this.currentLeaderEpoch = currentLeaderEpoch;\n-        }\n-\n-        // For V0\n-        public PartitionData(long timestamp, int maxNumOffsets) {\n-            this(timestamp, maxNumOffsets, Optional.empty());\n-        }\n-\n-        public PartitionData(long timestamp, Optional<Integer> currentLeaderEpoch) {\n-            this(timestamp, 1, currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public boolean equals(Object obj) {\n-            if (!(obj instanceof PartitionData)) return false;\n-            PartitionData other = (PartitionData) obj;\n-            return this.timestamp == other.timestamp &&\n-                this.currentLeaderEpoch.equals(other.currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return Objects.hash(timestamp, currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"{timestamp: \").append(timestamp).\n-                    append(\", maxNumOffsets: \").append(maxNumOffsets).\n-                    append(\", currentLeaderEpoch: \").append(currentLeaderEpoch).\n-                    append(\"}\");\n-            return bld.toString();\n+            return data.toString();\n         }\n     }\n \n     /**\n      * Private constructor with a specified version.\n      */\n-    private ListOffsetRequest(int replicaId,\n-                              Map<TopicPartition, PartitionData> targetTimes,\n-                              IsolationLevel isolationLevel,\n-                              short version) {\n+    private ListOffsetRequest(short version, ListOffsetRequestData data) {\n         super(ApiKeys.LIST_OFFSETS, version);\n-        this.replicaId = replicaId;\n-        this.isolationLevel = isolationLevel;\n-        this.partitionTimestamps = targetTimes;\n+        this.data = data;\n         this.duplicatePartitions = Collections.emptySet();\n     }\n \n     public ListOffsetRequest(Struct struct, short version) {\n         super(ApiKeys.LIST_OFFSETS, version);\n-        Set<TopicPartition> duplicatePartitions = new HashSet<>();\n-        replicaId = struct.get(REPLICA_ID);\n-        isolationLevel = struct.hasField(ISOLATION_LEVEL) ?\n-                IsolationLevel.forId(struct.get(ISOLATION_LEVEL)) :\n-                IsolationLevel.READ_UNCOMMITTED;\n-        partitionTimestamps = new HashMap<>();\n-        for (Object topicResponseObj : struct.get(TOPICS)) {\n-            Struct topicResponse = (Struct) topicResponseObj;\n-            String topic = topicResponse.get(TOPIC_NAME);\n-            for (Object partitionResponseObj : topicResponse.get(PARTITIONS)) {\n-                Struct partitionResponse = (Struct) partitionResponseObj;\n-                int partition = partitionResponse.get(PARTITION_ID);\n-                long timestamp = partitionResponse.get(TIMESTAMP);\n-                TopicPartition tp = new TopicPartition(topic, partition);\n-\n-                int maxNumOffsets = partitionResponse.getOrElse(MAX_NUM_OFFSETS, 1);\n-                Optional<Integer> currentLeaderEpoch = RequestUtils.getLeaderEpoch(partitionResponse, CURRENT_LEADER_EPOCH);\n-                PartitionData partitionData = new PartitionData(timestamp, maxNumOffsets, currentLeaderEpoch);\n-                if (partitionTimestamps.put(tp, partitionData) != null)\n+        data = new ListOffsetRequestData(struct, version);\n+        duplicatePartitions = new HashSet<>();\n+        Set<TopicPartition> partitions = new HashSet<>();\n+        for (ListOffsetTopic topic : data.topics()) {\n+            for (ListOffsetPartition partition : topic.partitions()) {\n+                TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                if (!partitions.add(tp)) {\n                     duplicatePartitions.add(tp);\n+                }\n             }\n         }\n-        this.duplicatePartitions = duplicatePartitions;\n     }\n \n     @Override\n-    @SuppressWarnings(\"deprecation\")\n     public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n-        Map<TopicPartition, ListOffsetResponse.PartitionData> responseData = new HashMap<>();\n         short versionId = version();\n-\n-        ListOffsetResponse.PartitionData partitionError = versionId == 0 ?\n-                new ListOffsetResponse.PartitionData(Errors.forException(e), Collections.emptyList()) :\n-                new ListOffsetResponse.PartitionData(Errors.forException(e), -1L, -1L, Optional.empty());\n-        for (TopicPartition partition : partitionTimestamps.keySet()) {\n-            responseData.put(partition, partitionError);\n+        short errorCode = Errors.forException(e).code();\n+\n+        List<ListOffsetTopicResponse> responses = new ArrayList<>();\n+        for (ListOffsetTopic topic : data.topics()) {\n+            ListOffsetTopicResponse topicResponse = new ListOffsetTopicResponse().setName(topic.name());\n+            List<ListOffsetPartitionResponse> partitions = new ArrayList<>();\n+            for (ListOffsetPartition partition : topic.partitions()) {\n+                ListOffsetPartitionResponse partitionresponse = new ListOffsetPartitionResponse()\n+                        .setErrorCode(errorCode)\n+                        .setPartitionIndex(partition.partitionIndex());\n+                if (versionId == 0) {\n+                    partitionresponse.setOldStyleOffsets(Collections.emptyList());\n+                } else {\n+                    partitionresponse.setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+                                     .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP);\n+                    if (versionId >= 4) {\n+                        partitionresponse.setLeaderEpoch(ListOffsetResponse.UNKNOWN_EPOCH);\n+                    }\n+                }\n+                partitions.add(partitionresponse);\n+            }\n+            topicResponse.setPartitions(partitions);\n+            responses.add(topicResponse);\n         }\n+        ListOffsetResponseData reponseData = new ListOffsetResponseData()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 309}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTE3MTI1OnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0NjoxOVrOG6NSjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0NjoxOVrOG6NSjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4ODMzNQ==", "bodyText": "Is this necessary? The leader epoch is -1 by default.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463688335", "createdAt": "2020-07-31T15:46:19Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "diffHunk": "@@ -156,145 +66,98 @@ private Builder(short oldestAllowedVersion,\n                         int replicaId,\n                         IsolationLevel isolationLevel) {\n             super(ApiKeys.LIST_OFFSETS, oldestAllowedVersion, latestAllowedVersion);\n-            this.replicaId = replicaId;\n-            this.isolationLevel = isolationLevel;\n+            data = new ListOffsetRequestData()\n+                    .setIsolationLevel(isolationLevel.id())\n+                    .setReplicaId(replicaId);\n         }\n \n-        public Builder setTargetTimes(Map<TopicPartition, PartitionData> partitionTimestamps) {\n-            this.partitionTimestamps = partitionTimestamps;\n+        public Builder setTargetTimes(List<ListOffsetTopic> topics) {\n+            data.setTopics(topics);\n             return this;\n         }\n \n         @Override\n         public ListOffsetRequest build(short version) {\n-            return new ListOffsetRequest(replicaId, partitionTimestamps, isolationLevel, version);\n+            return new ListOffsetRequest(version, data);\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"(type=ListOffsetRequest\")\n-               .append(\", replicaId=\").append(replicaId);\n-            if (partitionTimestamps != null) {\n-                bld.append(\", partitionTimestamps=\").append(partitionTimestamps);\n-            }\n-            bld.append(\", isolationLevel=\").append(isolationLevel);\n-            bld.append(\")\");\n-            return bld.toString();\n-        }\n-    }\n-\n-    public static final class PartitionData {\n-        public final long timestamp;\n-        public final int maxNumOffsets; // only supported in v0\n-        public final Optional<Integer> currentLeaderEpoch;\n-\n-        private PartitionData(long timestamp, int maxNumOffsets, Optional<Integer> currentLeaderEpoch) {\n-            this.timestamp = timestamp;\n-            this.maxNumOffsets = maxNumOffsets;\n-            this.currentLeaderEpoch = currentLeaderEpoch;\n-        }\n-\n-        // For V0\n-        public PartitionData(long timestamp, int maxNumOffsets) {\n-            this(timestamp, maxNumOffsets, Optional.empty());\n-        }\n-\n-        public PartitionData(long timestamp, Optional<Integer> currentLeaderEpoch) {\n-            this(timestamp, 1, currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public boolean equals(Object obj) {\n-            if (!(obj instanceof PartitionData)) return false;\n-            PartitionData other = (PartitionData) obj;\n-            return this.timestamp == other.timestamp &&\n-                this.currentLeaderEpoch.equals(other.currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return Objects.hash(timestamp, currentLeaderEpoch);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"{timestamp: \").append(timestamp).\n-                    append(\", maxNumOffsets: \").append(maxNumOffsets).\n-                    append(\", currentLeaderEpoch: \").append(currentLeaderEpoch).\n-                    append(\"}\");\n-            return bld.toString();\n+            return data.toString();\n         }\n     }\n \n     /**\n      * Private constructor with a specified version.\n      */\n-    private ListOffsetRequest(int replicaId,\n-                              Map<TopicPartition, PartitionData> targetTimes,\n-                              IsolationLevel isolationLevel,\n-                              short version) {\n+    private ListOffsetRequest(short version, ListOffsetRequestData data) {\n         super(ApiKeys.LIST_OFFSETS, version);\n-        this.replicaId = replicaId;\n-        this.isolationLevel = isolationLevel;\n-        this.partitionTimestamps = targetTimes;\n+        this.data = data;\n         this.duplicatePartitions = Collections.emptySet();\n     }\n \n     public ListOffsetRequest(Struct struct, short version) {\n         super(ApiKeys.LIST_OFFSETS, version);\n-        Set<TopicPartition> duplicatePartitions = new HashSet<>();\n-        replicaId = struct.get(REPLICA_ID);\n-        isolationLevel = struct.hasField(ISOLATION_LEVEL) ?\n-                IsolationLevel.forId(struct.get(ISOLATION_LEVEL)) :\n-                IsolationLevel.READ_UNCOMMITTED;\n-        partitionTimestamps = new HashMap<>();\n-        for (Object topicResponseObj : struct.get(TOPICS)) {\n-            Struct topicResponse = (Struct) topicResponseObj;\n-            String topic = topicResponse.get(TOPIC_NAME);\n-            for (Object partitionResponseObj : topicResponse.get(PARTITIONS)) {\n-                Struct partitionResponse = (Struct) partitionResponseObj;\n-                int partition = partitionResponse.get(PARTITION_ID);\n-                long timestamp = partitionResponse.get(TIMESTAMP);\n-                TopicPartition tp = new TopicPartition(topic, partition);\n-\n-                int maxNumOffsets = partitionResponse.getOrElse(MAX_NUM_OFFSETS, 1);\n-                Optional<Integer> currentLeaderEpoch = RequestUtils.getLeaderEpoch(partitionResponse, CURRENT_LEADER_EPOCH);\n-                PartitionData partitionData = new PartitionData(timestamp, maxNumOffsets, currentLeaderEpoch);\n-                if (partitionTimestamps.put(tp, partitionData) != null)\n+        data = new ListOffsetRequestData(struct, version);\n+        duplicatePartitions = new HashSet<>();\n+        Set<TopicPartition> partitions = new HashSet<>();\n+        for (ListOffsetTopic topic : data.topics()) {\n+            for (ListOffsetPartition partition : topic.partitions()) {\n+                TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                if (!partitions.add(tp)) {\n                     duplicatePartitions.add(tp);\n+                }\n             }\n         }\n-        this.duplicatePartitions = duplicatePartitions;\n     }\n \n     @Override\n-    @SuppressWarnings(\"deprecation\")\n     public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n-        Map<TopicPartition, ListOffsetResponse.PartitionData> responseData = new HashMap<>();\n         short versionId = version();\n-\n-        ListOffsetResponse.PartitionData partitionError = versionId == 0 ?\n-                new ListOffsetResponse.PartitionData(Errors.forException(e), Collections.emptyList()) :\n-                new ListOffsetResponse.PartitionData(Errors.forException(e), -1L, -1L, Optional.empty());\n-        for (TopicPartition partition : partitionTimestamps.keySet()) {\n-            responseData.put(partition, partitionError);\n+        short errorCode = Errors.forException(e).code();\n+\n+        List<ListOffsetTopicResponse> responses = new ArrayList<>();\n+        for (ListOffsetTopic topic : data.topics()) {\n+            ListOffsetTopicResponse topicResponse = new ListOffsetTopicResponse().setName(topic.name());\n+            List<ListOffsetPartitionResponse> partitions = new ArrayList<>();\n+            for (ListOffsetPartition partition : topic.partitions()) {\n+                ListOffsetPartitionResponse partitionresponse = new ListOffsetPartitionResponse()\n+                        .setErrorCode(errorCode)\n+                        .setPartitionIndex(partition.partitionIndex());\n+                if (versionId == 0) {\n+                    partitionresponse.setOldStyleOffsets(Collections.emptyList());\n+                } else {\n+                    partitionresponse.setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+                                     .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP);\n+                    if (versionId >= 4) {\n+                        partitionresponse.setLeaderEpoch(ListOffsetResponse.UNKNOWN_EPOCH);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 301}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTE3NTI4OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/requests/ListOffsetRequestTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0NzoyN1rOG6NU-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0NzoyN1rOG6NU-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4ODk1Mw==", "bodyText": "Arrays.asList could be replaced with Collections.singletonList", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463688953", "createdAt": "2020-07-31T15:47:27Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/ListOffsetRequestTest.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.requests;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.ListOffsetRequestData;\n+import org.apache.kafka.common.message.ListOffsetRequestData.ListOffsetPartition;\n+import org.apache.kafka.common.message.ListOffsetRequestData.ListOffsetTopic;\n+import org.apache.kafka.common.message.ListOffsetResponseData;\n+import org.apache.kafka.common.message.ListOffsetResponseData.ListOffsetPartitionResponse;\n+import org.apache.kafka.common.message.ListOffsetResponseData.ListOffsetTopicResponse;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.junit.Test;\n+\n+public class ListOffsetRequestTest {\n+\n+    @Test\n+    public void testDuplicatePartitions() {\n+        List<ListOffsetTopic> topics = Arrays.asList(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTE4MDI1OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/requests/ListOffsetRequestTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0ODo1MFrOG6NXxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0ODo1MFrOG6NXxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY4OTY2OA==", "bodyText": "We could iterate through v1 to v5 here to test every case.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463689668", "createdAt": "2020-07-31T15:48:50Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/ListOffsetRequestTest.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.requests;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.ListOffsetRequestData;\n+import org.apache.kafka.common.message.ListOffsetRequestData.ListOffsetPartition;\n+import org.apache.kafka.common.message.ListOffsetRequestData.ListOffsetTopic;\n+import org.apache.kafka.common.message.ListOffsetResponseData;\n+import org.apache.kafka.common.message.ListOffsetResponseData.ListOffsetPartitionResponse;\n+import org.apache.kafka.common.message.ListOffsetResponseData.ListOffsetTopicResponse;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.junit.Test;\n+\n+public class ListOffsetRequestTest {\n+\n+    @Test\n+    public void testDuplicatePartitions() {\n+        List<ListOffsetTopic> topics = Arrays.asList(\n+                new ListOffsetTopic()\n+                    .setName(\"topic\")\n+                    .setPartitions(Arrays.asList(\n+                            new ListOffsetPartition()\n+                                .setPartitionIndex(0),\n+                            new ListOffsetPartition()\n+                                .setPartitionIndex(0))));\n+        ListOffsetRequestData data = new ListOffsetRequestData()\n+                .setTopics(topics)\n+                .setReplicaId(-1);\n+        ListOffsetRequest request = new ListOffsetRequest(data.toStruct((short) 0), (short) 0);\n+        assertEquals(Collections.singleton(new TopicPartition(\"topic\", 0)), request.duplicatePartitions());\n+    }\n+\n+    @Test\n+    public void testGetErrorResponse() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTE4MzEyOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/requests/ListOffsetRequestTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo0OTozNFrOG6NZXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzo0Mjo1MlrOG_Cfog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MDA3Ng==", "bodyText": "We should also add a test in MessageTest for the automated struct", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463690076", "createdAt": "2020-07-31T15:49:34Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/ListOffsetRequestTest.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.requests;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.ListOffsetRequestData;\n+import org.apache.kafka.common.message.ListOffsetRequestData.ListOffsetPartition;\n+import org.apache.kafka.common.message.ListOffsetRequestData.ListOffsetTopic;\n+import org.apache.kafka.common.message.ListOffsetResponseData;\n+import org.apache.kafka.common.message.ListOffsetResponseData.ListOffsetPartitionResponse;\n+import org.apache.kafka.common.message.ListOffsetResponseData.ListOffsetTopicResponse;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.junit.Test;\n+\n+public class ListOffsetRequestTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc1NDMzOA==", "bodyText": "Probably ok to skip.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468754338", "createdAt": "2020-08-11T17:42:52Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/ListOffsetRequestTest.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.requests;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.ListOffsetRequestData;\n+import org.apache.kafka.common.message.ListOffsetRequestData.ListOffsetPartition;\n+import org.apache.kafka.common.message.ListOffsetRequestData.ListOffsetTopic;\n+import org.apache.kafka.common.message.ListOffsetResponseData;\n+import org.apache.kafka.common.message.ListOffsetResponseData.ListOffsetPartitionResponse;\n+import org.apache.kafka.common.message.ListOffsetResponseData.ListOffsetTopicResponse;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.junit.Test;\n+\n+public class ListOffsetRequestTest {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MDA3Ng=="}, "originalCommit": null, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTE5ODkzOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo1NDowNVrOG6NjCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzo0NDo0MVrOG_CjgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MjU1NA==", "bodyText": "Seems that this data construction logic has been reused in elsewhere (FetcherTest), we could get a helper like\nListOffsetResponseData getSingletonResponseV0(TopicPartition, Errors, OldStyleOffsets);\nListOffsetResponseData getSingletonResponseV0(TopicPartition, Errors, Timestamp, Offset, leaderEpoch);\n\nin the ListOffsetResponse to reuse.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463692554", "createdAt": "2020-07-31T15:54:05Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1251,15 +1267,28 @@ private ListOffsetRequest createListOffsetRequest(int version) {\n \n     private ListOffsetResponse createListOffsetResponse(int version) {\n         if (version == 0) {\n-            Map<TopicPartition, ListOffsetResponse.PartitionData> responseData = new HashMap<>();\n-            responseData.put(new TopicPartition(\"test\", 0),\n-                    new ListOffsetResponse.PartitionData(Errors.NONE, asList(100L)));\n-            return new ListOffsetResponse(responseData);\n+            ListOffsetResponseData data = new ListOffsetResponseData()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE5MzcxOA==", "bodyText": "I'm not sure about adding extra methods to ListOffsetResponse just to remove a few lines in tests.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r467193718", "createdAt": "2020-08-07T18:09:02Z", "author": {"login": "mimaison"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1251,15 +1267,28 @@ private ListOffsetRequest createListOffsetRequest(int version) {\n \n     private ListOffsetResponse createListOffsetResponse(int version) {\n         if (version == 0) {\n-            Map<TopicPartition, ListOffsetResponse.PartitionData> responseData = new HashMap<>();\n-            responseData.put(new TopicPartition(\"test\", 0),\n-                    new ListOffsetResponse.PartitionData(Errors.NONE, asList(100L)));\n-            return new ListOffsetResponse(responseData);\n+            ListOffsetResponseData data = new ListOffsetResponseData()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MjU1NA=="}, "originalCommit": null, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc1NTMyOQ==", "bodyText": "As my previous comment suggests, for the sake of encapsulation and reusability.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468755329", "createdAt": "2020-08-11T17:44:41Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1251,15 +1267,28 @@ private ListOffsetRequest createListOffsetRequest(int version) {\n \n     private ListOffsetResponse createListOffsetResponse(int version) {\n         if (version == 0) {\n-            Map<TopicPartition, ListOffsetResponse.PartitionData> responseData = new HashMap<>();\n-            responseData.put(new TopicPartition(\"test\", 0),\n-                    new ListOffsetResponse.PartitionData(Errors.NONE, asList(100L)));\n-            return new ListOffsetResponse(responseData);\n+            ListOffsetResponseData data = new ListOffsetResponseData()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MjU1NA=="}, "originalCommit": null, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTIwMTg3OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo1NDo1NVrOG6Nkzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNDo0NzoyMVrOHAPBSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MzAwNg==", "bodyText": "Similar for topic request topic construction, let me know if you think we could refactor out a helper like singletonRequestData(...) in ListOffsetRequest", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463693006", "createdAt": "2020-07-31T15:54:55Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1221,28 +1226,39 @@ private DeleteGroupsResponse createDeleteGroupsResponse() {\n \n     private ListOffsetRequest createListOffsetRequest(int version) {\n         if (version == 0) {\n-            Map<TopicPartition, ListOffsetRequest.PartitionData> offsetData = Collections.singletonMap(\n-                    new TopicPartition(\"test\", 0),\n-                    new ListOffsetRequest.PartitionData(1000000L, 10));\n+            ListOffsetTopic topic = new ListOffsetTopic()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE5NDkyNQ==", "bodyText": "Not entirely sure. It's only used 3 times so we're not going to save very much.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r467194925", "createdAt": "2020-08-07T18:11:26Z", "author": {"login": "mimaison"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1221,28 +1226,39 @@ private DeleteGroupsResponse createDeleteGroupsResponse() {\n \n     private ListOffsetRequest createListOffsetRequest(int version) {\n         if (version == 0) {\n-            Map<TopicPartition, ListOffsetRequest.PartitionData> offsetData = Collections.singletonMap(\n-                    new TopicPartition(\"test\", 0),\n-                    new ListOffsetRequest.PartitionData(1000000L, 10));\n+            ListOffsetTopic topic = new ListOffsetTopic()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MzAwNg=="}, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc1NDgzMw==", "bodyText": "Well, the purpose is more about encapsulation to reduce the import paths in this test class.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468754833", "createdAt": "2020-08-11T17:43:53Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1221,28 +1226,39 @@ private DeleteGroupsResponse createDeleteGroupsResponse() {\n \n     private ListOffsetRequest createListOffsetRequest(int version) {\n         if (version == 0) {\n-            Map<TopicPartition, ListOffsetRequest.PartitionData> offsetData = Collections.singletonMap(\n-                    new TopicPartition(\"test\", 0),\n-                    new ListOffsetRequest.PartitionData(1000000L, 10));\n+            ListOffsetTopic topic = new ListOffsetTopic()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MzAwNg=="}, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAwODEzOQ==", "bodyText": "I had a look but all 3 cases set different fields on ListOffsetPartition. So it's not very useful here.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r470008139", "createdAt": "2020-08-13T14:47:21Z", "author": {"login": "mimaison"}, "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1221,28 +1226,39 @@ private DeleteGroupsResponse createDeleteGroupsResponse() {\n \n     private ListOffsetRequest createListOffsetRequest(int version) {\n         if (version == 0) {\n-            Map<TopicPartition, ListOffsetRequest.PartitionData> offsetData = Collections.singletonMap(\n-                    new TopicPartition(\"test\", 0),\n-                    new ListOffsetRequest.PartitionData(1000000L, 10));\n+            ListOffsetTopic topic = new ListOffsetTopic()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MzAwNg=="}, "originalCommit": null, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTIxODM5OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo1OTozNlrOG6Nu2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNTo1OTozNlrOG6Nu2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5NTU3Ng==", "bodyText": "Redundant braces.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463695576", "createdAt": "2020-07-31T15:59:36Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -910,136 +913,163 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderOrFollowerException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n \n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)\n+    )\n \n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n \n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderOrFollowerException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    def buildErrorResponse(e: Errors, partition: ListOffsetPartition): ListOffsetPartitionResponse = {\n+      new ListOffsetPartitionResponse()\n+        .setPartitionIndex(partition.partitionIndex)\n+        .setErrorCode(e.code)\n+        .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+        .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+    }\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          buildErrorResponse(Errors.TOPIC_AUTHORIZATION_FAILED, partition)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          buildErrorResponse(Errors.INVALID_REQUEST, partition)\n+        } else {\n+\n+          try {\n+            val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n+            val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n+            val isolationLevelOpt = if (isClientRequest)\n+              Some(offsetRequest.isolationLevel)\n+            else\n+              None\n+\n+            val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n+              partition.timestamp,\n+              isolationLevelOpt,\n+              if (partition.currentLeaderEpoch == ListOffsetResponse.UNKNOWN_EPOCH) Optional.empty() else Optional.of(partition.currentLeaderEpoch),\n+              fetchOnlyFromLeader)\n+\n+            val response = foundOpt match {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 232}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NTIzMjc3OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNjowNDoxMFrOG6N3gw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNjowNDoxMFrOG6N3gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5Nzc5NQ==", "bodyText": "nit: remove unnecessary empty line", "url": "https://github.com/apache/kafka/pull/8295#discussion_r463697795", "createdAt": "2020-07-31T16:04:10Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1831,4 +1831,5 @@ class ReplicaManager(val config: KafkaConfig,\n \n     controller.electLeaders(partitions, electionType, electionCallback)\n   }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODUxNTkyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoxODozMVrOG-_Yig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QwOTozODo0MVrOHAD9Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwMzM3MA==", "bodyText": "Why do we convert the fatal scenario towards a warning?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468703370", "createdAt": "2020-08-11T16:18:31Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3973,25 +3977,38 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n                     Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n-                    for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n-                        TopicPartition tp = result.getKey();\n-                        PartitionData partitionData = result.getValue();\n-\n-                        KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n-                        Errors error = partitionData.error;\n-                        OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n-                        if (offsetRequestSpec == null) {\n-                            future.completeExceptionally(new KafkaException(\"Unexpected topic partition \" + tp + \" in broker response!\"));\n-                        } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n-                            retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n-                        } else if (error == Errors.NONE) {\n-                            future.complete(new ListOffsetsResultInfo(partitionData.offset, partitionData.timestamp, partitionData.leaderEpoch));\n-                        } else {\n-                            future.completeExceptionally(error.exception());\n+                    for (ListOffsetTopicResponse topic : response.topics()) {\n+                        for (ListOffsetPartitionResponse partition : topic.partitions()) {\n+                            TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                            KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n+                            Errors error = Errors.forCode(partition.errorCode());\n+                            OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n+                            if (offsetRequestSpec == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgyNjg2Ng==", "bodyText": "If offsetRequestSpec is null, future will be null too, so previous code will NPE.\nSee the discussion in #8295 (comment), we decided to log a warning like createTopics() does", "url": "https://github.com/apache/kafka/pull/8295#discussion_r469826866", "createdAt": "2020-08-13T09:38:41Z", "author": {"login": "mimaison"}, "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3973,25 +3977,38 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n                     Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n-                    for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n-                        TopicPartition tp = result.getKey();\n-                        PartitionData partitionData = result.getValue();\n-\n-                        KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n-                        Errors error = partitionData.error;\n-                        OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n-                        if (offsetRequestSpec == null) {\n-                            future.completeExceptionally(new KafkaException(\"Unexpected topic partition \" + tp + \" in broker response!\"));\n-                        } else if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n-                            retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n-                        } else if (error == Errors.NONE) {\n-                            future.complete(new ListOffsetsResultInfo(partitionData.offset, partitionData.timestamp, partitionData.leaderEpoch));\n-                        } else {\n-                            future.completeExceptionally(error.exception());\n+                    for (ListOffsetTopicResponse topic : response.topics()) {\n+                        for (ListOffsetPartitionResponse partition : topic.partitions()) {\n+                            TopicPartition tp = new TopicPartition(topic.name(), partition.partitionIndex());\n+                            KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n+                            Errors error = Errors.forCode(partition.errorCode());\n+                            OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n+                            if (offsetRequestSpec == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwMzM3MA=="}, "originalCommit": null, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODY5ODEyOnYy", "diffSide": "RIGHT", "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzowNToyM1rOG_BKlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzowNToyM1rOG_BKlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODczMjU2NA==", "bodyText": "Could we add a unit test for this function?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468732564", "createdAt": "2020-08-11T17:05:23Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java", "diffHunk": "@@ -307,32 +169,16 @@ public static ListOffsetRequest parse(ByteBuffer buffer, short version) {\n \n     @Override\n     protected Struct toStruct() {\n-        short version = version();\n-        Struct struct = new Struct(ApiKeys.LIST_OFFSETS.requestSchema(version));\n-        Map<String, Map<Integer, PartitionData>> topicsData = CollectionUtils.groupPartitionDataByTopic(partitionTimestamps);\n-\n-        struct.set(REPLICA_ID, replicaId);\n-        struct.setIfExists(ISOLATION_LEVEL, isolationLevel.id());\n+        return data.toStruct(version());\n+    }\n \n-        List<Struct> topicArray = new ArrayList<>();\n-        for (Map.Entry<String, Map<Integer, PartitionData>> topicEntry: topicsData.entrySet()) {\n-            Struct topicData = struct.instance(TOPICS);\n-            topicData.set(TOPIC_NAME, topicEntry.getKey());\n-            List<Struct> partitionArray = new ArrayList<>();\n-            for (Map.Entry<Integer, PartitionData> partitionEntry : topicEntry.getValue().entrySet()) {\n-                PartitionData offsetPartitionData = partitionEntry.getValue();\n-                Struct partitionData = topicData.instance(PARTITIONS);\n-                partitionData.set(PARTITION_ID, partitionEntry.getKey());\n-                partitionData.set(TIMESTAMP, offsetPartitionData.timestamp);\n-                partitionData.setIfExists(MAX_NUM_OFFSETS, offsetPartitionData.maxNumOffsets);\n-                RequestUtils.setLeaderEpochIfExists(partitionData, CURRENT_LEADER_EPOCH,\n-                        offsetPartitionData.currentLeaderEpoch);\n-                partitionArray.add(partitionData);\n-            }\n-            topicData.set(PARTITIONS, partitionArray.toArray());\n-            topicArray.add(topicData);\n+    public static List<ListOffsetTopic> toListOffsetTopics(Map<TopicPartition, ListOffsetPartition> timestampsToSearch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 364}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODcwNjA3OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzowNzo1MFrOG_BP3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxOToyOTowN1rOHTyIwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODczMzkxNg==", "bodyText": "I think we could reduce the change of this PR by reverting the numbering change which seems unnecessary.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468733916", "createdAt": "2020-08-11T17:07:50Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -3732,41 +3734,43 @@ public void testListOffsets() throws Exception {\n                 Collections.<String>emptySet(),\n                 node0);\n \n-        final TopicPartition tp1 = new TopicPartition(\"foo\", 0);\n-        final TopicPartition tp2 = new TopicPartition(\"bar\", 0);\n-        final TopicPartition tp3 = new TopicPartition(\"baz\", 0);\n+        final TopicPartition tp0 = new TopicPartition(\"foo\", 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgzNTE4Mg==", "bodyText": "I think it's a good cleanup, I changed the numbering because it confused me.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r469835182", "createdAt": "2020-08-13T09:53:04Z", "author": {"login": "mimaison"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -3732,41 +3734,43 @@ public void testListOffsets() throws Exception {\n                 Collections.<String>emptySet(),\n                 node0);\n \n-        final TopicPartition tp1 = new TopicPartition(\"foo\", 0);\n-        final TopicPartition tp2 = new TopicPartition(\"bar\", 0);\n-        final TopicPartition tp3 = new TopicPartition(\"baz\", 0);\n+        final TopicPartition tp0 = new TopicPartition(\"foo\", 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODczMzkxNg=="}, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDUwNjQzNA==", "bodyText": "I will leave it up to you, as long as you ensure the tests itself are mutated correctly, it's not easy to eyeball such a change for no-op.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r490506434", "createdAt": "2020-09-17T19:29:07Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -3732,41 +3734,43 @@ public void testListOffsets() throws Exception {\n                 Collections.<String>emptySet(),\n                 node0);\n \n-        final TopicPartition tp1 = new TopicPartition(\"foo\", 0);\n-        final TopicPartition tp2 = new TopicPartition(\"bar\", 0);\n-        final TopicPartition tp3 = new TopicPartition(\"baz\", 0);\n+        final TopicPartition tp0 = new TopicPartition(\"foo\", 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODczMzkxNg=="}, "originalCommit": null, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODcxNTcyOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzoxMDozM1rOG_BWKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzoxMDozM1rOG_BWKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODczNTUyOA==", "bodyText": "This could move to ListOffsetResponse as a helper, and maybe name as singletonListOffsetTopicResponse", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468735528", "createdAt": "2020-08-11T17:10:33Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -4068,6 +4093,58 @@ public void testListOffsetsMetadataNonRetriableErrors() throws Exception {\n         }\n     }\n \n+    @Test\n+    public void testListOffsetsPartialResponse() throws Exception {\n+        Node node0 = new Node(0, \"localhost\", 8120);\n+        Node node1 = new Node(1, \"localhost\", 8121);\n+        List<Node> nodes = Arrays.asList(node0, node1);\n+        List<PartitionInfo> pInfos = new ArrayList<>();\n+        pInfos.add(new PartitionInfo(\"foo\", 0, node0, new Node[]{node0, node1}, new Node[]{node0, node1}));\n+        pInfos.add(new PartitionInfo(\"foo\", 1, node0, new Node[]{node0, node1}, new Node[]{node0, node1}));\n+        final Cluster cluster =\n+            new Cluster(\n+                \"mockClusterId\",\n+                nodes,\n+                pInfos,\n+                Collections.<String>emptySet(),\n+                Collections.<String>emptySet(),\n+                node0);\n+\n+        final TopicPartition tp0 = new TopicPartition(\"foo\", 0);\n+        final TopicPartition tp1 = new TopicPartition(\"foo\", 1);\n+\n+        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(cluster)) {\n+            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n+\n+            env.kafkaClient().prepareResponse(prepareMetadataResponse(cluster, Errors.NONE));\n+\n+            ListOffsetTopicResponse t0 = prepareListOffsetTopicResponse(tp0, Errors.NONE, -2L, 123L, 456);\n+            ListOffsetResponseData data = new ListOffsetResponseData()\n+                    .setThrottleTimeMs(0)\n+                    .setTopics(Arrays.asList(t0));\n+            env.kafkaClient().prepareResponseFrom(new ListOffsetResponse(data), node0);\n+\n+            Map<TopicPartition, OffsetSpec> partitions = new HashMap<>();\n+            partitions.put(tp0, OffsetSpec.latest());\n+            partitions.put(tp1, OffsetSpec.latest());\n+            ListOffsetsResult result = env.adminClient().listOffsets(partitions);\n+            assertNotNull(result.partitionResult(tp0).get());\n+            TestUtils.assertFutureThrows(result.partitionResult(tp1), ApiException.class);\n+            TestUtils.assertFutureThrows(result.all(), ApiException.class);\n+        }\n+    }\n+\n+    private static ListOffsetTopicResponse prepareListOffsetTopicResponse(TopicPartition tp, Errors error, long timestamp, long offset, int epoch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 313}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODc0MDk3OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzoxNzoyOFrOG_BmKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMDowMzo1OVrOHAE18A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODczOTYyNw==", "bodyText": "This looks weird, as we are only filtering tp0 partitions, why we could check tp0 and tp1 later?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468739627", "createdAt": "2020-08-11T17:17:28Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -584,14 +590,22 @@ public void testFetchProgressWithMissingPartitionPosition() {\n         consumer.seekToEnd(singleton(tp0));\n         consumer.seekToBeginning(singleton(tp1));\n \n-        client.prepareResponse(\n-            body -> {\n-                ListOffsetRequest request = (ListOffsetRequest) body;\n-                Map<TopicPartition, ListOffsetRequest.PartitionData> timestamps = request.partitionTimestamps();\n-                return timestamps.get(tp0).timestamp == ListOffsetRequest.LATEST_TIMESTAMP &&\n-                        timestamps.get(tp1).timestamp == ListOffsetRequest.EARLIEST_TIMESTAMP;\n-            }, listOffsetsResponse(Collections.singletonMap(tp0, 50L),\n-                        Collections.singletonMap(tp1, Errors.NOT_LEADER_OR_FOLLOWER)));\n+        client.prepareResponse(body -> {\n+            ListOffsetRequest request = (ListOffsetRequest) body;\n+            List<ListOffsetPartition> partitions = request.topics().stream().flatMap(topic -> {\n+                if (topic.name().equals(tp0.topic()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg0MTM5Mg==", "bodyText": "It's because tp0 and tp1 are on the same topic. I'm updating this check to use topic instead so it's clearer", "url": "https://github.com/apache/kafka/pull/8295#discussion_r469841392", "createdAt": "2020-08-13T10:03:59Z", "author": {"login": "mimaison"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -584,14 +590,22 @@ public void testFetchProgressWithMissingPartitionPosition() {\n         consumer.seekToEnd(singleton(tp0));\n         consumer.seekToBeginning(singleton(tp1));\n \n-        client.prepareResponse(\n-            body -> {\n-                ListOffsetRequest request = (ListOffsetRequest) body;\n-                Map<TopicPartition, ListOffsetRequest.PartitionData> timestamps = request.partitionTimestamps();\n-                return timestamps.get(tp0).timestamp == ListOffsetRequest.LATEST_TIMESTAMP &&\n-                        timestamps.get(tp1).timestamp == ListOffsetRequest.EARLIEST_TIMESTAMP;\n-            }, listOffsetsResponse(Collections.singletonMap(tp0, 50L),\n-                        Collections.singletonMap(tp1, Errors.NOT_LEADER_OR_FOLLOWER)));\n+        client.prepareResponse(body -> {\n+            ListOffsetRequest request = (ListOffsetRequest) body;\n+            List<ListOffsetPartition> partitions = request.topics().stream().flatMap(topic -> {\n+                if (topic.name().equals(tp0.topic()))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODczOTYyNw=="}, "originalCommit": null, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODc0NzY0OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzoxOToyMlrOG_BqeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzoxOToyMlrOG_BqeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc0MDcyOA==", "bodyText": "new ArrayList<> is suffice", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468740728", "createdAt": "2020-08-11T17:19:22Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -2149,20 +2163,29 @@ private ListOffsetResponse listOffsetsResponse(Map<TopicPartition, Long> offsets\n \n     private ListOffsetResponse listOffsetsResponse(Map<TopicPartition, Long> partitionOffsets,\n                                                    Map<TopicPartition, Errors> partitionErrors) {\n-        Map<TopicPartition, ListOffsetResponse.PartitionData> partitionData = new HashMap<>();\n+        Map<String, ListOffsetTopicResponse> responses = new HashMap<>();\n         for (Map.Entry<TopicPartition, Long> partitionOffset : partitionOffsets.entrySet()) {\n-            partitionData.put(partitionOffset.getKey(), new ListOffsetResponse.PartitionData(Errors.NONE,\n-                    ListOffsetResponse.UNKNOWN_TIMESTAMP, partitionOffset.getValue(),\n-                    Optional.empty()));\n+            TopicPartition tp = partitionOffset.getKey();\n+            ListOffsetTopicResponse topic = responses.computeIfAbsent(tp.topic(), k -> new ListOffsetTopicResponse().setName(tp.topic()));\n+            topic.partitions().add(new ListOffsetPartitionResponse()\n+                    .setPartitionIndex(tp.partition())\n+                    .setErrorCode(Errors.NONE.code())\n+                    .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+                    .setOffset(partitionOffset.getValue()));\n         }\n \n         for (Map.Entry<TopicPartition, Errors> partitionError : partitionErrors.entrySet()) {\n-            partitionData.put(partitionError.getKey(), new ListOffsetResponse.PartitionData(\n-                    partitionError.getValue(), ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                    ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty()));\n+            TopicPartition tp = partitionError.getKey();\n+            ListOffsetTopicResponse topic = responses.computeIfAbsent(tp.topic(), k -> new ListOffsetTopicResponse().setName(tp.topic()));\n+            topic.partitions().add(new ListOffsetPartitionResponse()\n+                    .setPartitionIndex(tp.partition())\n+                    .setErrorCode(partitionError.getValue().code())\n+                    .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+                    .setOffset(ListOffsetResponse.UNKNOWN_OFFSET));\n         }\n-\n-        return new ListOffsetResponse(partitionData);\n+        ListOffsetResponseData data = new ListOffsetResponseData()\n+                .setTopics(new ArrayList<ListOffsetTopicResponse>(responses.values()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODc4OTE0OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzozMDozMVrOG_CETw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzozMDozMVrOG_CETw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc0NzM0Mw==", "bodyText": "both partitions", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468747343", "createdAt": "2020-08-11T17:30:31Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3546,12 +3594,54 @@ private void testGetOffsetsForTimesWithUnknownOffset() {\n         MetadataResponse initialMetadataUpdate = TestUtils.metadataUpdateWith(1, singletonMap(topicName, 1));\n         client.updateMetadata(initialMetadataUpdate);\n \n-        Map<TopicPartition, ListOffsetResponse.PartitionData> partitionData = new HashMap<>();\n-        partitionData.put(tp0, new ListOffsetResponse.PartitionData(Errors.NONE,\n-                ListOffsetResponse.UNKNOWN_TIMESTAMP, ListOffsetResponse.UNKNOWN_OFFSET,\n-                Optional.empty()));\n+        ListOffsetResponseData data = new ListOffsetResponseData()\n+                .setThrottleTimeMs(0)\n+                .setTopics(Collections.singletonList(new ListOffsetTopicResponse()\n+                        .setName(tp0.topic())\n+                        .setPartitions(Collections.singletonList(new ListOffsetPartitionResponse()\n+                                .setPartitionIndex(tp0.partition())\n+                                .setErrorCode(Errors.NONE.code())\n+                                .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+                                .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)))));\n+\n+        client.prepareResponseFrom(new ListOffsetResponse(data),\n+                metadata.fetch().leaderFor(tp0));\n+\n+        Map<TopicPartition, Long> timestampToSearch = new HashMap<>();\n+        timestampToSearch.put(tp0, 0L);\n+        Map<TopicPartition, OffsetAndTimestamp> offsetAndTimestampMap =\n+                fetcher.offsetsForTimes(timestampToSearch, time.timer(Long.MAX_VALUE));\n \n-        client.prepareResponseFrom(new ListOffsetResponse(0, partitionData),\n+        assertTrue(offsetAndTimestampMap.containsKey(tp0));\n+        assertNull(offsetAndTimestampMap.get(tp0));\n+    }\n+\n+    @Test\n+    public void testGetOffsetsForTimesWithUnknownOffsetV0() {\n+        buildFetcher();\n+        // Empty map\n+        assertTrue(fetcher.offsetsForTimes(new HashMap<>(), time.timer(100L)).isEmpty());\n+        // Unknown Offset\n+        client.reset();\n+        // Ensure metadata has both partition.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 268}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODgwODMwOnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNzozNjowOVrOG_CQSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMzo0ODowMlrOHAMWEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc1MDQwOA==", "bodyText": "Is this expected before the change in this PR?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468750408", "createdAt": "2020-08-11T17:36:09Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3546,12 +3594,54 @@ private void testGetOffsetsForTimesWithUnknownOffset() {\n         MetadataResponse initialMetadataUpdate = TestUtils.metadataUpdateWith(1, singletonMap(topicName, 1));\n         client.updateMetadata(initialMetadataUpdate);\n \n-        Map<TopicPartition, ListOffsetResponse.PartitionData> partitionData = new HashMap<>();\n-        partitionData.put(tp0, new ListOffsetResponse.PartitionData(Errors.NONE,\n-                ListOffsetResponse.UNKNOWN_TIMESTAMP, ListOffsetResponse.UNKNOWN_OFFSET,\n-                Optional.empty()));\n+        ListOffsetResponseData data = new ListOffsetResponseData()\n+                .setThrottleTimeMs(0)\n+                .setTopics(Collections.singletonList(new ListOffsetTopicResponse()\n+                        .setName(tp0.topic())\n+                        .setPartitions(Collections.singletonList(new ListOffsetPartitionResponse()\n+                                .setPartitionIndex(tp0.partition())\n+                                .setErrorCode(Errors.NONE.code())\n+                                .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+                                .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)))));\n+\n+        client.prepareResponseFrom(new ListOffsetResponse(data),\n+                metadata.fetch().leaderFor(tp0));\n+\n+        Map<TopicPartition, Long> timestampToSearch = new HashMap<>();\n+        timestampToSearch.put(tp0, 0L);\n+        Map<TopicPartition, OffsetAndTimestamp> offsetAndTimestampMap =\n+                fetcher.offsetsForTimes(timestampToSearch, time.timer(Long.MAX_VALUE));\n \n-        client.prepareResponseFrom(new ListOffsetResponse(0, partitionData),\n+        assertTrue(offsetAndTimestampMap.containsKey(tp0));\n+        assertNull(offsetAndTimestampMap.get(tp0));\n+    }\n+\n+    @Test\n+    public void testGetOffsetsForTimesWithUnknownOffsetV0() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 262}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk2NDMwNg==", "bodyText": "I think so. I used the following test on trunk and it passes:\n    @Test\n    public void testGetOffsetsForTimesWithUnknownOffsetV0() {\n        buildFetcher();\n        client.reset();\n        // Ensure metadata has both partition.\n        MetadataResponse initialMetadataUpdate = TestUtils.metadataUpdateWith(1, singletonMap(topicName, 1));\n        client.updateMetadata(initialMetadataUpdate);\n\n        Map<TopicPartition, ListOffsetResponse.PartitionData> partitionData = new HashMap<>();\n        partitionData.put(tp0, new ListOffsetResponse.PartitionData(Errors.NONE,\n                Collections.emptyList()));\n\n        client.prepareResponseFrom(new ListOffsetResponse(0, partitionData),\n                metadata.fetch().leaderFor(tp0));\n\n        Map<TopicPartition, Long> timestampToSearch = new HashMap<>();\n        timestampToSearch.put(tp0, 0L);\n        Map<TopicPartition, OffsetAndTimestamp> offsetAndTimestampMap =\n                fetcher.offsetsForTimes(timestampToSearch, time.timer(Long.MAX_VALUE));\n\n        assertTrue(offsetAndTimestampMap.containsKey(tp0));\n        assertNull(offsetAndTimestampMap.get(tp0));\n    }", "url": "https://github.com/apache/kafka/pull/8295#discussion_r469964306", "createdAt": "2020-08-13T13:48:02Z", "author": {"login": "mimaison"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3546,12 +3594,54 @@ private void testGetOffsetsForTimesWithUnknownOffset() {\n         MetadataResponse initialMetadataUpdate = TestUtils.metadataUpdateWith(1, singletonMap(topicName, 1));\n         client.updateMetadata(initialMetadataUpdate);\n \n-        Map<TopicPartition, ListOffsetResponse.PartitionData> partitionData = new HashMap<>();\n-        partitionData.put(tp0, new ListOffsetResponse.PartitionData(Errors.NONE,\n-                ListOffsetResponse.UNKNOWN_TIMESTAMP, ListOffsetResponse.UNKNOWN_OFFSET,\n-                Optional.empty()));\n+        ListOffsetResponseData data = new ListOffsetResponseData()\n+                .setThrottleTimeMs(0)\n+                .setTopics(Collections.singletonList(new ListOffsetTopicResponse()\n+                        .setName(tp0.topic())\n+                        .setPartitions(Collections.singletonList(new ListOffsetPartitionResponse()\n+                                .setPartitionIndex(tp0.partition())\n+                                .setErrorCode(Errors.NONE.code())\n+                                .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+                                .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)))));\n+\n+        client.prepareResponseFrom(new ListOffsetResponse(data),\n+                metadata.fetch().leaderFor(tp0));\n+\n+        Map<TopicPartition, Long> timestampToSearch = new HashMap<>();\n+        timestampToSearch.put(tp0, 0L);\n+        Map<TopicPartition, OffsetAndTimestamp> offsetAndTimestampMap =\n+                fetcher.offsetsForTimes(timestampToSearch, time.timer(Long.MAX_VALUE));\n \n-        client.prepareResponseFrom(new ListOffsetResponse(0, partitionData),\n+        assertTrue(offsetAndTimestampMap.containsKey(tp0));\n+        assertNull(offsetAndTimestampMap.get(tp0));\n+    }\n+\n+    @Test\n+    public void testGetOffsetsForTimesWithUnknownOffsetV0() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc1MDQwOA=="}, "originalCommit": null, "originalPosition": 262}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODkyNzM1OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxODowOToxM1rOG_Da3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxODowOToxM1rOG_Da3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc2OTUwMA==", "bodyText": "nit: line seems not necessary.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468769500", "createdAt": "2020-08-11T18:09:13Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -910,136 +913,162 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderOrFollowerException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n \n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)\n+    )\n \n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n \n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cased since these error messages\n+          // are typically transient and there is no value in logging the entire stack trace for the same\n           case e @ (_ : UnknownTopicOrPartitionException |\n                     _ : NotLeaderOrFollowerException |\n-                    _ : UnknownLeaderEpochException |\n-                    _ : FencedLeaderEpochException |\n-                    _ : KafkaStorageException |\n-                    _ : UnsupportedForMessageFormatException) =>\n-            debug(s\"Offset request with correlation id $correlationId from client $clientId on \" +\n-                s\"partition $topicPartition failed due to ${e.getMessage}\")\n-            buildErrorResponse(Errors.forException(e))\n-\n-          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE\n-          case e: OffsetNotAvailableException =>\n-            if(request.header.apiVersion >= 5) {\n-              buildErrorResponse(Errors.forException(e))\n-            } else {\n-              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)\n-            }\n-\n+                    _ : KafkaStorageException) =>\n+            debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n+              correlationId, clientId, topicPartition, e.getMessage))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n           case e: Throwable =>\n             error(\"Error while responding to offset request\", e)\n-            buildErrorResponse(Errors.forException(e))\n+            new ListOffsetPartitionResponse()\n+              .setPartitionIndex(partition.partitionIndex)\n+              .setErrorCode(Errors.forException(e).code)\n+        }\n+      }\n+      new ListOffsetTopicResponse().setName(topic.name).setPartitions(responsePartitions.asJava)\n+    }\n+    (responseTopics ++ unauthorizedResponseStatus).toList\n+  }\n+\n+  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): List[ListOffsetTopicResponse] = {\n+    val correlationId = request.header.correlationId\n+    val clientId = request.header.clientId\n+    val offsetRequest = request.body[ListOffsetRequest]\n+\n+    def buildErrorResponse(e: Errors, partition: ListOffsetPartition): ListOffsetPartitionResponse = {\n+      new ListOffsetPartitionResponse()\n+        .setPartitionIndex(partition.partitionIndex)\n+        .setErrorCode(e.code)\n+        .setTimestamp(ListOffsetResponse.UNKNOWN_TIMESTAMP)\n+        .setOffset(ListOffsetResponse.UNKNOWN_OFFSET)\n+    }\n+\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n+\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          buildErrorResponse(Errors.TOPIC_AUTHORIZATION_FAILED, partition)).asJava)\n+    )\n+\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n+        if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n+          debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n+              s\"failed because the partition is duplicated in the request.\")\n+          buildErrorResponse(Errors.INVALID_REQUEST, partition)\n+        } else {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 217}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODkzMTQ3OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxODoxMDoyMlrOG_DdZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxODoxMDoyMlrOG_DdZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3MDE0OA==", "bodyText": "special cases?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r468770148", "createdAt": "2020-08-11T18:10:22Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -910,136 +913,162 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderOrFollowerException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n \n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)\n+    )\n \n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n \n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cased since these error messages", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2OTA5NTg4OnYy", "diffSide": "RIGHT", "path": "clients/src/main/resources/common/message/ListOffsetResponse.json", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxOToyNzozNlrOHTyCtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzowMjoxNVrOHUMLzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDUwNDg4NA==", "bodyText": "Why do we need this default?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r490504884", "createdAt": "2020-09-17T19:27:36Z", "author": {"login": "abbccdda"}, "path": "clients/src/main/resources/common/message/ListOffsetResponse.json", "diffHunk": "@@ -48,7 +48,7 @@\n           \"about\": \"The timestamp associated with the returned offset.\" },\n         { \"name\": \"Offset\", \"type\": \"int64\", \"versions\": \"1+\", \"default\": \"-1\", \"ignorable\": false,\n           \"about\": \"The returned offset.\" },\n-        { \"name\": \"LeaderEpoch\", \"type\": \"int32\", \"versions\": \"4+\" }\n+        { \"name\": \"LeaderEpoch\", \"type\": \"int32\", \"versions\": \"4+\", \"default\": \"-1\" }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkzMzE5Nw==", "bodyText": "Until now, this field is an Optional and it's defaulted to -1 in https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/requests/RequestUtils.java#L30-L32\nOtherwise an int32 default value is 0 with the generator code", "url": "https://github.com/apache/kafka/pull/8295#discussion_r490933197", "createdAt": "2020-09-18T13:02:15Z", "author": {"login": "mimaison"}, "path": "clients/src/main/resources/common/message/ListOffsetResponse.json", "diffHunk": "@@ -48,7 +48,7 @@\n           \"about\": \"The timestamp associated with the returned offset.\" },\n         { \"name\": \"Offset\", \"type\": \"int64\", \"versions\": \"1+\", \"default\": \"-1\", \"ignorable\": false,\n           \"about\": \"The returned offset.\" },\n-        { \"name\": \"LeaderEpoch\", \"type\": \"int32\", \"versions\": \"4+\" }\n+        { \"name\": \"LeaderEpoch\", \"type\": \"int32\", \"versions\": \"4+\", \"default\": \"-1\" }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDUwNDg4NA=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2OTExMjE2OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxOTozMDoyMVrOHTyNmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzoyNjozMFrOHUNE3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDUwNzY3NA==", "bodyText": "Not sure why we need 8 indent here?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r490507674", "createdAt": "2020-09-17T19:30:21Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -2496,46 +2501,81 @@ public void testGetOffsetByTimeWithPartitionsRetryCouldTriggerMetadataUpdate() {\n             client.updateMetadata(initialUpdateResponse);\n \n             final long fetchTimestamp = 10L;\n-            Map<TopicPartition, ListOffsetResponse.PartitionData> allPartitionData = new HashMap<>();\n-            allPartitionData.put(tp0, new ListOffsetResponse.PartitionData(\n-                Errors.NONE, fetchTimestamp, 4L, Optional.empty()));\n-            allPartitionData.put(tp1, new ListOffsetResponse.PartitionData(\n-                retriableError, ListOffsetRequest.LATEST_TIMESTAMP, -1L, Optional.empty()));\n+            List<ListOffsetTopicResponse> topics = Collections.singletonList(\n+                    new ListOffsetTopicResponse()\n+                        .setName(tp0.topic())\n+                        .setPartitions(Arrays.asList(\n+                                new ListOffsetPartitionResponse()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk0NzgwNw==", "bodyText": "It's relatively common to ident twice when it's in 2 calls from the line above, ie setPartitions() and Arrays.asList().\nFor example, it's also done in:\n\nhttps://github.com/apache/kafka/blame/trunk/clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java#L3165-L3168\nhttps://github.com/apache/kafka/blame/trunk/clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java#L3724-L3725", "url": "https://github.com/apache/kafka/pull/8295#discussion_r490947807", "createdAt": "2020-09-18T13:26:30Z", "author": {"login": "mimaison"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -2496,46 +2501,81 @@ public void testGetOffsetByTimeWithPartitionsRetryCouldTriggerMetadataUpdate() {\n             client.updateMetadata(initialUpdateResponse);\n \n             final long fetchTimestamp = 10L;\n-            Map<TopicPartition, ListOffsetResponse.PartitionData> allPartitionData = new HashMap<>();\n-            allPartitionData.put(tp0, new ListOffsetResponse.PartitionData(\n-                Errors.NONE, fetchTimestamp, 4L, Optional.empty()));\n-            allPartitionData.put(tp1, new ListOffsetResponse.PartitionData(\n-                retriableError, ListOffsetRequest.LATEST_TIMESTAMP, -1L, Optional.empty()));\n+            List<ListOffsetTopicResponse> topics = Collections.singletonList(\n+                    new ListOffsetTopicResponse()\n+                        .setName(tp0.topic())\n+                        .setPartitions(Arrays.asList(\n+                                new ListOffsetPartitionResponse()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDUwNzY3NA=="}, "originalCommit": null, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2OTEyMTc0OnYy", "diffSide": "RIGHT", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxOTozMjowM1rOHTyULQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzoxNzowN1rOHUMuJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDUwOTM1Nw==", "bodyText": "Could we reuse the struct in L2508?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r490509357", "createdAt": "2020-09-17T19:32:03Z", "author": {"login": "abbccdda"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -2496,46 +2501,81 @@ public void testGetOffsetByTimeWithPartitionsRetryCouldTriggerMetadataUpdate() {\n             client.updateMetadata(initialUpdateResponse);\n \n             final long fetchTimestamp = 10L;\n-            Map<TopicPartition, ListOffsetResponse.PartitionData> allPartitionData = new HashMap<>();\n-            allPartitionData.put(tp0, new ListOffsetResponse.PartitionData(\n-                Errors.NONE, fetchTimestamp, 4L, Optional.empty()));\n-            allPartitionData.put(tp1, new ListOffsetResponse.PartitionData(\n-                retriableError, ListOffsetRequest.LATEST_TIMESTAMP, -1L, Optional.empty()));\n+            List<ListOffsetTopicResponse> topics = Collections.singletonList(\n+                    new ListOffsetTopicResponse()\n+                        .setName(tp0.topic())\n+                        .setPartitions(Arrays.asList(\n+                                new ListOffsetPartitionResponse()\n+                                    .setPartitionIndex(tp0.partition())\n+                                    .setErrorCode(Errors.NONE.code())\n+                                    .setTimestamp(fetchTimestamp)\n+                                    .setOffset(4L),\n+                                new ListOffsetPartitionResponse()\n+                                    .setPartitionIndex(tp1.partition())\n+                                    .setErrorCode(retriableError.code())\n+                                    .setTimestamp(ListOffsetRequest.LATEST_TIMESTAMP)\n+                                    .setOffset(-1L))));\n+            ListOffsetResponseData data = new ListOffsetResponseData()\n+                    .setThrottleTimeMs(0)\n+                    .setTopics(topics);\n \n             client.prepareResponseFrom(body -> {\n                 boolean isListOffsetRequest = body instanceof ListOffsetRequest;\n                 if (isListOffsetRequest) {\n                     ListOffsetRequest request = (ListOffsetRequest) body;\n-                    Map<TopicPartition, ListOffsetRequest.PartitionData> expectedTopicPartitions = new HashMap<>();\n-                    expectedTopicPartitions.put(tp0, new ListOffsetRequest.PartitionData(\n-                        fetchTimestamp, Optional.empty()));\n-                    expectedTopicPartitions.put(tp1, new ListOffsetRequest.PartitionData(\n-                        fetchTimestamp, Optional.empty()));\n-\n-                    return request.partitionTimestamps().equals(expectedTopicPartitions);\n+                    List<ListOffsetTopic> expectedTopics = Collections.singletonList(\n+                            new ListOffsetTopic()\n+                                .setName(tp0.topic())\n+                                .setPartitions(Arrays.asList(\n+                                        new ListOffsetPartition()\n+                                            .setPartitionIndex(tp1.partition())\n+                                            .setTimestamp(fetchTimestamp)\n+                                            .setCurrentLeaderEpoch(ListOffsetResponse.UNKNOWN_EPOCH),\n+                                            new ListOffsetPartition()\n+                                            .setPartitionIndex(tp0.partition())\n+                                            .setTimestamp(fetchTimestamp)\n+                                            .setCurrentLeaderEpoch(ListOffsetResponse.UNKNOWN_EPOCH))));\n+                    return request.topics().equals(expectedTopics);\n                 } else {\n                     return false;\n                 }\n-            }, new ListOffsetResponse(allPartitionData), originalLeader);\n+            }, new ListOffsetResponse(data), originalLeader);\n \n             client.prepareMetadataUpdate(updatedMetadata);\n \n             // If the metadata wasn't updated before retrying, the fetcher would consult the original leader and hit a NOT_LEADER exception.\n             // We will count the answered future response in the end to verify if this is the case.\n-            Map<TopicPartition, ListOffsetResponse.PartitionData> paritionDataWithFatalError = new HashMap<>(allPartitionData);\n-            paritionDataWithFatalError.put(tp1, new ListOffsetResponse.PartitionData(\n-                Errors.NOT_LEADER_OR_FOLLOWER, ListOffsetRequest.LATEST_TIMESTAMP, -1L, Optional.empty()));\n-            client.prepareResponseFrom(new ListOffsetResponse(paritionDataWithFatalError), originalLeader);\n+            List<ListOffsetTopicResponse> topicsWithFatalError = Collections.singletonList(\n+                    new ListOffsetTopicResponse()\n+                        .setName(tp0.topic())\n+                        .setPartitions(Arrays.asList(\n+                                new ListOffsetPartitionResponse()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk0MTk4OQ==", "bodyText": "Done", "url": "https://github.com/apache/kafka/pull/8295#discussion_r490941989", "createdAt": "2020-09-18T13:17:07Z", "author": {"login": "mimaison"}, "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -2496,46 +2501,81 @@ public void testGetOffsetByTimeWithPartitionsRetryCouldTriggerMetadataUpdate() {\n             client.updateMetadata(initialUpdateResponse);\n \n             final long fetchTimestamp = 10L;\n-            Map<TopicPartition, ListOffsetResponse.PartitionData> allPartitionData = new HashMap<>();\n-            allPartitionData.put(tp0, new ListOffsetResponse.PartitionData(\n-                Errors.NONE, fetchTimestamp, 4L, Optional.empty()));\n-            allPartitionData.put(tp1, new ListOffsetResponse.PartitionData(\n-                retriableError, ListOffsetRequest.LATEST_TIMESTAMP, -1L, Optional.empty()));\n+            List<ListOffsetTopicResponse> topics = Collections.singletonList(\n+                    new ListOffsetTopicResponse()\n+                        .setName(tp0.topic())\n+                        .setPartitions(Arrays.asList(\n+                                new ListOffsetPartitionResponse()\n+                                    .setPartitionIndex(tp0.partition())\n+                                    .setErrorCode(Errors.NONE.code())\n+                                    .setTimestamp(fetchTimestamp)\n+                                    .setOffset(4L),\n+                                new ListOffsetPartitionResponse()\n+                                    .setPartitionIndex(tp1.partition())\n+                                    .setErrorCode(retriableError.code())\n+                                    .setTimestamp(ListOffsetRequest.LATEST_TIMESTAMP)\n+                                    .setOffset(-1L))));\n+            ListOffsetResponseData data = new ListOffsetResponseData()\n+                    .setThrottleTimeMs(0)\n+                    .setTopics(topics);\n \n             client.prepareResponseFrom(body -> {\n                 boolean isListOffsetRequest = body instanceof ListOffsetRequest;\n                 if (isListOffsetRequest) {\n                     ListOffsetRequest request = (ListOffsetRequest) body;\n-                    Map<TopicPartition, ListOffsetRequest.PartitionData> expectedTopicPartitions = new HashMap<>();\n-                    expectedTopicPartitions.put(tp0, new ListOffsetRequest.PartitionData(\n-                        fetchTimestamp, Optional.empty()));\n-                    expectedTopicPartitions.put(tp1, new ListOffsetRequest.PartitionData(\n-                        fetchTimestamp, Optional.empty()));\n-\n-                    return request.partitionTimestamps().equals(expectedTopicPartitions);\n+                    List<ListOffsetTopic> expectedTopics = Collections.singletonList(\n+                            new ListOffsetTopic()\n+                                .setName(tp0.topic())\n+                                .setPartitions(Arrays.asList(\n+                                        new ListOffsetPartition()\n+                                            .setPartitionIndex(tp1.partition())\n+                                            .setTimestamp(fetchTimestamp)\n+                                            .setCurrentLeaderEpoch(ListOffsetResponse.UNKNOWN_EPOCH),\n+                                            new ListOffsetPartition()\n+                                            .setPartitionIndex(tp0.partition())\n+                                            .setTimestamp(fetchTimestamp)\n+                                            .setCurrentLeaderEpoch(ListOffsetResponse.UNKNOWN_EPOCH))));\n+                    return request.topics().equals(expectedTopics);\n                 } else {\n                     return false;\n                 }\n-            }, new ListOffsetResponse(allPartitionData), originalLeader);\n+            }, new ListOffsetResponse(data), originalLeader);\n \n             client.prepareMetadataUpdate(updatedMetadata);\n \n             // If the metadata wasn't updated before retrying, the fetcher would consult the original leader and hit a NOT_LEADER exception.\n             // We will count the answered future response in the end to verify if this is the case.\n-            Map<TopicPartition, ListOffsetResponse.PartitionData> paritionDataWithFatalError = new HashMap<>(allPartitionData);\n-            paritionDataWithFatalError.put(tp1, new ListOffsetResponse.PartitionData(\n-                Errors.NOT_LEADER_OR_FOLLOWER, ListOffsetRequest.LATEST_TIMESTAMP, -1L, Optional.empty()));\n-            client.prepareResponseFrom(new ListOffsetResponse(paritionDataWithFatalError), originalLeader);\n+            List<ListOffsetTopicResponse> topicsWithFatalError = Collections.singletonList(\n+                    new ListOffsetTopicResponse()\n+                        .setName(tp0.topic())\n+                        .setPartitions(Arrays.asList(\n+                                new ListOffsetPartitionResponse()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDUwOTM1Nw=="}, "originalCommit": null, "originalPosition": 153}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2OTE0Nzk4OnYy", "diffSide": "RIGHT", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxOTozNjo0MVrOHTymYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzoxNDoyOVrOHUMoFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDUxNDAxOQ==", "bodyText": "Are we missing storage exception here?", "url": "https://github.com/apache/kafka/pull/8295#discussion_r490514019", "createdAt": "2020-09-17T19:36:41Z", "author": {"login": "abbccdda"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -910,136 +913,161 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderOrFollowerException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n \n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)\n+    )\n \n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n \n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cases since these error messages", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk0MDQzOQ==", "bodyText": "This message has not changed. The way Github shows the diff here is confusing. If you look at https://github.com/apache/kafka/pull/8295/files#diff-d45970e44e2636ec847b63ac71827b71L944 on the right (which is the matching logic) you'll see it's already there.", "url": "https://github.com/apache/kafka/pull/8295#discussion_r490940439", "createdAt": "2020-09-18T13:14:29Z", "author": {"login": "mimaison"}, "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -910,136 +913,161 @@ class KafkaApis(val requestChannel: RequestChannel,\n   def handleListOffsetRequest(request: RequestChannel.Request): Unit = {\n     val version = request.header.apiVersion\n \n-    val mergedResponseMap = if (version == 0)\n+    val topics = if (version == 0)\n       handleListOffsetRequestV0(request)\n     else\n       handleListOffsetRequestV1AndAbove(request)\n \n-    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(requestThrottleMs, mergedResponseMap.asJava))\n+    sendResponseMaybeThrottle(request, requestThrottleMs => new ListOffsetResponse(new ListOffsetResponseData()\n+      .setThrottleTimeMs(requestThrottleMs)\n+      .setTopics(topics.asJava)))\n   }\n \n-  private def handleListOffsetRequestV0(request : RequestChannel.Request) : Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n+  private def handleListOffsetRequestV0(request : RequestChannel.Request) : List[ListOffsetTopicResponse] = {\n     val correlationId = request.header.correlationId\n     val clientId = request.header.clientId\n     val offsetRequest = request.body[ListOffsetRequest]\n \n-    val partitionTimestamps = offsetRequest.partitionTimestamps.asScala\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, partitionTimestamps)(_.topic)\n-\n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED, Seq.empty[JLong].asJava)\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      try {\n-        val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n-          topicPartition = topicPartition,\n-          timestamp = partitionData.timestamp,\n-          maxNumOffsets = partitionData.maxNumOffsets,\n-          isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n-          fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.NONE, offsets.map(JLong.valueOf).asJava))\n-      } catch {\n-        // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cased since these error messages\n-        // are typically transient and there is no value in logging the entire stack trace for the same\n-        case e @ (_ : UnknownTopicOrPartitionException |\n-                  _ : NotLeaderOrFollowerException |\n-                  _ : KafkaStorageException) =>\n-          debug(\"Offset request with correlation id %d from client %s on partition %s failed due to %s\".format(\n-            correlationId, clientId, topicPartition, e.getMessage))\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-        case e: Throwable =>\n-          error(\"Error while responding to offset request\", e)\n-          (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e), List[JLong]().asJava))\n-      }\n-    }\n-    responseMap ++ unauthorizedResponseStatus\n-  }\n-\n-  private def handleListOffsetRequestV1AndAbove(request : RequestChannel.Request): Map[TopicPartition, ListOffsetResponse.PartitionData] = {\n-    val correlationId = request.header.correlationId\n-    val clientId = request.header.clientId\n-    val offsetRequest = request.body[ListOffsetRequest]\n-\n-    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionMapByAuthorized(request.context,\n-      DESCRIBE, TOPIC, offsetRequest.partitionTimestamps.asScala)(_.topic)\n+    val (authorizedRequestInfo, unauthorizedRequestInfo) = partitionSeqByAuthorized(request.context,\n+        DESCRIBE, TOPIC, offsetRequest.topics.asScala.toSeq)(_.name)\n \n-    val unauthorizedResponseStatus = unauthorizedRequestInfo.map { case (k, _) =>\n-      k -> new ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,\n-        ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-        ListOffsetResponse.UNKNOWN_OFFSET,\n-        Optional.empty())\n-    }\n-\n-    val responseMap = authorizedRequestInfo.map { case (topicPartition, partitionData) =>\n-      if (offsetRequest.duplicatePartitions.contains(topicPartition)) {\n-        debug(s\"OffsetRequest with correlation id $correlationId from client $clientId on partition $topicPartition \" +\n-            s\"failed because the partition is duplicated in the request.\")\n-        (topicPartition, new ListOffsetResponse.PartitionData(Errors.INVALID_REQUEST,\n-          ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-          ListOffsetResponse.UNKNOWN_OFFSET,\n-          Optional.empty()))\n-      } else {\n+    val unauthorizedResponseStatus = unauthorizedRequestInfo.map(topic =>\n+      new ListOffsetTopicResponse()\n+        .setName(topic.name)\n+        .setPartitions(topic.partitions.asScala.map(partition =>\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)\n+    )\n \n-        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {\n-          (topicPartition, new ListOffsetResponse.PartitionData(\n-            e,\n-            ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-            ListOffsetResponse.UNKNOWN_OFFSET,\n-            Optional.empty()))\n-        }\n+    val responseTopics = authorizedRequestInfo.map { topic =>\n+      val responsePartitions = topic.partitions.asScala.map { partition =>\n+        val topicPartition = new TopicPartition(topic.name, partition.partitionIndex)\n \n         try {\n-          val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID\n-          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID\n-          val isolationLevelOpt = if (isClientRequest)\n-            Some(offsetRequest.isolationLevel)\n-          else\n-            None\n-\n-          val foundOpt = replicaManager.fetchOffsetForTimestamp(topicPartition,\n-            partitionData.timestamp,\n-            isolationLevelOpt,\n-            partitionData.currentLeaderEpoch,\n-            fetchOnlyFromLeader)\n-\n-          val response = foundOpt match {\n-            case Some(found) =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset, found.leaderEpoch)\n-            case None =>\n-              new ListOffsetResponse.PartitionData(Errors.NONE, ListOffsetResponse.UNKNOWN_TIMESTAMP,\n-                ListOffsetResponse.UNKNOWN_OFFSET, Optional.empty())\n-          }\n-          (topicPartition, response)\n+          val offsets = replicaManager.legacyFetchOffsetsForTimestamp(\n+            topicPartition = topicPartition,\n+            timestamp = partition.timestamp,\n+            maxNumOffsets = partition.maxNumOffsets,\n+            isFromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID,\n+            fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID)\n+          new ListOffsetPartitionResponse()\n+            .setPartitionIndex(partition.partitionIndex)\n+            .setErrorCode(Errors.NONE.code)\n+            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n         } catch {\n-          // NOTE: These exceptions are special cased since these error messages are typically transient or the client\n-          // would have received a clear exception and there is no value in logging the entire stack trace for the same\n+          // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cases since these error messages", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDUxNDAxOQ=="}, "originalCommit": null, "originalPosition": 147}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3331, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}