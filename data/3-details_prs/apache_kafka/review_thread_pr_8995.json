{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ2NDQxMzI1", "number": 8995, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMDowNzoyOFrOEMoyjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMDowNzoyOFrOEMoyjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNjg2NjY4OnYy", "diffSide": "RIGHT", "path": "docs/streams/core-concepts.html", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMDowNzoyOFrOGu3dYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQyMDo1OToyMFrOGvhmQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTc5NjMyMA==", "bodyText": "Can we avoid those super long lines? Similar below.", "url": "https://github.com/apache/kafka/pull/8995#discussion_r451796320", "createdAt": "2020-07-08T20:07:28Z", "author": {"login": "mjsax"}, "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -170,13 +150,59 @@ <h3><a id=\"streams_concepts_duality\" href=\"#streams-concepts-duality\">Duality of\n       or to run <a id=\"streams-developer-guide-interactive-queries\" href=\"/{{version}}/documentation/streams/developer-guide/interactive-queries#interactive-queries\">interactive queries</a>\n       against your application's latest processing results. And, beyond its internal usage, the Kafka Streams API\n       also allows developers to exploit this duality in their own applications.\n-  </p>\n+    </p>\n \n-  <p>\n+    <p>\n       Before we discuss concepts such as <a id=\"streams-developer-guide-dsl-aggregating\" href=\"/{{version}}/documentation/streams/developer-guide/dsl-api#aggregating\">aggregations</a>\n       in Kafka Streams, we must first introduce <strong>tables</strong> in more detail, and talk about the aforementioned stream-table duality.\n-      Essentially, this duality means that a stream can be viewed as a table, and a table can be viewed as a stream.\n-  </p>\n+      Essentially, this duality means that a stream can be viewed as a table, and a table can be viewed as a stream. Kafka's log compaction feature, for example, exploits this duality.\n+    </p>\n+\n+    <p>\n+        A simple form of a table is a collection of key-value pairs, also called a map or associative array. Such a table may look as follows:\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-01.png\">\n+\n+    The <b>stream-table duality</b> describes the close relationship between streams and tables.\n+    <ul>\n+        <li><b>Stream as Table</b>: A stream can be considered a changelog of a table, where each data record in the stream captures a state change of the table. A stream is thus a table in disguise, and it can be easily turned into a \"real\" table by replaying the changelog from beginning to end to reconstruct the table. Similarly, in a more general analogy, aggregating data records in a stream - such as computing the total number of pageviews by user from a stream of pageview events - will return a table (here with the key and the value being the user and its corresponding pageview count, respectively).</li>\n+        <li><b>Table as Stream</b>: A table can be considered a snapshot, at a point in time, of the latest value for each key in a stream (a stream's data records are key-value pairs). A table is thus a stream in disguise, and it can be easily turned into a \"real\" stream by iterating over each key-value entry in the table.</li>\n+    </ul>\n+\n+    <p>\n+        Let's illustrate this with an example. Imagine a table that tracks the total number of pageviews by user (first column of diagram below). Over time, whenever a new pageview event is processed, the state of the table is updated accordingly. Here, the state changes between different points in time - and different revisions of the table - can be represented as a changelog stream (second column).\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-02.png\" style=\"width:300px\">\n+\n+    <p>\n+        Interestingly, because of the stream-table duality, the same stream can be used to reconstruct the original table (third column):\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-03.png\" style=\"width:600px\">\n+\n+    <p>\n+        The same mechanism is used, for example, to replicate databases via change data capture (CDC) and, within Kafka Streams, to replicate its so-called state stores across machines for fault-tolerance.\n+        The stream-table duality is such an important concept that Kafka Streams models it explicitly via the <a href=\"#streams_kstream_ktable\">KStream, KTable, and GlobalKTable</a> interfaces.\n+    </p>\n+\n+    <h3><a id=\"streams_concepts_aggregations\" href=\"#streams_concepts_aggregations\">Aggregations</a></h3>\n+    <p>\n+        An <strong>aggregation</strong> operation takes one input stream or table, and yields a new table by combining multiple input records into a single output record. Examples of aggregations are computing counts or sum.\n+    </p>\n+\n+    <p>\n+        In the <code>Kafka Streams DSL</code>, an input stream of an <code>aggregation</code> can be a KStream or a KTable, but the output stream will always be a KTable. This allows Kafka Streams to update an aggregate value upon the out-of-order arrival of further records after the value was produced and emitted. When such out-of-order arrival happens, the aggregating KStream or KTable emits a new aggregate value. Because the output is a KTable, the new value is considered to overwrite the old value with the same key in subsequent processing steps.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "872d40071d3d516af16ed8b9bc2e05eaebdb4b56"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgwOTkzNg==", "bodyText": "Sure, but that's the style throughout the Kafka docs. :)", "url": "https://github.com/apache/kafka/pull/8995#discussion_r451809936", "createdAt": "2020-07-08T20:35:07Z", "author": {"login": "JimGalasyn"}, "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -170,13 +150,59 @@ <h3><a id=\"streams_concepts_duality\" href=\"#streams-concepts-duality\">Duality of\n       or to run <a id=\"streams-developer-guide-interactive-queries\" href=\"/{{version}}/documentation/streams/developer-guide/interactive-queries#interactive-queries\">interactive queries</a>\n       against your application's latest processing results. And, beyond its internal usage, the Kafka Streams API\n       also allows developers to exploit this duality in their own applications.\n-  </p>\n+    </p>\n \n-  <p>\n+    <p>\n       Before we discuss concepts such as <a id=\"streams-developer-guide-dsl-aggregating\" href=\"/{{version}}/documentation/streams/developer-guide/dsl-api#aggregating\">aggregations</a>\n       in Kafka Streams, we must first introduce <strong>tables</strong> in more detail, and talk about the aforementioned stream-table duality.\n-      Essentially, this duality means that a stream can be viewed as a table, and a table can be viewed as a stream.\n-  </p>\n+      Essentially, this duality means that a stream can be viewed as a table, and a table can be viewed as a stream. Kafka's log compaction feature, for example, exploits this duality.\n+    </p>\n+\n+    <p>\n+        A simple form of a table is a collection of key-value pairs, also called a map or associative array. Such a table may look as follows:\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-01.png\">\n+\n+    The <b>stream-table duality</b> describes the close relationship between streams and tables.\n+    <ul>\n+        <li><b>Stream as Table</b>: A stream can be considered a changelog of a table, where each data record in the stream captures a state change of the table. A stream is thus a table in disguise, and it can be easily turned into a \"real\" table by replaying the changelog from beginning to end to reconstruct the table. Similarly, in a more general analogy, aggregating data records in a stream - such as computing the total number of pageviews by user from a stream of pageview events - will return a table (here with the key and the value being the user and its corresponding pageview count, respectively).</li>\n+        <li><b>Table as Stream</b>: A table can be considered a snapshot, at a point in time, of the latest value for each key in a stream (a stream's data records are key-value pairs). A table is thus a stream in disguise, and it can be easily turned into a \"real\" stream by iterating over each key-value entry in the table.</li>\n+    </ul>\n+\n+    <p>\n+        Let's illustrate this with an example. Imagine a table that tracks the total number of pageviews by user (first column of diagram below). Over time, whenever a new pageview event is processed, the state of the table is updated accordingly. Here, the state changes between different points in time - and different revisions of the table - can be represented as a changelog stream (second column).\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-02.png\" style=\"width:300px\">\n+\n+    <p>\n+        Interestingly, because of the stream-table duality, the same stream can be used to reconstruct the original table (third column):\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-03.png\" style=\"width:600px\">\n+\n+    <p>\n+        The same mechanism is used, for example, to replicate databases via change data capture (CDC) and, within Kafka Streams, to replicate its so-called state stores across machines for fault-tolerance.\n+        The stream-table duality is such an important concept that Kafka Streams models it explicitly via the <a href=\"#streams_kstream_ktable\">KStream, KTable, and GlobalKTable</a> interfaces.\n+    </p>\n+\n+    <h3><a id=\"streams_concepts_aggregations\" href=\"#streams_concepts_aggregations\">Aggregations</a></h3>\n+    <p>\n+        An <strong>aggregation</strong> operation takes one input stream or table, and yields a new table by combining multiple input records into a single output record. Examples of aggregations are computing counts or sum.\n+    </p>\n+\n+    <p>\n+        In the <code>Kafka Streams DSL</code>, an input stream of an <code>aggregation</code> can be a KStream or a KTable, but the output stream will always be a KTable. This allows Kafka Streams to update an aggregate value upon the out-of-order arrival of further records after the value was produced and emitted. When such out-of-order arrival happens, the aggregating KStream or KTable emits a new aggregate value. Because the output is a KTable, the new value is considered to overwrite the old value with the same key in subsequent processing steps.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTc5NjMyMA=="}, "originalCommit": {"oid": "872d40071d3d516af16ed8b9bc2e05eaebdb4b56"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQ4MTMxMg==", "bodyText": "Unfortunately, and I try to get it into better shape incrementally (reading GitHub diffs with long lines is just a pain). Would go awesome if somebody (cough) could do a PR just fixing it throughout the docs -- the current lazy approach is somewhat tiring.", "url": "https://github.com/apache/kafka/pull/8995#discussion_r452481312", "createdAt": "2020-07-09T20:49:04Z", "author": {"login": "mjsax"}, "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -170,13 +150,59 @@ <h3><a id=\"streams_concepts_duality\" href=\"#streams-concepts-duality\">Duality of\n       or to run <a id=\"streams-developer-guide-interactive-queries\" href=\"/{{version}}/documentation/streams/developer-guide/interactive-queries#interactive-queries\">interactive queries</a>\n       against your application's latest processing results. And, beyond its internal usage, the Kafka Streams API\n       also allows developers to exploit this duality in their own applications.\n-  </p>\n+    </p>\n \n-  <p>\n+    <p>\n       Before we discuss concepts such as <a id=\"streams-developer-guide-dsl-aggregating\" href=\"/{{version}}/documentation/streams/developer-guide/dsl-api#aggregating\">aggregations</a>\n       in Kafka Streams, we must first introduce <strong>tables</strong> in more detail, and talk about the aforementioned stream-table duality.\n-      Essentially, this duality means that a stream can be viewed as a table, and a table can be viewed as a stream.\n-  </p>\n+      Essentially, this duality means that a stream can be viewed as a table, and a table can be viewed as a stream. Kafka's log compaction feature, for example, exploits this duality.\n+    </p>\n+\n+    <p>\n+        A simple form of a table is a collection of key-value pairs, also called a map or associative array. Such a table may look as follows:\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-01.png\">\n+\n+    The <b>stream-table duality</b> describes the close relationship between streams and tables.\n+    <ul>\n+        <li><b>Stream as Table</b>: A stream can be considered a changelog of a table, where each data record in the stream captures a state change of the table. A stream is thus a table in disguise, and it can be easily turned into a \"real\" table by replaying the changelog from beginning to end to reconstruct the table. Similarly, in a more general analogy, aggregating data records in a stream - such as computing the total number of pageviews by user from a stream of pageview events - will return a table (here with the key and the value being the user and its corresponding pageview count, respectively).</li>\n+        <li><b>Table as Stream</b>: A table can be considered a snapshot, at a point in time, of the latest value for each key in a stream (a stream's data records are key-value pairs). A table is thus a stream in disguise, and it can be easily turned into a \"real\" stream by iterating over each key-value entry in the table.</li>\n+    </ul>\n+\n+    <p>\n+        Let's illustrate this with an example. Imagine a table that tracks the total number of pageviews by user (first column of diagram below). Over time, whenever a new pageview event is processed, the state of the table is updated accordingly. Here, the state changes between different points in time - and different revisions of the table - can be represented as a changelog stream (second column).\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-02.png\" style=\"width:300px\">\n+\n+    <p>\n+        Interestingly, because of the stream-table duality, the same stream can be used to reconstruct the original table (third column):\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-03.png\" style=\"width:600px\">\n+\n+    <p>\n+        The same mechanism is used, for example, to replicate databases via change data capture (CDC) and, within Kafka Streams, to replicate its so-called state stores across machines for fault-tolerance.\n+        The stream-table duality is such an important concept that Kafka Streams models it explicitly via the <a href=\"#streams_kstream_ktable\">KStream, KTable, and GlobalKTable</a> interfaces.\n+    </p>\n+\n+    <h3><a id=\"streams_concepts_aggregations\" href=\"#streams_concepts_aggregations\">Aggregations</a></h3>\n+    <p>\n+        An <strong>aggregation</strong> operation takes one input stream or table, and yields a new table by combining multiple input records into a single output record. Examples of aggregations are computing counts or sum.\n+    </p>\n+\n+    <p>\n+        In the <code>Kafka Streams DSL</code>, an input stream of an <code>aggregation</code> can be a KStream or a KTable, but the output stream will always be a KTable. This allows Kafka Streams to update an aggregate value upon the out-of-order arrival of further records after the value was produced and emitted. When such out-of-order arrival happens, the aggregating KStream or KTable emits a new aggregate value. Because the output is a KTable, the new value is considered to overwrite the old value with the same key in subsequent processing steps.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTc5NjMyMA=="}, "originalCommit": {"oid": "872d40071d3d516af16ed8b9bc2e05eaebdb4b56"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjQ4NjcyMw==", "bodyText": "kk cool, I'll open a ticket.", "url": "https://github.com/apache/kafka/pull/8995#discussion_r452486723", "createdAt": "2020-07-09T20:59:20Z", "author": {"login": "JimGalasyn"}, "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -170,13 +150,59 @@ <h3><a id=\"streams_concepts_duality\" href=\"#streams-concepts-duality\">Duality of\n       or to run <a id=\"streams-developer-guide-interactive-queries\" href=\"/{{version}}/documentation/streams/developer-guide/interactive-queries#interactive-queries\">interactive queries</a>\n       against your application's latest processing results. And, beyond its internal usage, the Kafka Streams API\n       also allows developers to exploit this duality in their own applications.\n-  </p>\n+    </p>\n \n-  <p>\n+    <p>\n       Before we discuss concepts such as <a id=\"streams-developer-guide-dsl-aggregating\" href=\"/{{version}}/documentation/streams/developer-guide/dsl-api#aggregating\">aggregations</a>\n       in Kafka Streams, we must first introduce <strong>tables</strong> in more detail, and talk about the aforementioned stream-table duality.\n-      Essentially, this duality means that a stream can be viewed as a table, and a table can be viewed as a stream.\n-  </p>\n+      Essentially, this duality means that a stream can be viewed as a table, and a table can be viewed as a stream. Kafka's log compaction feature, for example, exploits this duality.\n+    </p>\n+\n+    <p>\n+        A simple form of a table is a collection of key-value pairs, also called a map or associative array. Such a table may look as follows:\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-01.png\">\n+\n+    The <b>stream-table duality</b> describes the close relationship between streams and tables.\n+    <ul>\n+        <li><b>Stream as Table</b>: A stream can be considered a changelog of a table, where each data record in the stream captures a state change of the table. A stream is thus a table in disguise, and it can be easily turned into a \"real\" table by replaying the changelog from beginning to end to reconstruct the table. Similarly, in a more general analogy, aggregating data records in a stream - such as computing the total number of pageviews by user from a stream of pageview events - will return a table (here with the key and the value being the user and its corresponding pageview count, respectively).</li>\n+        <li><b>Table as Stream</b>: A table can be considered a snapshot, at a point in time, of the latest value for each key in a stream (a stream's data records are key-value pairs). A table is thus a stream in disguise, and it can be easily turned into a \"real\" stream by iterating over each key-value entry in the table.</li>\n+    </ul>\n+\n+    <p>\n+        Let's illustrate this with an example. Imagine a table that tracks the total number of pageviews by user (first column of diagram below). Over time, whenever a new pageview event is processed, the state of the table is updated accordingly. Here, the state changes between different points in time - and different revisions of the table - can be represented as a changelog stream (second column).\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-02.png\" style=\"width:300px\">\n+\n+    <p>\n+        Interestingly, because of the stream-table duality, the same stream can be used to reconstruct the original table (third column):\n+    </p>\n+    <img class=\"centered\" src=\"/{{version}}/images/streams-table-duality-03.png\" style=\"width:600px\">\n+\n+    <p>\n+        The same mechanism is used, for example, to replicate databases via change data capture (CDC) and, within Kafka Streams, to replicate its so-called state stores across machines for fault-tolerance.\n+        The stream-table duality is such an important concept that Kafka Streams models it explicitly via the <a href=\"#streams_kstream_ktable\">KStream, KTable, and GlobalKTable</a> interfaces.\n+    </p>\n+\n+    <h3><a id=\"streams_concepts_aggregations\" href=\"#streams_concepts_aggregations\">Aggregations</a></h3>\n+    <p>\n+        An <strong>aggregation</strong> operation takes one input stream or table, and yields a new table by combining multiple input records into a single output record. Examples of aggregations are computing counts or sum.\n+    </p>\n+\n+    <p>\n+        In the <code>Kafka Streams DSL</code>, an input stream of an <code>aggregation</code> can be a KStream or a KTable, but the output stream will always be a KTable. This allows Kafka Streams to update an aggregate value upon the out-of-order arrival of further records after the value was produced and emitted. When such out-of-order arrival happens, the aggregating KStream or KTable emits a new aggregate value. Because the output is a KTable, the new value is considered to overwrite the old value with the same key in subsequent processing steps.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTc5NjMyMA=="}, "originalCommit": {"oid": "872d40071d3d516af16ed8b9bc2e05eaebdb4b56"}, "originalPosition": 75}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2196, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}