{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2MjgxMTA0", "number": 8817, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxNzoyOToyNVrODqet3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxMjoyMjowMlrODqxFYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1ODcwMDQ2OnYy", "diffSide": "RIGHT", "path": "buildenv/jenkins/common/build.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxNzoyOToyNVrOF6QPiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMToxNzo1M1rOF6d3Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyNzg0OQ==", "bodyText": "Please combine the two if statements into one statement:\nif (ARTIFACTORY_CONFIG && ARTIFACTORY_CONFIG['stashed']) {...}", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396627849", "createdAt": "2020-03-23T17:29:25Z", "author": {"login": "vsebe"}, "path": "buildenv/jenkins/common/build.groovy", "diffHunk": "@@ -432,44 +435,93 @@ def archive_diagnostics() {\n     } else {\n         sh \"find . -name 'core.*.dmp' -o -name 'javacore.*.txt' -o -name 'Snap.*.trc' -o -name 'jitdump.*.dmp' | sed 's#^./##' | tar -zcvf ${DIAGNOSTICS_FILENAME} -T -\"\n     }\n-    if (ARTIFACTORY_SERVER) {\n+    if (ARTIFACTORY_CONFIG) {\n         def uploadSpec = \"\"\"{\n             \"files\":[\n                 {\n                     \"pattern\": \"${DIAGNOSTICS_FILENAME}\",\n-                    \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                    \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                     \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"\n                 }\n             ]\n         }\"\"\"\n-        upload_artifactory(uploadSpec)\n-        DIAGNOSTICS_FILE_URL = \"${ARTIFACTORY_URL}/${ARTIFACTORY_UPLOAD_DIR}${DIAGNOSTICS_FILENAME}\"\n+        upload_artifactory_core(ARTIFACTORY_CONFIG['defaultGeo'], uploadSpec)\n+        DIAGNOSTICS_FILE_URL = \"${ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['url']}/${ARTIFACTORY_CONFIG['uploadDir']}${DIAGNOSTICS_FILENAME}\"\n         currentBuild.description += \"<br><a href=${DIAGNOSTICS_FILE_URL}>${DIAGNOSTICS_FILENAME}</a>\"\n     } else {\n         archiveArtifacts artifacts: \"${DIAGNOSTICS_FILENAME}\", fingerprint: false\n     }\n }\n \n def upload_artifactory(uploadSpec) {\n-    def server = Artifactory.server ARTIFACTORY_SERVER\n+    // Loop all the servers and upload if we've determined we should do so\n+    for (geo in ARTIFACTORY_CONFIG['geos']) {\n+        if (ARTIFACTORY_CONFIG[geo]['uploadBool']) {\n+            /*\n+            * If the server is behind a vpn and we aren't on a node behind the vpn,\n+            * save the sdk and upload it later on a machine behind the vpn\n+            */\n+            if (ARTIFACTORY_CONFIG[geo]['vpn'] == 'true' && !NODE_LABELS.contains(\"ci.geo.${geo}\")) {\n+                if (!ARTIFACTORY_CONFIG['stashed']) {\n+                    stash includes: \"**/${SDK_FILENAME},**/${TEST_FILENAME}\", name: 'sdk'\n+                    ARTIFACTORY_CONFIG['stashed'] = true\n+                    ARTIFACTORY_CONFIG['uploadSpec'] = uploadSpec\n+                }\n+                ARTIFACTORY_CONFIG[geo]['uploaded'] = false\n+            } else {\n+                upload_artifactory_core(geo, uploadSpec)\n+                ARTIFACTORY_CONFIG[geo]['uploaded'] = true\n+            }\n+        }\n+    }\n+}\n+\n+def upload_artifactory_core(geo, uploadSpec) {\n+    echo \"Uploading to '${geo}'...\"\n+    def server = Artifactory.server ARTIFACTORY_CONFIG[geo]['server']\n     // set connection timeout to 10 mins to avoid timeout on slow platforms\n     server.connection.timeout = 600\n \n     def buildInfo = Artifactory.newBuildInfo()\n-    buildInfo.retention maxBuilds: ARTIFACTORY_NUM_ARTIFACTS, maxDays: ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS, deleteBuildArtifacts: true\n+    buildInfo.retention maxBuilds: ARTIFACTORY_CONFIG[geo]['numArtifacts'], maxDays: ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts'], deleteBuildArtifacts: true\n     // Add BUILD_IDENTIFIER to the buildInfo. The UploadSpec adds it to the Artifact info\n     buildInfo.env.filter.addInclude(\"BUILD_IDENTIFIER\")\n     buildInfo.env.capture = true\n \n     //Retry uploading to Artifactory if errors occur\n     pipelineFunctions.retry_and_delay({\n         server.upload spec: uploadSpec, buildInfo: buildInfo;\n-        server.publishBuildInfo buildInfo},\n+        if (!ARTIFACTORY_CONFIG[geo]['vpn']){server.publishBuildInfo buildInfo}},\n         3, 300)\n \n-    // Write URL to env so that we can pull it from the upstream pipeline job\n-    env.ARTIFACTORY_URL = server.getUrl()\n-    env.ARTIFACTORY_CREDS = server.getCredentialsId()\n+    ARTIFACTORY_CONFIG[geo]['url'] = server.getUrl()\n+    ARTIFACTORY_CONFIG[geo]['creds'] = server.getCredentialsId()\n+    // If this is the default server, save the creds to pass to test\n+    if (geo == ARTIFACTORY_CONFIG['defaultGeo']) {\n+        env.ARTIFACTORY_CREDS = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']].creds\n+    }\n+}\n+\n+def upload_artifactory_post() {\n+    // Determine if we didn't do any artifactory uploads because of vpn.\n+    // At the time of writing this code, we would only hit this case if we compiled at OSU on plinux and needed to upload to UNB.\n+    if (ARTIFACTORY_CONFIG) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MTAxNQ==", "bodyText": "Done", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396851015", "createdAt": "2020-03-24T01:17:53Z", "author": {"login": "AdamBrousseau"}, "path": "buildenv/jenkins/common/build.groovy", "diffHunk": "@@ -432,44 +435,93 @@ def archive_diagnostics() {\n     } else {\n         sh \"find . -name 'core.*.dmp' -o -name 'javacore.*.txt' -o -name 'Snap.*.trc' -o -name 'jitdump.*.dmp' | sed 's#^./##' | tar -zcvf ${DIAGNOSTICS_FILENAME} -T -\"\n     }\n-    if (ARTIFACTORY_SERVER) {\n+    if (ARTIFACTORY_CONFIG) {\n         def uploadSpec = \"\"\"{\n             \"files\":[\n                 {\n                     \"pattern\": \"${DIAGNOSTICS_FILENAME}\",\n-                    \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                    \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                     \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"\n                 }\n             ]\n         }\"\"\"\n-        upload_artifactory(uploadSpec)\n-        DIAGNOSTICS_FILE_URL = \"${ARTIFACTORY_URL}/${ARTIFACTORY_UPLOAD_DIR}${DIAGNOSTICS_FILENAME}\"\n+        upload_artifactory_core(ARTIFACTORY_CONFIG['defaultGeo'], uploadSpec)\n+        DIAGNOSTICS_FILE_URL = \"${ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['url']}/${ARTIFACTORY_CONFIG['uploadDir']}${DIAGNOSTICS_FILENAME}\"\n         currentBuild.description += \"<br><a href=${DIAGNOSTICS_FILE_URL}>${DIAGNOSTICS_FILENAME}</a>\"\n     } else {\n         archiveArtifacts artifacts: \"${DIAGNOSTICS_FILENAME}\", fingerprint: false\n     }\n }\n \n def upload_artifactory(uploadSpec) {\n-    def server = Artifactory.server ARTIFACTORY_SERVER\n+    // Loop all the servers and upload if we've determined we should do so\n+    for (geo in ARTIFACTORY_CONFIG['geos']) {\n+        if (ARTIFACTORY_CONFIG[geo]['uploadBool']) {\n+            /*\n+            * If the server is behind a vpn and we aren't on a node behind the vpn,\n+            * save the sdk and upload it later on a machine behind the vpn\n+            */\n+            if (ARTIFACTORY_CONFIG[geo]['vpn'] == 'true' && !NODE_LABELS.contains(\"ci.geo.${geo}\")) {\n+                if (!ARTIFACTORY_CONFIG['stashed']) {\n+                    stash includes: \"**/${SDK_FILENAME},**/${TEST_FILENAME}\", name: 'sdk'\n+                    ARTIFACTORY_CONFIG['stashed'] = true\n+                    ARTIFACTORY_CONFIG['uploadSpec'] = uploadSpec\n+                }\n+                ARTIFACTORY_CONFIG[geo]['uploaded'] = false\n+            } else {\n+                upload_artifactory_core(geo, uploadSpec)\n+                ARTIFACTORY_CONFIG[geo]['uploaded'] = true\n+            }\n+        }\n+    }\n+}\n+\n+def upload_artifactory_core(geo, uploadSpec) {\n+    echo \"Uploading to '${geo}'...\"\n+    def server = Artifactory.server ARTIFACTORY_CONFIG[geo]['server']\n     // set connection timeout to 10 mins to avoid timeout on slow platforms\n     server.connection.timeout = 600\n \n     def buildInfo = Artifactory.newBuildInfo()\n-    buildInfo.retention maxBuilds: ARTIFACTORY_NUM_ARTIFACTS, maxDays: ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS, deleteBuildArtifacts: true\n+    buildInfo.retention maxBuilds: ARTIFACTORY_CONFIG[geo]['numArtifacts'], maxDays: ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts'], deleteBuildArtifacts: true\n     // Add BUILD_IDENTIFIER to the buildInfo. The UploadSpec adds it to the Artifact info\n     buildInfo.env.filter.addInclude(\"BUILD_IDENTIFIER\")\n     buildInfo.env.capture = true\n \n     //Retry uploading to Artifactory if errors occur\n     pipelineFunctions.retry_and_delay({\n         server.upload spec: uploadSpec, buildInfo: buildInfo;\n-        server.publishBuildInfo buildInfo},\n+        if (!ARTIFACTORY_CONFIG[geo]['vpn']){server.publishBuildInfo buildInfo}},\n         3, 300)\n \n-    // Write URL to env so that we can pull it from the upstream pipeline job\n-    env.ARTIFACTORY_URL = server.getUrl()\n-    env.ARTIFACTORY_CREDS = server.getCredentialsId()\n+    ARTIFACTORY_CONFIG[geo]['url'] = server.getUrl()\n+    ARTIFACTORY_CONFIG[geo]['creds'] = server.getCredentialsId()\n+    // If this is the default server, save the creds to pass to test\n+    if (geo == ARTIFACTORY_CONFIG['defaultGeo']) {\n+        env.ARTIFACTORY_CREDS = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']].creds\n+    }\n+}\n+\n+def upload_artifactory_post() {\n+    // Determine if we didn't do any artifactory uploads because of vpn.\n+    // At the time of writing this code, we would only hit this case if we compiled at OSU on plinux and needed to upload to UNB.\n+    if (ARTIFACTORY_CONFIG) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyNzg0OQ=="}, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1ODcxMzMxOnYy", "diffSide": "RIGHT", "path": "buildenv/jenkins/common/pipeline-functions.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxNzozMjoyNVrOF6QXxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMToxNzo0MVrOF6d3BA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyOTk1OA==", "bodyText": "Is this hard-coded value for development only?", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396629958", "createdAt": "2020-03-23T17:32:25Z", "author": {"login": "vsebe"}, "path": "buildenv/jenkins/common/pipeline-functions.groovy", "diffHunk": "@@ -223,7 +223,7 @@ def build(BUILD_JOB_NAME, OPENJDK_REPO, OPENJDK_BRANCH, OPENJDK_SHA, OPENJ9_REPO\n def test(JOB_NAME, UPSTREAM_JOB_NAME, UPSTREAM_JOB_NUMBER, NODE, OPENJ9_REPO, OPENJ9_BRANCH, OPENJ9_SHA, VENDOR_TEST_REPOS, VENDOR_TEST_BRANCHES, VENDOR_TEST_SHAS, VENDOR_TEST_DIRS, USER_CREDENTIALS_ID, CUSTOMIZED_SDK_URL, ARTIFACTORY_CREDS, TEST_FLAG, BUILD_IDENTIFIER, ghprbGhRepository, ghprbActualCommit, GITHUB_SERVER, ADOPTOPENJDK_REPO, ADOPTOPENJDK_BRANCH, IS_PARALLEL, extraTestLabels, keepReportDir) {\n     stage (\"${JOB_NAME}\") {\n         def testParams = []\n-        testParams.addAll([string(name: 'LABEL', value: NODE),\n+        testParams.addAll([string(name: 'LABEL', value: 'ub16p8j96'),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MDk0OA==", "bodyText": "Yes", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396850948", "createdAt": "2020-03-24T01:17:41Z", "author": {"login": "AdamBrousseau"}, "path": "buildenv/jenkins/common/pipeline-functions.groovy", "diffHunk": "@@ -223,7 +223,7 @@ def build(BUILD_JOB_NAME, OPENJDK_REPO, OPENJDK_BRANCH, OPENJDK_SHA, OPENJ9_REPO\n def test(JOB_NAME, UPSTREAM_JOB_NAME, UPSTREAM_JOB_NUMBER, NODE, OPENJ9_REPO, OPENJ9_BRANCH, OPENJ9_SHA, VENDOR_TEST_REPOS, VENDOR_TEST_BRANCHES, VENDOR_TEST_SHAS, VENDOR_TEST_DIRS, USER_CREDENTIALS_ID, CUSTOMIZED_SDK_URL, ARTIFACTORY_CREDS, TEST_FLAG, BUILD_IDENTIFIER, ghprbGhRepository, ghprbActualCommit, GITHUB_SERVER, ADOPTOPENJDK_REPO, ADOPTOPENJDK_BRANCH, IS_PARALLEL, extraTestLabels, keepReportDir) {\n     stage (\"${JOB_NAME}\") {\n         def testParams = []\n-        testParams.addAll([string(name: 'LABEL', value: NODE),\n+        testParams.addAll([string(name: 'LABEL', value: 'ub16p8j96'),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyOTk1OA=="}, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1ODcyMzYyOnYy", "diffSide": "RIGHT", "path": "buildenv/jenkins/common/variables-functions.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxNzozNDo1MlrOF6QecA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMToxODo1MVrOF6d4OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzMTY2NA==", "bodyText": "Could get_value(VARIABLES.artifactory.numArtifacts, geo) = null ?", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396631664", "createdAt": "2020-03-23T17:34:52Z", "author": {"login": "vsebe"}, "path": "buildenv/jenkins/common/variables-functions.groovy", "diffHunk": "@@ -702,19 +702,151 @@ def set_slack_channel() {\n }\n \n def set_artifactory_config() {\n-    ARTIFACTORY_SERVER = VARIABLES.artifactory_server\n-    if (ARTIFACTORY_SERVER) {\n-        env.ARTIFACTORY_SERVER = ARTIFACTORY_SERVER\n-        env.ARTIFACTORY_REPO = VARIABLES.artifactory_repo\n-        env.ARTIFACTORY_NUM_ARTIFACTS = VARIABLES.artifactory_num_artifacts\n-        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = VARIABLES.artifactory_days_to_keep_artifacts\n-        env.ARTIFACTORY_MANUAL_CLEANUP = VARIABLES.artifactory_manual_cleanup // This is being used by the cleanup script\n-        env.ARTIFACTORY_UPLOAD_DIR = \"${ARTIFACTORY_REPO}/${JOB_NAME}/${BUILD_ID}/\"\n-        echo \"Using artifactory server/repo: ${ARTIFACTORY_SERVER} / ${ARTIFACTORY_REPO}\"\n-        echo \"Keeping '${ARTIFACTORY_NUM_ARTIFACTS}' artifacts\"\n-        echo \"Keeping artifacts for '${ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS}' days\"\n-        echo \"Artifactory Manual Cleanup: ${env.ARTIFACTORY_MANUAL_CLEANUP}\"\n+    ARTIFACTORY_CONFIG = [:]\n+    echo \"Configure Artifactory...\"\n+\n+    if (VARIABLES.artifactory.defaultGeo) {\n+        // Allow default geo to be overridden with a param. Used by the Clenaup script to target a specific server.\n+        ARTIFACTORY_CONFIG['defaultGeo'] = (params.ARTIFACTORY_GEO) ? params.ARTIFACTORY_GEO : VARIABLES.artifactory.defaultGeo\n+        ARTIFACTORY_CONFIG['geos'] = VARIABLES.artifactory.server.keySet()\n+        ARTIFACTORY_CONFIG['repo'] = VARIABLES.artifactory.repo\n+        ARTIFACTORY_CONFIG['uploadDir'] = \"${ARTIFACTORY_CONFIG['repo']}/${JOB_NAME}/${BUILD_ID}/\"\n+        //println VARIABLES.artifactory\n+        //println ARTIFACTORY_CONFIG['defaultServerGeo']\n+        //println ARTIFACTORY_CONFIG['geos']\n+        //println ARTIFACTORY_CONFIG['repo']\n+        //println ARTIFACTORY_CONFIG['manualCleanup']\n+\n+        for (geo in ARTIFACTORY_CONFIG['geos']) {\n+            ARTIFACTORY_CONFIG[geo] = [:]\n+            ARTIFACTORY_CONFIG[geo]['server'] = get_value(VARIABLES.artifactory.server, geo)\n+            ARTIFACTORY_CONFIG[geo]['numArtifacts'] = get_value(VARIABLES.artifactory.numArtifacts, geo).toInteger()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MTI1Nw==", "bodyText": "It's possible but there is no valid use case for it to not be set. Ie. if it's not set then it's a user problem.", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396851257", "createdAt": "2020-03-24T01:18:51Z", "author": {"login": "AdamBrousseau"}, "path": "buildenv/jenkins/common/variables-functions.groovy", "diffHunk": "@@ -702,19 +702,151 @@ def set_slack_channel() {\n }\n \n def set_artifactory_config() {\n-    ARTIFACTORY_SERVER = VARIABLES.artifactory_server\n-    if (ARTIFACTORY_SERVER) {\n-        env.ARTIFACTORY_SERVER = ARTIFACTORY_SERVER\n-        env.ARTIFACTORY_REPO = VARIABLES.artifactory_repo\n-        env.ARTIFACTORY_NUM_ARTIFACTS = VARIABLES.artifactory_num_artifacts\n-        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = VARIABLES.artifactory_days_to_keep_artifacts\n-        env.ARTIFACTORY_MANUAL_CLEANUP = VARIABLES.artifactory_manual_cleanup // This is being used by the cleanup script\n-        env.ARTIFACTORY_UPLOAD_DIR = \"${ARTIFACTORY_REPO}/${JOB_NAME}/${BUILD_ID}/\"\n-        echo \"Using artifactory server/repo: ${ARTIFACTORY_SERVER} / ${ARTIFACTORY_REPO}\"\n-        echo \"Keeping '${ARTIFACTORY_NUM_ARTIFACTS}' artifacts\"\n-        echo \"Keeping artifacts for '${ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS}' days\"\n-        echo \"Artifactory Manual Cleanup: ${env.ARTIFACTORY_MANUAL_CLEANUP}\"\n+    ARTIFACTORY_CONFIG = [:]\n+    echo \"Configure Artifactory...\"\n+\n+    if (VARIABLES.artifactory.defaultGeo) {\n+        // Allow default geo to be overridden with a param. Used by the Clenaup script to target a specific server.\n+        ARTIFACTORY_CONFIG['defaultGeo'] = (params.ARTIFACTORY_GEO) ? params.ARTIFACTORY_GEO : VARIABLES.artifactory.defaultGeo\n+        ARTIFACTORY_CONFIG['geos'] = VARIABLES.artifactory.server.keySet()\n+        ARTIFACTORY_CONFIG['repo'] = VARIABLES.artifactory.repo\n+        ARTIFACTORY_CONFIG['uploadDir'] = \"${ARTIFACTORY_CONFIG['repo']}/${JOB_NAME}/${BUILD_ID}/\"\n+        //println VARIABLES.artifactory\n+        //println ARTIFACTORY_CONFIG['defaultServerGeo']\n+        //println ARTIFACTORY_CONFIG['geos']\n+        //println ARTIFACTORY_CONFIG['repo']\n+        //println ARTIFACTORY_CONFIG['manualCleanup']\n+\n+        for (geo in ARTIFACTORY_CONFIG['geos']) {\n+            ARTIFACTORY_CONFIG[geo] = [:]\n+            ARTIFACTORY_CONFIG[geo]['server'] = get_value(VARIABLES.artifactory.server, geo)\n+            ARTIFACTORY_CONFIG[geo]['numArtifacts'] = get_value(VARIABLES.artifactory.numArtifacts, geo).toInteger()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzMTY2NA=="}, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1ODg1Mzk5OnYy", "diffSide": "RIGHT", "path": "buildenv/jenkins/common/variables-functions.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxODowNjozNVrOF6RxBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMToxOToxNVrOF6d4jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY1MjgwNQ==", "bodyText": "There are multiple nodes per geo. It should set the flag only once (and skip the other nodes with same geo):\nif (!ARTIFACTORY_CONFIG[nodeGeo].contains('uploadBool') {\n    ARTIFACTORY_CONFIG[nodeGeo]['uploadBool'] = true\n}", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396652805", "createdAt": "2020-03-23T18:06:35Z", "author": {"login": "vsebe"}, "path": "buildenv/jenkins/common/variables-functions.groovy", "diffHunk": "@@ -702,19 +702,151 @@ def set_slack_channel() {\n }\n \n def set_artifactory_config() {\n-    ARTIFACTORY_SERVER = VARIABLES.artifactory_server\n-    if (ARTIFACTORY_SERVER) {\n-        env.ARTIFACTORY_SERVER = ARTIFACTORY_SERVER\n-        env.ARTIFACTORY_REPO = VARIABLES.artifactory_repo\n-        env.ARTIFACTORY_NUM_ARTIFACTS = VARIABLES.artifactory_num_artifacts\n-        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = VARIABLES.artifactory_days_to_keep_artifacts\n-        env.ARTIFACTORY_MANUAL_CLEANUP = VARIABLES.artifactory_manual_cleanup // This is being used by the cleanup script\n-        env.ARTIFACTORY_UPLOAD_DIR = \"${ARTIFACTORY_REPO}/${JOB_NAME}/${BUILD_ID}/\"\n-        echo \"Using artifactory server/repo: ${ARTIFACTORY_SERVER} / ${ARTIFACTORY_REPO}\"\n-        echo \"Keeping '${ARTIFACTORY_NUM_ARTIFACTS}' artifacts\"\n-        echo \"Keeping artifacts for '${ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS}' days\"\n-        echo \"Artifactory Manual Cleanup: ${env.ARTIFACTORY_MANUAL_CLEANUP}\"\n+    ARTIFACTORY_CONFIG = [:]\n+    echo \"Configure Artifactory...\"\n+\n+    if (VARIABLES.artifactory.defaultGeo) {\n+        // Allow default geo to be overridden with a param. Used by the Clenaup script to target a specific server.\n+        ARTIFACTORY_CONFIG['defaultGeo'] = (params.ARTIFACTORY_GEO) ? params.ARTIFACTORY_GEO : VARIABLES.artifactory.defaultGeo\n+        ARTIFACTORY_CONFIG['geos'] = VARIABLES.artifactory.server.keySet()\n+        ARTIFACTORY_CONFIG['repo'] = VARIABLES.artifactory.repo\n+        ARTIFACTORY_CONFIG['uploadDir'] = \"${ARTIFACTORY_CONFIG['repo']}/${JOB_NAME}/${BUILD_ID}/\"\n+        //println VARIABLES.artifactory\n+        //println ARTIFACTORY_CONFIG['defaultServerGeo']\n+        //println ARTIFACTORY_CONFIG['geos']\n+        //println ARTIFACTORY_CONFIG['repo']\n+        //println ARTIFACTORY_CONFIG['manualCleanup']\n+\n+        for (geo in ARTIFACTORY_CONFIG['geos']) {\n+            ARTIFACTORY_CONFIG[geo] = [:]\n+            ARTIFACTORY_CONFIG[geo]['server'] = get_value(VARIABLES.artifactory.server, geo)\n+            ARTIFACTORY_CONFIG[geo]['numArtifacts'] = get_value(VARIABLES.artifactory.numArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts'] = get_value(VARIABLES.artifactory.daysToKeepArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['manualCleanup'] = get_value(VARIABLES.artifactory.manualCleanup, geo)\n+            ARTIFACTORY_CONFIG[geo]['vpn'] = get_value(VARIABLES.artifactory.vpn, geo)\n+            //println geo\n+            //println ARTIFACTORY_CONFIG[geo]['server']\n+            //println ARTIFACTORY_CONFIG[geo]['numArtifacts']\n+            //println ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts']\n+        }\n+        ARTIFACTORY_CONFIG[VARIABLES.artifactory.defaultGeo]['uploadBool'] = true\n+\n+        // Determine if we need to upload more than the default server\n+        if (ARTIFACTORY_CONFIG['geos'].size() > 1) {\n+            // What platform did we build on\n+            compilePlatform = get_node_platform(NODE_LABELS)\n+\n+            // See if there are servers with colocated nodes of matching platform\n+            def testNodes = jenkins.model.Jenkins.instance.getLabel('ci.role.test').getNodes()\n+            //println testNodes\n+            for (node in testNodes) {\n+                def nodeGeo = get_node_geo(node.getLabelString())\n+                def nodePlatform = get_node_platform(node.getLabelString())\n+                //println nodeGeo\n+                //println nodePlatform\n+                // Upload if there is a server at geo where there are machines matching our platform.\n+                if (nodePlatform == compilePlatform && ARTIFACTORY_CONFIG['geos'].contains(nodeGeo)) {\n+                    ARTIFACTORY_CONFIG[nodeGeo]['uploadBool'] = true\n+                    //println ARTIFACTORY_CONFIG[nodeGeo]['uploadBool']", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MTM0Mw==", "bodyText": "Agree. Added an if higher up.", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396851343", "createdAt": "2020-03-24T01:19:15Z", "author": {"login": "AdamBrousseau"}, "path": "buildenv/jenkins/common/variables-functions.groovy", "diffHunk": "@@ -702,19 +702,151 @@ def set_slack_channel() {\n }\n \n def set_artifactory_config() {\n-    ARTIFACTORY_SERVER = VARIABLES.artifactory_server\n-    if (ARTIFACTORY_SERVER) {\n-        env.ARTIFACTORY_SERVER = ARTIFACTORY_SERVER\n-        env.ARTIFACTORY_REPO = VARIABLES.artifactory_repo\n-        env.ARTIFACTORY_NUM_ARTIFACTS = VARIABLES.artifactory_num_artifacts\n-        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = VARIABLES.artifactory_days_to_keep_artifacts\n-        env.ARTIFACTORY_MANUAL_CLEANUP = VARIABLES.artifactory_manual_cleanup // This is being used by the cleanup script\n-        env.ARTIFACTORY_UPLOAD_DIR = \"${ARTIFACTORY_REPO}/${JOB_NAME}/${BUILD_ID}/\"\n-        echo \"Using artifactory server/repo: ${ARTIFACTORY_SERVER} / ${ARTIFACTORY_REPO}\"\n-        echo \"Keeping '${ARTIFACTORY_NUM_ARTIFACTS}' artifacts\"\n-        echo \"Keeping artifacts for '${ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS}' days\"\n-        echo \"Artifactory Manual Cleanup: ${env.ARTIFACTORY_MANUAL_CLEANUP}\"\n+    ARTIFACTORY_CONFIG = [:]\n+    echo \"Configure Artifactory...\"\n+\n+    if (VARIABLES.artifactory.defaultGeo) {\n+        // Allow default geo to be overridden with a param. Used by the Clenaup script to target a specific server.\n+        ARTIFACTORY_CONFIG['defaultGeo'] = (params.ARTIFACTORY_GEO) ? params.ARTIFACTORY_GEO : VARIABLES.artifactory.defaultGeo\n+        ARTIFACTORY_CONFIG['geos'] = VARIABLES.artifactory.server.keySet()\n+        ARTIFACTORY_CONFIG['repo'] = VARIABLES.artifactory.repo\n+        ARTIFACTORY_CONFIG['uploadDir'] = \"${ARTIFACTORY_CONFIG['repo']}/${JOB_NAME}/${BUILD_ID}/\"\n+        //println VARIABLES.artifactory\n+        //println ARTIFACTORY_CONFIG['defaultServerGeo']\n+        //println ARTIFACTORY_CONFIG['geos']\n+        //println ARTIFACTORY_CONFIG['repo']\n+        //println ARTIFACTORY_CONFIG['manualCleanup']\n+\n+        for (geo in ARTIFACTORY_CONFIG['geos']) {\n+            ARTIFACTORY_CONFIG[geo] = [:]\n+            ARTIFACTORY_CONFIG[geo]['server'] = get_value(VARIABLES.artifactory.server, geo)\n+            ARTIFACTORY_CONFIG[geo]['numArtifacts'] = get_value(VARIABLES.artifactory.numArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts'] = get_value(VARIABLES.artifactory.daysToKeepArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['manualCleanup'] = get_value(VARIABLES.artifactory.manualCleanup, geo)\n+            ARTIFACTORY_CONFIG[geo]['vpn'] = get_value(VARIABLES.artifactory.vpn, geo)\n+            //println geo\n+            //println ARTIFACTORY_CONFIG[geo]['server']\n+            //println ARTIFACTORY_CONFIG[geo]['numArtifacts']\n+            //println ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts']\n+        }\n+        ARTIFACTORY_CONFIG[VARIABLES.artifactory.defaultGeo]['uploadBool'] = true\n+\n+        // Determine if we need to upload more than the default server\n+        if (ARTIFACTORY_CONFIG['geos'].size() > 1) {\n+            // What platform did we build on\n+            compilePlatform = get_node_platform(NODE_LABELS)\n+\n+            // See if there are servers with colocated nodes of matching platform\n+            def testNodes = jenkins.model.Jenkins.instance.getLabel('ci.role.test').getNodes()\n+            //println testNodes\n+            for (node in testNodes) {\n+                def nodeGeo = get_node_geo(node.getLabelString())\n+                def nodePlatform = get_node_platform(node.getLabelString())\n+                //println nodeGeo\n+                //println nodePlatform\n+                // Upload if there is a server at geo where there are machines matching our platform.\n+                if (nodePlatform == compilePlatform && ARTIFACTORY_CONFIG['geos'].contains(nodeGeo)) {\n+                    ARTIFACTORY_CONFIG[nodeGeo]['uploadBool'] = true\n+                    //println ARTIFACTORY_CONFIG[nodeGeo]['uploadBool']", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY1MjgwNQ=="}, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1ODkxOTIyOnYy", "diffSide": "RIGHT", "path": "buildenv/jenkins/common/variables-functions.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxODoyMjoxNVrOF6SajA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMToyNTo0MlrOF6d_SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY2MzQzNg==", "bodyText": "Could you please simplify the switch statement below, maybe use an array for all the matching cases sharing the same code, for example:\ndef nodePlatform\nswitch(baseOS) {\n    case ['aix, 'windows',  'osx', 'zos'] :\n        nodePlatform  = baseOS\n        break\n    case ['linux', 'ubuntu', 'rhel', 'cent', 'sles']:\n        ...\n        break\n    default:\n        echo \"WARNING: Unknown baseOS:'${baseOS}'\"\n        nodePlatform  = ''\n        break\n    }\nreturn nodePlatform", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396663436", "createdAt": "2020-03-23T18:22:15Z", "author": {"login": "vsebe"}, "path": "buildenv/jenkins/common/variables-functions.groovy", "diffHunk": "@@ -702,19 +702,151 @@ def set_slack_channel() {\n }\n \n def set_artifactory_config() {\n-    ARTIFACTORY_SERVER = VARIABLES.artifactory_server\n-    if (ARTIFACTORY_SERVER) {\n-        env.ARTIFACTORY_SERVER = ARTIFACTORY_SERVER\n-        env.ARTIFACTORY_REPO = VARIABLES.artifactory_repo\n-        env.ARTIFACTORY_NUM_ARTIFACTS = VARIABLES.artifactory_num_artifacts\n-        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = VARIABLES.artifactory_days_to_keep_artifacts\n-        env.ARTIFACTORY_MANUAL_CLEANUP = VARIABLES.artifactory_manual_cleanup // This is being used by the cleanup script\n-        env.ARTIFACTORY_UPLOAD_DIR = \"${ARTIFACTORY_REPO}/${JOB_NAME}/${BUILD_ID}/\"\n-        echo \"Using artifactory server/repo: ${ARTIFACTORY_SERVER} / ${ARTIFACTORY_REPO}\"\n-        echo \"Keeping '${ARTIFACTORY_NUM_ARTIFACTS}' artifacts\"\n-        echo \"Keeping artifacts for '${ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS}' days\"\n-        echo \"Artifactory Manual Cleanup: ${env.ARTIFACTORY_MANUAL_CLEANUP}\"\n+    ARTIFACTORY_CONFIG = [:]\n+    echo \"Configure Artifactory...\"\n+\n+    if (VARIABLES.artifactory.defaultGeo) {\n+        // Allow default geo to be overridden with a param. Used by the Clenaup script to target a specific server.\n+        ARTIFACTORY_CONFIG['defaultGeo'] = (params.ARTIFACTORY_GEO) ? params.ARTIFACTORY_GEO : VARIABLES.artifactory.defaultGeo\n+        ARTIFACTORY_CONFIG['geos'] = VARIABLES.artifactory.server.keySet()\n+        ARTIFACTORY_CONFIG['repo'] = VARIABLES.artifactory.repo\n+        ARTIFACTORY_CONFIG['uploadDir'] = \"${ARTIFACTORY_CONFIG['repo']}/${JOB_NAME}/${BUILD_ID}/\"\n+        //println VARIABLES.artifactory\n+        //println ARTIFACTORY_CONFIG['defaultServerGeo']\n+        //println ARTIFACTORY_CONFIG['geos']\n+        //println ARTIFACTORY_CONFIG['repo']\n+        //println ARTIFACTORY_CONFIG['manualCleanup']\n+\n+        for (geo in ARTIFACTORY_CONFIG['geos']) {\n+            ARTIFACTORY_CONFIG[geo] = [:]\n+            ARTIFACTORY_CONFIG[geo]['server'] = get_value(VARIABLES.artifactory.server, geo)\n+            ARTIFACTORY_CONFIG[geo]['numArtifacts'] = get_value(VARIABLES.artifactory.numArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts'] = get_value(VARIABLES.artifactory.daysToKeepArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['manualCleanup'] = get_value(VARIABLES.artifactory.manualCleanup, geo)\n+            ARTIFACTORY_CONFIG[geo]['vpn'] = get_value(VARIABLES.artifactory.vpn, geo)\n+            //println geo\n+            //println ARTIFACTORY_CONFIG[geo]['server']\n+            //println ARTIFACTORY_CONFIG[geo]['numArtifacts']\n+            //println ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts']\n+        }\n+        ARTIFACTORY_CONFIG[VARIABLES.artifactory.defaultGeo]['uploadBool'] = true\n+\n+        // Determine if we need to upload more than the default server\n+        if (ARTIFACTORY_CONFIG['geos'].size() > 1) {\n+            // What platform did we build on\n+            compilePlatform = get_node_platform(NODE_LABELS)\n+\n+            // See if there are servers with colocated nodes of matching platform\n+            def testNodes = jenkins.model.Jenkins.instance.getLabel('ci.role.test').getNodes()\n+            //println testNodes\n+            for (node in testNodes) {\n+                def nodeGeo = get_node_geo(node.getLabelString())\n+                def nodePlatform = get_node_platform(node.getLabelString())\n+                //println nodeGeo\n+                //println nodePlatform\n+                // Upload if there is a server at geo where there are machines matching our platform.\n+                if (nodePlatform == compilePlatform && ARTIFACTORY_CONFIG['geos'].contains(nodeGeo)) {\n+                    ARTIFACTORY_CONFIG[nodeGeo]['uploadBool'] = true\n+                    //println ARTIFACTORY_CONFIG[nodeGeo]['uploadBool']\n+                }\n+            }\n+        }\n+\n+        echo \"ARTIFACTORY_CONFIG:'${ARTIFACTORY_CONFIG}'\"\n+        /*\n+        * Write out default server values to string variables.\n+        * The upstream job calls job.getBuildVariables() which only returns strings.\n+        * Rather than parsing out the ARTIFACTORY_CONFIG map that is stored as a string,\n+        * we'll write out the values to env here as strings to save work later.\n+        */\n+        env.ARTIFACTORY_SERVER = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['server']\n+        env.ARTIFACTORY_REPO = ARTIFACTORY_CONFIG['repo']\n+        env.ARTIFACTORY_NUM_ARTIFACTS = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['numArtifacts']\n+        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['daysToKeepArtifacts']\n+        env.ARTIFACTORY_MANUAL_CLEANUP = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['manualCleanup']\n+    }\n+}\n+\n+def get_node_geo(nodeLabels) {\n+    if (nodeLabels.contains('ci.geo.')) {\n+        labelArray = nodeLabels.tokenize()\n+        for (label in labelArray) {\n+            if (label ==~ /ci\\.geo\\..*/) {\n+                return label.substring(7)\n+            }\n+        }\n     }\n+    return ''\n+}\n+\n+def get_node_platform(nodeLabels) {\n+    /*\n+    * xlinux -> arch=x86 && baseOS=linux\n+    * plinux -> arch=ppc64le && baseOS=linux\n+    * zlinux -> arch=s390x && baseOS=linux\n+    * aix -> baseOS=aix\n+    * windows -> baseOS=windows\n+    * osx -> baseOS=osx\n+    * zos -> baseOS=zos\n+    * aarch64 -> arch=aarch64\n+    */\n+    def arch = ''\n+    def baseOS = ''\n+    if (nodeLabels.contains('hw.arch.') && nodeLabels.contains('sw.os.')) {\n+        labelArray = nodeLabels.tokenize()\n+        for (label in labelArray) {\n+            switch(label) {\n+                case ~/hw\\.arch\\.[a-z0-9]+/:\n+                    arch = label.substring(8)\n+                    //println arch\n+                    break\n+                case ~/sw\\.os\\.[a-z]+/:\n+                    baseOS = label.substring(6)\n+                    //println baseOS\n+                    break\n+            }\n+        }\n+    }\n+    if (!arch || !baseOS) {\n+        echo \"WARNING: Unable to determine node arch/os:'${nodeLabels}'\"\n+        return ''\n+    }\n+    switch(baseOS) {\n+        case 'aix':", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MzA2NA==", "bodyText": "Added arrays for multi-cases.", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396853064", "createdAt": "2020-03-24T01:25:42Z", "author": {"login": "AdamBrousseau"}, "path": "buildenv/jenkins/common/variables-functions.groovy", "diffHunk": "@@ -702,19 +702,151 @@ def set_slack_channel() {\n }\n \n def set_artifactory_config() {\n-    ARTIFACTORY_SERVER = VARIABLES.artifactory_server\n-    if (ARTIFACTORY_SERVER) {\n-        env.ARTIFACTORY_SERVER = ARTIFACTORY_SERVER\n-        env.ARTIFACTORY_REPO = VARIABLES.artifactory_repo\n-        env.ARTIFACTORY_NUM_ARTIFACTS = VARIABLES.artifactory_num_artifacts\n-        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = VARIABLES.artifactory_days_to_keep_artifacts\n-        env.ARTIFACTORY_MANUAL_CLEANUP = VARIABLES.artifactory_manual_cleanup // This is being used by the cleanup script\n-        env.ARTIFACTORY_UPLOAD_DIR = \"${ARTIFACTORY_REPO}/${JOB_NAME}/${BUILD_ID}/\"\n-        echo \"Using artifactory server/repo: ${ARTIFACTORY_SERVER} / ${ARTIFACTORY_REPO}\"\n-        echo \"Keeping '${ARTIFACTORY_NUM_ARTIFACTS}' artifacts\"\n-        echo \"Keeping artifacts for '${ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS}' days\"\n-        echo \"Artifactory Manual Cleanup: ${env.ARTIFACTORY_MANUAL_CLEANUP}\"\n+    ARTIFACTORY_CONFIG = [:]\n+    echo \"Configure Artifactory...\"\n+\n+    if (VARIABLES.artifactory.defaultGeo) {\n+        // Allow default geo to be overridden with a param. Used by the Clenaup script to target a specific server.\n+        ARTIFACTORY_CONFIG['defaultGeo'] = (params.ARTIFACTORY_GEO) ? params.ARTIFACTORY_GEO : VARIABLES.artifactory.defaultGeo\n+        ARTIFACTORY_CONFIG['geos'] = VARIABLES.artifactory.server.keySet()\n+        ARTIFACTORY_CONFIG['repo'] = VARIABLES.artifactory.repo\n+        ARTIFACTORY_CONFIG['uploadDir'] = \"${ARTIFACTORY_CONFIG['repo']}/${JOB_NAME}/${BUILD_ID}/\"\n+        //println VARIABLES.artifactory\n+        //println ARTIFACTORY_CONFIG['defaultServerGeo']\n+        //println ARTIFACTORY_CONFIG['geos']\n+        //println ARTIFACTORY_CONFIG['repo']\n+        //println ARTIFACTORY_CONFIG['manualCleanup']\n+\n+        for (geo in ARTIFACTORY_CONFIG['geos']) {\n+            ARTIFACTORY_CONFIG[geo] = [:]\n+            ARTIFACTORY_CONFIG[geo]['server'] = get_value(VARIABLES.artifactory.server, geo)\n+            ARTIFACTORY_CONFIG[geo]['numArtifacts'] = get_value(VARIABLES.artifactory.numArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts'] = get_value(VARIABLES.artifactory.daysToKeepArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['manualCleanup'] = get_value(VARIABLES.artifactory.manualCleanup, geo)\n+            ARTIFACTORY_CONFIG[geo]['vpn'] = get_value(VARIABLES.artifactory.vpn, geo)\n+            //println geo\n+            //println ARTIFACTORY_CONFIG[geo]['server']\n+            //println ARTIFACTORY_CONFIG[geo]['numArtifacts']\n+            //println ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts']\n+        }\n+        ARTIFACTORY_CONFIG[VARIABLES.artifactory.defaultGeo]['uploadBool'] = true\n+\n+        // Determine if we need to upload more than the default server\n+        if (ARTIFACTORY_CONFIG['geos'].size() > 1) {\n+            // What platform did we build on\n+            compilePlatform = get_node_platform(NODE_LABELS)\n+\n+            // See if there are servers with colocated nodes of matching platform\n+            def testNodes = jenkins.model.Jenkins.instance.getLabel('ci.role.test').getNodes()\n+            //println testNodes\n+            for (node in testNodes) {\n+                def nodeGeo = get_node_geo(node.getLabelString())\n+                def nodePlatform = get_node_platform(node.getLabelString())\n+                //println nodeGeo\n+                //println nodePlatform\n+                // Upload if there is a server at geo where there are machines matching our platform.\n+                if (nodePlatform == compilePlatform && ARTIFACTORY_CONFIG['geos'].contains(nodeGeo)) {\n+                    ARTIFACTORY_CONFIG[nodeGeo]['uploadBool'] = true\n+                    //println ARTIFACTORY_CONFIG[nodeGeo]['uploadBool']\n+                }\n+            }\n+        }\n+\n+        echo \"ARTIFACTORY_CONFIG:'${ARTIFACTORY_CONFIG}'\"\n+        /*\n+        * Write out default server values to string variables.\n+        * The upstream job calls job.getBuildVariables() which only returns strings.\n+        * Rather than parsing out the ARTIFACTORY_CONFIG map that is stored as a string,\n+        * we'll write out the values to env here as strings to save work later.\n+        */\n+        env.ARTIFACTORY_SERVER = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['server']\n+        env.ARTIFACTORY_REPO = ARTIFACTORY_CONFIG['repo']\n+        env.ARTIFACTORY_NUM_ARTIFACTS = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['numArtifacts']\n+        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['daysToKeepArtifacts']\n+        env.ARTIFACTORY_MANUAL_CLEANUP = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['manualCleanup']\n+    }\n+}\n+\n+def get_node_geo(nodeLabels) {\n+    if (nodeLabels.contains('ci.geo.')) {\n+        labelArray = nodeLabels.tokenize()\n+        for (label in labelArray) {\n+            if (label ==~ /ci\\.geo\\..*/) {\n+                return label.substring(7)\n+            }\n+        }\n     }\n+    return ''\n+}\n+\n+def get_node_platform(nodeLabels) {\n+    /*\n+    * xlinux -> arch=x86 && baseOS=linux\n+    * plinux -> arch=ppc64le && baseOS=linux\n+    * zlinux -> arch=s390x && baseOS=linux\n+    * aix -> baseOS=aix\n+    * windows -> baseOS=windows\n+    * osx -> baseOS=osx\n+    * zos -> baseOS=zos\n+    * aarch64 -> arch=aarch64\n+    */\n+    def arch = ''\n+    def baseOS = ''\n+    if (nodeLabels.contains('hw.arch.') && nodeLabels.contains('sw.os.')) {\n+        labelArray = nodeLabels.tokenize()\n+        for (label in labelArray) {\n+            switch(label) {\n+                case ~/hw\\.arch\\.[a-z0-9]+/:\n+                    arch = label.substring(8)\n+                    //println arch\n+                    break\n+                case ~/sw\\.os\\.[a-z]+/:\n+                    baseOS = label.substring(6)\n+                    //println baseOS\n+                    break\n+            }\n+        }\n+    }\n+    if (!arch || !baseOS) {\n+        echo \"WARNING: Unable to determine node arch/os:'${nodeLabels}'\"\n+        return ''\n+    }\n+    switch(baseOS) {\n+        case 'aix':", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY2MzQzNg=="}, "originalCommit": {"oid": "4e8f6dfeae82a243d335430a476796b609ef1637"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2MTcwOTc2OnYy", "diffSide": "RIGHT", "path": "buildenv/jenkins/common/build.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxMjoyMjowMlrOF6tt-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDozNjoxNVrOF7L4uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzExMDc3Nw==", "bodyText": "type here descirption", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r397110777", "createdAt": "2020-03-24T12:22:02Z", "author": {"login": "pshipton"}, "path": "buildenv/jenkins/common/build.groovy", "diffHunk": "@@ -325,45 +325,48 @@ def archive_sdk() {\n                     }\n                 }\n             }\n-            if (ARTIFACTORY_SERVER) {\n+            if (ARTIFACTORY_CONFIG) {\n                 def specs = []\n                 def sdkSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${SDK_FILENAME}\",\n-                               \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                               \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                 specs.add(sdkSpec)\n                 def testSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${TEST_FILENAME}\",\n-                                \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                                \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                 \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                 specs.add(testSpec)\n                 def debugImageSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${DEBUG_IMAGE_FILENAME}\",\n-                                \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                                \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                 \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                 specs.add(debugImageSpec)\n                 if (params.ARCHIVE_JAVADOC) {\n                     def javadocSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${JAVADOC_FILENAME}\",\n-                                       \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                                       \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                        \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                     specs.add(javadocSpec)\n                 }\n                 def uploadFiles = [files : specs]\n                 def uploadSpec = JsonOutput.toJson(uploadFiles)\n                 upload_artifactory(uploadSpec)\n-                env.CUSTOMIZED_SDK_URL = \"${ARTIFACTORY_URL}/${ARTIFACTORY_UPLOAD_DIR}${SDK_FILENAME}\"\n+\n+                // Always use the default server link for the descirption and for test.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0829b3610b96c0c61b435bb86280e959829bb89a"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYwNTA1MQ==", "bodyText": "fixed", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r397605051", "createdAt": "2020-03-25T04:36:15Z", "author": {"login": "AdamBrousseau"}, "path": "buildenv/jenkins/common/build.groovy", "diffHunk": "@@ -325,45 +325,48 @@ def archive_sdk() {\n                     }\n                 }\n             }\n-            if (ARTIFACTORY_SERVER) {\n+            if (ARTIFACTORY_CONFIG) {\n                 def specs = []\n                 def sdkSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${SDK_FILENAME}\",\n-                               \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                               \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                 specs.add(sdkSpec)\n                 def testSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${TEST_FILENAME}\",\n-                                \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                                \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                 \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                 specs.add(testSpec)\n                 def debugImageSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${DEBUG_IMAGE_FILENAME}\",\n-                                \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                                \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                 \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                 specs.add(debugImageSpec)\n                 if (params.ARCHIVE_JAVADOC) {\n                     def javadocSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${JAVADOC_FILENAME}\",\n-                                       \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                                       \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                        \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                     specs.add(javadocSpec)\n                 }\n                 def uploadFiles = [files : specs]\n                 def uploadSpec = JsonOutput.toJson(uploadFiles)\n                 upload_artifactory(uploadSpec)\n-                env.CUSTOMIZED_SDK_URL = \"${ARTIFACTORY_URL}/${ARTIFACTORY_UPLOAD_DIR}${SDK_FILENAME}\"\n+\n+                // Always use the default server link for the descirption and for test.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzExMDc3Nw=="}, "originalCommit": {"oid": "0829b3610b96c0c61b435bb86280e959829bb89a"}, "originalPosition": 34}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 514, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}