{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4MDA1NzUy", "number": 1721, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzoyMjo0NlrOEWG61w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzozMDo1NFrOEWHEzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjE3NDk1OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzoyMjo0NlrOG9PUoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxMzoxMjo1OVrOG-3IhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2NzM2MA==", "bodyText": "Should reference the the Strimzi version variable.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466867360", "createdAt": "2020-08-07T07:22:46Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----\n \n-Next, deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the {prodname} connectors installed:\n-\n+. Deploy a Kafka broker cluster:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n-# Deploy an ephemeral single instance Kafka broker\n+# Deploy an ephemeral single instance Kafka broker:\n oc process strimzi-ephemeral -p CLUSTER_NAME=broker -p ZOOKEEPER_NODE_COUNT=1 -p KAFKA_NODE_COUNT=1 -p KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 | oc apply -f -\n+----\n \n-# Deploy a single instance of Kafka Connect with no plug-in installed\n-oc process strimzi-connect-s2i -p CLUSTER_NAME=debezium -p KAFKA_CONNECT_BOOTSTRAP_SERVERS=broker-kafka-bootstrap:9092 -p KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false -p KAFKA_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false | oc apply -f -\n+. Create a Kafka Connect image with the {prodname} connectors installed:\n \n-# Build a Debezium image\n-export DEBEZIUM_VERSION={debezium-version}\n-mkdir -p plugins && cd plugins && \\\n-for PLUGIN in {mongodb,mysql,postgres}; do \\\n-    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \\\n-done && \\\n-oc start-build debezium-connect --from-dir=. --follow && \\\n-cd .. && rm -rf plugins\n+.. Download and extract the archive for each {prodname} connector you want to run. For example: \n++\n+[source,options=\"nowrap\"]\n+----\n+curl https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.1.0.Final/debezium-connector-mysql-1.1.0.Final-plugin.tar.gz tar xvz`\n ----\n \n-After a while all parts should be up and running:\n+.. Create a `Dockerfile` that uses a Strimzi Kafka image as the base image. The following example creates a `plugins/debezium` directory, which would contain a directory for each {prodname} connector that you want to run. To run more than one {prodname} connector, insert a `COPY` line for each connector. \n++\n+[subs=+macros]\n+----\n+FROM strimzi/kafka:0.19.0-kafka-2.5.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODU2ODE5Nw==", "bodyText": "Done. (in next commit)", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r468568197", "createdAt": "2020-08-11T13:12:59Z", "author": {"login": "TovaCohen"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----\n \n-Next, deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the {prodname} connectors installed:\n-\n+. Deploy a Kafka broker cluster:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n-# Deploy an ephemeral single instance Kafka broker\n+# Deploy an ephemeral single instance Kafka broker:\n oc process strimzi-ephemeral -p CLUSTER_NAME=broker -p ZOOKEEPER_NODE_COUNT=1 -p KAFKA_NODE_COUNT=1 -p KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 | oc apply -f -\n+----\n \n-# Deploy a single instance of Kafka Connect with no plug-in installed\n-oc process strimzi-connect-s2i -p CLUSTER_NAME=debezium -p KAFKA_CONNECT_BOOTSTRAP_SERVERS=broker-kafka-bootstrap:9092 -p KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false -p KAFKA_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false | oc apply -f -\n+. Create a Kafka Connect image with the {prodname} connectors installed:\n \n-# Build a Debezium image\n-export DEBEZIUM_VERSION={debezium-version}\n-mkdir -p plugins && cd plugins && \\\n-for PLUGIN in {mongodb,mysql,postgres}; do \\\n-    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \\\n-done && \\\n-oc start-build debezium-connect --from-dir=. --follow && \\\n-cd .. && rm -rf plugins\n+.. Download and extract the archive for each {prodname} connector you want to run. For example: \n++\n+[source,options=\"nowrap\"]\n+----\n+curl https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.1.0.Final/debezium-connector-mysql-1.1.0.Final-plugin.tar.gz tar xvz`\n ----\n \n-After a while all parts should be up and running:\n+.. Create a `Dockerfile` that uses a Strimzi Kafka image as the base image. The following example creates a `plugins/debezium` directory, which would contain a directory for each {prodname} connector that you want to run. To run more than one {prodname} connector, insert a `COPY` line for each connector. \n++\n+[subs=+macros]\n+----\n+FROM strimzi/kafka:0.19.0-kafka-2.5.0", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2NzM2MA=="}, "originalCommit": null, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjE3NjQ1OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzoyMzoxN1rOG9PVfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxMzoxMzo1NlrOG-3Kww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2NzU4MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You should now see additional change messages in the consumer started previousl.\n          \n          \n            \n            You should now see additional change messages in the consumer started previously.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466867581", "createdAt": "2020-08-07T07:23:17Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -215,17 +234,17 @@ You should see an output like the following (formatted for the sake of readabili\n ...\n ----\n \n-Finally, the next example modifies some records in the `customers` table of the database:\n-\n+. Modify some records in the `customers` table of the database:\n++\n [source%nowrap,bash]\n ----\n oc exec -it $(oc get pods -o custom-columns=NAME:.metadata.name --no-headers -l app=mysql) \\\n     -- bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory'\n \n # For example, run UPDATE customers SET email=\"sally.thomas@example.com\" WHERE ID = 1001;\n ----\n-\n-You should now see additional change messages in the consumer started before.\n++\n+You should now see additional change messages in the consumer started previousl.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODU2ODc3MQ==", "bodyText": "Done in the next commit.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r468568771", "createdAt": "2020-08-11T13:13:56Z", "author": {"login": "TovaCohen"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -215,17 +234,17 @@ You should see an output like the following (formatted for the sake of readabili\n ...\n ----\n \n-Finally, the next example modifies some records in the `customers` table of the database:\n-\n+. Modify some records in the `customers` table of the database:\n++\n [source%nowrap,bash]\n ----\n oc exec -it $(oc get pods -o custom-columns=NAME:.metadata.name --no-headers -l app=mysql) \\\n     -- bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory'\n \n # For example, run UPDATE customers SET email=\"sally.thomas@example.com\" WHERE ID = 1001;\n ----\n-\n-You should now see additional change messages in the consumer started before.\n++\n+You should now see additional change messages in the consumer started previousl.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2NzU4MQ=="}, "originalCommit": null, "originalPosition": 198}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjE4MTg1OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzoyNTowMVrOG9PYog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxMzoxNjoxMlrOG-3QwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2ODM4Ng==", "bodyText": "Can you add a sentence along the lines of \"These instructions should work equally on any other Kubernetes distribution, using the kubectl command\".", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466868386", "createdAt": "2020-08-07T07:25:01Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODU3MDMwNA==", "bodyText": "I added: These instructions should also work on any other Kubernetes distribution by using the kubectl command.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r468570304", "createdAt": "2020-08-11T13:16:12Z", "author": {"login": "TovaCohen"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2ODM4Ng=="}, "originalCommit": null, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjE4NDY1OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzoyNTo1N1rOG9PaRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxMzo1MDo1NVrOG-4v5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2ODgwNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n          \n          \n            \n            To set up Apache Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to Kubernetes and OpenShift, as well as Kubernetes operators for running Kafka there.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466868804", "createdAt": "2020-08-07T07:25:57Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODU3MTk3NA==", "bodyText": "I updated it as you suggested.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r468571974", "createdAt": "2020-08-11T13:18:43Z", "author": {"login": "TovaCohen"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2ODgwNA=="}, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODU5NDY2MA==", "bodyText": "Cool. Btw. you can also directly suggestions like mine here in the UI (see the two buttons above).", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r468594660", "createdAt": "2020-08-11T13:50:55Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2ODgwNA=="}, "originalCommit": null, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjE4OTQ3OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzoyNzozN1rOG9PdMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxMzo0ODozNVrOG-4o3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2OTU1Mw==", "bodyText": "After that, a link like this would be nice: \"To learn more about setting up Apache Kafka with Strimzi on Kubernetes and OpenShift, refer to the [right part of strimzi doc link]\".", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466869553", "createdAt": "2020-08-07T07:27:37Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODU3ODEyMQ==", "bodyText": "This is the best URL that I could find. Let me know if there is a better one.\nhttps://strimzi.io/docs/operators/latest/overview.html#kafka-components_str", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r468578121", "createdAt": "2020-08-11T13:27:42Z", "author": {"login": "TovaCohen"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2OTU1Mw=="}, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODU5Mjg2MQ==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r468592861", "createdAt": "2020-08-11T13:48:35Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2OTU1Mw=="}, "originalCommit": null, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjE5MTc0OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzoyODoxN1rOG9Pemg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxMzozMDowOVrOG-311g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2OTkxNA==", "bodyText": "1.1.0.Final should be the Debezium version variable instead. Let's generally avoid any hard-coded version numbers, there should be variables for all of them.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466869914", "createdAt": "2020-08-07T07:28:17Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----\n \n-Next, deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the {prodname} connectors installed:\n-\n+. Deploy a Kafka broker cluster:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n-# Deploy an ephemeral single instance Kafka broker\n+# Deploy an ephemeral single instance Kafka broker:\n oc process strimzi-ephemeral -p CLUSTER_NAME=broker -p ZOOKEEPER_NODE_COUNT=1 -p KAFKA_NODE_COUNT=1 -p KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 | oc apply -f -\n+----\n \n-# Deploy a single instance of Kafka Connect with no plug-in installed\n-oc process strimzi-connect-s2i -p CLUSTER_NAME=debezium -p KAFKA_CONNECT_BOOTSTRAP_SERVERS=broker-kafka-bootstrap:9092 -p KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false -p KAFKA_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false | oc apply -f -\n+. Create a Kafka Connect image with the {prodname} connectors installed:\n \n-# Build a Debezium image\n-export DEBEZIUM_VERSION={debezium-version}\n-mkdir -p plugins && cd plugins && \\\n-for PLUGIN in {mongodb,mysql,postgres}; do \\\n-    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \\\n-done && \\\n-oc start-build debezium-connect --from-dir=. --follow && \\\n-cd .. && rm -rf plugins\n+.. Download and extract the archive for each {prodname} connector you want to run. For example: \n++\n+[source,options=\"nowrap\"]\n+----\n+curl https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.1.0.Final/debezium-connector-mysql-1.1.0.Final-plugin.tar.gz tar xvz`", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODU3OTc5OA==", "bodyText": "Corrected.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r468579798", "createdAt": "2020-08-11T13:30:09Z", "author": {"login": "TovaCohen"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----\n \n-Next, deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the {prodname} connectors installed:\n-\n+. Deploy a Kafka broker cluster:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n-# Deploy an ephemeral single instance Kafka broker\n+# Deploy an ephemeral single instance Kafka broker:\n oc process strimzi-ephemeral -p CLUSTER_NAME=broker -p ZOOKEEPER_NODE_COUNT=1 -p KAFKA_NODE_COUNT=1 -p KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 | oc apply -f -\n+----\n \n-# Deploy a single instance of Kafka Connect with no plug-in installed\n-oc process strimzi-connect-s2i -p CLUSTER_NAME=debezium -p KAFKA_CONNECT_BOOTSTRAP_SERVERS=broker-kafka-bootstrap:9092 -p KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false -p KAFKA_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false | oc apply -f -\n+. Create a Kafka Connect image with the {prodname} connectors installed:\n \n-# Build a Debezium image\n-export DEBEZIUM_VERSION={debezium-version}\n-mkdir -p plugins && cd plugins && \\\n-for PLUGIN in {mongodb,mysql,postgres}; do \\\n-    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \\\n-done && \\\n-oc start-build debezium-connect --from-dir=. --follow && \\\n-cd .. && rm -rf plugins\n+.. Download and extract the archive for each {prodname} connector you want to run. For example: \n++\n+[source,options=\"nowrap\"]\n+----\n+curl https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.1.0.Final/debezium-connector-mysql-1.1.0.Final-plugin.tar.gz tar xvz`", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2OTkxNA=="}, "originalCommit": null, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjE5Njc2OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzoyOTo0MVrOG9PheA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxMzozMjo0MVrOG-38rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg3MDY0OA==", "bodyText": "...push it to your preferred container registry, e.g. quay.io or Docker Hub, by...", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466870648", "createdAt": "2020-08-07T07:29:41Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----\n \n-Next, deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the {prodname} connectors installed:\n-\n+. Deploy a Kafka broker cluster:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n-# Deploy an ephemeral single instance Kafka broker\n+# Deploy an ephemeral single instance Kafka broker:\n oc process strimzi-ephemeral -p CLUSTER_NAME=broker -p ZOOKEEPER_NODE_COUNT=1 -p KAFKA_NODE_COUNT=1 -p KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 | oc apply -f -\n+----\n \n-# Deploy a single instance of Kafka Connect with no plug-in installed\n-oc process strimzi-connect-s2i -p CLUSTER_NAME=debezium -p KAFKA_CONNECT_BOOTSTRAP_SERVERS=broker-kafka-bootstrap:9092 -p KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false -p KAFKA_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false | oc apply -f -\n+. Create a Kafka Connect image with the {prodname} connectors installed:\n \n-# Build a Debezium image\n-export DEBEZIUM_VERSION={debezium-version}\n-mkdir -p plugins && cd plugins && \\\n-for PLUGIN in {mongodb,mysql,postgres}; do \\\n-    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \\\n-done && \\\n-oc start-build debezium-connect --from-dir=. --follow && \\\n-cd .. && rm -rf plugins\n+.. Download and extract the archive for each {prodname} connector you want to run. For example: \n++\n+[source,options=\"nowrap\"]\n+----\n+curl https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.1.0.Final/debezium-connector-mysql-1.1.0.Final-plugin.tar.gz tar xvz`\n ----\n \n-After a while all parts should be up and running:\n+.. Create a `Dockerfile` that uses a Strimzi Kafka image as the base image. The following example creates a `plugins/debezium` directory, which would contain a directory for each {prodname} connector that you want to run. To run more than one {prodname} connector, insert a `COPY` line for each connector. \n++\n+[subs=+macros]\n+----\n+FROM strimzi/kafka:0.19.0-kafka-2.5.0\n+USER root:root\n+RUN mkdir -p /opt/kafka/plugins/debezium\n+COPY ./debezium-connector-mysql/ /opt/kafka/plugins/debezium/\n+USER 1001\n+----\n++\n+Before Kafka Connect starts running the connector, Kafka Connect loads any third-party plug-ins that are in the `/opt/kafka/plugins` directory.\n \n+.. Build a Debezium image from your Dockerfile and push it to Docker Hub by executing the following commands. Replace `debezium-community` with the name of your Docker Hub organization. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODU4MTU1MA==", "bodyText": "I updated that to the following. Let me know if this needs to change:\nBuild a Debezium image from your Dockerfile and push it to your preferred container registry, for example, quay.io or Docker Hub, by executing the following commands.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r468581550", "createdAt": "2020-08-11T13:32:41Z", "author": {"login": "TovaCohen"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----\n \n-Next, deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the {prodname} connectors installed:\n-\n+. Deploy a Kafka broker cluster:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n-# Deploy an ephemeral single instance Kafka broker\n+# Deploy an ephemeral single instance Kafka broker:\n oc process strimzi-ephemeral -p CLUSTER_NAME=broker -p ZOOKEEPER_NODE_COUNT=1 -p KAFKA_NODE_COUNT=1 -p KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 | oc apply -f -\n+----\n \n-# Deploy a single instance of Kafka Connect with no plug-in installed\n-oc process strimzi-connect-s2i -p CLUSTER_NAME=debezium -p KAFKA_CONNECT_BOOTSTRAP_SERVERS=broker-kafka-bootstrap:9092 -p KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false -p KAFKA_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false | oc apply -f -\n+. Create a Kafka Connect image with the {prodname} connectors installed:\n \n-# Build a Debezium image\n-export DEBEZIUM_VERSION={debezium-version}\n-mkdir -p plugins && cd plugins && \\\n-for PLUGIN in {mongodb,mysql,postgres}; do \\\n-    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \\\n-done && \\\n-oc start-build debezium-connect --from-dir=. --follow && \\\n-cd .. && rm -rf plugins\n+.. Download and extract the archive for each {prodname} connector you want to run. For example: \n++\n+[source,options=\"nowrap\"]\n+----\n+curl https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.1.0.Final/debezium-connector-mysql-1.1.0.Final-plugin.tar.gz tar xvz`\n ----\n \n-After a while all parts should be up and running:\n+.. Create a `Dockerfile` that uses a Strimzi Kafka image as the base image. The following example creates a `plugins/debezium` directory, which would contain a directory for each {prodname} connector that you want to run. To run more than one {prodname} connector, insert a `COPY` line for each connector. \n++\n+[subs=+macros]\n+----\n+FROM strimzi/kafka:0.19.0-kafka-2.5.0\n+USER root:root\n+RUN mkdir -p /opt/kafka/plugins/debezium\n+COPY ./debezium-connector-mysql/ /opt/kafka/plugins/debezium/\n+USER 1001\n+----\n++\n+Before Kafka Connect starts running the connector, Kafka Connect loads any third-party plug-ins that are in the `/opt/kafka/plugins` directory.\n \n+.. Build a Debezium image from your Dockerfile and push it to Docker Hub by executing the following commands. Replace `debezium-community` with the name of your Docker Hub organization. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg3MDY0OA=="}, "originalCommit": null, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjIwMDQ2OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzozMDo1NFrOG9Pjuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzozMDo1NFrOG9Pjuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg3MTIyNw==", "bodyText": "...on Kubernetes or OpenShift...", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466871227", "createdAt": "2020-08-07T07:30:54Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -215,17 +234,17 @@ You should see an output like the following (formatted for the sake of readabili\n ...\n ----\n \n-Finally, the next example modifies some records in the `customers` table of the database:\n-\n+. Modify some records in the `customers` table of the database:\n++\n [source%nowrap,bash]\n ----\n oc exec -it $(oc get pods -o custom-columns=NAME:.metadata.name --no-headers -l app=mysql) \\\n     -- bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory'\n \n # For example, run UPDATE customers SET email=\"sally.thomas@example.com\" WHERE ID = 1001;\n ----\n-\n-You should now see additional change messages in the consumer started before.\n++\n+You should now see additional change messages in the consumer started previousl.\n \n If you have any questions or requests related to running {prodname} on OpenShift,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 200}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4255, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}