{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4MDA1NzUy", "number": 1721, "title": "DBZ-1908 Replacement PR, update doc for installing Debezium on OpenShift", "bodyText": "https://issues.redhat.com/browse/DBZ-1908\n@jcechace\nI messed up the previous PR, #1706.\nSo I closed it.\nThis is a new PR with the same updates and also I removed references to minishift. I also removed the reference to the example that uses minishift.\nThis is still missing a Dockerfile. I don't know what the content of the Dockerfile should be.", "createdAt": "2020-07-28T19:29:04Z", "url": "https://github.com/debezium/debezium/pull/1721", "merged": true, "mergeCommit": {"oid": "de95cd46cae3377948ac90abd19be6006b3ea896"}, "closed": true, "closedAt": "2020-08-13T05:51:45Z", "author": {"login": "TovaCohen"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc7UiUYABqjM2MTY2NjQwNjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc-HUMpgFqTQ2NTcwOTI5MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYzMDg5NjQ3", "url": "https://github.com/debezium/debezium/pull/1721#pullrequestreview-463089647", "createdAt": "2020-08-07T07:22:46Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzoyMjo0NlrOG9PUoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNzozMDo1NFrOG9Pjuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2NzM2MA==", "bodyText": "Should reference the the Strimzi version variable.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466867360", "createdAt": "2020-08-07T07:22:46Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----\n \n-Next, deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the {prodname} connectors installed:\n-\n+. Deploy a Kafka broker cluster:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n-# Deploy an ephemeral single instance Kafka broker\n+# Deploy an ephemeral single instance Kafka broker:\n oc process strimzi-ephemeral -p CLUSTER_NAME=broker -p ZOOKEEPER_NODE_COUNT=1 -p KAFKA_NODE_COUNT=1 -p KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 | oc apply -f -\n+----\n \n-# Deploy a single instance of Kafka Connect with no plug-in installed\n-oc process strimzi-connect-s2i -p CLUSTER_NAME=debezium -p KAFKA_CONNECT_BOOTSTRAP_SERVERS=broker-kafka-bootstrap:9092 -p KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false -p KAFKA_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false | oc apply -f -\n+. Create a Kafka Connect image with the {prodname} connectors installed:\n \n-# Build a Debezium image\n-export DEBEZIUM_VERSION={debezium-version}\n-mkdir -p plugins && cd plugins && \\\n-for PLUGIN in {mongodb,mysql,postgres}; do \\\n-    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \\\n-done && \\\n-oc start-build debezium-connect --from-dir=. --follow && \\\n-cd .. && rm -rf plugins\n+.. Download and extract the archive for each {prodname} connector you want to run. For example: \n++\n+[source,options=\"nowrap\"]\n+----\n+curl https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.1.0.Final/debezium-connector-mysql-1.1.0.Final-plugin.tar.gz tar xvz`\n ----\n \n-After a while all parts should be up and running:\n+.. Create a `Dockerfile` that uses a Strimzi Kafka image as the base image. The following example creates a `plugins/debezium` directory, which would contain a directory for each {prodname} connector that you want to run. To run more than one {prodname} connector, insert a `COPY` line for each connector. \n++\n+[subs=+macros]\n+----\n+FROM strimzi/kafka:0.19.0-kafka-2.5.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2NzU4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You should now see additional change messages in the consumer started previousl.\n          \n          \n            \n            You should now see additional change messages in the consumer started previously.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466867581", "createdAt": "2020-08-07T07:23:17Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -215,17 +234,17 @@ You should see an output like the following (formatted for the sake of readabili\n ...\n ----\n \n-Finally, the next example modifies some records in the `customers` table of the database:\n-\n+. Modify some records in the `customers` table of the database:\n++\n [source%nowrap,bash]\n ----\n oc exec -it $(oc get pods -o custom-columns=NAME:.metadata.name --no-headers -l app=mysql) \\\n     -- bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory'\n \n # For example, run UPDATE customers SET email=\"sally.thomas@example.com\" WHERE ID = 1001;\n ----\n-\n-You should now see additional change messages in the consumer started before.\n++\n+You should now see additional change messages in the consumer started previousl.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2ODM4Ng==", "bodyText": "Can you add a sentence along the lines of \"These instructions should work equally on any other Kubernetes distribution, using the kubectl command\".", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466868386", "createdAt": "2020-08-07T07:25:01Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2ODgwNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n          \n          \n            \n            To set up Apache Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to Kubernetes and OpenShift, as well as Kubernetes operators for running Kafka there.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466868804", "createdAt": "2020-08-07T07:25:57Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2OTU1Mw==", "bodyText": "After that, a link like this would be nice: \"To learn more about setting up Apache Kafka with Strimzi on Kubernetes and OpenShift, refer to the [right part of strimzi doc link]\".", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466869553", "createdAt": "2020-08-07T07:27:37Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg2OTkxNA==", "bodyText": "1.1.0.Final should be the Debezium version variable instead. Let's generally avoid any hard-coded version numbers, there should be variables for all of them.", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466869914", "createdAt": "2020-08-07T07:28:17Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----\n \n-Next, deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the {prodname} connectors installed:\n-\n+. Deploy a Kafka broker cluster:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n-# Deploy an ephemeral single instance Kafka broker\n+# Deploy an ephemeral single instance Kafka broker:\n oc process strimzi-ephemeral -p CLUSTER_NAME=broker -p ZOOKEEPER_NODE_COUNT=1 -p KAFKA_NODE_COUNT=1 -p KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 | oc apply -f -\n+----\n \n-# Deploy a single instance of Kafka Connect with no plug-in installed\n-oc process strimzi-connect-s2i -p CLUSTER_NAME=debezium -p KAFKA_CONNECT_BOOTSTRAP_SERVERS=broker-kafka-bootstrap:9092 -p KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false -p KAFKA_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false | oc apply -f -\n+. Create a Kafka Connect image with the {prodname} connectors installed:\n \n-# Build a Debezium image\n-export DEBEZIUM_VERSION={debezium-version}\n-mkdir -p plugins && cd plugins && \\\n-for PLUGIN in {mongodb,mysql,postgres}; do \\\n-    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \\\n-done && \\\n-oc start-build debezium-connect --from-dir=. --follow && \\\n-cd .. && rm -rf plugins\n+.. Download and extract the archive for each {prodname} connector you want to run. For example: \n++\n+[source,options=\"nowrap\"]\n+----\n+curl https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.1.0.Final/debezium-connector-mysql-1.1.0.Final-plugin.tar.gz tar xvz`", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg3MDY0OA==", "bodyText": "...push it to your preferred container registry, e.g. quay.io or Docker Hub, by...", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466870648", "createdAt": "2020-08-07T07:29:41Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -8,56 +8,75 @@\n \n toc::[]\n \n-The following describes how to set up the {prodname} connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.\n+This procedure is for setting up {prodname} connectors on Red Hat's link:https://www.openshift.com/[OpenShift] container platform. These instructions have been tested with the two most recent releases of OpenShift. \n \n-These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]\n--- allowing you to run a single node OpenShift instance locally on your machine.\n+To get started more quickly, try the link:https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n+It starts an OpenShift cluster just for you, which lets you start using {prodname} in your browser within a few minutes.\n \n-You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].\n+== {prodname} Deployment\n \n-And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[{prodname} online learning scenario].\n-It starts an OpenShift cluster just for you, allowing you to take your first steps with {prodname} in your browser just within a few minutes.\n+To set up Kafka and Kafka Connect on OpenShift, use the set of images that are provided by the link:https://strimzi.io/[Strimzi] project. These images offer \"Kafka as a Service\" by providing enterprise grade configuration files and images that bring Kafka to OpenShift.\n \n-== {prodname} Deployment\n+.Prerequisites\n \n-For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers \"Kafka as a Service\".\n-It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.\n+* The OpenShift command line interface (`oc`) is installed.\n+* Docker is installed. \n \n-First, install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project:\n+.Procedure\n \n+. In your OpenShift project, enter the following commands to install the operators and templates for the Kafka broker and Kafka Connect:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n export STRIMZI_VERSION={strimzi-version}\n git clone -b $STRIMZI_VERSION https://github.com/strimzi/strimzi-kafka-operator\n cd strimzi-kafka-operator\n \n-# We need to create security objects as part of installation so it is necessary to switch to admin user\n+# Switch to an admin user to create security objects as part of installation:\n oc login -u system:admin\n oc create -f install/cluster-operator && oc create -f examples/templates/cluster-operator\n ----\n \n-Next, deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the {prodname} connectors installed:\n-\n+. Deploy a Kafka broker cluster:\n++\n [source,shell,subs=\"attributes\",options=\"nowrap\"]\n ----\n-# Deploy an ephemeral single instance Kafka broker\n+# Deploy an ephemeral single instance Kafka broker:\n oc process strimzi-ephemeral -p CLUSTER_NAME=broker -p ZOOKEEPER_NODE_COUNT=1 -p KAFKA_NODE_COUNT=1 -p KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 | oc apply -f -\n+----\n \n-# Deploy a single instance of Kafka Connect with no plug-in installed\n-oc process strimzi-connect-s2i -p CLUSTER_NAME=debezium -p KAFKA_CONNECT_BOOTSTRAP_SERVERS=broker-kafka-bootstrap:9092 -p KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 -p KAFKA_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false -p KAFKA_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false | oc apply -f -\n+. Create a Kafka Connect image with the {prodname} connectors installed:\n \n-# Build a Debezium image\n-export DEBEZIUM_VERSION={debezium-version}\n-mkdir -p plugins && cd plugins && \\\n-for PLUGIN in {mongodb,mysql,postgres}; do \\\n-    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \\\n-done && \\\n-oc start-build debezium-connect --from-dir=. --follow && \\\n-cd .. && rm -rf plugins\n+.. Download and extract the archive for each {prodname} connector you want to run. For example: \n++\n+[source,options=\"nowrap\"]\n+----\n+curl https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.1.0.Final/debezium-connector-mysql-1.1.0.Final-plugin.tar.gz tar xvz`\n ----\n \n-After a while all parts should be up and running:\n+.. Create a `Dockerfile` that uses a Strimzi Kafka image as the base image. The following example creates a `plugins/debezium` directory, which would contain a directory for each {prodname} connector that you want to run. To run more than one {prodname} connector, insert a `COPY` line for each connector. \n++\n+[subs=+macros]\n+----\n+FROM strimzi/kafka:0.19.0-kafka-2.5.0\n+USER root:root\n+RUN mkdir -p /opt/kafka/plugins/debezium\n+COPY ./debezium-connector-mysql/ /opt/kafka/plugins/debezium/\n+USER 1001\n+----\n++\n+Before Kafka Connect starts running the connector, Kafka Connect loads any third-party plug-ins that are in the `/opt/kafka/plugins` directory.\n \n+.. Build a Debezium image from your Dockerfile and push it to Docker Hub by executing the following commands. Replace `debezium-community` with the name of your Docker Hub organization. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg3MTIyNw==", "bodyText": "...on Kubernetes or OpenShift...", "url": "https://github.com/debezium/debezium/pull/1721#discussion_r466871227", "createdAt": "2020-08-07T07:30:54Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/openshift.adoc", "diffHunk": "@@ -215,17 +234,17 @@ You should see an output like the following (formatted for the sake of readabili\n ...\n ----\n \n-Finally, the next example modifies some records in the `customers` table of the database:\n-\n+. Modify some records in the `customers` table of the database:\n++\n [source%nowrap,bash]\n ----\n oc exec -it $(oc get pods -o custom-columns=NAME:.metadata.name --no-headers -l app=mysql) \\\n     -- bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory'\n \n # For example, run UPDATE customers SET email=\"sally.thomas@example.com\" WHERE ID = 1001;\n ----\n-\n-You should now see additional change messages in the consumer started before.\n++\n+You should now see additional change messages in the consumer started previousl.\n \n If you have any questions or requests related to running {prodname} on OpenShift,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 200}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d8dae084f4ad9f5cc7c08dd1216e14e5bc316712", "author": {"user": {"login": "TovaCohen", "name": null}}, "url": "https://github.com/debezium/debezium/commit/d8dae084f4ad9f5cc7c08dd1216e14e5bc316712", "committedDate": "2020-08-11T13:10:59Z", "message": "DBZ-1908 Replacement PR, removes references to minishift"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2d4bc94851510887652fe757075c8a8ef3f8e042", "author": {"user": {"login": "TovaCohen", "name": null}}, "url": "https://github.com/debezium/debezium/commit/2d4bc94851510887652fe757075c8a8ef3f8e042", "committedDate": "2020-08-11T13:10:59Z", "message": "DBZ-1908 Replaced dockerfile and EXPORT section by using Strimzi blog procedure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a1f0c3d58225708599b79cc5d60e84cc6969595", "author": {"user": {"login": "TovaCohen", "name": null}}, "url": "https://github.com/debezium/debezium/commit/0a1f0c3d58225708599b79cc5d60e84cc6969595", "committedDate": "2020-08-11T13:44:36Z", "message": "DBZ-1908 Updates based on Gunnar's review, adds Kubernetes notes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "0a1f0c3d58225708599b79cc5d60e84cc6969595", "author": {"user": {"login": "TovaCohen", "name": null}}, "url": "https://github.com/debezium/debezium/commit/0a1f0c3d58225708599b79cc5d60e84cc6969595", "committedDate": "2020-08-11T13:44:36Z", "message": "DBZ-1908 Updates based on Gunnar's review, adds Kubernetes notes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b93117b8c26047676b3d2c16c3a0f020c6b131b", "author": {"user": {"login": "TovaCohen", "name": null}}, "url": "https://github.com/debezium/debezium/commit/2b93117b8c26047676b3d2c16c3a0f020c6b131b", "committedDate": "2020-08-11T14:14:32Z", "message": "DBZ-1908 Added \"version\" and \"connector\" fields to change event examples"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NzA5Mjkw", "url": "https://github.com/debezium/debezium/pull/1721#pullrequestreview-465709290", "createdAt": "2020-08-12T08:40:48Z", "commit": {"oid": "2b93117b8c26047676b3d2c16c3a0f020c6b131b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2527, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}