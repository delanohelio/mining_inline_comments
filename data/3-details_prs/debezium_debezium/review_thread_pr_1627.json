{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM3MDY5MTg4", "number": 1627, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNTozMjo0MlrOEHKAow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMzoyNToxN1rOEYDS4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTM5NDkxOnYy", "diffSide": "RIGHT", "path": "debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNTozMjo0MlrOGmY9Nw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMzoyMjoyMlrOHALQ5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjkwNzk1OQ==", "bodyText": "@gunnarmorling I\u2019ve been thinking about your comments about synchronization on #1596 and I think I still need some clarification.  Just wrapping all access to the streamingSource with synchronization blocks inline in the ChangeEventSourceCoordinator#start and ChangeEventSourceCoordinator#commitOffset methods wouldn\u2019t protect from a race condition between the offset commit and the catch up streaming deactivation by setting streamingSource to null.\nThere are a couple options that I\u2019ve looked at other than using the ReentrantLock:\nA new synchronized function could be added here that handles both the null check and streamingSource.commitOffset(offset) call in ChangeEventSourceCoordinator#commitOffset and the streamingSource = null deactivation in ChangeEventSourceCoordinator#start. Personally, this feels unnecessarily complex and would be difficult to integrate with the other calls to streamingSource.\nOR\nA separate object stored in an instance variable could be use as a lock to synchronize on.\nObject streamingSourceLock = new Object();\n ...\npublic void commitOffset(Map<String, ?> offset) {\n    synchronized (streamingSourceLock) {\n        if (streamingSource != null && offset != null) {\n            streamingSource.commitOffset(offset);\n        }\n    }\n}\n\nSince BaseSourceTask has access to the executing ChangeEventSourceCoordinator reference, both threads should synchronize correctly. That said, I feel using a generic Object as a lock is unidiomatic compared to the ReentrantLock and I like the ReentrantLock because it highlights where the race condition might occur.\nThoughts?", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r442907959", "createdAt": "2020-06-19T15:32:42Z", "author": {"login": "grantcooksey"}, "path": "debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java", "diffHunk": "@@ -122,8 +126,23 @@ public ChangeEventSourceCoordinator(OffsetContext previousOffset, ErrorHandler e\n         });\n     }\n \n+    protected CatchUpStreamingResult executeCatchUpStreaming(OffsetContext previousOffset, ChangeEventSourceContext context,\n+                                                             SnapshotChangeEventSource snapshotSource)\n+            throws InterruptedException {\n+        return new CatchUpStreamingResult(false);\n+    }\n+\n+    protected void streamEvents(OffsetContext offsetContext, ChangeEventSourceContext context) throws InterruptedException {\n+        streamingSource = changeEventSourceFactory.getStreamingChangeEventSource(offsetContext);\n+        eventDispatcher.setEventListener(streamingMetrics);\n+        streamingMetrics.connected(true);\n+        LOGGER.info(\"Starting streaming\");\n+        streamingSource.execute(context);\n+        LOGGER.info(\"Finished streaming\");\n+    }\n+\n     public void commitOffset(Map<String, ?> offset) {\n-        if (streamingSource != null && offset != null) {\n+        if (!commitOffsetLock.isLocked() && streamingSource != null && offset != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e476511de3292696d9562182fd8f5c2c26cece5"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgyNzk3MA==", "bodyText": "Getting back to this, now that 1.2 Final is out :)\nGood point, if the object can be set to null, we cannot synchronize on it. An alternative would be to declare the methods themselves as sychronized (or extract reasonably scoped methods), in which case the entire coordinator instance itself would be the synchronization object.", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r445827970", "createdAt": "2020-06-25T20:45:41Z", "author": {"login": "gunnarmorling"}, "path": "debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java", "diffHunk": "@@ -122,8 +126,23 @@ public ChangeEventSourceCoordinator(OffsetContext previousOffset, ErrorHandler e\n         });\n     }\n \n+    protected CatchUpStreamingResult executeCatchUpStreaming(OffsetContext previousOffset, ChangeEventSourceContext context,\n+                                                             SnapshotChangeEventSource snapshotSource)\n+            throws InterruptedException {\n+        return new CatchUpStreamingResult(false);\n+    }\n+\n+    protected void streamEvents(OffsetContext offsetContext, ChangeEventSourceContext context) throws InterruptedException {\n+        streamingSource = changeEventSourceFactory.getStreamingChangeEventSource(offsetContext);\n+        eventDispatcher.setEventListener(streamingMetrics);\n+        streamingMetrics.connected(true);\n+        LOGGER.info(\"Starting streaming\");\n+        streamingSource.execute(context);\n+        LOGGER.info(\"Finished streaming\");\n+    }\n+\n     public void commitOffset(Map<String, ?> offset) {\n-        if (streamingSource != null && offset != null) {\n+        if (!commitOffsetLock.isLocked() && streamingSource != null && offset != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjkwNzk1OQ=="}, "originalCommit": {"oid": "9e476511de3292696d9562182fd8f5c2c26cece5"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzIwNjk5OQ==", "bodyText": "Sorry for the slow response here, got caught up with work!\nCould you clarify what you mean by synchronizing the methods? The start method is already synchronized and since streaming occurs there, any thread that calls start won't leave the method until the connector shuts down.  Adding another synchronized method to this class sounds like that would introduce a deadlock.", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r453206999", "createdAt": "2020-07-11T15:43:28Z", "author": {"login": "grantcooksey"}, "path": "debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java", "diffHunk": "@@ -122,8 +126,23 @@ public ChangeEventSourceCoordinator(OffsetContext previousOffset, ErrorHandler e\n         });\n     }\n \n+    protected CatchUpStreamingResult executeCatchUpStreaming(OffsetContext previousOffset, ChangeEventSourceContext context,\n+                                                             SnapshotChangeEventSource snapshotSource)\n+            throws InterruptedException {\n+        return new CatchUpStreamingResult(false);\n+    }\n+\n+    protected void streamEvents(OffsetContext offsetContext, ChangeEventSourceContext context) throws InterruptedException {\n+        streamingSource = changeEventSourceFactory.getStreamingChangeEventSource(offsetContext);\n+        eventDispatcher.setEventListener(streamingMetrics);\n+        streamingMetrics.connected(true);\n+        LOGGER.info(\"Starting streaming\");\n+        streamingSource.execute(context);\n+        LOGGER.info(\"Finished streaming\");\n+    }\n+\n     public void commitOffset(Map<String, ?> offset) {\n-        if (streamingSource != null && offset != null) {\n+        if (!commitOffsetLock.isLocked() && streamingSource != null && offset != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjkwNzk1OQ=="}, "originalCommit": {"oid": "9e476511de3292696d9562182fd8f5c2c26cece5"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0NjU5Nw==", "bodyText": "@grantcooksey, I was a bit misled and missed that all this code runs async via the separate executor, i.e. the sychronized definition of start() doesn't impact it at all. I think your proposed solution is good.", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r469946597", "createdAt": "2020-08-13T13:22:22Z", "author": {"login": "gunnarmorling"}, "path": "debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java", "diffHunk": "@@ -122,8 +126,23 @@ public ChangeEventSourceCoordinator(OffsetContext previousOffset, ErrorHandler e\n         });\n     }\n \n+    protected CatchUpStreamingResult executeCatchUpStreaming(OffsetContext previousOffset, ChangeEventSourceContext context,\n+                                                             SnapshotChangeEventSource snapshotSource)\n+            throws InterruptedException {\n+        return new CatchUpStreamingResult(false);\n+    }\n+\n+    protected void streamEvents(OffsetContext offsetContext, ChangeEventSourceContext context) throws InterruptedException {\n+        streamingSource = changeEventSourceFactory.getStreamingChangeEventSource(offsetContext);\n+        eventDispatcher.setEventListener(streamingMetrics);\n+        streamingMetrics.connected(true);\n+        LOGGER.info(\"Starting streaming\");\n+        streamingSource.execute(context);\n+        LOGGER.info(\"Finished streaming\");\n+    }\n+\n     public void commitOffset(Map<String, ?> offset) {\n-        if (streamingSource != null && offset != null) {\n+        if (!commitOffsetLock.isLocked() && streamingSource != null && offset != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjkwNzk1OQ=="}, "originalCommit": {"oid": "9e476511de3292696d9562182fd8f5c2c26cece5"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzNjQ5NzMyOnYy", "diffSide": "RIGHT", "path": "debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMzoxMjowMFrOHAK2nw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQyMzowNToyNlrOHBOJJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTkzOTg3MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                // teh phase can stream event up to a specific lsn and the snapshot that occurs after the catch up\n          \n          \n            \n                                // the phase can stream event up to a specific lsn and the snapshot that occurs after the catch up", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r469939871", "createdAt": "2020-08-13T13:12:00Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java", "diffHunk": "@@ -191,7 +198,13 @@ else if (message.getOperation() == Operation.COMMIT) {\n                         pauseNoMessage.sleepWhen(true);\n                     }\n                 }\n-                connection.commit();\n+                if (!isInPreSnapshotCatchUpStreaming()) {\n+                    // During catch up streaming, the streaming phase needs to hold a transaction open so that\n+                    // teh phase can stream event up to a specific lsn and the snapshot that occurs after the catch up", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0MjM0Mw==", "bodyText": "Fixed in 3a9f502", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r471042343", "createdAt": "2020-08-15T23:05:26Z", "author": {"login": "grantcooksey"}, "path": "debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java", "diffHunk": "@@ -191,7 +198,13 @@ else if (message.getOperation() == Operation.COMMIT) {\n                         pauseNoMessage.sleepWhen(true);\n                     }\n                 }\n-                connection.commit();\n+                if (!isInPreSnapshotCatchUpStreaming()) {\n+                    // During catch up streaming, the streaming phase needs to hold a transaction open so that\n+                    // teh phase can stream event up to a specific lsn and the snapshot that occurs after the catch up", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTkzOTg3MQ=="}, "originalCommit": null, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzNjUwNzAyOnYy", "diffSide": "RIGHT", "path": "debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMzoxNDoxNlrOHAK8gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwODo0NDoyMVrOHO9D_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0MTM3OA==", "bodyText": "Where is the test asserting the duplicated events? IIUC, we should see two change events for each record, one from the catch-up streaming phase, and one from the new snapshot. I.e. four events overall?\nBtw. it'd be nice to add a test for the actual value proposition of this change: a custom snapshotter which snaphots an additional table. WDYT?", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r469941378", "createdAt": "2020-08-13T13:14:16Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java", "diffHunk": "@@ -1169,6 +1169,55 @@ public void shouldPeformSnapshotOnceForInitialOnlySnapshotMode() throws Exceptio\n         stopConnector(value -> assertThat(logInterceptor.containsMessage(\"Previous initial snapshot completed, no snapshot will be performed\")).isTrue());\n     }\n \n+    @Test\n+    @FixFor(\"DBZ-2094\")\n+    public void shouldResumeStreamingFromSlotPositionForCustomSnapshot() throws Exception {\n+        TestHelper.execute(SETUP_TABLES_STMT);\n+        // Perform an empty snapshot\n+        Configuration config = TestHelper.defaultConfig()\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.CUSTOM.getValue())\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE_CLASS, CustomStartFromStreamingTestSnapshot.class.getName())\n+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)\n+                .build();\n+        start(PostgresConnector.class, config);\n+        assertConnectorIsRunning();\n+        waitForStreamingRunning();\n+\n+        SourceRecords actualRecords = consumeRecordsByTopic(2);\n+        List<SourceRecord> s1recs = actualRecords.recordsForTopic(topicName(\"s1.a\"));\n+        List<SourceRecord> s2recs = actualRecords.recordsForTopic(topicName(\"s2.a\"));\n+        assertThat(s1recs.size()).isEqualTo(1);\n+        assertThat(s2recs.size()).isEqualTo(1);\n+        VerifyRecord.isValidRead(s1recs.get(0), PK_FIELD, 1);\n+        VerifyRecord.isValidRead(s2recs.get(0), PK_FIELD, 1);\n+\n+        stopConnector();\n+\n+        // Insert records while connector is stopped\n+        TestHelper.execute(INSERT_STMT);\n+        config = TestHelper.defaultConfig()\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.CUSTOM.getValue())\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE_CLASS, CustomStartFromStreamingTestSnapshot.class.getName())\n+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)\n+                .build();\n+        start(PostgresConnector.class, config);\n+        assertConnectorIsRunning();\n+\n+        waitForSnapshotToBeCompleted();\n+\n+        // Expect duplicate records from the snapshot and while streaming is running", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0MjU1OQ==", "bodyText": "Yupp, good catch! I adjusted the test to assert duplicated events.\nI agree that a test covering a partial snapshot is a good idea, I added another test.", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r471042559", "createdAt": "2020-08-15T23:09:11Z", "author": {"login": "grantcooksey"}, "path": "debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java", "diffHunk": "@@ -1169,6 +1169,55 @@ public void shouldPeformSnapshotOnceForInitialOnlySnapshotMode() throws Exceptio\n         stopConnector(value -> assertThat(logInterceptor.containsMessage(\"Previous initial snapshot completed, no snapshot will be performed\")).isTrue());\n     }\n \n+    @Test\n+    @FixFor(\"DBZ-2094\")\n+    public void shouldResumeStreamingFromSlotPositionForCustomSnapshot() throws Exception {\n+        TestHelper.execute(SETUP_TABLES_STMT);\n+        // Perform an empty snapshot\n+        Configuration config = TestHelper.defaultConfig()\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.CUSTOM.getValue())\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE_CLASS, CustomStartFromStreamingTestSnapshot.class.getName())\n+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)\n+                .build();\n+        start(PostgresConnector.class, config);\n+        assertConnectorIsRunning();\n+        waitForStreamingRunning();\n+\n+        SourceRecords actualRecords = consumeRecordsByTopic(2);\n+        List<SourceRecord> s1recs = actualRecords.recordsForTopic(topicName(\"s1.a\"));\n+        List<SourceRecord> s2recs = actualRecords.recordsForTopic(topicName(\"s2.a\"));\n+        assertThat(s1recs.size()).isEqualTo(1);\n+        assertThat(s2recs.size()).isEqualTo(1);\n+        VerifyRecord.isValidRead(s1recs.get(0), PK_FIELD, 1);\n+        VerifyRecord.isValidRead(s2recs.get(0), PK_FIELD, 1);\n+\n+        stopConnector();\n+\n+        // Insert records while connector is stopped\n+        TestHelper.execute(INSERT_STMT);\n+        config = TestHelper.defaultConfig()\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.CUSTOM.getValue())\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE_CLASS, CustomStartFromStreamingTestSnapshot.class.getName())\n+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)\n+                .build();\n+        start(PostgresConnector.class, config);\n+        assertConnectorIsRunning();\n+\n+        waitForSnapshotToBeCompleted();\n+\n+        // Expect duplicate records from the snapshot and while streaming is running", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0MTM3OA=="}, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTQ0MjU1Nw==", "bodyText": "Cool, thanks!", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r485442557", "createdAt": "2020-09-09T08:44:21Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java", "diffHunk": "@@ -1169,6 +1169,55 @@ public void shouldPeformSnapshotOnceForInitialOnlySnapshotMode() throws Exceptio\n         stopConnector(value -> assertThat(logInterceptor.containsMessage(\"Previous initial snapshot completed, no snapshot will be performed\")).isTrue());\n     }\n \n+    @Test\n+    @FixFor(\"DBZ-2094\")\n+    public void shouldResumeStreamingFromSlotPositionForCustomSnapshot() throws Exception {\n+        TestHelper.execute(SETUP_TABLES_STMT);\n+        // Perform an empty snapshot\n+        Configuration config = TestHelper.defaultConfig()\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.CUSTOM.getValue())\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE_CLASS, CustomStartFromStreamingTestSnapshot.class.getName())\n+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)\n+                .build();\n+        start(PostgresConnector.class, config);\n+        assertConnectorIsRunning();\n+        waitForStreamingRunning();\n+\n+        SourceRecords actualRecords = consumeRecordsByTopic(2);\n+        List<SourceRecord> s1recs = actualRecords.recordsForTopic(topicName(\"s1.a\"));\n+        List<SourceRecord> s2recs = actualRecords.recordsForTopic(topicName(\"s2.a\"));\n+        assertThat(s1recs.size()).isEqualTo(1);\n+        assertThat(s2recs.size()).isEqualTo(1);\n+        VerifyRecord.isValidRead(s1recs.get(0), PK_FIELD, 1);\n+        VerifyRecord.isValidRead(s2recs.get(0), PK_FIELD, 1);\n+\n+        stopConnector();\n+\n+        // Insert records while connector is stopped\n+        TestHelper.execute(INSERT_STMT);\n+        config = TestHelper.defaultConfig()\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.CUSTOM.getValue())\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE_CLASS, CustomStartFromStreamingTestSnapshot.class.getName())\n+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)\n+                .build();\n+        start(PostgresConnector.class, config);\n+        assertConnectorIsRunning();\n+\n+        waitForSnapshotToBeCompleted();\n+\n+        // Expect duplicate records from the snapshot and while streaming is running", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0MTM3OA=="}, "originalCommit": null, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzNjU1MjY1OnYy", "diffSide": "RIGHT", "path": "debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresOffsetContext.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMzoyNToxN1rOHALYOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwODo0NDozMlrOHO9Eig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0ODQ3NQ==", "bodyText": "@jpechane has a concurrent PR where we replace LSN representation from Long to a dedicated LSN type. Depending on which PR gets merged first, this one here should change to that new type, too. Just a heads-up, nothing to act on just yet.", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r469948475", "createdAt": "2020-08-13T13:25:17Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresOffsetContext.java", "diffHunk": "@@ -146,6 +147,21 @@ Long lastCompletelyProcessedLsn() {\n         return lastCompletelyProcessedLsn;\n     }\n \n+    /**\n+     * Returns the LSN that the streaming phase should stream events up to or null if\n+     * a stopping point is not set. If set during the streaming phase, any event with\n+     * an LSN less than the stopping LSN will be processed and once the stopping LSN\n+     * is reached, the streaming phase will end. Useful for a pre-snapshot catch up\n+     * streaming phase.\n+     */\n+    Long getStreamingStoppingLsn() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzI4MzAxNA==", "bodyText": "I saw #1751 was merged and I've added those changes here.", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r477283014", "createdAt": "2020-08-26T13:03:45Z", "author": {"login": "grantcooksey"}, "path": "debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresOffsetContext.java", "diffHunk": "@@ -146,6 +147,21 @@ Long lastCompletelyProcessedLsn() {\n         return lastCompletelyProcessedLsn;\n     }\n \n+    /**\n+     * Returns the LSN that the streaming phase should stream events up to or null if\n+     * a stopping point is not set. If set during the streaming phase, any event with\n+     * an LSN less than the stopping LSN will be processed and once the stopping LSN\n+     * is reached, the streaming phase will end. Useful for a pre-snapshot catch up\n+     * streaming phase.\n+     */\n+    Long getStreamingStoppingLsn() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0ODQ3NQ=="}, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTQ0MjY5OA==", "bodyText": "Excellent, thanks!", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r485442698", "createdAt": "2020-09-09T08:44:32Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresOffsetContext.java", "diffHunk": "@@ -146,6 +147,21 @@ Long lastCompletelyProcessedLsn() {\n         return lastCompletelyProcessedLsn;\n     }\n \n+    /**\n+     * Returns the LSN that the streaming phase should stream events up to or null if\n+     * a stopping point is not set. If set during the streaming phase, any event with\n+     * an LSN less than the stopping LSN will be processed and once the stopping LSN\n+     * is reached, the streaming phase will end. Useful for a pre-snapshot catch up\n+     * streaming phase.\n+     */\n+    Long getStreamingStoppingLsn() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0ODQ3NQ=="}, "originalCommit": null, "originalPosition": 19}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4306, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}