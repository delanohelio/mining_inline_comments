{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM3MDY5MTg4", "number": 1627, "title": "DBZ-2094 Allow Postgres snapshotter to set streaming start on resume", "bodyText": "When a connector resumes after previously streaming and takes a\nsnapshot, through a new method on the snapshotter interface,\nshouldStreamEventsStartingFromSnapshot, can choose whether\nto resume streaming from the last known streaming position or the\nbeginning of the snapshot. This is helpful for snapshotters that\nmay not want to resnapshot every table in the whitelist/blacklist\nbut not miss event on the tables that are skipped.\nThis PR was created to address changes requested in #1596", "createdAt": "2020-06-19T12:17:12Z", "url": "https://github.com/debezium/debezium/pull/1627", "merged": true, "mergeCommit": {"oid": "8bcbdb639db7a974e6b8631958386c84fb4d6e18"}, "closed": true, "closedAt": "2020-09-09T08:54:12Z", "author": {"login": "grantcooksey"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcs016ZAFqTQzNDE2ODczMA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdHISPQAFqTQ4NDc5ODE5NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM0MTY4NzMw", "url": "https://github.com/debezium/debezium/pull/1627#pullrequestreview-434168730", "createdAt": "2020-06-19T15:32:42Z", "commit": {"oid": "9e476511de3292696d9562182fd8f5c2c26cece5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNTozMjo0MlrOGmY9Nw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNTozMjo0MlrOGmY9Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjkwNzk1OQ==", "bodyText": "@gunnarmorling I\u2019ve been thinking about your comments about synchronization on #1596 and I think I still need some clarification.  Just wrapping all access to the streamingSource with synchronization blocks inline in the ChangeEventSourceCoordinator#start and ChangeEventSourceCoordinator#commitOffset methods wouldn\u2019t protect from a race condition between the offset commit and the catch up streaming deactivation by setting streamingSource to null.\nThere are a couple options that I\u2019ve looked at other than using the ReentrantLock:\nA new synchronized function could be added here that handles both the null check and streamingSource.commitOffset(offset) call in ChangeEventSourceCoordinator#commitOffset and the streamingSource = null deactivation in ChangeEventSourceCoordinator#start. Personally, this feels unnecessarily complex and would be difficult to integrate with the other calls to streamingSource.\nOR\nA separate object stored in an instance variable could be use as a lock to synchronize on.\nObject streamingSourceLock = new Object();\n ...\npublic void commitOffset(Map<String, ?> offset) {\n    synchronized (streamingSourceLock) {\n        if (streamingSource != null && offset != null) {\n            streamingSource.commitOffset(offset);\n        }\n    }\n}\n\nSince BaseSourceTask has access to the executing ChangeEventSourceCoordinator reference, both threads should synchronize correctly. That said, I feel using a generic Object as a lock is unidiomatic compared to the ReentrantLock and I like the ReentrantLock because it highlights where the race condition might occur.\nThoughts?", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r442907959", "createdAt": "2020-06-19T15:32:42Z", "author": {"login": "grantcooksey"}, "path": "debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java", "diffHunk": "@@ -122,8 +126,23 @@ public ChangeEventSourceCoordinator(OffsetContext previousOffset, ErrorHandler e\n         });\n     }\n \n+    protected CatchUpStreamingResult executeCatchUpStreaming(OffsetContext previousOffset, ChangeEventSourceContext context,\n+                                                             SnapshotChangeEventSource snapshotSource)\n+            throws InterruptedException {\n+        return new CatchUpStreamingResult(false);\n+    }\n+\n+    protected void streamEvents(OffsetContext offsetContext, ChangeEventSourceContext context) throws InterruptedException {\n+        streamingSource = changeEventSourceFactory.getStreamingChangeEventSource(offsetContext);\n+        eventDispatcher.setEventListener(streamingMetrics);\n+        streamingMetrics.connected(true);\n+        LOGGER.info(\"Starting streaming\");\n+        streamingSource.execute(context);\n+        LOGGER.info(\"Finished streaming\");\n+    }\n+\n     public void commitOffset(Map<String, ?> offset) {\n-        if (streamingSource != null && offset != null) {\n+        if (!commitOffsetLock.isLocked() && streamingSource != null && offset != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e476511de3292696d9562182fd8f5c2c26cece5"}, "originalPosition": 65}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9e476511de3292696d9562182fd8f5c2c26cece5", "author": {"user": {"login": "grantcooksey", "name": "Grant Cooksey"}}, "url": "https://github.com/debezium/debezium/commit/9e476511de3292696d9562182fd8f5c2c26cece5", "committedDate": "2020-06-15T10:14:23Z", "message": "DBZ-2094 Allow Postgres snapshotter to set streaming start on resume\n\nWhen a connector resumes after previously streaming and takes a\nsnapshot, through a new method on the snapshotter interface,\nshouldStreamEventsStartingFromSnapshot, can choose whether\nto resume streaming from the last known streaming position or the\nbeginning of the snapshot. This is helpful for snapshotters that\nmay not want to resnapshot every table in the whitelist/blacklist\nbut not miss event on the tables that are skipped."}, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2NzQ2NDIy", "url": "https://github.com/debezium/debezium/pull/1627#pullrequestreview-466746422", "createdAt": "2020-08-13T13:11:59Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMzoxMjowMFrOHAK2nw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMzoyNToxN1rOHALYOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTkzOTg3MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                // teh phase can stream event up to a specific lsn and the snapshot that occurs after the catch up\n          \n          \n            \n                                // the phase can stream event up to a specific lsn and the snapshot that occurs after the catch up", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r469939871", "createdAt": "2020-08-13T13:12:00Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java", "diffHunk": "@@ -191,7 +198,13 @@ else if (message.getOperation() == Operation.COMMIT) {\n                         pauseNoMessage.sleepWhen(true);\n                     }\n                 }\n-                connection.commit();\n+                if (!isInPreSnapshotCatchUpStreaming()) {\n+                    // During catch up streaming, the streaming phase needs to hold a transaction open so that\n+                    // teh phase can stream event up to a specific lsn and the snapshot that occurs after the catch up", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0MTM3OA==", "bodyText": "Where is the test asserting the duplicated events? IIUC, we should see two change events for each record, one from the catch-up streaming phase, and one from the new snapshot. I.e. four events overall?\nBtw. it'd be nice to add a test for the actual value proposition of this change: a custom snapshotter which snaphots an additional table. WDYT?", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r469941378", "createdAt": "2020-08-13T13:14:16Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java", "diffHunk": "@@ -1169,6 +1169,55 @@ public void shouldPeformSnapshotOnceForInitialOnlySnapshotMode() throws Exceptio\n         stopConnector(value -> assertThat(logInterceptor.containsMessage(\"Previous initial snapshot completed, no snapshot will be performed\")).isTrue());\n     }\n \n+    @Test\n+    @FixFor(\"DBZ-2094\")\n+    public void shouldResumeStreamingFromSlotPositionForCustomSnapshot() throws Exception {\n+        TestHelper.execute(SETUP_TABLES_STMT);\n+        // Perform an empty snapshot\n+        Configuration config = TestHelper.defaultConfig()\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.CUSTOM.getValue())\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE_CLASS, CustomStartFromStreamingTestSnapshot.class.getName())\n+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)\n+                .build();\n+        start(PostgresConnector.class, config);\n+        assertConnectorIsRunning();\n+        waitForStreamingRunning();\n+\n+        SourceRecords actualRecords = consumeRecordsByTopic(2);\n+        List<SourceRecord> s1recs = actualRecords.recordsForTopic(topicName(\"s1.a\"));\n+        List<SourceRecord> s2recs = actualRecords.recordsForTopic(topicName(\"s2.a\"));\n+        assertThat(s1recs.size()).isEqualTo(1);\n+        assertThat(s2recs.size()).isEqualTo(1);\n+        VerifyRecord.isValidRead(s1recs.get(0), PK_FIELD, 1);\n+        VerifyRecord.isValidRead(s2recs.get(0), PK_FIELD, 1);\n+\n+        stopConnector();\n+\n+        // Insert records while connector is stopped\n+        TestHelper.execute(INSERT_STMT);\n+        config = TestHelper.defaultConfig()\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.CUSTOM.getValue())\n+                .with(PostgresConnectorConfig.SNAPSHOT_MODE_CLASS, CustomStartFromStreamingTestSnapshot.class.getName())\n+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)\n+                .build();\n+        start(PostgresConnector.class, config);\n+        assertConnectorIsRunning();\n+\n+        waitForSnapshotToBeCompleted();\n+\n+        // Expect duplicate records from the snapshot and while streaming is running", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0NjU5Nw==", "bodyText": "@grantcooksey, I was a bit misled and missed that all this code runs async via the separate executor, i.e. the sychronized definition of start() doesn't impact it at all. I think your proposed solution is good.", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r469946597", "createdAt": "2020-08-13T13:22:22Z", "author": {"login": "gunnarmorling"}, "path": "debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java", "diffHunk": "@@ -122,8 +126,23 @@ public ChangeEventSourceCoordinator(OffsetContext previousOffset, ErrorHandler e\n         });\n     }\n \n+    protected CatchUpStreamingResult executeCatchUpStreaming(OffsetContext previousOffset, ChangeEventSourceContext context,\n+                                                             SnapshotChangeEventSource snapshotSource)\n+            throws InterruptedException {\n+        return new CatchUpStreamingResult(false);\n+    }\n+\n+    protected void streamEvents(OffsetContext offsetContext, ChangeEventSourceContext context) throws InterruptedException {\n+        streamingSource = changeEventSourceFactory.getStreamingChangeEventSource(offsetContext);\n+        eventDispatcher.setEventListener(streamingMetrics);\n+        streamingMetrics.connected(true);\n+        LOGGER.info(\"Starting streaming\");\n+        streamingSource.execute(context);\n+        LOGGER.info(\"Finished streaming\");\n+    }\n+\n     public void commitOffset(Map<String, ?> offset) {\n-        if (streamingSource != null && offset != null) {\n+        if (!commitOffsetLock.isLocked() && streamingSource != null && offset != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjkwNzk1OQ=="}, "originalCommit": {"oid": "9e476511de3292696d9562182fd8f5c2c26cece5"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTk0ODQ3NQ==", "bodyText": "@jpechane has a concurrent PR where we replace LSN representation from Long to a dedicated LSN type. Depending on which PR gets merged first, this one here should change to that new type, too. Just a heads-up, nothing to act on just yet.", "url": "https://github.com/debezium/debezium/pull/1627#discussion_r469948475", "createdAt": "2020-08-13T13:25:17Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresOffsetContext.java", "diffHunk": "@@ -146,6 +147,21 @@ Long lastCompletelyProcessedLsn() {\n         return lastCompletelyProcessedLsn;\n     }\n \n+    /**\n+     * Returns the LSN that the streaming phase should stream events up to or null if\n+     * a stopping point is not set. If set during the streaming phase, any event with\n+     * an LSN less than the stopping LSN will be processed and once the stopping LSN\n+     * is reached, the streaming phase will end. Useful for a pre-snapshot catch up\n+     * streaming phase.\n+     */\n+    Long getStreamingStoppingLsn() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "d852d9e3ebf076f7eda19eced5cb759b5d51e25c", "author": {"user": {"login": "grantcooksey", "name": "Grant Cooksey"}}, "url": "https://github.com/debezium/debezium/commit/d852d9e3ebf076f7eda19eced5cb759b5d51e25c", "committedDate": "2020-08-26T12:13:41Z", "message": "DBZ-2094 Allow Postgres snapshotter to set streaming start on resume\n\nWhen a connector resumes after previously streaming and takes a\nsnapshot, through a new method on the snapshotter interface,\nshouldStreamEventsStartingFromSnapshot, can choose whether\nto resume streaming from the last known streaming position or the\nbeginning of the snapshot. This is helpful for snapshotters that\nmay not want to resnapshot every table in the whitelist/blacklist\nbut not miss event on the tables that are skipped."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "d852d9e3ebf076f7eda19eced5cb759b5d51e25c", "author": {"user": {"login": "grantcooksey", "name": "Grant Cooksey"}}, "url": "https://github.com/debezium/debezium/commit/d852d9e3ebf076f7eda19eced5cb759b5d51e25c", "committedDate": "2020-08-26T12:13:41Z", "message": "DBZ-2094 Allow Postgres snapshotter to set streaming start on resume\n\nWhen a connector resumes after previously streaming and takes a\nsnapshot, through a new method on the snapshotter interface,\nshouldStreamEventsStartingFromSnapshot, can choose whether\nto resume streaming from the last known streaming position or the\nbeginning of the snapshot. This is helpful for snapshotters that\nmay not want to resnapshot every table in the whitelist/blacklist\nbut not miss event on the tables that are skipped."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0Nzk4MTk1", "url": "https://github.com/debezium/debezium/pull/1627#pullrequestreview-484798195", "createdAt": "2020-09-09T08:53:52Z", "commit": {"oid": "d852d9e3ebf076f7eda19eced5cb759b5d51e25c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2621, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}