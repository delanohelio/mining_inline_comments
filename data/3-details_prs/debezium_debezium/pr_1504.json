{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE4NTE5NTk4", "number": 1504, "title": "DBZ-651 Documentation for Debezium Server", "bodyText": "", "createdAt": "2020-05-15T10:51:17Z", "url": "https://github.com/debezium/debezium/pull/1504", "merged": true, "mergeCommit": {"oid": "c9ab75b3c6635f260cf665e2c7b4485651d4aeda"}, "closed": true, "closedAt": "2020-05-15T16:59:22Z", "author": {"login": "jpechane"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABchf04YAH2gAyNDE4NTE5NTk4OmVhMGI1ZjJlMTM4YmJhODhkMmNmNzY5YzkzZjk5ZjQyMmNkYzQzYzM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABchlGX_AH2gAyNDE4NTE5NTk4OjRiODFiMTI1NGI0ZGUzNTdlNzM3NGY2NDZkNWNjYjY4ZjJhMGY0ZTQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3", "author": {"user": {"login": "jpechane", "name": "Jiri Pechanec"}}, "url": "https://github.com/debezium/debezium/commit/ea0b5f2e138bba88d2cf769c93f99f422cdc43c3", "committedDate": "2020-05-15T10:50:24Z", "message": "DBZ-651 Documentation for Debezium Server"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyODA3ODg0", "url": "https://github.com/debezium/debezium/pull/1504#pullrequestreview-412807884", "createdAt": "2020-05-15T16:46:05Z", "commit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "state": "APPROVED", "comments": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjo0NjowNVrOGWMXrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjo1NjowMlrOGWMrnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNDUyNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n          \n          \n            \n            Debezium provides a ready-to-use application that streams change events from a source database to messaging infrastructure like Amazon Kinesis or Google Pub/Sub.\n          \n          \n            \n            For streaming change events to Apache Kafka, it is recommended to deploy the Debezium connectors via Kafka Connect.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425924525", "createdAt": "2020-05-15T16:46:05Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNDYzMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To install the server download and upack the server distribution archive:\n          \n          \n            \n            To install the server download and unpack the server distribution archive:", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425924631", "createdAt": "2020-05-15T16:46:17Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNDc4OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            NOTE: The above links is to nightly snapshot of the Debezium master branch.\n          \n          \n            \n            NOTE: The above links refers to the nightly snapshot build of the Debezium master branch.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425924788", "createdAt": "2020-05-15T16:46:37Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNTA0MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If you are looking for non-snapshot version, please select the appropriate version in the top right.\n          \n          \n            \n            If you are looking for a non-snapshot version, please select the appropriate version of this documentation in the menu to the right.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425925041", "createdAt": "2020-05-15T16:47:06Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNTE0Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            A directory named `debezium-server` will be created with content:\n          \n          \n            \n            A directory named `debezium-server` will be created with these contents:", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425925146", "createdAt": "2020-05-15T16:47:20Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNTQwNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n          \n          \n            \n            |-- debezium-server-{debezium-version}-runner.jar", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425925407", "createdAt": "2020-05-15T16:47:47Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNTUzOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n          \n          \n            \n            The server is started using `run.sh` script, dependencies are stored in the `lib` directory, and the directory `conf` contains configuration files.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425925538", "createdAt": "2020-05-15T16:48:03Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNTY0Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The main configuration file is `conf/application.properties`.\n          \n          \n            \n            The main configuration file is _conf/application.properties_.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425925643", "createdAt": "2020-05-15T16:48:19Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNTgxNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `debezium.source` is for source connector configuration\n          \n          \n            \n            * `debezium.source` is for source connector configuration; each instance of Debezium Server runs exactly one connector", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425925816", "createdAt": "2020-05-15T16:48:42Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNTk4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `debezium.transforms` is for configuration of Kafka Connect SMTs\n          \n          \n            \n            * `debezium.transforms` is for the configuration of message transformations", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425925981", "createdAt": "2020-05-15T16:49:02Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNjA5Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            An example configuration file can look like:\n          \n          \n            \n            An example configuration file can look like so:", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425926097", "createdAt": "2020-05-15T16:49:17Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNjIyMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            When the server is started it generates a sequnce of log messages like\n          \n          \n            \n            When the server is started it generates a seqeunce of log messages like this:", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425926222", "createdAt": "2020-05-15T16:49:30Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNjg0MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n          \n          \n            \n            The source configuration uses the same configuration properties that are described on the specific connector documentation pages (just with `debezium.source` prefix), together with few more specific ones, necessary for running outside of Kafka Connect:", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425926841", "createdAt": "2020-05-15T16:50:40Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNzIxNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n          \n          \n            \n            By default the output is in JSON format but an arbitrary implementation of Kafka Connect's `Converter` can be used.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425927216", "createdAt": "2020-05-15T16:51:21Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNzQ0NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Before the messages dare delivered to the sink they can run through a sequence of transformation.\n          \n          \n            \n            Before the messages are delivered to the sink, they can run through a sequence of transformations.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425927444", "createdAt": "2020-05-15T16:51:49Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 226}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNzc3Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.\n          \n          \n            \n            Amazon Kinesis is an implementation of data streaming system with support for stream sharding and other techniques for high scalability.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425927773", "createdAt": "2020-05-15T16:52:27Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.\n+The server supports https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect[single message transformations] defined by Kafka Connect.\n+The configuration will need to contain the list of transformations, implementation class for each transformation and configuration options for each of the transformations.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|`debezium.transformations`\n+|\n+|The comma separated list of symbolic names of transformations.\n+\n+|`debezium.transformations.<name>.class`\n+|\n+|The name of Java class implementing the transformation with name `<name>`.\n+\n+|`debezium.transformations.<name>.*`\n+|\n+|Configuration properties passed to the transformation with name `<name>`.\n+\n+|=======================\n+\n+\n+=== Sink configuration\n+\n+Sink configuration is specific for each sink type.\n+Currently the only supported sink is https://aws.amazon.com/kinesis/[Amazon Kinesis].\n+\n+The sink is selected by configuration property `debezium.sink.type`.\n+\n+\n+==== Amazon Kinesis\n+\n+Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 261}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyODAzMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |A credentials profile name use to communicate with Amazon API.\n          \n          \n            \n            |A credentials profile name used to communicate with Amazon API.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425928032", "createdAt": "2020-05-15T16:52:54Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.\n+The server supports https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect[single message transformations] defined by Kafka Connect.\n+The configuration will need to contain the list of transformations, implementation class for each transformation and configuration options for each of the transformations.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|`debezium.transformations`\n+|\n+|The comma separated list of symbolic names of transformations.\n+\n+|`debezium.transformations.<name>.class`\n+|\n+|The name of Java class implementing the transformation with name `<name>`.\n+\n+|`debezium.transformations.<name>.*`\n+|\n+|Configuration properties passed to the transformation with name `<name>`.\n+\n+|=======================\n+\n+\n+=== Sink configuration\n+\n+Sink configuration is specific for each sink type.\n+Currently the only supported sink is https://aws.amazon.com/kinesis/[Amazon Kinesis].\n+\n+The sink is selected by configuration property `debezium.sink.type`.\n+\n+\n+==== Amazon Kinesis\n+\n+Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.\n+Kinesis exposes a set of REST APIs and provides a (not-only) Java SDK that is used to implement the sink.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[kinesis-type]]<<kinesis-type, `debezium.sink.type`>>\n+|\n+|Must be set to `kinesis`.\n+\n+|[[kinesis-region]]<<kinesis-region, `debezium.sink.kinesis.region`>>\n+|\n+|A region name in which the Kinesis target streams are provided.\n+\n+|[[kinesis-credentials-profile]]<<kinesis-credentials-profile, `debezium.sink.kinesis.creadentials.profile`>>\n+|`default`\n+|A credentials profile name use to communicate with Amazon API.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 280}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyODA5Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |Kinesis does not support the notion of message without key. So this string will be used as message key for messages from tables without primary key.\n          \n          \n            \n            |Kinesis does not support the notion of messages without key. So this string will be used as message key for messages from tables without primary key.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425928096", "createdAt": "2020-05-15T16:53:03Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.\n+The server supports https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect[single message transformations] defined by Kafka Connect.\n+The configuration will need to contain the list of transformations, implementation class for each transformation and configuration options for each of the transformations.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|`debezium.transformations`\n+|\n+|The comma separated list of symbolic names of transformations.\n+\n+|`debezium.transformations.<name>.class`\n+|\n+|The name of Java class implementing the transformation with name `<name>`.\n+\n+|`debezium.transformations.<name>.*`\n+|\n+|Configuration properties passed to the transformation with name `<name>`.\n+\n+|=======================\n+\n+\n+=== Sink configuration\n+\n+Sink configuration is specific for each sink type.\n+Currently the only supported sink is https://aws.amazon.com/kinesis/[Amazon Kinesis].\n+\n+The sink is selected by configuration property `debezium.sink.type`.\n+\n+\n+==== Amazon Kinesis\n+\n+Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.\n+Kinesis exposes a set of REST APIs and provides a (not-only) Java SDK that is used to implement the sink.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[kinesis-type]]<<kinesis-type, `debezium.sink.type`>>\n+|\n+|Must be set to `kinesis`.\n+\n+|[[kinesis-region]]<<kinesis-region, `debezium.sink.kinesis.region`>>\n+|\n+|A region name in which the Kinesis target streams are provided.\n+\n+|[[kinesis-credentials-profile]]<<kinesis-credentials-profile, `debezium.sink.kinesis.creadentials.profile`>>\n+|`default`\n+|A credentials profile name use to communicate with Amazon API.\n+\n+|[[kinesis-null-key]]<<kinesis-null-key, `debezium.sink.kinesis.null.key`>>\n+|`default`\n+|Kinesis does not support the notion of message without key. So this string will be used as message key for messages from tables without primary key.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 284}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyODU2OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Kinesis sink beahviour can be modified by a custom code providing alternative implementations of requested functionality.\n          \n          \n            \n            The Kinesis sink behaviour can be modified by a custom logic providing alternative implementations for specific functionalities.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425928568", "createdAt": "2020-05-15T16:54:00Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.\n+The server supports https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect[single message transformations] defined by Kafka Connect.\n+The configuration will need to contain the list of transformations, implementation class for each transformation and configuration options for each of the transformations.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|`debezium.transformations`\n+|\n+|The comma separated list of symbolic names of transformations.\n+\n+|`debezium.transformations.<name>.class`\n+|\n+|The name of Java class implementing the transformation with name `<name>`.\n+\n+|`debezium.transformations.<name>.*`\n+|\n+|Configuration properties passed to the transformation with name `<name>`.\n+\n+|=======================\n+\n+\n+=== Sink configuration\n+\n+Sink configuration is specific for each sink type.\n+Currently the only supported sink is https://aws.amazon.com/kinesis/[Amazon Kinesis].\n+\n+The sink is selected by configuration property `debezium.sink.type`.\n+\n+\n+==== Amazon Kinesis\n+\n+Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.\n+Kinesis exposes a set of REST APIs and provides a (not-only) Java SDK that is used to implement the sink.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[kinesis-type]]<<kinesis-type, `debezium.sink.type`>>\n+|\n+|Must be set to `kinesis`.\n+\n+|[[kinesis-region]]<<kinesis-region, `debezium.sink.kinesis.region`>>\n+|\n+|A region name in which the Kinesis target streams are provided.\n+\n+|[[kinesis-credentials-profile]]<<kinesis-credentials-profile, `debezium.sink.kinesis.creadentials.profile`>>\n+|`default`\n+|A credentials profile name use to communicate with Amazon API.\n+\n+|[[kinesis-null-key]]<<kinesis-null-key, `debezium.sink.kinesis.null.key`>>\n+|`default`\n+|Kinesis does not support the notion of message without key. So this string will be used as message key for messages from tables without primary key.\n+\n+|=======================\n+\n+\n+==== Injection points\n+\n+Kinesis sink beahviour can be modified by a custom code providing alternative implementations of requested functionality.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 291}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyODgzMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |A code that maps the planned destination name into a physical Kinesis stream name. By default the same name is used.\n          \n          \n            \n            |Custom implementation maps the planned destination (topic) name into a physical Kinesis stream name. By default the same name is used.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425928831", "createdAt": "2020-05-15T16:54:34Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.\n+The server supports https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect[single message transformations] defined by Kafka Connect.\n+The configuration will need to contain the list of transformations, implementation class for each transformation and configuration options for each of the transformations.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|`debezium.transformations`\n+|\n+|The comma separated list of symbolic names of transformations.\n+\n+|`debezium.transformations.<name>.class`\n+|\n+|The name of Java class implementing the transformation with name `<name>`.\n+\n+|`debezium.transformations.<name>.*`\n+|\n+|Configuration properties passed to the transformation with name `<name>`.\n+\n+|=======================\n+\n+\n+=== Sink configuration\n+\n+Sink configuration is specific for each sink type.\n+Currently the only supported sink is https://aws.amazon.com/kinesis/[Amazon Kinesis].\n+\n+The sink is selected by configuration property `debezium.sink.type`.\n+\n+\n+==== Amazon Kinesis\n+\n+Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.\n+Kinesis exposes a set of REST APIs and provides a (not-only) Java SDK that is used to implement the sink.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[kinesis-type]]<<kinesis-type, `debezium.sink.type`>>\n+|\n+|Must be set to `kinesis`.\n+\n+|[[kinesis-region]]<<kinesis-region, `debezium.sink.kinesis.region`>>\n+|\n+|A region name in which the Kinesis target streams are provided.\n+\n+|[[kinesis-credentials-profile]]<<kinesis-credentials-profile, `debezium.sink.kinesis.creadentials.profile`>>\n+|`default`\n+|A credentials profile name use to communicate with Amazon API.\n+\n+|[[kinesis-null-key]]<<kinesis-null-key, `debezium.sink.kinesis.null.key`>>\n+|`default`\n+|Kinesis does not support the notion of message without key. So this string will be used as message key for messages from tables without primary key.\n+\n+|=======================\n+\n+\n+==== Injection points\n+\n+Kinesis sink beahviour can be modified by a custom code providing alternative implementations of requested functionality.\n+When the alternative implementations are not available then the default ones are used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Interface\n+|CDI classifier\n+|Description\n+\n+|[[kinesis-ext-client]]<<kinesis-ext-client, `software.amazon.awssdk.services.kinesis.KinesisClient`>>\n+|`@CustomConsumerBuilder`\n+|Custom configured instance of a `KinesisClient` used to send messages to target streams.\n+\n+|[[kinesis-ext-stream-name-mapper]]<<kinesis-ext-stream-name-mapper, `io.debezium.server.kinesis.StreamNameMapper`>>\n+|\n+|A code that maps the planned destination name into a physical Kinesis stream name. By default the same name is used.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyOTA4Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Debezium Server uses https://quarkus.io/[Quarkus framework] and relies on dependency injection to enable developer to extend its behaviour.\n          \n          \n            \n            Debezium Server uses the https://quarkus.io/[Quarkus framework] and relies on dependency injection to enable developer to extend its behaviour.\n          \n          \n            \n            Note that only the JVM mode of Quarkus is supported, but not native execution via GraalVM.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425929083", "createdAt": "2020-05-15T16:55:06Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.\n+The server supports https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect[single message transformations] defined by Kafka Connect.\n+The configuration will need to contain the list of transformations, implementation class for each transformation and configuration options for each of the transformations.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|`debezium.transformations`\n+|\n+|The comma separated list of symbolic names of transformations.\n+\n+|`debezium.transformations.<name>.class`\n+|\n+|The name of Java class implementing the transformation with name `<name>`.\n+\n+|`debezium.transformations.<name>.*`\n+|\n+|Configuration properties passed to the transformation with name `<name>`.\n+\n+|=======================\n+\n+\n+=== Sink configuration\n+\n+Sink configuration is specific for each sink type.\n+Currently the only supported sink is https://aws.amazon.com/kinesis/[Amazon Kinesis].\n+\n+The sink is selected by configuration property `debezium.sink.type`.\n+\n+\n+==== Amazon Kinesis\n+\n+Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.\n+Kinesis exposes a set of REST APIs and provides a (not-only) Java SDK that is used to implement the sink.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[kinesis-type]]<<kinesis-type, `debezium.sink.type`>>\n+|\n+|Must be set to `kinesis`.\n+\n+|[[kinesis-region]]<<kinesis-region, `debezium.sink.kinesis.region`>>\n+|\n+|A region name in which the Kinesis target streams are provided.\n+\n+|[[kinesis-credentials-profile]]<<kinesis-credentials-profile, `debezium.sink.kinesis.creadentials.profile`>>\n+|`default`\n+|A credentials profile name use to communicate with Amazon API.\n+\n+|[[kinesis-null-key]]<<kinesis-null-key, `debezium.sink.kinesis.null.key`>>\n+|`default`\n+|Kinesis does not support the notion of message without key. So this string will be used as message key for messages from tables without primary key.\n+\n+|=======================\n+\n+\n+==== Injection points\n+\n+Kinesis sink beahviour can be modified by a custom code providing alternative implementations of requested functionality.\n+When the alternative implementations are not available then the default ones are used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Interface\n+|CDI classifier\n+|Description\n+\n+|[[kinesis-ext-client]]<<kinesis-ext-client, `software.amazon.awssdk.services.kinesis.KinesisClient`>>\n+|`@CustomConsumerBuilder`\n+|Custom configured instance of a `KinesisClient` used to send messages to target streams.\n+\n+|[[kinesis-ext-stream-name-mapper]]<<kinesis-ext-stream-name-mapper, `io.debezium.server.kinesis.StreamNameMapper`>>\n+|\n+|A code that maps the planned destination name into a physical Kinesis stream name. By default the same name is used.\n+\n+|=======================\n+\n+\n+== Extensions\n+\n+Debezium Server uses https://quarkus.io/[Quarkus framework] and relies on dependency injection to enable developer to extend its behaviour.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 313}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyOTE5OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The server can be extended in two ways by providing a custom code:\n          \n          \n            \n            The server can be extended in two ways by providing a custom logic:", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425929198", "createdAt": "2020-05-15T16:55:19Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.\n+The server supports https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect[single message transformations] defined by Kafka Connect.\n+The configuration will need to contain the list of transformations, implementation class for each transformation and configuration options for each of the transformations.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|`debezium.transformations`\n+|\n+|The comma separated list of symbolic names of transformations.\n+\n+|`debezium.transformations.<name>.class`\n+|\n+|The name of Java class implementing the transformation with name `<name>`.\n+\n+|`debezium.transformations.<name>.*`\n+|\n+|Configuration properties passed to the transformation with name `<name>`.\n+\n+|=======================\n+\n+\n+=== Sink configuration\n+\n+Sink configuration is specific for each sink type.\n+Currently the only supported sink is https://aws.amazon.com/kinesis/[Amazon Kinesis].\n+\n+The sink is selected by configuration property `debezium.sink.type`.\n+\n+\n+==== Amazon Kinesis\n+\n+Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.\n+Kinesis exposes a set of REST APIs and provides a (not-only) Java SDK that is used to implement the sink.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[kinesis-type]]<<kinesis-type, `debezium.sink.type`>>\n+|\n+|Must be set to `kinesis`.\n+\n+|[[kinesis-region]]<<kinesis-region, `debezium.sink.kinesis.region`>>\n+|\n+|A region name in which the Kinesis target streams are provided.\n+\n+|[[kinesis-credentials-profile]]<<kinesis-credentials-profile, `debezium.sink.kinesis.creadentials.profile`>>\n+|`default`\n+|A credentials profile name use to communicate with Amazon API.\n+\n+|[[kinesis-null-key]]<<kinesis-null-key, `debezium.sink.kinesis.null.key`>>\n+|`default`\n+|Kinesis does not support the notion of message without key. So this string will be used as message key for messages from tables without primary key.\n+\n+|=======================\n+\n+\n+==== Injection points\n+\n+Kinesis sink beahviour can be modified by a custom code providing alternative implementations of requested functionality.\n+When the alternative implementations are not available then the default ones are used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Interface\n+|CDI classifier\n+|Description\n+\n+|[[kinesis-ext-client]]<<kinesis-ext-client, `software.amazon.awssdk.services.kinesis.KinesisClient`>>\n+|`@CustomConsumerBuilder`\n+|Custom configured instance of a `KinesisClient` used to send messages to target streams.\n+\n+|[[kinesis-ext-stream-name-mapper]]<<kinesis-ext-stream-name-mapper, `io.debezium.server.kinesis.StreamNameMapper`>>\n+|\n+|A code that maps the planned destination name into a physical Kinesis stream name. By default the same name is used.\n+\n+|=======================\n+\n+\n+== Extensions\n+\n+Debezium Server uses https://quarkus.io/[Quarkus framework] and relies on dependency injection to enable developer to extend its behaviour.\n+The server can be extended in two ways by providing a custom code:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 314}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyOTQxNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The name of the bean is the used as the `debezium.sink.type` option.\n          \n          \n            \n            The name of the bean is used as the `debezium.sink.type` option.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425929414", "createdAt": "2020-05-15T16:55:39Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.\n+The server supports https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect[single message transformations] defined by Kafka Connect.\n+The configuration will need to contain the list of transformations, implementation class for each transformation and configuration options for each of the transformations.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|`debezium.transformations`\n+|\n+|The comma separated list of symbolic names of transformations.\n+\n+|`debezium.transformations.<name>.class`\n+|\n+|The name of Java class implementing the transformation with name `<name>`.\n+\n+|`debezium.transformations.<name>.*`\n+|\n+|Configuration properties passed to the transformation with name `<name>`.\n+\n+|=======================\n+\n+\n+=== Sink configuration\n+\n+Sink configuration is specific for each sink type.\n+Currently the only supported sink is https://aws.amazon.com/kinesis/[Amazon Kinesis].\n+\n+The sink is selected by configuration property `debezium.sink.type`.\n+\n+\n+==== Amazon Kinesis\n+\n+Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.\n+Kinesis exposes a set of REST APIs and provides a (not-only) Java SDK that is used to implement the sink.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[kinesis-type]]<<kinesis-type, `debezium.sink.type`>>\n+|\n+|Must be set to `kinesis`.\n+\n+|[[kinesis-region]]<<kinesis-region, `debezium.sink.kinesis.region`>>\n+|\n+|A region name in which the Kinesis target streams are provided.\n+\n+|[[kinesis-credentials-profile]]<<kinesis-credentials-profile, `debezium.sink.kinesis.creadentials.profile`>>\n+|`default`\n+|A credentials profile name use to communicate with Amazon API.\n+\n+|[[kinesis-null-key]]<<kinesis-null-key, `debezium.sink.kinesis.null.key`>>\n+|`default`\n+|Kinesis does not support the notion of message without key. So this string will be used as message key for messages from tables without primary key.\n+\n+|=======================\n+\n+\n+==== Injection points\n+\n+Kinesis sink beahviour can be modified by a custom code providing alternative implementations of requested functionality.\n+When the alternative implementations are not available then the default ones are used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Interface\n+|CDI classifier\n+|Description\n+\n+|[[kinesis-ext-client]]<<kinesis-ext-client, `software.amazon.awssdk.services.kinesis.KinesisClient`>>\n+|`@CustomConsumerBuilder`\n+|Custom configured instance of a `KinesisClient` used to send messages to target streams.\n+\n+|[[kinesis-ext-stream-name-mapper]]<<kinesis-ext-stream-name-mapper, `io.debezium.server.kinesis.StreamNameMapper`>>\n+|\n+|A code that maps the planned destination name into a physical Kinesis stream name. By default the same name is used.\n+\n+|=======================\n+\n+\n+== Extensions\n+\n+Debezium Server uses https://quarkus.io/[Quarkus framework] and relies on dependency injection to enable developer to extend its behaviour.\n+The server can be extended in two ways by providing a custom code:\n+\n+* implementation of a new sink\n+* customization of an existing sink - i.e. non-standard configuration\n+\n+=== Implementation of a new sink\n+\n+The new sink can be implemented as a CDI bean implementing interface `DebeziumEngine.ChangeConsumer` and with annotation `@Named` and unique name and scope `@Dependent`.\n+The name of the bean is the used as the `debezium.sink.type` option.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyOTYyOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            See https://github.com/debezium/debezium/blob/master/debezium-server/src/main/java/io/debezium/server/kinesis/KinesisChangeConsumer.java[Kinesis sink] implementation for further details.\n          \n          \n            \n            See the https://github.com/debezium/debezium/blob/master/debezium-server/src/main/java/io/debezium/server/kinesis/KinesisChangeConsumer.java[Kinesis sink] implementation for further details.", "url": "https://github.com/debezium/debezium/pull/1504#discussion_r425929629", "createdAt": "2020-05-15T16:56:02Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/operations/debezium-server.adoc", "diffHunk": "@@ -0,0 +1,333 @@\n+= Debezium Server\n+include::../_attributes.adoc[]\n+:linkattrs:\n+:icons: font\n+:toc:\n+:toc-placement: macro\n+\n+toc::[]\n+\n+[NOTE]\n+====\n+This feature is currently in incubating state, i.e. exact semantics, configuration options etc. may change in future revisions, based on the feedback we receive. Please let us know if you encounter any problems while using this extension.\n+====\n+\n+Debezium provides an out-of-the-box application that streams changes from a source database to a sink system.\n+\n+== Installation\n+\n+To install the server download and upack the server distribution archive:\n+\n+ifeval::['{page-version}' == 'master']\n+* {link-server-snapshot}[Debezium Server distribution]\n+\n+NOTE: The above links is to nightly snapshot of the Debezium master branch.\n+If you are looking for non-snapshot version, please select the appropriate version in the top right.\n+endif::[]\n+ifeval::['{page-version}' != 'master']\n+* https://repo1.maven.org/maven2/io/debezium/debezium-server/{debezium-version}/debezium-server-{debezium-version}-distribution.tar.gz[Debezium Server distribution]\n+endif::[]\n+\n+A directory named `debezium-server` will be created with content:\n+----\n+debezium-server/\n+|-- CHANGELOG.md\n+|-- conf\n+|-- CONTRIBUTE.md\n+|-- COPYRIGHT.txt\n+|-- debezium-server-1.2.0-SNAPSHOT-runner.jar\n+|-- lib\n+|-- LICENSE-3rd-PARTIES.txt\n+|-- LICENSE.txt\n+|-- README.md\n+`-- run.sh\n+----\n+\n+The server is started using `run.sh` script, dependencies are stored in the `lib` directory and directory `conf` contains configuration files.\n+\n+== Configuration\n+\n+Debezium Server uses https://github.com/eclipse/microprofile-config[MicroProfile Configuration] for configuration.\n+This means that the application can be configured from disparate sources like configuration files, environment variables, system properties etc.\n+\n+The main configuration file is `conf/application.properties`.\n+There are multiple sections configured:\n+\n+* `debezium.source` is for source connector configuration\n+* `debezium.sink` is for the sink system configuration\n+* `debezium.format` is for the output serialization format configuration\n+* `debezium.transforms` is for configuration of Kafka Connect SMTs\n+\n+An example configuration file can look like:\n+\n+----\n+debezium.sink.type=kinesis\n+debezium.sink.kinesis.region=eu-central-1\n+debezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\n+debezium.source.offset.storage.file.filename=data/offsets.dat\n+debezium.source.offset.flush.interval.ms=0\n+debezium.source.database.hostname=localhost\n+debezium.source.database.port=5432\n+debezium.source.database.user=postgres\n+debezium.source.database.password=postgres\n+debezium.source.database.dbname=postgres\n+debezium.source.database.server.name=tutorial\n+debezium.source.schema.whitelist=inventory\n+----\n+\n+When the server is started it generates a sequnce of log messages like\n+\n+----\n+__  ____  __  _____   ___  __ ____  ______ \n+ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ \n+ -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\\ \\   \n+--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/   \n+2020-05-15 11:33:12,189 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using 'io.debezium.server.kinesis.KinesisChangeConsumer$$Lambda$119/0x0000000840130c40@f58853c' stream name mapper\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.kin.KinesisChangeConsumer] (main) Using default KinesisClient 'software.amazon.awssdk.services.kinesis.DefaultKinesisClient@d1f74b8'\n+2020-05-15 11:33:12,628 INFO  [io.deb.ser.DebeziumServer] (main) Consumer 'io.debezium.server.kinesis.KinesisChangeConsumer' instantiated\n+2020-05-15 11:33:12,754 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,757 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = false\n+\n+2020-05-15 11:33:12,763 INFO  [io.deb.emb.EmbeddedEngine$EmbeddedConfig] (main) EmbeddedConfig values: \n+\taccess.control.allow.methods = \n+\taccess.control.allow.origin = \n+\tadmin.listeners = null\n+\tbootstrap.servers = [localhost:9092]\n+\tclient.dns.lookup = default\n+\tconfig.providers = []\n+\tconnector.client.config.override.policy = None\n+\theader.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter\n+\tinternal.key.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tinternal.value.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tkey.converter = class org.apache.kafka.connect.json.JsonConverter\n+\tlisteners = null\n+\tmetric.reporters = []\n+\tmetrics.num.samples = 2\n+\tmetrics.recording.level = INFO\n+\tmetrics.sample.window.ms = 30000\n+\toffset.flush.interval.ms = 0\n+\toffset.flush.timeout.ms = 5000\n+\toffset.storage.file.filename = data/offsets.dat\n+\toffset.storage.partitions = null\n+\toffset.storage.replication.factor = null\n+\toffset.storage.topic = \n+\tplugin.path = null\n+\trest.advertised.host.name = null\n+\trest.advertised.listener = null\n+\trest.advertised.port = null\n+\trest.extension.classes = []\n+\trest.host.name = null\n+\trest.port = 8083\n+\tssl.client.auth = none\n+\ttask.shutdown.graceful.timeout.ms = 5000\n+\ttopic.tracking.allow.reset = true\n+\ttopic.tracking.enable = true\n+\tvalue.converter = class org.apache.kafka.connect.json.JsonConverter\n+\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,763 INFO  [org.apa.kaf.con.run.WorkerConfig] (main) Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration.\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = key\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,765 INFO  [org.apa.kaf.con.jso.JsonConverterConfig] (main) JsonConverterConfig values: \n+\tconverter.type = value\n+\tdecimal.format = BASE64\n+\tschemas.cache.size = 1000\n+\tschemas.enable = true\n+\n+2020-05-15 11:33:12,767 INFO  [io.deb.ser.DebeziumServer] (main) Engine executor started\n+2020-05-15 11:33:12,773 INFO  [org.apa.kaf.con.sto.FileOffsetBackingStore] (pool-3-thread-1) Starting FileOffsetBackingStore with file data/offsets.dat\n+2020-05-15 11:33:12,835 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1) Starting PostgresConnectorTask with configuration:\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    connector.class = io.debezium.connector.postgresql.PostgresConnector\n+2020-05-15 11:33:12,837 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.flush.interval.ms = 0\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.user = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.dbname = postgres\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    offset.storage.file.filename = data/offsets.dat\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.hostname = localhost\n+2020-05-15 11:33:12,838 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.password = ********\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    name = kinesis\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.server.name = tutorial\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    database.port = 5432\n+2020-05-15 11:33:12,839 INFO  [io.deb.con.com.BaseSourceTask] (pool-3-thread-1)    schema.whitelist = inventory\n+2020-05-15 11:33:12,908 INFO  [io.quarkus] (main) debezium-server 1.2.0-SNAPSHOT (powered by Quarkus 1.4.1.Final) started in 1.198s. Listening on: http://0.0.0.0:8080\n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Profile prod activated. \n+2020-05-15 11:33:12,911 INFO  [io.quarkus] (main) Installed features: [cdi, smallrye-health]\n+----\n+\n+=== Source configuration\n+\n+The source configuration uses the same configuration properties (just with `debezium.source` prefix) that are described in connectors' configurations together with few more specific necessary for running outside of Kafka Connect:\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[source-connector-class]]<<source-connector-class, `debezium.source.connector.class`>>\n+|\n+|The name of the Java class implementing the source connector.\n+\n+|[[source-offset-storage-file-filename]]<<source-offset-storage-file-filename, `debezium.source.offset.storage.file.filename`>>\n+|\n+|The file in which connector offsets are stored for non-Kafka deployments.\n+\n+|[[source-offset-flush-interval-ms]]<<source-offset-flush-interval-ms, `debezium.source.offset.flush.interval.ms`>>\n+|\n+|Defines how frequently the offsets are flushed into the file.\n+\n+|=======================\n+\n+\n+=== Format configuration\n+\n+The message output format can be configured for both key and value separately.\n+By default the output is in JSON format but an arbitrary implementation of Kafka Connect converter can be used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[debezium-format-key]]<<debezium-format-key, `debezium.format.key`>>\n+|`json`\n+|The name of the output format for key, one of `json`/`avro`.\n+\n+|[[debezium-format-key-props]]<<debezium-format-key-props, `debezium.format.key.*`>>\n+|\n+|Configuration properties passed to the key converter.\n+\n+|[[debezium-format-value]]<<debezium-format-value, `debezium.format.value`>>\n+|`json`\n+|The name of the output format for value, one of `json`/`avro`.\n+\n+|[[debezium-format-value-props]]<<debezium-format-value-props, `debezium.format.value.*`>>\n+|\n+|Configuration properties passed to the value converter.\n+\n+|=======================\n+\n+\n+=== Transformation configuration\n+\n+Before the messages dare delivered to the sink they can run through a sequence of transformation.\n+The server supports https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect[single message transformations] defined by Kafka Connect.\n+The configuration will need to contain the list of transformations, implementation class for each transformation and configuration options for each of the transformations.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|`debezium.transformations`\n+|\n+|The comma separated list of symbolic names of transformations.\n+\n+|`debezium.transformations.<name>.class`\n+|\n+|The name of Java class implementing the transformation with name `<name>`.\n+\n+|`debezium.transformations.<name>.*`\n+|\n+|Configuration properties passed to the transformation with name `<name>`.\n+\n+|=======================\n+\n+\n+=== Sink configuration\n+\n+Sink configuration is specific for each sink type.\n+Currently the only supported sink is https://aws.amazon.com/kinesis/[Amazon Kinesis].\n+\n+The sink is selected by configuration property `debezium.sink.type`.\n+\n+\n+==== Amazon Kinesis\n+\n+Amazon Kinesis is an implementation of data streming system with support form stream sharding and other techniques for high scalability.\n+Kinesis exposes a set of REST APIs and provides a (not-only) Java SDK that is used to implement the sink.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Property\n+|Default\n+|Description\n+\n+|[[kinesis-type]]<<kinesis-type, `debezium.sink.type`>>\n+|\n+|Must be set to `kinesis`.\n+\n+|[[kinesis-region]]<<kinesis-region, `debezium.sink.kinesis.region`>>\n+|\n+|A region name in which the Kinesis target streams are provided.\n+\n+|[[kinesis-credentials-profile]]<<kinesis-credentials-profile, `debezium.sink.kinesis.creadentials.profile`>>\n+|`default`\n+|A credentials profile name use to communicate with Amazon API.\n+\n+|[[kinesis-null-key]]<<kinesis-null-key, `debezium.sink.kinesis.null.key`>>\n+|`default`\n+|Kinesis does not support the notion of message without key. So this string will be used as message key for messages from tables without primary key.\n+\n+|=======================\n+\n+\n+==== Injection points\n+\n+Kinesis sink beahviour can be modified by a custom code providing alternative implementations of requested functionality.\n+When the alternative implementations are not available then the default ones are used.\n+\n+[cols=\"35%a,10%a,55%a\",options=\"header\"]\n+|=======================\n+|Interface\n+|CDI classifier\n+|Description\n+\n+|[[kinesis-ext-client]]<<kinesis-ext-client, `software.amazon.awssdk.services.kinesis.KinesisClient`>>\n+|`@CustomConsumerBuilder`\n+|Custom configured instance of a `KinesisClient` used to send messages to target streams.\n+\n+|[[kinesis-ext-stream-name-mapper]]<<kinesis-ext-stream-name-mapper, `io.debezium.server.kinesis.StreamNameMapper`>>\n+|\n+|A code that maps the planned destination name into a physical Kinesis stream name. By default the same name is used.\n+\n+|=======================\n+\n+\n+== Extensions\n+\n+Debezium Server uses https://quarkus.io/[Quarkus framework] and relies on dependency injection to enable developer to extend its behaviour.\n+The server can be extended in two ways by providing a custom code:\n+\n+* implementation of a new sink\n+* customization of an existing sink - i.e. non-standard configuration\n+\n+=== Implementation of a new sink\n+\n+The new sink can be implemented as a CDI bean implementing interface `DebeziumEngine.ChangeConsumer` and with annotation `@Named` and unique name and scope `@Dependent`.\n+The name of the bean is the used as the `debezium.sink.type` option.\n+\n+The sink needs to read the configuration using Microprofile Config API.\n+The execution path must pass the messages into the target system and regularly commit the passed/processed messages.\n+\n+See https://github.com/debezium/debezium/blob/master/debezium-server/src/main/java/io/debezium/server/kinesis/KinesisChangeConsumer.java[Kinesis sink] implementation for further details.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea0b5f2e138bba88d2cf769c93f99f422cdc43c3"}, "originalPosition": 327}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b81b1254b4de357e7374f646d5ccb68f2a0f4e4", "author": {"user": {"login": "gunnarmorling", "name": "Gunnar Morling"}}, "url": "https://github.com/debezium/debezium/commit/4b81b1254b4de357e7374f646d5ccb68f2a0f4e4", "committedDate": "2020-05-15T16:59:02Z", "message": "DBZ-651 Applying suggestions from code review"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2665, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}