{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1MzA5ODYy", "number": 1316, "title": "DBZ-1726 Move MongoDB connector to common framework", "bodyText": "https://issues.redhat.com/browse/DBZ-1726\nThe initial port of the MongoDB connector to the common connector framework.", "createdAt": "2020-03-08T20:28:14Z", "url": "https://github.com/debezium/debezium/pull/1316", "merged": true, "mergeCommit": {"oid": "baffcbdfd9943a9ce9d35195082d9ff12cb29ec1"}, "closed": true, "closedAt": "2020-03-11T09:15:01Z", "author": {"login": "Naros"}, "timelineItems": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcLvT5NgH2gAyMzg1MzA5ODYyOmZlYzMxZTdmN2ZmODk2YzVlYzMyY2NlNDJmNTRjMDg0YmJiMTAxOWE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcMjbllgFqTM3MjU3ODkwMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "fec31e7f7ff896c5ec32cce42f54c084bbb1019a", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/fec31e7f7ff896c5ec32cce42f54c084bbb1019a", "committedDate": "2020-03-08T20:26:31Z", "message": "DBZ-1726 Move MongoDB connector to common framework"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e4c6862d4ccc0ad4bc12dc9ac17639a5defee6c", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/9e4c6862d4ccc0ad4bc12dc9ac17639a5defee6c", "committedDate": "2020-03-08T20:32:40Z", "message": "DBZ-1726 Removed an unintended dependency."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "635eaeb0b40afb2f6b8a91bed9546379b3d3cf0d", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/635eaeb0b40afb2f6b8a91bed9546379b3d3cf0d", "committedDate": "2020-03-08T20:59:52Z", "message": "DBZ-1726 Fix formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56d4a1cf6a8ce61d877e8881e682fab584ac53e1", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/56d4a1cf6a8ce61d877e8881e682fab584ac53e1", "committedDate": "2020-03-09T04:19:53Z", "message": "DBZ-1726 Fix oplog cursor filter"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwOTM0NjMz", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-370934633", "createdAt": "2020-03-09T06:15:37Z", "commit": {"oid": "56d4a1cf6a8ce61d877e8881e682fab584ac53e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQwNjoxNTozOFrOFzb24g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQwNjoxNTozOFrOFzb24g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTQ3ODExNA==", "bodyText": "I wonder, does it make sense to have an interface hierarchy\nSingleOfsetContext extends OffsetConext\nPartitionedOffsetContext extends OffsetContext", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r389478114", "createdAt": "2020-03-09T06:15:38Z", "author": {"login": "jpechane"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbOffsetContext.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.kafka.connect.data.Schema;\n+import org.apache.kafka.connect.data.Struct;\n+import org.bson.Document;\n+\n+import io.debezium.connector.SnapshotRecord;\n+import io.debezium.pipeline.spi.OffsetContext;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.schema.DataCollectionId;\n+\n+/**\n+ * A context that facilitates the management of the current offsets across a set of mongodb replica sets.\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbOffsetContext implements OffsetContext {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56d4a1cf6a8ce61d877e8881e682fab584ac53e1"}, "originalPosition": 28}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxMDAzNzI3", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371003727", "createdAt": "2020-03-09T09:08:55Z", "commit": {"oid": "56d4a1cf6a8ce61d877e8881e682fab584ac53e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQwOTowODo1NVrOFzfRNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQwOTowODo1NVrOFzfRNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTUzNDAwNw==", "bodyText": "Could this be DataCollectionId instead of String?", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r389534007", "createdAt": "2020-03-09T09:08:55Z", "author": {"login": "gunnarmorling"}, "path": "debezium-core/src/main/java/io/debezium/pipeline/metrics/SnapshotChangeEventSourceMetrics.java", "diffHunk": "@@ -100,9 +100,9 @@ public void monitoredTablesDetermined(Iterable<TableId> tableIds) {\n     }\n \n     @Override\n-    public void tableSnapshotCompleted(TableId tableId, long numRows) {\n-        rowsScanned.put(tableId.toString(), numRows);\n-        remainingTables.remove(tableId.toString());\n+    public void dataCollectionSnapshotCompleted(String dataCollectionId, long numRows) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56d4a1cf6a8ce61d877e8881e682fab584ac53e1"}, "originalPosition": 7}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxMDA0MDEz", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371004013", "createdAt": "2020-03-09T09:09:24Z", "commit": {"oid": "56d4a1cf6a8ce61d877e8881e682fab584ac53e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQwOTowOToyNFrOFzfSBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQwOTowOToyNFrOFzfSBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTUzNDIxMw==", "bodyText": "Same question as above.", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r389534213", "createdAt": "2020-03-09T09:09:24Z", "author": {"login": "gunnarmorling"}, "path": "debezium-core/src/main/java/io/debezium/pipeline/source/spi/SnapshotProgressListener.java", "diffHunk": "@@ -41,7 +49,7 @@ public void monitoredTablesDetermined(Iterable<TableId> tableIds) {\n         }\n \n         @Override\n-        public void tableSnapshotCompleted(TableId tableId, long numRows) {\n+        public void dataCollectionSnapshotCompleted(String dataCollectionId, long numRows) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56d4a1cf6a8ce61d877e8881e682fab584ac53e1"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "62123b66a26d38590acc3a123295bb3c2d3d18a9", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/62123b66a26d38590acc3a123295bb3c2d3d18a9", "committedDate": "2020-03-09T15:08:23Z", "message": "DBZ-1726 Introduce DataCollectionId#identifier()"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381", "author": {"user": {"login": "gunnarmorling", "name": "Gunnar Morling"}}, "url": "https://github.com/debezium/debezium/commit/7d5eb1b8561e565f093f9c73b3faddd6d5ea7381", "committedDate": "2020-03-10T08:40:42Z", "message": "DBZ-1726 Removing some unused fields"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxNzQwMTA2", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371740106", "createdAt": "2020-03-10T08:03:09Z", "commit": {"oid": "62123b66a26d38590acc3a123295bb3c2d3d18a9"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwODowMzowOVrOF0EgmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwODowNDoxMlrOF0EiHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE0NDE1Mw==", "bodyText": "connectorConfig is unused.", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390144153", "createdAt": "2020-03-10T08:03:09Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbOffsetContext.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.kafka.connect.data.Schema;\n+import org.apache.kafka.connect.data.Struct;\n+import org.bson.Document;\n+\n+import io.debezium.connector.SnapshotRecord;\n+import io.debezium.pipeline.spi.OffsetContext;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.schema.DataCollectionId;\n+\n+/**\n+ * A context that facilitates the management of the current offsets across a set of mongodb replica sets.\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbOffsetContext implements OffsetContext {\n+\n+    private final MongoDbConnectorConfig connectorConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62123b66a26d38590acc3a123295bb3c2d3d18a9"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE0NDU0MA==", "bodyText": "That's unused.", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390144540", "createdAt": "2020-03-10T08:04:12Z", "author": {"login": "gunnarmorling"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbStreamingChangeEventSource.java", "diffHunk": "@@ -0,0 +1,408 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.OptionalLong;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.bson.BsonTimestamp;\n+import org.bson.Document;\n+import org.bson.conversions.Bson;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.mongodb.CursorType;\n+import com.mongodb.MongoClient;\n+import com.mongodb.ServerAddress;\n+import com.mongodb.client.FindIterable;\n+import com.mongodb.client.MongoCollection;\n+import com.mongodb.client.MongoCursor;\n+import com.mongodb.client.model.Filters;\n+\n+import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;\n+import io.debezium.pipeline.ErrorHandler;\n+import io.debezium.pipeline.EventDispatcher;\n+import io.debezium.pipeline.source.spi.StreamingChangeEventSource;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.util.Clock;\n+import io.debezium.util.Metronome;\n+import io.debezium.util.Threads;\n+\n+/**\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbStreamingChangeEventSource implements StreamingChangeEventSource {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(MongoDbStreamingChangeEventSource.class);\n+\n+    private static final String AUTHORIZATION_FAILURE_MESSAGE = \"Command failed with error 13\";\n+\n+    private static final String OPERATION_FIELD = \"op\";\n+    private static final String OBJECT_FIELD = \"o\";\n+    private static final String OPERATION_CONTROL = \"c\";\n+    private static final String TX_OPS = \"applyOps\";\n+\n+    private final EventDispatcher<CollectionId> dispatcher;\n+    private final ErrorHandler errorHandler;\n+    private final Clock clock;\n+    private final MongoDbOffsetContext offsetContext;\n+    private final MongoDbConnectorConfig connectorConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62123b66a26d38590acc3a123295bb3c2d3d18a9"}, "originalPosition": 62}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxODgxNjY4", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371881668", "createdAt": "2020-03-10T11:46:34Z", "commit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTo0NjozNFrOF0LfQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTo0NjozNFrOF0LfQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI1ODQ5Nw==", "bodyText": "There should be a common parent for RelationalSnapshotChangeEventSource and MongoDbSnapshotChangeEventSource that would contain a shared code like this.", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390258497", "createdAt": "2020-03-10T11:46:34Z", "author": {"login": "jpechane"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java", "diffHunk": "@@ -0,0 +1,599 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.bson.BsonTimestamp;\n+import org.bson.Document;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.mongodb.client.MongoCollection;\n+import com.mongodb.client.MongoCursor;\n+import com.mongodb.client.MongoDatabase;\n+\n+import io.debezium.config.ConfigurationDefaults;\n+import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;\n+import io.debezium.pipeline.ErrorHandler;\n+import io.debezium.pipeline.EventDispatcher;\n+import io.debezium.pipeline.EventDispatcher.SnapshotReceiver;\n+import io.debezium.pipeline.source.spi.SnapshotChangeEventSource;\n+import io.debezium.pipeline.source.spi.SnapshotProgressListener;\n+import io.debezium.pipeline.spi.ChangeRecordEmitter;\n+import io.debezium.pipeline.spi.OffsetContext;\n+import io.debezium.pipeline.spi.SnapshotResult;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.util.Clock;\n+import io.debezium.util.Metronome;\n+import io.debezium.util.Strings;\n+import io.debezium.util.Threads;\n+import io.debezium.util.Threads.Timer;\n+\n+/**\n+ * A {@link SnapshotChangeEventSource} that performs multi-threaded snapshots of replica sets.\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbSnapshotChangeEventSource implements SnapshotChangeEventSource {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(MongoDbSnapshotChangeEventSource.class);\n+\n+    private static final String AUTHORIZATION_FAILURE_MESSAGE = \"Command failed with error 13\";\n+\n+    private final MongoDbConnectorConfig connectorConfig;\n+    private final MongoDbTaskContext taskContext;\n+    private final MongoDbOffsetContext previousOffset;\n+    private final ConnectionContext connectionContext;\n+    private final ReplicaSets replicaSets;\n+    private final EventDispatcher<CollectionId> dispatcher;\n+    protected final Clock clock;\n+    private final SnapshotProgressListener snapshotProgressListener;\n+    private final ErrorHandler errorHandler;\n+    private AtomicBoolean aborted = new AtomicBoolean(false);\n+\n+    public MongoDbSnapshotChangeEventSource(MongoDbConnectorConfig connectorConfig, MongoDbTaskContext taskContext,\n+                                            ReplicaSets replicaSets, MongoDbOffsetContext previousOffset,\n+                                            EventDispatcher<CollectionId> dispatcher, Clock clock,\n+                                            SnapshotProgressListener snapshotProgressListener, ErrorHandler errorHandler) {\n+        this.connectorConfig = connectorConfig;\n+        this.taskContext = taskContext;\n+        this.connectionContext = taskContext.getConnectionContext();\n+        this.previousOffset = previousOffset;\n+        this.replicaSets = replicaSets;\n+        this.dispatcher = dispatcher;\n+        this.clock = clock;\n+        this.snapshotProgressListener = snapshotProgressListener;\n+        this.errorHandler = errorHandler;\n+    }\n+\n+    @Override\n+    public SnapshotResult execute(ChangeEventSourceContext context) throws InterruptedException {\n+        SnapshottingTask snapshottingTask = getSnapshottingTask(previousOffset, replicaSets);\n+        if (!snapshottingTask.snapshotData()) {\n+            LOGGER.debug(\"Skipping snapshotting\");\n+            return SnapshotResult.skipped(previousOffset);\n+        }\n+\n+        delaySnapshotIfNeeded(context);\n+\n+        final SnapshotContext ctx;\n+        try {\n+            ctx = prepare(context);\n+        }\n+        catch (Exception e) {\n+            LOGGER.error(\"Failed to initialize snapshot context.\", e);\n+            throw new RuntimeException(e);\n+        }\n+\n+        try {\n+            LOGGER.info(\"Snapshot step 1 - Preparing\");\n+            snapshotProgressListener.snapshotStarted();\n+\n+            if (previousOffset != null && previousOffset.isSnapshotRunning()) {\n+                LOGGER.info(\"Previous snapshot was cancelled before completion; a new snapshot will be taken.\");\n+            }\n+\n+            LOGGER.info(\"Snapshot step 2 - Determining snapshot offsets\");\n+            determineSnapshotOffsets(ctx, replicaSets);\n+\n+            List<ReplicaSet> replicaSetsToSnapshot = snapshottingTask.getReplicaSetsToSnapshot();\n+\n+            final int threads = replicaSetsToSnapshot.size();\n+            final ExecutorService executor = Threads.newFixedThreadPool(MongoDbConnector.class, taskContext.serverName(), \"replicator-snapshot\", threads);\n+            final CountDownLatch latch = new CountDownLatch(threads);\n+\n+            LOGGER.info(\"Ignoring unnamed replica sets: {}\", replicaSets.unnamedReplicaSets());\n+            LOGGER.info(\"Starting {} thread(s) to snapshot replica sets: {}\", threads, replicaSetsToSnapshot);\n+\n+            LOGGER.info(\"Snapshot step 3 - Snapshotting data\");\n+            replicaSetsToSnapshot.forEach(replicaSet -> {\n+                executor.submit(() -> {\n+                    try {\n+                        taskContext.configureLoggingContext(replicaSet.replicaSetName());\n+                        try {\n+                            snapshotReplicaSet(context, ctx, replicaSet);\n+                        }\n+                        finally {\n+                            final MongoDbOffsetContext offset = (MongoDbOffsetContext) ctx.offset;\n+                            // todo: DBZ-1726 - this causes MongoDbConnectorIT#shouldEmitHeartbeatMessages to fail\n+                            // omitted for now since it does not appear we did this in previous connector code.\n+                            // dispatcher.alwaysDispatchHeartbeatEvent(offset.getReplicaSetOffsetContext(replicaSet));\n+                        }\n+                    }\n+                    catch (Throwable t) {\n+                        LOGGER.error(\"Snapshot for replica set {} failed\", replicaSet.replicaSetName(), t);\n+                        errorHandler.setProducerThrowable(t);\n+                    }\n+                    finally {\n+                        latch.countDown();\n+                    }\n+                });\n+            });\n+\n+            // Wait for the executor service threads to end.\n+            try {\n+                latch.await();\n+            }\n+            catch (InterruptedException e) {\n+                Thread.currentThread().interrupt();\n+                aborted.set(true);\n+            }\n+\n+            // Shutdown executor and close connections\n+            try {\n+                executor.shutdown();\n+            }\n+            finally {\n+                LOGGER.info(\"Stopping mongodb connections\");\n+                taskContext.getConnectionContext().shutdown();\n+            }\n+\n+            if (aborted.get()) {\n+                return SnapshotResult.aborted();\n+            }\n+\n+            snapshotProgressListener.snapshotCompleted();\n+\n+            return SnapshotResult.completed(ctx.offset);\n+        }\n+        catch (InterruptedException e) {\n+            LOGGER.warn(\"Snapshot was interrupted before completion\");\n+            snapshotProgressListener.snapshotAborted();\n+            throw e;\n+        }\n+        catch (RuntimeException e) {\n+            snapshotProgressListener.snapshotAborted();\n+            throw e;\n+        }\n+        catch (Throwable t) {\n+            snapshotProgressListener.snapshotAborted();\n+            throw new RuntimeException(t);\n+        }\n+        finally {\n+            LOGGER.info(\"Snapshot step 4 - Finalizing\");\n+            complete(ctx);\n+        }\n+    }\n+\n+    protected SnapshottingTask getSnapshottingTask(OffsetContext previousOffset, ReplicaSets replicaSets) {\n+        if (previousOffset == null) {\n+            LOGGER.info(\"No previous offset has been found\");\n+            if (connectorConfig.getSnapshotMode().equals(MongoDbConnectorConfig.SnapshotMode.NEVER)) {\n+                LOGGER.info(\"According to the connector configuration, no snapshot will occur.\");\n+                return new SnapshottingTask(Collections.emptyList());\n+            }\n+            return new SnapshottingTask(replicaSets.all());\n+        }\n+\n+        // Even if there are previous offsets, if no snapshot should occur, return task with no replica sets\n+        if (connectorConfig.getSnapshotMode().equals(MongoDbConnectorConfig.SnapshotMode.NEVER)) {\n+            LOGGER.info(\"According to the connector configuration, no snapshot will occur.\");\n+            return new SnapshottingTask(Collections.emptyList());\n+        }\n+\n+        // Collect which replica-sets require being snapshotted\n+        final List<ReplicaSet> replicaSetSnapshots = new ArrayList<>();\n+        final MongoDbOffsetContext offsetContext = (MongoDbOffsetContext) previousOffset;\n+        try {\n+            replicaSets.onEachReplicaSet(replicaSet -> {\n+                MongoPrimary primary = null;\n+                try {\n+                    primary = establishConnectionToPrimary(replicaSet);\n+                    final ReplicaSetOffsetContext rsOffsetContext = offsetContext.getReplicaSetOffsetContext(replicaSet);\n+                    if (primary != null && isInitialSyncExpected(primary, rsOffsetContext)) {\n+                        replicaSetSnapshots.add(replicaSet);\n+                    }\n+                }\n+                finally {\n+                    if (primary != null) {\n+                        primary.stop();\n+                    }\n+                }\n+            });\n+        }\n+        finally {\n+            taskContext.getConnectionContext().shutdown();\n+        }\n+\n+        return new SnapshottingTask(replicaSetSnapshots);\n+    }\n+\n+    private void delaySnapshotIfNeeded(ChangeEventSourceContext context) throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "originalPosition": 238}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxODg0MzA0", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371884304", "createdAt": "2020-03-10T11:51:22Z", "commit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTo1MToyMlrOF0LntA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTo1MToyMlrOF0LntA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI2MDY2MA==", "bodyText": "Hardcoded return false value - etiher a bug or code not needed", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390260660", "createdAt": "2020-03-10T11:51:22Z", "author": {"login": "jpechane"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java", "diffHunk": "@@ -0,0 +1,599 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.bson.BsonTimestamp;\n+import org.bson.Document;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.mongodb.client.MongoCollection;\n+import com.mongodb.client.MongoCursor;\n+import com.mongodb.client.MongoDatabase;\n+\n+import io.debezium.config.ConfigurationDefaults;\n+import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;\n+import io.debezium.pipeline.ErrorHandler;\n+import io.debezium.pipeline.EventDispatcher;\n+import io.debezium.pipeline.EventDispatcher.SnapshotReceiver;\n+import io.debezium.pipeline.source.spi.SnapshotChangeEventSource;\n+import io.debezium.pipeline.source.spi.SnapshotProgressListener;\n+import io.debezium.pipeline.spi.ChangeRecordEmitter;\n+import io.debezium.pipeline.spi.OffsetContext;\n+import io.debezium.pipeline.spi.SnapshotResult;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.util.Clock;\n+import io.debezium.util.Metronome;\n+import io.debezium.util.Strings;\n+import io.debezium.util.Threads;\n+import io.debezium.util.Threads.Timer;\n+\n+/**\n+ * A {@link SnapshotChangeEventSource} that performs multi-threaded snapshots of replica sets.\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbSnapshotChangeEventSource implements SnapshotChangeEventSource {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(MongoDbSnapshotChangeEventSource.class);\n+\n+    private static final String AUTHORIZATION_FAILURE_MESSAGE = \"Command failed with error 13\";\n+\n+    private final MongoDbConnectorConfig connectorConfig;\n+    private final MongoDbTaskContext taskContext;\n+    private final MongoDbOffsetContext previousOffset;\n+    private final ConnectionContext connectionContext;\n+    private final ReplicaSets replicaSets;\n+    private final EventDispatcher<CollectionId> dispatcher;\n+    protected final Clock clock;\n+    private final SnapshotProgressListener snapshotProgressListener;\n+    private final ErrorHandler errorHandler;\n+    private AtomicBoolean aborted = new AtomicBoolean(false);\n+\n+    public MongoDbSnapshotChangeEventSource(MongoDbConnectorConfig connectorConfig, MongoDbTaskContext taskContext,\n+                                            ReplicaSets replicaSets, MongoDbOffsetContext previousOffset,\n+                                            EventDispatcher<CollectionId> dispatcher, Clock clock,\n+                                            SnapshotProgressListener snapshotProgressListener, ErrorHandler errorHandler) {\n+        this.connectorConfig = connectorConfig;\n+        this.taskContext = taskContext;\n+        this.connectionContext = taskContext.getConnectionContext();\n+        this.previousOffset = previousOffset;\n+        this.replicaSets = replicaSets;\n+        this.dispatcher = dispatcher;\n+        this.clock = clock;\n+        this.snapshotProgressListener = snapshotProgressListener;\n+        this.errorHandler = errorHandler;\n+    }\n+\n+    @Override\n+    public SnapshotResult execute(ChangeEventSourceContext context) throws InterruptedException {\n+        SnapshottingTask snapshottingTask = getSnapshottingTask(previousOffset, replicaSets);\n+        if (!snapshottingTask.snapshotData()) {\n+            LOGGER.debug(\"Skipping snapshotting\");\n+            return SnapshotResult.skipped(previousOffset);\n+        }\n+\n+        delaySnapshotIfNeeded(context);\n+\n+        final SnapshotContext ctx;\n+        try {\n+            ctx = prepare(context);\n+        }\n+        catch (Exception e) {\n+            LOGGER.error(\"Failed to initialize snapshot context.\", e);\n+            throw new RuntimeException(e);\n+        }\n+\n+        try {\n+            LOGGER.info(\"Snapshot step 1 - Preparing\");\n+            snapshotProgressListener.snapshotStarted();\n+\n+            if (previousOffset != null && previousOffset.isSnapshotRunning()) {\n+                LOGGER.info(\"Previous snapshot was cancelled before completion; a new snapshot will be taken.\");\n+            }\n+\n+            LOGGER.info(\"Snapshot step 2 - Determining snapshot offsets\");\n+            determineSnapshotOffsets(ctx, replicaSets);\n+\n+            List<ReplicaSet> replicaSetsToSnapshot = snapshottingTask.getReplicaSetsToSnapshot();\n+\n+            final int threads = replicaSetsToSnapshot.size();\n+            final ExecutorService executor = Threads.newFixedThreadPool(MongoDbConnector.class, taskContext.serverName(), \"replicator-snapshot\", threads);\n+            final CountDownLatch latch = new CountDownLatch(threads);\n+\n+            LOGGER.info(\"Ignoring unnamed replica sets: {}\", replicaSets.unnamedReplicaSets());\n+            LOGGER.info(\"Starting {} thread(s) to snapshot replica sets: {}\", threads, replicaSetsToSnapshot);\n+\n+            LOGGER.info(\"Snapshot step 3 - Snapshotting data\");\n+            replicaSetsToSnapshot.forEach(replicaSet -> {\n+                executor.submit(() -> {\n+                    try {\n+                        taskContext.configureLoggingContext(replicaSet.replicaSetName());\n+                        try {\n+                            snapshotReplicaSet(context, ctx, replicaSet);\n+                        }\n+                        finally {\n+                            final MongoDbOffsetContext offset = (MongoDbOffsetContext) ctx.offset;\n+                            // todo: DBZ-1726 - this causes MongoDbConnectorIT#shouldEmitHeartbeatMessages to fail\n+                            // omitted for now since it does not appear we did this in previous connector code.\n+                            // dispatcher.alwaysDispatchHeartbeatEvent(offset.getReplicaSetOffsetContext(replicaSet));\n+                        }\n+                    }\n+                    catch (Throwable t) {\n+                        LOGGER.error(\"Snapshot for replica set {} failed\", replicaSet.replicaSetName(), t);\n+                        errorHandler.setProducerThrowable(t);\n+                    }\n+                    finally {\n+                        latch.countDown();\n+                    }\n+                });\n+            });\n+\n+            // Wait for the executor service threads to end.\n+            try {\n+                latch.await();\n+            }\n+            catch (InterruptedException e) {\n+                Thread.currentThread().interrupt();\n+                aborted.set(true);\n+            }\n+\n+            // Shutdown executor and close connections\n+            try {\n+                executor.shutdown();\n+            }\n+            finally {\n+                LOGGER.info(\"Stopping mongodb connections\");\n+                taskContext.getConnectionContext().shutdown();\n+            }\n+\n+            if (aborted.get()) {\n+                return SnapshotResult.aborted();\n+            }\n+\n+            snapshotProgressListener.snapshotCompleted();\n+\n+            return SnapshotResult.completed(ctx.offset);\n+        }\n+        catch (InterruptedException e) {\n+            LOGGER.warn(\"Snapshot was interrupted before completion\");\n+            snapshotProgressListener.snapshotAborted();\n+            throw e;\n+        }\n+        catch (RuntimeException e) {\n+            snapshotProgressListener.snapshotAborted();\n+            throw e;\n+        }\n+        catch (Throwable t) {\n+            snapshotProgressListener.snapshotAborted();\n+            throw new RuntimeException(t);\n+        }\n+        finally {\n+            LOGGER.info(\"Snapshot step 4 - Finalizing\");\n+            complete(ctx);\n+        }\n+    }\n+\n+    protected SnapshottingTask getSnapshottingTask(OffsetContext previousOffset, ReplicaSets replicaSets) {\n+        if (previousOffset == null) {\n+            LOGGER.info(\"No previous offset has been found\");\n+            if (connectorConfig.getSnapshotMode().equals(MongoDbConnectorConfig.SnapshotMode.NEVER)) {\n+                LOGGER.info(\"According to the connector configuration, no snapshot will occur.\");\n+                return new SnapshottingTask(Collections.emptyList());\n+            }\n+            return new SnapshottingTask(replicaSets.all());\n+        }\n+\n+        // Even if there are previous offsets, if no snapshot should occur, return task with no replica sets\n+        if (connectorConfig.getSnapshotMode().equals(MongoDbConnectorConfig.SnapshotMode.NEVER)) {\n+            LOGGER.info(\"According to the connector configuration, no snapshot will occur.\");\n+            return new SnapshottingTask(Collections.emptyList());\n+        }\n+\n+        // Collect which replica-sets require being snapshotted\n+        final List<ReplicaSet> replicaSetSnapshots = new ArrayList<>();\n+        final MongoDbOffsetContext offsetContext = (MongoDbOffsetContext) previousOffset;\n+        try {\n+            replicaSets.onEachReplicaSet(replicaSet -> {\n+                MongoPrimary primary = null;\n+                try {\n+                    primary = establishConnectionToPrimary(replicaSet);\n+                    final ReplicaSetOffsetContext rsOffsetContext = offsetContext.getReplicaSetOffsetContext(replicaSet);\n+                    if (primary != null && isInitialSyncExpected(primary, rsOffsetContext)) {\n+                        replicaSetSnapshots.add(replicaSet);\n+                    }\n+                }\n+                finally {\n+                    if (primary != null) {\n+                        primary.stop();\n+                    }\n+                }\n+            });\n+        }\n+        finally {\n+            taskContext.getConnectionContext().shutdown();\n+        }\n+\n+        return new SnapshottingTask(replicaSetSnapshots);\n+    }\n+\n+    private void delaySnapshotIfNeeded(ChangeEventSourceContext context) throws InterruptedException {\n+        Duration snapshotDelay = connectorConfig.getSnapshotDelay();\n+\n+        if (snapshotDelay.isZero() || snapshotDelay.isNegative()) {\n+            return;\n+        }\n+\n+        Timer timer = Threads.timer(Clock.SYSTEM, snapshotDelay);\n+        Metronome metronome = Metronome.parker(ConfigurationDefaults.RETURN_CONTROL_INTERVAL, Clock.SYSTEM);\n+\n+        while (!timer.expired()) {\n+            if (!context.isRunning()) {\n+                throw new InterruptedException(\"Interrupted while awaiting initial snapshot delay\");\n+            }\n+\n+            LOGGER.info(\"The connector will wait for {}s before proceeding\", timer.remaining().getSeconds());\n+            metronome.pause();\n+        }\n+    }\n+\n+    protected SnapshotContext prepare(ChangeEventSourceContext sourceContext) throws Exception {\n+        return new MongoDbSnapshotContext();\n+    }\n+\n+    protected void complete(SnapshotContext snapshotContext) {\n+    }\n+\n+    private void snapshotReplicaSet(ChangeEventSourceContext sourceContext, SnapshotContext ctx, ReplicaSet replicaSet) throws InterruptedException {\n+        MongoPrimary primaryClient = null;\n+        try {\n+            primaryClient = establishConnectionToPrimary(replicaSet);\n+            if (primaryClient != null) {\n+                createDataEvents(sourceContext, ctx, replicaSet, primaryClient);\n+            }\n+        }\n+        finally {\n+            if (primaryClient != null) {\n+                primaryClient.stop();\n+            }\n+        }\n+    }\n+\n+    private MongoPrimary establishConnectionToPrimary(ReplicaSet replicaSet) {\n+        return connectionContext.primaryFor(replicaSet, taskContext.filters(), (desc, error) -> {\n+            // propagate authorization failures\n+            if (error.getMessage() != null && error.getMessage().startsWith(AUTHORIZATION_FAILURE_MESSAGE)) {\n+                throw new ConnectException(\"Error while attempting to \" + desc, error);\n+            }\n+            else {\n+                LOGGER.error(\"Error while attempting to {}: \", desc, error.getMessage(), error);\n+                throw new ConnectException(\"Error while attempting to \" + desc, error);\n+            }\n+        });\n+    }\n+\n+    private boolean isInitialSyncExpected(MongoPrimary primaryClient, ReplicaSetOffsetContext offsetContext) {\n+        boolean performSnapshot = true;\n+        if (offsetContext.hasOffset()) {\n+            if (LOGGER.isInfoEnabled()) {\n+                LOGGER.info(\"Found existing offset for replica set '{}' at {}\", offsetContext.getReplicaSetName(), offsetContext.getOffset());\n+            }\n+            performSnapshot = false;\n+            if (connectionContext.performSnapshotEvenIfNotNeeded()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "originalPosition": 300}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxODg2MTYy", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371886162", "createdAt": "2020-03-10T11:54:38Z", "commit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTo1NDozOVrOF0Ltqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTo1NDozOVrOF0Ltqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI2MjE4Ng==", "bodyText": "Could we use snapshot instead of initialSync to be consistent with other connectors? Same for other instances", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390262186", "createdAt": "2020-03-10T11:54:39Z", "author": {"login": "jpechane"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbOffsetContext.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.kafka.connect.data.Schema;\n+import org.apache.kafka.connect.data.Struct;\n+import org.bson.Document;\n+\n+import io.debezium.connector.SnapshotRecord;\n+import io.debezium.pipeline.spi.OffsetContext;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.schema.DataCollectionId;\n+\n+/**\n+ * A context that facilitates the management of the current offsets across a set of mongodb replica sets.\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbOffsetContext implements OffsetContext {\n+\n+    private final SourceInfo sourceInfo;\n+    private final TransactionContext transactionContext;\n+    private final Map<ReplicaSet, ReplicaSetOffsetContext> replicaSetOffsetContexts = new ConcurrentHashMap<>();\n+\n+    public MongoDbOffsetContext(SourceInfo sourceInfo, TransactionContext transactionContext) {\n+        this.sourceInfo = sourceInfo;\n+        this.transactionContext = transactionContext;\n+    }\n+\n+    public MongoDbOffsetContext(SourceInfo sourceInfo, TransactionContext transactionContext, Map<ReplicaSet, Document> offsets) {\n+        this(sourceInfo, transactionContext);\n+        offsets.forEach((replicaSet, document) -> sourceInfo.opLogEvent(replicaSet.replicaSetName(), document, document, 0));\n+    }\n+\n+    void startInitialSync(String replicaSetName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxODg3NTQ1", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371887545", "createdAt": "2020-03-10T11:57:02Z", "commit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTo1NzowMlrOF0Lx5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTo1NzowMlrOF0Lx5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI2MzI3MQ==", "bodyText": "I believe this deserves a TODO note - right now we implement when needed snapshot by default. In future we should provide the same otpions as other connectors and this should server as a reminder where wheen_needed functionlaity lies.", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390263271", "createdAt": "2020-03-10T11:57:02Z", "author": {"login": "jpechane"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java", "diffHunk": "@@ -0,0 +1,599 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.bson.BsonTimestamp;\n+import org.bson.Document;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.mongodb.client.MongoCollection;\n+import com.mongodb.client.MongoCursor;\n+import com.mongodb.client.MongoDatabase;\n+\n+import io.debezium.config.ConfigurationDefaults;\n+import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;\n+import io.debezium.pipeline.ErrorHandler;\n+import io.debezium.pipeline.EventDispatcher;\n+import io.debezium.pipeline.EventDispatcher.SnapshotReceiver;\n+import io.debezium.pipeline.source.spi.SnapshotChangeEventSource;\n+import io.debezium.pipeline.source.spi.SnapshotProgressListener;\n+import io.debezium.pipeline.spi.ChangeRecordEmitter;\n+import io.debezium.pipeline.spi.OffsetContext;\n+import io.debezium.pipeline.spi.SnapshotResult;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.util.Clock;\n+import io.debezium.util.Metronome;\n+import io.debezium.util.Strings;\n+import io.debezium.util.Threads;\n+import io.debezium.util.Threads.Timer;\n+\n+/**\n+ * A {@link SnapshotChangeEventSource} that performs multi-threaded snapshots of replica sets.\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbSnapshotChangeEventSource implements SnapshotChangeEventSource {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(MongoDbSnapshotChangeEventSource.class);\n+\n+    private static final String AUTHORIZATION_FAILURE_MESSAGE = \"Command failed with error 13\";\n+\n+    private final MongoDbConnectorConfig connectorConfig;\n+    private final MongoDbTaskContext taskContext;\n+    private final MongoDbOffsetContext previousOffset;\n+    private final ConnectionContext connectionContext;\n+    private final ReplicaSets replicaSets;\n+    private final EventDispatcher<CollectionId> dispatcher;\n+    protected final Clock clock;\n+    private final SnapshotProgressListener snapshotProgressListener;\n+    private final ErrorHandler errorHandler;\n+    private AtomicBoolean aborted = new AtomicBoolean(false);\n+\n+    public MongoDbSnapshotChangeEventSource(MongoDbConnectorConfig connectorConfig, MongoDbTaskContext taskContext,\n+                                            ReplicaSets replicaSets, MongoDbOffsetContext previousOffset,\n+                                            EventDispatcher<CollectionId> dispatcher, Clock clock,\n+                                            SnapshotProgressListener snapshotProgressListener, ErrorHandler errorHandler) {\n+        this.connectorConfig = connectorConfig;\n+        this.taskContext = taskContext;\n+        this.connectionContext = taskContext.getConnectionContext();\n+        this.previousOffset = previousOffset;\n+        this.replicaSets = replicaSets;\n+        this.dispatcher = dispatcher;\n+        this.clock = clock;\n+        this.snapshotProgressListener = snapshotProgressListener;\n+        this.errorHandler = errorHandler;\n+    }\n+\n+    @Override\n+    public SnapshotResult execute(ChangeEventSourceContext context) throws InterruptedException {\n+        SnapshottingTask snapshottingTask = getSnapshottingTask(previousOffset, replicaSets);\n+        if (!snapshottingTask.snapshotData()) {\n+            LOGGER.debug(\"Skipping snapshotting\");\n+            return SnapshotResult.skipped(previousOffset);\n+        }\n+\n+        delaySnapshotIfNeeded(context);\n+\n+        final SnapshotContext ctx;\n+        try {\n+            ctx = prepare(context);\n+        }\n+        catch (Exception e) {\n+            LOGGER.error(\"Failed to initialize snapshot context.\", e);\n+            throw new RuntimeException(e);\n+        }\n+\n+        try {\n+            LOGGER.info(\"Snapshot step 1 - Preparing\");\n+            snapshotProgressListener.snapshotStarted();\n+\n+            if (previousOffset != null && previousOffset.isSnapshotRunning()) {\n+                LOGGER.info(\"Previous snapshot was cancelled before completion; a new snapshot will be taken.\");\n+            }\n+\n+            LOGGER.info(\"Snapshot step 2 - Determining snapshot offsets\");\n+            determineSnapshotOffsets(ctx, replicaSets);\n+\n+            List<ReplicaSet> replicaSetsToSnapshot = snapshottingTask.getReplicaSetsToSnapshot();\n+\n+            final int threads = replicaSetsToSnapshot.size();\n+            final ExecutorService executor = Threads.newFixedThreadPool(MongoDbConnector.class, taskContext.serverName(), \"replicator-snapshot\", threads);\n+            final CountDownLatch latch = new CountDownLatch(threads);\n+\n+            LOGGER.info(\"Ignoring unnamed replica sets: {}\", replicaSets.unnamedReplicaSets());\n+            LOGGER.info(\"Starting {} thread(s) to snapshot replica sets: {}\", threads, replicaSetsToSnapshot);\n+\n+            LOGGER.info(\"Snapshot step 3 - Snapshotting data\");\n+            replicaSetsToSnapshot.forEach(replicaSet -> {\n+                executor.submit(() -> {\n+                    try {\n+                        taskContext.configureLoggingContext(replicaSet.replicaSetName());\n+                        try {\n+                            snapshotReplicaSet(context, ctx, replicaSet);\n+                        }\n+                        finally {\n+                            final MongoDbOffsetContext offset = (MongoDbOffsetContext) ctx.offset;\n+                            // todo: DBZ-1726 - this causes MongoDbConnectorIT#shouldEmitHeartbeatMessages to fail\n+                            // omitted for now since it does not appear we did this in previous connector code.\n+                            // dispatcher.alwaysDispatchHeartbeatEvent(offset.getReplicaSetOffsetContext(replicaSet));\n+                        }\n+                    }\n+                    catch (Throwable t) {\n+                        LOGGER.error(\"Snapshot for replica set {} failed\", replicaSet.replicaSetName(), t);\n+                        errorHandler.setProducerThrowable(t);\n+                    }\n+                    finally {\n+                        latch.countDown();\n+                    }\n+                });\n+            });\n+\n+            // Wait for the executor service threads to end.\n+            try {\n+                latch.await();\n+            }\n+            catch (InterruptedException e) {\n+                Thread.currentThread().interrupt();\n+                aborted.set(true);\n+            }\n+\n+            // Shutdown executor and close connections\n+            try {\n+                executor.shutdown();\n+            }\n+            finally {\n+                LOGGER.info(\"Stopping mongodb connections\");\n+                taskContext.getConnectionContext().shutdown();\n+            }\n+\n+            if (aborted.get()) {\n+                return SnapshotResult.aborted();\n+            }\n+\n+            snapshotProgressListener.snapshotCompleted();\n+\n+            return SnapshotResult.completed(ctx.offset);\n+        }\n+        catch (InterruptedException e) {\n+            LOGGER.warn(\"Snapshot was interrupted before completion\");\n+            snapshotProgressListener.snapshotAborted();\n+            throw e;\n+        }\n+        catch (RuntimeException e) {\n+            snapshotProgressListener.snapshotAborted();\n+            throw e;\n+        }\n+        catch (Throwable t) {\n+            snapshotProgressListener.snapshotAborted();\n+            throw new RuntimeException(t);\n+        }\n+        finally {\n+            LOGGER.info(\"Snapshot step 4 - Finalizing\");\n+            complete(ctx);\n+        }\n+    }\n+\n+    protected SnapshottingTask getSnapshottingTask(OffsetContext previousOffset, ReplicaSets replicaSets) {\n+        if (previousOffset == null) {\n+            LOGGER.info(\"No previous offset has been found\");\n+            if (connectorConfig.getSnapshotMode().equals(MongoDbConnectorConfig.SnapshotMode.NEVER)) {\n+                LOGGER.info(\"According to the connector configuration, no snapshot will occur.\");\n+                return new SnapshottingTask(Collections.emptyList());\n+            }\n+            return new SnapshottingTask(replicaSets.all());\n+        }\n+\n+        // Even if there are previous offsets, if no snapshot should occur, return task with no replica sets\n+        if (connectorConfig.getSnapshotMode().equals(MongoDbConnectorConfig.SnapshotMode.NEVER)) {\n+            LOGGER.info(\"According to the connector configuration, no snapshot will occur.\");\n+            return new SnapshottingTask(Collections.emptyList());\n+        }\n+\n+        // Collect which replica-sets require being snapshotted\n+        final List<ReplicaSet> replicaSetSnapshots = new ArrayList<>();\n+        final MongoDbOffsetContext offsetContext = (MongoDbOffsetContext) previousOffset;\n+        try {\n+            replicaSets.onEachReplicaSet(replicaSet -> {\n+                MongoPrimary primary = null;\n+                try {\n+                    primary = establishConnectionToPrimary(replicaSet);\n+                    final ReplicaSetOffsetContext rsOffsetContext = offsetContext.getReplicaSetOffsetContext(replicaSet);\n+                    if (primary != null && isInitialSyncExpected(primary, rsOffsetContext)) {\n+                        replicaSetSnapshots.add(replicaSet);\n+                    }\n+                }\n+                finally {\n+                    if (primary != null) {\n+                        primary.stop();\n+                    }\n+                }\n+            });\n+        }\n+        finally {\n+            taskContext.getConnectionContext().shutdown();\n+        }\n+\n+        return new SnapshottingTask(replicaSetSnapshots);\n+    }\n+\n+    private void delaySnapshotIfNeeded(ChangeEventSourceContext context) throws InterruptedException {\n+        Duration snapshotDelay = connectorConfig.getSnapshotDelay();\n+\n+        if (snapshotDelay.isZero() || snapshotDelay.isNegative()) {\n+            return;\n+        }\n+\n+        Timer timer = Threads.timer(Clock.SYSTEM, snapshotDelay);\n+        Metronome metronome = Metronome.parker(ConfigurationDefaults.RETURN_CONTROL_INTERVAL, Clock.SYSTEM);\n+\n+        while (!timer.expired()) {\n+            if (!context.isRunning()) {\n+                throw new InterruptedException(\"Interrupted while awaiting initial snapshot delay\");\n+            }\n+\n+            LOGGER.info(\"The connector will wait for {}s before proceeding\", timer.remaining().getSeconds());\n+            metronome.pause();\n+        }\n+    }\n+\n+    protected SnapshotContext prepare(ChangeEventSourceContext sourceContext) throws Exception {\n+        return new MongoDbSnapshotContext();\n+    }\n+\n+    protected void complete(SnapshotContext snapshotContext) {\n+    }\n+\n+    private void snapshotReplicaSet(ChangeEventSourceContext sourceContext, SnapshotContext ctx, ReplicaSet replicaSet) throws InterruptedException {\n+        MongoPrimary primaryClient = null;\n+        try {\n+            primaryClient = establishConnectionToPrimary(replicaSet);\n+            if (primaryClient != null) {\n+                createDataEvents(sourceContext, ctx, replicaSet, primaryClient);\n+            }\n+        }\n+        finally {\n+            if (primaryClient != null) {\n+                primaryClient.stop();\n+            }\n+        }\n+    }\n+\n+    private MongoPrimary establishConnectionToPrimary(ReplicaSet replicaSet) {\n+        return connectionContext.primaryFor(replicaSet, taskContext.filters(), (desc, error) -> {\n+            // propagate authorization failures\n+            if (error.getMessage() != null && error.getMessage().startsWith(AUTHORIZATION_FAILURE_MESSAGE)) {\n+                throw new ConnectException(\"Error while attempting to \" + desc, error);\n+            }\n+            else {\n+                LOGGER.error(\"Error while attempting to {}: \", desc, error.getMessage(), error);\n+                throw new ConnectException(\"Error while attempting to \" + desc, error);\n+            }\n+        });\n+    }\n+\n+    private boolean isInitialSyncExpected(MongoPrimary primaryClient, ReplicaSetOffsetContext offsetContext) {\n+        boolean performSnapshot = true;\n+        if (offsetContext.hasOffset()) {\n+            if (LOGGER.isInfoEnabled()) {\n+                LOGGER.info(\"Found existing offset for replica set '{}' at {}\", offsetContext.getReplicaSetName(), offsetContext.getOffset());\n+            }\n+            performSnapshot = false;\n+            if (connectionContext.performSnapshotEvenIfNotNeeded()) {\n+                LOGGER.info(\"Configured to perform initial sync of replica set '{}'\", offsetContext.getReplicaSetName());\n+                performSnapshot = true;\n+            }\n+            else {\n+                if (offsetContext.isInitialSyncOngoing()) {\n+                    // The latest snapshot was not completed, so restart it\n+                    LOGGER.info(\"The previous initial sync was incomplete for '{}', so initiating another initial sync\", offsetContext.getReplicaSetName());\n+                    performSnapshot = true;\n+                }\n+                else {\n+                    // There is no ongoing initial sync, so look to see if our last recorded offset still exists in the oplog.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "originalPosition": 311}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxODkwMjgy", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371890282", "createdAt": "2020-03-10T12:01:30Z", "commit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMjowMTozMVrOF0L6OQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMjowMTozMVrOF0L6OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI2NTQwMQ==", "bodyText": "Again a common ancestor to this and RelationalSnapshotChangeEventSource would be good together with intorducing doExectue() method.", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390265401", "createdAt": "2020-03-10T12:01:31Z", "author": {"login": "jpechane"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java", "diffHunk": "@@ -0,0 +1,599 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.bson.BsonTimestamp;\n+import org.bson.Document;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.mongodb.client.MongoCollection;\n+import com.mongodb.client.MongoCursor;\n+import com.mongodb.client.MongoDatabase;\n+\n+import io.debezium.config.ConfigurationDefaults;\n+import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;\n+import io.debezium.pipeline.ErrorHandler;\n+import io.debezium.pipeline.EventDispatcher;\n+import io.debezium.pipeline.EventDispatcher.SnapshotReceiver;\n+import io.debezium.pipeline.source.spi.SnapshotChangeEventSource;\n+import io.debezium.pipeline.source.spi.SnapshotProgressListener;\n+import io.debezium.pipeline.spi.ChangeRecordEmitter;\n+import io.debezium.pipeline.spi.OffsetContext;\n+import io.debezium.pipeline.spi.SnapshotResult;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.util.Clock;\n+import io.debezium.util.Metronome;\n+import io.debezium.util.Strings;\n+import io.debezium.util.Threads;\n+import io.debezium.util.Threads.Timer;\n+\n+/**\n+ * A {@link SnapshotChangeEventSource} that performs multi-threaded snapshots of replica sets.\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbSnapshotChangeEventSource implements SnapshotChangeEventSource {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(MongoDbSnapshotChangeEventSource.class);\n+\n+    private static final String AUTHORIZATION_FAILURE_MESSAGE = \"Command failed with error 13\";\n+\n+    private final MongoDbConnectorConfig connectorConfig;\n+    private final MongoDbTaskContext taskContext;\n+    private final MongoDbOffsetContext previousOffset;\n+    private final ConnectionContext connectionContext;\n+    private final ReplicaSets replicaSets;\n+    private final EventDispatcher<CollectionId> dispatcher;\n+    protected final Clock clock;\n+    private final SnapshotProgressListener snapshotProgressListener;\n+    private final ErrorHandler errorHandler;\n+    private AtomicBoolean aborted = new AtomicBoolean(false);\n+\n+    public MongoDbSnapshotChangeEventSource(MongoDbConnectorConfig connectorConfig, MongoDbTaskContext taskContext,\n+                                            ReplicaSets replicaSets, MongoDbOffsetContext previousOffset,\n+                                            EventDispatcher<CollectionId> dispatcher, Clock clock,\n+                                            SnapshotProgressListener snapshotProgressListener, ErrorHandler errorHandler) {\n+        this.connectorConfig = connectorConfig;\n+        this.taskContext = taskContext;\n+        this.connectionContext = taskContext.getConnectionContext();\n+        this.previousOffset = previousOffset;\n+        this.replicaSets = replicaSets;\n+        this.dispatcher = dispatcher;\n+        this.clock = clock;\n+        this.snapshotProgressListener = snapshotProgressListener;\n+        this.errorHandler = errorHandler;\n+    }\n+\n+    @Override\n+    public SnapshotResult execute(ChangeEventSourceContext context) throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "originalPosition": 87}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxODkzMTM2", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371893136", "createdAt": "2020-03-10T12:06:31Z", "commit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMjowNjozMlrOF0MC-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMjowNjozMlrOF0MC-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI2NzY0Mg==", "bodyText": "Do we need a separate thread here? I mean is there any blocking op or can we unwind ans simplify it to a single thread?", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390267642", "createdAt": "2020-03-10T12:06:32Z", "author": {"login": "jpechane"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbStreamingChangeEventSource.java", "diffHunk": "@@ -0,0 +1,406 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.OptionalLong;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.bson.BsonTimestamp;\n+import org.bson.Document;\n+import org.bson.conversions.Bson;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.mongodb.CursorType;\n+import com.mongodb.MongoClient;\n+import com.mongodb.ServerAddress;\n+import com.mongodb.client.FindIterable;\n+import com.mongodb.client.MongoCollection;\n+import com.mongodb.client.MongoCursor;\n+import com.mongodb.client.model.Filters;\n+\n+import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;\n+import io.debezium.pipeline.ErrorHandler;\n+import io.debezium.pipeline.EventDispatcher;\n+import io.debezium.pipeline.source.spi.StreamingChangeEventSource;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.util.Clock;\n+import io.debezium.util.Metronome;\n+import io.debezium.util.Threads;\n+\n+/**\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbStreamingChangeEventSource implements StreamingChangeEventSource {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(MongoDbStreamingChangeEventSource.class);\n+\n+    private static final String AUTHORIZATION_FAILURE_MESSAGE = \"Command failed with error 13\";\n+\n+    private static final String OPERATION_FIELD = \"op\";\n+    private static final String OBJECT_FIELD = \"o\";\n+    private static final String OPERATION_CONTROL = \"c\";\n+    private static final String TX_OPS = \"applyOps\";\n+\n+    private final EventDispatcher<CollectionId> dispatcher;\n+    private final ErrorHandler errorHandler;\n+    private final Clock clock;\n+    private final MongoDbOffsetContext offsetContext;\n+    private final ConnectionContext connectionContext;\n+    private final ReplicaSets replicaSets;\n+    private final MongoDbTaskContext taskContext;\n+\n+    public MongoDbStreamingChangeEventSource(MongoDbConnectorConfig connectorConfig, MongoDbTaskContext taskContext,\n+                                             ReplicaSets replicaSets, MongoDbOffsetContext offsetContext,\n+                                             EventDispatcher<CollectionId> dispatcher, ErrorHandler errorHandler, Clock clock) {\n+        this.connectionContext = taskContext.getConnectionContext();\n+        this.dispatcher = dispatcher;\n+        this.errorHandler = errorHandler;\n+        this.clock = clock;\n+        this.replicaSets = replicaSets;\n+        this.taskContext = taskContext;\n+        this.offsetContext = (offsetContext != null) ? offsetContext : initializeOffsets(connectorConfig, replicaSets);\n+    }\n+\n+    @Override\n+    public void execute(ChangeEventSourceContext context) throws InterruptedException {\n+        // Starts a thread for each replica-set and executes the streaming process\n+        final int threads = replicaSets.replicaSetCount();\n+        final ExecutorService executor = Threads.newFixedThreadPool(MongoDbConnector.class, taskContext.serverName(), \"replicator-streaming\", threads);\n+        final CountDownLatch latch = new CountDownLatch(threads);\n+\n+        LOGGER.info(\"Starting {} thread(s) to stream changes for replica sets: {}\", threads, replicaSets);\n+        replicaSets.validReplicaSets().forEach(replicaSet -> {\n+            executor.submit(() -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "originalPosition": 87}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxODk4OTI1", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371898925", "createdAt": "2020-03-10T12:16:15Z", "commit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMjoxNjoxNVrOF0MVZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMjoxNjoxNVrOF0MVZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI3MjM1OA==", "bodyText": "MongoDb supports transactions - so it should be added here, see io.debezium.connector.mongodb.MongoDbStreamingChangeEventSource.handleOplogEvent(ServerAddress, Document, Document, long, ReplicaSetOplogContext)", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390272358", "createdAt": "2020-03-10T12:16:15Z", "author": {"login": "jpechane"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbEventMetadataProvider.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Instant;\n+import java.util.Map;\n+\n+import org.apache.kafka.connect.data.Struct;\n+\n+import io.debezium.data.Envelope;\n+import io.debezium.pipeline.source.spi.EventMetadataProvider;\n+import io.debezium.pipeline.spi.OffsetContext;\n+import io.debezium.schema.DataCollectionId;\n+import io.debezium.util.Collect;\n+\n+/**\n+ * An {@link EventMetadataProvider} implementation for Mongodb to extract metrics data from events.\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbEventMetadataProvider implements EventMetadataProvider {\n+\n+    @Override\n+    public Instant getEventTimestamp(DataCollectionId source, OffsetContext offset, Object key, Struct value) {\n+        if (value == null) {\n+            return null;\n+        }\n+        final Struct sourceInfo = value.getStruct(Envelope.FieldName.SOURCE);\n+        if (source == null) {\n+            return null;\n+        }\n+        final Long timestamp = sourceInfo.getInt64(SourceInfo.TIMESTAMP_KEY);\n+        return timestamp == null ? null : Instant.ofEpochMilli(timestamp);\n+    }\n+\n+    @Override\n+    public Map<String, String> getEventSourcePosition(DataCollectionId source, OffsetContext offset, Object key, Struct value) {\n+        if (value == null) {\n+            return null;\n+        }\n+        final Struct sourceInfo = value.getStruct(Envelope.FieldName.SOURCE);\n+        if (source == null) {\n+            return null;\n+        }\n+\n+        Integer ord = sourceInfo.getInt32(SourceInfo.ORDER);\n+        return Collect.hashMapOf(SourceInfo.ORDER, Integer.toString(ord));\n+    }\n+\n+    @Override\n+    public String getTransactionId(DataCollectionId source, OffsetContext offset, Object key, Struct value) {\n+        // todo: DBZ-1726 for now this returns null; is there an implementation alternative?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "originalPosition": 55}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxODk5Mzk4", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-371899398", "createdAt": "2020-03-10T12:17:03Z", "commit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMjoxNzowM1rOF0MW-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMjoxNzowM1rOF0MW-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI3Mjc2Mw==", "bodyText": "Should integrate TransactionMonitor", "url": "https://github.com/debezium/debezium/pull/1316#discussion_r390272763", "createdAt": "2020-03-10T12:17:03Z", "author": {"login": "jpechane"}, "path": "debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbStreamingChangeEventSource.java", "diffHunk": "@@ -0,0 +1,406 @@\n+/*\n+ * Copyright Debezium Authors.\n+ *\n+ * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.debezium.connector.mongodb;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.OptionalLong;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.bson.BsonTimestamp;\n+import org.bson.Document;\n+import org.bson.conversions.Bson;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.mongodb.CursorType;\n+import com.mongodb.MongoClient;\n+import com.mongodb.ServerAddress;\n+import com.mongodb.client.FindIterable;\n+import com.mongodb.client.MongoCollection;\n+import com.mongodb.client.MongoCursor;\n+import com.mongodb.client.model.Filters;\n+\n+import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;\n+import io.debezium.pipeline.ErrorHandler;\n+import io.debezium.pipeline.EventDispatcher;\n+import io.debezium.pipeline.source.spi.StreamingChangeEventSource;\n+import io.debezium.pipeline.txmetadata.TransactionContext;\n+import io.debezium.util.Clock;\n+import io.debezium.util.Metronome;\n+import io.debezium.util.Threads;\n+\n+/**\n+ *\n+ * @author Chris Cranford\n+ */\n+public class MongoDbStreamingChangeEventSource implements StreamingChangeEventSource {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(MongoDbStreamingChangeEventSource.class);\n+\n+    private static final String AUTHORIZATION_FAILURE_MESSAGE = \"Command failed with error 13\";\n+\n+    private static final String OPERATION_FIELD = \"op\";\n+    private static final String OBJECT_FIELD = \"o\";\n+    private static final String OPERATION_CONTROL = \"c\";\n+    private static final String TX_OPS = \"applyOps\";\n+\n+    private final EventDispatcher<CollectionId> dispatcher;\n+    private final ErrorHandler errorHandler;\n+    private final Clock clock;\n+    private final MongoDbOffsetContext offsetContext;\n+    private final ConnectionContext connectionContext;\n+    private final ReplicaSets replicaSets;\n+    private final MongoDbTaskContext taskContext;\n+\n+    public MongoDbStreamingChangeEventSource(MongoDbConnectorConfig connectorConfig, MongoDbTaskContext taskContext,\n+                                             ReplicaSets replicaSets, MongoDbOffsetContext offsetContext,\n+                                             EventDispatcher<CollectionId> dispatcher, ErrorHandler errorHandler, Clock clock) {\n+        this.connectionContext = taskContext.getConnectionContext();\n+        this.dispatcher = dispatcher;\n+        this.errorHandler = errorHandler;\n+        this.clock = clock;\n+        this.replicaSets = replicaSets;\n+        this.taskContext = taskContext;\n+        this.offsetContext = (offsetContext != null) ? offsetContext : initializeOffsets(connectorConfig, replicaSets);\n+    }\n+\n+    @Override\n+    public void execute(ChangeEventSourceContext context) throws InterruptedException {\n+        // Starts a thread for each replica-set and executes the streaming process\n+        final int threads = replicaSets.replicaSetCount();\n+        final ExecutorService executor = Threads.newFixedThreadPool(MongoDbConnector.class, taskContext.serverName(), \"replicator-streaming\", threads);\n+        final CountDownLatch latch = new CountDownLatch(threads);\n+\n+        LOGGER.info(\"Starting {} thread(s) to stream changes for replica sets: {}\", threads, replicaSets);\n+        replicaSets.validReplicaSets().forEach(replicaSet -> {\n+            executor.submit(() -> {\n+                MongoPrimary primaryClient = null;\n+                try {\n+                    primaryClient = establishConnectionToPrimary(replicaSet);\n+                    if (primaryClient != null) {\n+                        final AtomicReference<MongoPrimary> primaryReference = new AtomicReference<>(primaryClient);\n+                        primaryClient.execute(\"read from oplog on '\" + replicaSet + \"'\", primary -> {\n+                            readOplog(primary, primaryReference.get(), replicaSet, context);\n+                        });\n+                    }\n+                }\n+                catch (Throwable t) {\n+                    LOGGER.error(\"Streaming for replica set {} failed\", replicaSet.replicaSetName(), t);\n+                    errorHandler.setProducerThrowable(t);\n+                }\n+                finally {\n+                    if (primaryClient != null) {\n+                        primaryClient.stop();\n+                    }\n+\n+                    latch.countDown();\n+                }\n+            });\n+        });\n+\n+        // Wait for the executor service to terminate.\n+        try {\n+            latch.await();\n+        }\n+        catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+        }\n+\n+        // Shutdown the executor and cleanup connections\n+        try {\n+            executor.shutdown();\n+        }\n+        finally {\n+            taskContext.getConnectionContext().shutdown();\n+        }\n+    }\n+\n+    private MongoPrimary establishConnectionToPrimary(ReplicaSet replicaSet) {\n+        return connectionContext.primaryFor(replicaSet, taskContext.filters(), (desc, error) -> {\n+            // propagate authorization failures\n+            if (error.getMessage() != null && error.getMessage().startsWith(AUTHORIZATION_FAILURE_MESSAGE)) {\n+                throw new ConnectException(\"Error while attempting to \" + desc, error);\n+            }\n+            else {\n+                LOGGER.error(\"Error while attempting to {}: {}\", desc, error.getMessage(), error);\n+                throw new ConnectException(\"Error while attempting to \" + desc, error);\n+            }\n+        });\n+    }\n+\n+    private void readOplog(MongoClient primary, MongoPrimary primaryClient, ReplicaSet replicaSet, ChangeEventSourceContext context) {\n+        final ReplicaSetOffsetContext rsOffsetContext = offsetContext.getReplicaSetOffsetContext(replicaSet);\n+\n+        final BsonTimestamp oplogStart = rsOffsetContext.lastOffsetTimestamp();\n+        final OptionalLong txOrder = rsOffsetContext.lastOffsetTxOrder();\n+\n+        final ServerAddress primaryAddress = primary.getAddress();\n+        LOGGER.info(\"Reading oplog for '{}' primary {} starting at {}\", replicaSet, primaryAddress, oplogStart);\n+\n+        // Include none of the cluster-internal operations and only those events since the previous timestamp\n+        MongoCollection<Document> oplog = primary.getDatabase(\"local\").getCollection(\"oplog.rs\");\n+\n+        ReplicaSetOplogContext oplogContext = new ReplicaSetOplogContext(rsOffsetContext, primaryClient, replicaSet);\n+\n+        Bson filter = null;\n+        if (!txOrder.isPresent()) {\n+            LOGGER.info(\"The last event processed was not transactional, resuming at the oplog event after '{}'\", oplogStart);\n+            filter = Filters.and(Filters.gt(\"ts\", oplogStart), // start just after our last position\n+                    Filters.exists(\"fromMigrate\", false)); // skip internal movements across shards\n+        }\n+        else {\n+            LOGGER.info(\"The last event processed was transactional, resuming at the oplog event '{}', expecting to skip '{}' events\",\n+                    oplogStart, txOrder.getAsLong());\n+            filter = Filters.and(Filters.gte(\"ts\", oplogStart), Filters.exists(\"fromMigrate\", false));\n+            oplogContext.setIncompleteEventTimestamp(oplogStart);\n+            oplogContext.setIncompleteTxOrder(txOrder.getAsLong());\n+        }\n+\n+        final FindIterable<Document> results = oplog.find(filter)\n+                .sort(new Document(\"$natural\", 1))\n+                .oplogReplay(true)\n+                .cursorType(CursorType.TailableAwait);\n+\n+        try (MongoCursor<Document> cursor = results.iterator()) {\n+            // In Replicator, this used cursor.hasNext() but this is a blocking call and I observed that this can\n+            // delay the shutdown of the connector by up to 15 seconds or longer. By introducing a Metronome, we\n+            // can respond to the stop request much faster and without much overhead.\n+            Metronome pause = Metronome.sleeper(Duration.ofMillis(500), clock);\n+            while (context.isRunning()) {\n+                // Use tryNext which will return null if no document is yet available from the cursor.\n+                // In this situation if not document is available, we'll pause.\n+                final Document event = cursor.tryNext();\n+                if (event != null) {\n+                    if (!handleOplogEvent(primaryAddress, event, event, 0, oplogContext)) {\n+                        // Something happened and we are supposed to stop reading\n+                        return;\n+                    }\n+\n+                    try {\n+                        dispatcher.dispatchHeartbeatEvent(oplogContext.getOffset());\n+                    }\n+                    catch (InterruptedException e) {\n+                        LOGGER.info(\"Replicator thread is interrupted\");\n+                        Thread.currentThread().interrupt();\n+                        return;\n+                    }\n+                }\n+                else {\n+                    try {\n+                        pause.pause();\n+                    }\n+                    catch (InterruptedException e) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean handleOplogEvent(ServerAddress primaryAddress, Document event, Document masterEvent, long txOrder, ReplicaSetOplogContext oplogContext) {\n+        String ns = event.getString(\"ns\");\n+        Document object = event.get(OBJECT_FIELD, Document.class);\n+        if (Objects.isNull(object)) {\n+            if (LOGGER.isWarnEnabled()) {\n+                LOGGER.warn(\"Missing 'o' field in event, so skipping {}\", event.toJson());\n+            }\n+            return true;\n+        }\n+\n+        if (Objects.isNull(ns) || ns.isEmpty()) {\n+            // These are considered replica set events\n+            String msg = object.getString(\"msg\");\n+            if (\"new primary\".equals(msg)) {\n+                AtomicReference<ServerAddress> address = new AtomicReference<>();\n+                try {\n+                    oplogContext.getPrimary().executeBlocking(\"conn\", mongoClient -> {\n+                        ServerAddress currentPrimary = mongoClient.getAddress();\n+                        address.set(currentPrimary);\n+                    });\n+                }\n+                catch (InterruptedException e) {\n+                    LOGGER.error(\"Get current primary executeBlocking\", e);\n+                }\n+\n+                ServerAddress serverAddress = address.get();\n+                if (Objects.nonNull(serverAddress) && !serverAddress.equals(primaryAddress)) {\n+                    LOGGER.info(\"Found new primary event in oplog, so stopping use of {} to continue with new primary {}\",\n+                            primaryAddress, serverAddress);\n+                }\n+                else {\n+                    LOGGER.info(\"Found new primary event in oplog, current {} is new primary. \" +\n+                            \"Continue to process oplog event.\", primaryAddress);\n+                }\n+            }\n+            // Otherwise ignore\n+            if (LOGGER.isDebugEnabled()) {\n+                LOGGER.debug(\"Skipping event with no namespace: {}\", event.toJson());\n+            }\n+            return true;\n+        }\n+\n+        final List<Document> txChanges = transactionChanges(event);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d5eb1b8561e565f093f9c73b3faddd6d5ea7381"}, "originalPosition": 253}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0158b56f0742462b6f8aa26911a54be58b7f6991", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/0158b56f0742462b6f8aa26911a54be58b7f6991", "committedDate": "2020-03-10T15:44:30Z", "message": "DBZ-1726 Introduced AbstractSnapshotChangeEventSource and refactor implementations"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ece206ebfe6f9aae3f672d3ec157d429f753f95", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/7ece206ebfe6f9aae3f672d3ec157d429f753f95", "committedDate": "2020-03-10T15:45:04Z", "message": "DBZ-1726 Implemented getting transaction-id metadata"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "270f1d82445cd555dcc72cbf95faf276739d8597", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/270f1d82445cd555dcc72cbf95faf276739d8597", "committedDate": "2020-03-10T17:05:58Z", "message": "DBZ-1726 Fix formatting failures"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9158ad80db837c7db24dd0626324dacc24b5d26f", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/9158ad80db837c7db24dd0626324dacc24b5d26f", "committedDate": "2020-03-10T17:38:40Z", "message": "DBZ-1726 Fix test failure for relational connectors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a370d2bd7c672e7e5d8abbab9a324c9912f6d606", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/a370d2bd7c672e7e5d8abbab9a324c9912f6d606", "committedDate": "2020-03-10T18:20:44Z", "message": "DBZ-1726 Documentation updates for mongodb.adoc\n\n* Added metrics details\n* Changed references from initial sync to snapshot for consistency"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53a38fdf0c0952ee0b4d6261cc86ce625029df3d", "author": {"user": {"login": "Naros", "name": "Chris Cranford"}}, "url": "https://github.com/debezium/debezium/commit/53a38fdf0c0952ee0b4d6261cc86ce625029df3d", "committedDate": "2020-03-10T18:51:48Z", "message": "DBZ-1726 Added TransactionMonitor hooks"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNTc4OTAy", "url": "https://github.com/debezium/debezium/pull/1316#pullrequestreview-372578902", "createdAt": "2020-03-11T09:10:00Z", "commit": {"oid": "53a38fdf0c0952ee0b4d6261cc86ce625029df3d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2115, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}