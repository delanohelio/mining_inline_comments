{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg3OTE0Nzg2", "number": 1813, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMToyNTozNVrOEkApHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDozMTo1MlrOEkFXzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTk0NzE5OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMToyNTozNVrOHSsUxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDo0MDozMlrOHS0L6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MjYzMA==", "bodyText": "Can we use that for the downstream docs as well or do we need a different wording here?\nWhat do you suggest? @gunnarmorling  @TovaCohen", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489362630", "createdAt": "2020-09-16T11:25:35Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MzYyMw==", "bodyText": "No, for downstream this should refer to the connector CRD equivalent of this configuration.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489363623", "createdAt": "2020-09-16T11:27:43Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MjYzMA=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM4NTI3OA==", "bodyText": "Do you have an example where we link to a CRD (parallel to the docker hub link). I honestly couldn't find any example", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489385278", "createdAt": "2020-09-16T12:07:42Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MjYzMA=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM4NzAzOQ==", "bodyText": "is it {DockerKafkaConnect} ?", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489387039", "createdAt": "2020-09-16T12:10:43Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MjYzMA=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM5NzA5OQ==", "bodyText": "See any connector doc page (under \"example configuration\").", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489397099", "createdAt": "2020-09-16T12:28:16Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MjYzMA=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ3NjAxMQ==", "bodyText": "@gunnarmorling This is a CRD for a connector. The config needs to go to the Kafka Connect container env var.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489476011", "createdAt": "2020-09-16T14:20:52Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MjYzMA=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ5MTQzNA==", "bodyText": "see below", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489491434", "createdAt": "2020-09-16T14:40:32Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MjYzMA=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTk1MDAwOnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMToyNjozNlrOHSsWjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowMzo0MlrOHSyd8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MzA4Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            `auto.create.topics.enable` is enabled.{empty} +\n          \n          \n            \n            `auto.create.topics.enable` is set to `true`.{empty} +", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489363086", "createdAt": "2020-09-16T11:26:36Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2MzI4Mg==", "bodyText": "Done", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489463282", "createdAt": "2020-09-16T14:03:42Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MzA4Ng=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTk1MDg5OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMToyNjo1M1rOHSsXFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwOTo1Mzo0MVrOHUGP2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MzIyMQ==", "bodyText": "I only allowed these resources in community. Is that fine or can this be in the downstream docs as well?", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489363221", "createdAt": "2020-09-16T11:26:53Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\"\n+}\n+----\n+\n+ifdef::community[]\n+== Additional resources\n+- Debezium Blog: https://debezium.io/blog/2020/09/15/debezium-auto-create-topics/[Auto-creating Debezium Change Data Topics]\n+- Kafka Improvement Proposal about adding topic auto-creation to Kafka Connect: https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics[KIP-158]\n+endif::community[]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM5NzMxOA==", "bodyText": "No, we typically don't link to blogs/upstream from prod docs.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489397318", "createdAt": "2020-09-16T12:28:36Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\"\n+}\n+----\n+\n+ifdef::community[]\n+== Additional resources\n+- Debezium Blog: https://debezium.io/blog/2020/09/15/debezium-auto-create-topics/[Auto-creating Debezium Change Data Topics]\n+- Kafka Improvement Proposal about adding topic auto-creation to Kafka Connect: https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics[KIP-158]\n+endif::community[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MzIyMQ=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2MjQzMg==", "bodyText": "So yes, it's fine then?", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489462432", "createdAt": "2020-09-16T14:02:31Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\"\n+}\n+----\n+\n+ifdef::community[]\n+== Additional resources\n+- Debezium Blog: https://debezium.io/blog/2020/09/15/debezium-auto-create-topics/[Auto-creating Debezium Change Data Topics]\n+- Kafka Improvement Proposal about adding topic auto-creation to Kafka Connect: https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics[KIP-158]\n+endif::community[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MzIyMQ=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgzNTkyOA==", "bodyText": "Yeah :)", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r490835928", "createdAt": "2020-09-18T09:53:41Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\"\n+}\n+----\n+\n+ifdef::community[]\n+== Additional resources\n+- Debezium Blog: https://debezium.io/blog/2020/09/15/debezium-auto-create-topics/[Auto-creating Debezium Change Data Topics]\n+- Kafka Improvement Proposal about adding topic auto-creation to Kafka Connect: https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics[KIP-158]\n+endif::community[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MzIyMQ=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTk1NDQ0OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMToyODowNFrOHSsZWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowNDowMVrOHSyeyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MzgwMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            have precedent and override any inclusion rules for topics.\n          \n          \n            \n            take precedence and override any inclusion rules for topics.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489363803", "createdAt": "2020-09-16T11:28:04Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2MzQ5Nw==", "bodyText": "Done", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489463497", "createdAt": "2020-09-16T14:04:01Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2MzgwMw=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTk1NjM4OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMToyODo0MlrOHSsajw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowNDoyMVrOHSyfmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NDExMQ==", "bodyText": "There's a var in antora.yml or similar for the Kafka docs base URL.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489364111", "createdAt": "2020-09-16T11:28:42Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2MzcwNA==", "bodyText": "Done", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489463704", "createdAt": "2020-09-16T14:04:21Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NDExMQ=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTk1NzkyOnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMToyOTowN1rOHSsbgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMToyOTowN1rOHSsbgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NDM1NQ==", "bodyText": "See above.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489364355", "createdAt": "2020-09-16T11:29:07Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTk2MTI1OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMTozMDowM1rOHSsdYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowNDo1N1rOHSyhWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NDgzNA==", "bodyText": "Maybe add some empty lines between the groups?", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489364834", "createdAt": "2020-09-16T11:30:03Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM3NDE3MQ==", "bodyText": "There are empty lines in the above separate examples. In this complete example I would like to have it very authentic, means all together.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489374171", "createdAt": "2020-09-16T11:47:24Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NDgzNA=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM5NzU2OA==", "bodyText": "You can have empty lines in your real-world JSON/CRD, too ;)", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489397568", "createdAt": "2020-09-16T12:29:02Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NDgzNA=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2NDE1Mw==", "bodyText": "I know. But don't! :D", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489464153", "createdAt": "2020-09-16T14:04:57Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NDgzNA=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 196}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTk2MzE5OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMTozMDozN1rOHSsehQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowNToxM1rOHSyiTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NTEyNQ==", "bodyText": "An introductory sentence would be good: \"To learn more about topic creation settings...\".", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489365125", "createdAt": "2020-09-16T11:30:37Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\"\n+}\n+----\n+\n+ifdef::community[]\n+== Additional resources", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM3NDM4MQ==", "bodyText": "very good point! will do that.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489374381", "createdAt": "2020-09-16T11:47:47Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\"\n+}\n+----\n+\n+ifdef::community[]\n+== Additional resources", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NTEyNQ=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2NDM5OA==", "bodyText": "Done", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489464398", "createdAt": "2020-09-16T14:05:13Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,216 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is enabled.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+// TODO: how to express this for downstream?\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[Debezium's container image for Kafka Connect]).\n+====\n+\n+== Configuration\n+\n+Topic auto-creation is based on groups. Every custom group has an `include` and an\n+`exclude` property which are comma-separated lists of regular expressions matching\n+topic names that should be included or excluded.\n+\n+[NOTE]\n+====\n+You can specify both, `include` and `exclude` parameters, but note that exclusion rules\n+have precedent and override any inclusion rules for topics.\n+====\n+\n+You don't have to specify any custom group. When there's no custom group registered or\n+the registered group's `include` patterns don't match the topic which is to be created\n+then the default config will be used.\n+\n+You can specify all https://kafka.apache.org/documentation/#topicconfigs[*topic level configuration parameters*]\n+to customize how topics will be created.\n+\n+=== Default Group Config\n+\n+The default config can be passed in the connector config JSON like:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,  //<1>\n+    \"topic.creation.default.partitions\": 10,  //<2>\n+    \"topic.creation.default.cleanup.policy\": \"compact\",  //<3>\n+    \"topic.creation.default.compression.type\": \"lz4\"  //<4>\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for the `default` topic creation group\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|`topic.creation.default.replication.factor` defines the replication factor for topics created by\n+the default group.\n+\n+|2\n+|`topic.creation.default.partitions` defines the number of partitions for topics created by\n+the default group.\n+\n+|3\n+|`topic.creation.default.cleanup.policy` is mapped to the https://kafka.apache.org/documentation/#cleanup.policy[`cleanup.policy`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines the log retention policy.\n+\n+|4\n+|`topic.creation.default.compression.type` is mapped to the https://kafka.apache.org/documentation/#compression.type[`compression.type`]\n+property of the https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameters] and\n+defines how messages are compressed on harddisk.\n+|===\n+\n+As you can see, you can put every https://kafka.apache.org/documentation/#topicconfigs[topic level configuration parameter]\n+as property.\n+\n+=== Custom Group Config\n+\n+You can specify multiple groups. Similar to the `default` group you group properties together by\n+the group name. This will look like that in your connector JSON:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    //<1>\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",  //<2>\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+\n+    //<3>\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",  //<4>\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",  //<5>\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\",\n+\n+     ...\n+}\n+----\n+\n+.Connector configuration for custom `inventory` and `applicationlogs` topic creation groups\n+[cols=\"1,9\",options=\"header\"]\n+|===\n+|Item |Description\n+\n+|1\n+|First we define the configuration for the `inventory` group.\n+\n+|2\n+|`topic.creation.inventory.include` defines a regular expression to match all topics that start with\n+`dbserver1.inventory.`. The config defined for the `inventory` group will only be applied when the\n+topic name matches the given regular expression.\n+\n+|3\n+|Then we define the configuration for the `applicationlogs` group.\n+\n+|4\n+|`topic.creation.applicationlogs.include` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name matches the given regular expression. As there's also the `exclude`\n+property defined at position *<5>* all topics matching this `include` regular expression might be\n+further restricted by the that `exlude` property.\n+\n+|5\n+|`topic.creation.applicationlogs.exclude` defines a regular expression to match all topics that start\n+with `dbserver1.logs.applog-old-`. The config defined for the `applicationlogs` group will only be\n+applied when the topic name does *not* match the given regular expression. As there's also the\n+`include` property set for this group the `applicationlogs` group will only be applied to topics\n+which name matches the `include` regular expression/s *and* _not_ match the `exclude` regular\n+expression/s.\n+|===\n+\n+=== Registering Custom Groups\n+\n+Finally, we need to register the two defined custom groups `inventory` and `applicationlogs` with\n+the `topic.creation.groups` property:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+\n+     ...\n+}\n+----\n+\n+A complete connector JSON config will look like that:\n+\n+[source,options=\"nowrap\",json]\n+----\n+{\n+    ...\n+\n+    \"topic.creation.default.replication.factor\": 3,\n+    \"topic.creation.default.partitions\": 10,\n+    \"topic.creation.default.cleanup.policy\": \"compact\",\n+    \"topic.creation.default.compression.type\": \"lz4\"\n+    \"topic.creation.groups\": \"inventory,applicationlogs\",\n+    \"topic.creation.inventory.include\": \"dbserver1\\\\.inventory\\\\.*\",\n+    \"topic.creation.inventory.replication.factor\": 3,\n+    \"topic.creation.inventory.partitions\": 20,\n+    \"topic.creation.inventory.cleanup.policy\": \"compact\",\n+    \"topic.creation.inventory.delete.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.include\": \"dbserver1\\\\.logs\\\\.applog-.*\",\n+    \"topic.creation.applicationlogs.exclude\": \"dbserver1\\\\.logs\\\\.applog-old-.*\",\n+    \"topic.creation.applicationlogs.replication.factor\": 1,\n+    \"topic.creation.applicationlogs.partitions\": 20,\n+    \"topic.creation.applicationlogs.cleanup.policy\": \"delete\",\n+    \"topic.creation.applicationlogs.retention.ms\": 7776000000,\n+    \"topic.creation.applicationlogs.compression.type\": \"lz4\"\n+}\n+----\n+\n+ifdef::community[]\n+== Additional resources", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM2NTEyNQ=="}, "originalCommit": {"oid": "957e01fc0ffd997032b42e6ba2596b2f5c67371d"}, "originalPosition": 213}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MjU5OTY1OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/install.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowNjoxOFrOHSylZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwOTo1MzoyM1rOHUGPOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2NTE5MA==", "bodyText": "added a reference / backlink and note here as well @gunnarmorling", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489465190", "createdAt": "2020-09-16T14:06:18Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/install.adoc", "diffHunk": "@@ -103,6 +103,10 @@ e.g. when updating them\n ** Replicated in production\n ** Single partition\n *** You can relax the single partition rule but your application must handle out-of-order events for different rows in database (events for a single row are still totally ordered). If multiple partitions are used, Kafka will determine the partition by hashing the key by default. Other partition strategies require using SMTs to set the partition number for each record.\n+// the condition can be removed once downstream  is updated to Kafka 2.6+\n+ifdef::community[]\n+** For customizable topic auto-creation (available since Kafka Connect 2.6.0) see {link-prefix}:{link-topic-auto-creation}[Custom Topic Auto-Creation]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ae98cda4e30b79e3c74b604629e66fd8efc8f10"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgzNTc2OQ==", "bodyText": "+1", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r490835769", "createdAt": "2020-09-18T09:53:23Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/install.adoc", "diffHunk": "@@ -103,6 +103,10 @@ e.g. when updating them\n ** Replicated in production\n ** Single partition\n *** You can relax the single partition rule but your application must handle out-of-order events for different rows in database (events for a single row are still totally ordered). If multiple partitions are used, Kafka will determine the partition by hashing the key by default. Other partition strategies require using SMTs to set the partition number for each record.\n+// the condition can be removed once downstream  is updated to Kafka 2.6+\n+ifdef::community[]\n+** For customizable topic auto-creation (available since Kafka Connect 2.6.0) see {link-prefix}:{link-topic-auto-creation}[Custom Topic Auto-Creation]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2NTE5MA=="}, "originalCommit": {"oid": "0ae98cda4e30b79e3c74b604629e66fd8efc8f10"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MjcyMjA2OnYy", "diffSide": "RIGHT", "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDozMTo1MlrOHSzxeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwOTo1NTo1MlrOHUGUdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ4NDY2NA==", "bodyText": "is that a correct example for it? WDYT? @gunnarmorling", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r489484664", "createdAt": "2020-09-16T14:31:52Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,246 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is set to `true`.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+ifdef::community[]\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[{prodname}'s container image for Kafka Connect]).\n+====\n+endif::community[]\n+\n+ifdef::product[]\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect CRD:\n+====\n+\n+[source,yaml,options=\"nowrap\"]\n+----\n+apiVersion: kafka.strimzi.io/v1beta1\n+kind: KafkaConnect\n+metadata:\n+  name: my-connect-cluster\n+\n+...\n+\n+spec:\n+  config:\n+    topic.creation.enable: \"false\"\n+----\n+endif::product[]", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgzNTQ1OA==", "bodyText": "In general, yes, it is. Problem though is that downstream isn't on AK 2.6 yet, so it doesn't really make sense to have this here yet. But it's not a problem, as this page will not be added to downstream docs without explicit opt-in. Can you please log a Jira issue for tracking that for 1.3. Thanks!", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r490835458", "createdAt": "2020-09-18T09:52:45Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,246 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is set to `true`.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+ifdef::community[]\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[{prodname}'s container image for Kafka Connect]).\n+====\n+endif::community[]\n+\n+ifdef::product[]\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect CRD:\n+====\n+\n+[source,yaml,options=\"nowrap\"]\n+----\n+apiVersion: kafka.strimzi.io/v1beta1\n+kind: KafkaConnect\n+metadata:\n+  name: my-connect-cluster\n+\n+...\n+\n+spec:\n+  config:\n+    topic.creation.enable: \"false\"\n+----\n+endif::product[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ4NDY2NA=="}, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgzNzA2Ng==", "bodyText": "@TovaCohen  already created https://issues.redhat.com/browse/FUSEDOC-4157 to handle adding and styling of that docs section. It's also already annotated for the downstream module handling.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r490837066", "createdAt": "2020-09-18T09:55:46Z", "author": {"login": "rk3rn3r"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,246 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is set to `true`.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+ifdef::community[]\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[{prodname}'s container image for Kafka Connect]).\n+====\n+endif::community[]\n+\n+ifdef::product[]\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect CRD:\n+====\n+\n+[source,yaml,options=\"nowrap\"]\n+----\n+apiVersion: kafka.strimzi.io/v1beta1\n+kind: KafkaConnect\n+metadata:\n+  name: my-connect-cluster\n+\n+...\n+\n+spec:\n+  config:\n+    topic.creation.enable: \"false\"\n+----\n+endif::product[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ4NDY2NA=="}, "originalCommit": null, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgzNzExMQ==", "bodyText": "Ah, just seeing below this issue already exists. All good then.", "url": "https://github.com/debezium/debezium/pull/1813#discussion_r490837111", "createdAt": "2020-09-18T09:55:52Z", "author": {"login": "gunnarmorling"}, "path": "documentation/modules/ROOT/pages/configuration/topic-auto-create-config.adoc", "diffHunk": "@@ -0,0 +1,246 @@\n+// Category: debezium-using\n+// Type: assembly\n+// ModuleID: configuring-debezium-to-auto-create-change-data-capture-topics\n+// Title: Configuring {prodname} to use automatically create topics\n+[id=\"cdc-topic-auto-create-config\"]\n+= Custom Topic Auto-Creation\n+\n+:toc:\n+:toc-placement: macro\n+:linkattrs:\n+:icons: font\n+:source-highlighter: highlight.js\n+\n+toc::[]\n+\n+{prodname} automatically creates *internal* topics for offsets, connector status, config\n+storage and history topics. The destination topics for the captured tables will be\n+automatically created with a default config by the Kafka brokers when\n+`auto.create.topics.enable` is set to `true`.{empty} +\n+When topic creation is disabled on the brokers, for example in production environments,\n+or when the topics need a different configuration then these topics have to be created\n+upfront either automated in a custom deployment process or manually until Kafka Connect 2.6.\n+\n+Since Kafka 2.6.0 Kafka Connect supports customizable topic auto-creation.\n+\n+== Kafka Connect\n+\n+Kafka Connect since Kafka 2.6.0 comes with topic creation enabled:\n+\n+[source,options=\"nowrap\",shell]\n+----\n+topic.creation.enable = true\n+----\n+\n+ifdef::community[]\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect config (_connect-distributed.properties_ file or via environment variable\n+_CONNECT_TOPIC_CREATION_ENABLE_ when using https://hub.docker.com/r/debezium/connect[{prodname}'s container image for Kafka Connect]).\n+====\n+endif::community[]\n+\n+ifdef::product[]\n+[NOTE]\n+====\n+If you don't want to allow automatic topic creation by connectors you can set this value to `false`\n+in the Kafka Connect CRD:\n+====\n+\n+[source,yaml,options=\"nowrap\"]\n+----\n+apiVersion: kafka.strimzi.io/v1beta1\n+kind: KafkaConnect\n+metadata:\n+  name: my-connect-cluster\n+\n+...\n+\n+spec:\n+  config:\n+    topic.creation.enable: \"false\"\n+----\n+endif::product[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ4NDY2NA=="}, "originalCommit": null, "originalPosition": 64}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4204, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}