{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4ODA4NTE5", "number": 1670, "title": "[BC-25] Add snappy compression strategy for rpc messages", "bodyText": "PR Description\nThis PR adds snappy compression (see: SnappyCompressor) for RPC requests, and configures this strategy for use based on CLI options.\nThe Snappy library we're using operates over InputStream's, so the rpc processing logic was reworked to run over InputStream's rather than individual ByteBuf segments.  The RpcRequestHandler interface has been updated accordingly, and the surrounding logic has been reworked.", "createdAt": "2020-04-24T23:35:02Z", "url": "https://github.com/ConsenSys/teku/pull/1670", "merged": true, "mergeCommit": {"oid": "dfb6d62588bd0755dd4a8c19a871f49817f9db8b"}, "closed": true, "closedAt": "2020-05-01T00:54:08Z", "author": {"login": "mbaxter"}, "timelineItems": {"totalCount": 33, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABccFSK4ABqjMyODA3NzEwOTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcc14H_AFqTQwMzk0ODgzOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "55265f7232d2c236060e7532afc941a2534be016", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/55265f7232d2c236060e7532afc941a2534be016", "committedDate": "2020-04-24T23:26:15Z", "message": "Rework RPC handler to operate on InputStreams, add Compressor's"}, "afterCommit": {"oid": "6634d70a44de3b73266606b89a3bf7a5fcd95868", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/6634d70a44de3b73266606b89a3bf7a5fcd95868", "committedDate": "2020-04-28T15:04:44Z", "message": "Experiment with test fix"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6634d70a44de3b73266606b89a3bf7a5fcd95868", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/6634d70a44de3b73266606b89a3bf7a5fcd95868", "committedDate": "2020-04-28T15:04:44Z", "message": "Experiment with test fix"}, "afterCommit": {"oid": "ddd13f70c5ec0b9ebcfa1e9dd6e7912d03cf6344", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/ddd13f70c5ec0b9ebcfa1e9dd6e7912d03cf6344", "committedDate": "2020-04-28T15:47:18Z", "message": "Experiment with test fix"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ddd13f70c5ec0b9ebcfa1e9dd6e7912d03cf6344", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/ddd13f70c5ec0b9ebcfa1e9dd6e7912d03cf6344", "committedDate": "2020-04-28T15:47:18Z", "message": "Experiment with test fix"}, "afterCommit": {"oid": "162d662bc8b0d14676c5c99134be1d2311dcbe4f", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/162d662bc8b0d14676c5c99134be1d2311dcbe4f", "committedDate": "2020-04-28T17:38:12Z", "message": "Update tests to wait for async tasks to run"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "162d662bc8b0d14676c5c99134be1d2311dcbe4f", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/162d662bc8b0d14676c5c99134be1d2311dcbe4f", "committedDate": "2020-04-28T17:38:12Z", "message": "Update tests to wait for async tasks to run"}, "afterCommit": {"oid": "440fd76f38dbbd9fd75b84adf1cc49d8b97702a5", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/440fd76f38dbbd9fd75b84adf1cc49d8b97702a5", "committedDate": "2020-04-28T17:55:42Z", "message": "Update tests to wait for async tasks to run"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "39b5e08229b424ac8a3d1c3f4ac4ed76a6fdd126", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/39b5e08229b424ac8a3d1c3f4ac4ed76a6fdd126", "committedDate": "2020-04-29T18:13:49Z", "message": "Add cli option for enabling snappy compression"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "857de0c480da22d65cd1ad856bed97a99845a14d", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/857de0c480da22d65cd1ad856bed97a99845a14d", "committedDate": "2020-04-29T18:13:49Z", "message": "Set snappy compression according to network"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8612eca94b684dc8e7ff3af602a46fedf898f910", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/8612eca94b684dc8e7ff3af602a46fedf898f910", "committedDate": "2020-04-29T18:13:49Z", "message": "Add ByteUtil, fix byte validation in RocksDB utils"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fca5db90c3b02c0dc36dfe3a24e16b1ce36f694a", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/fca5db90c3b02c0dc36dfe3a24e16b1ce36f694a", "committedDate": "2020-04-29T18:13:50Z", "message": "Update async and future utils to accept exception-throwing methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "78325105f244bd37c088a699c443d72788b32203", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/78325105f244bd37c088a699c443d72788b32203", "committedDate": "2020-04-29T18:13:50Z", "message": "Rework RPC handler to operate on InputStreams, add Compressor's"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4194ba685cfec4c67f9d5469243d0fb66654f593", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/4194ba685cfec4c67f9d5469243d0fb66654f593", "committedDate": "2020-04-29T18:13:50Z", "message": "Improve logging / error handling, small cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf52c934a66f86c181a554fc77b3cecca25a1dd5", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/bf52c934a66f86c181a554fc77b3cecca25a1dd5", "committedDate": "2020-04-29T18:13:50Z", "message": "Copy relevant bytes to OutputStream"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2da34090b21e539a3d0eef9885c87a3f8464ba0", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/a2da34090b21e539a3d0eef9885c87a3f8464ba0", "committedDate": "2020-04-29T18:13:50Z", "message": "Update tests to wait for async tasks to run"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dfe9d3418a7641eabacad274c39814049f302e4d", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/dfe9d3418a7641eabacad274c39814049f302e4d", "committedDate": "2020-04-29T18:15:53Z", "message": "Select rpc encoding approach according to CLI configuration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6c0ee76e3a05da16723292da51a7419ab2e80edb", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/6c0ee76e3a05da16723292da51a7419ab2e80edb", "committedDate": "2020-04-29T18:26:19Z", "message": "Modify integration tests to run across encoding strategies"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "48044e17daa1c08ef248e142fed832164843d625", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/48044e17daa1c08ef248e142fed832164843d625", "committedDate": "2020-04-29T18:26:23Z", "message": "Don't close underlying inputStream when we uncompress data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e79d61fa021d6179b8c69d70b5e7e6fc357d013f", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/e79d61fa021d6179b8c69d70b5e7e6fc357d013f", "committedDate": "2020-04-29T18:26:23Z", "message": "Fix request handler tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca9b65cdc79583ced1ce98180e0a359bcbe7164b", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/ca9b65cdc79583ced1ce98180e0a359bcbe7164b", "committedDate": "2020-04-29T18:26:23Z", "message": "Run RequestHandler tests with different encodings"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b9c291c2ed863e811bebc727bd170e56afd4ecbe", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/b9c291c2ed863e811bebc727bd170e56afd4ecbe", "committedDate": "2020-04-29T18:13:03Z", "message": "Run RequestHandler tests with different encodings"}, "afterCommit": {"oid": "ca9b65cdc79583ced1ce98180e0a359bcbe7164b", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/ca9b65cdc79583ced1ce98180e0a359bcbe7164b", "committedDate": "2020-04-29T18:26:23Z", "message": "Run RequestHandler tests with different encodings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7394d5ac8719db5e236dc925816c698649e376c3", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/7394d5ac8719db5e236dc925816c698649e376c3", "committedDate": "2020-04-29T18:59:01Z", "message": "Fix bad merge"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bbfbea0cf6a28d565e421d7e9636f02002be304a", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/bbfbea0cf6a28d565e421d7e9636f02002be304a", "committedDate": "2020-04-29T19:00:09Z", "message": "Make default null value explicit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/2727a0b183d80178ad6c5487f2307628ebd5a13e", "committedDate": "2020-04-29T19:31:32Z", "message": "Cleanup - fix a few small issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMDY3NzE0", "url": "https://github.com/ConsenSys/teku/pull/1670#pullrequestreview-403067714", "createdAt": "2020-04-29T21:54:36Z", "commit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMTo1NDozNlrOGOSdGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMjowMzo1NVrOGOStnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzYzNTYwOQ==", "bodyText": "Internally, the SnappyFramedInputStream blocks waiting for the next full frame to arrive. So if we get a partial frame over the wire, the SnappyCompressor will block waiting for the rest of the frame to arrive.", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417635609", "createdAt": "2020-04-29T21:54:36Z", "author": {"login": "mbaxter"}, "path": "networking/eth2/src/test/java/tech/pegasys/artemis/networking/eth2/compression/SnappyCompressorTest.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 ConsenSys AG.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+ * an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package tech.pegasys.artemis.networking.eth2.compression;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static tech.pegasys.artemis.networking.eth2.compression.SnappyCompressor.MAX_FRAME_CONTENT_SIZE;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.InputStream;\n+import java.io.PipedInputStream;\n+import java.io.PipedOutputStream;\n+import org.apache.tuweni.bytes.Bytes;\n+import org.junit.jupiter.api.Disabled;\n+import org.junit.jupiter.api.Test;\n+import tech.pegasys.artemis.datastructures.state.BeaconState;\n+import tech.pegasys.artemis.datastructures.util.DataStructureUtil;\n+import tech.pegasys.artemis.datastructures.util.SimpleOffsetSerializer;\n+\n+public class SnappyCompressorTest {\n+  private final DataStructureUtil dataStructureUtil = new DataStructureUtil();\n+  private final Compressor compressor = new SnappyCompressor();\n+\n+  @Test\n+  public void roundTrip() throws Exception {\n+    final BeaconState state = dataStructureUtil.randomBeaconState(0);\n+    final Bytes serializedState =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(state).toArrayUnsafe());\n+\n+    final Bytes compressed = compressor.compress(serializedState);\n+    assertThat(compressed).isNotEqualTo(serializedState);\n+\n+    final Bytes uncompressed = compressor.uncompress(compressed);\n+    assertThat(uncompressed).isEqualTo(serializedState);\n+  }\n+\n+  @Test\n+  public void uncompress_invalidData() {\n+    final BeaconState state = dataStructureUtil.randomBeaconState(0);\n+    final Bytes serializedState =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(state).toArrayUnsafe());\n+\n+    assertThatThrownBy(() -> compressor.uncompress(serializedState))\n+        .isInstanceOf(CompressionException.class);\n+  }\n+\n+  @Test\n+  public void uncompress_seriesOfValues() throws Exception {\n+    final BeaconState stateA = dataStructureUtil.randomBeaconState(0);\n+    final BeaconState stateB = dataStructureUtil.randomBeaconState(1);\n+    final Bytes serializedStateA =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(stateA).toArrayUnsafe());\n+    final Bytes serializedStateB =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(stateB).toArrayUnsafe());\n+\n+    final Bytes compressedA = compressor.compress(serializedStateA);\n+    final Bytes compressedB = compressor.compress(serializedStateB);\n+    final Bytes compressedSeries = Bytes.concatenate(compressedA, compressedB);\n+    final InputStream input = new ByteArrayInputStream(compressedSeries.toArrayUnsafe());\n+\n+    // Get first value\n+    final Bytes uncompressed = compressor.uncompress(input, serializedStateA.size());\n+    assertThat(uncompressed).isEqualTo(serializedStateA);\n+    // Then next value\n+    final Bytes uncompressed2 = compressor.uncompress(input, serializedStateB.size());\n+    assertThat(uncompressed2).isEqualTo(serializedStateB);\n+    // Input stream should now be closed\n+    assertThat(input.available()).isEqualTo(0);\n+    assertThat(input.read()).isEqualTo(-1);\n+  }\n+\n+  @Test\n+  public void uncompress_partialValue() throws Exception {\n+    final BeaconState state = dataStructureUtil.randomBeaconState(0);\n+    final Bytes serializedState =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(state).toArrayUnsafe());\n+\n+    final Bytes compressed = compressor.compress(serializedState);\n+    final int maxBytes = MAX_FRAME_CONTENT_SIZE / 2;\n+    // Check assumptions\n+    assertThat(serializedState.size()).isGreaterThan(MAX_FRAME_CONTENT_SIZE);\n+\n+    final InputStream input = new ByteArrayInputStream(compressed.toArrayUnsafe());\n+    final Bytes uncompressed = compressor.uncompress(input, maxBytes);\n+    assertThat(uncompressed.size()).isLessThanOrEqualTo(maxBytes);\n+  }\n+\n+  @Test\n+  @Disabled(\"SnappyCompressor will currently block in this case\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzYzNzA2Nw==", "bodyText": "The networking spec says:\n\nA reader SHOULD NOT read more than max_encoded_len(n) bytes after reading the SSZ length prefix n from the header.\n\nBut I don't think we can actually enforce that atm because of how the Snappy library works.  See: https://github.com/PegaSysEng/teku/pull/1670/files#r417635609", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417637067", "createdAt": "2020-04-29T21:57:57Z", "author": {"login": "mbaxter"}, "path": "networking/eth2/src/main/java/tech/pegasys/artemis/networking/eth2/compression/Compressor.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Copyright 2020 ConsenSys AG.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+ * an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package tech.pegasys.artemis.networking.eth2.compression;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.tuweni.bytes.Bytes;\n+\n+public interface Compressor {\n+\n+  /**\n+   * Returns the compressed data\n+   *\n+   * @param data The data to compress\n+   * @return The compressed data\n+   */\n+  Bytes compress(final Bytes data);\n+\n+  /**\n+   * Returns the uncompressed data.\n+   *\n+   * @param data The data to uncompress.\n+   * @return The uncompressed data.\n+   */\n+  default Bytes uncompress(final Bytes data) throws CompressionException {\n+    try (final InputStream byteStream = new ByteArrayInputStream(data.toArrayUnsafe())) {\n+      // Read everything\n+      return uncompress(byteStream, Integer.MAX_VALUE);\n+    } catch (IOException e) {\n+      throw new RuntimeException(\n+          \"Unexpected error encountered while preparing to uncompress bytes\", e);\n+    }\n+  }\n+\n+  /**\n+   * Uncompress up to {@code maxBytes} bytes. May return fewer bytes if the end of stream is\n+   * detected or an error occurs.\n+   *\n+   * @param input The underlying {@link InputStream} to read from.\n+   * @param maxBytes The maximum number of uncompressed bytes to produce\n+   * @return The uncompressed bytes read from the underlying inputStream {@code input} stream.\n+   */\n+  Bytes uncompress(final InputStream input, final int maxBytes) throws CompressionException;\n+\n+  /**\n+   * Returns a maximum estimate of the size of a compressed payload given the uncompressed payload\n+   * size.\n+   *\n+   * @param uncompressedLength The size of an uncompressed payload.\n+   * @return The maximum size of a payload of size {@code uncompressedLength} after compression.\n+   */\n+  int getMaxCompressedLength(final int uncompressedLength);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzYzODg0Ng==", "bodyText": "(discussion) Here, we're processing the input asynchronously using the standard DelayedExecutorAsyncRunner.  Wondering if we should run these tasks in a dedicated thread pool?", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417638846", "createdAt": "2020-04-29T22:01:42Z", "author": {"login": "mbaxter"}, "path": "networking/p2p/src/main/java/tech/pegasys/artemis/networking/p2p/libp2p/rpc/RpcHandler.java", "diffHunk": "@@ -169,11 +194,25 @@ public void setRequestHandler(RpcRequestHandler rpcRequestHandler) {\n         throw new IllegalStateException(\"Attempt to set an already set data handler\");\n       }\n       this.rpcRequestHandler = rpcRequestHandler;\n-      activeFuture.thenAccept(__ -> rpcRequestHandler.onActivation(rpcStream)).reportExceptions();\n-      while (!bufferedData.isEmpty()) {\n-        ByteBuf currentBuffer = bufferedData.remove(0);\n-        this.rpcRequestHandler.onData(nodeId, rpcStream, currentBuffer);\n-      }\n+\n+      activeFuture\n+          .thenCompose(\n+              __ ->\n+                  asyncRunner.runAsync(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzYzOTgzOQ==", "bodyText": "We might want to have some kind of custom InputStream that runs over appended ByteBuf instances, similar to how we were previously managing these ByteBuf's in MessageBuffer.  If we think that's worth doing, I can add a follow-up ticket.", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417639839", "createdAt": "2020-04-29T22:03:55Z", "author": {"login": "mbaxter"}, "path": "networking/p2p/src/main/java/tech/pegasys/artemis/networking/p2p/libp2p/rpc/RpcHandler.java", "diffHunk": "@@ -157,10 +174,18 @@ public RpcStream getRpcStream() {\n \n     @Override\n     protected void channelRead0(final ChannelHandlerContext ctx, final ByteBuf msg) {\n-      if (rpcRequestHandler != null) {\n-        rpcRequestHandler.onData(nodeId, rpcStream, msg);\n-      } else {\n-        bufferedData.add(msg);\n+      if (outputStreamClosed) {\n+        // Discard any data if output stream has been closed\n+        return;\n+      }\n+      try {\n+        // TODO - we may want to optimize this to pass on ByteBuf's directly and manage their\n+        //  garbage collection rather than immediately copying these bytes\n+        final Bytes bytes = Bytes.wrapByteBuf(msg);\n+        outputStream.write(bytes.toArray());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 78}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMTE1MDk4", "url": "https://github.com/ConsenSys/teku/pull/1670#pullrequestreview-403115098", "createdAt": "2020-04-29T23:46:21Z", "commit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMzo0NjoyMlrOGOU7yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwMDo0NToyNlrOGOWAgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY3NjIzNQ==", "bodyText": "Slightly crazy idea and probably something for a follow up PR anyway, but what if we had a test fixture class implementing ArgumentsProvider that could gave a stream of Eth2Network.builder().rpcEncoding(..) with each of the encodings.  Then you could just use @ArgumentsSource(RpcEncodingsProvider.class) on methods.", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417676235", "createdAt": "2020-04-29T23:46:22Z", "author": {"login": "ajsutton"}, "path": "networking/eth2/src/integration-test/java/tech/pegasys/artemis/networking/eth2/PeerStatusIntegrationTest.java", "diffHunk": "@@ -51,17 +55,29 @@ public void tearDown() {\n     networkFactory.stopAll();\n   }\n \n-  @Test\n-  public void shouldExchangeStatusMessagesOnConnection() throws Exception {\n+  public static Stream<Arguments> getEncodings() {\n+    final List<RpcEncoding> encodings = List.of(RpcEncoding.SSZ, RpcEncoding.SSZ_SNAPPY);\n+    return encodings.stream().map(e -> Arguments.of(e.getName(), e));\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4NDU1MA==", "bodyText": "The potential risk here is that SnappyFramedInputStream maintains any kind of internal state or buffer of read data.  Sounds like it works now but it feels slightly dangerous to be creating and discarding wrapper input streams.\nIdeally when the input stream was first created, the compressor would get a chance to wrap it and then you could just use it as an input stream to read data from.  It might be possible to do that in the RpcRequestHandler but not entirely sure.", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417684550", "createdAt": "2020-04-30T00:13:12Z", "author": {"login": "ajsutton"}, "path": "networking/eth2/src/main/java/tech/pegasys/artemis/networking/eth2/compression/SnappyCompressor.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright 2020 ConsenSys AG.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+ * an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package tech.pegasys.artemis.networking.eth2.compression;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import org.apache.tuweni.bytes.Bytes;\n+import org.xerial.snappy.SnappyFramedInputStream;\n+import org.xerial.snappy.SnappyFramedOutputStream;\n+import tech.pegasys.artemis.util.iostreams.DelegatingInputStream;\n+\n+public class SnappyCompressor implements Compressor {\n+  // The max uncompressed bytes that will be packed into a single frame\n+  // See:\n+  // https://github.com/google/snappy/blob/251d935d5096da77c4fef26ea41b019430da5572/framing_format.txt#L104-L106\n+  static final int MAX_FRAME_CONTENT_SIZE = 65536;\n+\n+  @Override\n+  public Bytes compress(final Bytes data) {\n+\n+    try (final ByteArrayOutputStream out = new ByteArrayOutputStream(data.size() / 2);\n+        final OutputStream compressor = new SnappyFramedOutputStream(out)) {\n+      compressor.write(data.toArrayUnsafe());\n+      compressor.flush();\n+      return Bytes.wrap(out.toByteArray());\n+    } catch (IOException e) {\n+      throw new RuntimeException(\"Failed to compress data\", e);\n+    }\n+  }\n+\n+  @Override\n+  public Bytes uncompress(final InputStream input, final int maxBytes) throws CompressionException {\n+    // This is a bit of a hack - but we don't want to close the underlying stream when\n+    // we close the SnappyFramedInputStream\n+    final UnclosableInputStream wrappedStream = new UnclosableInputStream(input);\n+\n+    try (final InputStream snappyIn = new SnappyFramedInputStream(wrappedStream)) {\n+      return Bytes.wrap(snappyIn.readNBytes(maxBytes));\n+    } catch (IOException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4NDU5Ng==", "bodyText": "We don't ever seem to call this method.", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417684596", "createdAt": "2020-04-30T00:13:23Z", "author": {"login": "ajsutton"}, "path": "networking/eth2/src/main/java/tech/pegasys/artemis/networking/eth2/compression/SnappyCompressor.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright 2020 ConsenSys AG.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+ * an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package tech.pegasys.artemis.networking.eth2.compression;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import org.apache.tuweni.bytes.Bytes;\n+import org.xerial.snappy.SnappyFramedInputStream;\n+import org.xerial.snappy.SnappyFramedOutputStream;\n+import tech.pegasys.artemis.util.iostreams.DelegatingInputStream;\n+\n+public class SnappyCompressor implements Compressor {\n+  // The max uncompressed bytes that will be packed into a single frame\n+  // See:\n+  // https://github.com/google/snappy/blob/251d935d5096da77c4fef26ea41b019430da5572/framing_format.txt#L104-L106\n+  static final int MAX_FRAME_CONTENT_SIZE = 65536;\n+\n+  @Override\n+  public Bytes compress(final Bytes data) {\n+\n+    try (final ByteArrayOutputStream out = new ByteArrayOutputStream(data.size() / 2);\n+        final OutputStream compressor = new SnappyFramedOutputStream(out)) {\n+      compressor.write(data.toArrayUnsafe());\n+      compressor.flush();\n+      return Bytes.wrap(out.toByteArray());\n+    } catch (IOException e) {\n+      throw new RuntimeException(\"Failed to compress data\", e);\n+    }\n+  }\n+\n+  @Override\n+  public Bytes uncompress(final InputStream input, final int maxBytes) throws CompressionException {\n+    // This is a bit of a hack - but we don't want to close the underlying stream when\n+    // we close the SnappyFramedInputStream\n+    final UnclosableInputStream wrappedStream = new UnclosableInputStream(input);\n+\n+    try (final InputStream snappyIn = new SnappyFramedInputStream(wrappedStream)) {\n+      return Bytes.wrap(snappyIn.readNBytes(maxBytes));\n+    } catch (IOException e) {\n+      throw new CompressionException(\"Unable to uncompress data\", e);\n+    }\n+  }\n+\n+  @Override\n+  public int getMaxCompressedLength(final int uncompressedLength) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4NzAwNQ==", "bodyText": "In terms of being able to re-use the one input stream instead of discarding the wrapper each time - I wonder if responseDecoder rather than being used directly could be changed to something like responseDecoder.forInputStream(input) and that returns an object that provides the decodeNextResponse methods - then it'd be able to hold onto the one snappy wrapper stream.  I think you'd have to do the same trick with RpcEncoding having a decoderFor(InputStream) kind of method too and maybe again at the actual Compressor level.\nUnfortunate amount of boiler plate code there but SnappyFramedInputStream has a frameHeader buffer which worries me that would could potentially lose bytes.", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417687005", "createdAt": "2020-04-30T00:22:09Z", "author": {"login": "ajsutton"}, "path": "networking/eth2/src/main/java/tech/pegasys/artemis/networking/eth2/rpc/core/Eth2OutgoingRequestHandler.java", "diffHunk": "@@ -57,56 +58,70 @@ public Eth2OutgoingRequestHandler(\n \n     responseProcessor =\n         new AsyncResponseProcessor<>(asyncRunner, responseStream, this::onAsyncProcessorError);\n-    responseHandler = new ResponseRpcDecoder<>(responseProcessor::processResponse, this.method);\n+    responseDecoder = method.createResponseDecoder();\n   }\n \n-  @Override\n-  public void onActivation(final RpcStream rpcStream) {\n-    this.rpcStream = rpcStream;\n+  public void handleInitialPayloadSent(final RpcStream stream) {\n+    this.rpcStream = stream;\n+\n+    if (method.shouldReceiveResponse()) {\n+      // Close the write side of the stream\n+      stream.closeWriteStream().reportExceptions();\n+      // Start timer for first bytes\n+      ensureFirstBytesArriveWithinTimeLimit(stream);\n+    } else {\n+      // If we're not expecting any response, complete the request\n+      completeRequest(stream);\n+    }\n   }\n \n   @Override\n-  public void onData(final NodeId nodeId, final RpcStream rpcStream, final ByteBuf bytes) {\n+  public void processInput(\n+      final NodeId nodeId, final RpcStream rpcStream, final InputStream input) {\n     try {\n-      if (hasReceivedInitialBytes.compareAndSet(false, true)) {\n-        // Setup initial chunk timeout\n-        ensureNextResponseArrivesInTime(rpcStream, currentChunkCount.get(), currentChunkCount);\n-      }\n-      LOG.trace(\"Requester received {} bytes.\", bytes.capacity());\n-      responseHandler.onDataReceived(bytes);\n-\n-      final int previousResponseCount = currentChunkCount.get();\n-      currentChunkCount.set(responseProcessor.getResponseCount());\n-      if (currentChunkCount.get() >= maximumResponseChunks) {\n-        completeRequest(rpcStream);\n-      } else if (currentChunkCount.get() > previousResponseCount) {\n-        ensureNextResponseArrivesInTime(rpcStream, currentChunkCount.get(), currentChunkCount);\n+      this.rpcStream = rpcStream;\n+\n+      Optional<TResponse> maybeResponse =\n+          responseDecoder.decodeNextResponse(input, this::onFirstByteReceived);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY5MTQ1Mw==", "bodyText": "We probably want to get this test working before we merge.  Will unfortunately have to be multithreaded I guess and likely not all that easy to write but seems quite important.", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417691453", "createdAt": "2020-04-30T00:36:35Z", "author": {"login": "ajsutton"}, "path": "networking/eth2/src/test/java/tech/pegasys/artemis/networking/eth2/compression/SnappyCompressorTest.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 ConsenSys AG.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+ * an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package tech.pegasys.artemis.networking.eth2.compression;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static tech.pegasys.artemis.networking.eth2.compression.SnappyCompressor.MAX_FRAME_CONTENT_SIZE;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.InputStream;\n+import java.io.PipedInputStream;\n+import java.io.PipedOutputStream;\n+import org.apache.tuweni.bytes.Bytes;\n+import org.junit.jupiter.api.Disabled;\n+import org.junit.jupiter.api.Test;\n+import tech.pegasys.artemis.datastructures.state.BeaconState;\n+import tech.pegasys.artemis.datastructures.util.DataStructureUtil;\n+import tech.pegasys.artemis.datastructures.util.SimpleOffsetSerializer;\n+\n+public class SnappyCompressorTest {\n+  private final DataStructureUtil dataStructureUtil = new DataStructureUtil();\n+  private final Compressor compressor = new SnappyCompressor();\n+\n+  @Test\n+  public void roundTrip() throws Exception {\n+    final BeaconState state = dataStructureUtil.randomBeaconState(0);\n+    final Bytes serializedState =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(state).toArrayUnsafe());\n+\n+    final Bytes compressed = compressor.compress(serializedState);\n+    assertThat(compressed).isNotEqualTo(serializedState);\n+\n+    final Bytes uncompressed = compressor.uncompress(compressed);\n+    assertThat(uncompressed).isEqualTo(serializedState);\n+  }\n+\n+  @Test\n+  public void uncompress_invalidData() {\n+    final BeaconState state = dataStructureUtil.randomBeaconState(0);\n+    final Bytes serializedState =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(state).toArrayUnsafe());\n+\n+    assertThatThrownBy(() -> compressor.uncompress(serializedState))\n+        .isInstanceOf(CompressionException.class);\n+  }\n+\n+  @Test\n+  public void uncompress_seriesOfValues() throws Exception {\n+    final BeaconState stateA = dataStructureUtil.randomBeaconState(0);\n+    final BeaconState stateB = dataStructureUtil.randomBeaconState(1);\n+    final Bytes serializedStateA =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(stateA).toArrayUnsafe());\n+    final Bytes serializedStateB =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(stateB).toArrayUnsafe());\n+\n+    final Bytes compressedA = compressor.compress(serializedStateA);\n+    final Bytes compressedB = compressor.compress(serializedStateB);\n+    final Bytes compressedSeries = Bytes.concatenate(compressedA, compressedB);\n+    final InputStream input = new ByteArrayInputStream(compressedSeries.toArrayUnsafe());\n+\n+    // Get first value\n+    final Bytes uncompressed = compressor.uncompress(input, serializedStateA.size());\n+    assertThat(uncompressed).isEqualTo(serializedStateA);\n+    // Then next value\n+    final Bytes uncompressed2 = compressor.uncompress(input, serializedStateB.size());\n+    assertThat(uncompressed2).isEqualTo(serializedStateB);\n+    // Input stream should now be closed\n+    assertThat(input.available()).isEqualTo(0);\n+    assertThat(input.read()).isEqualTo(-1);\n+  }\n+\n+  @Test\n+  public void uncompress_partialValue() throws Exception {\n+    final BeaconState state = dataStructureUtil.randomBeaconState(0);\n+    final Bytes serializedState =\n+        Bytes.wrap(SimpleOffsetSerializer.serialize(state).toArrayUnsafe());\n+\n+    final Bytes compressed = compressor.compress(serializedState);\n+    final int maxBytes = MAX_FRAME_CONTENT_SIZE / 2;\n+    // Check assumptions\n+    assertThat(serializedState.size()).isGreaterThan(MAX_FRAME_CONTENT_SIZE);\n+\n+    final InputStream input = new ByteArrayInputStream(compressed.toArrayUnsafe());\n+    final Bytes uncompressed = compressor.uncompress(input, maxBytes);\n+    assertThat(uncompressed.size()).isLessThanOrEqualTo(maxBytes);\n+  }\n+\n+  @Test\n+  @Disabled(\"SnappyCompressor will currently block in this case\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY5MzgyNg==", "bodyText": "On the plus side, copying the data means we don't have to manage retaining and releasing the ByteBuf if we jump threads later.  So unless this shows up as a significant performance issue it would be great to leave as-is.", "url": "https://github.com/ConsenSys/teku/pull/1670#discussion_r417693826", "createdAt": "2020-04-30T00:45:26Z", "author": {"login": "ajsutton"}, "path": "networking/p2p/src/main/java/tech/pegasys/artemis/networking/p2p/libp2p/rpc/RpcHandler.java", "diffHunk": "@@ -157,10 +174,18 @@ public RpcStream getRpcStream() {\n \n     @Override\n     protected void channelRead0(final ChannelHandlerContext ctx, final ByteBuf msg) {\n-      if (rpcRequestHandler != null) {\n-        rpcRequestHandler.onData(nodeId, rpcStream, msg);\n-      } else {\n-        bufferedData.add(msg);\n+      if (outputStreamClosed) {\n+        // Discard any data if output stream has been closed\n+        return;\n+      }\n+      try {\n+        // TODO - we may want to optimize this to pass on ByteBuf's directly and manage their\n+        //  garbage collection rather than immediately copying these bytes\n+        final Bytes bytes = Bytes.wrapByteBuf(msg);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2727a0b183d80178ad6c5487f2307628ebd5a13e"}, "originalPosition": 77}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e83546ae4c43520f6efcce98ee827d4bd9206ef", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/0e83546ae4c43520f6efcce98ee827d4bd9206ef", "committedDate": "2020-04-30T15:40:40Z", "message": "Merge branch 'master' into bc-25/compress-rpc-messages"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8eb87800d7f0267a055ee36e8a4687eeafcba857", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/8eb87800d7f0267a055ee36e8a4687eeafcba857", "committedDate": "2020-04-30T16:56:41Z", "message": "Add test case for malicious payload, currently disabled\n\nWe need to rework the compression logic to handle this case"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d424fb768a1fd43dfe3768e39aafc8aea420b1b1", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/d424fb768a1fd43dfe3768e39aafc8aea420b1b1", "committedDate": "2020-04-30T17:52:14Z", "message": "Rework Compressor API to explicitly require expected payload size"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "347d6cdc1d4829755b260a77eafef5d077c78259", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/347d6cdc1d4829755b260a77eafef5d077c78259", "committedDate": "2020-04-30T20:16:18Z", "message": "Extract constant to utils"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc4c5ff6253e2889b24c426fff4c1fb13fdd65db", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/dc4c5ff6253e2889b24c426fff4c1fb13fdd65db", "committedDate": "2020-04-30T20:16:49Z", "message": "Limit the number of bytes we're allowed to read while uncompressing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb3f874e9004f325c9bdf1a71110ada65f0f577f", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/bb3f874e9004f325c9bdf1a71110ada65f0f577f", "committedDate": "2020-04-30T20:44:00Z", "message": "Be more forgiving when handling requests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "66c6104851bb2e2b183852878c52ed91e96900ee", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/66c6104851bb2e2b183852878c52ed91e96900ee", "committedDate": "2020-04-30T22:24:46Z", "message": "Merge branch 'master' into bc-25/compress-rpc-messages"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3e46e1214fcc1727200f4f670474721f8526d33", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/d3e46e1214fcc1727200f4f670474721f8526d33", "committedDate": "2020-04-30T23:12:52Z", "message": "Update comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0c94eac258ad2f49cd408e820dcb1b7934d36c72", "author": {"user": {"login": "mbaxter", "name": null}}, "url": "https://github.com/ConsenSys/teku/commit/0c94eac258ad2f49cd408e820dcb1b7934d36c72", "committedDate": "2020-04-30T23:13:15Z", "message": "Fix MockInputStream implementation, fix error encoding in test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzOTQ4ODM4", "url": "https://github.com/ConsenSys/teku/pull/1670#pullrequestreview-403948838", "createdAt": "2020-04-30T23:42:14Z", "commit": {"oid": "0c94eac258ad2f49cd408e820dcb1b7934d36c72"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4129, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}