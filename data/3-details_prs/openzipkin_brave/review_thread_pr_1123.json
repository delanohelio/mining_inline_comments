{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkzMzcxNjEw", "number": 1123, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDowMzo1NlrODrDnuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDowODo1N1rODrDqeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2NDc0NjgwOnYy", "diffSide": "RIGHT", "path": "instrumentation/kafka-clients/src/main/java/brave/kafka/clients/KafkaTracing.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDowMzo1NlrOF7LdjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDo0MTo0N1rOF7L9WA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5ODA5Mw==", "bodyText": "this was a bug.. I searched for all cases we (like me) did incorrect comparisons against EMPTY", "url": "https://github.com/openzipkin/brave/pull/1123#discussion_r397598093", "createdAt": "2020-03-25T04:03:56Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-clients/src/main/java/brave/kafka/clients/KafkaTracing.java", "diffHunk": "@@ -132,9 +135,12 @@ public KafkaTracing build() {\n     this.processorExtractor = propagation.extractor(KafkaPropagation.GETTER);\n     this.producerInjector = propagation.injector(KafkaProducerRequest::setHeader);\n     this.consumerInjector = propagation.injector(KafkaConsumerRequest::setHeader);\n+    this.propagationKeys = new LinkedHashSet<>(propagation.keys());\n+    // When Extra Fields or similar are in use, the result != TraceContextOrSamplingFlags.EMPTY\n+    this.emptyExtraction = propagation.<Map<String, String>>extractor(Map::get)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63f3b984fc3004c4fd17a32aeaf8fad3ce521d5b"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYwNjIzMg==", "bodyText": "Does this sort of bug only affect Kafka? If the pattern is generic enough, one idea is something like Propagation.isEmpty(TraceContextOrSamplingFlags) so we don't need to repeat this logic as much.", "url": "https://github.com/openzipkin/brave/pull/1123#discussion_r397606232", "createdAt": "2020-03-25T04:41:47Z", "author": {"login": "anuraaga"}, "path": "instrumentation/kafka-clients/src/main/java/brave/kafka/clients/KafkaTracing.java", "diffHunk": "@@ -132,9 +135,12 @@ public KafkaTracing build() {\n     this.processorExtractor = propagation.extractor(KafkaPropagation.GETTER);\n     this.producerInjector = propagation.injector(KafkaProducerRequest::setHeader);\n     this.consumerInjector = propagation.injector(KafkaConsumerRequest::setHeader);\n+    this.propagationKeys = new LinkedHashSet<>(propagation.keys());\n+    // When Extra Fields or similar are in use, the result != TraceContextOrSamplingFlags.EMPTY\n+    this.emptyExtraction = propagation.<Map<String, String>>extractor(Map::get)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5ODA5Mw=="}, "originalCommit": {"oid": "63f3b984fc3004c4fd17a32aeaf8fad3ce521d5b"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2NDc0OTIyOnYy", "diffSide": "RIGHT", "path": "instrumentation/kafka-clients/src/test/java/brave/kafka/clients/ITKafkaTracing.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDowNTo0NlrOF7Le3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDowNTo0NlrOF7Le3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5ODQyOQ==", "bodyText": "@anuraaga this is using multiple reporters.. indeed efforts like this are piecemeal as things come up. Mainly because it is so much work to refactor all the tests across all modules. Once things settle, and things stop changing, we can think hard about cleaner design with the benefit of seeing warts bit by bit.", "url": "https://github.com/openzipkin/brave/pull/1123#discussion_r397598429", "createdAt": "2020-03-25T04:05:46Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-clients/src/test/java/brave/kafka/clients/ITKafkaTracing.java", "diffHunk": "@@ -45,97 +40,57 @@\n import org.junit.ClassRule;\n import org.junit.Rule;\n import org.junit.Test;\n-import org.junit.rules.TestName;\n-import org.junit.rules.TestRule;\n-import org.junit.rules.TestWatcher;\n-import org.junit.runner.Description;\n import zipkin2.DependencyLink;\n import zipkin2.Span;\n+import zipkin2.Span.Kind;\n import zipkin2.internal.DependencyLinker;\n \n-import static brave.kafka.clients.BaseTracingTest.takeSpan;\n import static brave.kafka.clients.KafkaTags.KAFKA_TOPIC_TAG;\n import static brave.messaging.MessagingRequestMatchers.channelNameEquals;\n import static brave.messaging.MessagingRequestMatchers.operationEquals;\n import static org.assertj.core.api.Assertions.assertThat;\n import static org.assertj.core.groups.Tuple.tuple;\n \n-public class ITKafkaTracing {\n-\n-  String TEST_KEY = \"foo\";\n-  String TEST_VALUE = \"bar\";\n-\n-  /**\n-   * See brave.http.ITHttp for rationale on using a concurrent blocking queue eventhough some calls,\n-   * like consumer operations, happen on the main thread.\n-   */\n-  BlockingQueue<Span> consumerSpans = new LinkedBlockingQueue<>();\n-  BlockingQueue<Span> producerSpans = new LinkedBlockingQueue<>();\n-\n-  KafkaTracing consumerTracing = KafkaTracing.create(Tracing.newBuilder()\n-    .localServiceName(\"consumer\")\n-    .currentTraceContext(ThreadLocalCurrentTraceContext.newBuilder()\n-      .addScopeDecorator(StrictScopeDecorator.create())\n-      .build())\n-    .spanReporter(consumerSpans::add)\n-    .build());\n-  KafkaTracing producerTracing = KafkaTracing.create(Tracing.newBuilder()\n-    .localServiceName(\"producer\")\n-    .currentTraceContext(ThreadLocalCurrentTraceContext.newBuilder()\n-      .addScopeDecorator(StrictScopeDecorator.create())\n-      .build())\n-    .spanReporter(producerSpans::add)\n-    .build());\n-\n+public class ITKafkaTracing extends ITKafka {\n   @ClassRule\n   public static KafkaJunitRule kafkaRule = new KafkaJunitRule(EphemeralKafkaBroker.create());\n-  @Rule\n-  public TestName testName = new TestName();\n+\n+  @Rule public TestSpanReporter producerReporter = new TestSpanReporter();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63f3b984fc3004c4fd17a32aeaf8fad3ce521d5b"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2NDc1MDgyOnYy", "diffSide": "RIGHT", "path": "instrumentation/kafka-clients/src/test/java/brave/kafka/clients/ITKafkaTracing.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDowNjo1N1rOF7Lf3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDowNjo1N1rOF7Lf3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5ODY4NA==", "bodyText": "this sort of stuff looks gross now, but when we complete the messaging abstraction, should end up contained.", "url": "https://github.com/openzipkin/brave/pull/1123#discussion_r397598684", "createdAt": "2020-03-25T04:06:57Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-clients/src/test/java/brave/kafka/clients/ITKafkaTracing.java", "diffHunk": "@@ -331,19 +301,19 @@ void checkB3Unsampled(ConsumerRecords<String, String> records) {\n       });\n   }\n \n-  @Test public void customSampler_consumer() throws Exception {\n+  @Test public void customSampler_consumer() {\n     String topic = testName.getMethodName();\n \n-    consumerTracing = KafkaTracing.create(MessagingTracing.newBuilder(\n-      Tracing.newBuilder().spanReporter(consumerSpans::add).build()\n-    ).consumerSampler(MessagingRuleSampler.newBuilder()\n-      .putRule(operationEquals(\"receive\"), Sampler.NEVER_SAMPLE)\n-      .build()).build());\n+    consumerTracing = KafkaTracing.create(\n+      MessagingTracing.newBuilder(consumerTracing.messagingTracing.tracing())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63f3b984fc3004c4fd17a32aeaf8fad3ce521d5b"}, "originalPosition": 333}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2NDc1Mzg2OnYy", "diffSide": "RIGHT", "path": "instrumentation/kafka-clients/src/main/java/brave/kafka/clients/TracingConsumer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDowODo1N1rOF7Lhjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwNDowODo1N1rOF7Lhjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5OTExOQ==", "bodyText": "this is the code that tests now caught as a bug. Basically, when we had an empty incoming context, we'd still split into traces for each message. The reason is that we don't have an abstract notion to say if \"extra\" are empty or not. Meanwhile, the trick to just make an empty context works fine.", "url": "https://github.com/openzipkin/brave/pull/1123#discussion_r397599119", "createdAt": "2020-03-25T04:08:57Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-clients/src/main/java/brave/kafka/clients/TracingConsumer.java", "diffHunk": "@@ -98,7 +101,7 @@\n \n         // If we extracted neither a trace context, nor request-scoped data (extra),\n         // and sharing trace is enabled make or reuse a span for this topic\n-        if (extracted.equals(TraceContextOrSamplingFlags.EMPTY) && singleRootSpanOnReceiveBatch) {\n+        if (extracted.equals(emptyExtraction) && singleRootSpanOnReceiveBatch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63f3b984fc3004c4fd17a32aeaf8fad3ce521d5b"}, "originalPosition": 38}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1577, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}