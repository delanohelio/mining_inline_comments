{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEzNzk3MjM2", "number": 1189, "title": "Kafka Streams instrumentation Rationale", "bodyText": "Changes:\n\nAdd more details on transformers and partitioning\nAdd note on tracing all Kafka Streams operations.", "createdAt": "2020-05-05T23:11:42Z", "url": "https://github.com/openzipkin/brave/pull/1189", "merged": true, "mergeCommit": {"oid": "29c1e5c25c91b4d4fec8b55de8a8e8b0026fdff5"}, "closed": true, "closedAt": "2020-05-06T10:12:06Z", "author": {"login": "jeqo"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcecP2iAH2gAyNDEzNzk3MjM2OjAxMjFlM2Q4ZGI4YTVkMmY4Yjk4YmYxZDcyOTk2NzFkYmNhYTU0NjI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcelzDuAFqTQwNjQ3MDEzMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0121e3d8db8a5d2f8b98bf1d7299671dbcaa5462", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/0121e3d8db8a5d2f8b98bf1d7299671dbcaa5462", "committedDate": "2020-05-05T22:58:28Z", "message": "docs: add note on why not to trace everything on kafka streams"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "441051710ecef263f9ada60a016d534ae8179264", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/441051710ecef263f9ada60a016d534ae8179264", "committedDate": "2020-05-05T23:05:46Z", "message": "docs: rephrasing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/1f9efeb6754b2b12aef174a527bccdf0dce836d9", "committedDate": "2020-05-05T23:10:51Z", "message": "fix: add emdashs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2MjI0ODE5", "url": "https://github.com/openzipkin/brave/pull/1189#pullrequestreview-406224819", "createdAt": "2020-05-05T23:33:16Z", "commit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQyMzozMzoxNlrOGQ_XOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQyMzozMzoxNlrOGQ_XOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQ2ODUzNw==", "bodyText": "I'd change it into \"Couldn't we just enable tracing for every operation?\", not a native but feels like more representing the intention of this note.", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420468537", "createdAt": "2020-05-05T23:33:16Z", "author": {"login": "jcchavezs"}, "path": "instrumentation/kafka-streams/README.md", "diffHunk": "@@ -95,6 +95,25 @@ referencing the parent context stored on Headers, if available.\n Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).\n \n+### Why not to trace _every_ Kafka Streams operation?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2MjI1NDgx", "url": "https://github.com/openzipkin/brave/pull/1189#pullrequestreview-406225481", "createdAt": "2020-05-05T23:35:19Z", "commit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQyMzozNToxOVrOGQ_ZwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQyMzozNToxOVrOGQ_ZwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQ2OTE4NQ==", "bodyText": "I would add next to \"all operations would be traced\" the note \"(while not all of them are interesting)\"", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420469185", "createdAt": "2020-05-05T23:35:19Z", "author": {"login": "jcchavezs"}, "path": "instrumentation/kafka-streams/README.md", "diffHunk": "@@ -95,6 +95,25 @@ referencing the parent context stored on Headers, if available.\n Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).\n \n+### Why not to trace _every_ Kafka Streams operation?\n+\n+When starting to design this instrumentation, \u201ctrace everything\u201d was the first idea:\n+When a message enters the Kafka Streams topology starts a new `poll` span, and every operation\n+(e.g. `map`, `filter`, `join`, etc.) is chained as an additional child span.\n+\n+Kafka Streams materializes its topology _internally_ based on DSL operations. \n+Therefore, is not possible to hook into\n+the topology creation process to instrument each operation.\n+\n+Even though this could be desirable it would require, first, to add new \"doors\" on the Kafka Streams\n+side to manipulate or intercept data around each operation&mdash;which will be hard to sale&mdash;;\n+and even if available, it would potentially expose excessive details as **all**\n+operations would be traced, making traces harder to grok&mdash;and would probably create the need to support", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2MjQyODQ1", "url": "https://github.com/openzipkin/brave/pull/1189#pullrequestreview-406242845", "createdAt": "2020-05-06T00:29:59Z", "commit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "state": "APPROVED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwMDoyOTo1OVrOGRAYMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwMDozNTo0NVrOGRAeMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQ4NTE3MQ==", "bodyText": "do we need to do '\u2014' in markdown? oh boy...", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420485171", "createdAt": "2020-05-06T00:29:59Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/README.md", "diffHunk": "@@ -95,6 +95,25 @@ referencing the parent context stored on Headers, if available.\n Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).\n \n+### Why not to trace _every_ Kafka Streams operation?\n+\n+When starting to design this instrumentation, \u201ctrace everything\u201d was the first idea:\n+When a message enters the Kafka Streams topology starts a new `poll` span, and every operation\n+(e.g. `map`, `filter`, `join`, etc.) is chained as an additional child span.\n+\n+Kafka Streams materializes its topology _internally_ based on DSL operations. \n+Therefore, is not possible to hook into\n+the topology creation process to instrument each operation.\n+\n+Even though this could be desirable it would require, first, to add new \"doors\" on the Kafka Streams\n+side to manipulate or intercept data around each operation&mdash;which will be hard to sale&mdash;;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQ4NTQwNA==", "bodyText": "\"Why doesn't this trace all Kafka Streams operations?\"", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420485404", "createdAt": "2020-05-06T00:30:50Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/README.md", "diffHunk": "@@ -95,6 +95,25 @@ referencing the parent context stored on Headers, if available.\n Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).\n \n+### Why not to trace _every_ Kafka Streams operation?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQ2ODUzNw=="}, "originalCommit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQ4NTcwMA==", "bodyText": "For example, XXX is not traceable this way, yet a part of the stream.", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420485700", "createdAt": "2020-05-06T00:31:51Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/README.md", "diffHunk": "@@ -95,6 +95,25 @@ referencing the parent context stored on Headers, if available.\n Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).\n \n+### Why not to trace _every_ Kafka Streams operation?\n+\n+When starting to design this instrumentation, \u201ctrace everything\u201d was the first idea:\n+When a message enters the Kafka Streams topology starts a new `poll` span, and every operation\n+(e.g. `map`, `filter`, `join`, etc.) is chained as an additional child span.\n+\n+Kafka Streams materializes its topology _internally_ based on DSL operations. \n+Therefore, is not possible to hook into\n+the topology creation process to instrument each operation.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQ4NjU3NQ==", "bodyText": "move this sentence to the former paragraph to finish the thought? maybe as\n\"We considered changing Kafka Streams to have hooks to do this, but it would be a hard sell. The maintainers of Kafka Streams would have to agree to add hooks in dozens of places, and move lacking context so that they can work\"\n^^ is an assumed rationale, you can correct it.", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420486575", "createdAt": "2020-05-06T00:35:18Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/README.md", "diffHunk": "@@ -95,6 +95,25 @@ referencing the parent context stored on Headers, if available.\n Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).\n \n+### Why not to trace _every_ Kafka Streams operation?\n+\n+When starting to design this instrumentation, \u201ctrace everything\u201d was the first idea:\n+When a message enters the Kafka Streams topology starts a new `poll` span, and every operation\n+(e.g. `map`, `filter`, `join`, etc.) is chained as an additional child span.\n+\n+Kafka Streams materializes its topology _internally_ based on DSL operations. \n+Therefore, is not possible to hook into\n+the topology creation process to instrument each operation.\n+\n+Even though this could be desirable it would require, first, to add new \"doors\" on the Kafka Streams", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQ4NjcwNw==", "bodyText": "break to paragraph at \"even if available..", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420486707", "createdAt": "2020-05-06T00:35:45Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/README.md", "diffHunk": "@@ -95,6 +95,25 @@ referencing the parent context stored on Headers, if available.\n Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).\n \n+### Why not to trace _every_ Kafka Streams operation?\n+\n+When starting to design this instrumentation, \u201ctrace everything\u201d was the first idea:\n+When a message enters the Kafka Streams topology starts a new `poll` span, and every operation\n+(e.g. `map`, `filter`, `join`, etc.) is chained as an additional child span.\n+\n+Kafka Streams materializes its topology _internally_ based on DSL operations. \n+Therefore, is not possible to hook into\n+the topology creation process to instrument each operation.\n+\n+Even though this could be desirable it would require, first, to add new \"doors\" on the Kafka Streams\n+side to manipulate or intercept data around each operation&mdash;which will be hard to sale&mdash;;\n+and even if available, it would potentially expose excessive details as **all**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f9efeb6754b2b12aef174a527bccdf0dce836d9"}, "originalPosition": 16}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "520d6b849aab1f8e28b584c7b40d0120f898fc64", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/520d6b849aab1f8e28b584c7b40d0120f898fc64", "committedDate": "2020-05-06T08:29:26Z", "message": "apply feedback, and move to rationale"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2NDA0Njc2", "url": "https://github.com/openzipkin/brave/pull/1189#pullrequestreview-406404676", "createdAt": "2020-05-06T08:34:27Z", "commit": {"oid": "520d6b849aab1f8e28b584c7b40d0120f898fc64"}, "state": "APPROVED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwODozNDoyN1rOGRJFBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwODozOTo1MVrOGRJQ4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYyNzcxNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            propagated downstream onto the Stream topology. As the span context is stored in the Record Headers,\n          \n          \n            \n            propagated downstream onto the Stream topology. The span context is stored in the Record Headers,", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420627717", "createdAt": "2020-05-06T08:34:27Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/RATIONALE.md", "diffHunk": "@@ -0,0 +1,42 @@\n+# brave-kafka-streams rationale\n+\n+## What's happening?\n+Typically, there are at least two spans involved in traces produces by a Kafka Stream application:\n+* One created by the Consumers that starts a Stream or Table, by `builder.stream(topic)`.\n+* One created by the Producer that sends a records to a Stream, by `builder.to(topic)`\n+\n+By receiving records in a Kafka Streams application with Tracing enabled, the span created, once\n+a record is received, will inject the span context on the headers of the Record, and it will get\n+propagated downstream onto the Stream topology. As the span context is stored in the Record Headers,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520d6b849aab1f8e28b584c7b40d0120f898fc64"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYyNzg4OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If intermediate steps on the Stream topology require tracing, then `TracingProcessorSupplier` and\n          \n          \n            \n            If intermediate steps on the Stream topology require tracing, `TracingProcessorSupplier` and", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420627888", "createdAt": "2020-05-06T08:34:42Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/RATIONALE.md", "diffHunk": "@@ -0,0 +1,42 @@\n+# brave-kafka-streams rationale\n+\n+## What's happening?\n+Typically, there are at least two spans involved in traces produces by a Kafka Stream application:\n+* One created by the Consumers that starts a Stream or Table, by `builder.stream(topic)`.\n+* One created by the Producer that sends a records to a Stream, by `builder.to(topic)`\n+\n+By receiving records in a Kafka Streams application with Tracing enabled, the span created, once\n+a record is received, will inject the span context on the headers of the Record, and it will get\n+propagated downstream onto the Stream topology. As the span context is stored in the Record Headers,\n+the Producers at the middle (e.g. `builder.through(topic)`) or at the end of a Stream topology\n+will reference the initial span, and mark the end of a Stream Process.\n+\n+If intermediate steps on the Stream topology require tracing, then `TracingProcessorSupplier` and", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520d6b849aab1f8e28b584c7b40d0120f898fc64"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYyODM1Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            `TracingTransformerSupplier` will allow you to define a Processor/Transformer where execution is recorded as Span,\n          \n          \n            \n            `TracingTransformerSupplier` record execution into a new Span,", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420628352", "createdAt": "2020-05-06T08:35:31Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/RATIONALE.md", "diffHunk": "@@ -0,0 +1,42 @@\n+# brave-kafka-streams rationale\n+\n+## What's happening?\n+Typically, there are at least two spans involved in traces produces by a Kafka Stream application:\n+* One created by the Consumers that starts a Stream or Table, by `builder.stream(topic)`.\n+* One created by the Producer that sends a records to a Stream, by `builder.to(topic)`\n+\n+By receiving records in a Kafka Streams application with Tracing enabled, the span created, once\n+a record is received, will inject the span context on the headers of the Record, and it will get\n+propagated downstream onto the Stream topology. As the span context is stored in the Record Headers,\n+the Producers at the middle (e.g. `builder.through(topic)`) or at the end of a Stream topology\n+will reference the initial span, and mark the end of a Stream Process.\n+\n+If intermediate steps on the Stream topology require tracing, then `TracingProcessorSupplier` and\n+`TracingTransformerSupplier` will allow you to define a Processor/Transformer where execution is recorded as Span,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520d6b849aab1f8e28b584c7b40d0120f898fc64"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYyODY2Mw==", "bodyText": "mention why we care?", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420628663", "createdAt": "2020-05-06T08:36:04Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/RATIONALE.md", "diffHunk": "@@ -0,0 +1,42 @@\n+# brave-kafka-streams rationale\n+\n+## What's happening?\n+Typically, there are at least two spans involved in traces produces by a Kafka Stream application:\n+* One created by the Consumers that starts a Stream or Table, by `builder.stream(topic)`.\n+* One created by the Producer that sends a records to a Stream, by `builder.to(topic)`\n+\n+By receiving records in a Kafka Streams application with Tracing enabled, the span created, once\n+a record is received, will inject the span context on the headers of the Record, and it will get\n+propagated downstream onto the Stream topology. As the span context is stored in the Record Headers,\n+the Producers at the middle (e.g. `builder.through(topic)`) or at the end of a Stream topology\n+will reference the initial span, and mark the end of a Stream Process.\n+\n+If intermediate steps on the Stream topology require tracing, then `TracingProcessorSupplier` and\n+`TracingTransformerSupplier` will allow you to define a Processor/Transformer where execution is recorded as Span,\n+referencing the parent context stored on Headers, if available.\n+\n+### Partitioning\n+\n+Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n+grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520d6b849aab1f8e28b584c7b40d0120f898fc64"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYyOTA4NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The impact of adding these and rearrange lacking context would have a considerable impact surface.\n          \n          \n            \n            Adding these and rearrange lacking context would have a considerable library impact.", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420629085", "createdAt": "2020-05-06T08:36:50Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/RATIONALE.md", "diffHunk": "@@ -0,0 +1,42 @@\n+# brave-kafka-streams rationale\n+\n+## What's happening?\n+Typically, there are at least two spans involved in traces produces by a Kafka Stream application:\n+* One created by the Consumers that starts a Stream or Table, by `builder.stream(topic)`.\n+* One created by the Producer that sends a records to a Stream, by `builder.to(topic)`\n+\n+By receiving records in a Kafka Streams application with Tracing enabled, the span created, once\n+a record is received, will inject the span context on the headers of the Record, and it will get\n+propagated downstream onto the Stream topology. As the span context is stored in the Record Headers,\n+the Producers at the middle (e.g. `builder.through(topic)`) or at the end of a Stream topology\n+will reference the initial span, and mark the end of a Stream Process.\n+\n+If intermediate steps on the Stream topology require tracing, then `TracingProcessorSupplier` and\n+`TracingTransformerSupplier` will allow you to define a Processor/Transformer where execution is recorded as Span,\n+referencing the parent context stored on Headers, if available.\n+\n+### Partitioning\n+\n+Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n+grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).\n+\n+### Why doesn't this trace all Kafka Streams operations?\n+\n+When starting to design this instrumentation, \u201ctrace everything\u201d was the first idea:\n+When a message enters the Kafka Streams topology starts a new `poll` span, and every operation\n+(e.g. `map`, `filter`, `join`, etc.) is chained as an additional child span.\n+\n+Kafka Streams materializes its topology _internally_ based on DSL operations.\n+Therefore, is not possible to hook into the topology creation process to instrument each operation.\n+\n+We considered changing Kafka Streams to have hooks to do this, but it would be a hard sell.\n+The impact of adding these and rearrange lacking context would have a considerable impact surface.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520d6b849aab1f8e28b584c7b40d0120f898fc64"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzMDc1Mw==", "bodyText": "Even if we had hooks, tracing all operations would be excessive. The resulting large\ntraces would be harder to understand, leading to requests to disable tracing. The\ncode involved to disable tracing may mean more code than visa versa!", "url": "https://github.com/openzipkin/brave/pull/1189#discussion_r420630753", "createdAt": "2020-05-06T08:39:51Z", "author": {"login": "codefromthecrypt"}, "path": "instrumentation/kafka-streams/RATIONALE.md", "diffHunk": "@@ -0,0 +1,42 @@\n+# brave-kafka-streams rationale\n+\n+## What's happening?\n+Typically, there are at least two spans involved in traces produces by a Kafka Stream application:\n+* One created by the Consumers that starts a Stream or Table, by `builder.stream(topic)`.\n+* One created by the Producer that sends a records to a Stream, by `builder.to(topic)`\n+\n+By receiving records in a Kafka Streams application with Tracing enabled, the span created, once\n+a record is received, will inject the span context on the headers of the Record, and it will get\n+propagated downstream onto the Stream topology. As the span context is stored in the Record Headers,\n+the Producers at the middle (e.g. `builder.through(topic)`) or at the end of a Stream topology\n+will reference the initial span, and mark the end of a Stream Process.\n+\n+If intermediate steps on the Stream topology require tracing, then `TracingProcessorSupplier` and\n+`TracingTransformerSupplier` will allow you to define a Processor/Transformer where execution is recorded as Span,\n+referencing the parent context stored on Headers, if available.\n+\n+### Partitioning\n+\n+Be aware that operations that require `builder.transformer(...)` will cause re-partitioning when\n+grouping or joining downstream ([Kafka docs](https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#applying-processors-and-transformers-processor-api-integration)).\n+\n+### Why doesn't this trace all Kafka Streams operations?\n+\n+When starting to design this instrumentation, \u201ctrace everything\u201d was the first idea:\n+When a message enters the Kafka Streams topology starts a new `poll` span, and every operation\n+(e.g. `map`, `filter`, `join`, etc.) is chained as an additional child span.\n+\n+Kafka Streams materializes its topology _internally_ based on DSL operations.\n+Therefore, is not possible to hook into the topology creation process to instrument each operation.\n+\n+We considered changing Kafka Streams to have hooks to do this, but it would be a hard sell.\n+The impact of adding these and rearrange lacking context would have a considerable impact surface.\n+\n+Even if available, it would potentially expose excessive details as **all**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520d6b849aab1f8e28b584c7b40d0120f898fc64"}, "originalPosition": 35}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2bd1ba21e830f3d06586352a36d818afe7ace253", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/2bd1ba21e830f3d06586352a36d818afe7ace253", "committedDate": "2020-05-06T08:56:29Z", "message": "Update instrumentation/kafka-streams/RATIONALE.md\n\nCo-authored-by: Adrian Cole <adriancole@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d709714332effb49d96b50404a70bbfa68ef9201", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/d709714332effb49d96b50404a70bbfa68ef9201", "committedDate": "2020-05-06T08:57:16Z", "message": "Update instrumentation/kafka-streams/RATIONALE.md\n\nCo-authored-by: Adrian Cole <adriancole@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9992561616deca2804664e3abfd5bc9ed11e2bbe", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/9992561616deca2804664e3abfd5bc9ed11e2bbe", "committedDate": "2020-05-06T08:57:31Z", "message": "Update instrumentation/kafka-streams/RATIONALE.md\n\nCo-authored-by: Adrian Cole <adriancole@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef8d4e95a6011bb17a5b4d453ba0ae7e1df4fa40", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/ef8d4e95a6011bb17a5b4d453ba0ae7e1df4fa40", "committedDate": "2020-05-06T08:58:11Z", "message": "Update instrumentation/kafka-streams/RATIONALE.md\n\nCo-authored-by: Adrian Cole <adriancole@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e3abf8ea673be57a461aee615204be9ee11c706", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/0e3abf8ea673be57a461aee615204be9ee11c706", "committedDate": "2020-05-06T09:01:45Z", "message": "apply adriano's feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f25cc1513587c4e54b68a73db26ee653bc03cb61", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/f25cc1513587c4e54b68a73db26ee653bc03cb61", "committedDate": "2020-05-06T09:17:25Z", "message": "add more details on partitioning"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd084b03df30a33ae18dc0ebbf0e6522323acb99", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/openzipkin/brave/commit/bd084b03df30a33ae18dc0ebbf0e6522323acb99", "committedDate": "2020-05-06T09:18:15Z", "message": "fix title"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2NDcwMTMz", "url": "https://github.com/openzipkin/brave/pull/1189#pullrequestreview-406470133", "createdAt": "2020-05-06T10:06:04Z", "commit": {"oid": "bd084b03df30a33ae18dc0ebbf0e6522323acb99"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1718, "cost": 1, "resetAt": "2021-11-01T15:33:45Z"}}}