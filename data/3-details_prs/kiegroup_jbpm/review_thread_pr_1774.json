{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAwMDY0ODI3", "number": 1774, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNzo0NjoyNVrOEs6KYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQxMzo0ODoyOFrOEwQpHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NTI1NzI4OnYy", "diffSide": "RIGHT", "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNzo0NjoyNVrOHgZokw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxMjoyMjo1N1rOHgj91A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzczNjQ2Nw==", "bodyText": "Not involved in the tx. We don't want phantom messages in the queue.", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r503736467", "createdAt": "2020-10-13T07:46:25Z", "author": {"login": "elguardian"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * This event emitter expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>\n+ *  <li>org.jbpm.event.emitters.kafka.boopstrap.servers - kafka server ip, default is localhost:9092</li>\n+ *  <li>org.jbpm.event.emitters.kafka.topic.<processes|tasks|cases>. Topic name for subscribing to these events. Defaults are \"jbpm-<processes|tasks|cases>-events\"</li>\n+ * </ul> \n+ */\n+public class KafkaEventEmitter implements EventEmitter {\n+    private static final String SOURCE_FORMATTER = \"/process/%s/%s\";\n+    private Producer<String, byte[]> producer;\n+    private ObjectMapper mapper;\n+\n+    public KafkaEventEmitter() {\n+        this(new KafkaProducer<>(getConfigs()));\n+    }\n+\n+    // allow unit test\n+    KafkaEventEmitter(Producer<String, byte[]> producer) {\n+        this.producer = producer;\n+        mapper = new ObjectMapper()\n+                .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                        \"org.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                                \"org.kie.server.json.date_format\",\n+                                \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))))\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+    }\n+\n+    public void deliver(Collection<InstanceView<?>> data) {\n+        // no-op\n+    }\n+\n+    public void apply(Collection<InstanceView<?>> data) {\n+        if (data == null || data.isEmpty()) {\n+            return;\n+        }\n+\n+        for (InstanceView<?> view : data) {\n+            String processId;\n+            long processInstanceId;\n+            String type;\n+            String topic;\n+            if (view instanceof ProcessInstanceView) {\n+                ProcessInstanceView processInstanceView = (ProcessInstanceView) view;\n+                topic = \"processes\";\n+                type = \"process\";\n+                processInstanceId = processInstanceView.getId();\n+                processId = processInstanceView.getProcessId();\n+            } else if (view instanceof TaskInstanceView) {\n+                TaskInstanceView taskInstanceView = (TaskInstanceView) view;\n+                topic = \"tasks\";\n+                type = \"task\";\n+                processInstanceId = taskInstanceView.getProcessInstanceId();\n+                processId = taskInstanceView.getProcessId();\n+            } else if (view instanceof CaseInstanceView) {\n+                CaseInstanceView caseInstanceView = (CaseInstanceView) view;\n+                topic = \"cases\";\n+                type = \"case\";\n+                processInstanceId = caseInstanceView.getId();\n+                processId = caseInstanceView.getCaseDefinitionId();\n+            } else {\n+                throw new UnsupportedOperationException(\"view \" + view.getClass());\n+            }\n+            try {\n+                producer.send(new ProducerRecord<>(getTopic(topic), mapper.writeValueAsBytes(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad11ca5d768a30fdea5baee58f8d255c5200fc5"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzkwNTc0OA==", "bodyText": "Transactional approach has been changed.\nIn deliver method we prepare the data\nIn apply we commit\nIn drop we rollback\nThis requires the usage of a ThreadLocal variable for the kafka transactional producer", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r503905748", "createdAt": "2020-10-13T12:22:57Z", "author": {"login": "fjtirado"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * This event emitter expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>\n+ *  <li>org.jbpm.event.emitters.kafka.boopstrap.servers - kafka server ip, default is localhost:9092</li>\n+ *  <li>org.jbpm.event.emitters.kafka.topic.<processes|tasks|cases>. Topic name for subscribing to these events. Defaults are \"jbpm-<processes|tasks|cases>-events\"</li>\n+ * </ul> \n+ */\n+public class KafkaEventEmitter implements EventEmitter {\n+    private static final String SOURCE_FORMATTER = \"/process/%s/%s\";\n+    private Producer<String, byte[]> producer;\n+    private ObjectMapper mapper;\n+\n+    public KafkaEventEmitter() {\n+        this(new KafkaProducer<>(getConfigs()));\n+    }\n+\n+    // allow unit test\n+    KafkaEventEmitter(Producer<String, byte[]> producer) {\n+        this.producer = producer;\n+        mapper = new ObjectMapper()\n+                .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                        \"org.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                                \"org.kie.server.json.date_format\",\n+                                \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))))\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+    }\n+\n+    public void deliver(Collection<InstanceView<?>> data) {\n+        // no-op\n+    }\n+\n+    public void apply(Collection<InstanceView<?>> data) {\n+        if (data == null || data.isEmpty()) {\n+            return;\n+        }\n+\n+        for (InstanceView<?> view : data) {\n+            String processId;\n+            long processInstanceId;\n+            String type;\n+            String topic;\n+            if (view instanceof ProcessInstanceView) {\n+                ProcessInstanceView processInstanceView = (ProcessInstanceView) view;\n+                topic = \"processes\";\n+                type = \"process\";\n+                processInstanceId = processInstanceView.getId();\n+                processId = processInstanceView.getProcessId();\n+            } else if (view instanceof TaskInstanceView) {\n+                TaskInstanceView taskInstanceView = (TaskInstanceView) view;\n+                topic = \"tasks\";\n+                type = \"task\";\n+                processInstanceId = taskInstanceView.getProcessInstanceId();\n+                processId = taskInstanceView.getProcessId();\n+            } else if (view instanceof CaseInstanceView) {\n+                CaseInstanceView caseInstanceView = (CaseInstanceView) view;\n+                topic = \"cases\";\n+                type = \"case\";\n+                processInstanceId = caseInstanceView.getId();\n+                processId = caseInstanceView.getCaseDefinitionId();\n+            } else {\n+                throw new UnsupportedOperationException(\"view \" + view.getClass());\n+            }\n+            try {\n+                producer.send(new ProducerRecord<>(getTopic(topic), mapper.writeValueAsBytes(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzczNjQ2Nw=="}, "originalCommit": {"oid": "dad11ca5d768a30fdea5baee58f8d255c5200fc5"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NTI2NzU0OnYy", "diffSide": "RIGHT", "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNzo0OTowMFrOHgZuwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxMjoyMzoxMFrOHgj-WQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzczODA0OA==", "bodyText": "org.kie.jbpm.emitter.kafka.bootstrap.servers.\nThat is the standard.", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r503738048", "createdAt": "2020-10-13T07:49:00Z", "author": {"login": "elguardian"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * This event emitter expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>\n+ *  <li>org.jbpm.event.emitters.kafka.boopstrap.servers - kafka server ip, default is localhost:9092</li>\n+ *  <li>org.jbpm.event.emitters.kafka.topic.<processes|tasks|cases>. Topic name for subscribing to these events. Defaults are \"jbpm-<processes|tasks|cases>-events\"</li>\n+ * </ul> \n+ */\n+public class KafkaEventEmitter implements EventEmitter {\n+    private static final String SOURCE_FORMATTER = \"/process/%s/%s\";\n+    private Producer<String, byte[]> producer;\n+    private ObjectMapper mapper;\n+\n+    public KafkaEventEmitter() {\n+        this(new KafkaProducer<>(getConfigs()));\n+    }\n+\n+    // allow unit test\n+    KafkaEventEmitter(Producer<String, byte[]> producer) {\n+        this.producer = producer;\n+        mapper = new ObjectMapper()\n+                .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                        \"org.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                                \"org.kie.server.json.date_format\",\n+                                \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))))\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+    }\n+\n+    public void deliver(Collection<InstanceView<?>> data) {\n+        // no-op\n+    }\n+\n+    public void apply(Collection<InstanceView<?>> data) {\n+        if (data == null || data.isEmpty()) {\n+            return;\n+        }\n+\n+        for (InstanceView<?> view : data) {\n+            String processId;\n+            long processInstanceId;\n+            String type;\n+            String topic;\n+            if (view instanceof ProcessInstanceView) {\n+                ProcessInstanceView processInstanceView = (ProcessInstanceView) view;\n+                topic = \"processes\";\n+                type = \"process\";\n+                processInstanceId = processInstanceView.getId();\n+                processId = processInstanceView.getProcessId();\n+            } else if (view instanceof TaskInstanceView) {\n+                TaskInstanceView taskInstanceView = (TaskInstanceView) view;\n+                topic = \"tasks\";\n+                type = \"task\";\n+                processInstanceId = taskInstanceView.getProcessInstanceId();\n+                processId = taskInstanceView.getProcessId();\n+            } else if (view instanceof CaseInstanceView) {\n+                CaseInstanceView caseInstanceView = (CaseInstanceView) view;\n+                topic = \"cases\";\n+                type = \"case\";\n+                processInstanceId = caseInstanceView.getId();\n+                processId = caseInstanceView.getCaseDefinitionId();\n+            } else {\n+                throw new UnsupportedOperationException(\"view \" + view.getClass());\n+            }\n+            try {\n+                producer.send(new ProducerRecord<>(getTopic(topic), mapper.writeValueAsBytes(\n+                        new CloudEventSpec1(type, String.format(SOURCE_FORMATTER, processId, processInstanceId),\n+                                view))));\n+            } catch (JsonProcessingException e) {\n+                throw new IllegalArgumentException(\"cannot convert \" + view + \" to byte[]\", e);\n+            }\n+        }\n+    }\n+\n+    private static String getTopic(String eventType) {\n+        return System.getProperty(\"org.jbpm.event.emitters.kafka.topic.\" + eventType, \"jbpm-\" + eventType + \"-events\");\n+    }\n+\n+    public void drop(Collection<InstanceView<?>> data) {\n+        // no-op\n+    }\n+\n+    @Override\n+    public void close() {\n+        producer.close();\n+    }\n+\n+    @Override\n+    public EventCollection newCollection() {\n+        return new BaseEventCollection();\n+    }\n+\n+    private static Map<String, Object> getConfigs() {\n+        Map<String, Object> configs = new HashMap<>();\n+        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                \"org.jbpm.event.emitters.kafka.boopstrap.servers\", \"localhost:9092\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad11ca5d768a30fdea5baee58f8d255c5200fc5"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzkwNTg4MQ==", "bodyText": "Changed", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r503905881", "createdAt": "2020-10-13T12:23:10Z", "author": {"login": "fjtirado"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * This event emitter expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>\n+ *  <li>org.jbpm.event.emitters.kafka.boopstrap.servers - kafka server ip, default is localhost:9092</li>\n+ *  <li>org.jbpm.event.emitters.kafka.topic.<processes|tasks|cases>. Topic name for subscribing to these events. Defaults are \"jbpm-<processes|tasks|cases>-events\"</li>\n+ * </ul> \n+ */\n+public class KafkaEventEmitter implements EventEmitter {\n+    private static final String SOURCE_FORMATTER = \"/process/%s/%s\";\n+    private Producer<String, byte[]> producer;\n+    private ObjectMapper mapper;\n+\n+    public KafkaEventEmitter() {\n+        this(new KafkaProducer<>(getConfigs()));\n+    }\n+\n+    // allow unit test\n+    KafkaEventEmitter(Producer<String, byte[]> producer) {\n+        this.producer = producer;\n+        mapper = new ObjectMapper()\n+                .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                        \"org.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                                \"org.kie.server.json.date_format\",\n+                                \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))))\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+    }\n+\n+    public void deliver(Collection<InstanceView<?>> data) {\n+        // no-op\n+    }\n+\n+    public void apply(Collection<InstanceView<?>> data) {\n+        if (data == null || data.isEmpty()) {\n+            return;\n+        }\n+\n+        for (InstanceView<?> view : data) {\n+            String processId;\n+            long processInstanceId;\n+            String type;\n+            String topic;\n+            if (view instanceof ProcessInstanceView) {\n+                ProcessInstanceView processInstanceView = (ProcessInstanceView) view;\n+                topic = \"processes\";\n+                type = \"process\";\n+                processInstanceId = processInstanceView.getId();\n+                processId = processInstanceView.getProcessId();\n+            } else if (view instanceof TaskInstanceView) {\n+                TaskInstanceView taskInstanceView = (TaskInstanceView) view;\n+                topic = \"tasks\";\n+                type = \"task\";\n+                processInstanceId = taskInstanceView.getProcessInstanceId();\n+                processId = taskInstanceView.getProcessId();\n+            } else if (view instanceof CaseInstanceView) {\n+                CaseInstanceView caseInstanceView = (CaseInstanceView) view;\n+                topic = \"cases\";\n+                type = \"case\";\n+                processInstanceId = caseInstanceView.getId();\n+                processId = caseInstanceView.getCaseDefinitionId();\n+            } else {\n+                throw new UnsupportedOperationException(\"view \" + view.getClass());\n+            }\n+            try {\n+                producer.send(new ProducerRecord<>(getTopic(topic), mapper.writeValueAsBytes(\n+                        new CloudEventSpec1(type, String.format(SOURCE_FORMATTER, processId, processInstanceId),\n+                                view))));\n+            } catch (JsonProcessingException e) {\n+                throw new IllegalArgumentException(\"cannot convert \" + view + \" to byte[]\", e);\n+            }\n+        }\n+    }\n+\n+    private static String getTopic(String eventType) {\n+        return System.getProperty(\"org.jbpm.event.emitters.kafka.topic.\" + eventType, \"jbpm-\" + eventType + \"-events\");\n+    }\n+\n+    public void drop(Collection<InstanceView<?>> data) {\n+        // no-op\n+    }\n+\n+    @Override\n+    public void close() {\n+        producer.close();\n+    }\n+\n+    @Override\n+    public EventCollection newCollection() {\n+        return new BaseEventCollection();\n+    }\n+\n+    private static Map<String, Object> getConfigs() {\n+        Map<String, Object> configs = new HashMap<>();\n+        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                \"org.jbpm.event.emitters.kafka.boopstrap.servers\", \"localhost:9092\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzczODA0OA=="}, "originalCommit": {"oid": "dad11ca5d768a30fdea5baee58f8d255c5200fc5"}, "originalPosition": 137}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NTI3MTIwOnYy", "diffSide": "RIGHT", "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNzo0OTo1M1rOHgZw6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxMjoyMTo1OVrOHgj7kA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzczODYwMg==", "bodyText": "More meaninful name for the cloud event. Maybe KafkaEventSpecification if you like.", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r503738602", "createdAt": "2020-10-13T07:49:53Z", "author": {"login": "elguardian"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * This event emitter expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>\n+ *  <li>org.jbpm.event.emitters.kafka.boopstrap.servers - kafka server ip, default is localhost:9092</li>\n+ *  <li>org.jbpm.event.emitters.kafka.topic.<processes|tasks|cases>. Topic name for subscribing to these events. Defaults are \"jbpm-<processes|tasks|cases>-events\"</li>\n+ * </ul> \n+ */\n+public class KafkaEventEmitter implements EventEmitter {\n+    private static final String SOURCE_FORMATTER = \"/process/%s/%s\";\n+    private Producer<String, byte[]> producer;\n+    private ObjectMapper mapper;\n+\n+    public KafkaEventEmitter() {\n+        this(new KafkaProducer<>(getConfigs()));\n+    }\n+\n+    // allow unit test\n+    KafkaEventEmitter(Producer<String, byte[]> producer) {\n+        this.producer = producer;\n+        mapper = new ObjectMapper()\n+                .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                        \"org.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                                \"org.kie.server.json.date_format\",\n+                                \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))))\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+    }\n+\n+    public void deliver(Collection<InstanceView<?>> data) {\n+        // no-op\n+    }\n+\n+    public void apply(Collection<InstanceView<?>> data) {\n+        if (data == null || data.isEmpty()) {\n+            return;\n+        }\n+\n+        for (InstanceView<?> view : data) {\n+            String processId;\n+            long processInstanceId;\n+            String type;\n+            String topic;\n+            if (view instanceof ProcessInstanceView) {\n+                ProcessInstanceView processInstanceView = (ProcessInstanceView) view;\n+                topic = \"processes\";\n+                type = \"process\";\n+                processInstanceId = processInstanceView.getId();\n+                processId = processInstanceView.getProcessId();\n+            } else if (view instanceof TaskInstanceView) {\n+                TaskInstanceView taskInstanceView = (TaskInstanceView) view;\n+                topic = \"tasks\";\n+                type = \"task\";\n+                processInstanceId = taskInstanceView.getProcessInstanceId();\n+                processId = taskInstanceView.getProcessId();\n+            } else if (view instanceof CaseInstanceView) {\n+                CaseInstanceView caseInstanceView = (CaseInstanceView) view;\n+                topic = \"cases\";\n+                type = \"case\";\n+                processInstanceId = caseInstanceView.getId();\n+                processId = caseInstanceView.getCaseDefinitionId();\n+            } else {\n+                throw new UnsupportedOperationException(\"view \" + view.getClass());\n+            }\n+            try {\n+                producer.send(new ProducerRecord<>(getTopic(topic), mapper.writeValueAsBytes(\n+                        new CloudEventSpec1(type, String.format(SOURCE_FORMATTER, processId, processInstanceId),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad11ca5d768a30fdea5baee58f8d255c5200fc5"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzkwNTE2OA==", "bodyText": "The event format, as requested in JIRA, follow the kogito format, which use Cloud Event spec 1 https://github.com/cloudevents/spec. Having this info into account, the current name is pretty descriptive ;)", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r503905168", "createdAt": "2020-10-13T12:21:59Z", "author": {"login": "fjtirado"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * This event emitter expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>\n+ *  <li>org.jbpm.event.emitters.kafka.boopstrap.servers - kafka server ip, default is localhost:9092</li>\n+ *  <li>org.jbpm.event.emitters.kafka.topic.<processes|tasks|cases>. Topic name for subscribing to these events. Defaults are \"jbpm-<processes|tasks|cases>-events\"</li>\n+ * </ul> \n+ */\n+public class KafkaEventEmitter implements EventEmitter {\n+    private static final String SOURCE_FORMATTER = \"/process/%s/%s\";\n+    private Producer<String, byte[]> producer;\n+    private ObjectMapper mapper;\n+\n+    public KafkaEventEmitter() {\n+        this(new KafkaProducer<>(getConfigs()));\n+    }\n+\n+    // allow unit test\n+    KafkaEventEmitter(Producer<String, byte[]> producer) {\n+        this.producer = producer;\n+        mapper = new ObjectMapper()\n+                .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                        \"org.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                                \"org.kie.server.json.date_format\",\n+                                \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))))\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+    }\n+\n+    public void deliver(Collection<InstanceView<?>> data) {\n+        // no-op\n+    }\n+\n+    public void apply(Collection<InstanceView<?>> data) {\n+        if (data == null || data.isEmpty()) {\n+            return;\n+        }\n+\n+        for (InstanceView<?> view : data) {\n+            String processId;\n+            long processInstanceId;\n+            String type;\n+            String topic;\n+            if (view instanceof ProcessInstanceView) {\n+                ProcessInstanceView processInstanceView = (ProcessInstanceView) view;\n+                topic = \"processes\";\n+                type = \"process\";\n+                processInstanceId = processInstanceView.getId();\n+                processId = processInstanceView.getProcessId();\n+            } else if (view instanceof TaskInstanceView) {\n+                TaskInstanceView taskInstanceView = (TaskInstanceView) view;\n+                topic = \"tasks\";\n+                type = \"task\";\n+                processInstanceId = taskInstanceView.getProcessInstanceId();\n+                processId = taskInstanceView.getProcessId();\n+            } else if (view instanceof CaseInstanceView) {\n+                CaseInstanceView caseInstanceView = (CaseInstanceView) view;\n+                topic = \"cases\";\n+                type = \"case\";\n+                processInstanceId = caseInstanceView.getId();\n+                processId = caseInstanceView.getCaseDefinitionId();\n+            } else {\n+                throw new UnsupportedOperationException(\"view \" + view.getClass());\n+            }\n+            try {\n+                producer.send(new ProducerRecord<>(getTopic(topic), mapper.writeValueAsBytes(\n+                        new CloudEventSpec1(type, String.format(SOURCE_FORMATTER, processId, processInstanceId),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzczODYwMg=="}, "originalCommit": {"oid": "dad11ca5d768a30fdea5baee58f8d255c5200fc5"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MDQwMjIzOnYy", "diffSide": "RIGHT", "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/CloudEvent_1_0.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwOTozMzo1MlrOHhKjWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMToxNjo0MlrOHhOHZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUzNzk0Nw==", "bodyText": "In the examples from the cloudevent documentation is set up to \"1.0\", perhaps it's nitpicking, and it has no importance at all", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r504537947", "createdAt": "2020-10-14T09:33:52Z", "author": {"login": "gmunozfe"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/CloudEvent_1_0.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.util.Date;\n+import java.util.UUID;\n+\n+class CloudEventSpec1 {\n+\n+    private String specversion = \"1_0\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca4768dc20efe45190354ce665bfad867dd6a9d8"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU5NjMyNQ==", "bodyText": "good catch", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r504596325", "createdAt": "2020-10-14T11:16:42Z", "author": {"login": "fjtirado"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/CloudEvent_1_0.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.util.Date;\n+import java.util.UUID;\n+\n+class CloudEventSpec1 {\n+\n+    private String specversion = \"1_0\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUzNzk0Nw=="}, "originalCommit": {"oid": "ca4768dc20efe45190354ce665bfad867dd6a9d8"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MDQyMjk4OnYy", "diffSide": "RIGHT", "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwOTozODo1OVrOHhKvnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMToxNTo1OFrOHhOF9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU0MTA4NQ==", "bodyText": "I think default value with localhost and fixed port may be misleading (if there's another bootstrap running there but it's not the target one), probably it's better to fail with an exception if the property is not configured, wdyt?", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r504541085", "createdAt": "2020-10-14T09:38:59Z", "author": {"login": "gmunozfe"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.io.IOException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.KafkaException;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * Expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.boopstrap.servers - kafka server ip, default is localhost:9092</li>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.topic.<processes|tasks|cases>. Topic name for subscribing to these events. Defaults are \"jbpm-<processes|tasks|cases>-events\"</li>\n+ * </ul> \n+ */\n+public class KafkaEventEmitter implements EventEmitter {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaEventEmitter.class);\n+    private static final String SOURCE_FORMATTER = \"/process/%s/%s\";\n+    private ObjectMapper mapper;\n+\n+    private ThreadLocal<Producer<String, byte[]>> localProducer = new ThreadLocal<>();\n+\n+    public KafkaEventEmitter() {\n+        mapper = new ObjectMapper()\n+                .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                        \"org.kie.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                                \"org.kie.server.json.date_format\",\n+                                \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))))\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+    }\n+\n+    public void deliver(Collection<InstanceView<?>> data) {\n+        if (data == null || data.isEmpty()) {\n+            return;\n+        }\n+        Producer<String, byte[]> producer = getProducer();\n+        localProducer.set(producer);\n+        producer.initTransactions();\n+        producer.beginTransaction();\n+\n+        for (InstanceView<?> view : data) {\n+            String processId;\n+            long processInstanceId;\n+            String type;\n+            String topic;\n+            if (view instanceof ProcessInstanceView) {\n+                ProcessInstanceView processInstanceView = (ProcessInstanceView) view;\n+                topic = \"processes\";\n+                type = \"process\";\n+                processInstanceId = processInstanceView.getId();\n+                processId = processInstanceView.getProcessId();\n+            } else if (view instanceof TaskInstanceView) {\n+                TaskInstanceView taskInstanceView = (TaskInstanceView) view;\n+                topic = \"tasks\";\n+                type = \"task\";\n+                processInstanceId = taskInstanceView.getProcessInstanceId();\n+                processId = taskInstanceView.getProcessId();\n+            } else if (view instanceof CaseInstanceView) {\n+                CaseInstanceView caseInstanceView = (CaseInstanceView) view;\n+                topic = \"cases\";\n+                type = \"case\";\n+                processInstanceId = caseInstanceView.getId();\n+                processId = caseInstanceView.getCaseDefinitionId();\n+            } else {\n+                throw new UnsupportedOperationException(\"Unsupported view type \" + view.getClass());\n+            }\n+            try {\n+                producer.send(new ProducerRecord<>(getTopic(topic), mapper.writeValueAsBytes(\n+                        new CloudEventSpec1(type, String.format(SOURCE_FORMATTER, processId, processInstanceId),\n+                                view))));\n+            } catch (IOException ex) {\n+                throw new IllegalArgumentException(\"Error creating cloud event for view \" + view, ex);\n+            }\n+        }\n+    }\n+\n+    @SuppressWarnings({\"squid:S2139\", \"squid:S3457\"})\n+    public void apply(Collection<InstanceView<?>> data) {\n+        try {\n+            localProducer.get().commitTransaction();\n+        } catch (KafkaException ex) {\n+            logger.error(\"Error publishing events \" + data, ex);\n+            localProducer.get().abortTransaction();\n+            throw ex;\n+        } finally {\n+            localProducer.remove();\n+        }\n+    }\n+\n+    public void drop(Collection<InstanceView<?>> data) {\n+        try {\n+            localProducer.get().abortTransaction();\n+        } finally {\n+            localProducer.remove();\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        localProducer.remove();\n+    }\n+\n+    @Override\n+    public EventCollection newCollection() {\n+        return new BaseEventCollection();\n+    }\n+\n+    protected Producer<String, byte[]> getProducer() {\n+        Map<String, Object> configs = new HashMap<>();\n+        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                \"org.kie.jbpm.event.emitters.kafka.boopstrap.servers\", \"localhost:9092\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca4768dc20efe45190354ce665bfad867dd6a9d8"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU5NTk1OQ==", "bodyText": "hmmmm, I think we should try the default, exception will be thrown if not found there anyway", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r504595959", "createdAt": "2020-10-14T11:15:58Z", "author": {"login": "fjtirado"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.io.IOException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.KafkaException;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * Expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.boopstrap.servers - kafka server ip, default is localhost:9092</li>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.topic.<processes|tasks|cases>. Topic name for subscribing to these events. Defaults are \"jbpm-<processes|tasks|cases>-events\"</li>\n+ * </ul> \n+ */\n+public class KafkaEventEmitter implements EventEmitter {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaEventEmitter.class);\n+    private static final String SOURCE_FORMATTER = \"/process/%s/%s\";\n+    private ObjectMapper mapper;\n+\n+    private ThreadLocal<Producer<String, byte[]>> localProducer = new ThreadLocal<>();\n+\n+    public KafkaEventEmitter() {\n+        mapper = new ObjectMapper()\n+                .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                        \"org.kie.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                                \"org.kie.server.json.date_format\",\n+                                \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))))\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+    }\n+\n+    public void deliver(Collection<InstanceView<?>> data) {\n+        if (data == null || data.isEmpty()) {\n+            return;\n+        }\n+        Producer<String, byte[]> producer = getProducer();\n+        localProducer.set(producer);\n+        producer.initTransactions();\n+        producer.beginTransaction();\n+\n+        for (InstanceView<?> view : data) {\n+            String processId;\n+            long processInstanceId;\n+            String type;\n+            String topic;\n+            if (view instanceof ProcessInstanceView) {\n+                ProcessInstanceView processInstanceView = (ProcessInstanceView) view;\n+                topic = \"processes\";\n+                type = \"process\";\n+                processInstanceId = processInstanceView.getId();\n+                processId = processInstanceView.getProcessId();\n+            } else if (view instanceof TaskInstanceView) {\n+                TaskInstanceView taskInstanceView = (TaskInstanceView) view;\n+                topic = \"tasks\";\n+                type = \"task\";\n+                processInstanceId = taskInstanceView.getProcessInstanceId();\n+                processId = taskInstanceView.getProcessId();\n+            } else if (view instanceof CaseInstanceView) {\n+                CaseInstanceView caseInstanceView = (CaseInstanceView) view;\n+                topic = \"cases\";\n+                type = \"case\";\n+                processInstanceId = caseInstanceView.getId();\n+                processId = caseInstanceView.getCaseDefinitionId();\n+            } else {\n+                throw new UnsupportedOperationException(\"Unsupported view type \" + view.getClass());\n+            }\n+            try {\n+                producer.send(new ProducerRecord<>(getTopic(topic), mapper.writeValueAsBytes(\n+                        new CloudEventSpec1(type, String.format(SOURCE_FORMATTER, processId, processInstanceId),\n+                                view))));\n+            } catch (IOException ex) {\n+                throw new IllegalArgumentException(\"Error creating cloud event for view \" + view, ex);\n+            }\n+        }\n+    }\n+\n+    @SuppressWarnings({\"squid:S2139\", \"squid:S3457\"})\n+    public void apply(Collection<InstanceView<?>> data) {\n+        try {\n+            localProducer.get().commitTransaction();\n+        } catch (KafkaException ex) {\n+            logger.error(\"Error publishing events \" + data, ex);\n+            localProducer.get().abortTransaction();\n+            throw ex;\n+        } finally {\n+            localProducer.remove();\n+        }\n+    }\n+\n+    public void drop(Collection<InstanceView<?>> data) {\n+        try {\n+            localProducer.get().abortTransaction();\n+        } finally {\n+            localProducer.remove();\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        localProducer.remove();\n+    }\n+\n+    @Override\n+    public EventCollection newCollection() {\n+        return new BaseEventCollection();\n+    }\n+\n+    protected Producer<String, byte[]> getProducer() {\n+        Map<String, Object> configs = new HashMap<>();\n+        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                \"org.kie.jbpm.event.emitters.kafka.boopstrap.servers\", \"localhost:9092\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU0MTA4NQ=="}, "originalCommit": {"oid": "ca4768dc20efe45190354ce665bfad867dd6a9d8"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MDUwMjQ2OnYy", "diffSide": "RIGHT", "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwOTo1OToyNVrOHhLhhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwOTo1OToyNVrOHhLhhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU1Mzg2MQ==", "bodyText": "typo, change ElasticSearch by Kafka broker", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r504553861", "createdAt": "2020-10-14T09:59:25Z", "author": {"login": "gmunozfe"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.io.IOException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.KafkaException;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * Expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca4768dc20efe45190354ce665bfad867dd6a9d8"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MDUxNjk1OnYy", "diffSide": "RIGHT", "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMDowMzoyOFrOHhLqqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMDowMzoyOFrOHhLqqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU1NjIwMw==", "bodyText": "Missing ProducerConfig.CLIENT_ID_CONFIG property.\nFrom Confluent documentation: Although not required, you should always set a client.id since this allows you to easily correlate requests on the broker with the client instance which made it.", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r504556203", "createdAt": "2020-10-14T10:03:28Z", "author": {"login": "gmunozfe"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/main/java/org/jbpm/event/emitters/kafka/KafkaEventEmitter.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.io.IOException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import com.fasterxml.jackson.databind.ser.std.ByteArraySerializer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.KafkaException;\n+import org.jbpm.persistence.api.integration.EventCollection;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.base.BaseEventCollection;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Kafka implementation of EventEmitter that simply pushes out data to Kafka topic. \n+ * \n+ * Expects following parameters to configure itself - via system properties\n+ * <ul>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.date_format - date and time format to be sent to ElasticSearch - default format is yyyy-MM-dd'T'HH:mm:ss.SSSZ</li>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.boopstrap.servers - kafka server ip, default is localhost:9092</li>\n+ *  <li>org.kie.jbpm.event.emitters.kafka.topic.<processes|tasks|cases>. Topic name for subscribing to these events. Defaults are \"jbpm-<processes|tasks|cases>-events\"</li>\n+ * </ul> \n+ */\n+public class KafkaEventEmitter implements EventEmitter {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaEventEmitter.class);\n+    private static final String SOURCE_FORMATTER = \"/process/%s/%s\";\n+    private ObjectMapper mapper;\n+\n+    private ThreadLocal<Producer<String, byte[]>> localProducer = new ThreadLocal<>();\n+\n+    public KafkaEventEmitter() {\n+        mapper = new ObjectMapper()\n+                .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                        \"org.kie.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                                \"org.kie.server.json.date_format\",\n+                                \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))))\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+    }\n+\n+    public void deliver(Collection<InstanceView<?>> data) {\n+        if (data == null || data.isEmpty()) {\n+            return;\n+        }\n+        Producer<String, byte[]> producer = getProducer();\n+        localProducer.set(producer);\n+        producer.initTransactions();\n+        producer.beginTransaction();\n+\n+        for (InstanceView<?> view : data) {\n+            String processId;\n+            long processInstanceId;\n+            String type;\n+            String topic;\n+            if (view instanceof ProcessInstanceView) {\n+                ProcessInstanceView processInstanceView = (ProcessInstanceView) view;\n+                topic = \"processes\";\n+                type = \"process\";\n+                processInstanceId = processInstanceView.getId();\n+                processId = processInstanceView.getProcessId();\n+            } else if (view instanceof TaskInstanceView) {\n+                TaskInstanceView taskInstanceView = (TaskInstanceView) view;\n+                topic = \"tasks\";\n+                type = \"task\";\n+                processInstanceId = taskInstanceView.getProcessInstanceId();\n+                processId = taskInstanceView.getProcessId();\n+            } else if (view instanceof CaseInstanceView) {\n+                CaseInstanceView caseInstanceView = (CaseInstanceView) view;\n+                topic = \"cases\";\n+                type = \"case\";\n+                processInstanceId = caseInstanceView.getId();\n+                processId = caseInstanceView.getCaseDefinitionId();\n+            } else {\n+                throw new UnsupportedOperationException(\"Unsupported view type \" + view.getClass());\n+            }\n+            try {\n+                producer.send(new ProducerRecord<>(getTopic(topic), mapper.writeValueAsBytes(\n+                        new CloudEventSpec1(type, String.format(SOURCE_FORMATTER, processId, processInstanceId),\n+                                view))));\n+            } catch (IOException ex) {\n+                throw new IllegalArgumentException(\"Error creating cloud event for view \" + view, ex);\n+            }\n+        }\n+    }\n+\n+    @SuppressWarnings({\"squid:S2139\", \"squid:S3457\"})\n+    public void apply(Collection<InstanceView<?>> data) {\n+        try {\n+            localProducer.get().commitTransaction();\n+        } catch (KafkaException ex) {\n+            logger.error(\"Error publishing events \" + data, ex);\n+            localProducer.get().abortTransaction();\n+            throw ex;\n+        } finally {\n+            localProducer.remove();\n+        }\n+    }\n+\n+    public void drop(Collection<InstanceView<?>> data) {\n+        try {\n+            localProducer.get().abortTransaction();\n+        } finally {\n+            localProducer.remove();\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        localProducer.remove();\n+    }\n+\n+    @Override\n+    public EventCollection newCollection() {\n+        return new BaseEventCollection();\n+    }\n+\n+    protected Producer<String, byte[]> getProducer() {\n+        Map<String, Object> configs = new HashMap<>();\n+        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                \"org.kie.jbpm.event.emitters.kafka.boopstrap.servers\", \"localhost:9092\"));\n+        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n+        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, UUID.randomUUID().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca4768dc20efe45190354ce665bfad867dd6a9d8"}, "originalPosition": 153}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MDU3ODMzOnYy", "diffSide": "RIGHT", "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/test/java/org/jbpm/event/emitters/kafka/KafkaEventEmitterTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMDoyMDoyNFrOHhMQ4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMToyNTo0NVrOHhOYrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU2NTk4NQ==", "bodyText": "Could you add any other rainy test for coverage? e.g. pass data null or empty or provoke an exception at send", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r504565985", "createdAt": "2020-10-14T10:20:24Z", "author": {"login": "gmunozfe"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/test/java/org/jbpm/event/emitters/kafka/KafkaEventEmitterTest.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import org.apache.kafka.clients.producer.MockProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+import org.junit.Test;\n+import org.kie.api.runtime.process.ProcessInstance;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class KafkaEventEmitterTest {\n+\n+    private static class MockKafkaEventEmitter extends KafkaEventEmitter {\n+\n+        public MockProducer<String, byte[]> producer = new MockProducer<>();\n+\n+        @Override\n+        protected Producer<String, byte[]> getProducer() {\n+            return producer;\n+        }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Test\n+    public void testProducer() throws IOException, ParseException {\n+\n+        SimpleDateFormat dateFormat = new SimpleDateFormat(System.getProperty(\n+                \"org.kie.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                        \"org.kie.server.json.date_format\",\n+                        \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\")));\n+        ObjectMapper mapper = new ObjectMapper()\n+                .setDateFormat(dateFormat)\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+        Date date = new Date();\n+        ProcessInstanceView piView = new ProcessInstanceView();\n+        piView.setCompositeId(\"server-1\");\n+        piView.setContainerId(\"container-1\");\n+        piView.setCorrelationKey(\"process-1\");\n+        piView.setDate(date);\n+        piView.setId(1L);\n+        piView.setInitiator(\"pepe\");\n+        piView.setParentId(0L);\n+        piView.setProcessId(\"Test\");\n+        piView.setProcessInstanceDescription(\"a process\");\n+        piView.setProcessName(\"Test\");\n+        piView.setProcessVersion(\"1_0\");\n+        piView.setState(1);\n+        piView.setVariables(Collections.emptyMap());\n+\n+        TaskInstanceView taskView = new TaskInstanceView();\n+        taskView.setProcessId(\"Test\");\n+        taskView.setProcessInstanceId(1L);\n+        taskView.setActualOwner(\"pepe\");\n+\n+        CaseInstanceView caseView = new CaseInstanceView();\n+        caseView.setProcessId(\"Test\");\n+        caseView.setId(1L);\n+        caseView.setInitiator(\"pepe\");\n+\n+        System.setProperty(\"org.kie.jbpm.event.emitters.kafka.topic.cases\", \"customer-cases\");\n+\n+        try (MockKafkaEventEmitter emitter = new MockKafkaEventEmitter()) {\n+            emit(emitter, Arrays.asList(piView, taskView, caseView));\n+\n+            List<ProducerRecord<String, byte[]>> producedEvents = emitter.producer.history();\n+            assertEquals(3, producedEvents.size());\n+\n+            ProducerRecord<String, byte[]> record = producedEvents.get(0);\n+            assertEquals(\"jbpm-processes-events\", record.topic());\n+            Map<String, Object> piEvent = mapper.readValue(record.value(), Map.class);\n+            assertEquals(\"process\", piEvent.get(\"type\"));\n+            assertEquals(\"/process/Test/1\", piEvent.get(\"source\"));\n+            assertTrue(dateFormat.parse(piEvent.get(\"time\").toString()).compareTo(date) >= 0);\n+            assertTrue(piEvent.get(\"data\") instanceof Map);\n+            Map<String, Object> pi = (Map<String, Object>) piEvent.get(\"data\");\n+            assertEquals(\"server-1\", pi.get(\"compositeId\"));\n+            assertEquals(\"container-1\", pi.get(\"containerId\"));\n+            assertEquals(\"process-1\", pi.get(\"correlationKey\"));\n+            assertEquals(1, pi.get(\"id\"));\n+            assertEquals(0, pi.get(\"parentId\"));\n+            assertEquals(\"Test\", pi.get(\"processId\"));\n+            assertEquals(\"pepe\", pi.get(\"initiator\"));\n+            assertEquals(1, pi.get(\"state\"));\n+            assertEquals(\"a process\", pi.get(\"processInstanceDescription\"));\n+            assertEquals(\"Test\", pi.get(\"processName\"));\n+            assertEquals(\"1_0\", pi.get(\"processVersion\"));\n+            assertTrue(pi.get(\"variables\") instanceof Map);\n+            assertTrue(((Map<?, ?>) pi.get(\"variables\")).isEmpty());\n+\n+            record = producedEvents.get(1);\n+            assertEquals(\"jbpm-tasks-events\", record.topic());\n+            Map<String, Object> taskEvent = mapper.readValue(record.value(), Map.class);\n+            assertEquals(\"task\", taskEvent.get(\"type\"));\n+            assertEquals(\"/process/Test/1\", taskEvent.get(\"source\"));\n+            assertTrue(taskEvent.get(\"data\") instanceof Map);\n+            Map<String, Object> task = (Map<String, Object>) taskEvent.get(\"data\");\n+            assertEquals(\"Test\", task.get(\"processId\"));\n+            assertEquals(1, task.get(\"processInstanceId\"));\n+            assertEquals(\"pepe\", task.get(\"actualOwner\"));\n+\n+            record = producedEvents.get(2);\n+            assertEquals(\"customer-cases\", record.topic());\n+            Map<String, Object> caseEvent = mapper.readValue(record.value(), Map.class);\n+            assertEquals(\"case\", caseEvent.get(\"type\"));\n+            assertEquals(\"/process/Test/1\", caseEvent.get(\"source\"));\n+            assertTrue(caseEvent.get(\"data\") instanceof Map);\n+            Map<String, Object> case1 = (Map<String, Object>) caseEvent.get(\"data\");\n+            assertEquals(\"Test\", case1.get(\"caseDefinitionId\"));\n+            assertEquals(1, case1.get(\"id\"));\n+            assertEquals(\"pepe\", case1.get(\"owner\"));\n+        } finally {\n+            System.clearProperty(\"org.kie.jbpm.event.emitters.kafka.topic.cases\");\n+        }\n+    }\n+\n+    @Test\n+    public void testProducerFailure() throws IOException, ParseException {\n+\n+        InstanceView<ProcessInstance> piView = new InstanceView<ProcessInstance>() {\n+            private static final long serialVersionUID = 1L;\n+\n+            @Override\n+            public ProcessInstance getSource() {\n+                return null;\n+            }\n+\n+            @Override\n+            public void copyFromSource() {\n+\n+            }\n+        };\n+        try (MockKafkaEventEmitter emitter = new MockKafkaEventEmitter()) {\n+            emit(emitter, Collections.singletonList(piView));\n+            List<ProducerRecord<String, byte[]>> producedEvents = emitter.producer.history();\n+            assertEquals(0, producedEvents.size());\n+        }\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca4768dc20efe45190354ce665bfad867dd6a9d8"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDYwMDc1MA==", "bodyText": "Yes, done", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r504600750", "createdAt": "2020-10-14T11:25:45Z", "author": {"login": "fjtirado"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/src/test/java/org/jbpm/event/emitters/kafka/KafkaEventEmitterTest.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.jbpm.event.emitters.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+\n+import com.fasterxml.jackson.databind.MapperFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import org.apache.kafka.clients.producer.MockProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.jbpm.persistence.api.integration.EventEmitter;\n+import org.jbpm.persistence.api.integration.InstanceView;\n+import org.jbpm.persistence.api.integration.model.CaseInstanceView;\n+import org.jbpm.persistence.api.integration.model.ProcessInstanceView;\n+import org.jbpm.persistence.api.integration.model.TaskInstanceView;\n+import org.junit.Test;\n+import org.kie.api.runtime.process.ProcessInstance;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class KafkaEventEmitterTest {\n+\n+    private static class MockKafkaEventEmitter extends KafkaEventEmitter {\n+\n+        public MockProducer<String, byte[]> producer = new MockProducer<>();\n+\n+        @Override\n+        protected Producer<String, byte[]> getProducer() {\n+            return producer;\n+        }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Test\n+    public void testProducer() throws IOException, ParseException {\n+\n+        SimpleDateFormat dateFormat = new SimpleDateFormat(System.getProperty(\n+                \"org.kie.jbpm.event.emitters.kafka.date_format\", System.getProperty(\n+                        \"org.kie.server.json.date_format\",\n+                        \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\")));\n+        ObjectMapper mapper = new ObjectMapper()\n+                .setDateFormat(dateFormat)\n+                .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)\n+                .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true);\n+        Date date = new Date();\n+        ProcessInstanceView piView = new ProcessInstanceView();\n+        piView.setCompositeId(\"server-1\");\n+        piView.setContainerId(\"container-1\");\n+        piView.setCorrelationKey(\"process-1\");\n+        piView.setDate(date);\n+        piView.setId(1L);\n+        piView.setInitiator(\"pepe\");\n+        piView.setParentId(0L);\n+        piView.setProcessId(\"Test\");\n+        piView.setProcessInstanceDescription(\"a process\");\n+        piView.setProcessName(\"Test\");\n+        piView.setProcessVersion(\"1_0\");\n+        piView.setState(1);\n+        piView.setVariables(Collections.emptyMap());\n+\n+        TaskInstanceView taskView = new TaskInstanceView();\n+        taskView.setProcessId(\"Test\");\n+        taskView.setProcessInstanceId(1L);\n+        taskView.setActualOwner(\"pepe\");\n+\n+        CaseInstanceView caseView = new CaseInstanceView();\n+        caseView.setProcessId(\"Test\");\n+        caseView.setId(1L);\n+        caseView.setInitiator(\"pepe\");\n+\n+        System.setProperty(\"org.kie.jbpm.event.emitters.kafka.topic.cases\", \"customer-cases\");\n+\n+        try (MockKafkaEventEmitter emitter = new MockKafkaEventEmitter()) {\n+            emit(emitter, Arrays.asList(piView, taskView, caseView));\n+\n+            List<ProducerRecord<String, byte[]>> producedEvents = emitter.producer.history();\n+            assertEquals(3, producedEvents.size());\n+\n+            ProducerRecord<String, byte[]> record = producedEvents.get(0);\n+            assertEquals(\"jbpm-processes-events\", record.topic());\n+            Map<String, Object> piEvent = mapper.readValue(record.value(), Map.class);\n+            assertEquals(\"process\", piEvent.get(\"type\"));\n+            assertEquals(\"/process/Test/1\", piEvent.get(\"source\"));\n+            assertTrue(dateFormat.parse(piEvent.get(\"time\").toString()).compareTo(date) >= 0);\n+            assertTrue(piEvent.get(\"data\") instanceof Map);\n+            Map<String, Object> pi = (Map<String, Object>) piEvent.get(\"data\");\n+            assertEquals(\"server-1\", pi.get(\"compositeId\"));\n+            assertEquals(\"container-1\", pi.get(\"containerId\"));\n+            assertEquals(\"process-1\", pi.get(\"correlationKey\"));\n+            assertEquals(1, pi.get(\"id\"));\n+            assertEquals(0, pi.get(\"parentId\"));\n+            assertEquals(\"Test\", pi.get(\"processId\"));\n+            assertEquals(\"pepe\", pi.get(\"initiator\"));\n+            assertEquals(1, pi.get(\"state\"));\n+            assertEquals(\"a process\", pi.get(\"processInstanceDescription\"));\n+            assertEquals(\"Test\", pi.get(\"processName\"));\n+            assertEquals(\"1_0\", pi.get(\"processVersion\"));\n+            assertTrue(pi.get(\"variables\") instanceof Map);\n+            assertTrue(((Map<?, ?>) pi.get(\"variables\")).isEmpty());\n+\n+            record = producedEvents.get(1);\n+            assertEquals(\"jbpm-tasks-events\", record.topic());\n+            Map<String, Object> taskEvent = mapper.readValue(record.value(), Map.class);\n+            assertEquals(\"task\", taskEvent.get(\"type\"));\n+            assertEquals(\"/process/Test/1\", taskEvent.get(\"source\"));\n+            assertTrue(taskEvent.get(\"data\") instanceof Map);\n+            Map<String, Object> task = (Map<String, Object>) taskEvent.get(\"data\");\n+            assertEquals(\"Test\", task.get(\"processId\"));\n+            assertEquals(1, task.get(\"processInstanceId\"));\n+            assertEquals(\"pepe\", task.get(\"actualOwner\"));\n+\n+            record = producedEvents.get(2);\n+            assertEquals(\"customer-cases\", record.topic());\n+            Map<String, Object> caseEvent = mapper.readValue(record.value(), Map.class);\n+            assertEquals(\"case\", caseEvent.get(\"type\"));\n+            assertEquals(\"/process/Test/1\", caseEvent.get(\"source\"));\n+            assertTrue(caseEvent.get(\"data\") instanceof Map);\n+            Map<String, Object> case1 = (Map<String, Object>) caseEvent.get(\"data\");\n+            assertEquals(\"Test\", case1.get(\"caseDefinitionId\"));\n+            assertEquals(1, case1.get(\"id\"));\n+            assertEquals(\"pepe\", case1.get(\"owner\"));\n+        } finally {\n+            System.clearProperty(\"org.kie.jbpm.event.emitters.kafka.topic.cases\");\n+        }\n+    }\n+\n+    @Test\n+    public void testProducerFailure() throws IOException, ParseException {\n+\n+        InstanceView<ProcessInstance> piView = new InstanceView<ProcessInstance>() {\n+            private static final long serialVersionUID = 1L;\n+\n+            @Override\n+            public ProcessInstance getSource() {\n+                return null;\n+            }\n+\n+            @Override\n+            public void copyFromSource() {\n+\n+            }\n+        };\n+        try (MockKafkaEventEmitter emitter = new MockKafkaEventEmitter()) {\n+            emit(emitter, Collections.singletonList(piView));\n+            List<ProducerRecord<String, byte[]>> producedEvents = emitter.producer.history();\n+            assertEquals(0, producedEvents.size());\n+        }\n+    }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU2NTk4NQ=="}, "originalCommit": {"oid": "ca4768dc20efe45190354ce665bfad867dd6a9d8"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5MDM5Nzc0OnYy", "diffSide": "RIGHT", "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/pom.xml", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQxMzo0ODoyOFrOHltOUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQxMzo1MjowMVrOHltfsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTMwMDMwNA==", "bodyText": "@fjtirado @elguardian you need to fix the version as on master is already 7.46.0-SNAPSHOT, this breaks the master", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r509300304", "createdAt": "2020-10-21T13:48:28Z", "author": {"login": "mareknovotny"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/pom.xml", "diffHunk": "@@ -0,0 +1,45 @@\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+  <parent>\n+    <groupId>org.jbpm</groupId>\n+    <artifactId>jbpm-event-emitters</artifactId>\n+    <version>7.45.0-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "365f9f52520cbdf8fcbc15cba2da224b8c79f05d"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTMwNDc1Mg==", "bodyText": "fixed in c5796f6", "url": "https://github.com/kiegroup/jbpm/pull/1774#discussion_r509304752", "createdAt": "2020-10-21T13:52:01Z", "author": {"login": "mareknovotny"}, "path": "jbpm-event-emitters/jbpm-event-emitters-kafka/pom.xml", "diffHunk": "@@ -0,0 +1,45 @@\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+  <parent>\n+    <groupId>org.jbpm</groupId>\n+    <artifactId>jbpm-event-emitters</artifactId>\n+    <version>7.45.0-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTMwMDMwNA=="}, "originalCommit": {"oid": "365f9f52520cbdf8fcbc15cba2da224b8c79f05d"}, "originalPosition": 8}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1600, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}