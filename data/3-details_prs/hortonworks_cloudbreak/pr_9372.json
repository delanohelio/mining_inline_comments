{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE1MDAwMjA1", "number": 9372, "title": "CB-9616: Have kinit code look for more HDFS node directories.", "bodyText": "Closes CB-9616.\nIn Medium duty datalakes we don't have an hdfs-NAMENODE directory, so trying to kinit fails.  It actually doesn't matter which keytab we use, so the regular expression to look for the directory can also include JOURNALNODE and DATANODE.\nThis is done in both the backup and the restore script.", "createdAt": "2020-11-03T21:26:43Z", "url": "https://github.com/hortonworks/cloudbreak/pull/9372", "merged": true, "mergeCommit": {"oid": "980b96d47e744fbfbcf9fed1fa0de9a64ef2e7ee"}, "closed": true, "closedAt": "2020-11-18T01:23:03Z", "author": {"login": "brycederriso"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdb3lnFgFqTUyOTQxMjgxMA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABddfuFdABqjQwMDc0MjQ3NzQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI5NDEyODEw", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#pullrequestreview-529412810", "createdAt": "2020-11-12T19:18:13Z", "commit": {"oid": "09780909c0cbdb3dd505ab2ea08d5210ab396a51"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxOToxODoxM1rOHyKCHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxOToxODoxM1rOHyKCHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjM1NTIyOA==", "bodyText": "This will work as long one of the service listed below are running in the gateway node where salt-master is running.\n\nJOURNALNODE\nDATANODE\nNAMENODE\n\nExtend this to use keytab's for Solr and Hbase services as well if the HDFS keytab's are not found.\nLater we could update the logic in CB to run this command on a host where Solr/Hbase services are running instead of always picking the gatewayFQDN node.", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#discussion_r522355228", "createdAt": "2020-11-12T19:18:13Z", "author": {"login": "kkalvagadda1"}, "path": "orchestrator-salt/src/main/resources/salt/salt/postgresql/disaster_recovery/scripts/backup_db.sh", "diffHunk": "@@ -56,7 +56,7 @@ errorExit() {\n kinit_as_hdfs() {\n   # Use a new Kerberos credential cache, to keep from clobbering the default.\n   export KRB5CCNAME=/tmp/krb5cc_cloudbreak_$EUID\n-  HDFS_KEYTAB=/run/cloudera-scm-agent/process/$(ls -t /run/cloudera-scm-agent/process/ | grep hdfs-NAMENODE$ | head -n 1)/hdfs.keytab\n+  HDFS_KEYTAB=/run/cloudera-scm-agent/process/$(ls -t /run/cloudera-scm-agent/process/ | grep \"hdfs-\\(JOURNALNODE\\|DATANODE\\|NAMENODE\\)$\" | head -n 1)/hdfs.keytab", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09780909c0cbdb3dd505ab2ea08d5210ab396a51"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwNDIwNDIx", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#pullrequestreview-530420421", "createdAt": "2020-11-13T21:15:47Z", "commit": {"oid": "c0441cfca17d8d575c826b0cc30eb3e00ec6e5ce"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMToxNTo0OFrOHy_ziA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMToyMToxNFrOHy_86Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzNjIzMg==", "bodyText": "Was this the reason why the error was not logged?", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#discussion_r523236232", "createdAt": "2020-11-13T21:15:48Z", "author": {"login": "kkalvagadda1"}, "path": "orchestrator-salt/src/main/resources/salt/salt/postgresql/disaster_recovery/scripts/restore_db.sh", "diffHunk": "@@ -3,7 +3,6 @@\n # This script uses the 'psql' cli to drop hive and ranger databases, create them, then read in a plain SQL file to restore data.\n # We retrieve the SQL files from a valid URL, which should be `s3a://` or `abfs://` for AWS or Azure clouds respectively.\n \n-set -o errexit", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0441cfca17d8d575c826b0cc30eb3e00ec6e5ce"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzODI4Ng==", "bodyText": "With the above change, you might use the key tab for hdfs/hbase/solr services but when you perform kinit you are always using hdfs as the principal name.", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#discussion_r523238286", "createdAt": "2020-11-13T21:20:25Z", "author": {"login": "kkalvagadda1"}, "path": "orchestrator-salt/src/main/resources/salt/salt/postgresql/disaster_recovery/scripts/backup_db.sh", "diffHunk": "@@ -56,9 +55,15 @@ errorExit() {\n kinit_as_hdfs() {\n   # Use a new Kerberos credential cache, to keep from clobbering the default.\n   export KRB5CCNAME=/tmp/krb5cc_cloudbreak_$EUID\n-  HDFS_KEYTAB=/run/cloudera-scm-agent/process/$(ls -t /run/cloudera-scm-agent/process/ | grep hdfs-NAMENODE$ | head -n 1)/hdfs.keytab\n-  doLog \"kinit as hdfs using Keytab: $HDFS_KEYTAB\"\n-  kinit -kt \"$HDFS_KEYTAB\" \"hdfs/$(hostname -f)\"\n+\n+  KEYTAB=$(find /run/cloudera-scm-agent/process/ -name \"*.keytab\" -path \"*hdfs*\" -o \\\n+   -path \"*hbase-REGIONSERVER\" -o \\\n+   -path \"*hbase-MASTER\" -o \\\n+   -path \"*solr-SOLRSERVER\" \\\n+   | head -n 1)\n+\n+  doLog \"kinit as hdfs using Keytab: $KEYTAB\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0441cfca17d8d575c826b0cc30eb3e00ec6e5ce"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzODM4Nw==", "bodyText": "With the above change, you might use the key tab for hdfs/hbase/solr services but when you perform kinit you are always using hdfs as the principal name.", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#discussion_r523238387", "createdAt": "2020-11-13T21:20:39Z", "author": {"login": "kkalvagadda1"}, "path": "orchestrator-salt/src/main/resources/salt/salt/postgresql/disaster_recovery/scripts/restore_db.sh", "diffHunk": "@@ -57,9 +56,15 @@ errorExit() {\n kinit_as_hdfs() {\n   # Use a new Kerberos credential cache, to keep from clobbering the default.\n   export KRB5CCNAME=/tmp/krb5cc_cloudbreak_$EUID\n-  HDFS_KEYTAB=/run/cloudera-scm-agent/process/$(ls -t /run/cloudera-scm-agent/process/ | grep hdfs-NAMENODE$ | head -n 1)/hdfs.keytab\n-  doLog \"kinit as hdfs using Keytab: $HDFS_KEYTAB\"\n-  kinit -kt \"$HDFS_KEYTAB\" \"hdfs/$(hostname -f)\"\n+\n+  KEYTAB=$(find /run/cloudera-scm-agent/process/ -name \"*.keytab\" -path \"*hdfs*\" -o \\\n+   -path \"*hbase-REGIONSERVER\" -o \\\n+   -path \"*hbase-MASTER\" -o \\\n+   -path \"*solr-SOLRSERVER\" \\\n+   | head -n 1)\n+\n+  doLog \"kinit as hdfs using Keytab: $KEYTAB\"\n+  kinit -kt \"$KEYTAB\" \"hdfs/$(hostname -f)\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0441cfca17d8d575c826b0cc30eb3e00ec6e5ce"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzODU3Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              doLog \"kinit as hdfs using Keytab: $KEYTAB\"\n          \n          \n            \n              doLog \"kinit using Keytab: $KEYTAB\"", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#discussion_r523238572", "createdAt": "2020-11-13T21:21:07Z", "author": {"login": "kkalvagadda1"}, "path": "orchestrator-salt/src/main/resources/salt/salt/postgresql/disaster_recovery/scripts/restore_db.sh", "diffHunk": "@@ -57,9 +56,15 @@ errorExit() {\n kinit_as_hdfs() {\n   # Use a new Kerberos credential cache, to keep from clobbering the default.\n   export KRB5CCNAME=/tmp/krb5cc_cloudbreak_$EUID\n-  HDFS_KEYTAB=/run/cloudera-scm-agent/process/$(ls -t /run/cloudera-scm-agent/process/ | grep hdfs-NAMENODE$ | head -n 1)/hdfs.keytab\n-  doLog \"kinit as hdfs using Keytab: $HDFS_KEYTAB\"\n-  kinit -kt \"$HDFS_KEYTAB\" \"hdfs/$(hostname -f)\"\n+\n+  KEYTAB=$(find /run/cloudera-scm-agent/process/ -name \"*.keytab\" -path \"*hdfs*\" -o \\\n+   -path \"*hbase-REGIONSERVER\" -o \\\n+   -path \"*hbase-MASTER\" -o \\\n+   -path \"*solr-SOLRSERVER\" \\\n+   | head -n 1)\n+\n+  doLog \"kinit as hdfs using Keytab: $KEYTAB\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0441cfca17d8d575c826b0cc30eb3e00ec6e5ce"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzODYzMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              doLog \"kinit as hdfs using Keytab: $KEYTAB\"\n          \n          \n            \n              doLog \"kinit using Keytab: $KEYTAB\"", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#discussion_r523238633", "createdAt": "2020-11-13T21:21:14Z", "author": {"login": "kkalvagadda1"}, "path": "orchestrator-salt/src/main/resources/salt/salt/postgresql/disaster_recovery/scripts/backup_db.sh", "diffHunk": "@@ -56,9 +55,15 @@ errorExit() {\n kinit_as_hdfs() {\n   # Use a new Kerberos credential cache, to keep from clobbering the default.\n   export KRB5CCNAME=/tmp/krb5cc_cloudbreak_$EUID\n-  HDFS_KEYTAB=/run/cloudera-scm-agent/process/$(ls -t /run/cloudera-scm-agent/process/ | grep hdfs-NAMENODE$ | head -n 1)/hdfs.keytab\n-  doLog \"kinit as hdfs using Keytab: $HDFS_KEYTAB\"\n-  kinit -kt \"$HDFS_KEYTAB\" \"hdfs/$(hostname -f)\"\n+\n+  KEYTAB=$(find /run/cloudera-scm-agent/process/ -name \"*.keytab\" -path \"*hdfs*\" -o \\\n+   -path \"*hbase-REGIONSERVER\" -o \\\n+   -path \"*hbase-MASTER\" -o \\\n+   -path \"*solr-SOLRSERVER\" \\\n+   | head -n 1)\n+\n+  doLog \"kinit as hdfs using Keytab: $KEYTAB\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0441cfca17d8d575c826b0cc30eb3e00ec6e5ce"}, "originalPosition": 22}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0a12095b9e6193505f038b831fd76ca139fba88e", "author": {"user": {"login": "brycederriso", "name": "Bryce"}}, "url": "https://github.com/hortonworks/cloudbreak/commit/0a12095b9e6193505f038b831fd76ca139fba88e", "committedDate": "2020-11-16T21:40:23Z", "message": "Add handling for 3 different kinit branches.\n\nKinit as:\n* hbase\n* hdfs\n* solr"}, "afterCommit": {"oid": "7e85145fa6a70f900a2869735c8e7d885748c616", "author": {"user": {"login": "brycederriso", "name": "Bryce"}}, "url": "https://github.com/hortonworks/cloudbreak/commit/7e85145fa6a70f900a2869735c8e7d885748c616", "committedDate": "2020-11-16T21:50:28Z", "message": "Add handling for 3 different kinit branches.\n\nKinit as:\n* hbase\n* hdfs\n* solr"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyNjc0NjAw", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#pullrequestreview-532674600", "createdAt": "2020-11-17T18:35:25Z", "commit": {"oid": "7e85145fa6a70f900a2869735c8e7d885748c616"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyNzc1NDk0", "url": "https://github.com/hortonworks/cloudbreak/pull/9372#pullrequestreview-532775494", "createdAt": "2020-11-17T20:17:01Z", "commit": {"oid": "7e85145fa6a70f900a2869735c8e7d885748c616"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da5cec30c44b62f1f140c7d772fb1a19a4e04760", "author": {"user": {"login": "brycederriso", "name": "Bryce"}}, "url": "https://github.com/hortonworks/cloudbreak/commit/da5cec30c44b62f1f140c7d772fb1a19a4e04760", "committedDate": "2020-11-17T20:37:56Z", "message": "Have kinit code look for more HDFS node directories.\n\nDon't bail immediately on errors.\n\nI set `errexit` a while ago, which basically derails the `errorExit`\nfunction since we can't ever catch errors.\n\nRemoving that option should improve error messaging.\n\nUse find to locate a broad variety of keytabs.\n\nAdd handling for 3 different kinit branches.\n\nKinit as:\n* hbase\n* hdfs\n* solr"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7e85145fa6a70f900a2869735c8e7d885748c616", "author": {"user": {"login": "brycederriso", "name": "Bryce"}}, "url": "https://github.com/hortonworks/cloudbreak/commit/7e85145fa6a70f900a2869735c8e7d885748c616", "committedDate": "2020-11-16T21:50:28Z", "message": "Add handling for 3 different kinit branches.\n\nKinit as:\n* hbase\n* hdfs\n* solr"}, "afterCommit": {"oid": "da5cec30c44b62f1f140c7d772fb1a19a4e04760", "author": {"user": {"login": "brycederriso", "name": "Bryce"}}, "url": "https://github.com/hortonworks/cloudbreak/commit/da5cec30c44b62f1f140c7d772fb1a19a4e04760", "committedDate": "2020-11-17T20:37:56Z", "message": "Have kinit code look for more HDFS node directories.\n\nDon't bail immediately on errors.\n\nI set `errexit` a while ago, which basically derails the `errorExit`\nfunction since we can't ever catch errors.\n\nRemoving that option should improve error messaging.\n\nUse find to locate a broad variety of keytabs.\n\nAdd handling for 3 different kinit branches.\n\nKinit as:\n* hbase\n* hdfs\n* solr"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2076, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}