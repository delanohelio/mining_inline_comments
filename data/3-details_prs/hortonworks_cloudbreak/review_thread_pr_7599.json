{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg5NTI5NTM0", "number": 7599, "reviewThreads": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMDo0Mjo1MVrODp0h9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzozNjoyOVrODp3srQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MTc4ODY4OnYy", "diffSide": "RIGHT", "path": "client-cm/src/main/java/com/sequenceiq/cloudbreak/cm/client/retry/ApiExceptionRetryPolicy.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMDo0Mjo1MVrOF5O0fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMDo0Mjo1MVrOF5O0fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU1NTk2Nw==", "bodyText": "It's time to cover this little class with a unit test.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395555967", "createdAt": "2020-03-20T10:42:51Z", "author": {"login": "foldik"}, "path": "client-cm/src/main/java/com/sequenceiq/cloudbreak/cm/client/retry/ApiExceptionRetryPolicy.java", "diffHunk": "@@ -24,7 +24,14 @@ public boolean canRetry(RetryContext context) {\n         if (lastThrowable instanceof ApiException) {\n             if (context.getRetryCount() <= RETRY_LIMIT) {\n                 int code = ApiException.class.cast(lastThrowable).getCode();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MTgyMDk0OnYy", "diffSide": "RIGHT", "path": "cluster-cm/src/main/java/com/sequenceiq/cloudbreak/cm/ClouderaManagerModificationService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMDo1Mzo0MVrOF5PIcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNzozNTowMVrOF5dKGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU2MTA3NA==", "bodyText": "What about an UnsupportedOperationException or remove (or mark them to be removable) these methods if we don't support them? Otherwise these methods lie to other developers.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395561074", "createdAt": "2020-03-20T10:53:41Z", "author": {"login": "foldik"}, "path": "cluster-cm/src/main/java/com/sequenceiq/cloudbreak/cm/ClouderaManagerModificationService.java", "diffHunk": "@@ -143,6 +154,89 @@ public void initApiClient() throws ClusterClientInitException {\n         }\n     }\n \n+    @Override\n+    public void cleanupCluster(Telemetry telemetry) throws CloudbreakException {\n+        if (telemetry != null && telemetry.getWorkloadAnalytics() != null) {\n+            if (StackType.DATALAKE.equals(stack.getType())) {\n+                LOGGER.info(\"Stack type is datalake, no need for WA cleanup\");\n+            } else {\n+                databusService.cleanUpMachineUser(stack);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void upgradeClusterRuntime(Set<ClusterComponent> components) throws CloudbreakException {\n+        try {\n+            ClusterComponent stackComponent = components.stream()\n+                    .filter(clusterComponent -> clusterComponent.getName().equals(com.sequenceiq.cloudbreak.cloud.model.component.StackType.CDH.name()))\n+                    .findFirst().orElse(null);\n+\n+            if (Objects.isNull(stackComponent)) {\n+                throw new NotFoundException(\"Runtime component not found!\");\n+            }\n+            ClouderaManagerProduct stackProduct = stackComponent.getAttributes().get(ClouderaManagerProduct.class);\n+            String stackProductVersion = stackProduct.getVersion();\n+            String stackProductParcel = stackProduct.getParcel();\n+            String product = com.sequenceiq.cloudbreak.cloud.model.component.StackType.CDH.name();\n+\n+            ClustersResourceApi clustersResourceApi = clouderaManagerApiFactory.getClustersResourceApi(apiClient);\n+            ParcelResourceApi parcelResourceApi = clouderaManagerApiFactory.getParcelResourceApi(apiClient);\n+            MgmtServiceResourceApi mgmtServiceResourceApi = clouderaManagerApiFactory.getMgmtServiceResourceApi(apiClient);\n+\n+            startClouderaManager(stack, apiClient);\n+            setParcelRepo(stackProductParcel);\n+            downloadParcel(stackProductVersion, parcelResourceApi, product);\n+            distributeParcel(stackProductVersion, parcelResourceApi, product);\n+            callUpgradeCdhCommand(stackProductVersion, clustersResourceApi);\n+            restartStaleServices(mgmtServiceResourceApi, clustersResourceApi);\n+\n+        } catch (ApiException | IOException e) {\n+            LOGGER.info(\"Could not upgrade Cloudera Runtime services\", e);\n+            throw new ClouderaManagerOperationFailedException(e.getMessage(), e);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, String> gatherInstalledComponents(String hostname) {\n+        return Map.of();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5MDg3NQ==", "bodyText": "Ok, agreed.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395790875", "createdAt": "2020-03-20T17:35:01Z", "author": {"login": "pdarvasi"}, "path": "cluster-cm/src/main/java/com/sequenceiq/cloudbreak/cm/ClouderaManagerModificationService.java", "diffHunk": "@@ -143,6 +154,89 @@ public void initApiClient() throws ClusterClientInitException {\n         }\n     }\n \n+    @Override\n+    public void cleanupCluster(Telemetry telemetry) throws CloudbreakException {\n+        if (telemetry != null && telemetry.getWorkloadAnalytics() != null) {\n+            if (StackType.DATALAKE.equals(stack.getType())) {\n+                LOGGER.info(\"Stack type is datalake, no need for WA cleanup\");\n+            } else {\n+                databusService.cleanUpMachineUser(stack);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void upgradeClusterRuntime(Set<ClusterComponent> components) throws CloudbreakException {\n+        try {\n+            ClusterComponent stackComponent = components.stream()\n+                    .filter(clusterComponent -> clusterComponent.getName().equals(com.sequenceiq.cloudbreak.cloud.model.component.StackType.CDH.name()))\n+                    .findFirst().orElse(null);\n+\n+            if (Objects.isNull(stackComponent)) {\n+                throw new NotFoundException(\"Runtime component not found!\");\n+            }\n+            ClouderaManagerProduct stackProduct = stackComponent.getAttributes().get(ClouderaManagerProduct.class);\n+            String stackProductVersion = stackProduct.getVersion();\n+            String stackProductParcel = stackProduct.getParcel();\n+            String product = com.sequenceiq.cloudbreak.cloud.model.component.StackType.CDH.name();\n+\n+            ClustersResourceApi clustersResourceApi = clouderaManagerApiFactory.getClustersResourceApi(apiClient);\n+            ParcelResourceApi parcelResourceApi = clouderaManagerApiFactory.getParcelResourceApi(apiClient);\n+            MgmtServiceResourceApi mgmtServiceResourceApi = clouderaManagerApiFactory.getMgmtServiceResourceApi(apiClient);\n+\n+            startClouderaManager(stack, apiClient);\n+            setParcelRepo(stackProductParcel);\n+            downloadParcel(stackProductVersion, parcelResourceApi, product);\n+            distributeParcel(stackProductVersion, parcelResourceApi, product);\n+            callUpgradeCdhCommand(stackProductVersion, clustersResourceApi);\n+            restartStaleServices(mgmtServiceResourceApi, clustersResourceApi);\n+\n+        } catch (ApiException | IOException e) {\n+            LOGGER.info(\"Could not upgrade Cloudera Runtime services\", e);\n+            throw new ClouderaManagerOperationFailedException(e.getMessage(), e);\n+        }\n+    }\n+\n+    @Override\n+    public Map<String, String> gatherInstalledComponents(String hostname) {\n+        return Map.of();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU2MTA3NA=="}, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MTg3NDc0OnYy", "diffSide": "RIGHT", "path": "cluster-cm/src/test/java/com/sequenceiq/cloudbreak/cm/ClouderaManagerModificationServiceTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMToxMzowM1rOF5PrTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNzo0OTo1NlrOF5dpSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU2OTk5OA==", "bodyText": "I think it would be useful here to fix the order in which these APIs should be called. You can do it with InOrder from mockito.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395569998", "createdAt": "2020-03-20T11:13:03Z", "author": {"login": "foldik"}, "path": "cluster-cm/src/test/java/com/sequenceiq/cloudbreak/cm/ClouderaManagerModificationServiceTest.java", "diffHunk": "@@ -258,6 +275,85 @@ void upscaleCluster() throws Exception {\n         assertEquals(\"upscaled\", applyTemplateBodyCatcher.getValue().getItems().get(0).getHostname());\n     }\n \n+    @Test\n+    void testUpgradeClusterComponentIsNotPresent() {\n+        Set<ClusterComponent> clusterComponents = TestUtil.clusterComponentSet(cluster);\n+        Set<ClusterComponent> clusterComponentsNoCDH\n+                = clusterComponents.stream().filter(clusterComponent -> !clusterComponent.getName().equals(\"CDH\")).collect(Collectors.toSet());\n+\n+        cluster.setComponents(clusterComponentsNoCDH);\n+        NotFoundException exception = assertThrows(NotFoundException.class, () -> underTest.upgradeClusterRuntime(clusterComponentsNoCDH));\n+        Assertions.assertEquals(\"Runtime component not found!\", exception.getMessage());\n+    }\n+\n+    @Test\n+    void testUpgradeCluster() throws CloudbreakException, ApiException {\n+        TestUtil.clusterComponents(cluster);\n+\n+        when(clouderaManagerApiFactory.getMgmtServiceResourceApi(any())).thenReturn(mgmtServiceResourceApi);\n+        when(clouderaManagerApiFactory.getParcelResourceApi(any())).thenReturn(parcelResourceApi);\n+        when(clouderaManagerApiFactory.getClustersResourceApi(any())).thenReturn(clustersResourceApi);\n+        when(clouderaManagerApiFactory.getClouderaManagerResourceApi(any())).thenReturn(clouderaManagerResourceApi);\n+        when(clouderaManagerApiFactory.getServicesResourceApi(apiClientMock)).thenReturn(servicesResourceApi);\n+        BigDecimal apiCommandId = new BigDecimal(200);\n+        PollingResult successPollingResult = PollingResult.SUCCESS;\n+        ParcelResource parcelResource = new ParcelResource(stack.getName(), TestUtil.CDH, TestUtil.CDH_VERSION);\n+\n+        // Start download\n+        when(parcelResourceApi.startDownloadCommand(eq(stack.getName()), eq(TestUtil.CDH), eq(TestUtil.CDH_VERSION)))\n+                .thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCdpRuntimeParcelDownload(stack, apiClientMock, apiCommandId, parcelResource))\n+                .thenReturn(successPollingResult);\n+\n+        // Start distribute\n+        when(parcelResourceApi.startDistributionCommand(eq(stack.getName()), eq(TestUtil.CDH), eq(TestUtil.CDH_VERSION)))\n+                .thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCdpRuntimeParcelDistribute(stack, apiClientMock, apiCommandId, parcelResource))\n+                .thenReturn(successPollingResult);\n+\n+        // Upgrade\n+        ApiCdhUpgradeArgs upgradeArgs = new ApiCdhUpgradeArgs();\n+        upgradeArgs.setCdhParcelVersion(TestUtil.CDH_VERSION);\n+        when(clustersResourceApi.upgradeCdhCommand(eq(stack.getName()), eq(upgradeArgs))).thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCdpRuntimeUpgrade(stack, apiClientMock, apiCommandId))\n+                .thenReturn(successPollingResult);\n+\n+        // Mgmt Service restart\n+        ApiCommandList apiCommandList = new ApiCommandList();\n+        apiCommandList.setItems(new ArrayList<>());\n+        when(mgmtServiceResourceApi.listActiveCommands(\"SUMMARY\")).thenReturn(apiCommandList);\n+        when(mgmtServiceResourceApi.restartCommand()).thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCmServicesRestart(stack, apiClientMock, apiCommandId))\n+                .thenReturn(successPollingResult);\n+\n+        ApiService apiService = new ApiService()\n+                .name(\"SERVICE\")\n+                .configStalenessStatus(ApiConfigStalenessStatus.STALE)\n+                .clientConfigStalenessStatus(ApiConfigStalenessStatus.STALE);\n+        List<ApiService> apiServices = List.of(apiService);\n+        ApiServiceList apiServiceList = new ApiServiceList();\n+        apiServiceList.setItems(apiServices);\n+\n+        when(servicesResourceApi.readServices(stack.getName(), \"SUMMARY\")).thenReturn(apiServiceList);\n+        when(clustersResourceApi.listActiveCommands(stack.getName(), \"SUMMARY\")).thenReturn(apiCommandList);\n+        when(clustersResourceApi.deployClientConfig(stack.getName())).thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clustersResourceApi.refresh(stack.getName())).thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCmClientConfigDeployment(stack, apiClientMock, apiCommandId))\n+                .thenReturn(successPollingResult);\n+        when(clouderaManagerPollingServiceProvider.startPollingCmConfigurationRefresh(stack, apiClientMock, apiCommandId))\n+                .thenReturn(successPollingResult);\n+\n+        underTest.upgradeClusterRuntime(cluster.getComponents());\n+\n+        verify(clouderaManagerResourceApi, times(1)).updateConfig(any(), any());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5ODg1OQ==", "bodyText": "Ok, agreed.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395798859", "createdAt": "2020-03-20T17:49:56Z", "author": {"login": "pdarvasi"}, "path": "cluster-cm/src/test/java/com/sequenceiq/cloudbreak/cm/ClouderaManagerModificationServiceTest.java", "diffHunk": "@@ -258,6 +275,85 @@ void upscaleCluster() throws Exception {\n         assertEquals(\"upscaled\", applyTemplateBodyCatcher.getValue().getItems().get(0).getHostname());\n     }\n \n+    @Test\n+    void testUpgradeClusterComponentIsNotPresent() {\n+        Set<ClusterComponent> clusterComponents = TestUtil.clusterComponentSet(cluster);\n+        Set<ClusterComponent> clusterComponentsNoCDH\n+                = clusterComponents.stream().filter(clusterComponent -> !clusterComponent.getName().equals(\"CDH\")).collect(Collectors.toSet());\n+\n+        cluster.setComponents(clusterComponentsNoCDH);\n+        NotFoundException exception = assertThrows(NotFoundException.class, () -> underTest.upgradeClusterRuntime(clusterComponentsNoCDH));\n+        Assertions.assertEquals(\"Runtime component not found!\", exception.getMessage());\n+    }\n+\n+    @Test\n+    void testUpgradeCluster() throws CloudbreakException, ApiException {\n+        TestUtil.clusterComponents(cluster);\n+\n+        when(clouderaManagerApiFactory.getMgmtServiceResourceApi(any())).thenReturn(mgmtServiceResourceApi);\n+        when(clouderaManagerApiFactory.getParcelResourceApi(any())).thenReturn(parcelResourceApi);\n+        when(clouderaManagerApiFactory.getClustersResourceApi(any())).thenReturn(clustersResourceApi);\n+        when(clouderaManagerApiFactory.getClouderaManagerResourceApi(any())).thenReturn(clouderaManagerResourceApi);\n+        when(clouderaManagerApiFactory.getServicesResourceApi(apiClientMock)).thenReturn(servicesResourceApi);\n+        BigDecimal apiCommandId = new BigDecimal(200);\n+        PollingResult successPollingResult = PollingResult.SUCCESS;\n+        ParcelResource parcelResource = new ParcelResource(stack.getName(), TestUtil.CDH, TestUtil.CDH_VERSION);\n+\n+        // Start download\n+        when(parcelResourceApi.startDownloadCommand(eq(stack.getName()), eq(TestUtil.CDH), eq(TestUtil.CDH_VERSION)))\n+                .thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCdpRuntimeParcelDownload(stack, apiClientMock, apiCommandId, parcelResource))\n+                .thenReturn(successPollingResult);\n+\n+        // Start distribute\n+        when(parcelResourceApi.startDistributionCommand(eq(stack.getName()), eq(TestUtil.CDH), eq(TestUtil.CDH_VERSION)))\n+                .thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCdpRuntimeParcelDistribute(stack, apiClientMock, apiCommandId, parcelResource))\n+                .thenReturn(successPollingResult);\n+\n+        // Upgrade\n+        ApiCdhUpgradeArgs upgradeArgs = new ApiCdhUpgradeArgs();\n+        upgradeArgs.setCdhParcelVersion(TestUtil.CDH_VERSION);\n+        when(clustersResourceApi.upgradeCdhCommand(eq(stack.getName()), eq(upgradeArgs))).thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCdpRuntimeUpgrade(stack, apiClientMock, apiCommandId))\n+                .thenReturn(successPollingResult);\n+\n+        // Mgmt Service restart\n+        ApiCommandList apiCommandList = new ApiCommandList();\n+        apiCommandList.setItems(new ArrayList<>());\n+        when(mgmtServiceResourceApi.listActiveCommands(\"SUMMARY\")).thenReturn(apiCommandList);\n+        when(mgmtServiceResourceApi.restartCommand()).thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCmServicesRestart(stack, apiClientMock, apiCommandId))\n+                .thenReturn(successPollingResult);\n+\n+        ApiService apiService = new ApiService()\n+                .name(\"SERVICE\")\n+                .configStalenessStatus(ApiConfigStalenessStatus.STALE)\n+                .clientConfigStalenessStatus(ApiConfigStalenessStatus.STALE);\n+        List<ApiService> apiServices = List.of(apiService);\n+        ApiServiceList apiServiceList = new ApiServiceList();\n+        apiServiceList.setItems(apiServices);\n+\n+        when(servicesResourceApi.readServices(stack.getName(), \"SUMMARY\")).thenReturn(apiServiceList);\n+        when(clustersResourceApi.listActiveCommands(stack.getName(), \"SUMMARY\")).thenReturn(apiCommandList);\n+        when(clustersResourceApi.deployClientConfig(stack.getName())).thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clustersResourceApi.refresh(stack.getName())).thenReturn(new ApiCommand().id(apiCommandId));\n+        when(clouderaManagerPollingServiceProvider.startPollingCmClientConfigDeployment(stack, apiClientMock, apiCommandId))\n+                .thenReturn(successPollingResult);\n+        when(clouderaManagerPollingServiceProvider.startPollingCmConfigurationRefresh(stack, apiClientMock, apiCommandId))\n+                .thenReturn(successPollingResult);\n+\n+        underTest.upgradeClusterRuntime(cluster.getComponents());\n+\n+        verify(clouderaManagerResourceApi, times(1)).updateConfig(any(), any());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU2OTk5OA=="}, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MTkyMDAxOnYy", "diffSide": "RIGHT", "path": "cluster-cm/src/main/java/com/sequenceiq/cloudbreak/cm/model/ParcelStatus.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMToyOTowOFrOF5QIag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNzo0OToxNlrOF5dn7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU3NzQ1MA==", "bodyText": "We only use the DOWNLOADED, DISTRIBUTED, ACTIVATED states. I think it doesn't worth to keep other states here, we don't build on them at the moment and if we would, we can easily get them from the CM API spec, other than that it can be tempting for developers to solve some future problems in a quick and dirty way if these unmanaged states give them the possibility.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395577450", "createdAt": "2020-03-20T11:29:08Z", "author": {"login": "foldik"}, "path": "cluster-cm/src/main/java/com/sequenceiq/cloudbreak/cm/model/ParcelStatus.java", "diffHunk": "@@ -0,0 +1,13 @@\n+package com.sequenceiq.cloudbreak.cm.model;\n+\n+public enum ParcelStatus {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5ODUwOA==", "bodyText": "I missed this enum previously big time to have a complete understanding of the state machine, so I would keep this as it is now.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395798508", "createdAt": "2020-03-20T17:49:16Z", "author": {"login": "pdarvasi"}, "path": "cluster-cm/src/main/java/com/sequenceiq/cloudbreak/cm/model/ParcelStatus.java", "diffHunk": "@@ -0,0 +1,13 @@\n+package com.sequenceiq.cloudbreak.cm.model;\n+\n+public enum ParcelStatus {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU3NzQ1MA=="}, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MTk0NzYxOnYy", "diffSide": "RIGHT", "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMTo0MDowM1rOF5QaTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxODowMDoxM1rOF5eA2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MjAyOA==", "bodyText": "Are all these states supported and the upgrade can bring the cluster back with the new version? It might worth to check in which scenario some other magic status syncer puts the status into DELETE_FAILED state for example.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395582028", "createdAt": "2020-03-20T11:40:03Z", "author": {"login": "foldik"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java", "diffHunk": "@@ -94,4 +96,9 @@ public Status mapToFailedIfInProgress() {\n                 return this;\n         }\n     }\n+\n+    public static Set<Status> getUpgradableStates() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgwNDg5MQ==", "bodyText": "Yep, this naming was misleading, renamed the method to getAllowedDataHubStatesForSdxUpgrade\nHope this makes more sense now. :)", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395804891", "createdAt": "2020-03-20T18:00:13Z", "author": {"login": "pdarvasi"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java", "diffHunk": "@@ -94,4 +96,9 @@ public Status mapToFailedIfInProgress() {\n                 return this;\n         }\n     }\n+\n+    public static Set<Status> getUpgradableStates() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MjAyOA=="}, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjA0Mjk5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/cluster/ClusterManagerUpgradeService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjoxNDoyNVrOF5RVaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjoxNDoyNVrOF5RVaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU5NzE2Mw==", "bodyText": "The following things that I say should be tested, it might not be the case here. The stackUtil.collectNodes(stack) method gives back all nodes and this can cause an error. Let's say you have a stopped node in the node list, then this method will give back the stopped node and if the salt master based on the salt scripts wants to talk to this stopped node then this step will fail. There is another method that you can use, the stackUtil.collectReachableNodes(Stack stack), this method will filter out the stopped nodes, so that you can do the work on them when the repair process brings them back. Please fix this method call in a unit test as well, if you change it.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395597163", "createdAt": "2020-03-20T12:14:25Z", "author": {"login": "foldik"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/cluster/ClusterManagerUpgradeService.java", "diffHunk": "@@ -63,15 +65,14 @@ public void upgradeCluster(Long stackId) throws CloudbreakOrchestratorException\n                 Set<String> gatewayFQDN = Collections.singleton(gatewayInstance.getDiscoveryFQDN());\n                 ExitCriteriaModel exitCriteriaModel = clusterDeletionBasedModel(stack.getId(), cluster.getId());\n                 Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n-                Map<String, Object> credentials = new HashMap<>();\n-                ClusterSecurityService clusterSecurityService = clusterApiConnectors.getConnector(stack).clusterSecurityService();\n-                credentials.put(\"username\", clusterSecurityService.getCloudbreakClusterUserName());\n-                credentials.put(\"password\", clusterSecurityService.getCloudbreakClusterPassword());\n-                servicePillar.put(\"ambari-credentials\", new SaltPillarProperties(\"/ambari/credentials.sls\", singletonMap(\"ambari\", credentials)));\n+                ClouderaManagerRepo clouderaManagerRepo = clusterComponentConfigProvider.getClouderaManagerRepoDetails(cluster.getId());\n+                servicePillar.put(\"cloudera-manager-repo\", new SaltPillarProperties(\"/cloudera-manager/repo.sls\",\n+                        singletonMap(\"cloudera-manager\", singletonMap(\"repo\", clouderaManagerRepo))));\n+\n                 SaltConfig pillar = new SaltConfig(servicePillar);\n                 hostOrchestrator.upgradeClusterManager(gatewayConfig, gatewayFQDN, stackUtil.collectNodes(stack), pillar, exitCriteriaModel);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjA4NzQzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/ClusterRepairFlowEventChainFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjoyOTozMlrOF5RwOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjoyOTozMlrOF5RwOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwNDAyNw==", "bodyText": "Too expensive. Please only get back the name and environmentCrn from the database.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395604027", "createdAt": "2020-03-20T12:29:32Z", "author": {"login": "foldik"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/ClusterRepairFlowEventChainFactory.java", "diffHunk": "@@ -150,15 +151,16 @@ private RescheduleStatusCheckTriggerEvent rescheduleStatusCheckEvent(ClusterRepa\n \n     private StackAndClusterUpscaleTriggerEvent fullUpscaleEvent(ClusterRepairTriggerEvent event, String hostGroupName, List<String> hostNames,\n                                                                 boolean singlePrimaryGateway, boolean kerberosSecured) {\n-        Stack stack = event.getStack();\n+        Stack stack = stackService.getByIdWithListsInTransaction(event.getStackId());\n         boolean singleNodeCluster = clusterService.isSingleNode(stack);\n         ClusterManagerType cmType = ClusterManagerType.CLOUDERA_MANAGER;\n         return new StackAndClusterUpscaleTriggerEvent(FlowChainTriggers.FULL_UPSCALE_TRIGGER_EVENT, event.getResourceId(), hostGroupName,\n                 hostNames.size(), ScalingType.UPSCALE_TOGETHER, Sets.newHashSet(hostNames), singlePrimaryGateway,\n                 kerberosSecured, event.accepted(), singleNodeCluster, cmType);\n     }\n \n-    private boolean isKerberosSecured(Stack stack) {\n+    private boolean isKerberosSecured(Long stackId) {\n+        Stack stack = stackService.getByIdWithListsInTransaction(stackId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjA4NzYwOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/ClusterRepairFlowEventChainFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjoyOTozNlrOF5RwVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjoyOTozNlrOF5RwVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwNDA1Mg==", "bodyText": "The stackService.getByIdWithLisstsInTransation(..) call is a very expensive operation. I think this can't be justified  with the need for ids (Set<Long>). Can you please write a proper query in the repository level which only gives back the necessary data (a Set<Long>)?", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395604052", "createdAt": "2020-03-20T12:29:36Z", "author": {"login": "foldik"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/ClusterRepairFlowEventChainFactory.java", "diffHunk": "@@ -121,13 +121,14 @@ private RepairConfig createRepairConfig(ClusterRepairTriggerEvent event) {\n     }\n \n     private StackDownscaleTriggerEvent stackDownscaleEvent(ClusterRepairTriggerEvent event, String groupName, List<String> hostNames) {\n-        Stack stack = event.getStack();\n+        Stack stack = stackService.getByIdWithListsInTransaction(event.getStackId());\n         Set<Long> privateIdsForHostNames = stackService.getPrivateIdsForHostNames(stack.getInstanceMetaDataAsList(), new HashSet<>(hostNames));\n         return new StackDownscaleTriggerEvent(STACK_DOWNSCALE_EVENT.event(), event.getResourceId(), groupName, privateIdsForHostNames, event.accepted());\n     }\n \n     private ClusterAndStackDownscaleTriggerEvent fullDownscaleEvent(ClusterRepairTriggerEvent event, String hostGroupName, List<String> hostNames) {\n-        Set<Long> privateIdsForHostNames = stackService.getPrivateIdsForHostNames(event.getStack().getInstanceMetaDataAsList(), hostNames);\n+        Stack stack = stackService.getByIdWithListsInTransaction(event.getStackId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjA5MDA5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/ClusterRepairFlowEventChainFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjozMDozMlrOF5Rx_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjozMDozMlrOF5Rx_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwNDQ3Nw==", "bodyText": "For a single bool... Please optimize this query as well.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395604477", "createdAt": "2020-03-20T12:30:32Z", "author": {"login": "foldik"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/ClusterRepairFlowEventChainFactory.java", "diffHunk": "@@ -150,15 +151,16 @@ private RescheduleStatusCheckTriggerEvent rescheduleStatusCheckEvent(ClusterRepa\n \n     private StackAndClusterUpscaleTriggerEvent fullUpscaleEvent(ClusterRepairTriggerEvent event, String hostGroupName, List<String> hostNames,\n                                                                 boolean singlePrimaryGateway, boolean kerberosSecured) {\n-        Stack stack = event.getStack();\n+        Stack stack = stackService.getByIdWithListsInTransaction(event.getStackId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjA5MzU0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/ClusterRepairFlowEventChainFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjozMTozMVrOF5R0GA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjozMTozMVrOF5R0GA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwNTAxNg==", "bodyText": "Below optimization request goes here as well.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395605016", "createdAt": "2020-03-20T12:31:31Z", "author": {"login": "foldik"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/ClusterRepairFlowEventChainFactory.java", "diffHunk": "@@ -121,13 +121,14 @@ private RepairConfig createRepairConfig(ClusterRepairTriggerEvent event) {\n     }\n \n     private StackDownscaleTriggerEvent stackDownscaleEvent(ClusterRepairTriggerEvent event, String groupName, List<String> hostNames) {\n-        Stack stack = event.getStack();\n+        Stack stack = stackService.getByIdWithListsInTransaction(event.getStackId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjEwNDYyOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/UpgradeDatalakeFlowEventChainFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjozNTowN1rOF5R7IA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxODozNzoxOVrOF5fK_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwNjgxNg==", "bodyText": "Please use the com.sequenceiq.cloudbreak.service.stackstatus.StackStatusService#findFirstByStackIdOrderByCreatedDesc repository call instead of this expensive call.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395606816", "createdAt": "2020-03-20T12:35:07Z", "author": {"login": "foldik"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/UpgradeDatalakeFlowEventChainFactory.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package com.sequenceiq.cloudbreak.core.flow2.chain;\n+\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.upgrade.ClusterUpgradeEvent.CLUSTER_MANAGER_UPGRADE_EVENT;\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.upgrade.ClusterUpgradeEvent.CLUSTER_MANAGER_UPGRADE_FINISHED_EVENT;\n+\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+\n+import javax.inject.Inject;\n+\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatalakeClusterUpgradeTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.chain.FlowEventChainFactory;\n+\n+@Component\n+public class UpgradeDatalakeFlowEventChainFactory implements FlowEventChainFactory<DatalakeClusterUpgradeTriggerEvent> {\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Override\n+    public String initEvent() {\n+        return FlowChainTriggers.DATALAKE_CLUSTER_UPGRADE_CHAIN_TRIGGER_EVENT;\n+    }\n+\n+    @Override\n+    public Queue<Selectable> createFlowTriggerEventQueue(DatalakeClusterUpgradeTriggerEvent event) {\n+        Queue<Selectable> chain = new ConcurrentLinkedQueue<>();\n+\n+        Stack stack = stackService.getById(event.getResourceId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgyMzg3MQ==", "bodyText": "Ok.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395823871", "createdAt": "2020-03-20T18:37:19Z", "author": {"login": "pdarvasi"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/chain/UpgradeDatalakeFlowEventChainFactory.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package com.sequenceiq.cloudbreak.core.flow2.chain;\n+\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.upgrade.ClusterUpgradeEvent.CLUSTER_MANAGER_UPGRADE_EVENT;\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.upgrade.ClusterUpgradeEvent.CLUSTER_MANAGER_UPGRADE_FINISHED_EVENT;\n+\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+\n+import javax.inject.Inject;\n+\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatalakeClusterUpgradeTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.chain.FlowEventChainFactory;\n+\n+@Component\n+public class UpgradeDatalakeFlowEventChainFactory implements FlowEventChainFactory<DatalakeClusterUpgradeTriggerEvent> {\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Override\n+    public String initEvent() {\n+        return FlowChainTriggers.DATALAKE_CLUSTER_UPGRADE_CHAIN_TRIGGER_EVENT;\n+    }\n+\n+    @Override\n+    public Queue<Selectable> createFlowTriggerEventQueue(DatalakeClusterUpgradeTriggerEvent event) {\n+        Queue<Selectable> chain = new ConcurrentLinkedQueue<>();\n+\n+        Stack stack = stackService.getById(event.getResourceId());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwNjgxNg=="}, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjE0OTgyOnYy", "diffSide": "RIGHT", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/datalake/upgrade/DatalakeUpgradeActions.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjo1MDoxMVrOF5SX6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjo1MDoxMVrOF5SX6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNDE4Ng==", "bodyText": "If this gets back an error, for example another flow was started before this call then the sdx cluster will go into a failed state. Please check and use some similar solution here from the repair flow.\ncom.sequenceiq.datalake.flow.repair.event.SdxRepairCouldNotStartEvent", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395614186", "createdAt": "2020-03-20T12:50:11Z", "author": {"login": "foldik"}, "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/datalake/upgrade/DatalakeUpgradeActions.java", "diffHunk": "@@ -0,0 +1,148 @@\n+package com.sequenceiq.datalake.flow.datalake.upgrade;\n+\n+import static com.sequenceiq.datalake.flow.datalake.upgrade.DatalakeUpgradeEvent.DATALAKE_UPGRADE_FAILED_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.datalake.upgrade.DatalakeUpgradeEvent.DATALAKE_UPGRADE_FINALIZED_EVENT;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.ImageInfoV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.UpgradeOptionV4Response;\n+import com.sequenceiq.cloudbreak.event.ResourceEvent;\n+import com.sequenceiq.datalake.entity.DatalakeStatusEnum;\n+import com.sequenceiq.datalake.flow.SdxContext;\n+import com.sequenceiq.datalake.flow.datalake.upgrade.event.DatalakeChangeImageWaitRequest;\n+import com.sequenceiq.datalake.flow.datalake.upgrade.event.DatalakeImageChangeEvent;\n+import com.sequenceiq.datalake.flow.datalake.upgrade.event.DatalakeUpgradeFailedEvent;\n+import com.sequenceiq.datalake.flow.datalake.upgrade.event.DatalakeUpgradeStartEvent;\n+import com.sequenceiq.datalake.flow.datalake.upgrade.event.DatalakeUpgradeSuccessEvent;\n+import com.sequenceiq.datalake.flow.datalake.upgrade.event.DatalakeUpgradeWaitRequest;\n+import com.sequenceiq.datalake.service.AbstractSdxAction;\n+import com.sequenceiq.datalake.service.sdx.SdxUpgradeService;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+@Configuration\n+public class DatalakeUpgradeActions {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeUpgradeActions.class);\n+\n+    @Inject\n+    private SdxUpgradeService sdxUpgradeService;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Bean(name = \"DATALAKE_UPGRADE_START_STATE\")\n+    public Action<?, ?> datalakeUpgrade() {\n+        return new AbstractSdxAction<>(DatalakeUpgradeStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeUpgradeStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeUpgradeStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                sdxUpgradeService.upgradeCluster(payload.getResourceId(), payload.getImageId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjE4MTc0OnYy", "diffSide": "RIGHT", "path": "integration-test/src/main/java/com/sequenceiq/it/cloudbreak/util/ClouderaManagerUtil.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzowMDowNVrOF5SsCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzowMDowNVrOF5SsCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxOTMzNw==", "bodyText": "Please don't use the String.format with a logger, it kills the option to do runtime optimization based on log level. Use instead this version: LOGGER.error(\"Can't get users' list at: {} or test user is not valid with {}\", cmClient.getBasePath(), userDetails).", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395619337", "createdAt": "2020-03-20T13:00:05Z", "author": {"login": "foldik"}, "path": "integration-test/src/main/java/com/sequenceiq/it/cloudbreak/util/ClouderaManagerUtil.java", "diffHunk": "@@ -79,7 +79,7 @@ public static StackTestDto checkClouderaManagerUser(TestContext testContext, Sta\n                 throw new TestFailException(\"Requested user details are not valid \" + userDetails);\n             }\n         } catch (Exception e) {\n-            LOGGER.error(\"Can't get users' list at: %s or test user is not valid with %s\", cmClient.getBasePath(), userDetails);\n+            LOGGER.error(String.format(\"Can't get users' list at: %s or test user is not valid with %s\", cmClient.getBasePath(), userDetails));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjE4OTU5OnYy", "diffSide": "RIGHT", "path": "integration-test/src/main/java/com/sequenceiq/it/cloudbreak/action/sdx/SdxSetFlowChainIdAction.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzowMjo0MFrOF5SxKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxODowMzowN1rOF5eHUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYyMDY0OQ==", "bodyText": "Please use the SdxSetFlowChainIdAction class for the logger initialization.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395620649", "createdAt": "2020-03-20T13:02:40Z", "author": {"login": "foldik"}, "path": "integration-test/src/main/java/com/sequenceiq/it/cloudbreak/action/sdx/SdxSetFlowChainIdAction.java", "diffHunk": "@@ -11,7 +11,7 @@\n \n public class SdxSetFlowChainIdAction implements Action<SdxTestDto, SdxClient> {\n \n-    private static final Logger LOGGER = LoggerFactory.getLogger(SdxUpgradeAction.class);\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxOsUpgradeAction.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgwNjU0Ng==", "bodyText": "Ok, thanks!", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395806546", "createdAt": "2020-03-20T18:03:07Z", "author": {"login": "pdarvasi"}, "path": "integration-test/src/main/java/com/sequenceiq/it/cloudbreak/action/sdx/SdxSetFlowChainIdAction.java", "diffHunk": "@@ -11,7 +11,7 @@\n \n public class SdxSetFlowChainIdAction implements Action<SdxTestDto, SdxClient> {\n \n-    private static final Logger LOGGER = LoggerFactory.getLogger(SdxUpgradeAction.class);\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxOsUpgradeAction.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYyMDY0OQ=="}, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjIwMDUwOnYy", "diffSide": "RIGHT", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/upgrade/SdxClusterUpgradeService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzowNjoyMFrOF5S4SQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxODoxMDozMFrOF5eWHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYyMjQ3Mw==", "bodyText": "CollectionUtils.isEmpty(upgradeCandidates)", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395622473", "createdAt": "2020-03-20T13:06:20Z", "author": {"login": "foldik"}, "path": "datalake/src/main/java/com/sequenceiq/datalake/service/upgrade/SdxClusterUpgradeService.java", "diffHunk": "@@ -0,0 +1,74 @@\n+package com.sequenceiq.datalake.service.upgrade;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+import javax.inject.Inject;\n+\n+import org.apache.logging.log4j.util.Strings;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.ImageInfoV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.UpgradeOptionsV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.datalake.controller.exception.BadRequestException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.service.sdx.SdxService;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+\n+@Component\n+public class SdxClusterUpgradeService {\n+\n+    private static final long WORKSPACE_ID = 0L;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxService sdxService;\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    public UpgradeOptionsV4Response checkForClusterUpgradeByName(String name) {\n+        return stackV4Endpoint.checkForClusterUpgradeByName(0L, name);\n+    }\n+\n+    public UpgradeOptionsV4Response checkForStackUpgradeByCrn(String userCrn, String crn) {\n+        SdxCluster sdxCluster = sdxService.getByCrn(userCrn, crn);\n+        return stackV4Endpoint.checkForClusterUpgradeByName(WORKSPACE_ID, sdxCluster.getClusterName());\n+    }\n+\n+    public FlowIdentifier triggerUpgradeByName(String userCrn, String clusterName, String imageId) {\n+        SdxCluster cluster = sdxService.getSdxByNameInAccount(userCrn, clusterName);\n+        validateImageId(clusterName, imageId);\n+        MDCBuilder.buildMdcContext(cluster);\n+        return sdxReactorFlowManager.triggerDatalakeClusterUpgradeFlow(cluster.getId(), imageId);\n+    }\n+\n+    public FlowIdentifier triggerUpgradeByCrn(String userCrn, String clusterCrn, String imageId) {\n+        SdxCluster cluster = sdxService.getByCrn(userCrn, clusterCrn);\n+        validateImageId(cluster.getClusterName(), imageId);\n+        MDCBuilder.buildMdcContext(cluster);\n+        return sdxReactorFlowManager.triggerDatalakeClusterUpgradeFlow(cluster.getId(), imageId);\n+    }\n+\n+    private void validateImageId(String clusterName, String imageId) {\n+        UpgradeOptionsV4Response upgradeOptionsV4Response = checkForClusterUpgradeByName(clusterName);\n+        List<ImageInfoV4Response> upgradeCandidates = upgradeOptionsV4Response.getUpgradeCandidates();\n+        if (Objects.isNull(upgradeCandidates) || upgradeCandidates.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgxMDMzMg==", "bodyText": "Ok, thanks", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395810332", "createdAt": "2020-03-20T18:10:30Z", "author": {"login": "pdarvasi"}, "path": "datalake/src/main/java/com/sequenceiq/datalake/service/upgrade/SdxClusterUpgradeService.java", "diffHunk": "@@ -0,0 +1,74 @@\n+package com.sequenceiq.datalake.service.upgrade;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+import javax.inject.Inject;\n+\n+import org.apache.logging.log4j.util.Strings;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.ImageInfoV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.UpgradeOptionsV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.datalake.controller.exception.BadRequestException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.service.sdx.SdxService;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+\n+@Component\n+public class SdxClusterUpgradeService {\n+\n+    private static final long WORKSPACE_ID = 0L;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxService sdxService;\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    public UpgradeOptionsV4Response checkForClusterUpgradeByName(String name) {\n+        return stackV4Endpoint.checkForClusterUpgradeByName(0L, name);\n+    }\n+\n+    public UpgradeOptionsV4Response checkForStackUpgradeByCrn(String userCrn, String crn) {\n+        SdxCluster sdxCluster = sdxService.getByCrn(userCrn, crn);\n+        return stackV4Endpoint.checkForClusterUpgradeByName(WORKSPACE_ID, sdxCluster.getClusterName());\n+    }\n+\n+    public FlowIdentifier triggerUpgradeByName(String userCrn, String clusterName, String imageId) {\n+        SdxCluster cluster = sdxService.getSdxByNameInAccount(userCrn, clusterName);\n+        validateImageId(clusterName, imageId);\n+        MDCBuilder.buildMdcContext(cluster);\n+        return sdxReactorFlowManager.triggerDatalakeClusterUpgradeFlow(cluster.getId(), imageId);\n+    }\n+\n+    public FlowIdentifier triggerUpgradeByCrn(String userCrn, String clusterCrn, String imageId) {\n+        SdxCluster cluster = sdxService.getByCrn(userCrn, clusterCrn);\n+        validateImageId(cluster.getClusterName(), imageId);\n+        MDCBuilder.buildMdcContext(cluster);\n+        return sdxReactorFlowManager.triggerDatalakeClusterUpgradeFlow(cluster.getId(), imageId);\n+    }\n+\n+    private void validateImageId(String clusterName, String imageId) {\n+        UpgradeOptionsV4Response upgradeOptionsV4Response = checkForClusterUpgradeByName(clusterName);\n+        List<ImageInfoV4Response> upgradeCandidates = upgradeOptionsV4Response.getUpgradeCandidates();\n+        if (Objects.isNull(upgradeCandidates) || upgradeCandidates.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYyMjQ3Mw=="}, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjIxMTY1OnYy", "diffSide": "RIGHT", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/upgrade/SdxClusterUpgradeService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzowOTozMVrOF5S_QA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzowOTozMVrOF5S_QA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYyNDI1Ng==", "bodyText": "Please write some unit tests for the validation logic.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395624256", "createdAt": "2020-03-20T13:09:31Z", "author": {"login": "foldik"}, "path": "datalake/src/main/java/com/sequenceiq/datalake/service/upgrade/SdxClusterUpgradeService.java", "diffHunk": "@@ -0,0 +1,74 @@\n+package com.sequenceiq.datalake.service.upgrade;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+import javax.inject.Inject;\n+\n+import org.apache.logging.log4j.util.Strings;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.ImageInfoV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.UpgradeOptionsV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.datalake.controller.exception.BadRequestException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.service.sdx.SdxService;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+\n+@Component\n+public class SdxClusterUpgradeService {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjIxMTg1OnYy", "diffSide": "RIGHT", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/upgrade/SdxClusterUpgradeService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzowOTozNlrOF5S_ZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxODowMjowN1rOF5eFGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYyNDI5Mw==", "bodyText": "Use the apache commons StringUtils please. Strings is from a logging library.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395624293", "createdAt": "2020-03-20T13:09:36Z", "author": {"login": "foldik"}, "path": "datalake/src/main/java/com/sequenceiq/datalake/service/upgrade/SdxClusterUpgradeService.java", "diffHunk": "@@ -0,0 +1,74 @@\n+package com.sequenceiq.datalake.service.upgrade;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+import javax.inject.Inject;\n+\n+import org.apache.logging.log4j.util.Strings;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.ImageInfoV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.UpgradeOptionsV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.datalake.controller.exception.BadRequestException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.service.sdx.SdxService;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+\n+@Component\n+public class SdxClusterUpgradeService {\n+\n+    private static final long WORKSPACE_ID = 0L;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxService sdxService;\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    public UpgradeOptionsV4Response checkForClusterUpgradeByName(String name) {\n+        return stackV4Endpoint.checkForClusterUpgradeByName(0L, name);\n+    }\n+\n+    public UpgradeOptionsV4Response checkForStackUpgradeByCrn(String userCrn, String crn) {\n+        SdxCluster sdxCluster = sdxService.getByCrn(userCrn, crn);\n+        return stackV4Endpoint.checkForClusterUpgradeByName(WORKSPACE_ID, sdxCluster.getClusterName());\n+    }\n+\n+    public FlowIdentifier triggerUpgradeByName(String userCrn, String clusterName, String imageId) {\n+        SdxCluster cluster = sdxService.getSdxByNameInAccount(userCrn, clusterName);\n+        validateImageId(clusterName, imageId);\n+        MDCBuilder.buildMdcContext(cluster);\n+        return sdxReactorFlowManager.triggerDatalakeClusterUpgradeFlow(cluster.getId(), imageId);\n+    }\n+\n+    public FlowIdentifier triggerUpgradeByCrn(String userCrn, String clusterCrn, String imageId) {\n+        SdxCluster cluster = sdxService.getByCrn(userCrn, clusterCrn);\n+        validateImageId(cluster.getClusterName(), imageId);\n+        MDCBuilder.buildMdcContext(cluster);\n+        return sdxReactorFlowManager.triggerDatalakeClusterUpgradeFlow(cluster.getId(), imageId);\n+    }\n+\n+    private void validateImageId(String clusterName, String imageId) {\n+        UpgradeOptionsV4Response upgradeOptionsV4Response = checkForClusterUpgradeByName(clusterName);\n+        List<ImageInfoV4Response> upgradeCandidates = upgradeOptionsV4Response.getUpgradeCandidates();\n+        if (Objects.isNull(upgradeCandidates) || upgradeCandidates.isEmpty()) {\n+            throw new BadRequestException(String.format(\"There is no compatible image to upgrade for stack %s\", clusterName));\n+        } else if (upgradeCandidates.stream().noneMatch(imageInfoV4Response -> imageInfoV4Response.getImageId().equalsIgnoreCase(imageId))) {\n+            String candidates = upgradeCandidates.stream().map(ImageInfoV4Response::getImageId).collect(Collectors.joining(\",\"));\n+            throw new BadRequestException(String.format(\"The given image (%s) is not eligible for upgrading the cluster. \"\n+                    + \"Please choose an id from the following image(s): %s\", imageId, candidates));\n+        } else if (Strings.isNotEmpty(upgradeOptionsV4Response.getReason())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgwNTk3Ng==", "bodyText": "Ok.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395805976", "createdAt": "2020-03-20T18:02:07Z", "author": {"login": "pdarvasi"}, "path": "datalake/src/main/java/com/sequenceiq/datalake/service/upgrade/SdxClusterUpgradeService.java", "diffHunk": "@@ -0,0 +1,74 @@\n+package com.sequenceiq.datalake.service.upgrade;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+import javax.inject.Inject;\n+\n+import org.apache.logging.log4j.util.Strings;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.ImageInfoV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.UpgradeOptionsV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.datalake.controller.exception.BadRequestException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.service.sdx.SdxService;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+\n+@Component\n+public class SdxClusterUpgradeService {\n+\n+    private static final long WORKSPACE_ID = 0L;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxService sdxService;\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    public UpgradeOptionsV4Response checkForClusterUpgradeByName(String name) {\n+        return stackV4Endpoint.checkForClusterUpgradeByName(0L, name);\n+    }\n+\n+    public UpgradeOptionsV4Response checkForStackUpgradeByCrn(String userCrn, String crn) {\n+        SdxCluster sdxCluster = sdxService.getByCrn(userCrn, crn);\n+        return stackV4Endpoint.checkForClusterUpgradeByName(WORKSPACE_ID, sdxCluster.getClusterName());\n+    }\n+\n+    public FlowIdentifier triggerUpgradeByName(String userCrn, String clusterName, String imageId) {\n+        SdxCluster cluster = sdxService.getSdxByNameInAccount(userCrn, clusterName);\n+        validateImageId(clusterName, imageId);\n+        MDCBuilder.buildMdcContext(cluster);\n+        return sdxReactorFlowManager.triggerDatalakeClusterUpgradeFlow(cluster.getId(), imageId);\n+    }\n+\n+    public FlowIdentifier triggerUpgradeByCrn(String userCrn, String clusterCrn, String imageId) {\n+        SdxCluster cluster = sdxService.getByCrn(userCrn, clusterCrn);\n+        validateImageId(cluster.getClusterName(), imageId);\n+        MDCBuilder.buildMdcContext(cluster);\n+        return sdxReactorFlowManager.triggerDatalakeClusterUpgradeFlow(cluster.getId(), imageId);\n+    }\n+\n+    private void validateImageId(String clusterName, String imageId) {\n+        UpgradeOptionsV4Response upgradeOptionsV4Response = checkForClusterUpgradeByName(clusterName);\n+        List<ImageInfoV4Response> upgradeCandidates = upgradeOptionsV4Response.getUpgradeCandidates();\n+        if (Objects.isNull(upgradeCandidates) || upgradeCandidates.isEmpty()) {\n+            throw new BadRequestException(String.format(\"There is no compatible image to upgrade for stack %s\", clusterName));\n+        } else if (upgradeCandidates.stream().noneMatch(imageInfoV4Response -> imageInfoV4Response.getImageId().equalsIgnoreCase(imageId))) {\n+            String candidates = upgradeCandidates.stream().map(ImageInfoV4Response::getImageId).collect(Collectors.joining(\",\"));\n+            throw new BadRequestException(String.format(\"The given image (%s) is not eligible for upgrading the cluster. \"\n+                    + \"Please choose an id from the following image(s): %s\", imageId, candidates));\n+        } else if (Strings.isNotEmpty(upgradeOptionsV4Response.getReason())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYyNDI5Mw=="}, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjMwNzY1OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/upgrade/ClusterUpgradeService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzozNjoyOVrOF5T8Pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzozNjoyOVrOF5T8Pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYzOTg3MQ==", "bodyText": "This is a simple class but if an issue comes up later because some developer did something wrong here then everybody will scream the developer's name who developed the cluster upgrade flow and unfortunately the support guy, or the e2e guy, or you should spend hours to find the cause and then that lazy guy, who broke the  functionality and didn't test his work, so I would write a unit test to make his job harder. This is true for other classes as well.", "url": "https://github.com/hortonworks/cloudbreak/pull/7599#discussion_r395639871", "createdAt": "2020-03-20T13:36:29Z", "author": {"login": "foldik"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/upgrade/ClusterUpgradeService.java", "diffHunk": "@@ -0,0 +1,69 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.upgrade;\n+\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.CLUSTER_MANAGER_UPGRADE;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.CLUSTER_MANAGER_UPGRADE_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.CLUSTER_MANAGER_UPGRADE_FINISHED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.CLUSTER_UPGRADE;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.CLUSTER_UPGRADE_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.CLUSTER_UPGRADE_FINISHED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_UPGRADE;\n+\n+import javax.inject.Inject;\n+\n+import org.springframework.stereotype.Service;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.cloud.model.catalog.Image;\n+import com.sequenceiq.cloudbreak.core.flow2.stack.CloudbreakFlowMessageService;\n+import com.sequenceiq.cloudbreak.service.StackUpdater;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterService;\n+import com.sequenceiq.cloudbreak.service.image.StatedImage;\n+\n+@Service\n+public class ClusterUpgradeService {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7747ad0d395551cf0bfb30b2eed8020c9e160d"}, "originalPosition": 24}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2681, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}