{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM0NzUwNzc1", "number": 8284, "reviewThreads": {"totalCount": 48, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxOTozNzoyOFrOEG4wsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQwOTo0NTo1NVrOEJmmqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NjU2ODgxOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/controller/v4/StackV4Controller.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxOTozNzoyOFrOGl9fYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwNzoyMDoxNVrOGm0nvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ1Nzk1NA==", "bodyText": "The FreeIPA management service uses an operation service to allocate operation IDs rather than just returning the flow ID. That way you can check the status of the operation. I would recommend checking to see if StackOperationService or ClusterOperationService should be used here.\nThe same thing applies to restoreDatabaseByName().", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442457954", "createdAt": "2020-06-18T19:37:28Z", "author": {"login": "jamisonbennett"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/controller/v4/StackV4Controller.java", "diffHunk": "@@ -197,11 +197,15 @@ public FlowIdentifier updateSaltByName(Long workspaceId, String name) {\n \n     @Override\n     public BackupV4Response backupDatabaseByName(Long workspaceId, String name, String backupLocation, String backupId) {\n-        return null;\n+        FlowIdentifier flowIdentifier =\n+            stackOperations.backupClusterDatabase(NameOrCrn.ofName(name), workspaceId, backupLocation, backupId);\n+        return new BackupV4Response(flowIdentifier);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjgzMDQ5MA==", "bodyText": "@jamisonbennett we are using a similar approach for this.\nHere is the flow Datalake-dr service -> datalake Service -> CB Service.\nDatalake service returns an operation id that can used to poll the status. Datalake service keeps polling for the stack status and will update the operation status accordingly.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442830490", "createdAt": "2020-06-19T13:08:49Z", "author": {"login": "kkalvagadda1"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/controller/v4/StackV4Controller.java", "diffHunk": "@@ -197,11 +197,15 @@ public FlowIdentifier updateSaltByName(Long workspaceId, String name) {\n \n     @Override\n     public BackupV4Response backupDatabaseByName(Long workspaceId, String name, String backupLocation, String backupId) {\n-        return null;\n+        FlowIdentifier flowIdentifier =\n+            stackOperations.backupClusterDatabase(NameOrCrn.ofName(name), workspaceId, backupLocation, backupId);\n+        return new BackupV4Response(flowIdentifier);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ1Nzk1NA=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzAzOTg0Mg==", "bodyText": "What is the difference between an operation and a flow? Is there a has-a or is-a relationship between them? Or are they different notions of a thing going on in the datalake?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443039842", "createdAt": "2020-06-19T20:54:06Z", "author": {"login": "brycederriso"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/controller/v4/StackV4Controller.java", "diffHunk": "@@ -197,11 +197,15 @@ public FlowIdentifier updateSaltByName(Long workspaceId, String name) {\n \n     @Override\n     public BackupV4Response backupDatabaseByName(Long workspaceId, String name, String backupLocation, String backupId) {\n-        return null;\n+        FlowIdentifier flowIdentifier =\n+            stackOperations.backupClusterDatabase(NameOrCrn.ofName(name), workspaceId, backupLocation, backupId);\n+        return new BackupV4Response(flowIdentifier);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ1Nzk1NA=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2MTIxMw==", "bodyText": "operation(id) was introduced by @handavid in FreeIPA for usersync as it's not running in a flow, and back then flowid wasn't present on the api. So if you are running a flow it should be enough to expose flowid", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443361213", "createdAt": "2020-06-22T07:20:15Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/controller/v4/StackV4Controller.java", "diffHunk": "@@ -197,11 +197,15 @@ public FlowIdentifier updateSaltByName(Long workspaceId, String name) {\n \n     @Override\n     public BackupV4Response backupDatabaseByName(Long workspaceId, String name, String backupLocation, String backupId) {\n-        return null;\n+        FlowIdentifier flowIdentifier =\n+            stackOperations.backupClusterDatabase(NameOrCrn.ofName(name), workspaceId, backupLocation, backupId);\n+        return new BackupV4Response(flowIdentifier);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ1Nzk1NA=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NjYwNTM0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/AbstractDatabaseRestoreAction.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxOTo0NzoxNVrOGl92zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo0OTozOVrOGm5nzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ2Mzk1MQ==", "bodyText": "nit: It looks like 2 of the 3 the derived classes implement getFailurePayload() returning null. If you move that here it will remove the redundant code.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442463951", "createdAt": "2020-06-18T19:47:15Z", "author": {"login": "jamisonbennett"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/AbstractDatabaseRestoreAction.java", "diffHunk": "@@ -0,0 +1,15 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.common.event.Payload;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.flow.core.AbstractAction;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+public abstract class AbstractDatabaseRestoreAction<P extends Payload>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg4ODEyNg==", "bodyText": "Same as the other comment about getFailurePayload().", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442888126", "createdAt": "2020-06-19T14:56:21Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/AbstractDatabaseRestoreAction.java", "diffHunk": "@@ -0,0 +1,15 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.common.event.Payload;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.flow.core.AbstractAction;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+public abstract class AbstractDatabaseRestoreAction<P extends Payload>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ2Mzk1MQ=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0MzE1MA==", "bodyText": "same as for backup part", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443443150", "createdAt": "2020-06-22T09:49:39Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/AbstractDatabaseRestoreAction.java", "diffHunk": "@@ -0,0 +1,15 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.common.event.Payload;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.flow.core.AbstractAction;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+public abstract class AbstractDatabaseRestoreAction<P extends Payload>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ2Mzk1MQ=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NjYwNzE4OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/AbstractDatabaseBackupAction.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxOTo0Nzo1MlrOGl93-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo0Mjo1MVrOGm5Y7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ2NDI0OQ==", "bodyText": "nit: It looks like 2 of the 3 the derived classes implement getFailurePayload() returning null. If you move that here it will remove the redundant code.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442464249", "createdAt": "2020-06-18T19:47:52Z", "author": {"login": "jamisonbennett"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/AbstractDatabaseBackupAction.java", "diffHunk": "@@ -0,0 +1,15 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.common.event.Payload;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.flow.core.AbstractAction;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+public abstract class AbstractDatabaseBackupAction<P extends Payload>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg4NzcyOA==", "bodyText": "The code isn't technically redundant, because one has the signature getFailurePayload(DatabaseBackupSuccess payload...) and the other has the signature getFailurePayload(DatabaseBackupFailedEvent payload...). I tried replacing them with a generic getFailurePayload(StackEvent payload...) method here, but that doesn't work.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442887728", "createdAt": "2020-06-19T14:55:38Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/AbstractDatabaseBackupAction.java", "diffHunk": "@@ -0,0 +1,15 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.common.event.Payload;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.flow.core.AbstractAction;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+public abstract class AbstractDatabaseBackupAction<P extends Payload>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ2NDI0OQ=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQzOTM0MQ==", "bodyText": "you could use the payload and add it here so you won't have to implement there", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443439341", "createdAt": "2020-06-22T09:42:51Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/AbstractDatabaseBackupAction.java", "diffHunk": "@@ -0,0 +1,15 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.common.event.Payload;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.flow.core.AbstractAction;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+public abstract class AbstractDatabaseBackupAction<P extends Payload>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ2NDI0OQ=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1ODkyMTYxOnYy", "diffSide": "RIGHT", "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxMzoxMjoxNFrOGmUVCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNToxMTowMFrOGmYPuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjgzMjEzNg==", "bodyText": "Your project setting could be different. That is any the imports are re-ordered. Can you check?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442832136", "createdAt": "2020-06-19T13:12:14Z", "author": {"login": "kkalvagadda1"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java", "diffHunk": "@@ -1,5 +1,45 @@\n package com.sequenceiq.cloudbreak.api.endpoint.v4.stacks;\n \n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.ClusterRepairV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.MaintenanceModeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackImageChangeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackScaleV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.UpdateClusterV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.UserNamePasswordV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.tags.upgrade.UpgradeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.GeneratedBlueprintV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.RetryableFlowResponse;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackStatusV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackViewV4Responses;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.upgrade.UpgradeOptionV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.upgrade.UpgradeV4Response;\n+import com.sequenceiq.cloudbreak.doc.Notes;\n+import com.sequenceiq.cloudbreak.doc.OperationDescriptions.StackOpDescription;\n+import com.sequenceiq.cloudbreak.jerseyclient.RetryAndMetrics;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import java.util.Set;\n+import javax.validation.Valid;\n+import javax.validation.constraints.NotEmpty;\n+import javax.validation.constraints.NotNull;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.DELETE;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.PUT;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.PathParam;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.core.MediaType;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg4MjMzMw==", "bodyText": "I've followed the instructions in the cloudbreak README.md to import all the Intellij settings it asked me to, and this is how my IDE re-orders the imports. I can't change it; if I try to move the imports at all it will automatically move them back. My IDE didn't do this before I imported the cloudbreak project settings, so I'm not sure what to do about it now.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442882333", "createdAt": "2020-06-19T14:45:55Z", "author": {"login": "hreeve-cloudera"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java", "diffHunk": "@@ -1,5 +1,45 @@\n package com.sequenceiq.cloudbreak.api.endpoint.v4.stacks;\n \n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.ClusterRepairV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.MaintenanceModeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackImageChangeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackScaleV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.UpdateClusterV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.UserNamePasswordV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.tags.upgrade.UpgradeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.GeneratedBlueprintV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.RetryableFlowResponse;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackStatusV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackViewV4Responses;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.upgrade.UpgradeOptionV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.upgrade.UpgradeV4Response;\n+import com.sequenceiq.cloudbreak.doc.Notes;\n+import com.sequenceiq.cloudbreak.doc.OperationDescriptions.StackOpDescription;\n+import com.sequenceiq.cloudbreak.jerseyclient.RetryAndMetrics;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import java.util.Set;\n+import javax.validation.Valid;\n+import javax.validation.constraints.NotEmpty;\n+import javax.validation.constraints.NotNull;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.DELETE;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.PUT;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.PathParam;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.core.MediaType;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjgzMjEzNg=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg4MzE4Ng==", "bodyText": "The original authors might not have had those imports, so it could be normal that you will get a reordering.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442883186", "createdAt": "2020-06-19T14:47:27Z", "author": {"login": "gergopapi2"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java", "diffHunk": "@@ -1,5 +1,45 @@\n package com.sequenceiq.cloudbreak.api.endpoint.v4.stacks;\n \n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.ClusterRepairV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.MaintenanceModeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackImageChangeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackScaleV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.UpdateClusterV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.UserNamePasswordV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.tags.upgrade.UpgradeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.GeneratedBlueprintV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.RetryableFlowResponse;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackStatusV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackViewV4Responses;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.upgrade.UpgradeOptionV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.upgrade.UpgradeV4Response;\n+import com.sequenceiq.cloudbreak.doc.Notes;\n+import com.sequenceiq.cloudbreak.doc.OperationDescriptions.StackOpDescription;\n+import com.sequenceiq.cloudbreak.jerseyclient.RetryAndMetrics;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import java.util.Set;\n+import javax.validation.Valid;\n+import javax.validation.constraints.NotEmpty;\n+import javax.validation.constraints.NotNull;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.DELETE;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.PUT;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.PathParam;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.core.MediaType;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjgzMjEzNg=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg5NjMxMw==", "bodyText": "My IDE reorders the imports of any file I add new imports to. That's okay if it's reordering it to what the imports are supposed to look like. And I imported the cloudbreak settings so I have to assume it is. But it's not just new imports, it's all imports in the file.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442896313", "createdAt": "2020-06-19T15:11:00Z", "author": {"login": "hreeve-cloudera"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java", "diffHunk": "@@ -1,5 +1,45 @@\n package com.sequenceiq.cloudbreak.api.endpoint.v4.stacks;\n \n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.ClusterRepairV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.MaintenanceModeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackImageChangeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackScaleV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.StackV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.UpdateClusterV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.UserNamePasswordV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.request.tags.upgrade.UpgradeV4Request;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.GeneratedBlueprintV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.RetryableFlowResponse;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackStatusV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackViewV4Responses;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.upgrade.UpgradeOptionV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.upgrade.UpgradeV4Response;\n+import com.sequenceiq.cloudbreak.doc.Notes;\n+import com.sequenceiq.cloudbreak.doc.OperationDescriptions.StackOpDescription;\n+import com.sequenceiq.cloudbreak.jerseyclient.RetryAndMetrics;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import java.util.Set;\n+import javax.validation.Valid;\n+import javax.validation.constraints.NotEmpty;\n+import javax.validation.constraints.NotNull;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.DELETE;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.PUT;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.PathParam;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.core.MediaType;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjgzMjEzNg=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTE2NTIwOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreStatusService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNDoyNTozMlrOGmWtZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNDoyNjoyNlrOGmWvVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg3MTE0MA==", "bodyText": "It should be BACKUP_IN_PROGRESS", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442871140", "createdAt": "2020-06-19T14:25:32Z", "author": {"login": "kkalvagadda1"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreStatusService.java", "diffHunk": "@@ -0,0 +1,65 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.core.flow2.stack.CloudbreakFlowMessageService;\n+import com.sequenceiq.cloudbreak.service.StackUpdater;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterService;\n+import javax.inject.Inject;\n+import org.springframework.stereotype.Service;\n+\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FINISHED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FINISHED;\n+\n+@Service\n+public class BackupRestoreStatusService {\n+\n+    @Inject\n+    private CloudbreakFlowMessageService flowMessageService;\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private StackUpdater stackUpdater;\n+\n+    public void backupDatabase(long stackId, String backupId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_IN_PROGRESS, \"Initiating database backup \" + backupId);\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_IN_PROGRESS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg3MTYzNw==", "bodyText": "It applies to both updateClusterStatusByStackId and fireEventAndLog.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442871637", "createdAt": "2020-06-19T14:26:26Z", "author": {"login": "kkalvagadda1"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreStatusService.java", "diffHunk": "@@ -0,0 +1,65 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.core.flow2.stack.CloudbreakFlowMessageService;\n+import com.sequenceiq.cloudbreak.service.StackUpdater;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterService;\n+import javax.inject.Inject;\n+import org.springframework.stereotype.Service;\n+\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FINISHED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FINISHED;\n+\n+@Service\n+public class BackupRestoreStatusService {\n+\n+    @Inject\n+    private CloudbreakFlowMessageService flowMessageService;\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private StackUpdater stackUpdater;\n+\n+    public void backupDatabase(long stackId, String backupId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_IN_PROGRESS, \"Initiating database backup \" + backupId);\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_IN_PROGRESS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg3MTE0MA=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTE3MDQ5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreStatusService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNDoyNzowMVrOGmWwpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNDoyNzowMVrOGmWwpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg3MTk3Mw==", "bodyText": "Status should be BACKUP_FAILED.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442871973", "createdAt": "2020-06-19T14:27:01Z", "author": {"login": "kkalvagadda1"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreStatusService.java", "diffHunk": "@@ -0,0 +1,65 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.core.flow2.stack.CloudbreakFlowMessageService;\n+import com.sequenceiq.cloudbreak.service.StackUpdater;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterService;\n+import javax.inject.Inject;\n+import org.springframework.stereotype.Service;\n+\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FINISHED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FINISHED;\n+\n+@Service\n+public class BackupRestoreStatusService {\n+\n+    @Inject\n+    private CloudbreakFlowMessageService flowMessageService;\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private StackUpdater stackUpdater;\n+\n+    public void backupDatabase(long stackId, String backupId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_IN_PROGRESS, \"Initiating database backup \" + backupId);\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_IN_PROGRESS);\n+        flowMessageService.fireEventAndLog(stackId, Status.UPDATE_IN_PROGRESS.name(), DATALAKE_DATABASE_BACKUP);\n+    }\n+\n+    public void backupDatabaseFinished(long stackId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_FINISHED, \"Database was successfully backed up.\");\n+        clusterService.updateClusterStatusByStackId(stackId, Status.AVAILABLE);\n+        flowMessageService.fireEventAndLog(stackId, Status.AVAILABLE.name(), DATALAKE_DATABASE_BACKUP_FINISHED);\n+    }\n+\n+    public void handleDatabaseBackupFailure(long stackId, String errorReason, DetailedStackStatus detailedStatus) {\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_FAILED, errorReason);\n+        stackUpdater.updateStackStatus(stackId, detailedStatus);\n+        flowMessageService.fireEventAndLog(stackId, Status.UPDATE_FAILED.name(), DATALAKE_DATABASE_BACKUP_FAILED, errorReason);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTE3MjAxOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreStatusService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNDoyNzoyN1rOGmWxoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNDoyNzoyN1rOGmWxoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg3MjIyNA==", "bodyText": "Should be RESTORE_IN_PROGRESS", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442872224", "createdAt": "2020-06-19T14:27:27Z", "author": {"login": "kkalvagadda1"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreStatusService.java", "diffHunk": "@@ -0,0 +1,65 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.core.flow2.stack.CloudbreakFlowMessageService;\n+import com.sequenceiq.cloudbreak.service.StackUpdater;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterService;\n+import javax.inject.Inject;\n+import org.springframework.stereotype.Service;\n+\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FINISHED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FINISHED;\n+\n+@Service\n+public class BackupRestoreStatusService {\n+\n+    @Inject\n+    private CloudbreakFlowMessageService flowMessageService;\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private StackUpdater stackUpdater;\n+\n+    public void backupDatabase(long stackId, String backupId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_IN_PROGRESS, \"Initiating database backup \" + backupId);\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_IN_PROGRESS);\n+        flowMessageService.fireEventAndLog(stackId, Status.UPDATE_IN_PROGRESS.name(), DATALAKE_DATABASE_BACKUP);\n+    }\n+\n+    public void backupDatabaseFinished(long stackId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_FINISHED, \"Database was successfully backed up.\");\n+        clusterService.updateClusterStatusByStackId(stackId, Status.AVAILABLE);\n+        flowMessageService.fireEventAndLog(stackId, Status.AVAILABLE.name(), DATALAKE_DATABASE_BACKUP_FINISHED);\n+    }\n+\n+    public void handleDatabaseBackupFailure(long stackId, String errorReason, DetailedStackStatus detailedStatus) {\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_FAILED, errorReason);\n+        stackUpdater.updateStackStatus(stackId, detailedStatus);\n+        flowMessageService.fireEventAndLog(stackId, Status.UPDATE_FAILED.name(), DATALAKE_DATABASE_BACKUP_FAILED, errorReason);\n+    }\n+\n+    public void restoreDatabase(long stackId, String backupId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_IN_PROGRESS, \"Initiating database restore \" + backupId);\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_IN_PROGRESS);\n+        flowMessageService.fireEventAndLog(stackId, Status.UPDATE_IN_PROGRESS.name(), DATALAKE_DATABASE_RESTORE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTE3MzU1OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreStatusService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNDoyNzo1MVrOGmWyig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNDoyNzo1MVrOGmWyig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg3MjQ1OA==", "bodyText": "Should be RESTORE_FAILED", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442872458", "createdAt": "2020-06-19T14:27:51Z", "author": {"login": "kkalvagadda1"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreStatusService.java", "diffHunk": "@@ -0,0 +1,65 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.core.flow2.stack.CloudbreakFlowMessageService;\n+import com.sequenceiq.cloudbreak.service.StackUpdater;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterService;\n+import javax.inject.Inject;\n+import org.springframework.stereotype.Service;\n+\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_BACKUP_FINISHED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FAILED;\n+import static com.sequenceiq.cloudbreak.event.ResourceEvent.DATALAKE_DATABASE_RESTORE_FINISHED;\n+\n+@Service\n+public class BackupRestoreStatusService {\n+\n+    @Inject\n+    private CloudbreakFlowMessageService flowMessageService;\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private StackUpdater stackUpdater;\n+\n+    public void backupDatabase(long stackId, String backupId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_IN_PROGRESS, \"Initiating database backup \" + backupId);\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_IN_PROGRESS);\n+        flowMessageService.fireEventAndLog(stackId, Status.UPDATE_IN_PROGRESS.name(), DATALAKE_DATABASE_BACKUP);\n+    }\n+\n+    public void backupDatabaseFinished(long stackId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_FINISHED, \"Database was successfully backed up.\");\n+        clusterService.updateClusterStatusByStackId(stackId, Status.AVAILABLE);\n+        flowMessageService.fireEventAndLog(stackId, Status.AVAILABLE.name(), DATALAKE_DATABASE_BACKUP_FINISHED);\n+    }\n+\n+    public void handleDatabaseBackupFailure(long stackId, String errorReason, DetailedStackStatus detailedStatus) {\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_FAILED, errorReason);\n+        stackUpdater.updateStackStatus(stackId, detailedStatus);\n+        flowMessageService.fireEventAndLog(stackId, Status.UPDATE_FAILED.name(), DATALAKE_DATABASE_BACKUP_FAILED, errorReason);\n+    }\n+\n+    public void restoreDatabase(long stackId, String backupId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_BACKUP_IN_PROGRESS, \"Initiating database restore \" + backupId);\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_IN_PROGRESS);\n+        flowMessageService.fireEventAndLog(stackId, Status.UPDATE_IN_PROGRESS.name(), DATALAKE_DATABASE_RESTORE);\n+    }\n+\n+    public void restoreDatabaseFinished(long stackId) {\n+        stackUpdater.updateStackStatus(stackId, DetailedStackStatus.DATABASE_RESTORE_FINISHED, \"Database was successfully restored.\");\n+        clusterService.updateClusterStatusByStackId(stackId, Status.AVAILABLE);\n+        flowMessageService.fireEventAndLog(stackId, Status.AVAILABLE.name(), DATALAKE_DATABASE_RESTORE_FINISHED);\n+    }\n+\n+    public void handleDatabaseRestoreFailure(long stackId, String errorReason, DetailedStackStatus detailedStatus) {\n+        clusterService.updateClusterStatusByStackId(stackId, Status.UPDATE_FAILED, errorReason);\n+        stackUpdater.updateStackStatus(stackId, detailedStatus);\n+        flowMessageService.fireEventAndLog(stackId, Status.UPDATE_FAILED.name(), DATALAKE_DATABASE_RESTORE_FAILED, errorReason);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTI5MDY5OnYy", "diffSide": "RIGHT", "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/DetailedStackStatus.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNTowMjoyMFrOGmX9rA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNjo0OTozMVrOGmbT-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg5MTY5Mg==", "bodyText": "I think final states should be mapped to Status.AVAILABLE. I think if the state is not available state, no other can be run on it after that.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442891692", "createdAt": "2020-06-19T15:02:20Z", "author": {"login": "kkalvagadda1"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/DetailedStackStatus.java", "diffHunk": "@@ -73,7 +73,14 @@\n \n     CLUSTER_MANAGER_UPGRADE_FAILED(Status.AVAILABLE),\n     CLUSTER_UPGRADE_FAILED(Status.AVAILABLE),\n-    CLUSTER_UPGRADE_FINISHED(Status.AVAILABLE);\n+    CLUSTER_UPGRADE_FINISHED(Status.AVAILABLE),\n+    // Database backup/restore statuses\n+    DATABASE_BACKUP_IN_PROGRESS(Status.BACKUP_IN_PROGRESS),\n+    DATABASE_BACKUP_FINISHED(Status.BACKUP_FINISHED),\n+    DATABASE_BACKUP_FAILED(Status.BACKUP_FAILED),\n+    DATABASE_RESTORE_IN_PROGRESS(Status.RESTORE_IN_PROGRESS),\n+    DATABASE_RESTORE_FINISHED(Status.RESTORE_FINISHED),\n+    DATABASE_RESTORE_FAILED(Status.RESTORE_FAILED);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjkwNDYxMg==", "bodyText": "I think, regardless of the result, status should be mapped to Status.AVAILABLE.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442904612", "createdAt": "2020-06-19T15:26:37Z", "author": {"login": "kkalvagadda1"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/DetailedStackStatus.java", "diffHunk": "@@ -73,7 +73,14 @@\n \n     CLUSTER_MANAGER_UPGRADE_FAILED(Status.AVAILABLE),\n     CLUSTER_UPGRADE_FAILED(Status.AVAILABLE),\n-    CLUSTER_UPGRADE_FINISHED(Status.AVAILABLE);\n+    CLUSTER_UPGRADE_FINISHED(Status.AVAILABLE),\n+    // Database backup/restore statuses\n+    DATABASE_BACKUP_IN_PROGRESS(Status.BACKUP_IN_PROGRESS),\n+    DATABASE_BACKUP_FINISHED(Status.BACKUP_FINISHED),\n+    DATABASE_BACKUP_FAILED(Status.BACKUP_FAILED),\n+    DATABASE_RESTORE_IN_PROGRESS(Status.RESTORE_IN_PROGRESS),\n+    DATABASE_RESTORE_FINISHED(Status.RESTORE_FINISHED),\n+    DATABASE_RESTORE_FAILED(Status.RESTORE_FAILED);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg5MTY5Mg=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk0NjU1NA==", "bodyText": "Status.AVAILABLE has a StatusKind of StatusKind.FINAL. The FINISHED and FAILED enums here also have StatusKind.FINAL, which I believe indicates they're done and will put the cluster back into a state where additional operations can be run. I did run multiple backups on the same cluster as part of my testing, so each one did seem to be getting resolved.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r442946554", "createdAt": "2020-06-19T16:49:31Z", "author": {"login": "hreeve-cloudera"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/DetailedStackStatus.java", "diffHunk": "@@ -73,7 +73,14 @@\n \n     CLUSTER_MANAGER_UPGRADE_FAILED(Status.AVAILABLE),\n     CLUSTER_UPGRADE_FAILED(Status.AVAILABLE),\n-    CLUSTER_UPGRADE_FINISHED(Status.AVAILABLE);\n+    CLUSTER_UPGRADE_FINISHED(Status.AVAILABLE),\n+    // Database backup/restore statuses\n+    DATABASE_BACKUP_IN_PROGRESS(Status.BACKUP_IN_PROGRESS),\n+    DATABASE_BACKUP_FINISHED(Status.BACKUP_FINISHED),\n+    DATABASE_BACKUP_FAILED(Status.BACKUP_FAILED),\n+    DATABASE_RESTORE_IN_PROGRESS(Status.RESTORE_IN_PROGRESS),\n+    DATABASE_RESTORE_FINISHED(Status.RESTORE_FINISHED),\n+    DATABASE_RESTORE_FAILED(Status.RESTORE_FAILED);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjg5MTY5Mg=="}, "originalCommit": {"oid": "55021251ac918a73f2bab1115e9a5d6fa212f570"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MDMyNjAwOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQyMTo1MDoyNVrOGmiCHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQyMDoxNTozMlrOGmoJwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA1NjY3MQ==", "bodyText": "I'm of the opinion that correctly handling paths is scary/hard, but this also decently easy to test.\nCould you run some unit tests against the scheme or fullLocation handling?\nRefactoring to something like:\npublic static SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) {\n        String fullLocation = buildFullLocation(location, backupId, cloudPlatform); // test me\n\n        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n        return new SaltConfig(servicePillar);\n    }\n\npublic static String buildFullLocation (String location, String backupId, String cloudPlatform) {\n        String fullLocation = location + \"/\" + backupId + \"_database_backup\";\n        String scheme;\n        if (\"aws\".equalsIgnoreCase(cloudPlatform)) {\n            scheme = \"s3:/\";\n        } else if (\"azure\".equalsIgnoreCase(cloudPlatform)) {\n            // TODO verify this is right when azure flow is working\n            scheme = \"abfs:/\";\n        } else {\n            throw new UnsupportedOperationException(\"Cloud platform \" + cloudPlatform + \"not supported for backup/restore\");\n        }\n\n        if (fullLocation.startsWith(\"/\")) {\n            fullLocation = scheme + fullLocation;\n        } else {\n            fullLocation = scheme + fullLocation.substring(fullLocation.indexOf(\"//\") + 1);\n        }\n        return fullLocation;\n}", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443056671", "createdAt": "2020-06-19T21:50:25Z", "author": {"login": "brycederriso"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Collections.singletonMap;\n+\n+public class HandlerMethods {\n+\n+    private HandlerMethods() {\n+\n+    }\n+\n+    public static SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4e96284d23b4725ffd3eca4bca167b68950deb2"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA1ODg3NA==", "bodyText": "I can write some unit tests around that, but am I handling paths incorrectly here? Outside of the requested refactor?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443058874", "createdAt": "2020-06-19T21:59:25Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Collections.singletonMap;\n+\n+public class HandlerMethods {\n+\n+    private HandlerMethods() {\n+\n+    }\n+\n+    public static SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA1NjY3MQ=="}, "originalCommit": {"oid": "c4e96284d23b4725ffd3eca4bca167b68950deb2"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzEzNzgzMA==", "bodyText": "I don't think we handle a relative path like bucket/backups correctly here:\nfullLocation = scheme + fullLocation.substring(fullLocation.indexOf(\"//\") + 1);\nWe'd get s3:/bucket/backups, right? I'm not sure how resilient this method needs to be.\nTo be pedantic, we may want to define the schemes without the slash to follow the URI specification, if we ever do try to use them with the URI constructor I think it would blow up.\nI'd consider using the URI class to at least guarantee that we have a valid URI coming out of this, though it may not be a valid s3/abfs/hdfs uri.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443137830", "createdAt": "2020-06-20T15:08:53Z", "author": {"login": "brycederriso"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Collections.singletonMap;\n+\n+public class HandlerMethods {\n+\n+    private HandlerMethods() {\n+\n+    }\n+\n+    public static SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA1NjY3MQ=="}, "originalCommit": {"oid": "c4e96284d23b4725ffd3eca4bca167b68950deb2"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1NjkyOA==", "bodyText": "I was using the URI class originally, but it wasn't doing exactly what I wanted so I changed it. That's no excuse for not digging into what I was doing wrong though :). I've updated the code to use URIs and added unit tests around it.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443156928", "createdAt": "2020-06-20T20:15:32Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Collections.singletonMap;\n+\n+public class HandlerMethods {\n+\n+    private HandlerMethods() {\n+\n+    }\n+\n+    public static SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA1NjY3MQ=="}, "originalCommit": {"oid": "c4e96284d23b4725ffd3eca4bca167b68950deb2"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2Mjk5NDk5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/DatabaseBackupActions.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo0MDoxMlrOGm5TUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo0MDoxMlrOGm5TUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQzNzkwNg==", "bodyText": "is this really necessary?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443437906", "createdAt": "2020-06-22T09:40:12Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/DatabaseBackupActions.java", "diffHunk": "@@ -0,0 +1,120 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreStatusService;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatabaseBackupTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.Flow;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Map;\n+import java.util.Optional;\n+import javax.inject.Inject;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup.DatabaseBackupEvent.DATABASE_BACKUP_FAILED_EVENT;\n+\n+@Configuration\n+public class DatabaseBackupActions {\n+\n+    @Inject\n+    private BackupRestoreStatusService backupRestoreStatusService;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Bean(name = \"DATABASE_BACKUP_STATE\")\n+    public Action<?, ?> backupDatabase() {\n+        return new AbstractDatabaseBackupAction<>(DatabaseBackupTriggerEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseBackupTriggerEvent payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseBackupTriggerEvent payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.backupDatabase(context.getStackId(), context.getBackupId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new DatabaseBackupRequest(context.getStackId(), context.getBackupLocation(), context.getBackupId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseBackupTriggerEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return DatabaseBackupFailedEvent.from(payload, ex, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_BACKUP_FINISHED_STATE\")\n+    public Action<?, ?> databaseBackupFinished() {\n+        return new AbstractDatabaseBackupAction<>(DatabaseBackupSuccess.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseBackupSuccess payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, null, null);\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseBackupSuccess payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.backupDatabaseFinished(context.getStackId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new StackEvent(DatabaseBackupEvent.DATABASE_BACKUP_FINALIZED_EVENT.event(), context.getStackId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseBackupSuccess payload, Optional<BackupRestoreContext> flowContext, Exception ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2Mjk5NzE4OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/DatabaseBackupActions.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo0MDo0OFrOGm5Upw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo0MDo0OFrOGm5Upw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQzODI0Nw==", "bodyText": "same, I don't think this is necessary", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443438247", "createdAt": "2020-06-22T09:40:48Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/DatabaseBackupActions.java", "diffHunk": "@@ -0,0 +1,120 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreStatusService;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatabaseBackupTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.Flow;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Map;\n+import java.util.Optional;\n+import javax.inject.Inject;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup.DatabaseBackupEvent.DATABASE_BACKUP_FAILED_EVENT;\n+\n+@Configuration\n+public class DatabaseBackupActions {\n+\n+    @Inject\n+    private BackupRestoreStatusService backupRestoreStatusService;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Bean(name = \"DATABASE_BACKUP_STATE\")\n+    public Action<?, ?> backupDatabase() {\n+        return new AbstractDatabaseBackupAction<>(DatabaseBackupTriggerEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseBackupTriggerEvent payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseBackupTriggerEvent payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.backupDatabase(context.getStackId(), context.getBackupId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new DatabaseBackupRequest(context.getStackId(), context.getBackupLocation(), context.getBackupId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseBackupTriggerEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return DatabaseBackupFailedEvent.from(payload, ex, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_BACKUP_FINISHED_STATE\")\n+    public Action<?, ?> databaseBackupFinished() {\n+        return new AbstractDatabaseBackupAction<>(DatabaseBackupSuccess.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseBackupSuccess payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, null, null);\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseBackupSuccess payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.backupDatabaseFinished(context.getStackId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new StackEvent(DatabaseBackupEvent.DATABASE_BACKUP_FINALIZED_EVENT.event(), context.getStackId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseBackupSuccess payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return null;\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_BACKUP_FAILED_STATE\")\n+    public Action<?, ?> databaseBackupFailedAction() {\n+        return new AbstractDatabaseBackupAction<>(DatabaseBackupFailedEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseBackupFailedEvent payload) {\n+                Flow flow = getFlow(flowParameters.getFlowId());\n+                Stack stack = stackService.getById(payload.getResourceId());\n+                MDCBuilder.buildMdcContext(stack);\n+                flow.setFlowFailed(payload.getException());\n+                return BackupRestoreContext.from(flowParameters, payload, null, null);\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseBackupFailedEvent payload, Map<Object, Object> variables) throws Exception {\n+                backupRestoreStatusService.handleDatabaseBackupFailure(context.getStackId(), payload.getException().getMessage(), payload.getDetailedStatus());\n+                sendEvent(context, DATABASE_BACKUP_FAILED_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseBackupFailedEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzAxMzEwOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/DatabaseBackupActions.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo0NToxN1rOGm5ePg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo0NToxN1rOGm5ePg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0MDcwMg==", "bodyText": "default context creation should go into abstract action", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443440702", "createdAt": "2020-06-22T09:45:17Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/DatabaseBackupActions.java", "diffHunk": "@@ -0,0 +1,120 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreStatusService;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatabaseBackupTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.Flow;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Map;\n+import java.util.Optional;\n+import javax.inject.Inject;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup.DatabaseBackupEvent.DATABASE_BACKUP_FAILED_EVENT;\n+\n+@Configuration\n+public class DatabaseBackupActions {\n+\n+    @Inject\n+    private BackupRestoreStatusService backupRestoreStatusService;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Bean(name = \"DATABASE_BACKUP_STATE\")\n+    public Action<?, ?> backupDatabase() {\n+        return new AbstractDatabaseBackupAction<>(DatabaseBackupTriggerEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseBackupTriggerEvent payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseBackupTriggerEvent payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.backupDatabase(context.getStackId(), context.getBackupId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new DatabaseBackupRequest(context.getStackId(), context.getBackupLocation(), context.getBackupId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseBackupTriggerEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return DatabaseBackupFailedEvent.from(payload, ex, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_BACKUP_FINISHED_STATE\")\n+    public Action<?, ?> databaseBackupFinished() {\n+        return new AbstractDatabaseBackupAction<>(DatabaseBackupSuccess.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzAzMDg0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/DatabaseRestoreActions.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo1MDoyM1rOGm5pXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo1MDoyM1rOGm5pXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0MzU1MQ==", "bodyText": "same as for backup, general context creation should go into abstract", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443443551", "createdAt": "2020-06-22T09:50:23Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/DatabaseRestoreActions.java", "diffHunk": "@@ -0,0 +1,120 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreStatusService;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatabaseRestoreTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreSuccess;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.Flow;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Map;\n+import java.util.Optional;\n+import javax.inject.Inject;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore.DatabaseRestoreEvent.DATABASE_RESTORE_FAILED_EVENT;\n+\n+@Configuration\n+public class DatabaseRestoreActions {\n+\n+    @Inject\n+    private BackupRestoreStatusService backupRestoreStatusService;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Bean(name = \"DATABASE_RESTORE_STATE\")\n+    public Action<?, ?> restoreDatabase() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreTriggerEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreTriggerEvent payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseRestoreTriggerEvent payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.restoreDatabase(context.getStackId(), context.getBackupId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new DatabaseRestoreRequest(context.getStackId(), context.getBackupLocation(), context.getBackupId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseRestoreTriggerEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return DatabaseRestoreFailedEvent.from(payload, ex, DetailedStackStatus.DATABASE_RESTORE_FAILED);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_RESTORE_FINISHED_STATE\")\n+    public Action<?, ?> databaseRestoreFinished() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreSuccess.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzAzNDMwOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/DatabaseRestoreActions.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo1MToxNVrOGm5rcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDowMzozNVrOGpbPpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0NDA4MQ==", "bodyText": "I think context should be set by flow core here (same applies to backup). Is there a reason you added it here?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443444081", "createdAt": "2020-06-22T09:51:15Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/DatabaseRestoreActions.java", "diffHunk": "@@ -0,0 +1,120 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreStatusService;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatabaseRestoreTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreSuccess;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.Flow;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Map;\n+import java.util.Optional;\n+import javax.inject.Inject;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore.DatabaseRestoreEvent.DATABASE_RESTORE_FAILED_EVENT;\n+\n+@Configuration\n+public class DatabaseRestoreActions {\n+\n+    @Inject\n+    private BackupRestoreStatusService backupRestoreStatusService;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Bean(name = \"DATABASE_RESTORE_STATE\")\n+    public Action<?, ?> restoreDatabase() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreTriggerEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreTriggerEvent payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseRestoreTriggerEvent payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.restoreDatabase(context.getStackId(), context.getBackupId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new DatabaseRestoreRequest(context.getStackId(), context.getBackupLocation(), context.getBackupId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseRestoreTriggerEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return DatabaseRestoreFailedEvent.from(payload, ex, DetailedStackStatus.DATABASE_RESTORE_FAILED);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_RESTORE_FINISHED_STATE\")\n+    public Action<?, ?> databaseRestoreFinished() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreSuccess.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreSuccess payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, null, null);\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseRestoreSuccess payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.restoreDatabaseFinished(context.getStackId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new StackEvent(DatabaseRestoreEvent.DATABASE_RESTORE_FINALIZED_EVENT.event(), context.getStackId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseRestoreSuccess payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return null;\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_RESTORE_FAILED_STATE\")\n+    public Action<?, ?> databaseRestoreFailedAction() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreFailedEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreFailedEvent payload) {\n+                Flow flow = getFlow(flowParameters.getFlowId());\n+                Stack stack = stackService.getById(payload.getResourceId());\n+                MDCBuilder.buildMdcContext(stack);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzU5ODE3Ng==", "bodyText": "I'm not sure what you mean. I was using the the ClusterUpgradeActions class as a base, and basically copied what it did for failures. This is my first time working in this code, so I don't have the context for why everything I was looking at as an example works the way it does. Do you have an example of what you mean?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443598176", "createdAt": "2020-06-22T14:26:34Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/DatabaseRestoreActions.java", "diffHunk": "@@ -0,0 +1,120 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreStatusService;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatabaseRestoreTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreSuccess;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.Flow;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Map;\n+import java.util.Optional;\n+import javax.inject.Inject;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore.DatabaseRestoreEvent.DATABASE_RESTORE_FAILED_EVENT;\n+\n+@Configuration\n+public class DatabaseRestoreActions {\n+\n+    @Inject\n+    private BackupRestoreStatusService backupRestoreStatusService;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Bean(name = \"DATABASE_RESTORE_STATE\")\n+    public Action<?, ?> restoreDatabase() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreTriggerEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreTriggerEvent payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseRestoreTriggerEvent payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.restoreDatabase(context.getStackId(), context.getBackupId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new DatabaseRestoreRequest(context.getStackId(), context.getBackupLocation(), context.getBackupId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseRestoreTriggerEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return DatabaseRestoreFailedEvent.from(payload, ex, DetailedStackStatus.DATABASE_RESTORE_FAILED);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_RESTORE_FINISHED_STATE\")\n+    public Action<?, ?> databaseRestoreFinished() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreSuccess.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreSuccess payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, null, null);\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseRestoreSuccess payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.restoreDatabaseFinished(context.getStackId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new StackEvent(DatabaseRestoreEvent.DATABASE_RESTORE_FINALIZED_EVENT.event(), context.getStackId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseRestoreSuccess payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return null;\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_RESTORE_FAILED_STATE\")\n+    public Action<?, ?> databaseRestoreFailedAction() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreFailedEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreFailedEvent payload) {\n+                Flow flow = getFlow(flowParameters.getFlowId());\n+                Stack stack = stackService.getById(payload.getResourceId());\n+                MDCBuilder.buildMdcContext(stack);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0NDA4MQ=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDAzNTE1Mw==", "bodyText": "I also had to check this. So what I found:\n\nif you use ErrorHandlerAwareReactorEventFactory it will set MdcContext in the headers and flow engine will persist this\nif the above is set then LogContextAspects will load it and set it when a flow step is starting\nif we would like to set it, we usually do it in the context creation part, which is in the flow's abstract action in most cases, as it is the same throughout that flow\n\nif I were you I would remove that MDCBuilder line and check the logs, and check them with it, to see if there is any difference", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444035153", "createdAt": "2020-06-23T07:59:37Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/DatabaseRestoreActions.java", "diffHunk": "@@ -0,0 +1,120 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreStatusService;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatabaseRestoreTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreSuccess;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.Flow;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Map;\n+import java.util.Optional;\n+import javax.inject.Inject;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore.DatabaseRestoreEvent.DATABASE_RESTORE_FAILED_EVENT;\n+\n+@Configuration\n+public class DatabaseRestoreActions {\n+\n+    @Inject\n+    private BackupRestoreStatusService backupRestoreStatusService;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Bean(name = \"DATABASE_RESTORE_STATE\")\n+    public Action<?, ?> restoreDatabase() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreTriggerEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreTriggerEvent payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseRestoreTriggerEvent payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.restoreDatabase(context.getStackId(), context.getBackupId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new DatabaseRestoreRequest(context.getStackId(), context.getBackupLocation(), context.getBackupId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseRestoreTriggerEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return DatabaseRestoreFailedEvent.from(payload, ex, DetailedStackStatus.DATABASE_RESTORE_FAILED);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_RESTORE_FINISHED_STATE\")\n+    public Action<?, ?> databaseRestoreFinished() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreSuccess.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreSuccess payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, null, null);\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseRestoreSuccess payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.restoreDatabaseFinished(context.getStackId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new StackEvent(DatabaseRestoreEvent.DATABASE_RESTORE_FINALIZED_EVENT.event(), context.getStackId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseRestoreSuccess payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return null;\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_RESTORE_FAILED_STATE\")\n+    public Action<?, ?> databaseRestoreFailedAction() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreFailedEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreFailedEvent payload) {\n+                Flow flow = getFlow(flowParameters.getFlowId());\n+                Stack stack = stackService.getById(payload.getResourceId());\n+                MDCBuilder.buildMdcContext(stack);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0NDA4MQ=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA5MTE3NQ==", "bodyText": "if you fix the MdcContext when triggering the flow this MDCContext build here could be omitted I think", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446091175", "createdAt": "2020-06-26T10:03:35Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/restore/DatabaseRestoreActions.java", "diffHunk": "@@ -0,0 +1,120 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreStatusService;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatabaseRestoreTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreSuccess;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.Flow;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Map;\n+import java.util.Optional;\n+import javax.inject.Inject;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.restore.DatabaseRestoreEvent.DATABASE_RESTORE_FAILED_EVENT;\n+\n+@Configuration\n+public class DatabaseRestoreActions {\n+\n+    @Inject\n+    private BackupRestoreStatusService backupRestoreStatusService;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Bean(name = \"DATABASE_RESTORE_STATE\")\n+    public Action<?, ?> restoreDatabase() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreTriggerEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreTriggerEvent payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseRestoreTriggerEvent payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.restoreDatabase(context.getStackId(), context.getBackupId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new DatabaseRestoreRequest(context.getStackId(), context.getBackupLocation(), context.getBackupId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseRestoreTriggerEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return DatabaseRestoreFailedEvent.from(payload, ex, DetailedStackStatus.DATABASE_RESTORE_FAILED);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_RESTORE_FINISHED_STATE\")\n+    public Action<?, ?> databaseRestoreFinished() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreSuccess.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreSuccess payload) {\n+                return BackupRestoreContext.from(flowParameters, payload, null, null);\n+            }\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseRestoreSuccess payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.restoreDatabaseFinished(context.getStackId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new StackEvent(DatabaseRestoreEvent.DATABASE_RESTORE_FINALIZED_EVENT.event(), context.getStackId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseRestoreSuccess payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return null;\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_RESTORE_FAILED_STATE\")\n+    public Action<?, ?> databaseRestoreFailedAction() {\n+        return new AbstractDatabaseRestoreAction<>(DatabaseRestoreFailedEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseRestoreFailedEvent payload) {\n+                Flow flow = getFlow(flowParameters.getFlowId());\n+                Stack stack = stackService.getById(payload.getResourceId());\n+                MDCBuilder.buildMdcContext(stack);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0NDA4MQ=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA0MjYyOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo1MzozMVrOGm5wmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo1Mzo0NlrOGm5xIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0NTQwMg==", "bodyText": "Can we drop the static methods and convert this to a component and use it with inject?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443445402", "createdAt": "2020-06-22T09:53:31Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Collections.singletonMap;\n+\n+public class HandlerMethods {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0NTUzNw==", "bodyText": "also rename this please", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443445537", "createdAt": "2020-06-22T09:53:46Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Collections.singletonMap;\n+\n+public class HandlerMethods {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0NTQwMg=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA1OTQxOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwOTo1Nzo1NlrOGm56rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMTowNTo1MVrOGojHsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0Nzk4Mg==", "bodyText": "I don't think UnsupportedOperationException is the right one here\nalso we usually put cloud platform dependent stuff into cloud modules so we have mostly generic parts here", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443447982", "createdAt": "2020-06-22T09:57:56Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Collections.singletonMap;\n+\n+public class HandlerMethods {\n+\n+    private HandlerMethods() {\n+\n+    }\n+\n+    public static SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public static String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String fullLocation;\n+        if (\"aws\".equalsIgnoreCase(cloudPlatform)) {\n+            if (uri.getScheme() != null && !uri.getScheme().startsWith(\"s3\")) {\n+                throw new UnsupportedOperationException(\"Incorrect URL scheme for AWS cloud platform: \" + location);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYwMjUwMQ==", "bodyText": "Why do you think UnsupportedOperationException isn't the right exception here?\nI don't know enough about the cloudbreak codebase to know how to address your comment about the cloud modules. What do you want me to do there?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443602501", "createdAt": "2020-06-22T14:32:01Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Collections.singletonMap;\n+\n+public class HandlerMethods {\n+\n+    private HandlerMethods() {\n+\n+    }\n+\n+    public static SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public static String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String fullLocation;\n+        if (\"aws\".equalsIgnoreCase(cloudPlatform)) {\n+            if (uri.getScheme() != null && !uri.getScheme().startsWith(\"s3\")) {\n+                throw new UnsupportedOperationException(\"Incorrect URL scheme for AWS cloud platform: \" + location);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0Nzk4Mg=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3MTYzNQ==", "bodyText": "This is now being handled by BackupRestoreV4RequestValidator.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r445171635", "createdAt": "2020-06-24T21:05:51Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/HandlerMethods.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Collections.singletonMap;\n+\n+public class HandlerMethods {\n+\n+    private HandlerMethods() {\n+\n+    }\n+\n+    public static SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public static String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String fullLocation;\n+        if (\"aws\".equalsIgnoreCase(cloudPlatform)) {\n+            if (uri.getScheme() != null && !uri.getScheme().startsWith(\"s3\")) {\n+                throw new UnsupportedOperationException(\"Incorrect URL scheme for AWS cloud platform: \" + location);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0Nzk4Mg=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA2Njk4OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMDowMlrOGm5_TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOToyNjoxN1rOGng-vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0OTE2NQ==", "bodyText": "are we sure about this? what if termination is triggered during backup?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443449165", "createdAt": "2020-06-22T10:00:02Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "diffHunk": "@@ -0,0 +1,77 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.HandlerMethods;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseBackupHandler extends ExceptionCatcherEventHandler<DatabaseBackupRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseBackupHandler.class);\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return \"DatabaseBackupRequest\";\n+    }\n+\n+    @Override\n+    protected Selectable defaultFailureEvent(Long resourceId, Exception e) {\n+        return new DatabaseBackupFailedEvent(resourceId, e, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+    }\n+\n+    @Override\n+    protected void doAccept(HandlerEvent event) {\n+        LOGGER.debug(\"Accepting Database backup event...\");\n+        DatabaseBackupRequest request = event.getData();\n+        Selectable result;\n+        Long stackId = request.getResourceId();\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(stackId);\n+            Cluster cluster = stack.getCluster();\n+            InstanceMetaData gatewayInstance = stack.getPrimaryGatewayInstance();\n+            GatewayConfig gatewayConfig = gatewayConfigService.getGatewayConfig(stack, gatewayInstance, cluster.getGateway() != null);\n+            Set<String> gatewayFQDN = Collections.singleton(gatewayInstance.getDiscoveryFQDN());\n+            ExitCriteriaModel noExitModel = ClusterDeletionBasedExitCriteriaModel.nonCancellableModel();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYwNTAzNg==", "bodyText": "Are we sure about what? The ExitCriteriaModel? Because honestly, I'm not sure about that at all. I don't know what ClusterDeletionBasedExitCriteriaModel is or if this is the right choice for our flow. I talked about it with Krisztian briefly, and this was his suggestion, but I don't yet have the context to know why this is right or wrong. Can you or anyone else explain exactly what the ExitCriteriaModel is and how it should be used?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443605036", "createdAt": "2020-06-22T14:35:14Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "diffHunk": "@@ -0,0 +1,77 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.HandlerMethods;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseBackupHandler extends ExceptionCatcherEventHandler<DatabaseBackupRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseBackupHandler.class);\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return \"DatabaseBackupRequest\";\n+    }\n+\n+    @Override\n+    protected Selectable defaultFailureEvent(Long resourceId, Exception e) {\n+        return new DatabaseBackupFailedEvent(resourceId, e, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+    }\n+\n+    @Override\n+    protected void doAccept(HandlerEvent event) {\n+        LOGGER.debug(\"Accepting Database backup event...\");\n+        DatabaseBackupRequest request = event.getData();\n+        Selectable result;\n+        Long stackId = request.getResourceId();\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(stackId);\n+            Cluster cluster = stack.getCluster();\n+            InstanceMetaData gatewayInstance = stack.getPrimaryGatewayInstance();\n+            GatewayConfig gatewayConfig = gatewayConfigService.getGatewayConfig(stack, gatewayInstance, cluster.getGateway() != null);\n+            Set<String> gatewayFQDN = Collections.singleton(gatewayInstance.getDiscoveryFQDN());\n+            ExitCriteriaModel noExitModel = ClusterDeletionBasedExitCriteriaModel.nonCancellableModel();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0OTE2NQ=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4Nzk5OQ==", "bodyText": "this ExitCriteriaModel is for defining if salt polling/running should be canceled. So it's like if you would like to stop CB to poll the saltorchestrator when the cluster is terminated you should use the ClusterDeletionBasedExitCriteriaModel. As you run your salt states in the cluster I think it would make sense to use it, so CB would free up those threads and won't poll until timeout", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444087999", "createdAt": "2020-06-23T09:26:17Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "diffHunk": "@@ -0,0 +1,77 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.HandlerMethods;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseBackupHandler extends ExceptionCatcherEventHandler<DatabaseBackupRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseBackupHandler.class);\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return \"DatabaseBackupRequest\";\n+    }\n+\n+    @Override\n+    protected Selectable defaultFailureEvent(Long resourceId, Exception e) {\n+        return new DatabaseBackupFailedEvent(resourceId, e, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+    }\n+\n+    @Override\n+    protected void doAccept(HandlerEvent event) {\n+        LOGGER.debug(\"Accepting Database backup event...\");\n+        DatabaseBackupRequest request = event.getData();\n+        Selectable result;\n+        Long stackId = request.getResourceId();\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(stackId);\n+            Cluster cluster = stack.getCluster();\n+            InstanceMetaData gatewayInstance = stack.getPrimaryGatewayInstance();\n+            GatewayConfig gatewayConfig = gatewayConfigService.getGatewayConfig(stack, gatewayInstance, cluster.getGateway() != null);\n+            Set<String> gatewayFQDN = Collections.singleton(gatewayInstance.getDiscoveryFQDN());\n+            ExitCriteriaModel noExitModel = ClusterDeletionBasedExitCriteriaModel.nonCancellableModel();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0OTE2NQ=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA2OTEyOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMDozOFrOGm6Ahw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMDozOFrOGm6Ahw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0OTQ3OQ==", "bodyText": "error/warn should be better level", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443449479", "createdAt": "2020-06-22T10:00:38Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "diffHunk": "@@ -0,0 +1,77 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.HandlerMethods;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseBackupHandler extends ExceptionCatcherEventHandler<DatabaseBackupRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseBackupHandler.class);\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return \"DatabaseBackupRequest\";\n+    }\n+\n+    @Override\n+    protected Selectable defaultFailureEvent(Long resourceId, Exception e) {\n+        return new DatabaseBackupFailedEvent(resourceId, e, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+    }\n+\n+    @Override\n+    protected void doAccept(HandlerEvent event) {\n+        LOGGER.debug(\"Accepting Database backup event...\");\n+        DatabaseBackupRequest request = event.getData();\n+        Selectable result;\n+        Long stackId = request.getResourceId();\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(stackId);\n+            Cluster cluster = stack.getCluster();\n+            InstanceMetaData gatewayInstance = stack.getPrimaryGatewayInstance();\n+            GatewayConfig gatewayConfig = gatewayConfigService.getGatewayConfig(stack, gatewayInstance, cluster.getGateway() != null);\n+            Set<String> gatewayFQDN = Collections.singleton(gatewayInstance.getDiscoveryFQDN());\n+            ExitCriteriaModel noExitModel = ClusterDeletionBasedExitCriteriaModel.nonCancellableModel();\n+            SaltConfig saltConfig = HandlerMethods.createSaltConfig(request.getBackupLocation(), request.getBackupId(), stack.getCloudPlatform());\n+            hostOrchestrator.backupDatabase(gatewayConfig, gatewayFQDN, stackUtil.collectReachableNodes(stack), saltConfig, noExitModel);\n+\n+            result = new DatabaseBackupSuccess(stackId);\n+        } catch (Exception e) {\n+            LOGGER.info(\"Database backup event failed\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA3MDQ3OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/restore/DatabaseRestoreHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMTowMFrOGm6BXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMTowMFrOGm6BXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0OTY5NA==", "bodyText": "same here", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443449694", "createdAt": "2020-06-22T10:01:00Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/restore/DatabaseRestoreHandler.java", "diffHunk": "@@ -0,0 +1,77 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.HandlerMethods;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseRestoreHandler extends ExceptionCatcherEventHandler<DatabaseRestoreRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseRestoreHandler.class);\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return \"DatabaseRestoreRequest\";\n+    }\n+\n+    @Override\n+    protected Selectable defaultFailureEvent(Long resourceId, Exception e) {\n+        return new DatabaseRestoreFailedEvent(resourceId, e, DetailedStackStatus.DATABASE_RESTORE_FAILED);\n+    }\n+\n+    @Override\n+    protected void doAccept(HandlerEvent event) {\n+        LOGGER.debug(\"Accepting Database restore event...\");\n+        DatabaseRestoreRequest request = event.getData();\n+        Selectable result;\n+        Long stackId = request.getResourceId();\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(stackId);\n+            Cluster cluster = stack.getCluster();\n+            InstanceMetaData gatewayInstance = stack.getPrimaryGatewayInstance();\n+            GatewayConfig gatewayConfig = gatewayConfigService.getGatewayConfig(stack, gatewayInstance, cluster.getGateway() != null);\n+            Set<String> gatewayFQDN = Collections.singleton(gatewayInstance.getDiscoveryFQDN());\n+            ExitCriteriaModel noExitModel = ClusterDeletionBasedExitCriteriaModel.nonCancellableModel();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA3MDg1OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/restore/DatabaseRestoreHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMTowN1rOGm6Bpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMTowN1rOGm6Bpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ0OTc2Ng==", "bodyText": "also the same", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443449766", "createdAt": "2020-06-22T10:01:07Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/restore/DatabaseRestoreHandler.java", "diffHunk": "@@ -0,0 +1,77 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.HandlerMethods;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseRestoreHandler extends ExceptionCatcherEventHandler<DatabaseRestoreRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseRestoreHandler.class);\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return \"DatabaseRestoreRequest\";\n+    }\n+\n+    @Override\n+    protected Selectable defaultFailureEvent(Long resourceId, Exception e) {\n+        return new DatabaseRestoreFailedEvent(resourceId, e, DetailedStackStatus.DATABASE_RESTORE_FAILED);\n+    }\n+\n+    @Override\n+    protected void doAccept(HandlerEvent event) {\n+        LOGGER.debug(\"Accepting Database restore event...\");\n+        DatabaseRestoreRequest request = event.getData();\n+        Selectable result;\n+        Long stackId = request.getResourceId();\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(stackId);\n+            Cluster cluster = stack.getCluster();\n+            InstanceMetaData gatewayInstance = stack.getPrimaryGatewayInstance();\n+            GatewayConfig gatewayConfig = gatewayConfigService.getGatewayConfig(stack, gatewayInstance, cluster.getGateway() != null);\n+            Set<String> gatewayFQDN = Collections.singleton(gatewayInstance.getDiscoveryFQDN());\n+            ExitCriteriaModel noExitModel = ClusterDeletionBasedExitCriteriaModel.nonCancellableModel();\n+            SaltConfig saltConfig = HandlerMethods.createSaltConfig(request.getBackupLocation(), request.getBackupId(), stack.getCloudPlatform());\n+            hostOrchestrator.restoreDatabase(gatewayConfig, gatewayFQDN, stackUtil.collectReachableNodes(stack), saltConfig, noExitModel);\n+\n+            result = new DatabaseRestoreSuccess(stackId);\n+        } catch (Exception e) {\n+            LOGGER.info(\"Database restore event failed\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA3NzAzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/distrox/v1/distrox/StackOperations.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMjo1NFrOGm6FdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwODoyMzowNFrOGnek2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ1MDc0MA==", "bodyText": "why can't this work by crn?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443450740", "createdAt": "2020-06-22T10:02:54Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/distrox/v1/distrox/StackOperations.java", "diffHunk": "@@ -315,6 +316,26 @@ public Stack getStackByCrn(String crn) {\n         return stackCommonService.getRetryableFlows(name, workspaceId);\n     }\n \n+    public FlowIdentifier backupClusterDatabase(@NotNull NameOrCrn nameOrCrn, Long workspaceId, String location, String backupId) {\n+        LOGGER.debug(\"Starting cluster database backup: \" + nameOrCrn);\n+        if (nameOrCrn.hasName()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYwODA5MQ==", "bodyText": "It theoretically can. It's just that in the datalake disaster recovery service flow, the user only has the option to provide the environment name, not the CRN. So we only expect to get the name when it calls cloudbreak to do the backup/restore.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443608091", "createdAt": "2020-06-22T14:39:02Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/distrox/v1/distrox/StackOperations.java", "diffHunk": "@@ -315,6 +316,26 @@ public Stack getStackByCrn(String crn) {\n         return stackCommonService.getRetryableFlows(name, workspaceId);\n     }\n \n+    public FlowIdentifier backupClusterDatabase(@NotNull NameOrCrn nameOrCrn, Long workspaceId, String location, String backupId) {\n+        LOGGER.debug(\"Starting cluster database backup: \" + nameOrCrn);\n+        if (nameOrCrn.hasName()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ1MDc0MA=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA0ODYwMg==", "bodyText": "I see, but if you check everything else (except upgrade, which I don't know why) supports both crn and name. I think this should too", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444048602", "createdAt": "2020-06-23T08:23:04Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/distrox/v1/distrox/StackOperations.java", "diffHunk": "@@ -315,6 +316,26 @@ public Stack getStackByCrn(String crn) {\n         return stackCommonService.getRetryableFlows(name, workspaceId);\n     }\n \n+    public FlowIdentifier backupClusterDatabase(@NotNull NameOrCrn nameOrCrn, Long workspaceId, String location, String backupId) {\n+        LOGGER.debug(\"Starting cluster database backup: \" + nameOrCrn);\n+        if (nameOrCrn.hasName()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ1MDc0MA=="}, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA3OTE3OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/distrox/v1/distrox/StackOperations.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMzoyOFrOGm6GtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowMzoyOFrOGm6GtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ1MTA2MA==", "bodyText": "same, why is it restricted to name?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443451060", "createdAt": "2020-06-22T10:03:28Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/distrox/v1/distrox/StackOperations.java", "diffHunk": "@@ -315,6 +316,26 @@ public Stack getStackByCrn(String crn) {\n         return stackCommonService.getRetryableFlows(name, workspaceId);\n     }\n \n+    public FlowIdentifier backupClusterDatabase(@NotNull NameOrCrn nameOrCrn, Long workspaceId, String location, String backupId) {\n+        LOGGER.debug(\"Starting cluster database backup: \" + nameOrCrn);\n+        if (nameOrCrn.hasName()) {\n+            return databaseBackupRestoreService.backupDatabase(workspaceId, nameOrCrn.getName(), location, backupId);\n+        } else {\n+            LOGGER.debug(\"No stack name provided for backup, found: \" + nameOrCrn);\n+            throw new BadRequestException(\"Please provide a stack name for backup\");\n+        }\n+    }\n+\n+    public FlowIdentifier restoreClusterDatabase(@NotNull NameOrCrn nameOrCrn, Long workspaceId, String location, String backupId) {\n+        LOGGER.debug(\"Starting cluster database restore: \" + nameOrCrn);\n+        if (nameOrCrn.hasName()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA5MjcwOnYy", "diffSide": "RIGHT", "path": "orchestrator-salt/src/main/java/com/sequenceiq/cloudbreak/orchestrator/salt/SaltOrchestrator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowNzozMFrOGm6PZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowNzozMFrOGm6PZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ1MzI4Nw==", "bodyText": "this part is the same as in restoreDatabase, could you refactor it into a separate method?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443453287", "createdAt": "2020-06-22T10:07:30Z", "author": {"login": "lacikaaa"}, "path": "orchestrator-salt/src/main/java/com/sequenceiq/cloudbreak/orchestrator/salt/SaltOrchestrator.java", "diffHunk": "@@ -856,6 +856,46 @@ public String name() {\n         }\n     }\n \n+    @Override\n+    public void backupDatabase(GatewayConfig primaryGateway, Set<String> target, Set<Node> allNodes, SaltConfig saltConfig,\n+            ExitCriteriaModel exitModel) throws CloudbreakOrchestratorFailedException {\n+        try (SaltConnector sc = createSaltConnector(primaryGateway)) {\n+            for (Entry<String, SaltPillarProperties> propertiesEntry : saltConfig.getServicePillarConfig().entrySet()) {\n+                OrchestratorBootstrap pillarSave = new PillarSave(sc, Sets.newHashSet(primaryGateway.getPrivateAddress()), propertiesEntry.getValue());\n+                Callable<Boolean> saltPillarRunner = saltRunner.runner(pillarSave, exitCriteria, exitModel);\n+                saltPillarRunner.call();\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MzA5NTI5OnYy", "diffSide": "RIGHT", "path": "orchestrator-salt/src/main/java/com/sequenceiq/cloudbreak/orchestrator/salt/SaltOrchestrator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowODoxN1rOGm6RBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxMDowODoxN1rOGm6RBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQ1MzcwMA==", "bodyText": "as I see the 2 method is the same except this parameter, could you refactor them to reflect this and eliminate duplication?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r443453700", "createdAt": "2020-06-22T10:08:17Z", "author": {"login": "lacikaaa"}, "path": "orchestrator-salt/src/main/java/com/sequenceiq/cloudbreak/orchestrator/salt/SaltOrchestrator.java", "diffHunk": "@@ -856,6 +856,46 @@ public String name() {\n         }\n     }\n \n+    @Override\n+    public void backupDatabase(GatewayConfig primaryGateway, Set<String> target, Set<Node> allNodes, SaltConfig saltConfig,\n+            ExitCriteriaModel exitModel) throws CloudbreakOrchestratorFailedException {\n+        try (SaltConnector sc = createSaltConnector(primaryGateway)) {\n+            for (Entry<String, SaltPillarProperties> propertiesEntry : saltConfig.getServicePillarConfig().entrySet()) {\n+                OrchestratorBootstrap pillarSave = new PillarSave(sc, Sets.newHashSet(primaryGateway.getPrivateAddress()), propertiesEntry.getValue());\n+                Callable<Boolean> saltPillarRunner = saltRunner.runner(pillarSave, exitCriteria, exitModel);\n+                saltPillarRunner.call();\n+            }\n+\n+            StateRunner stateRunner = new StateRunner(target, allNodes, DATABASE_BACKUP);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e117cc071b93d2d2cb72ad82ffdbd82a080d5863"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzA3OTc1OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOToyODo1MFrOGnhEuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwOToyMzoxMlrOGoKJjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTUyOA==", "bodyText": "this should be either private or in a separate class, as it's not called from anywhere else", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444089528", "createdAt": "2020-06-23T09:28:50Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTg0OQ==", "bodyText": "backupid is not used", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444089849", "createdAt": "2020-06-23T09:29:25Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTUyOA=="}, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NDU2NA==", "bodyText": "there is a class, CloudStorageConfigGenerator maybe it worth checking out if you could use/reuse some parts of it", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444094564", "createdAt": "2020-06-23T09:37:23Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTUyOA=="}, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUzNTgwMQ==", "bodyText": "It's called from BackupRestoreSaltConfigGeneratorTest. I've made it package local.\nI accidentally deleted the part where backupId was used when I refactored this code. It's been added back.\nI looked at CloudStorageConfigGenerator.  I prefer what I'm doing here, so unless there's a strong reason to change it I'm going to keep what I have.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444535801", "createdAt": "2020-06-23T22:07:37Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTUyOA=="}, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc2MjUxMQ==", "bodyText": "at least \"aws\" and \"azure\" should be replaced with CloudConstants/CloudPlatform", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444762511", "createdAt": "2020-06-24T09:23:12Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTUyOA=="}, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzA4NTY0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOTozMDoyNFrOGnhINQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOTozMDoyNFrOGnhINQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5MDQyMQ==", "bodyText": "could you do this before we merge this pr?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444090421", "createdAt": "2020-06-23T09:30:24Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String fullLocation;\n+        if (\"aws\".equalsIgnoreCase(cloudPlatform)) {\n+            if (uri.getScheme() != null && !uri.getScheme().startsWith(\"s3\")) {\n+                throw new UnsupportedOperationException(\"Incorrect URL scheme for AWS cloud platform: \" + location);\n+            }\n+            fullLocation = \"s3://\" + uri.getSchemeSpecificPart().replaceAll(\"^/+\", \"\");\n+        } else if (\"azure\".equalsIgnoreCase(cloudPlatform)) {\n+            // TODO verify this is right when azure flow is working", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzExNDc5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOTozODoyMVrOGnhalg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMTowNToyNlrOGojG4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NTEyNg==", "bodyText": "I think validating this here is a bit late. This should be caught when processing the request. Just check how this works for logging/telemetry", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444095126", "createdAt": "2020-06-23T09:38:21Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String fullLocation;\n+        if (\"aws\".equalsIgnoreCase(cloudPlatform)) {\n+            if (uri.getScheme() != null && !uri.getScheme().startsWith(\"s3\")) {\n+                throw new UnsupportedOperationException(\"Incorrect URL scheme for AWS cloud platform: \" + location);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI5NjkyNw==", "bodyText": "Where is the logging/telemetry logic? This is my first experience in this codebase so I'm not sure exactly what you're referencing.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444296927", "createdAt": "2020-06-23T15:05:53Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String fullLocation;\n+        if (\"aws\".equalsIgnoreCase(cloudPlatform)) {\n+            if (uri.getScheme() != null && !uri.getScheme().startsWith(\"s3\")) {\n+                throw new UnsupportedOperationException(\"Incorrect URL scheme for AWS cloud platform: \" + location);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NTEyNg=="}, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc3MDIwOA==", "bodyText": "so the validation should be done around DatabaseBackupRestoreService#backupDatabase/restoreDatabase and the flow shouldn't be started with invalid input\nif you check LoggingBase it has separate input for AWS/Azure and those have validators, so it's checked on request time", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444770208", "createdAt": "2020-06-24T09:36:42Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String fullLocation;\n+        if (\"aws\".equalsIgnoreCase(cloudPlatform)) {\n+            if (uri.getScheme() != null && !uri.getScheme().startsWith(\"s3\")) {\n+                throw new UnsupportedOperationException(\"Incorrect URL scheme for AWS cloud platform: \" + location);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NTEyNg=="}, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3MTQyNw==", "bodyText": "I've added a BackupRestoreV4RequestValidator class and unit tests for it. It checks the location scheme, and also makes sure that required parameters are set.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r445171427", "createdAt": "2020-06-24T21:05:26Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    public String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String fullLocation;\n+        if (\"aws\".equalsIgnoreCase(cloudPlatform)) {\n+            if (uri.getScheme() != null && !uri.getScheme().startsWith(\"s3\")) {\n+                throw new UnsupportedOperationException(\"Incorrect URL scheme for AWS cloud platform: \" + location);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NTEyNg=="}, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzEyODg0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/api/event/cluster/dr/restore/DatabaseRestoreRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOTo0MjoyM1rOGnhjkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOTo0MjoyM1rOGnhjkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NzQyNQ==", "bodyText": "I won't go over all of your requests, but please fix them all.\nSo you shouldn't do this. If you check StackEvent it has already an implementation which will return with the same by default.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444097425", "createdAt": "2020-06-23T09:42:23Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/api/event/cluster/dr/restore/DatabaseRestoreRequest.java", "diffHunk": "@@ -0,0 +1,15 @@\n+package com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.BackupRestoreEvent;\n+\n+public class DatabaseRestoreRequest extends BackupRestoreEvent {\n+\n+    public DatabaseRestoreRequest(Long stackId, String backupLocation, String backupId) {\n+        super(stackId, backupLocation, backupId);\n+    }\n+\n+    @Override\n+    public String selector() {\n+        return \"DatabaseRestoreRequest\";\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzEzMzY1OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/restore/DatabaseRestoreHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOTo0Mzo0NVrOGnhmrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOTo0Mzo0NVrOGnhmrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5ODIyMg==", "bodyText": "please use EventSelectorUtil here also. And fix in other places too if necessary", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444098222", "createdAt": "2020-06-23T09:43:45Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/restore/DatabaseRestoreHandler.java", "diffHunk": "@@ -0,0 +1,80 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.BackupRestoreSaltConfigGenerator;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseRestoreHandler extends ExceptionCatcherEventHandler<DatabaseRestoreRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseRestoreHandler.class);\n+\n+    @Inject\n+    private BackupRestoreSaltConfigGenerator saltConfigGenerator;\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return \"DatabaseRestoreRequest\";\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzE2NTM4OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/api/event/cluster/dr/backup/DatabaseBackupSuccess.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOTo1MjoxNVrOGnh6Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwOTo1MjoxNVrOGnh6Ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwMzIwMg==", "bodyText": "so we usually we do this the other way around. I would omit this part and let EventSelectorUtil take care of the selector here.\nI would modify DatabaseBackupEvent like this:\nDATABASE_BACKUP_FINISHED_EVENT(EventSelectorUtil.selector(DatabaseBackupSuccess.class)),\ncould you check the other events to be in line with this pattern?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r444103202", "createdAt": "2020-06-23T09:52:15Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/api/event/cluster/dr/backup/DatabaseBackupSuccess.java", "diffHunk": "@@ -0,0 +1,17 @@\n+package com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.BackupRestoreEvent;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup.DatabaseBackupEvent.DATABASE_BACKUP_FINISHED_EVENT;\n+\n+public class DatabaseBackupSuccess extends BackupRestoreEvent {\n+\n+    public DatabaseBackupSuccess(Long stackId) {\n+        super(stackId, null, null);\n+    }\n+\n+    @Override\n+    public String selector() {\n+        return DATABASE_BACKUP_FINISHED_EVENT.event();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2de4c18d49e806d546a1c2cd46e7e5f06490c35"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTUxNzU5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/service/DatabaseBackupRestoreService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOTo1NjozOVrOGpbC0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNDoxNToyOFrOGpijqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA4Nzg4OQ==", "bodyText": "after this line you should build mdccontext with MDCBuilder.buildMdcContext\nsame for restore", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446087889", "createdAt": "2020-06-26T09:56:39Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/service/DatabaseBackupRestoreService.java", "diffHunk": "@@ -0,0 +1,83 @@\n+package com.sequenceiq.cloudbreak.service;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.dto.NameOrCrn;\n+import com.sequenceiq.cloudbreak.controller.validation.dr.BackupRestoreV4RequestValidator;\n+import com.sequenceiq.cloudbreak.core.flow2.service.ReactorFlowManager;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.event.ResourceEvent;\n+import com.sequenceiq.cloudbreak.exception.BadRequestException;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.structuredevent.event.CloudbreakEventService;\n+import com.sequenceiq.cloudbreak.validation.ValidationResult;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import com.sequenceiq.flow.core.FlowLogService;\n+import com.sequenceiq.flow.domain.FlowLog;\n+import java.util.List;\n+import javax.inject.Inject;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.springframework.stereotype.Service;\n+\n+@Service\n+public class DatabaseBackupRestoreService {\n+\n+    private static final String DATALAKE_DATABASE_BACKUP = \"DATALAKE_DATABASE_BACKUP\";\n+\n+    private static final String DATALAKE_DATABASE_RESTORE = \"DATALAKE_DATABASE_RESTORE\";\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private FlowLogService flowLogService;\n+\n+    @Inject\n+    private ReactorFlowManager flowManager;\n+\n+    @Inject\n+    private CloudbreakEventService eventService;\n+\n+    @Inject\n+    private BackupRestoreV4RequestValidator requestValidator;\n+\n+    public void validate(Long workspaceId, NameOrCrn nameOrCrn, String location, String backupId) {\n+        Stack stack = stackService.getByNameOrCrnInWorkspace(nameOrCrn, workspaceId);\n+        ValidationResult validationResult = requestValidator.validate(stack, location, backupId);\n+        if (validationResult.hasError()) {\n+            throw new BadRequestException(validationResult.getFormattedErrors());\n+        }\n+    }\n+\n+    public FlowIdentifier backupDatabase(Long workspaceId, NameOrCrn nameOrCrn, String location, String backupId) {\n+        Stack stack = stackService.getByNameOrCrnInWorkspace(nameOrCrn, workspaceId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjIxMDk4Nw==", "bodyText": "will do", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446210987", "createdAt": "2020-06-26T14:15:28Z", "author": {"login": "kkalvagadda1"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/service/DatabaseBackupRestoreService.java", "diffHunk": "@@ -0,0 +1,83 @@\n+package com.sequenceiq.cloudbreak.service;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.dto.NameOrCrn;\n+import com.sequenceiq.cloudbreak.controller.validation.dr.BackupRestoreV4RequestValidator;\n+import com.sequenceiq.cloudbreak.core.flow2.service.ReactorFlowManager;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.event.ResourceEvent;\n+import com.sequenceiq.cloudbreak.exception.BadRequestException;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.structuredevent.event.CloudbreakEventService;\n+import com.sequenceiq.cloudbreak.validation.ValidationResult;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import com.sequenceiq.flow.core.FlowLogService;\n+import com.sequenceiq.flow.domain.FlowLog;\n+import java.util.List;\n+import javax.inject.Inject;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.springframework.stereotype.Service;\n+\n+@Service\n+public class DatabaseBackupRestoreService {\n+\n+    private static final String DATALAKE_DATABASE_BACKUP = \"DATALAKE_DATABASE_BACKUP\";\n+\n+    private static final String DATALAKE_DATABASE_RESTORE = \"DATALAKE_DATABASE_RESTORE\";\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private FlowLogService flowLogService;\n+\n+    @Inject\n+    private ReactorFlowManager flowManager;\n+\n+    @Inject\n+    private CloudbreakEventService eventService;\n+\n+    @Inject\n+    private BackupRestoreV4RequestValidator requestValidator;\n+\n+    public void validate(Long workspaceId, NameOrCrn nameOrCrn, String location, String backupId) {\n+        Stack stack = stackService.getByNameOrCrnInWorkspace(nameOrCrn, workspaceId);\n+        ValidationResult validationResult = requestValidator.validate(stack, location, backupId);\n+        if (validationResult.hasError()) {\n+            throw new BadRequestException(validationResult.getFormattedErrors());\n+        }\n+    }\n+\n+    public FlowIdentifier backupDatabase(Long workspaceId, NameOrCrn nameOrCrn, String location, String backupId) {\n+        Stack stack = stackService.getByNameOrCrnInWorkspace(nameOrCrn, workspaceId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA4Nzg4OQ=="}, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTUxOTY2OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/service/DatabaseBackupRestoreService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOTo1NzoyMlrOGpbEKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOTo1NzoyMlrOGpbEKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA4ODIzMw==", "bodyText": "I don't think you should need this as the flow engine would reject this flow if other is running", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446088233", "createdAt": "2020-06-26T09:57:22Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/service/DatabaseBackupRestoreService.java", "diffHunk": "@@ -0,0 +1,83 @@\n+package com.sequenceiq.cloudbreak.service;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.dto.NameOrCrn;\n+import com.sequenceiq.cloudbreak.controller.validation.dr.BackupRestoreV4RequestValidator;\n+import com.sequenceiq.cloudbreak.core.flow2.service.ReactorFlowManager;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.event.ResourceEvent;\n+import com.sequenceiq.cloudbreak.exception.BadRequestException;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.structuredevent.event.CloudbreakEventService;\n+import com.sequenceiq.cloudbreak.validation.ValidationResult;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import com.sequenceiq.flow.core.FlowLogService;\n+import com.sequenceiq.flow.domain.FlowLog;\n+import java.util.List;\n+import javax.inject.Inject;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.springframework.stereotype.Service;\n+\n+@Service\n+public class DatabaseBackupRestoreService {\n+\n+    private static final String DATALAKE_DATABASE_BACKUP = \"DATALAKE_DATABASE_BACKUP\";\n+\n+    private static final String DATALAKE_DATABASE_RESTORE = \"DATALAKE_DATABASE_RESTORE\";\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private FlowLogService flowLogService;\n+\n+    @Inject\n+    private ReactorFlowManager flowManager;\n+\n+    @Inject\n+    private CloudbreakEventService eventService;\n+\n+    @Inject\n+    private BackupRestoreV4RequestValidator requestValidator;\n+\n+    public void validate(Long workspaceId, NameOrCrn nameOrCrn, String location, String backupId) {\n+        Stack stack = stackService.getByNameOrCrnInWorkspace(nameOrCrn, workspaceId);\n+        ValidationResult validationResult = requestValidator.validate(stack, location, backupId);\n+        if (validationResult.hasError()) {\n+            throw new BadRequestException(validationResult.getFormattedErrors());\n+        }\n+    }\n+\n+    public FlowIdentifier backupDatabase(Long workspaceId, NameOrCrn nameOrCrn, String location, String backupId) {\n+        Stack stack = stackService.getByNameOrCrnInWorkspace(nameOrCrn, workspaceId);\n+        List<FlowLog> flowLogs = flowLogService.findAllByResourceIdAndFinalizedIsFalseOrderByCreatedDesc(stack.getId());\n+        if (!CollectionUtils.isEmpty(flowLogs)) {\n+            String errorMsg = String.format(\"Database backup cannot be performed because there is an active flow running: %s\",\n+                flowLogs.stream().map(FlowLog::toString));\n+            eventService.fireCloudbreakEvent(\n+                stack.getId(),\n+                DATALAKE_DATABASE_BACKUP,\n+                ResourceEvent.DATALAKE_DATABASE_BACKUP_COULD_NOT_START,\n+                List.of(errorMsg));\n+            throw new BadRequestException(errorMsg);\n+        } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTU3MTI0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDoxNTo0OVrOGpblrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMzoyNjo0NVrOGpg1jg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA5NjgxNA==", "bodyText": "just for future safety I would do else if here for Azure. When we introduce a new SPI support, like GCP we have to modify it here, so maybe an exception for unsupported SPI would be necessary to notice this easily", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446096814", "createdAt": "2020-06-26T10:15:49Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,37 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static com.sequenceiq.cloudbreak.common.type.CloudConstants.AWS;\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String suffix = '/' + backupId + \"_database_backup\";\n+        String fullLocation;\n+        if (AWS.equalsIgnoreCase(cloudPlatform)) {\n+            fullLocation = \"s3://\" + uri.getSchemeSpecificPart().replaceAll(\"^/+\", \"\");\n+        } else {\n+            fullLocation = \"abfs://\" + uri.getSchemeSpecificPart().replaceAll(\"^/+\", \"\");\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE4Mjc5OA==", "bodyText": "So I originally had an else if, and then a final else that threw an UnsupportedOperationException. You said I shouldn't be throwing an UnsupportedOperationException, but you didn't answer when I asked what I should be doing instead. So instead I made the BackupRestoreV4RequestValidator, which validates the scheme is either AWS or AZURE before the flow gets here, and removed the UnsupportedOperationException. Are you saying I should add it back? Is there some other exception type I should be using?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446182798", "createdAt": "2020-06-26T13:26:45Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/BackupRestoreSaltConfigGenerator.java", "diffHunk": "@@ -0,0 +1,37 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltPillarProperties;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.springframework.stereotype.Component;\n+\n+import static com.sequenceiq.cloudbreak.common.type.CloudConstants.AWS;\n+import static java.util.Collections.singletonMap;\n+\n+@Component\n+public class BackupRestoreSaltConfigGenerator {\n+\n+    public SaltConfig createSaltConfig(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        String fullLocation = buildFullLocation(location, backupId, cloudPlatform);\n+\n+        Map<String, SaltPillarProperties> servicePillar = new HashMap<>();\n+        servicePillar.put(\"disaster-recovery\", new SaltPillarProperties(\"/postgresql/disaster_recovery.sls\",\n+            singletonMap(\"disaster_recovery\", singletonMap(\"object_storage_url\", fullLocation))));\n+        return new SaltConfig(servicePillar);\n+    }\n+\n+    String buildFullLocation(String location, String backupId, String cloudPlatform) throws URISyntaxException {\n+        URI uri = new URI(location);\n+        String suffix = '/' + backupId + \"_database_backup\";\n+        String fullLocation;\n+        if (AWS.equalsIgnoreCase(cloudPlatform)) {\n+            fullLocation = \"s3://\" + uri.getSchemeSpecificPart().replaceAll(\"^/+\", \"\");\n+        } else {\n+            fullLocation = \"abfs://\" + uri.getSchemeSpecificPart().replaceAll(\"^/+\", \"\");\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA5NjgxNA=="}, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTU5MDQwOnYy", "diffSide": "RIGHT", "path": "orchestrator-salt/src/main/java/com/sequenceiq/cloudbreak/orchestrator/salt/SaltOrchestrator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDoyMjowN1rOGpbxRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMzozNzoxNVrOGphMuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA5OTc4Mg==", "bodyText": "something is off with your formatter I think. I reformatted this class on your branch from my idea, and it restored the original formatting. Could you make sure you have loaded the config for your idea?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446099782", "createdAt": "2020-06-26T10:22:07Z", "author": {"login": "lacikaaa"}, "path": "orchestrator-salt/src/main/java/com/sequenceiq/cloudbreak/orchestrator/salt/SaltOrchestrator.java", "diffHunk": "@@ -81,8 +48,37 @@\n import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n import com.sequenceiq.cloudbreak.service.Retry;\n import com.sequenceiq.cloudbreak.util.CompressUtil;\n-\n import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.AbstractMap.SimpleImmutableEntry;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.retry.annotation.Retryable;\n+import org.springframework.stereotype.Component;\n+import org.springframework.util.CollectionUtils;\n+import org.springframework.util.StringUtils;\n+\n+import static com.sequenceiq.cloudbreak.common.type.OrchestratorConstants.SALT;\n+import static com.sequenceiq.cloudbreak.common.type.RecipeExecutionPhase.PRE_CLOUDERA_MANAGER_START;\n+import static com.sequenceiq.cloudbreak.common.type.RecipeExecutionPhase.convert;\n+import static com.sequenceiq.cloudbreak.util.FileReaderUtils.readFileFromClasspath;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE4ODcyOA==", "bodyText": "I've loaded the config as instructed in the cloudbreak README at least twice. I'm not sure what else to do at this point.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446188728", "createdAt": "2020-06-26T13:37:15Z", "author": {"login": "hreeve-cloudera"}, "path": "orchestrator-salt/src/main/java/com/sequenceiq/cloudbreak/orchestrator/salt/SaltOrchestrator.java", "diffHunk": "@@ -81,8 +48,37 @@\n import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n import com.sequenceiq.cloudbreak.service.Retry;\n import com.sequenceiq.cloudbreak.util.CompressUtil;\n-\n import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.AbstractMap.SimpleImmutableEntry;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.stream.Collectors;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.retry.annotation.Retryable;\n+import org.springframework.stereotype.Component;\n+import org.springframework.util.CollectionUtils;\n+import org.springframework.util.StringUtils;\n+\n+import static com.sequenceiq.cloudbreak.common.type.OrchestratorConstants.SALT;\n+import static com.sequenceiq.cloudbreak.common.type.RecipeExecutionPhase.PRE_CLOUDERA_MANAGER_START;\n+import static com.sequenceiq.cloudbreak.common.type.RecipeExecutionPhase.convert;\n+import static com.sequenceiq.cloudbreak.util.FileReaderUtils.readFileFromClasspath;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA5OTc4Mg=="}, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTU5NzUzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/DatabaseBackupActions.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDoyNDo0NlrOGpb1lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDoyNDo0NlrOGpb1lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwMDg4Ng==", "bodyText": "if you fix the context at trigger you might omit this line", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446100886", "createdAt": "2020-06-26T10:24:46Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/backup/DatabaseBackupActions.java", "diffHunk": "@@ -0,0 +1,99 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.AbstractBackupRestoreActions;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreContext;\n+import com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.BackupRestoreStatusService;\n+import com.sequenceiq.cloudbreak.core.flow2.event.DatabaseBackupTriggerEvent;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.flow.core.Flow;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Map;\n+import java.util.Optional;\n+import javax.inject.Inject;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import static com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr.backup.DatabaseBackupEvent.DATABASE_BACKUP_FAIL_HANDLED_EVENT;\n+\n+@Configuration\n+public class DatabaseBackupActions {\n+\n+    @Inject\n+    private BackupRestoreStatusService backupRestoreStatusService;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Bean(name = \"DATABASE_BACKUP_STATE\")\n+    public Action<?, ?> backupDatabase() {\n+        return new AbstractBackupRestoreActions<>(DatabaseBackupTriggerEvent.class) {\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseBackupTriggerEvent payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.backupDatabase(context.getStackId(), context.getBackupId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new DatabaseBackupRequest(context.getStackId(), context.getBackupLocation(), context.getBackupId());\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatabaseBackupTriggerEvent payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+                return DatabaseBackupFailedEvent.from(payload, ex, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_BACKUP_FINISHED_STATE\")\n+    public Action<?, ?> databaseBackupFinished() {\n+        return new AbstractBackupRestoreActions<>(DatabaseBackupSuccess.class) {\n+\n+            @Override\n+            protected void doExecute(BackupRestoreContext context, DatabaseBackupSuccess payload, Map<Object, Object> variables) {\n+                backupRestoreStatusService.backupDatabaseFinished(context.getStackId());\n+                sendEvent(context);\n+            }\n+\n+            @Override\n+            protected Selectable createRequest(BackupRestoreContext context) {\n+                return new StackEvent(DatabaseBackupEvent.DATABASE_BACKUP_FINALIZED_EVENT.event(), context.getStackId());\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATABASE_BACKUP_FAILED_STATE\")\n+    public Action<?, ?> databaseBackupFailedAction() {\n+        return new AbstractBackupRestoreActions<>(DatabaseBackupFailedEvent.class) {\n+\n+            @Override\n+            protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatabaseBackupFailedEvent payload) {\n+                Flow flow = getFlow(flowParameters.getFlowId());\n+                Stack stack = stackService.getById(payload.getResourceId());\n+                MDCBuilder.buildMdcContext(stack);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTYwOTk2OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/controller/validation/dr/BackupRestoreV4RequestValidator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDoyOTowMlrOGpb9Tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDoyOTowMlrOGpb9Tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwMjg2Mg==", "bodyText": "both azure and aws patterns could be compiled and be static final, like:\nprivate static final Pattern AWS_PATTERN_COMPILED = Pattern.compile(AWS_PATTERN, Pattern.CASE_INSENSITIVE);", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446102862", "createdAt": "2020-06-26T10:29:02Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/controller/validation/dr/BackupRestoreV4RequestValidator.java", "diffHunk": "@@ -0,0 +1,61 @@\n+package com.sequenceiq.cloudbreak.controller.validation.dr;\n+\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.validation.ValidationResult;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.springframework.stereotype.Component;\n+\n+import static com.sequenceiq.cloudbreak.common.type.CloudConstants.AWS;\n+import static com.sequenceiq.cloudbreak.common.type.CloudConstants.AZURE;\n+\n+@Component\n+public class BackupRestoreV4RequestValidator {\n+\n+    private static final String AWS_PATTERN = \"(^s3[a|n]?$)|(^$)\";\n+\n+    private static final String AZURE_PATTERN = \"(^abfs[s]?$)|(^$)\";\n+\n+    public ValidationResult validate(Stack stack, String location, String backupId) {\n+        ValidationResult.ValidationResultBuilder resultBuilder = ValidationResult.builder();\n+        String cloudPlatform = stack.cloudPlatform();\n+\n+        if (Strings.isNullOrEmpty(backupId)) {\n+            resultBuilder.error(\"Parameter backupId required\");\n+        }\n+        if (Strings.isNullOrEmpty(location)) {\n+            resultBuilder.error(\"Parameter backupLocation required\");\n+        } else {\n+            validateCloudLocationScheme(cloudPlatform, location, resultBuilder);\n+        }\n+        return resultBuilder.build();\n+    }\n+\n+    private void validateCloudLocationScheme(String cloudPlatform, String location, ValidationResult.ValidationResultBuilder resultBuilder) {\n+        try {\n+            URI uri = new URI(location);\n+            if (AWS.equalsIgnoreCase(cloudPlatform)) {\n+                if (uri.getScheme() != null) {\n+                    Matcher matcher = Pattern.compile(AWS_PATTERN, Pattern.CASE_INSENSITIVE).matcher(uri.getScheme());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTY0MTYzOnYy", "diffSide": "RIGHT", "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDo0MTozMFrOGpcRfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDo0MTozMFrOGpcRfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwODAzMQ==", "bodyText": "please add this to the mapToFailedIfInProgress method switch\nsame for RESTORE_IN_PROGRESS", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446108031", "createdAt": "2020-06-26T10:41:30Z", "author": {"login": "lacikaaa"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java", "diffHunk": "@@ -38,7 +34,13 @@\n     EXTERNAL_DATABASE_CREATION_FAILED(StatusKind.FINAL),\n     EXTERNAL_DATABASE_DELETION_IN_PROGRESS(StatusKind.PROGRESS),\n     EXTERNAL_DATABASE_DELETION_FINISHED(StatusKind.PROGRESS),\n-    EXTERNAL_DATABASE_DELETION_FAILED(StatusKind.FINAL);\n+    EXTERNAL_DATABASE_DELETION_FAILED(StatusKind.FINAL),\n+    BACKUP_IN_PROGRESS(StatusKind.PROGRESS),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTY1ODkzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/AbstractBackupRestoreActions.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDo0ODoyMlrOGpccCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNDo1MTo1N1rOGpj3tQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExMDcyOA==", "bodyText": "I'm very afraid of this could cause NullPointerException somewhere. If you check the failure handling action it will use the payload, and if there is a null pointer I think it would make the flow stuck for a while", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446110728", "createdAt": "2020-06-26T10:48:22Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/AbstractBackupRestoreActions.java", "diffHunk": "@@ -0,0 +1,28 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr;\n+\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.BackupRestoreEvent;\n+import com.sequenceiq.flow.core.AbstractAction;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Optional;\n+import org.springframework.statemachine.StateContext;\n+\n+public abstract class AbstractBackupRestoreActions<P extends BackupRestoreEvent>\n+    extends AbstractAction<FlowState, FlowEvent, BackupRestoreContext, P> {\n+\n+    protected AbstractBackupRestoreActions(Class<P> payloadClass) {\n+        super(payloadClass);\n+    }\n+\n+    @Override\n+    protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+            P payload) {\n+        return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+    }\n+\n+    @Override\n+    protected Object getFailurePayload(P payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+        return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjIzMjUwMQ==", "bodyText": "Used StackFailureEvent as the default here instead of null.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446232501", "createdAt": "2020-06-26T14:51:57Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/AbstractBackupRestoreActions.java", "diffHunk": "@@ -0,0 +1,28 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr;\n+\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.BackupRestoreEvent;\n+import com.sequenceiq.flow.core.AbstractAction;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+import java.util.Optional;\n+import org.springframework.statemachine.StateContext;\n+\n+public abstract class AbstractBackupRestoreActions<P extends BackupRestoreEvent>\n+    extends AbstractAction<FlowState, FlowEvent, BackupRestoreContext, P> {\n+\n+    protected AbstractBackupRestoreActions(Class<P> payloadClass) {\n+        super(payloadClass);\n+    }\n+\n+    @Override\n+    protected BackupRestoreContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+            P payload) {\n+        return BackupRestoreContext.from(flowParameters, payload, payload.getBackupLocation(), payload.getBackupId());\n+    }\n+\n+    @Override\n+    protected Object getFailurePayload(P payload, Optional<BackupRestoreContext> flowContext, Exception ex) {\n+        return null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExMDcyOA=="}, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTY3MTY2OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDo1MzozOFrOGpckAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQxMzoyOToxMFrOGqQ-wA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExMjc3MA==", "bodyText": "I'm a bit confused here and maybe @foldik or @bbihari could chime in.\nSo I think FINISHED states shouldn't be here, as it would mean everything should be back to normal and operational.\nAlso, I think if backup fails, it shouldn't mean that the cluster isn't operational, or does it?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446112770", "createdAt": "2020-06-26T10:53:38Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "diffHunk": "@@ -141,8 +138,10 @@ protected void executeInternal(JobExecutionContext context) throws JobExecutionE\n                 Status.MAINTENANCE_MODE_ENABLED,\n                 Status.EXTERNAL_DATABASE_CREATION_IN_PROGRESS,\n                 Status.BACKUP_IN_PROGRESS,\n+                Status.BACKUP_FINISHED,\n                 Status.BACKUP_FAILED,\n                 Status.RESTORE_IN_PROGRESS,\n+                Status.RESTORE_FINISHED,\n                 Status.RESTORE_FAILED", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE3OTM0NA==", "bodyText": "It shouldn't, no.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446179344", "createdAt": "2020-06-26T13:20:55Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "diffHunk": "@@ -141,8 +138,10 @@ protected void executeInternal(JobExecutionContext context) throws JobExecutionE\n                 Status.MAINTENANCE_MODE_ENABLED,\n                 Status.EXTERNAL_DATABASE_CREATION_IN_PROGRESS,\n                 Status.BACKUP_IN_PROGRESS,\n+                Status.BACKUP_FINISHED,\n                 Status.BACKUP_FAILED,\n                 Status.RESTORE_IN_PROGRESS,\n+                Status.RESTORE_FINISHED,\n                 Status.RESTORE_FAILED", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExMjc3MA=="}, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjIzMzE5OQ==", "bodyText": "I've gone ahead and removed the FINISHED enums. If @foldik or @bbihari have any other suggestions I'll make them later.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446233199", "createdAt": "2020-06-26T14:52:59Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "diffHunk": "@@ -141,8 +138,10 @@ protected void executeInternal(JobExecutionContext context) throws JobExecutionE\n                 Status.MAINTENANCE_MODE_ENABLED,\n                 Status.EXTERNAL_DATABASE_CREATION_IN_PROGRESS,\n                 Status.BACKUP_IN_PROGRESS,\n+                Status.BACKUP_FINISHED,\n                 Status.BACKUP_FAILED,\n                 Status.RESTORE_IN_PROGRESS,\n+                Status.RESTORE_FINISHED,\n                 Status.RESTORE_FAILED", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExMjc3MA=="}, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkwMTQ5Mw==", "bodyText": "Every new status enum value should be categorized as syncable/ignored/unschedulable.\nIf it's \"unschedulable\" then that state should be an end-state like terminated. If it's \"ignored\" then it should be an in-progress state.\nThe FAILED states should be handled in SdxClusterStatusCheckerJob too.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446901493", "createdAt": "2020-06-29T11:35:08Z", "author": {"login": "bbihari"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "diffHunk": "@@ -141,8 +138,10 @@ protected void executeInternal(JobExecutionContext context) throws JobExecutionE\n                 Status.MAINTENANCE_MODE_ENABLED,\n                 Status.EXTERNAL_DATABASE_CREATION_IN_PROGRESS,\n                 Status.BACKUP_IN_PROGRESS,\n+                Status.BACKUP_FINISHED,\n                 Status.BACKUP_FAILED,\n                 Status.RESTORE_IN_PROGRESS,\n+                Status.RESTORE_FINISHED,\n                 Status.RESTORE_FAILED", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExMjc3MA=="}, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk3MTU4NA==", "bodyText": "Handled in what way? It looks like only a handful of states from Status are explicitly handled in SdxClusterStatusCheckerJob.", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446971584", "createdAt": "2020-06-29T13:29:10Z", "author": {"login": "hreeve-cloudera"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "diffHunk": "@@ -141,8 +138,10 @@ protected void executeInternal(JobExecutionContext context) throws JobExecutionE\n                 Status.MAINTENANCE_MODE_ENABLED,\n                 Status.EXTERNAL_DATABASE_CREATION_IN_PROGRESS,\n                 Status.BACKUP_IN_PROGRESS,\n+                Status.BACKUP_FINISHED,\n                 Status.BACKUP_FAILED,\n                 Status.RESTORE_IN_PROGRESS,\n+                Status.RESTORE_FINISHED,\n                 Status.RESTORE_FAILED", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExMjc3MA=="}, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTY5NjIzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreContext.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMTowMzo0MlrOGpczpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMTowMzo0MlrOGpczpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExNjc3NQ==", "bodyText": "these should be final", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446116775", "createdAt": "2020-06-26T11:03:42Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/core/flow2/cluster/datalake/dr/BackupRestoreContext.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package com.sequenceiq.cloudbreak.core.flow2.cluster.datalake.dr;\n+\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import com.sequenceiq.flow.core.CommonContext;\n+import com.sequenceiq.flow.core.FlowParameters;\n+\n+public class BackupRestoreContext extends CommonContext {\n+\n+    private Long stackId;\n+\n+    private String backupLocation;\n+\n+    private String backupId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTcwMjYyOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/api/event/cluster/dr/BackupRestoreEvent.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMTowNjowNVrOGpc3pA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMTowNjowNVrOGpc3pA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExNzc5Ng==", "bodyText": "should be final", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446117796", "createdAt": "2020-06-26T11:06:05Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/api/event/cluster/dr/BackupRestoreEvent.java", "diffHunk": "@@ -0,0 +1,36 @@\n+package com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr;\n+\n+import com.sequenceiq.cloudbreak.common.event.AcceptResult;\n+import com.sequenceiq.cloudbreak.reactor.api.event.StackEvent;\n+import reactor.rx.Promise;\n+\n+public class BackupRestoreEvent extends StackEvent {\n+\n+    private String backupLocation;\n+\n+    private String backupId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTcxNzI4OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToxMTozM1rOGpdAgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToxMTozM1rOGpdAgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMDA2Nw==", "bodyText": "please use Cluster#hasGateway", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446120067", "createdAt": "2020-06-26T11:11:33Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.BackupRestoreSaltConfigGenerator;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.event.EventSelectorUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseBackupHandler extends ExceptionCatcherEventHandler<DatabaseBackupRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseBackupHandler.class);\n+\n+    @Inject\n+    private BackupRestoreSaltConfigGenerator saltConfigGenerator;\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return EventSelectorUtil.selector(DatabaseBackupRequest.class);\n+    }\n+\n+    @Override\n+    protected Selectable defaultFailureEvent(Long resourceId, Exception e) {\n+        return new DatabaseBackupFailedEvent(resourceId, e, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+    }\n+\n+    @Override\n+    protected void doAccept(HandlerEvent event) {\n+        LOGGER.debug(\"Accepting Database backup event...\");\n+        DatabaseBackupRequest request = event.getData();\n+        Selectable result;\n+        Long stackId = request.getResourceId();\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(stackId);\n+            Cluster cluster = stack.getCluster();\n+            InstanceMetaData gatewayInstance = stack.getPrimaryGatewayInstance();\n+            GatewayConfig gatewayConfig = gatewayConfigService.getGatewayConfig(stack, gatewayInstance, cluster.getGateway() != null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTcxNzk4OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/restore/DatabaseRestoreHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToxMTo0OVrOGpdA8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToxMTo0OVrOGpdA8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMDE3Ng==", "bodyText": "please use Cluster#hasGateway", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446120176", "createdAt": "2020-06-26T11:11:49Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/restore/DatabaseRestoreHandler.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.restore;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.restore.DatabaseRestoreSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.BackupRestoreSaltConfigGenerator;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.event.EventSelectorUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseRestoreHandler extends ExceptionCatcherEventHandler<DatabaseRestoreRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseRestoreHandler.class);\n+\n+    @Inject\n+    private BackupRestoreSaltConfigGenerator saltConfigGenerator;\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return EventSelectorUtil.selector(DatabaseRestoreRequest.class);\n+    }\n+\n+    @Override\n+    protected Selectable defaultFailureEvent(Long resourceId, Exception e) {\n+        return new DatabaseRestoreFailedEvent(resourceId, e, DetailedStackStatus.DATABASE_RESTORE_FAILED);\n+    }\n+\n+    @Override\n+    protected void doAccept(HandlerEvent event) {\n+        LOGGER.debug(\"Accepting Database restore event...\");\n+        DatabaseRestoreRequest request = event.getData();\n+        Selectable result;\n+        Long stackId = request.getResourceId();\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(stackId);\n+            Cluster cluster = stack.getCluster();\n+            InstanceMetaData gatewayInstance = stack.getPrimaryGatewayInstance();\n+            GatewayConfig gatewayConfig = gatewayConfigService.getGatewayConfig(stack, gatewayInstance, cluster.getGateway() != null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTczMDkzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToxNjoyM1rOGpdIxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToxNjoyM1rOGpdIxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMjE4Mg==", "bodyText": "this is strange. we should log de event or event data here to make it a bit meaningful. same for the other handler\nalso for receiving the event there should be already a log provided by LogContextAspects", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446122182", "createdAt": "2020-06-26T11:16:23Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/reactor/handler/cluster/dr/backup/DatabaseBackupHandler.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.backup;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.DetailedStackStatus;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.cloudbreak.core.bootstrap.service.ClusterDeletionBasedExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.orchestrator.host.HostOrchestrator;\n+import com.sequenceiq.cloudbreak.orchestrator.model.GatewayConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.model.SaltConfig;\n+import com.sequenceiq.cloudbreak.orchestrator.state.ExitCriteriaModel;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupFailedEvent;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupRequest;\n+import com.sequenceiq.cloudbreak.reactor.api.event.cluster.dr.backup.DatabaseBackupSuccess;\n+import com.sequenceiq.cloudbreak.reactor.handler.cluster.dr.BackupRestoreSaltConfigGenerator;\n+import com.sequenceiq.cloudbreak.service.GatewayConfigService;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.util.StackUtil;\n+import com.sequenceiq.flow.event.EventSelectorUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+import java.util.Collections;\n+import java.util.Set;\n+import javax.inject.Inject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatabaseBackupHandler extends ExceptionCatcherEventHandler<DatabaseBackupRequest> {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatabaseBackupHandler.class);\n+\n+    @Inject\n+    private BackupRestoreSaltConfigGenerator saltConfigGenerator;\n+\n+    @Inject\n+    private GatewayConfigService gatewayConfigService;\n+\n+    @Inject\n+    private HostOrchestrator hostOrchestrator;\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private StackUtil stackUtil;\n+\n+    @Override\n+    public String selector() {\n+        return EventSelectorUtil.selector(DatabaseBackupRequest.class);\n+    }\n+\n+    @Override\n+    protected Selectable defaultFailureEvent(Long resourceId, Exception e) {\n+        return new DatabaseBackupFailedEvent(resourceId, e, DetailedStackStatus.DATABASE_BACKUP_FAILED);\n+    }\n+\n+    @Override\n+    protected void doAccept(HandlerEvent event) {\n+        LOGGER.debug(\"Accepting Database backup event...\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTczODgyOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/service/DatabaseBackupRestoreService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToxOTowOVrOGpdNag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToxOTowOVrOGpdNag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMzM3MA==", "bodyText": "it would be nice to have a line of log here after MDCContext is build. same for restore method", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446123370", "createdAt": "2020-06-26T11:19:09Z", "author": {"login": "lacikaaa"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/service/DatabaseBackupRestoreService.java", "diffHunk": "@@ -0,0 +1,83 @@\n+package com.sequenceiq.cloudbreak.service;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.dto.NameOrCrn;\n+import com.sequenceiq.cloudbreak.controller.validation.dr.BackupRestoreV4RequestValidator;\n+import com.sequenceiq.cloudbreak.core.flow2.service.ReactorFlowManager;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.event.ResourceEvent;\n+import com.sequenceiq.cloudbreak.exception.BadRequestException;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.structuredevent.event.CloudbreakEventService;\n+import com.sequenceiq.cloudbreak.validation.ValidationResult;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import com.sequenceiq.flow.core.FlowLogService;\n+import com.sequenceiq.flow.domain.FlowLog;\n+import java.util.List;\n+import javax.inject.Inject;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.springframework.stereotype.Service;\n+\n+@Service\n+public class DatabaseBackupRestoreService {\n+\n+    private static final String DATALAKE_DATABASE_BACKUP = \"DATALAKE_DATABASE_BACKUP\";\n+\n+    private static final String DATALAKE_DATABASE_RESTORE = \"DATALAKE_DATABASE_RESTORE\";\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private FlowLogService flowLogService;\n+\n+    @Inject\n+    private ReactorFlowManager flowManager;\n+\n+    @Inject\n+    private CloudbreakEventService eventService;\n+\n+    @Inject\n+    private BackupRestoreV4RequestValidator requestValidator;\n+\n+    public void validate(Long workspaceId, NameOrCrn nameOrCrn, String location, String backupId) {\n+        Stack stack = stackService.getByNameOrCrnInWorkspace(nameOrCrn, workspaceId);\n+        ValidationResult validationResult = requestValidator.validate(stack, location, backupId);\n+        if (validationResult.hasError()) {\n+            throw new BadRequestException(validationResult.getFormattedErrors());\n+        }\n+    }\n+\n+    public FlowIdentifier backupDatabase(Long workspaceId, NameOrCrn nameOrCrn, String location, String backupId) {\n+        Stack stack = stackService.getByNameOrCrnInWorkspace(nameOrCrn, workspaceId);\n+        List<FlowLog> flowLogs = flowLogService.findAllByResourceIdAndFinalizedIsFalseOrderByCreatedDesc(stack.getId());\n+        if (!CollectionUtils.isEmpty(flowLogs)) {\n+            String errorMsg = String.format(\"Database backup cannot be performed because there is an active flow running: %s\",\n+                flowLogs.stream().map(FlowLog::toString));\n+            eventService.fireCloudbreakEvent(\n+                stack.getId(),\n+                DATALAKE_DATABASE_BACKUP,\n+                ResourceEvent.DATALAKE_DATABASE_BACKUP_COULD_NOT_START,\n+                List.of(errorMsg));\n+            throw new BadRequestException(errorMsg);\n+        } else {\n+            return flowManager.triggerDatalakeDatabaseBackup(stack.getId(), location, backupId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTc0ODY2OnYy", "diffSide": "RIGHT", "path": "orchestrator-salt/src/main/java/com/sequenceiq/cloudbreak/orchestrator/salt/SaltOrchestrator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToyMjozNlrOGpdTZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMToyMjozNlrOGpdTZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNDkwMQ==", "bodyText": "this should be error level, shouldn't it?", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446124901", "createdAt": "2020-06-26T11:22:36Z", "author": {"login": "lacikaaa"}, "path": "orchestrator-salt/src/main/java/com/sequenceiq/cloudbreak/orchestrator/salt/SaltOrchestrator.java", "diffHunk": "@@ -934,6 +934,37 @@ public String name() {\n         }\n     }\n \n+    @Override\n+    public void backupDatabase(GatewayConfig primaryGateway, Set<String> target, Set<Node> allNodes, SaltConfig saltConfig,\n+            ExitCriteriaModel exitModel) throws CloudbreakOrchestratorFailedException {\n+        callBackupRestore(primaryGateway, target, allNodes, saltConfig, exitModel, DATABASE_BACKUP);\n+    }\n+\n+    @Override\n+    public void restoreDatabase(GatewayConfig primaryGateway, Set<String> target, Set<Node> allNodes, SaltConfig saltConfig,\n+                                ExitCriteriaModel exitModel) throws CloudbreakOrchestratorFailedException {\n+        callBackupRestore(primaryGateway, target, allNodes, saltConfig, exitModel, DATABASE_RESTORE);\n+    }\n+\n+    private void callBackupRestore(GatewayConfig primaryGateway, Set<String> target, Set<Node> allNodes, SaltConfig saltConfig,\n+            ExitCriteriaModel exitModel, String state) throws CloudbreakOrchestratorFailedException {\n+        try (SaltConnector sc = createSaltConnector(primaryGateway)) {\n+            for (Entry<String, SaltPillarProperties> propertiesEntry : saltConfig.getServicePillarConfig().entrySet()) {\n+                OrchestratorBootstrap pillarSave = new PillarSave(sc, Sets.newHashSet(primaryGateway.getPrivateAddress()), propertiesEntry.getValue());\n+                Callable<Boolean> saltPillarRunner = saltRunner.runner(pillarSave, exitCriteria, exitModel, maxRetry, true);\n+                saltPillarRunner.call();\n+            }\n+\n+            StateRunner stateRunner = new StateRunner(target, allNodes, state);\n+            OrchestratorBootstrap saltJobIdTracker = new SaltJobIdTracker(sc, stateRunner);\n+            Callable<Boolean> saltJobRunBootstrapRunner = saltRunner.runner(saltJobIdTracker, exitCriteria, exitModel, maxRetry, true);\n+            saltJobRunBootstrapRunner.call();\n+        } catch (Exception e) {\n+            LOGGER.info(\"Error occurred during database backup/restore\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90e7f337c3e3f79431a40e1c0ad391735ca3fb57"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4NTA1MTMwOnYy", "diffSide": "RIGHT", "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQwOTo0NTo1NVrOGqLbYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQwOTo0NTo1NVrOGqLbYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg4MDYwOA==", "bodyText": "RESTORE_IN_PROGRESS", "url": "https://github.com/hortonworks/cloudbreak/pull/8284#discussion_r446880608", "createdAt": "2020-06-29T09:45:55Z", "author": {"login": "lacikaaa"}, "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java", "diffHunk": "@@ -97,6 +97,10 @@ public Status mapToFailedIfInProgress() {\n                 return START_FAILED;\n             case STOP_IN_PROGRESS:\n                 return STOP_FAILED;\n+            case BACKUP_IN_PROGRESS:\n+                return BACKUP_FAILED;\n+            case RESTORE_FAILED:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70dd6848d1c074624b120889e7c1533a982135c9"}, "originalPosition": 31}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3218, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}