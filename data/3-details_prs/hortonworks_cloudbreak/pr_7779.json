{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAyNzk3NDkw", "number": 7779, "title": "CB-5736 load based monitors evaulators", "bodyText": "Introduce LoadBased Evaluators and Monitors  for Autoscaling.\nIntegrate with Yarn Scaling API to query yarn recommendations.\nDefault tunnel for cluster communication changed to ClusterProxy.\nCloses #CB-5736", "createdAt": "2020-04-13T19:23:35Z", "url": "https://github.com/hortonworks/cloudbreak/pull/7779", "merged": true, "mergeCommit": {"oid": "e22fbca7e915d999bca1938341af2db60877d5f4"}, "closed": true, "closedAt": "2020-04-18T13:11:17Z", "author": {"login": "smaniraju"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcXUEhjgH2gAyNDAyNzk3NDkwOjJjMmEwMjJhNGQ1MmM1NDk3N2VhODEyMWExMTY3NWNjNDVlMmRiNWU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcY1UBRABqjMyNDcyNzM3MDI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2c2a022a4d52c54977ea8121a11675cc45e2db5e", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/2c2a022a4d52c54977ea8121a11675cc45e2db5e", "committedDate": "2020-04-13T19:29:23Z", "message": "CB-5734 DistroX Autoscaling API\n\nIntroduce DistroX Autoscaling API.\nSupports Time Based and Load Based Alerts."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3c966a64e341d630bccfe28bd45867168b74ba3f", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/3c966a64e341d630bccfe28bd45867168b74ba3f", "committedDate": "2020-04-13T19:21:16Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}, "afterCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "committedDate": "2020-04-13T19:29:23Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyMzg0ODA5", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#pullrequestreview-392384809", "createdAt": "2020-04-13T19:40:48Z", "commit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QxOTo0MDo0OFrOGEylUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QxOTo0MDo0OFrOGEylUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3NjI0MA==", "bodyText": "cluster-manager-host-health-monitor is required for periscope functionality, it removes orphaned clusters in periscope which are deleted in cloudbreak.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r407676240", "createdAt": "2020-04-13T19:40:48Z", "author": {"login": "smaniraju"}, "path": "autoscale/src/main/resources/application.yml", "diffHunk": "@@ -44,6 +45,19 @@ periscope:\n       addr: localhost\n       port: 5432\n   cloudbreak.url: http://localhost:9091\n+  enabledAutoscaleMonitors:\n+    time-monitor:\n+      enabled: true\n+    load-monitor:\n+      enabled: true\n+    rejected-thread-monitor:\n+      enabled: true\n+    cluster-manager-host-health-monitor:\n+      enabled: true", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzNTA2NDMx", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#pullrequestreview-393506431", "createdAt": "2020-04-15T07:06:46Z", "commit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "state": "COMMENTED", "comments": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNzowNjo0NlrOGFsdfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwODozODoxN1rOGFvkVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNDUwOQ==", "bodyText": "Doesn't seem to be used anywhere?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408624509", "createdAt": "2020-04-15T07:06:46Z", "author": {"login": "sidseth"}, "path": "autoscale-api/src/main/java/com/sequenceiq/periscope/doc/ApiDescription.java", "diffHunk": "@@ -121,6 +121,10 @@\n         public static final String SCALING_CONFIGURATION = \"Scaling configuration for the cluster\";\n     }\n \n+    public static class DistroXClusterJsonsProperties {\n+        public static final String DISTROX_SCALING_MODE = \"Scaling Types supported for distrox clusters\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNjA2Ng==", "bodyText": "Would be a little careful with this (logging the response vs just the time). Can blow up the logs (at DEBUG level). Also, have to make sure there's no sensitive information in any of the Responses.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408626066", "createdAt": "2020-04-15T07:10:02Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/aspects/RequestLogging.java", "diffHunk": "@@ -11,10 +11,16 @@\n \n     private static final Logger LOGGER = LoggerFactory.getLogger(RequestLogging.class);\n \n-    public <T> T logging(Supplier<T> callback, String requestName) {\n+    public <T> T logResponse(Supplier<T> callback, String requestName) {\n         long start = System.currentTimeMillis();\n-        T o = callback.get();\n-        LOGGER.debug(\"Ambari '{}' finished in {} ms\", requestName, System.currentTimeMillis() - start);\n-        return o;\n+        T response = callback.get();\n+        LOGGER.debug(\"Request '{}' finished in {} ms, Response {}\", requestName, System.currentTimeMillis() - start, response);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyOTg1Nw==", "bodyText": "This seems to be in 'minutes' - as per LoadAlertConfiguration variable naming. 30 seems a little too much. Maybe a 2 minute default? and rename param to include the unit.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408629857", "createdAt": "2020-04-15T07:17:47Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/Cluster.java", "diffHunk": "@@ -29,6 +29,12 @@\n @Entity\n public class Cluster implements Monitored, Clustered {\n \n+    public static final int DEFAULT_HOSTGROUP_MIN_SIZE = 1;\n+\n+    public static final int DEFAULT_HOSTGROUP_MAX_SIZE = 50;\n+\n+    public static final int DEFAULT_HOSTGROUP_COOL_DOWN = 30;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMDY2Nw==", "bodyText": "Not sure why these 2 defaults are required? min and max are mandatory parameters while registering a LoadAlert, correct?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408630667", "createdAt": "2020-04-15T07:19:18Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/Cluster.java", "diffHunk": "@@ -29,6 +29,12 @@\n @Entity\n public class Cluster implements Monitored, Clustered {\n \n+    public static final int DEFAULT_HOSTGROUP_MIN_SIZE = 1;\n+\n+    public static final int DEFAULT_HOSTGROUP_MAX_SIZE = 50;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMTc2Ng==", "bodyText": "Same as comment above. Can the defaults be skipped, since these values must be specified.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408631766", "createdAt": "2020-04-15T07:21:25Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/LoadAlertConfiguration.java", "diffHunk": "@@ -1,12 +1,15 @@\n package com.sequenceiq.periscope.domain;\n \n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n public class LoadAlertConfiguration {\n \n-    private Integer minResourceValue;\n+    private Integer minResourceValue = Cluster.DEFAULT_HOSTGROUP_MIN_SIZE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMzgyNg==", "bodyText": "Nit: TimeUnit.MILLISECONDS.convert(coolDownMinutes, TimeUnit.MINUTES)", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408633826", "createdAt": "2020-04-15T07:25:15Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/LoadAlertConfiguration.java", "diffHunk": "@@ -28,6 +31,11 @@ public Integer getCoolDownMinutes() {\n         return coolDownMinutes;\n     }\n \n+    @JsonIgnore\n+    public Long getCoolDownMillis() {\n+        return coolDownMinutes  * TimeUtil.MIN_IN_MS;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNjAzMg==", "bodyText": "These are used to deserialize the response from YARN?\nWOuld it make sense to ask YARN to provide a Swagger spec, and generate code from that?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408636032", "createdAt": "2020-04-15T07:29:27Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/model/yarn/NewNodeManagerCandidates.java", "diffHunk": "@@ -0,0 +1,67 @@\n+package com.sequenceiq.periscope.model.yarn;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+\n+public class NewNodeManagerCandidates {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MTM3NQ==", "bodyText": "This isn't a fixed name. It is set to 'compute' in our default template, but could be set to anything.\nRef the discussion in today's call about how relying on the hostname (derived from hostgroup) is temporary.\nI believe this needs to be a check on components for the hostgroup - which becomes relevant when HBase comes in. For now skip the check?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408641375", "createdAt": "2020-04-15T07:39:21Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/LoadMonitor.java", "diffHunk": "@@ -0,0 +1,50 @@\n+package com.sequenceiq.periscope.monitor;\n+\n+import java.util.List;\n+\n+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.StackType;\n+import com.sequenceiq.periscope.api.model.ClusterState;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.load.YarnLoadEvaluator;\n+\n+@Component\n+@ConditionalOnProperty(prefix = \"periscope.enabledAutoscaleMonitors.load-monitor\", name = \"enabled\", havingValue = \"true\")\n+public class LoadMonitor extends ClusterMonitor {\n+\n+    @Override\n+    public String getIdentifier() {\n+        return \"load-monitor\";\n+    }\n+\n+    @Override\n+    public String getTriggerExpression() {\n+        return MonitorUpdateRate.EVERY_MIN_RATE_CRON;\n+    }\n+\n+    @Override\n+    public Class<? extends EvaluatorExecutor> getEvaluatorType(Cluster cluster) {\n+        return getLoadEvaluatorForCluster(cluster);\n+    }\n+\n+    @Override\n+    protected List<Cluster> getMonitored() {\n+        List<Long> clusterIds = getClusterService().findLoadAlertClustersForNode(StackType.WORKLOAD,\n+                ClusterState.RUNNING, true, getPeriscopeNodeConfig().getId());\n+        return clusterIds.isEmpty() ? List.of() : getClusterService().findClustersByClusterIds(clusterIds);\n+    }\n+\n+    protected Class<? extends EvaluatorExecutor> getLoadEvaluatorForCluster(Cluster cluster) {\n+        String policyHostGroup = cluster.getLoadAlerts().stream().findFirst()\n+                .get().getScalingPolicy().getHostGroup().toLowerCase();\n+\n+        switch (policyHostGroup) {\n+            case \"compute\":", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MTk0Nw==", "bodyText": "Will this ever be disabled?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408641947", "createdAt": "2020-04-15T07:40:17Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/RejectedThreadMonitor.java", "diffHunk": "@@ -17,6 +18,7 @@\n import com.sequenceiq.periscope.monitor.evaluator.ClusterCreationEvaluator;\n \n @Component\n+@ConditionalOnProperty(prefix = \"periscope.enabledAutoscaleMonitors.rejected-thread-monitor\", name = \"enabled\", havingValue = \"true\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MzE2Mw==", "bodyText": "Initial plan is memory only. YARN CPU scheduling is not enforced (likely see available CPUs go negative on the YARN UI), and Tez etc are not set up very well to handle cpu scheduling.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408643163", "createdAt": "2020-04-15T07:42:38Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java", "diffHunk": "@@ -0,0 +1,93 @@\n+package com.sequenceiq.periscope.monitor.client;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.client.Client;\n+import javax.ws.rs.client.Entity;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.http.MediaType;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.client.RestClientUtil;\n+import com.sequenceiq.cloudbreak.common.mappable.CloudPlatform;\n+import com.sequenceiq.periscope.aspects.RequestLogging;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.model.CloudInstanceType;\n+import com.sequenceiq.periscope.model.TlsConfiguration;\n+import com.sequenceiq.periscope.model.yarn.HostGroupInstanceType;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Request;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.service.MachineUserService;\n+import com.sequenceiq.periscope.service.configuration.CloudInstanceTypeService;\n+import com.sequenceiq.periscope.service.configuration.ClusterProxyConfigurationService;\n+import com.sequenceiq.periscope.service.security.TlsSecurityService;\n+\n+@Component\n+public class YarnMetricsClient {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnMetricsClient.class);\n+\n+    private static final String YARN_API_URL = \"%s/proxy/%s/resourcemanager/v1/cluster/scaling\";\n+\n+    private static final String HEADER_ACTOR_CRN = \"x-cdp-actor-crn\";\n+\n+    private static final String PARAM_UPSCALE_FACTOR_NODE_RESOURCE_TYPE = \"upscaling-factor-in-node-resource-types\";\n+\n+    private static final String DEFAULT_UPSCALE_RESOURCE_TYPE = \"memory-mb,vcore\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0NDI2Nw==", "bodyText": "Where would Exceptions like this end up in a running Periscope system?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408644267", "createdAt": "2020-04-15T07:44:29Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java", "diffHunk": "@@ -0,0 +1,93 @@\n+package com.sequenceiq.periscope.monitor.client;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.client.Client;\n+import javax.ws.rs.client.Entity;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.http.MediaType;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.client.RestClientUtil;\n+import com.sequenceiq.cloudbreak.common.mappable.CloudPlatform;\n+import com.sequenceiq.periscope.aspects.RequestLogging;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.model.CloudInstanceType;\n+import com.sequenceiq.periscope.model.TlsConfiguration;\n+import com.sequenceiq.periscope.model.yarn.HostGroupInstanceType;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Request;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.service.MachineUserService;\n+import com.sequenceiq.periscope.service.configuration.CloudInstanceTypeService;\n+import com.sequenceiq.periscope.service.configuration.ClusterProxyConfigurationService;\n+import com.sequenceiq.periscope.service.security.TlsSecurityService;\n+\n+@Component\n+public class YarnMetricsClient {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnMetricsClient.class);\n+\n+    private static final String YARN_API_URL = \"%s/proxy/%s/resourcemanager/v1/cluster/scaling\";\n+\n+    private static final String HEADER_ACTOR_CRN = \"x-cdp-actor-crn\";\n+\n+    private static final String PARAM_UPSCALE_FACTOR_NODE_RESOURCE_TYPE = \"upscaling-factor-in-node-resource-types\";\n+\n+    private static final String DEFAULT_UPSCALE_RESOURCE_TYPE = \"memory-mb,vcore\";\n+\n+    @Inject\n+    private MachineUserService machineUserService;\n+\n+    @Inject\n+    private TlsSecurityService tlsSecurityService;\n+\n+    @Inject\n+    private ClusterProxyConfigurationService clusterProxyConfigurationService;\n+\n+    @Inject\n+    private CloudInstanceTypeService cloudInstanceTypeService;\n+\n+    @Inject\n+    private RequestLogging requestLogging;\n+\n+    public YarnScalingServiceV1Response getYarnMetricsForCluster(Cluster cluster,\n+            String hostGroupInstanceType,\n+            CloudPlatform cloudPlatform) throws Exception {\n+\n+        TlsConfiguration tlsConfig = tlsSecurityService.getTls(cluster.getId());\n+        Optional<String> clusterProxyUrl = clusterProxyConfigurationService.getClusterProxyUrl();\n+        if (!clusterProxyUrl.isPresent() || !cluster.getTunnel().useClusterProxy()) {\n+            String msg = String.format(\"ClusterProxy Not Configured for Cluster {}, cannot query YARN Metrics.\", cluster.getStackCrn());\n+            throw new RuntimeException(msg);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1MzU3Mw==", "bodyText": "From testing, this is fairly quick, correct?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408653573", "createdAt": "2020-04-15T08:00:48Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1NDM1NQ==", "bodyText": "Can more context be sent along with this event. What caused the failrue? (Inability to talk to YARN, something else)", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408654355", "createdAt": "2020-04-15T08:02:13Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1NjQ1Mw==", "bodyText": "As a future enhancement, we likely need to introduce a parameter which indicates how many nodes we will add in 1 iteration.\ne.g. if YARN says add 200 nodes (which is within max node count) - we should not attempt to add 200 nodes in 1 invocation. Instead add 50. Nexy upscale can add the next 50 and so on.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408656453", "createdAt": "2020-04-15T08:06:01Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst().map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() ->\n+                                new RuntimeException(String.format(\"Yarn Scaling API Response does not contain recommended host count \" +\n+                                                \"for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        int maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        maxAllowedScaleUp = maxAllowedScaleUp < 0 ? 0 : maxAllowedScaleUp;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1OTI0Mg==", "bodyText": "This does not belong here, even as a transient entity.\nThink it is better to change the event that is being published to contain any dynamic information of this kind.\nSo instead of sending the BaseAlert in the SaclingEvent - send a new entity, which could internally contain the BaseAlert if required, but is more focussed on what scaling action needs to be taken. (decomissionNodeIds, newNodeCount, etc)", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408659242", "createdAt": "2020-04-15T08:11:08Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/BaseAlert.java", "diffHunk": "@@ -32,6 +35,9 @@\n     @OneToOne(cascade = CascadeType.ALL, orphanRemoval = true)\n     private ScalingPolicy scalingPolicy;\n \n+    @Transient\n+    private List<String> decommissionNodeIds;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2MTQwMA==", "bodyText": "How efficient / inefficient is this approach? i.e. will it end up iterating over the same lists multiple times over (including string split, etc) for different nodes which need to be removed?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408661400", "createdAt": "2020-04-15T08:14:52Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst().map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() ->\n+                                new RuntimeException(String.format(\"Yarn Scaling API Response does not contain recommended host count \" +\n+                                                \"for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        int maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        maxAllowedScaleUp = maxAllowedScaleUp < 0 ? 0 : maxAllowedScaleUp;\n+        int scaleUpCount = Math.min(maxAllowedScaleUp, yarnRecommendedHostGroupCount);\n+\n+        LOGGER.info(\"ScaleUp NodeCount {} for Cluster {}, HostGroup {]\", scaleUpCount,\n+                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n+\n+        if (scaleUpCount > 0) {\n+            loadAlert.getScalingPolicy().setScalingAdjustment(scaleUpCount);\n+            eventPublisher.publishEvent(new ScalingEvent(loadAlert));\n+        }\n+    }\n+\n+    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n+        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n+        int maxAllowedScaleDown = hostGroupFqdns.size() - loadAlert.getLoadAlertConfiguration().getMinResourceValue();\n+        maxAllowedScaleDown = maxAllowedScaleDown < 0 ? 0 : maxAllowedScaleDown;\n+\n+        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+                .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n+                .map(DecommissionCandidate::getNodeId)\n+                .map(nodeFqdn -> nodeFqdn.split(\":\")[0])", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2MTU3Ng==", "bodyText": "See comment in BaseAlert.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408661576", "createdAt": "2020-04-15T08:15:11Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst().map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() ->\n+                                new RuntimeException(String.format(\"Yarn Scaling API Response does not contain recommended host count \" +\n+                                                \"for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        int maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        maxAllowedScaleUp = maxAllowedScaleUp < 0 ? 0 : maxAllowedScaleUp;\n+        int scaleUpCount = Math.min(maxAllowedScaleUp, yarnRecommendedHostGroupCount);\n+\n+        LOGGER.info(\"ScaleUp NodeCount {} for Cluster {}, HostGroup {]\", scaleUpCount,\n+                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n+\n+        if (scaleUpCount > 0) {\n+            loadAlert.getScalingPolicy().setScalingAdjustment(scaleUpCount);\n+            eventPublisher.publishEvent(new ScalingEvent(loadAlert));\n+        }\n+    }\n+\n+    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n+        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n+        int maxAllowedScaleDown = hostGroupFqdns.size() - loadAlert.getLoadAlertConfiguration().getMinResourceValue();\n+        maxAllowedScaleDown = maxAllowedScaleDown < 0 ? 0 : maxAllowedScaleDown;\n+\n+        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+                .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n+                .map(DecommissionCandidate::getNodeId)\n+                .map(nodeFqdn -> nodeFqdn.split(\":\")[0])\n+                .filter(s -> hostGroupFqdns.contains(s))\n+                .limit(maxAllowedScaleDown)\n+                .map(nodeFqdn -> hostGroupFqdnsToInstanceId.get(nodeFqdn))\n+                .collect(Collectors.toList());\n+\n+        LOGGER.info(\"ScaleDown NodeCount {} for Cluster {}, HostGroup {], NodeIds {}\",\n+                decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup(),\n+                decommissionHostGroupNodeIds);\n+\n+        if (!decommissionHostGroupNodeIds.isEmpty()) {\n+            loadAlert.setDecommissionNodeIds(decommissionHostGroupNodeIds);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2NzgwMg==", "bodyText": "Can this and azure-vm.json use the same values that are already available in Cloudbreak?\nMaintaining 2 copies of the same / similar files will lead to confusion sometime in the future when instances are changed.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408667802", "createdAt": "2020-04-15T08:25:39Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/resources/definitions/aws-vm.json", "diffHunk": "@@ -0,0 +1,174 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2ODcyNw==", "bodyText": "It seems to do this by talking to the cluster itself, instead of getting the state from Cloudbreak? Letting Cloudbreak talk to the cluster for health, and then getting this information from Cloudbreak I think will work better. Future enhancement: Not related to this change at all.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408668727", "createdAt": "2020-04-15T08:27:12Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/resources/application.yml", "diffHunk": "@@ -44,6 +45,19 @@ periscope:\n       addr: localhost\n       port: 5432\n   cloudbreak.url: http://localhost:9091\n+  enabledAutoscaleMonitors:\n+    time-monitor:\n+      enabled: true\n+    load-monitor:\n+      enabled: true\n+    rejected-thread-monitor:\n+      enabled: true\n+    cluster-manager-host-health-monitor:\n+      enabled: true", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3NjI0MA=="}, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2OTYwNg==", "bodyText": "Why remove the final?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408669606", "createdAt": "2020-04-15T08:28:39Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/utils/ClusterUtils.java", "diffHunk": "@@ -2,12 +2,16 @@\n \n import java.text.DecimalFormat;\n \n-public final class ClusterUtils {\n+public class ClusterUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY3NDA2OA==", "bodyText": "Can the CB returned instance types be used directly? Why define them again in Periscope.\nAlternately, if a library exists which can do this conversion - Periscope can rely on the DB entry directly.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408674068", "createdAt": "2020-04-15T08:35:59Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/service/configuration/CloudInstanceTypeService.java", "diffHunk": "@@ -0,0 +1,84 @@\n+package com.sequenceiq.periscope.service.configuration;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.PostConstruct;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.sequenceiq.cloudbreak.client.CloudbreakInternalCrnClient;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.common.mappable.CloudPlatform;\n+import com.sequenceiq.cloudbreak.service.CloudbreakResourceReaderService;\n+import com.sequenceiq.periscope.model.CloudInstanceType;\n+import com.sequenceiq.periscope.utils.FileReaderUtils;\n+\n+@Component\n+public class CloudInstanceTypeService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(FileReaderUtils.class);\n+\n+    @Inject\n+    private CloudbreakResourceReaderService cloudbreakResourceReaderService;\n+\n+    @Inject\n+    private CloudbreakInternalCrnClient internalCrnClient;\n+\n+    private Map<String, CloudInstanceType> awsInstanceTypes = new HashMap<>();\n+\n+    private Map<String, CloudInstanceType> azureInstanceTypes = new HashMap<>();\n+\n+    @PostConstruct\n+    public void init() {\n+        readCloudInstanceTypes(\"aws\", awsInstanceTypes);\n+        readCloudInstanceTypes(\"azure\", azureInstanceTypes);\n+    }\n+\n+    public Optional<CloudInstanceType> getCloudVMInstanceType(CloudPlatform cloudPlatform, String hostGroupInstanceType) {\n+        CloudInstanceType cloudVmType;\n+        switch (cloudPlatform) {\n+            case AWS:\n+                cloudVmType = awsInstanceTypes.get(hostGroupInstanceType);\n+                break;\n+            case AZURE:\n+                cloudVmType = azureInstanceTypes.get(hostGroupInstanceType);\n+                break;\n+            default:\n+                cloudVmType = null;\n+        }\n+        return Optional.ofNullable(cloudVmType);\n+    }\n+\n+    private void readCloudInstanceTypes(String cloudPlatform, Map<String, CloudInstanceType> vmInstanceTypes) {\n+        try {\n+            String cloudInstanceTypeConfig = cloudbreakResourceReaderService.resourceDefinition(cloudPlatform, \"vm\");\n+\n+            TypeReference<HashMap<String, Set<CloudInstanceType>>> typeRef = new TypeReference<>() { };\n+            Set<CloudInstanceType> cloudInstanceTypes = JsonUtil.readValue(cloudInstanceTypeConfig, typeRef).get(\"items\");\n+\n+            for (CloudInstanceType cloudInstanceType : cloudInstanceTypes) {\n+                vmInstanceTypes.put(cloudInstanceType.getInstanceName(), cloudInstanceType);\n+            }\n+\n+            Set<String> configuredCloudInstances = cloudInstanceTypes.stream().map(CloudInstanceType::getInstanceName).collect(Collectors.toSet());\n+            Set<String> cbSupportedInstances = internalCrnClient.withInternalCrn()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY3NTA5Mw==", "bodyText": "I'm still confused about whether CLUSTER_PROXY is the default or not. Maybe this gets changed to be the default in the production deployment.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408675093", "createdAt": "2020-04-15T08:37:44Z", "author": {"login": "sidseth"}, "path": "environment/src/main/resources/application.yml", "diffHunk": "@@ -90,7 +90,8 @@ environment:\n   enabledParentPlatforms: AWS, MOCK\n   enabledChildPlatforms: YARN, MOCK\n   tunnel:\n-    default: DIRECT\n+    default: CLUSTER_PROXY", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY3NTQxNQ==", "bodyText": "This looks like an accidental formatting change?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408675415", "createdAt": "2020-04-15T08:38:17Z", "author": {"login": "sidseth"}, "path": "core/src/main/resources/application.yml", "diffHunk": "@@ -177,24 +177,24 @@ cb:\n     host.name.prefix.length: 255\n     distrox:\n       enabled.instance.types: >\n-        Standard_D8_v3,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0MjQxNzk2", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#pullrequestreview-394241796", "createdAt": "2020-04-16T01:34:14Z", "commit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwMTozNDoxNFrOGGRWng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwMjoyNDo1OVrOGGSMpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIyODk1OA==", "bodyText": "Not needed any more.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409228958", "createdAt": "2020-04-16T01:34:14Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingHandler.java", "diffHunk": "@@ -45,60 +47,72 @@\n     @Inject\n     private ClouderaManagerTotalHostsEvaluator totalHostsEvaluatorService;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzMTE2Nw==", "bodyText": "Is there, by any chance, an alternate mechanism to fetch information like #hosts in a stack, without pulling information about the entire stack. Suspect this is a large amount of data being pulled, and not sure what load it puts on the Cloudbreak database.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409231167", "createdAt": "2020-04-16T01:42:16Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/CloudbreakCommunicator.java", "diffHunk": "@@ -1,20 +1,36 @@\n package com.sequenceiq.periscope.monitor.handler;\n \n+import java.util.List;\n+\n import javax.inject.Inject;\n \n import org.springframework.stereotype.Service;\n \n import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n import com.sequenceiq.cloudbreak.client.CloudbreakInternalCrnClient;\n+import com.sequenceiq.periscope.aspects.RequestLogging;\n+import com.sequenceiq.periscope.domain.Cluster;\n \n @Service\n public class CloudbreakCommunicator {\n \n     @Inject\n     private CloudbreakInternalCrnClient cloudbreakInternalCrnClient;\n \n+    @Inject\n+    private RequestLogging requestLogging;\n+\n     public StackV4Response getByCrn(String stackCrn) {\n         return cloudbreakInternalCrnClient.withInternalCrn().autoscaleEndpoint().get(stackCrn);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNDMyMg==", "bodyText": "Nit:\ns/nodeIds(s)/nodeId(s).\nAlso '{}' instead of {}.\nAlong with this, could we also publish the count of how many nodes were to be removed. Likewise in the message sent to History.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409234322", "createdAt": "2020-04-16T01:53:36Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingRequest.java", "diffHunk": "@@ -139,7 +152,31 @@ private void scaleDown(int scalingAdjustment, int totalNodes) {\n             scalingStatus = ScalingStatus.FAILED;\n             metricService.incrementMetricCounter(MetricType.CLUSTER_DOWNSCALE_FAILED);\n             statusReason = \"Couldn't trigger downscaling due to: \" + e.getMessage();\n-            LOGGER.info(statusReason, e);\n+            LOGGER.info(\"Couldn't trigger downscaling for host group '{}', cluster '{}', error '{}' \",\n+                    hostGroup, cluster.getStackCrn(), e);\n+        } finally {\n+            createHistoryAndNotify(totalNodes, statusReason, scalingStatus);\n+        }\n+    }\n+\n+    private void scaleDownByNodeIds(List<String> decommissionNodeIds) {\n+        metricService.incrementMetricCounter(MetricType.CLUSTER_DOWNSCALE_TRIGGERED);\n+        String hostGroup = policy.getHostGroup();\n+        String statusReason = null;\n+        ScalingStatus scalingStatus = null;\n+        try {\n+            LOGGER.debug(\"Sending request to remove  nodeIds(s) {} from host group '{}', cluster '{}' \",\n+                    decommissionNodeIds, hostGroup, cluster.getStackCrn());\n+            cloudbreakCommunicator.decommissionInstancesForCluster(cluster, decommissionNodeIds);\n+            scalingStatus = ScalingStatus.SUCCESS;\n+            statusReason = \"Downscale successfully triggered\";\n+            metricService.incrementMetricCounter(MetricType.CLUSTER_DOWNSCALE_SUCCESSFUL);\n+        } catch (Exception e) {\n+            scalingStatus = ScalingStatus.FAILED;\n+            metricService.incrementMetricCounter(MetricType.CLUSTER_DOWNSCALE_FAILED);\n+            statusReason = \"Couldn't trigger downscaling due to: \" + e.getMessage();\n+            LOGGER.info(\"Couldn't trigger downscaling to remove  nodeIds(s) {} from host group '{}', cluster '{}', error '{}' \",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNTIwNQ==", "bodyText": "Is this needed? Isn't the stack CRN already available?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409235205", "createdAt": "2020-04-16T01:56:42Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingRequest.java", "diffHunk": "@@ -92,7 +102,8 @@ private void scaleUp(int scalingAdjustment, int totalNodes) {\n         String statusReason = null;\n         ScalingStatus scalingStatus = null;\n         try {\n-            LOGGER.debug(\"Sending request to add {} instance(s) into host group '{}', triggered policy '{}'\", scalingAdjustment, hostGroup, policy.getName());\n+            LOGGER.debug(\"Sending request to add {} instance(s) into host group '{}', triggered policy '{}', cluster '{}'\",\n+                    scalingAdjustment, hostGroup, policy.getName(), cluster.getStackCrn());\n             String stackCrn = internalCrnClient.withInternalCrn().autoscaleEndpoint().getStackForAmbari(ambariAddressJson).getCrn();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNzAyNQ==", "bodyText": "This will be triggered in case of TimeAlerts. Will eventually have to change that over to work with the YARN API as well - so that nodes are not removed randomly. Separate jira / patch.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409237025", "createdAt": "2020-04-16T02:03:25Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingRequest.java", "diffHunk": "@@ -56,21 +60,27 @@\n     @Inject\n     private PeriscopeMetricService metricService;\n \n-    public ScalingRequest(Cluster cluster, ScalingPolicy policy, int totalNodes, int desiredNodeCount) {\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    public ScalingRequest(Cluster cluster, ScalingPolicy policy, int totalNodes, int desiredNodeCount, List<String> decommissionNodeIds) {\n         this.cluster = cluster;\n         this.policy = policy;\n         this.totalNodes = totalNodes;\n         this.desiredNodeCount = desiredNodeCount;\n+        this.decommissionNodeIds = decommissionNodeIds;\n     }\n \n     @Override\n     public void run() {\n         MDCBuilder.buildMdcContext(cluster);\n         try {\n             int scalingAdjustment = desiredNodeCount - totalNodes;\n-            if (scalingAdjustment > 0) {\n+            if (!decommissionNodeIds.isEmpty()) {\n+                scaleDownByNodeIds(decommissionNodeIds);\n+            } else if (scalingAdjustment > 0) {\n                 scaleUp(scalingAdjustment, totalNodes);\n-            } else {\n+            } else if (scalingAdjustment < 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzODY0Nw==", "bodyText": "Also, I suspect this gets triggered if the cluster has somehow managed to go above the maximum size. e.g. the max node count is reconfigured.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409238647", "createdAt": "2020-04-16T02:09:23Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingRequest.java", "diffHunk": "@@ -56,21 +60,27 @@\n     @Inject\n     private PeriscopeMetricService metricService;\n \n-    public ScalingRequest(Cluster cluster, ScalingPolicy policy, int totalNodes, int desiredNodeCount) {\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    public ScalingRequest(Cluster cluster, ScalingPolicy policy, int totalNodes, int desiredNodeCount, List<String> decommissionNodeIds) {\n         this.cluster = cluster;\n         this.policy = policy;\n         this.totalNodes = totalNodes;\n         this.desiredNodeCount = desiredNodeCount;\n+        this.decommissionNodeIds = decommissionNodeIds;\n     }\n \n     @Override\n     public void run() {\n         MDCBuilder.buildMdcContext(cluster);\n         try {\n             int scalingAdjustment = desiredNodeCount - totalNodes;\n-            if (scalingAdjustment > 0) {\n+            if (!decommissionNodeIds.isEmpty()) {\n+                scaleDownByNodeIds(decommissionNodeIds);\n+            } else if (scalingAdjustment > 0) {\n                 scaleUp(scalingAdjustment, totalNodes);\n-            } else {\n+            } else if (scalingAdjustment < 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNzAyNQ=="}, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzOTI2Ng==", "bodyText": "Check min/max node count constraints first? If this gets reconfigured - then how the YARN response is processed may need to be re-evaluated.\ne.g. cluster at 20 nodes. Max reconfigured to 10. YARN replies with 'need more resources'.\nLooks like scaleUp handles this - except for bringing the node count down to the maxValue.\nCould be a follow up jira as well, since you have already tested this.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409239266", "createdAt": "2020-04-16T02:11:46Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MTU5MQ==", "bodyText": "Removing this check - does it affect the evaluators other than the YarnLoadEvaluator? YarnLoadEvaluator performs this check itself. The others do not - so may end up triggering way more events?", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409241591", "createdAt": "2020-04-16T02:20:24Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingHandler.java", "diffHunk": "@@ -45,60 +47,72 @@\n     @Inject\n     private ClouderaManagerTotalHostsEvaluator totalHostsEvaluatorService;\n \n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n     @Override\n     public void onApplicationEvent(ScalingEvent event) {\n         BaseAlert alert = event.getAlert();\n         Cluster cluster = clusterService.findById(alert.getCluster().getId());\n         MDCBuilder.buildMdcContext(cluster);\n-        scale(cluster, alert.getScalingPolicy());\n+        handleClusterScaling(cluster, alert);\n     }\n \n-    private void scale(Cluster cluster, ScalingPolicy policy) {\n-        long remainingTime = getRemainingCooldownTime(cluster);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MjQzMA==", "bodyText": "Any chance this can be passed in to ScalingHandler? May not be possible for anything other than the YARNLoadEvaluator.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409242430", "createdAt": "2020-04-16T02:23:38Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingHandler.java", "diffHunk": "@@ -45,60 +47,72 @@\n     @Inject\n     private ClouderaManagerTotalHostsEvaluator totalHostsEvaluatorService;\n \n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n     @Override\n     public void onApplicationEvent(ScalingEvent event) {\n         BaseAlert alert = event.getAlert();\n         Cluster cluster = clusterService.findById(alert.getCluster().getId());\n         MDCBuilder.buildMdcContext(cluster);\n-        scale(cluster, alert.getScalingPolicy());\n+        handleClusterScaling(cluster, alert);\n     }\n \n-    private void scale(Cluster cluster, ScalingPolicy policy) {\n-        long remainingTime = getRemainingCooldownTime(cluster);\n-        if (remainingTime <= 0) {\n-            int totalNodes = totalHostsEvaluatorService.getTotalHosts(cluster);\n-            int desiredNodeCount = getDesiredNodeCount(cluster, policy, totalNodes);\n-            if (totalNodes != desiredNodeCount) {\n-                Runnable scalingRequest = (Runnable) applicationContext.getBean(\"ScalingRequest\", cluster, policy, totalNodes, desiredNodeCount);\n-                executorService.submit(scalingRequest);\n-                rejectedThreadService.remove(cluster.getId());\n-                cluster.setLastScalingActivityCurrent();\n-                clusterService.save(cluster);\n-            } else {\n-                LOGGER.debug(\"No scaling activity required\");\n-            }\n+    private void handleClusterScaling(Cluster cluster, BaseAlert alert) {\n+\n+        ScalingPolicy policy = alert.getScalingPolicy();\n+        Runnable scalingRequest = null;\n+        if (!alert.getDecommissionNodeIds().isEmpty()) {\n+            scalingRequest = (Runnable) applicationContext.getBean(\"ScalingRequest\", cluster, policy,\n+                    0, 0, alert.getDecommissionNodeIds());\n         } else {\n-            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n-                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+            int hostGroupNodeCount = getHostGroupNodeCount(cluster, policy);\n+            int desiredNodeCount = getDesiredNodeCount(cluster, policy, hostGroupNodeCount);\n+            if (hostGroupNodeCount != desiredNodeCount) {\n+                scalingRequest = (Runnable) applicationContext.getBean(\"ScalingRequest\", cluster, policy,\n+                        hostGroupNodeCount, desiredNodeCount, List.of());\n+            }\n         }\n-    }\n \n-    private long getRemainingCooldownTime(Cluster cluster) {\n-        long coolDown = cluster.getCoolDown();\n-        long lastScalingActivity = cluster.getLastScalingActivity();\n-        return lastScalingActivity == 0L ? 0L : (coolDown * TimeUtil.MIN_IN_MS) - (System.currentTimeMillis() - lastScalingActivity);\n+        if (scalingRequest != null) {\n+            executorService.submit(scalingRequest);\n+            rejectedThreadService.remove(cluster.getId());\n+            cluster.setLastScalingActivityCurrent();\n+            clusterService.save(cluster);\n+        } else {\n+            LOGGER.debug(\"No scaling activity required for cluster crn {}\", cluster.getStackCrn());\n+        }\n     }\n \n-    private int getDesiredNodeCount(Cluster cluster, ScalingPolicy policy, int totalNodes) {\n+    private int getDesiredNodeCount(Cluster cluster, ScalingPolicy policy, int hostGroupNodeCount) {\n         int scalingAdjustment = policy.getScalingAdjustment();\n-        int desiredNodeCount;\n+        int desiredHostGroupNodeCount;\n         switch (policy.getAdjustmentType()) {\n             case NODE_COUNT:\n-                desiredNodeCount = totalNodes + scalingAdjustment;\n+            case LOAD_BASED:\n+                desiredHostGroupNodeCount = hostGroupNodeCount + scalingAdjustment;\n                 break;\n             case PERCENTAGE:\n-                desiredNodeCount = totalNodes\n-                        + (int) (ceil(totalNodes * ((double) scalingAdjustment / ClusterUtils.MAX_CAPACITY)));\n+                desiredHostGroupNodeCount = hostGroupNodeCount\n+                        + (int) (ceil(hostGroupNodeCount * ((double) scalingAdjustment / ClusterUtils.MAX_CAPACITY)));\n                 break;\n             case EXACT:\n-                desiredNodeCount = policy.getScalingAdjustment();\n+                desiredHostGroupNodeCount = policy.getScalingAdjustment();\n                 break;\n             default:\n-                desiredNodeCount = totalNodes;\n+                desiredHostGroupNodeCount = hostGroupNodeCount;\n         }\n-        int minSize = cluster.getMinSize();\n-        int maxSize = cluster.getMaxSize();\n-        return desiredNodeCount < minSize ? minSize : desiredNodeCount > maxSize ? maxSize : desiredNodeCount;\n+        int minSize = cluster.getHostGroupMinSize();\n+        int maxSize = cluster.getHostGroupMaxSize();\n+\n+        return desiredHostGroupNodeCount < minSize ? minSize : desiredHostGroupNodeCount > maxSize ? maxSize : desiredHostGroupNodeCount;\n     }\n \n+    private int getHostGroupNodeCount(Cluster cluster, ScalingPolicy policy) {\n+        StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0Mjc4OA==", "bodyText": "However the event which gets published is changed - I think it'll be useful to include a timestamp in the event. That can be used to track metrics on how long from event generation to event processing - and generate alerts based on that. Will be useful for load testing as well.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409242788", "createdAt": "2020-04-16T02:24:59Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst().map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() ->\n+                                new RuntimeException(String.format(\"Yarn Scaling API Response does not contain recommended host count \" +\n+                                                \"for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        int maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        maxAllowedScaleUp = maxAllowedScaleUp < 0 ? 0 : maxAllowedScaleUp;\n+        int scaleUpCount = Math.min(maxAllowedScaleUp, yarnRecommendedHostGroupCount);\n+\n+        LOGGER.info(\"ScaleUp NodeCount {} for Cluster {}, HostGroup {]\", scaleUpCount,\n+                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n+\n+        if (scaleUpCount > 0) {\n+            loadAlert.getScalingPolicy().setScalingAdjustment(scaleUpCount);\n+            eventPublisher.publishEvent(new ScalingEvent(loadAlert));\n+        }\n+    }\n+\n+    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n+        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n+        int maxAllowedScaleDown = hostGroupFqdns.size() - loadAlert.getLoadAlertConfiguration().getMinResourceValue();\n+        maxAllowedScaleDown = maxAllowedScaleDown < 0 ? 0 : maxAllowedScaleDown;\n+\n+        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+                .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n+                .map(DecommissionCandidate::getNodeId)\n+                .map(nodeFqdn -> nodeFqdn.split(\":\")[0])\n+                .filter(s -> hostGroupFqdns.contains(s))\n+                .limit(maxAllowedScaleDown)\n+                .map(nodeFqdn -> hostGroupFqdnsToInstanceId.get(nodeFqdn))\n+                .collect(Collectors.toList());\n+\n+        LOGGER.info(\"ScaleDown NodeCount {} for Cluster {}, HostGroup {], NodeIds {}\",\n+                decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup(),\n+                decommissionHostGroupNodeIds);\n+\n+        if (!decommissionHostGroupNodeIds.isEmpty()) {\n+            loadAlert.setDecommissionNodeIds(decommissionHostGroupNodeIds);\n+            eventPublisher.publishEvent(new ScalingEvent(loadAlert));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92"}, "originalPosition": 177}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "committedDate": "2020-04-13T19:29:23Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}, "afterCommit": {"oid": "8f201909aca9016a323c5996cdbd41c4a1752328", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/8f201909aca9016a323c5996cdbd41c4a1752328", "committedDate": "2020-04-16T14:32:53Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk1MDc2OTgx", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#pullrequestreview-395076981", "createdAt": "2020-04-16T23:59:14Z", "commit": {"oid": "8f201909aca9016a323c5996cdbd41c4a1752328"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMzo1OToxNFrOGG7Rug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QwMDoxNDo0MlrOGG7jVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxNTgzNA==", "bodyText": "Min should be 0. It's possible for a hostGroup to run no instances.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409915834", "createdAt": "2020-04-16T23:59:14Z", "author": {"login": "sidseth"}, "path": "autoscale-api/src/main/java/com/sequenceiq/periscope/api/model/LoadAlertConfigurationRequest.java", "diffHunk": "@@ -11,12 +14,19 @@\n public class LoadAlertConfigurationRequest implements Json {\n \n     @ApiModelProperty(LoadAlertJsonProperties.LOAD_ALERT_CONFIGURATION_MIN_RESOUCE_VALUE)\n+    @Min(value = 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f201909aca9016a323c5996cdbd41c4a1752328"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxNjU4Ng==", "bodyText": "Think the 'min' should still be about 2 minutes here, to allow for enhancements in scale-up performance.\nAlso scale-down can finish within 2 minutes, or even faster.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409916586", "createdAt": "2020-04-17T00:01:54Z", "author": {"login": "sidseth"}, "path": "autoscale-api/src/main/java/com/sequenceiq/periscope/api/model/LoadAlertConfigurationRequest.java", "diffHunk": "@@ -11,12 +14,19 @@\n public class LoadAlertConfigurationRequest implements Json {\n \n     @ApiModelProperty(LoadAlertJsonProperties.LOAD_ALERT_CONFIGURATION_MIN_RESOUCE_VALUE)\n+    @Min(value = 1)\n+    @Digits(fraction = 0, integer = 3)\n     private @Valid Integer minResourceValue;\n \n     @ApiModelProperty(LoadAlertJsonProperties.LOAD_ALERT_CONFIGURATION_MAX_RESOUCE_VALUE)\n+    @Max(value = 200)\n+    @Digits(fraction = 0, integer = 3)\n     private @Valid Integer maxResourceValue;\n \n     @ApiModelProperty(LoadAlertJsonProperties.LOAD_ALERT_CONFIGURATION_COOL_DOWN_MINS_VALUE)\n+    @Min(value = 5)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f201909aca9016a323c5996cdbd41c4a1752328"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkyMDM0MQ==", "bodyText": "The same comment about modifying a 'Model' object applies here. Is there any chance this gets persisted to the DB accidentally?\nThe 'scaleUpCount' is essentially the same as the 'decommissionNodeIds' during scaleDown. Why not move this into ScalingRequest as well?\nFor all the other Evaluators, ScalingAdjustment is static, and is not modified by the Evaluators.", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409920341", "createdAt": "2020-04-17T00:14:42Z", "author": {"login": "sidseth"}, "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,187 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import static com.sequenceiq.periscope.monitor.evaluator.ScalingConstants.DEFAULT_MAX_SCALE_UP_STEP_SIZE;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst()\n+                        .map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() -> new RuntimeException(String.format(\n+                                \"Yarn Scaling API Response does not contain recommended node count \" +\n+                                        \" for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        Integer maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        Integer scaleUpCount = IntStream.of(yarnRecommendedHostGroupCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE, maxAllowedScaleUp)\n+                .filter(i -> i >= 0)\n+                .min()\n+                .getAsInt();\n+\n+        LOGGER.info(\"ScaleUp NodeCount {} for Cluster {}, HostGroup {]\", scaleUpCount,\n+                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n+\n+        if (scaleUpCount > 0) {\n+            loadAlert.getScalingPolicy().setScalingAdjustment(scaleUpCount);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f201909aca9016a323c5996cdbd41c4a1752328"}, "originalPosition": 158}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8f201909aca9016a323c5996cdbd41c4a1752328", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/8f201909aca9016a323c5996cdbd41c4a1752328", "committedDate": "2020-04-16T14:32:53Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}, "afterCommit": {"oid": "d66ab2f82203a7a9f886dcc33d929ab152f73ee9", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/d66ab2f82203a7a9f886dcc33d929ab152f73ee9", "committedDate": "2020-04-17T16:45:41Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d66ab2f82203a7a9f886dcc33d929ab152f73ee9", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/d66ab2f82203a7a9f886dcc33d929ab152f73ee9", "committedDate": "2020-04-17T16:45:41Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}, "afterCommit": {"oid": "02368bf722a69de52ec06c3cb1b4ecbc062743c4", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/02368bf722a69de52ec06c3cb1b4ecbc062743c4", "committedDate": "2020-04-18T12:17:37Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4872222a46ddc17a56b66f44c5ed073684e8b7c3", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/4872222a46ddc17a56b66f44c5ed073684e8b7c3", "committedDate": "2020-04-18T12:40:20Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "02368bf722a69de52ec06c3cb1b4ecbc062743c4", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/02368bf722a69de52ec06c3cb1b4ecbc062743c4", "committedDate": "2020-04-18T12:17:37Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}, "afterCommit": {"oid": "4872222a46ddc17a56b66f44c5ed073684e8b7c3", "author": {"user": {"login": "smaniraju", "name": null}}, "url": "https://github.com/hortonworks/cloudbreak/commit/4872222a46ddc17a56b66f44c5ed073684e8b7c3", "committedDate": "2020-04-18T12:40:20Z", "message": "CB-5736 Introduce support for Load Based Alert Monitors"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2315, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}