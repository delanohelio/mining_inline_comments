{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg3NjExNjI3", "number": 9020, "reviewThreads": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjowMlrOEj6nLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwNzo1NzoxNlrOEl9y6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MDk1OTE2OnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjowMlrOHSi5NQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDo0NDo1NFrOHS0ZOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODExNw==", "bodyText": "I guess it should be removed", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208117", "createdAt": "2020-09-16T07:02:02Z", "author": {"login": "doktoric"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ5NDg0Mg==", "bodyText": "Thanks. Went back and cleaned all that up.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489494842", "createdAt": "2020-09-16T14:44:54Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODExNw=="}, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MDk1OTQ5OnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjowOFrOHSi5ZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjowOFrOHSi5ZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODE2NA==", "bodyText": "I guess it should be removed", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208164", "createdAt": "2020-09-16T07:02:08Z", "author": {"login": "doktoric"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MDk2MDM3OnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjoyN1rOHSi5-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjoyN1rOHSi5-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODMxMw==", "bodyText": "please remove if not required", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208313", "createdAt": "2020-09-16T07:02:27Z", "author": {"login": "doktoric"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            BackupDatalakeStatusRequest.Builder builder = BackupDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setBackupId(backupId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MDk2MDgxOnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjozNVrOHSi6Ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjozNVrOHSi6Ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODM3OQ==", "bodyText": "I guess it should be removed", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208379", "createdAt": "2020-09-16T07:02:35Z", "author": {"login": "doktoric"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            BackupDatalakeStatusRequest.Builder builder = BackupDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setBackupId(backupId);\n+\n+            return statusConverter.convert(\n+                newStub(channelWrapper.getChannel(), UUID.randomUUID().toString(), actorCrn)\n+                    .backupDatalakeStatus(builder.build())\n+            );\n+        }\n+    }\n+\n+    public DatalakeDrStatusResponse getRestoreStatusByRestoreId(String datalakeName, String restoreId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(restoreId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MDk2MTAwOnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjozOVrOHSi6WA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjozOVrOHSi6WA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODQwOA==", "bodyText": "I guess it should be removed", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208408", "createdAt": "2020-09-16T07:02:39Z", "author": {"login": "doktoric"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            BackupDatalakeStatusRequest.Builder builder = BackupDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setBackupId(backupId);\n+\n+            return statusConverter.convert(\n+                newStub(channelWrapper.getChannel(), UUID.randomUUID().toString(), actorCrn)\n+                    .backupDatalakeStatus(builder.build())\n+            );\n+        }\n+    }\n+\n+    public DatalakeDrStatusResponse getRestoreStatusByRestoreId(String datalakeName, String restoreId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(restoreId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MDk2MTM4OnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjo0OVrOHSi6mg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjo0OVrOHSi6mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODQ3NA==", "bodyText": "please remove if not required", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208474", "createdAt": "2020-09-16T07:02:49Z", "author": {"login": "doktoric"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            BackupDatalakeStatusRequest.Builder builder = BackupDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setBackupId(backupId);\n+\n+            return statusConverter.convert(\n+                newStub(channelWrapper.getChannel(), UUID.randomUUID().toString(), actorCrn)\n+                    .backupDatalakeStatus(builder.build())\n+            );\n+        }\n+    }\n+\n+    public DatalakeDrStatusResponse getRestoreStatusByRestoreId(String datalakeName, String restoreId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(restoreId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            RestoreDatalakeStatusRequest.Builder builder = RestoreDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setRestoreId(restoreId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MDk3NDQ2OnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowNjo1OVrOHSjCUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwOTowNDoyNlrOHUEgHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA==", "bodyText": "If we would like to connect one of the cp service then we need changes in dps-k8s repo", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489210450", "createdAt": "2020-09-16T07:06:59Z", "author": {"login": "doktoric"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ5OTE2Ng==", "bodyText": "I have a PR here is to add this config setting in the CSI repo: https://github.infra.cloudera.com/thunderhead/cloud-services-infra/pull/1741. Is that what you mean, or is the dps-k8s repo different?", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489499166", "createdAt": "2020-09-16T14:50:11Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA=="}, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwMjc3OQ==", "bodyText": "The CSI change alone isn't doing anything. If you want to wire up the 2 services you'll need to make changes in CB helm charts: https://github.infra.cloudera.com/thunderhead/dps-k8s/tree/master/cloudbreak/helm-charts/cloudbreak-umbrella/charts", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489502779", "createdAt": "2020-09-16T14:54:59Z", "author": {"login": "keyki"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA=="}, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNjQ2OA==", "bodyText": "Thanks. I'll look into that now.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489506468", "createdAt": "2020-09-16T14:59:37Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA=="}, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgwNzMyNQ==", "bodyText": "I think the colon should be removed and a default value must be included in the application.yaml which points to local mock, because right now it won't start locally", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r490807325", "createdAt": "2020-09-18T09:04:26Z", "author": {"login": "lacikaaa"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA=="}, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MjQ3MjcxOnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/build.gradle", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMzozOTozM1rOHSxWwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDo1MTo1OVrOHS0vYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ0NTA1OA==", "bodyText": "are you sure these dependencies are necessary? I'm not sure about you need common here", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489445058", "createdAt": "2020-09-16T13:39:33Z", "author": {"login": "lacikaaa"}, "path": "datalake-dr-connector/build.gradle", "diffHunk": "@@ -0,0 +1,55 @@\n+apply plugin: 'com.google.protobuf'\n+\n+buildscript {\n+    repositories {\n+        mavenLocal()\n+        mavenCentral()\n+        maven { url = \"$repoUrl\" }\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath 'com.google.protobuf:protobuf-gradle-plugin:0.8.8'\n+    }\n+}\n+\n+dependencies {\n+    compile project(':common')\n+    compile project(':grpc-common')\n+    compile project(':auth-connector')\n+    compile project(':structuredevent-model')\n+    compile project(':flow')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwMDUxMg==", "bodyText": "I've cleaned up the build.gradle file to remove any unnecessary dependencies. I did need common for the logger, but there was a bunch of other stuff I could take out. I've also updated the header to \"CB-8717 Add thunderhead datalake-dr service connector\".", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489500512", "createdAt": "2020-09-16T14:51:59Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake-dr-connector/build.gradle", "diffHunk": "@@ -0,0 +1,55 @@\n+apply plugin: 'com.google.protobuf'\n+\n+buildscript {\n+    repositories {\n+        mavenLocal()\n+        mavenCentral()\n+        maven { url = \"$repoUrl\" }\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath 'com.google.protobuf:protobuf-gradle-plugin:0.8.8'\n+    }\n+}\n+\n+dependencies {\n+    compile project(':common')\n+    compile project(':grpc-common')\n+    compile project(':auth-connector')\n+    compile project(':structuredevent-model')\n+    compile project(':flow')", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ0NTA1OA=="}, "originalCommit": {"oid": "1fa10da1f38d8d63832c82c2db9dece4995dac39"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2Mjg2NTk3OnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNTowMToxNFrOHS1Lqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNzoxNToxOFrOHTtSRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA==", "bodyText": "we can not depend on just the getOverallState. Here you need to check the internal states as well.\nIf the overall status could be failed but the internal states could be still in progress.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489507754", "createdAt": "2020-09-16T15:01:14Z", "author": {"login": "kkalvagadda1"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package com.sequenceiq.cloudbreak.datalakedr.converter;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import java.util.Optional;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class GrpcStatusResponseToDatalakeDrStatusResponseConverter {\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.BackupDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a029658a9307869a649df016c313b0874cf621e"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUxNDU1NA==", "bodyText": "My thought there was that if the overall state was failed, but some operations were still in progress, that we no longer had to block the flow. At that point it doesn't matter if something interrupts the b/r operation, because even if the remaining operations succeed, we still end up in a bad state. I'm pretty confident that's true for backup flows. However, I'm not as sure about restore flows. If part of a restore has failed, but there are ongoing operations, would we wind up in a worse position if we interrupted those operations? Or would it not matter because we would have to re-attempt the restore regardless?", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489514554", "createdAt": "2020-09-16T15:10:09Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package com.sequenceiq.cloudbreak.datalakedr.converter;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import java.util.Optional;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class GrpcStatusResponseToDatalakeDrStatusResponseConverter {\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.BackupDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())\n+        );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA=="}, "originalCommit": {"oid": "3a029658a9307869a649df016c313b0874cf621e"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUyODkwNg==", "bodyText": "I agree with you with the internal behavior. Why do we want to report that backup-restore operations are complete even when some of the internal operations are still in progress when it can be reported accurately with a simple check?", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489528906", "createdAt": "2020-09-16T15:29:12Z", "author": {"login": "kkalvagadda1"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package com.sequenceiq.cloudbreak.datalakedr.converter;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import java.util.Optional;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class GrpcStatusResponseToDatalakeDrStatusResponseConverter {\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.BackupDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())\n+        );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA=="}, "originalCommit": {"oid": "3a029658a9307869a649df016c313b0874cf621e"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUzNDM3Mw==", "bodyText": "It's not a question of reporting, it's a question of blocking other flows. If the Solr backup has failed, but the HBase backup is still ongoing, do we want to block other datalake flows until the HBase backup is complete? Or do we want to say that the overall backup has failed, so don't bother waiting for the HBase part to finish and go ahead and unblock the other flows?", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489534373", "createdAt": "2020-09-16T15:36:36Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package com.sequenceiq.cloudbreak.datalakedr.converter;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import java.util.Optional;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class GrpcStatusResponseToDatalakeDrStatusResponseConverter {\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.BackupDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())\n+        );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA=="}, "originalCommit": {"oid": "3a029658a9307869a649df016c313b0874cf621e"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQyNjk1MA==", "bodyText": "I'm resolving this conversation because it is likely going to be rendered a moot point but an upcoming change in the datalake-dr service.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r490426950", "createdAt": "2020-09-17T17:15:18Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package com.sequenceiq.cloudbreak.datalakedr.converter;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import java.util.Optional;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class GrpcStatusResponseToDatalakeDrStatusResponseConverter {\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.BackupDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())\n+        );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA=="}, "originalCommit": {"oid": "3a029658a9307869a649df016c313b0874cf621e"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2Mjg2NjU5OnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNTowMToyMlrOHS1MCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNTowMToyMlrOHS1MCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzg0OA==", "bodyText": "we can not depend on just the getOverallState. Here you need to check the internal states as well.\nIf the overall status could be failed but the internal states could be still in progress.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489507848", "createdAt": "2020-09-16T15:01:22Z", "author": {"login": "kkalvagadda1"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package com.sequenceiq.cloudbreak.datalakedr.converter;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import java.util.Optional;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class GrpcStatusResponseToDatalakeDrStatusResponseConverter {\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.BackupDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())\n+        );\n+    }\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.RestoreDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a029658a9307869a649df016c313b0874cf621e"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MzE4MTkzOnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxODo1NDozN1rOHUYbtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxODo1NDozN1rOHUYbtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzMzg3Ng==", "bodyText": "The value should not have : as it will initialize it with an empty string. All these definitions should present in the application.yamls instead.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491133876", "createdAt": "2020-09-18T18:54:37Z", "author": {"login": "keyki"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9aef76d8f484676a00909f5efa7a5e61784bb83f"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MzE5MDM2OnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxODo1NzoyN1rOHUYg-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQyMDo0MjoyNVrOHUbTUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNTIyNQ==", "bodyText": "Does this mean that the application won't start if we're not configuring this endpoint? If that's the case we will need to introduce the datalake dr application in our dev Kubernetes cluster as well along with the local CBD. I would rather create another endpoint to enable/disable this feature so it's not a hard dependency. If it's just not configured then we're skipping some of steps that you do as part of this PR. We do similar things with Cluster Proxy, Public Endpoint Management service and with other external services as well.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491135225", "createdAt": "2020-09-18T18:57:27Z", "author": {"login": "keyki"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")\n+    private String endpoint;\n+\n+    private String host;\n+\n+    private int port;\n+\n+    @PostConstruct\n+    public void init() {\n+        if (isConfigured()) {\n+            String[] parts = endpoint.split(\":\");\n+            if (parts.length < 1 || parts.length > 2) {\n+                throw new IllegalArgumentException(\"altus.datalakedr.endpoint must be in host or host:port format.\");\n+            }\n+            host = parts[0];\n+            port = parts.length == 2\n+                ? Integer.parseInt(parts[1])\n+                : DEFAULT_DATALAKE_DR_PORT;\n+        } else {\n+            throw new IllegalStateException(\"altus.datalakedr.endpoint is not configured\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9aef76d8f484676a00909f5efa7a5e61784bb83f"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTE2Nzc0Ng==", "bodyText": "I tried running the CB application and it fails with the endpoint not being set. Probably we should create a datalakedr.enabled variable also with a false default value and safeguard all calls to only make them if it's enabled. As a reference, you can take a look at clusterProxy.enabled var and how it's used.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491167746", "createdAt": "2020-09-18T20:12:04Z", "author": {"login": "keyki"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")\n+    private String endpoint;\n+\n+    private String host;\n+\n+    private int port;\n+\n+    @PostConstruct\n+    public void init() {\n+        if (isConfigured()) {\n+            String[] parts = endpoint.split(\":\");\n+            if (parts.length < 1 || parts.length > 2) {\n+                throw new IllegalArgumentException(\"altus.datalakedr.endpoint must be in host or host:port format.\");\n+            }\n+            host = parts[0];\n+            port = parts.length == 2\n+                ? Integer.parseInt(parts[1])\n+                : DEFAULT_DATALAKE_DR_PORT;\n+        } else {\n+            throw new IllegalStateException(\"altus.datalakedr.endpoint is not configured\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNTIyNQ=="}, "originalCommit": {"oid": "9aef76d8f484676a00909f5efa7a5e61784bb83f"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTE4MDg4MQ==", "bodyText": "I've removed the datalake-dr-connector dependency from core/build.gradle. I've also removed the colon from ${altus.datalakedr.endpoint}, included the default value of an empty string in the datalake application.yml file. Finally, I added a new setting altus.datalakedr.enabled that defaults to false if it's not set, and will prevent DatalakeDrConfig from throwing an exception on init() if it's not enabled. Please let me know if that's working for you.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491180881", "createdAt": "2020-09-18T20:42:25Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")\n+    private String endpoint;\n+\n+    private String host;\n+\n+    private int port;\n+\n+    @PostConstruct\n+    public void init() {\n+        if (isConfigured()) {\n+            String[] parts = endpoint.split(\":\");\n+            if (parts.length < 1 || parts.length > 2) {\n+                throw new IllegalArgumentException(\"altus.datalakedr.endpoint must be in host or host:port format.\");\n+            }\n+            host = parts[0];\n+            port = parts.length == 2\n+                ? Integer.parseInt(parts[1])\n+                : DEFAULT_DATALAKE_DR_PORT;\n+        } else {\n+            throw new IllegalStateException(\"altus.datalakedr.endpoint is not configured\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNTIyNQ=="}, "originalCommit": {"oid": "9aef76d8f484676a00909f5efa7a5e61784bb83f"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3ODIwNTQ1OnYy", "diffSide": "RIGHT", "path": "datalake/src/main/resources/application.yml", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQwODo1NjowOVrOHVGScQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwNzo1ODowOFrOHVuV4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTg4NTE2OQ==", "bodyText": "this port doesn't seem right to me, having the same value as audit", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491885169", "createdAt": "2020-09-21T08:56:09Z", "author": {"login": "lacikaaa"}, "path": "datalake/src/main/resources/application.yml", "diffHunk": "@@ -68,6 +68,8 @@ altus:\n   audit:\n     enabled: true\n     endpoint: localhost:8982\n+  datalakedr:\n+    endpoint: localhost:8982", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686651139f8703f4f723522d9e449ed1752dc6dd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1Mjg3NQ==", "bodyText": "8982 is the service port for all thunderhead services. What exactly is this file used for? I thought I had to add this setting here when I first did the change, but I'm also adding it to the Helm charts in this review., so I'm not sure when this setting is actually going to be used.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r492452875", "createdAt": "2020-09-22T03:12:55Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake/src/main/resources/application.yml", "diffHunk": "@@ -68,6 +68,8 @@ altus:\n   audit:\n     enabled: true\n     endpoint: localhost:8982\n+  datalakedr:\n+    endpoint: localhost:8982", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTg4NTE2OQ=="}, "originalCommit": {"oid": "686651139f8703f4f723522d9e449ed1752dc6dd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUzNTA0NQ==", "bodyText": "so this is usually for default settings, as we try to avoid in code defaults. in case of endpoints, we can say the default is for local development. in that case this looks a good choice, to point this to the mock, but the mock doesn't have any implementation yet.\nso I think we can delete the endpoint line as it doesn't make any difference as the client is disabled and there is nothing which it can call at that port", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r492535045", "createdAt": "2020-09-22T07:47:17Z", "author": {"login": "lacikaaa"}, "path": "datalake/src/main/resources/application.yml", "diffHunk": "@@ -68,6 +68,8 @@ altus:\n   audit:\n     enabled: true\n     endpoint: localhost:8982\n+  datalakedr:\n+    endpoint: localhost:8982", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTg4NTE2OQ=="}, "originalCommit": {"oid": "686651139f8703f4f723522d9e449ed1752dc6dd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjU0MTQwOQ==", "bodyText": "Since we have altus.datalakedr.enabled set to false we don't' need to set any value to it.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r492541409", "createdAt": "2020-09-22T07:58:08Z", "author": {"login": "keyki"}, "path": "datalake/src/main/resources/application.yml", "diffHunk": "@@ -68,6 +68,8 @@ altus:\n   audit:\n     enabled: true\n     endpoint: localhost:8982\n+  datalakedr:\n+    endpoint: localhost:8982", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTg4NTE2OQ=="}, "originalCommit": {"oid": "686651139f8703f4f723522d9e449ed1752dc6dd"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3ODIxNDYzOnYy", "diffSide": "RIGHT", "path": "integration-test/docker-compose_template.yml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQwODo1ODozN1rOHVGX_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwMzowODoyMVrOHVo4NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTg4NjU5MQ==", "bodyText": "you are pointing int tests to the mock, but there is no mock implementation of this service, is there? this could be misleading", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491886591", "createdAt": "2020-09-21T08:58:37Z", "author": {"login": "lacikaaa"}, "path": "integration-test/docker-compose_template.yml", "diffHunk": "@@ -33,6 +33,7 @@ services:\n       - INTEGRATIONTEST_SDX_SERVER=http://dev-gateway\n       - INTEGRATIONTEST_REDBEAMS_SERVER=http://dev-gateway\n       - ALTUS_AUDIT_ENDPOINT=thunderhead-mock\n+      - ALTUS_DATALAKEDR_ENDPOINT=thunderhead-mock", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686651139f8703f4f723522d9e449ed1752dc6dd"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1MTg5Mg==", "bodyText": "Removed these settings.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r492451892", "createdAt": "2020-09-22T03:08:21Z", "author": {"login": "hreeve-cloudera"}, "path": "integration-test/docker-compose_template.yml", "diffHunk": "@@ -33,6 +33,7 @@ services:\n       - INTEGRATIONTEST_SDX_SERVER=http://dev-gateway\n       - INTEGRATIONTEST_REDBEAMS_SERVER=http://dev-gateway\n       - ALTUS_AUDIT_ENDPOINT=thunderhead-mock\n+      - ALTUS_DATALAKEDR_ENDPOINT=thunderhead-mock", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTg4NjU5MQ=="}, "originalCommit": {"oid": "686651139f8703f4f723522d9e449ed1752dc6dd"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA4MjQ1MjI0OnYy", "diffSide": "RIGHT", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwNzo1NzoxNlrOHVuTzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQxNToyNDoxMFrOHV_x3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjU0MDg3Ng==", "bodyText": "Can you please move the default value to application.yaml?", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r492540876", "createdAt": "2020-09-22T07:57:16Z", "author": {"login": "keyki"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,57 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint}\")\n+    private String endpoint;\n+\n+    @Value(\"${altus.datalakedr.enabled:false}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff9b5233efffe9c5b84e4585cac6c48bfc52150"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgyNzEwMg==", "bodyText": "Done.", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r492827102", "createdAt": "2020-09-22T15:24:10Z", "author": {"login": "hreeve-cloudera"}, "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,57 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint}\")\n+    private String endpoint;\n+\n+    @Value(\"${altus.datalakedr.enabled:false}\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjU0MDg3Ng=="}, "originalCommit": {"oid": "bff9b5233efffe9c5b84e4585cac6c48bfc52150"}, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2287, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}