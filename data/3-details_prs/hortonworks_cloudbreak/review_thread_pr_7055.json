{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYyMDgzNDA1", "number": 7055, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNDowMzowMlrODXh65w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNDowMzowMlrODXh65w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1OTk5NTkxOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNDowMzowMlrOFc31XQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNDowMzowMlrOFc31XQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTgxOTIyOQ==", "bodyText": "has this the same logic as getAllFailedInstanceMetadata?", "url": "https://github.com/hortonworks/cloudbreak/pull/7055#discussion_r365819229", "createdAt": "2020-01-13T14:03:02Z", "author": {"login": "horadla23"}, "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "diffHunk": "@@ -0,0 +1,229 @@\n+package com.sequenceiq.cloudbreak.job;\n+\n+import static com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.base.InstanceStatus.SERVICES_UNHEALTHY;\n+import static com.sequenceiq.cloudbreak.cloud.model.AvailabilityZone.availabilityZone;\n+import static com.sequenceiq.cloudbreak.cloud.model.HostName.hostName;\n+import static com.sequenceiq.cloudbreak.cloud.model.Location.location;\n+import static com.sequenceiq.cloudbreak.cloud.model.Region.region;\n+import static java.util.stream.Collectors.toSet;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.inject.Inject;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.quartz.JobExecutionContext;\n+import org.quartz.JobExecutionException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.gs.collections.impl.factory.Sets;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.cloud.context.CloudContext;\n+import com.sequenceiq.cloudbreak.cloud.handler.InstanceStateQuery;\n+import com.sequenceiq.cloudbreak.cloud.model.CloudCredential;\n+import com.sequenceiq.cloudbreak.cloud.model.CloudInstance;\n+import com.sequenceiq.cloudbreak.cloud.model.CloudVmInstanceStatus;\n+import com.sequenceiq.cloudbreak.cloud.model.HostName;\n+import com.sequenceiq.cloudbreak.cloud.model.InstanceStatus;\n+import com.sequenceiq.cloudbreak.cloud.model.Location;\n+import com.sequenceiq.cloudbreak.cluster.api.ClusterApi;\n+import com.sequenceiq.cloudbreak.cluster.status.ClusterStatus;\n+import com.sequenceiq.cloudbreak.cluster.status.ClusterStatusResult;\n+import com.sequenceiq.cloudbreak.common.type.ClusterManagerState;\n+import com.sequenceiq.cloudbreak.converter.spi.CredentialToCloudCredentialConverter;\n+import com.sequenceiq.cloudbreak.converter.spi.InstanceMetaDataToCloudInstanceConverter;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceGroup;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterApiConnectors;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterService;\n+import com.sequenceiq.cloudbreak.service.environment.credential.CredentialConverter;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.service.stack.flow.InstanceSyncState;\n+import com.sequenceiq.cloudbreak.service.stack.flow.StackSyncService;\n+import com.sequenceiq.environment.client.EnvironmentInternalCrnClient;\n+import com.sequenceiq.flow.core.FlowLogService;\n+import com.sequenceiq.statuschecker.job.StatusCheckerJob;\n+\n+@Component\n+public class StackStatusCheckerJob extends StatusCheckerJob {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(StackStatusCheckerJob.class);\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private ClusterApiConnectors clusterApiConnectors;\n+\n+    @Inject\n+    private InstanceMetaDataToCloudInstanceConverter cloudInstanceConverter;\n+\n+    @Inject\n+    private InstanceStateQuery instanceStateQuery;\n+\n+    @Inject\n+    private EnvironmentInternalCrnClient environmentInternalCrnClient;\n+\n+    @Inject\n+    private CredentialConverter credentialConverter;\n+\n+    @Inject\n+    private CredentialToCloudCredentialConverter cloudCredentialConverter;\n+\n+    @Inject\n+    private StackSyncService syncService;\n+\n+    @Inject\n+    private FlowLogService flowLogService;\n+\n+    @Override\n+    protected void executeInternal(JobExecutionContext context) throws JobExecutionException {\n+        if (flowLogService.isOtherFlowRunning(getStackId())) {\n+            LOGGER.debug(\"StackStatusCheckerJob cannot run, because flow is running for stack: {}\", getStackId());\n+            return;\n+        }\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(getStackId());\n+            if (stack.isStackInDeletionOrFailedPhase()) {\n+                LOGGER.debug(\"StackStatusCheckerJob cannot run, stack is being terminated: {}\", getStackId());\n+                return;\n+            }\n+            ClusterApi connector = clusterApiConnectors.getConnector(stack);\n+            try {\n+                if (isClusterManagerRunning(stack, connector)) {\n+                    Map<HostName, ClusterManagerState> hostStatuses = connector.clusterStatusService().getExtendedHostStatuses();\n+                    LOGGER.debug(\"Cluster '{}' state check, cm running, hoststates: {}\", stack.getId(), hostStatuses);\n+                    reportHealthAndSyncInstances(stack, getFailedInstancesInstanceMetadata(stack, hostStatuses),\n+                            getNewHealthyHostNames(stack, hostStatuses), InstanceSyncState.RUNNING);\n+                } else {\n+                    syncInstances(stack, getAllRunningInstanceMetadata(stack), InstanceSyncState.DELETED_ON_PROVIDER_SIDE);\n+                }\n+            } catch (RuntimeException e) {\n+                syncInstances(stack, getAllRunningInstanceMetadata(stack), InstanceSyncState.DELETED_ON_PROVIDER_SIDE);\n+            }\n+        } catch (Exception e) {\n+            LOGGER.info(\"Exception during cluster state check.\", e);\n+        }\n+    }\n+\n+    private void reportHealthAndSyncInstances(Stack stack, Collection<InstanceMetaData> failedInstances,\n+            Set<String> newHealtyHostNames, InstanceSyncState defaultState) {\n+        Set<String> failedNodeNames = failedInstances.stream()\n+                .map(InstanceMetaData::getDiscoveryFQDN)\n+                .collect(toSet());\n+        clusterService.reportHealthChange(stack.getResourceCrn(), failedNodeNames, newHealtyHostNames);\n+        if (failedNodeNames.size() > 0) {\n+            clusterService.updateClusterStatusByStackId(stack.getId(), Status.AMBIGUOUS);\n+        } else if (stack.getCluster().getStatus() == Status.AMBIGUOUS) {\n+            clusterService.updateClusterStatusByStackId(stack.getId(), Status.AVAILABLE);\n+        }\n+        syncInstances(stack, failedInstances, InstanceSyncState.RUNNING);\n+    }\n+\n+    private boolean isClusterManagerRunning(Stack stack, ClusterApi connector) {\n+        return !stack.isStopped() && !queryClusterStatus(connector).getClusterStatus().equals(ClusterStatus.AMBARISERVER_NOT_RUNNING);\n+    }\n+\n+    private void syncInstances(Stack stack, Collection<InstanceMetaData> instanceMetaData, InstanceSyncState defaultState) {\n+        List<CloudVmInstanceStatus> instanceStatuses = queryInstanceStatuses(stack, instanceMetaData);\n+        LOGGER.debug(\"Cluster '{}' state check on provider, instances: {}\", stack.getId(), instanceStatuses);\n+        syncService.autoSync(stack, instanceStatuses, true, defaultState);\n+    }\n+\n+    private ClusterStatusResult queryClusterStatus(ClusterApi connector) {\n+        Optional<Cluster> cluster = clusterService.retrieveClusterByStackIdWithoutAuth(getStackId());\n+        String blueprintName = cluster.isPresent() ? cluster.get().getBlueprint().getStackName() : null;\n+        return connector.clusterStatusService().getStatus(StringUtils.isNotBlank(blueprintName));\n+    }\n+\n+    private Set<String> getNewHealthyHostNames(Stack stack, Map<HostName, ClusterManagerState> hostStatuses) {\n+        Set<String> healthyHosts = hostStatuses.entrySet().stream()\n+                .filter(e -> e.getValue().getClusterManagerStatus() == ClusterManagerState.ClusterManagerStatus.HEALTHY)\n+                .map(Map.Entry::getKey)\n+                .map(HostName::value)\n+                .collect(Collectors.toSet());\n+        Set<String> unhealthyStoredHosts = getAllRunningInstanceMetadata(stack).stream()\n+                .filter(i -> i.getInstanceStatus() == SERVICES_UNHEALTHY)\n+                .map(InstanceMetaData::getDiscoveryFQDN)\n+                .collect(Collectors.toSet());\n+        return Sets.intersect(healthyHosts, unhealthyStoredHosts);\n+    }\n+\n+    private Set<InstanceMetaData> getFailedInstancesInstanceMetadata(Stack stack, Map<HostName, ClusterManagerState> hostStatuses) {\n+        Set<String> failedHosts = hostStatuses.entrySet().stream()\n+                .filter(e -> e.getValue().getClusterManagerStatus() == ClusterManagerState.ClusterManagerStatus.UNHEALTHY)\n+                .map(Map.Entry::getKey)\n+                .map(HostName::value)\n+                .collect(Collectors.toSet());\n+        Set<String> noReportHosts = getAllRunningInstanceMetadata(stack).stream()\n+                .filter(i -> hostStatuses.get(hostName(i.getDiscoveryFQDN())) == null)\n+                .map(InstanceMetaData::getDiscoveryFQDN)\n+                .collect(Collectors.toSet());\n+        return stack.getInstanceMetaDataAsList().stream()\n+                .filter(i -> failedHosts.contains(i.getDiscoveryFQDN()) || noReportHosts.contains(i.getDiscoveryFQDN()))\n+                .collect(Collectors.toSet());\n+    }\n+\n+    private List<InstanceMetaData> getAllRunningInstanceMetadata(Stack stack) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce97670a169638f2731a9b3726a197356527dc2e"}, "originalPosition": 180}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2913, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}