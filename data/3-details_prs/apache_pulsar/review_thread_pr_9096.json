{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQ2OTY1Mjg0", "number": 9096, "reviewThreads": {"totalCount": 74, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzozMDoxMVrOFM5ajw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yM1QxMzozMjoxMVrOFSNsKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDY3OTE5OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzozMDoxMVrOIQ1ibg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzozMDoxMVrOIQ1ibg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNTI5NA==", "bodyText": "Could you please check the format changes related to the .proto? It's better to keep consistent with the current format", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554525294", "createdAt": "2021-01-10T07:30:11Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDY5NzA5OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzo1MTowNVrOIQ1qnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzo1MTowNVrOIQ1qnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzM5MQ==", "bodyText": "Do we need this field in the OffloadSegment? A ledger might be offloaded as multiple segments,  it's better to use the bookkeeperDeleted in the OffloadContext", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527391", "createdAt": "2021-01-10T07:51:05Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDY5NzU5OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzo1MTo1MVrOIQ1q3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzo1MzowMFrOIQ1rMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzQ1Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              optional int64 assignedTs = 5; //epoch millis\n          \n          \n            \n              optional int64 assignedTimestamp = 5; //epoch millis", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527452", "createdAt": "2021-01-10T07:51:51Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 assignedTs = 5; //epoch millis", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzUzNw==", "bodyText": "Please give a meaningful description? epoch millis is confuse here.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527537", "createdAt": "2021-01-10T07:53:00Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 assignedTs = 5; //epoch millis", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzQ1Mg=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDY5ODg4OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzo1MzoyMFrOIQ1rdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzo1MzoyN1rOIQ1rfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzYwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              optional int64 offloadedTs = 6; //epoch millis\n          \n          \n            \n              optional int64 offloadedTimestamp = 6; //epoch millis", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527605", "createdAt": "2021-01-10T07:53:20Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 assignedTs = 5; //epoch millis\n+  optional int64 offloadedTs = 6; //epoch millis", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzYxMg==", "bodyText": "Please give a meaningful description? epoch millis is confuse here.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527612", "createdAt": "2021-01-10T07:53:27Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 assignedTs = 5; //epoch millis\n+  optional int64 offloadedTs = 6; //epoch millis", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzYwNQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcwMzk0OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzo1ODozMVrOIQ1trg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNDoxNjozNFrOIQ_4ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODE3NA==", "bodyText": "Do we need to expose the SegmentInfo here?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554528174", "createdAt": "2021-01-10T07:58:31Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NDgxOQ==", "bodyText": "This should be an interface not a class.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554694819", "createdAt": "2021-01-11T04:16:34Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODE3NA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcwNjk2OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODowMjoxMFrOIQ1vCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwOTowMzo0OFrOIRMgJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODUyMg==", "bodyText": "Is it possible to check the consecutive in the offloader? I think it's more easy to handle in the managedledger.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554528522", "createdAt": "2021-01-10T08:02:10Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        PositionImpl lastOffered();\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                ManagedLedgerException.OffloadNotConsecutiveException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDkwMTU0Mg==", "bodyText": "@codelipenghui managedledger can do a full in-depth check use for ledger information, but managed ledger will also use a naive check(if ledger id equals and entry id is consecutive, then it is consecutive, that's most common case), that can be used to spot bugs when managedledger not work properly.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554901542", "createdAt": "2021-01-11T09:03:48Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        PositionImpl lastOffered();\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                ManagedLedgerException.OffloadNotConsecutiveException;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODUyMg=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcxMDc0OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODowNjozNVrOIQ1w0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNDoxNzo0NFrOIQ_78Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODk3OQ==", "bodyText": "It's better to also add async method for these 3 methods. Usually, we should implement the sync method based on the async method.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554528979", "createdAt": "2021-01-10T08:06:35Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        PositionImpl lastOffered();\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NTY2NQ==", "bodyText": "+1", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554695665", "createdAt": "2021-01-11T04:17:44Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        PositionImpl lastOffered();\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODk3OQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcxMjc1OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODowOTowMlrOIQ1x0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxMzowNDo0OVrOIRUeMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTIzMw==", "bodyText": "Please check the comment of this method, I think here is not correct, The result just return a future for the OffloadHandle, this does not mean that the data has been persisted", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529233", "createdAt": "2021-01-10T08:09:02Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +161,32 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Offload the passed in ledger to longterm storage.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned future completes, the ledger has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMjExNA==", "bodyText": "Comment updated", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555032114", "createdAt": "2021-01-11T13:04:49Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +161,32 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Offload the passed in ledger to longterm storage.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned future completes, the ledger has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTIzMw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcxMzE4OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODowOTo0MFrOIQ1yBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODowOTo0MFrOIQ1yBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTI4NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                interface OffloaderHandle {\n          \n          \n            \n                interface OffloadHandle {", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529284", "createdAt": "2021-01-10T08:09:40Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcxMzc1OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODoxMDoxOVrOIQ1yTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNjo1ODoyMVrOIRejXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw==", "bodyText": "UnsupportedOperationException?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529357", "createdAt": "2021-01-10T08:10:19Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +217,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzNDkyOQ==", "bodyText": "It's the default behavior of the interface, useful when a new implementation only implements a part of the interface but still useful.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555034929", "createdAt": "2021-01-11T13:10:05Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +217,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMjE2MA==", "bodyText": "you should return a CompletableFuture that reports the UnsupportedOperationException\nthe caller of a method that returns a Future does not expect the method to throw exceptions.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555102160", "createdAt": "2021-01-11T14:54:03Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +217,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTE5NzI3Nw==", "bodyText": "Maybe the exception should be UnsupportedOperationException?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555197277", "createdAt": "2021-01-11T16:58:21Z", "author": {"login": "gaoran10"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +217,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcxNTczOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODoxMzoyMlrOIQ1zPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODoxMzoyMlrOIQ1zPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTU5Nw==", "bodyText": "maxOffloadSegmentRolloverTimeInSeconds?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529597", "createdAt": "2021-01-10T08:13:22Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,10 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcxODUwOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODoxNjoyOFrOIQ10hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxMTozNjozNVrOIR9oRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTkyNQ==", "bodyText": "We also need to add the minOffloadSegmentRolloverTimeInSeconds to avoid the segments rollover too often.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529925", "createdAt": "2021-01-10T08:16:28Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,10 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";\n+    public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n+    public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA1MzA4NQ==", "bodyText": "Do you mean segment may become larger than MAX_SEGMENT_SIZE_IN_BYTES if the time it reaches MAX_SEGMENT_SIZE_IN_BYTES is shorter than minOffloadSegmentRolloverTimeInSeconds? If so, maybe we need a REAL_MAX_SEGMENT_SIZE_IN_BYTES to avoid the segment become too big.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555053085", "createdAt": "2021-01-11T13:40:54Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,10 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";\n+    public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n+    public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTkyNQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTcwNjQzNg==", "bodyText": "minOffloadSegmentRolloverTimeInSeconds related implementations added", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555706436", "createdAt": "2021-01-12T11:36:35Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,10 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";\n+    public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n+    public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTkyNQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcyNDU4OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODoyMzo0M1rOIQ13Yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTozMDo1OFrOIWFugw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA==", "bodyText": "Can we reuse the OffloadIndexBlock? In my opinion, we just add some fields at the index header. Shall we need to introduce a new interface here? I think this will introduce more duplicate code", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554530658", "createdAt": "2021-01-10T08:23:43Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMDI5OA==", "bodyText": "+1", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554700298", "createdAt": "2021-01-11T04:24:38Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA2MDExNQ==", "bodyText": "We not only add some fields at the index header but also make the content repeatable, it actually makes every method in the OffloadIndexBlock a bit different from before. If we reuse OffloadIndexBlock, I think the methods of OffloadIndexBlock will be doubled, and we need to use extra checks to make sure users use the right version of a method, I don't think it will make less duplicate code.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555060115", "createdAt": "2021-01-11T13:52:04Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MzI5NQ==", "bodyText": "okay works for me.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557583295", "createdAt": "2021-01-14T17:54:10Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAzMzQxMQ==", "bodyText": "@Renkai, we are talking about the interface, not the implementation. From the OffloadIndexBlock interface, most of the methods are the same as the StreamingOffloadIndexBlock  right?\nAnother unreasonable place is the index block is format concept, Not only streaming offload can use this format right? If we want a new offloaded that offload based on the time window or data size but not streaming offloaded, this new version IndexBlock also can be used?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560033411", "createdAt": "2021-01-19T09:30:58Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcyNTAxOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODoyNDoxMVrOIQ13mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwNzozNDo0NlrOIR08NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDcxMw==", "bodyText": "Please consider reuse the OffloadIndexBlockBuilder", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554530713", "createdAt": "2021-01-10T08:24:11Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.StreamingOffloadIndexBlockBuilderImpl;\n+\n+/**\n+ * Interface for builder of index block used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+@LimitedPrivate\n+public interface StreamingOffloadIndexBlockBuilder {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA2MTE4OQ==", "bodyText": "Reuse builder is OK to me, I will reuse the builder after we decide on the design of OffloadIndexBlock and StreamingOffloadIndexBlock", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555061189", "createdAt": "2021-01-11T13:53:39Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.StreamingOffloadIndexBlockBuilderImpl;\n+\n+/**\n+ * Interface for builder of index block used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+@LimitedPrivate\n+public interface StreamingOffloadIndexBlockBuilder {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDcxMw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTU2NDA4NQ==", "bodyText": "OffloadIndexBlockBuilder and StreamingOffloadIndexBlockBuilder now are using the same implementation\npublic class OffloadIndexBlockBuilderImpl implements OffloadIndexBlockBuilder, StreamingOffloadIndexBlockBuilder", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555564085", "createdAt": "2021-01-12T07:34:46Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.StreamingOffloadIndexBlockBuilderImpl;\n+\n+/**\n+ * Interface for builder of index block used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+@LimitedPrivate\n+public interface StreamingOffloadIndexBlockBuilder {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDcxMw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MDcyNjEzOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODoyNToyM1rOIQ14KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxMzo1NjoxM1rOIRWWHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDg1Nw==", "bodyText": "Why change it to getFirstEntryId? The index always point to one entryId right?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554530857", "createdAt": "2021-01-10T08:25:23Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java", "diffHunk": "@@ -33,7 +33,7 @@\n     /**\n      * Get the entryId that this entry contains.\n      */\n-    long getEntryId();\n+    long getFirstEntryId();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA2MjgxMw==", "bodyText": "No, the index point to a block, I think the former name has some misleading.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555062813", "createdAt": "2021-01-11T13:56:13Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java", "diffHunk": "@@ -33,7 +33,7 @@\n     /**\n      * Get the entryId that this entry contains.\n      */\n-    long getEntryId();\n+    long getFirstEntryId();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDg1Nw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MjAwMjE5OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNDoxNzowMlrOIQ_6Jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxMzo1OToyNlrOIRWeSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NTIwNw==", "bodyText": "Same question as above. Can we make it an interface?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554695207", "createdAt": "2021-01-11T04:17:02Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA2NDkwNA==", "bodyText": "It's a data object like a POJO or Java Bean, I don't see the benefit to make it an interface.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555064904", "createdAt": "2021-01-11T13:59:26Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NTIwNw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MjAxNjA0OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNDoyMDozNVrOIRADZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDoxNjo0OFrOIRXJjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ==", "bodyText": "Can you explain why do we need this method? Also, add a comment to this method?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554697575", "createdAt": "2021-01-11T04:20:35Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -594,4 +593,6 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    CompletableFuture<LedgerMetadata> getRawLedgerMetadata(long ledgerId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5OTA5Mw==", "bodyText": "I would like to see if we can avoid adding LedgerMetadata here. Because LedgerMetadata is a specific interface for bookkeeper. We should avoid binding the metadata format to bookkeeper's ledger metadata. This would simplify tiered storage integration.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554699093", "createdAt": "2021-01-11T04:22:54Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -594,4 +593,6 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    CompletableFuture<LedgerMetadata> getRawLedgerMetadata(long ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDgxMzE2MA==", "bodyText": "We use LedgerMetadata because we need to use tiered storage to implement a org.apache.bookkeeper.client.api.ReadHandle, which is also a specific interface for bookkeeper, I think it's not avoidable.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554813160", "createdAt": "2021-01-11T06:59:51Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -594,4 +593,6 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    CompletableFuture<LedgerMetadata> getRawLedgerMetadata(long ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA3MzE4Mg==", "bodyText": "Can you explain why do we need this method? Also, add a comment to this method?\n\nFormer offloader get a ReadHandle from ManagedLedger, and get LedgerMetadata from ReadHandle, our new offloader does not hold any ReadHandle but it still needs LedgerMetadata to make the block index", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555073182", "createdAt": "2021-01-11T14:12:42Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -594,4 +593,6 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    CompletableFuture<LedgerMetadata> getRawLedgerMetadata(long ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA3NTk4Mw==", "bodyText": "Actually, I want to name this method to getLedgerMetadata, but a method with this name already exists \n  \n    \n      pulsar/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n    \n    \n         Line 1685\n      in\n      138390c\n    \n    \n    \n    \n\n        \n          \n           public CompletableFuture<String> getLedgerMetadata(long ledgerId) { \n        \n    \n  \n\n\nMaybe it's better to name the existing method getLedgerMetadataStr", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555075983", "createdAt": "2021-01-11T14:16:48Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -594,4 +593,6 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    CompletableFuture<LedgerMetadata> getRawLedgerMetadata(long ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MjA0MjcyOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/test/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloaderBase.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNDoyNjo1NlrOIRAU1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxODowMjo0NVrOITwgcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMjAzOA==", "bodyText": "Can you explain why do you add a \"Mock\" method in the actual implementation?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554702038", "createdAt": "2021-01-11T04:26:56Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/test/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloaderBase.java", "diffHunk": "@@ -82,7 +71,11 @@ protected static MockZooKeeper createMockZooKeeper() throws Exception {\n                 CreateMode.PERSISTENT);\n         return zk;\n     }\n-    \n+\n+    protected static MockManagedLedger createMockManagedLedger() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA3OTM3Mg==", "bodyText": "BlobStoreManagedLedgerOffloaderBase is a class for test, not implementation. Its name doesn't like a test class, but you can see its directory src/test/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloaderBase.java is a test directory.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555079372", "createdAt": "2021-01-11T14:21:57Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/test/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloaderBase.java", "diffHunk": "@@ -82,7 +71,11 @@ protected static MockZooKeeper createMockZooKeeper() throws Exception {\n                 CreateMode.PERSISTENT);\n         return zk;\n     }\n-    \n+\n+    protected static MockManagedLedger createMockManagedLedger() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMjAzOA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4ODU5Mg==", "bodyText": "Make sense now.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557588592", "createdAt": "2021-01-14T18:02:45Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/test/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloaderBase.java", "diffHunk": "@@ -82,7 +71,11 @@ protected static MockZooKeeper createMockZooKeeper() throws Exception {\n                 CreateMode.PERSISTENT);\n         return zk;\n     }\n-    \n+\n+    protected static MockManagedLedger createMockManagedLedger() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMjAzOA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDU1MzczOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1MTo1OFrOIRYqEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1MTo1OFrOIRYqEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMDY4OA==", "bodyText": "typo: uid", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555100688", "createdAt": "2021-01-11T14:51:58Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDU1NzQ3OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1Mjo1NFrOIRYsfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwOTo0Mjo1MlrOISnMOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ==", "bodyText": "what happens if I call this method for the same ManagedLedger more times, with overlapping intervals ?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555101311", "createdAt": "2021-01-11T14:52:54Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * a uid in the metadata, it will attempt to cleanup this attempt with a call\n+     * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n+     * the managed ledger will update its metadata again, to record the completion,\n+     * ensuring that subsequent calls will not attempt to offload the same ledger\n+     * again.\n+     *\n+     * @return an OffloaderHandle, which when `completeFuture()` completed, denotes that the offload has been successful.\n+     */\n+    default CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                              long beginEntry,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjIxNTA3NA==", "bodyText": "what happens if I call this method for the same ManagedLedger more times, with overlapping intervals?\n\nYes, the caller should prevent this happens.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556215074", "createdAt": "2021-01-13T02:02:51Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * a uid in the metadata, it will attempt to cleanup this attempt with a call\n+     * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n+     * the managed ledger will update its metadata again, to record the completion,\n+     * ensuring that subsequent calls will not attempt to offload the same ledger\n+     * again.\n+     *\n+     * @return an OffloaderHandle, which when `completeFuture()` completed, denotes that the offload has been successful.\n+     */\n+    default CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                              long beginEntry,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMzNzEzNg==", "bodyText": "if the caller invokes this method with overlapping intervals, will the system be in a corrupted state ?\nis there any way to detect the problem and fail ?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556337136", "createdAt": "2021-01-13T08:20:48Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * a uid in the metadata, it will attempt to cleanup this attempt with a call\n+     * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n+     * the managed ledger will update its metadata again, to record the completion,\n+     * ensuring that subsequent calls will not attempt to offload the same ledger\n+     * again.\n+     *\n+     * @return an OffloaderHandle, which when `completeFuture()` completed, denotes that the offload has been successful.\n+     */\n+    default CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                              long beginEntry,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjM2ODk4NQ==", "bodyText": "ManagedLedger will check the begin entry and endEntryId in https://github.com/apache/pulsar/wiki/PIP-76:-Streaming-Offload#metadata-changes to avoid corruption, it's not included in this PR yet because it will make the PR too big and include too many details. This PR focused on the interface change of Offloader, I will submit another PR with corruption detection you mentioned.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556368985", "createdAt": "2021-01-13T09:14:08Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * a uid in the metadata, it will attempt to cleanup this attempt with a call\n+     * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n+     * the managed ledger will update its metadata again, to record the completion,\n+     * ensuring that subsequent calls will not attempt to offload the same ledger\n+     * again.\n+     *\n+     * @return an OffloaderHandle, which when `completeFuture()` completed, denotes that the offload has been successful.\n+     */\n+    default CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                              long beginEntry,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjM4NzM4Ng==", "bodyText": "works for me, thanks", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556387386", "createdAt": "2021-01-13T09:42:52Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * a uid in the metadata, it will attempt to cleanup this attempt with a call\n+     * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n+     * the managed ledger will update its metadata again, to record the completion,\n+     * ensuring that subsequent calls will not attempt to offload the same ledger\n+     * again.\n+     *\n+     * @return an OffloaderHandle, which when `completeFuture()` completed, denotes that the offload has been successful.\n+     */\n+    default CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                              long beginEntry,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDU2Mzc3OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1NDowOVrOIRYwHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1NDowOVrOIRYwHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMjIzNg==", "bodyText": "the same here", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555102236", "createdAt": "2021-01-11T14:54:09Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +239,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();\n+    }\n+\n+    default CompletableFuture<Void> deleteOffloaded(UUID uid,\n+                                                    Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedOperationException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDU3ODU1OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1NzoxMVrOIRY4_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwOTo0Mjo0NlrOISnMBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA==", "bodyText": "should not we perform this operation only after the end of the loop above ?\nwhat happens if the streamingOffloadLoop does not complete in time ?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555104508", "createdAt": "2021-01-11T14:57:11Z", "author": {"login": "eolivelli"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjIxNzE2OA==", "bodyText": "should not we perform this operation only after the end of the loop above ?\nwhat happens if the streamingOffloadLoop does not complete in time ?\n\nWhat's 'this operation' do you mean here?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556217168", "createdAt": "2021-01-13T02:09:34Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMzNjEyNw==", "bodyText": "closeSegment", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556336127", "createdAt": "2021-01-13T08:18:54Z", "author": {"login": "eolivelli"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjM2NTMwNA==", "bodyText": "The segment will be closed when the time limit reached, and the streamingOffloadLoop will aware of it and stop looping.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556365304", "createdAt": "2021-01-13T09:08:17Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjM4NzMzMw==", "bodyText": "ok, thanks for your clarification", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556387333", "createdAt": "2021-01-13T09:42:46Z", "author": {"login": "eolivelli"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDU3OTc1OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1NzoyNlrOIRY5qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTo0NToyNlrOIWGWOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDY4Mw==", "bodyText": "we can provide more information here", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555104683", "createdAt": "2021-01-11T14:57:26Z", "author": {"login": "eolivelli"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                    OffloadNotConsecutiveException {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getRawLedgerMetadata(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MzU3Nw==", "bodyText": "+1", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560043577", "createdAt": "2021-01-19T09:45:26Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                    OffloadNotConsecutiveException {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getRawLedgerMetadata(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDY4Mw=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 185}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDU4NDU3OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1ODoyOFrOIRY8nw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1ODoyOFrOIRY8nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNTQzOQ==", "bodyText": "nit: static ?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555105439", "createdAt": "2021-01-11T14:58:28Z", "author": {"login": "eolivelli"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                    OffloadNotConsecutiveException {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getRawLedgerMetadata(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.build();\n+                final StreamingOffloadIndexBlock.IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+        } else {\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+            OffloadNotConsecutiveException {\n+        if (segmentInfo.isClosed()) {\n+            throw new OffloadSegmentClosedException(\"Segment already closed \" + segmentInfo);\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition, entry.getPosition())) {\n+                throw new OffloadNotConsecutiveException(\n+                        Strings.lenientFormat(\"position %s and %s are not consecutive\", lastOfferedPosition,\n+                                entry.getPosition()));\n+            }\n+            entry.retain();\n+            offloadBuffer.add(entry);\n+            bufferLength.getAndAdd(entry.getLength());\n+            segmentLength.getAndAdd(entry.getLength());\n+            lastOfferedPosition = entry.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength) {\n+                closeSegment();\n+            }\n+            return true;\n+        }\n+    }\n+\n+    private synchronized void closeSegment() {\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+    }\n+\n+    private boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 251}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NTI0MTEwOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNzoxNjoyOFrOIRfUPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDo0NDoyNFrOIRs_qQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIwOTc4OQ==", "bodyText": "The indent could be consistent with others.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555209789", "createdAt": "2021-01-11T17:16:28Z", "author": {"login": "gaoran10"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -32,12 +32,23 @@ message OffloadDriverMetadata {\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional int64 assignedTimestamp = 5; //timestamp in millisecond\n+  optional int64 offloadedTimestamp = 6; //timestamp in millisecond\n+  optional int64 endEntryId = 7;\n+  optional OffloadDriverMetadata driverMetadata = 8;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzMzg5Nw==", "bodyText": "But others are not consistent with each other, some use 4 spaces, some use 2 spaces", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555433897", "createdAt": "2021-01-12T00:44:24Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -32,12 +32,23 @@ message OffloadDriverMetadata {\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional int64 assignedTimestamp = 5; //timestamp in millisecond\n+  optional int64 offloadedTimestamp = 6; //timestamp in millisecond\n+  optional int64 endEntryId = 7;\n+  optional OffloadDriverMetadata driverMetadata = 8;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIwOTc4OQ=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NTI0NzM3OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNzoxNzo1N1rOIRfYEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNzoxNzo1N1rOIRfYEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIxMDc2OQ==", "bodyText": "The filed number is not continuous.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555210769", "createdAt": "2021-01-11T17:17:57Z", "author": {"login": "gaoran10"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -32,12 +32,23 @@ message OffloadDriverMetadata {\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional int64 assignedTimestamp = 5; //timestamp in millisecond", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NTMwMTY1OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNzozMDozN1rOIRf4XA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDo0MjoxNFrOIRs86Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIxOTAzNg==", "bodyText": "Does one StreamingOffloadIndexBlock will contain multiple ledgers indexes?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555219036", "createdAt": "2021-01-11T17:30:37Z", "author": {"login": "gaoran10"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {\n+\n+    /**\n+     * Get the content of the index block as InputStream.\n+     * Read out in format:\n+     *   | index_magic_header | index_block_len | index_entry_count |\n+     *   | data_object_size | segment_metadata_length | segment metadata | index entries ... |\n+     */\n+    IndexInputStream toStream() throws IOException;\n+\n+    /**\n+     * Get the related OffloadIndexEntry that contains the given messageEntryId.\n+     *\n+     * @param messageEntryId\n+     *                      the entry id of message\n+     * @return the offload index entry\n+     */\n+    OffloadIndexEntry getIndexEntryForEntry(long ledgerId, long messageEntryId) throws IOException;\n+\n+    public long getStartEntryId(long ledgerId);\n+\n+    /**\n+     * Get the entry count that contained in this index Block.\n+     */\n+    int getEntryCount();\n+\n+    /**\n+     * Get LedgerMetadata.\n+     */\n+    Map<Long, LedgerMetadata> getLedgerMetadata();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzMzE5Mw==", "bodyText": "Yes", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555433193", "createdAt": "2021-01-12T00:42:14Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {\n+\n+    /**\n+     * Get the content of the index block as InputStream.\n+     * Read out in format:\n+     *   | index_magic_header | index_block_len | index_entry_count |\n+     *   | data_object_size | segment_metadata_length | segment metadata | index entries ... |\n+     */\n+    IndexInputStream toStream() throws IOException;\n+\n+    /**\n+     * Get the related OffloadIndexEntry that contains the given messageEntryId.\n+     *\n+     * @param messageEntryId\n+     *                      the entry id of message\n+     * @return the offload index entry\n+     */\n+    OffloadIndexEntry getIndexEntryForEntry(long ledgerId, long messageEntryId) throws IOException;\n+\n+    public long getStartEntryId(long ledgerId);\n+\n+    /**\n+     * Get the entry count that contained in this index Block.\n+     */\n+    int getEntryCount();\n+\n+    /**\n+     * Get LedgerMetadata.\n+     */\n+    Map<Long, LedgerMetadata> getLedgerMetadata();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIxOTAzNg=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDQzMjExOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo0NDo1MVrOITv1mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo0NDo1MVrOITv1mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3NzYyNw==", "bodyText": "Can you move the implementation outside of an interface?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557577627", "createdAt": "2021-01-14T17:44:51Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDQzNTAyOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo0NTozNFrOITv3Xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwNzoxODo1N1rOIUFvCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODA3OQ==", "bodyText": "What does \"create one per second\" mean?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557578079", "createdAt": "2021-01-14T17:45:34Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzkzNjM5Mg==", "bodyText": "'per segment' typo fixed", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557936392", "createdAt": "2021-01-15T07:18:57Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODA3OQ=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDQzOTE1OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo0NjozMlrOITv53Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODoyNDo1OVrOIWDFmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODcxNw==", "bodyText": "It is a bit strange to implement an async method over a sync method. We usually implement the other way around.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557578717", "createdAt": "2021-01-14T17:46:32Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzkzOTYxNw==", "bodyText": "Our current sync method implementation is quite efficient (just compare two existing number and return), though a bit strange, I still don't think we should sacrifice the performance to make the implementation conform common practice.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557939617", "createdAt": "2021-01-15T07:22:45Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODcxNw=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MDE3MA==", "bodyText": "You can't assume the canOffer always \"efficient\", it depends on the implementations. From the interface perspective, this is not the right way.\nuse default for the interface method, this means it's not required for the implementation to implement this method, so an implementation can only implement the sync method. If the sync method need some time-consuming operations, This destroys the original intention of the interface", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559990170", "createdAt": "2021-01-19T08:24:59Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODcxNw=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDQ0MjUzOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo0NzoyNFrOITv75g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo0NzoyNFrOITv75g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3OTIzOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n          \n          \n            \n                 * longterm storage, so it is safe to delete the original copy in bookkeeper.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557579238", "createdAt": "2021-01-14T17:47:24Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDQ1NzQ2OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo1MTowN1rOITwE-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo1MTowN1rOITwE-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MTU2MA==", "bodyText": "If this interface is designed to be an async method, the exception should be returned from the CompletableFuture. The interface seems to be mix async semantic with sync semantic together.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557581560", "createdAt": "2021-01-14T17:51:07Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -595,4 +594,10 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    /**\n+     * Get basic ledger summary after the ledger is closed.\n+     * will got exception if corresponding ledger was not closed when the method called.\n+     */\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDQ2NDkzOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo1MzoyMFrOITwJ0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwNjo1MzozM1rOIUEdrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MjgwMQ==", "bodyText": "What happens if the ledger is closed with zero entries?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557582801", "createdAt": "2021-01-14T17:53:20Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1686,20 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException {\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n+        if (ledgerInfo == null) {\n+            throw new ManagedLedgerException(\n+                    Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n+        } else if (ledgerInfo.getSize() == 0 || ledgerInfo.getEntries() == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzkxNTU2Nw==", "bodyText": "What happens if the ledger is closed with zero entries?\n\nIt will be deleted from metadata, see \n  \n    \n      pulsar/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n    \n    \n        Lines 1535 to 1547\n      in\n      d3a6a8c\n    \n    \n    \n    \n\n        \n          \n           if (entriesInLedger > 0) { \n        \n\n        \n          \n               LedgerInfo info = LedgerInfo.newBuilder().setLedgerId(lh.getId()).setEntries(entriesInLedger) \n        \n\n        \n          \n                       .setSize(lh.getLength()).setTimestamp(clock.millis()).build(); \n        \n\n        \n          \n               ledgers.put(lh.getId(), info); \n        \n\n        \n          \n           } else { \n        \n\n        \n          \n               // The last ledger was empty, so we can discard it \n        \n\n        \n          \n               ledgers.remove(lh.getId()); \n        \n\n        \n          \n               mbean.startDataLedgerDeleteOp(); \n        \n\n        \n          \n               bookKeeper.asyncDeleteLedger(lh.getId(), (rc, ctx) -> { \n        \n\n        \n          \n                   mbean.endDataLedgerDeleteOp(); \n        \n\n        \n          \n                   log.info(\"[{}] Delete complete for empty ledger {}. rc={}\", name, lh.getId(), rc); \n        \n\n        \n          \n               }, null); \n        \n\n        \n          \n           }", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557915567", "createdAt": "2021-01-15T06:53:33Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1686,20 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException {\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n+        if (ledgerInfo == null) {\n+            throw new ManagedLedgerException(\n+                    Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n+        } else if (ledgerInfo.getSize() == 0 || ledgerInfo.getEntries() == 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MjgwMQ=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDQ3MjA5OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo1NToyNlrOITwOcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo1NToyNlrOITwOcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4Mzk4Ng==", "bodyText": "Can we move implementation out of this interface?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557583986", "createdAt": "2021-01-14T17:55:26Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {\n+\n+    /**\n+     * Get the content of the index block as InputStream.\n+     * Read out in format:\n+     *   | index_magic_header | index_block_len | index_entry_count |\n+     *   | data_object_size | segment_metadata_length | segment metadata | index entries ... |\n+     */\n+    IndexInputStream toStream() throws IOException;\n+\n+    /**\n+     * Get the related OffloadIndexEntry that contains the given messageEntryId.\n+     *\n+     * @param messageEntryId\n+     *                      the entry id of message\n+     * @return the offload index entry\n+     */\n+    OffloadIndexEntry getIndexEntryForEntry(long ledgerId, long messageEntryId) throws IOException;\n+\n+    public long getStartEntryId(long ledgerId);\n+\n+    /**\n+     * Get the entry count that contained in this index Block.\n+     */\n+    int getEntryCount();\n+\n+    /**\n+     * Get LedgerMetadata.\n+     * @return\n+     */\n+    LedgerMetadata getLedgerMetadata(long ledgerId);\n+\n+    /**\n+     * Get the total size of the data object.\n+     */\n+    long getDataObjectLength();\n+\n+    /**\n+     * Get the length of the header in the blocks in the data object.\n+     */\n+    long getDataBlockHeaderLength();\n+\n+    /**\n+     * An input stream which knows the size of the stream upfront.\n+     */\n+    class IndexInputStream extends FilterInputStream {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDQ4MjE5OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo1Nzo1OVrOITwUkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwODozNDo0N1rOIUL92A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA==", "bodyText": "Put log.debug into if (log.isDebugEnabled()) { ... }", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557585554", "createdAt": "2021-01-14T17:57:59Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NjQyOA==", "bodyText": "Please address all the occurrences.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557586428", "createdAt": "2021-01-14T17:59:21Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODAxMDM0NQ==", "bodyText": "@sijie I don't think put log.debug into if (log.isDebugEnabled()) { ... } is a good practice today. It was originally designed to reduce string construction cost in log4j1, but today every log framework implemented slf4j provided a lazy formatter to prevent string construction when debug is not enabled. It can not only reduce boilerplate code and avoid check the log level twice.\nif (log.isDebugEnabled()) { ... } should only happened when we have extra computation for debug.\nSee\nhttps://logging.apache.org/log4j/2.x/manual/api.html (Section: Substituting Parameters)\nhttps://logging.apache.org/log4j/log4j-2.3/performance.html", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r558010345", "createdAt": "2021-01-15T08:15:38Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODAzODQ4OA==", "bodyText": "@Renkai that would be a very long discussion, thanks for bringing it up!\nin my opinion it is better to have a consistent way of using the logger thru all of the codebase.\nif we want to change this pattern please start a new discussion, and so we can start a new set of patches.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r558038488", "createdAt": "2021-01-15T08:34:47Z", "author": {"login": "eolivelli"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDQ5ODUwOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxODowMjowN1rOITwfGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxODowMjowN1rOITwfGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4ODI0OA==", "bodyText": "Can you rename it to maxOffloadSegmentSizeInBytes?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557588248", "createdAt": "2021-01-14T18:02:07Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,12 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"maxOffloadSegmentRolloverTimeInSeconds\";\n+    public static final String MIN_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"minOffloadSegmentRolloverTimeInSeconds\";\n+    public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final long DEFAULT_MIN_SEGMENT_TIME_IN_SECOND = 0;\n+    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMTI3NjkwOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQyMTozNTo0NVrOIT4JAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQyMTozNTo0NVrOIT4JAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxMzY2NA==", "bodyText": "Should this be info or debug?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557713664", "createdAt": "2021-01-14T21:35:45Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());\n+            return promise;\n+        }\n+        executor.submit(() -> {\n+            List<LedgerEntry> entries = new ArrayList<LedgerEntry>();\n+            List<GroupedReader> groupedReaders = null;\n+            try {\n+                groupedReaders = getGroupedReader(firstEntry, lastEntry);\n+            } catch (Exception e) {\n+                promise.completeExceptionally(e);\n+                return;\n+            }\n+\n+            for (GroupedReader groupedReader : groupedReaders) {\n+                long entriesToRead = (groupedReader.lastEntry - groupedReader.firstEntry) + 1;\n+                long nextExpectedId = groupedReader.firstEntry;\n+                try {\n+                    while (entriesToRead > 0) {\n+                        int length = groupedReader.dataStream.readInt();\n+                        if (length < 0) { // hit padding or new block\n+                            groupedReader.inputStream\n+                                    .seek(groupedReader.index\n+                                            .getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                            .getDataOffset());\n+                            continue;\n+                        }\n+                        long entryId = groupedReader.dataStream.readLong();\n+\n+                        if (entryId == nextExpectedId) {\n+                            ByteBuf buf = PulsarByteBufAllocator.DEFAULT.buffer(length, length);\n+                            entries.add(LedgerEntryImpl.create(ledgerId, entryId, length, buf));\n+                            int toWrite = length;\n+                            while (toWrite > 0) {\n+                                toWrite -= buf.writeBytes(groupedReader.dataStream, toWrite);\n+                            }\n+                            entriesToRead--;\n+                            nextExpectedId++;\n+                        } else if (entryId > nextExpectedId) {\n+                            groupedReader.inputStream\n+                                    .seek(groupedReader.index\n+                                            .getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                            .getDataOffset());\n+                            continue;\n+                        } else if (entryId < nextExpectedId\n+                                && !groupedReader.index.getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                .equals(\n+                                        groupedReader.index.getIndexEntryForEntry(groupedReader.ledgerId, entryId))) {\n+                            groupedReader.inputStream\n+                                    .seek(groupedReader.index\n+                                            .getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                            .getDataOffset());\n+                            continue;\n+                        } else if (entryId > groupedReader.lastEntry) {\n+                            log.info(\"Expected to read {}, but read {}, which is greater than last entry {}\",\n+                                    nextExpectedId, entryId, groupedReader.lastEntry);\n+                            throw new BKException.BKUnexpectedConditionException();\n+                        } else {\n+                            val skipped = groupedReader.inputStream.skip(length);\n+                            log.info(\"Skipped {} bytes.\", skipped);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 186}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMTI4NzIzOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQyMTozOTowMFrOIT4PcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODoyNjoxNVrOIWDJHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTMxMg==", "bodyText": "PositionImpl is an implementation. Should this be Position?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557715312", "createdAt": "2021-01-14T21:39:00Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzkyMTQ2Ng==", "bodyText": "Position exposes too little methods, I'm not sure if I should add some methods to it.\n\n  \n    \n      pulsar/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/Position.java\n    \n    \n        Lines 29 to 37\n      in\n      3b2c852\n    \n    \n    \n    \n\n        \n          \n           public interface Position { \n        \n\n        \n          \n               /** \n        \n\n        \n          \n                * Get the position of the entry next to this one. The returned position might point to a non-existing, or not-yet \n        \n\n        \n          \n                * existing entry \n        \n\n        \n          \n                * \n        \n\n        \n          \n                * @return the position of the next logical entry \n        \n\n        \n          \n                */ \n        \n\n        \n          \n               Position getNext(); \n        \n\n        \n          \n           }", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557921466", "createdAt": "2021-01-15T07:00:58Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTMxMg=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MTA3MQ==", "bodyText": "From the interface perspective, we should use Position", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559991071", "createdAt": "2021-01-19T08:26:15Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTMxMg=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMTI5MTE2OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQyMTo0MDoxNlrOIT4R4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQyMTo0MDoxNlrOIT4R4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTkzNg==", "bodyText": "Should this be EntryImpl or Entry?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557715936", "createdAt": "2021-01-14T21:40:16Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMTI5ODA2OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQyMTo0MjozNFrOIT4WRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwOToxNzozNVrOIUP_FQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNzA2MA==", "bodyText": "Don't we need a close method to seal the offloaded segment?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557717060", "createdAt": "2021-01-14T21:42:34Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODEwNDM0MQ==", "bodyText": "close method added", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r558104341", "createdAt": "2021-01-15T09:17:35Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNzA2MA=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjEzMjA5OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODoxNjoxMVrOIWCyNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODoxNjoxMVrOIWCyNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk4NTIwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    default CompletableFuture<Boolean> asyncCanOffer(long size) {\n          \n          \n            \n                    default CompletableFuture<Boolean> canOfferAsync(long size) {", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559985205", "createdAt": "2021-01-19T08:16:11Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjE4NjEzOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODozMDowOFrOIWDSIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODozMDowOFrOIWDSIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MzM3OA==", "bodyText": "same as the above comment, you can remove the default implementation from the interface.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559993378", "createdAt": "2021-01-19T08:30:08Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjE4NzE1OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODozMDoyMlrOIWDSqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODozMDoyMlrOIWDSqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MzUxNQ==", "bodyText": "Same as above comment.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559993515", "createdAt": "2021-01-19T08:30:22Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n+\n+        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n+            return CompletableFuture.completedFuture(offerEntry(entry));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjE4ODA5OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODozMDo0M1rOIWDTXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODozMDo0M1rOIWDTXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MzY5Mw==", "bodyText": "Same as the above comment", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559993693", "createdAt": "2021-01-19T08:30:43Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n+\n+        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n+            return CompletableFuture.completedFuture(offerEntry(entry));\n+        }\n+\n+        CompletableFuture<OffloadResult> getOffloadResultAsync();\n+\n+        /**\n+         * Manually close current offloading segment\n+         * @return true if the segment is not already closed\n+         */\n+        boolean close();\n+\n+        default CompletableFuture<Boolean> AsyncClose() {\n+            return CompletableFuture.completedFuture(close());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjI1MzA0OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerException.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODo0Njo1N1rOIWD6Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODo0Njo1N1rOIWD6Dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwMzU5OQ==", "bodyText": "Do we need this exception? As I mentioned before, there are some markers in the managed ledger, this will affect the continuity of entry id when offload data to the tiered storage", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560003599", "createdAt": "2021-01-19T08:46:57Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerException.java", "diffHunk": "@@ -151,6 +151,18 @@ public OffloadInProgressException(String msg) {\n         }\n     }\n \n+    public static class OffloadSegmentClosedException extends ManagedLedgerException {\n+        public OffloadSegmentClosedException(String msg) {\n+            super(msg);\n+        }\n+    }\n+\n+    public static class OffloadNotConsecutiveException extends ManagedLedgerException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjI2NjMwOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODo0OTo1MlrOIWEBqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMzoyMDo0MVrOIWOEuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwNTU0NA==", "bodyText": "Is it better to named getLedgerInfo? and does not distinguish whether it is closed. The closed state should contains in the LedgerInfo(Now I think we use the entries=0 to determine the ledger close or not)", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560005544", "createdAt": "2021-01-19T08:49:52Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -595,4 +594,10 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    /**\n+     * Get basic ledger summary after the ledger is closed.\n+     * will got exception if corresponding ledger was not closed when the method called.\n+     */\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE3MDE3MQ==", "bodyText": "Is it better to named getLedgerInfo? and does not distinguish whether it is closed. The closed state should contains in the LedgerInfo(Now I think we use the entries=0 to determine the ledger close or not)\n\nMy design is refuse to return an unclosed result to prevent caller to get an incomplete result in accident.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560170171", "createdAt": "2021-01-19T13:20:41Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -595,4 +594,10 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    /**\n+     * Get basic ledger summary after the ledger is closed.\n+     * will got exception if corresponding ledger was not closed when the method called.\n+     */\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwNTU0NA=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjI5NTUwOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODo1NjoyMFrOIWESpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODo1NjoyMFrOIWESpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwOTg5NQ==", "bodyText": "It's better to define the result as CompletableFuture<Optional>? If use exception, it's better to define a specific exception because we need a way to determine if the exception is ledger not found exception? Use ManagedLedgerException to determine if the ledger is existed or not seem a bit confuse.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560009895", "createdAt": "2021-01-19T08:56:20Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1686,23 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n+        if (ledgerInfo == null) {\n+            final ManagedLedgerException exception = new ManagedLedgerException(\n+                    Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n+            result.completeExceptionally(exception);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjMxODk3OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTowMTo0OVrOIWEgnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTowMTo0OVrOIWEgnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAxMzQ2OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public final long beginLedger;\n          \n          \n            \n                public final long beginLedgerId;\n          \n      \n    \n    \n  \n\nPlease check all.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560013468", "createdAt": "2021-01-19T09:01:49Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.impl;\n+\n+\n+import java.util.Map;\n+import java.util.UUID;\n+import lombok.ToString;\n+import org.apache.bookkeeper.mledger.LedgerOffloader;\n+\n+@ToString\n+public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n+    public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+        this.uuid = uuid;\n+        this.beginLedger = beginLedger;\n+        this.beginEntry = beginEntry;\n+        this.driverName = driverName;\n+        this.driverMetadata = driverMetadata;\n+    }\n+\n+\n+    public final UUID uuid;\n+    public final long beginLedger;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjMyMjUyOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTowMjo0M1rOIWEivQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTowMjo0M1rOIWEivQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAxNDAxMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n          \n          \n            \n            public class OffloadSegmentInfoImpl implements LedgerOffloader.SegmentInfo {", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560014013", "createdAt": "2021-01-19T09:02:43Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.impl;\n+\n+\n+import java.util.Map;\n+import java.util.UUID;\n+import lombok.ToString;\n+import org.apache.bookkeeper.mledger.LedgerOffloader;\n+\n+@ToString\n+public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjM5NTkzOnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOToxOTozMlrOIWFOkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMDozNjoxMlrOIWn8qQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA==", "bodyText": "Is it used for managed ledger or any other component? If it only for offload internal, we don't need to expose it.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560025234", "createdAt": "2021-01-19T09:19:32Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE4OTQxNA==", "bodyText": "Is it used for managed ledger or any other component? If it only for offload internal, we don't need to expose it.\n\nWill be used in managed ledger", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560189414", "createdAt": "2021-01-19T13:51:45Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE4OTc3NQ==", "bodyText": "Is it used for managed ledger or any other component? If it only for offload internal, we don't need to expose it.\n\nWill be used in managed ledger", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560189775", "createdAt": "2021-01-19T13:52:18Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI3OTI2Nw==", "bodyText": "Could you provide more information about how the managed ledger uses this interface? in my opinion, the ledger offloader only create a ledgerHandle then offer entry by the ledgerHandle and get the offload result. And I think the PIP https://github.com/apache/pulsar/wiki/PIP-76%3A-Streaming-Offload also does not mention this interface. Does the offload result can't work here?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560279267", "createdAt": "2021-01-19T15:49:26Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDU5NDA4OQ==", "bodyText": "Could you provide more information about how the managed ledger uses this interface? in my opinion, the ledger offloader only create a ledgerHandle then offer entry by the ledgerHandle and get the offload result. And I think the PIP https://github.com/apache/pulsar/wiki/PIP-76%3A-Streaming-Offload also does not mention this interface. Does the offload result can't work here?\n\nIn my current implementation, the managed ledger will keep a reference of the SegmentInfo, and once the offload got result, it will check if the result is the same with the kept one.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560594089", "createdAt": "2021-01-20T00:36:12Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjQwMzYyOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOToyMToxOVrOIWFTPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMDowOTo1NVrOIWnaIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNjQyOQ==", "bodyText": "Any reason to modify this method?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560026429", "createdAt": "2021-01-19T09:21:19Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java", "diffHunk": "@@ -71,7 +71,7 @@\n     /**\n      * Construct OffloadIndex from an InputStream.\n      */\n-    OffloadIndexBlock fromStream(InputStream is) throws IOException;\n+    OffloadIndexBlock indexFromStream(InputStream is) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE5MjM5OA==", "bodyText": "Because now we have two different method with similar behavior, it's better to have a distinguish\n   @Override\n    public OffloadIndexBlock indexFromStream(InputStream is) throws IOException {\n        return OffloadIndexBlockImpl.get(is);\n    }\n\n    @Override\n    public StreamingOffloadIndexBlock streamingIndexFromStream(InputStream is) throws IOException {\n        return StreamingOffloadIndexBlockImpl.get(is);\n    }", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560192398", "createdAt": "2021-01-19T13:56:05Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java", "diffHunk": "@@ -71,7 +71,7 @@\n     /**\n      * Construct OffloadIndex from an InputStream.\n      */\n-    OffloadIndexBlock fromStream(InputStream is) throws IOException;\n+    OffloadIndexBlock indexFromStream(InputStream is) throws IOException;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNjQyOQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI4MjAyMA==", "bodyText": "Sorry, I can't get the point here. Do you mean the method name will duplicated?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560282020", "createdAt": "2021-01-19T15:53:01Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java", "diffHunk": "@@ -71,7 +71,7 @@\n     /**\n      * Construct OffloadIndex from an InputStream.\n      */\n-    OffloadIndexBlock fromStream(InputStream is) throws IOException;\n+    OffloadIndexBlock indexFromStream(InputStream is) throws IOException;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNjQyOQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDU4NTI0OA==", "bodyText": "Sorry, I can't get the point here. Do you mean the method name will duplicated?\n\nYes", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560585248", "createdAt": "2021-01-20T00:09:55Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java", "diffHunk": "@@ -71,7 +71,7 @@\n     /**\n      * Construct OffloadIndex from an InputStream.\n      */\n-    OffloadIndexBlock fromStream(InputStream is) throws IOException;\n+    OffloadIndexBlock indexFromStream(InputStream is) throws IOException;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNjQyOQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjQ4NjE1OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTozOToxMFrOIWGFGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNToxMDo1NFrOIWS36A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAzOTE5Mw==", "bodyText": "It's not correct here, because might skip all messages of a ledger. As I mentioned before, it's hard to determine the Consecutive at the offloader. And the marker also will affect this behavior in the future.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560039193", "createdAt": "2021-01-19T09:39:10Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n+        if (segmentInfo.isClosed()) {\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n+            }\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength\n+                    && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n+                closeSegment();\n+            }\n+            return OfferEntryResult.SUCCESS;\n+        }\n+    }\n+\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n+    }\n+\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n+                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n+            return true;\n+        } else if (offeringPosition.getEntryId() == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI0ODgwOA==", "bodyText": "consecutive check removed", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560248808", "createdAt": "2021-01-19T15:10:54Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n+        if (segmentInfo.isClosed()) {\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n+            }\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength\n+                    && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n+                closeSegment();\n+            }\n+            return OfferEntryResult.SUCCESS;\n+        }\n+    }\n+\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n+    }\n+\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n+                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n+            return true;\n+        } else if (offeringPosition.getEntryId() == 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAzOTE5Mw=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 293}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjQ5NDEwOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTo0MDo0OVrOIWGJuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNTo1NjoxMVrOIWVDcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MDM3Ng==", "bodyText": "If the segment closed return false, the buffer fills up return false, how to determine at the managed ledger?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560040376", "createdAt": "2021-01-19T09:40:49Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n+        if (segmentInfo.isClosed()) {\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n+            }\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength\n+                    && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n+                closeSegment();\n+            }\n+            return OfferEntryResult.SUCCESS;\n+        }\n+    }\n+\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n+    }\n+\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n+                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n+            return true;\n+        } else if (offeringPosition.getEntryId() == 0) {\n+            return true;\n+        } else {\n+            // lastOfferedPosition not initialized\n+            return lastOfferedPosition.equals(PositionImpl.latest);\n+        }\n+    }\n+\n+    private PositionImpl lastOffered() {\n+        return lastOfferedPosition;\n+    }\n+\n+    private boolean canOffer(long size) {\n+        if (segmentInfo.isClosed()) {\n+            return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI1MDc5Mg==", "bodyText": "My new offerEntry implementation returns an enum with more rich info, so we may no need to call canOffer anymore\n        enum OfferEntryResult {\n            SUCCESS,\n            FAIL_BUFFER_FULL,\n            FAIL_SEGMENT_CLOSED,\n            FAIL_NOT_CONSECUTIVE\n        }", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560250792", "createdAt": "2021-01-19T15:13:29Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n+        if (segmentInfo.isClosed()) {\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n+            }\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength\n+                    && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n+                closeSegment();\n+            }\n+            return OfferEntryResult.SUCCESS;\n+        }\n+    }\n+\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n+    }\n+\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n+                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n+            return true;\n+        } else if (offeringPosition.getEntryId() == 0) {\n+            return true;\n+        } else {\n+            // lastOfferedPosition not initialized\n+            return lastOfferedPosition.equals(PositionImpl.latest);\n+        }\n+    }\n+\n+    private PositionImpl lastOffered() {\n+        return lastOfferedPosition;\n+    }\n+\n+    private boolean canOffer(long size) {\n+        if (segmentInfo.isClosed()) {\n+            return false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MDM3Ng=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI4NDUyOA==", "bodyText": "But canOffer return boolean right? If broker call canOffer it return false here, then the broker need to try to add one more entry to check if the offload segment closed? Is my understanding correct?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560284528", "createdAt": "2021-01-19T15:56:11Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n+        if (segmentInfo.isClosed()) {\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n+            }\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength\n+                    && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n+                closeSegment();\n+            }\n+            return OfferEntryResult.SUCCESS;\n+        }\n+    }\n+\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n+    }\n+\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n+                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n+            return true;\n+        } else if (offeringPosition.getEntryId() == 0) {\n+            return true;\n+        } else {\n+            // lastOfferedPosition not initialized\n+            return lastOfferedPosition.equals(PositionImpl.latest);\n+        }\n+    }\n+\n+    private PositionImpl lastOffered() {\n+        return lastOfferedPosition;\n+    }\n+\n+    private boolean canOffer(long size) {\n+        if (segmentInfo.isClosed()) {\n+            return false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MDM3Ng=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 307}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjUzMTg2OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTo0OToxOVrOIWGhAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwOTo0OToxOVrOIWGhAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0NjMzOA==", "bodyText": "we can provide more information here", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560046338", "createdAt": "2021-01-19T09:49:19Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 219}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjYyODQ2OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDoxMTo1NFrOIWHchw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNFQxNDozMTowMFrOIZNKmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2MTU3NQ==", "bodyText": "StreamingDataBlockHeaderImpl -> DataBlockHeaderImplV2? @Renkai @sijie The header format can be used by different offload implementations, I think coupling with streaming offload is not a good choice.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560061575", "createdAt": "2021-01-19T10:11:54Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.io.CountingInputStream;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufInputStream;\n+import java.io.DataInputStream;\n+import java.io.EOFException;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.DataBlockHeader;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+/**\n+ * The data block header in code storage for each data block.\n+ */\n+public class StreamingDataBlockHeaderImpl implements DataBlockHeader {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE1MzMwMw==", "bodyText": "Have you checked this comment @Renkai?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563153303", "createdAt": "2021-01-23T13:33:35Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.io.CountingInputStream;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufInputStream;\n+import java.io.DataInputStream;\n+import java.io.EOFException;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.DataBlockHeader;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+/**\n+ * The data block header in code storage for each data block.\n+ */\n+public class StreamingDataBlockHeaderImpl implements DataBlockHeader {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2MTU3NQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzMwMTAxNw==", "bodyText": "@codelipenghui It's copied from other source code, I think the original author want to use 'cold storage', which is more commonly called 'tiered storage' now, I have changed the comment to tiered storage", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563301017", "createdAt": "2021-01-24T14:31:00Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.io.CountingInputStream;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufInputStream;\n+import java.io.DataInputStream;\n+import java.io.EOFException;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.DataBlockHeader;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+/**\n+ * The data block header in code storage for each data block.\n+ */\n+public class StreamingDataBlockHeaderImpl implements DataBlockHeader {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2MTU3NQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjY3MzQyOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDoyMjozMVrOIWH3xQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNDowNjo1OFrOIWP20Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2ODU0OQ==", "bodyText": "Is the BufferedOffloadStream need to be close after offload complete? I notice during the offload loop, the BufferedOffloadStream is created for each loop, but can't find where to close it.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560068549", "createdAt": "2021-01-19T10:22:31Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE5OTM3Nw==", "bodyText": "The JCloud API should closed it, original ledger based offloader created a stream without call close, too.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560199377", "createdAt": "2021-01-19T14:06:58Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2ODU0OQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjcxOTk0OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDozNDozMFrOIWIUxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDozNDozMFrOIWIUxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3NTk3Mw==", "bodyText": "final?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560075973", "createdAt": "2021-01-19T10:34:30Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjc1Nzg1OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDo0NDowMlrOIWIsag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNDoyNTowMlrOIWQpcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4MjAyNg==", "bodyText": "Should peek first? If the next entry exceeds the max block size, what the behavior?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560082026", "createdAt": "2021-01-19T10:44:02Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;\n+    int validDataOffset = NOT_INITIALIZED;\n+    CompositeByteBuf currentEntry;\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getBeginEntryId() {\n+        return beginEntryId;\n+    }\n+\n+    public long getBlockSize() {\n+        return blockSize;\n+    }\n+\n+\n+    public BufferedOffloadStream(int blockSize,\n+                                 ConcurrentLinkedQueue<Entry> entryBuffer,\n+                                 SegmentInfoImpl segmentInfo,\n+                                 long ledgerId,\n+                                 long beginEntryId,\n+                                 AtomicLong bufferLength) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.segmentInfo = segmentInfo;\n+        this.entryBuffer = entryBuffer;\n+        this.bufferLength = bufferLength;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n+\n+    @Override\n+    public int read() throws IOException {\n+        if (blockHead.available() > 0) {\n+            offset++;\n+            return blockHead.read();\n+        }\n+        //if current exists, use current first\n+        if (currentEntry != null) {\n+            if (currentEntry.readableBytes() > 0) {\n+                offset += 1;\n+                return currentEntry.readUnsignedByte();\n+            } else {\n+                currentEntry.release();\n+                currentEntry = null;\n+            }\n+        }\n+\n+        if (blockSize <= offset) {\n+            return -1;\n+        } else if (validDataOffset != NOT_INITIALIZED) {\n+            return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n+        }\n+\n+        Entry headEntry;\n+\n+        while ((headEntry = entryBuffer.peek()) == null) {\n+            if (segmentInfo.isClosed()) {\n+                if (validDataOffset == NOT_INITIALIZED) {\n+                    validDataOffset = offset;\n+                }\n+                return read();\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    log.error(\"sleep failed\", e);\n+                }\n+            }\n+        }\n+\n+        //create new block when a ledger end\n+        if (headEntry.getLedgerId() != this.ledgerId) {\n+            if (validDataOffset == NOT_INITIALIZED) {\n+                validDataOffset = offset;\n+            }\n+            return read();\n+        }\n+\n+        if (blockSize >= offset\n+                + ENTRY_HEADER_SIZE\n+                + headEntry.getLength()) {\n+            entryBuffer.poll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDIxMjMzOA==", "bodyText": "Should peek first? If the next entry exceeds the max block size, what the behavior?\n\nSince block size is decided when block is created, I'm afraid we have to make the next block larger than an entry, I will supplement the code.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560212338", "createdAt": "2021-01-19T14:25:02Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;\n+    int validDataOffset = NOT_INITIALIZED;\n+    CompositeByteBuf currentEntry;\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getBeginEntryId() {\n+        return beginEntryId;\n+    }\n+\n+    public long getBlockSize() {\n+        return blockSize;\n+    }\n+\n+\n+    public BufferedOffloadStream(int blockSize,\n+                                 ConcurrentLinkedQueue<Entry> entryBuffer,\n+                                 SegmentInfoImpl segmentInfo,\n+                                 long ledgerId,\n+                                 long beginEntryId,\n+                                 AtomicLong bufferLength) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.segmentInfo = segmentInfo;\n+        this.entryBuffer = entryBuffer;\n+        this.bufferLength = bufferLength;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n+\n+    @Override\n+    public int read() throws IOException {\n+        if (blockHead.available() > 0) {\n+            offset++;\n+            return blockHead.read();\n+        }\n+        //if current exists, use current first\n+        if (currentEntry != null) {\n+            if (currentEntry.readableBytes() > 0) {\n+                offset += 1;\n+                return currentEntry.readUnsignedByte();\n+            } else {\n+                currentEntry.release();\n+                currentEntry = null;\n+            }\n+        }\n+\n+        if (blockSize <= offset) {\n+            return -1;\n+        } else if (validDataOffset != NOT_INITIALIZED) {\n+            return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n+        }\n+\n+        Entry headEntry;\n+\n+        while ((headEntry = entryBuffer.peek()) == null) {\n+            if (segmentInfo.isClosed()) {\n+                if (validDataOffset == NOT_INITIALIZED) {\n+                    validDataOffset = offset;\n+                }\n+                return read();\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    log.error(\"sleep failed\", e);\n+                }\n+            }\n+        }\n+\n+        //create new block when a ledger end\n+        if (headEntry.getLedgerId() != this.ledgerId) {\n+            if (validDataOffset == NOT_INITIALIZED) {\n+                validDataOffset = offset;\n+            }\n+            return read();\n+        }\n+\n+        if (blockSize >= offset\n+                + ENTRY_HEADER_SIZE\n+                + headEntry.getLength()) {\n+            entryBuffer.poll();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4MjAyNg=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjc5MTE1OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDo1MjoxMlrOIWJA-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNTo1ODowOVrOIWVKFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4NzI5MQ==", "bodyText": "is the streamingParts clear automatically after complete the upload? I can't find any places to clear the streamingParts. BTW, the streamingParts seems can be a local variable", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560087291", "createdAt": "2021-01-19T10:52:12Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDIxMzU4MQ==", "bodyText": "is the streamingParts clear automatically after complete the upload? I can't find any places to clear the streamingParts. BTW, the streamingParts seems can be a local variable\n\nAs we discussed formerly, a new offloader will be created once the segment offloaded, so streamingParts will be garbage collected with the offloader.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560213581", "createdAt": "2021-01-19T14:26:37Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4NzI5MQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI4NjIyOA==", "bodyText": "If the streamingParts does not clear, for the next offload loop, how to avoid offload the duplicate data?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560286228", "createdAt": "2021-01-19T15:58:09Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4NzI5MQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 221}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjc5NzA4OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDo1Mzo1MFrOIWJEwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDo1Mzo1MFrOIWJEwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4ODI1Ng==", "bodyText": "Is it need to close?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560088256", "createdAt": "2021-01-19T10:53:50Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 227}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjgwMTg4OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDo1NTowNVrOIWJHhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDo1NTowNVrOIWJHhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4ODk2NA==", "bodyText": "Please provide more information, if you have many topics, the debug log can't help find any thing here.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560088964", "createdAt": "2021-01-19T10:55:05Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 240}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjgwMjQ3OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDo1NToxNVrOIWJH5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMDo1NToxNVrOIWJH5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4OTA2Mw==", "bodyText": "Same as above comment", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560089063", "createdAt": "2021-01-19T10:55:15Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 242}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjgzODYxOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMTowNDozNFrOIWJeBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNTowODoxNlrOIWSveA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NDcyNg==", "bodyText": "here will be a serious problem because the streaming offload will retry to get entry from the queue for every 100ms, if a topic does not write any messages, the thread will available for other topic offloading until the offload segment timeout(closed) right?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560094726", "createdAt": "2021-01-19T11:04:34Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 244}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI0NjY0OA==", "bodyText": "I used schedule instead of sleep", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560246648", "createdAt": "2021-01-19T15:08:16Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NDcyNg=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 244}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjg0Njk3OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMTowNjo1NFrOIWJjTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNTowODo0NlrOIWSxDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NjA3OQ==", "bodyText": "We should to recycle the entries after read complete?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560096079", "createdAt": "2021-01-19T11:06:54Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;\n+    int validDataOffset = NOT_INITIALIZED;\n+    CompositeByteBuf currentEntry;\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getBeginEntryId() {\n+        return beginEntryId;\n+    }\n+\n+    public long getBlockSize() {\n+        return blockSize;\n+    }\n+\n+\n+    public BufferedOffloadStream(int blockSize,\n+                                 ConcurrentLinkedQueue<Entry> entryBuffer,\n+                                 SegmentInfoImpl segmentInfo,\n+                                 long ledgerId,\n+                                 long beginEntryId,\n+                                 AtomicLong bufferLength) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.segmentInfo = segmentInfo;\n+        this.entryBuffer = entryBuffer;\n+        this.bufferLength = bufferLength;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n+\n+    @Override\n+    public int read() throws IOException {\n+        if (blockHead.available() > 0) {\n+            offset++;\n+            return blockHead.read();\n+        }\n+        //if current exists, use current first\n+        if (currentEntry != null) {\n+            if (currentEntry.readableBytes() > 0) {\n+                offset += 1;\n+                return currentEntry.readUnsignedByte();\n+            } else {\n+                currentEntry.release();\n+                currentEntry = null;\n+            }\n+        }\n+\n+        if (blockSize <= offset) {\n+            return -1;\n+        } else if (validDataOffset != NOT_INITIALIZED) {\n+            return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n+        }\n+\n+        Entry headEntry;\n+\n+        while ((headEntry = entryBuffer.peek()) == null) {\n+            if (segmentInfo.isClosed()) {\n+                if (validDataOffset == NOT_INITIALIZED) {\n+                    validDataOffset = offset;\n+                }\n+                return read();\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    log.error(\"sleep failed\", e);\n+                }\n+            }\n+        }\n+\n+        //create new block when a ledger end\n+        if (headEntry.getLedgerId() != this.ledgerId) {\n+            if (validDataOffset == NOT_INITIALIZED) {\n+                validDataOffset = offset;\n+            }\n+            return read();\n+        }\n+\n+        if (blockSize >= offset\n+                + ENTRY_HEADER_SIZE\n+                + headEntry.getLength()) {\n+            entryBuffer.poll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI0NzA1Mw==", "bodyText": "headEntry.release added", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560247053", "createdAt": "2021-01-19T15:08:46Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;\n+    int validDataOffset = NOT_INITIALIZED;\n+    CompositeByteBuf currentEntry;\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getBeginEntryId() {\n+        return beginEntryId;\n+    }\n+\n+    public long getBlockSize() {\n+        return blockSize;\n+    }\n+\n+\n+    public BufferedOffloadStream(int blockSize,\n+                                 ConcurrentLinkedQueue<Entry> entryBuffer,\n+                                 SegmentInfoImpl segmentInfo,\n+                                 long ledgerId,\n+                                 long beginEntryId,\n+                                 AtomicLong bufferLength) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.segmentInfo = segmentInfo;\n+        this.entryBuffer = entryBuffer;\n+        this.bufferLength = bufferLength;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n+\n+    @Override\n+    public int read() throws IOException {\n+        if (blockHead.available() > 0) {\n+            offset++;\n+            return blockHead.read();\n+        }\n+        //if current exists, use current first\n+        if (currentEntry != null) {\n+            if (currentEntry.readableBytes() > 0) {\n+                offset += 1;\n+                return currentEntry.readUnsignedByte();\n+            } else {\n+                currentEntry.release();\n+                currentEntry = null;\n+            }\n+        }\n+\n+        if (blockSize <= offset) {\n+            return -1;\n+        } else if (validDataOffset != NOT_INITIALIZED) {\n+            return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n+        }\n+\n+        Entry headEntry;\n+\n+        while ((headEntry = entryBuffer.peek()) == null) {\n+            if (segmentInfo.isClosed()) {\n+                if (validDataOffset == NOT_INITIALIZED) {\n+                    validDataOffset = offset;\n+                }\n+                return read();\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    log.error(\"sleep failed\", e);\n+                }\n+            }\n+        }\n+\n+        //create new block when a ledger end\n+        if (headEntry.getLedgerId() != this.ledgerId) {\n+            if (validDataOffset == NOT_INITIALIZED) {\n+                validDataOffset = offset;\n+            }\n+            return read();\n+        }\n+\n+        if (blockSize >= offset\n+                + ENTRY_HEADER_SIZE\n+                + headEntry.getLength()) {\n+            entryBuffer.poll();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NjA3OQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjg3NzQ2OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMToxNDoyOFrOIWJ1sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNDozMjowOVrOIWQ_ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwMDc4NA==", "bodyText": "also close the dataStreams?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560100784", "createdAt": "2021-01-19T11:14:28Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDIxODAxNA==", "bodyText": "Seems close dataStreams will close inputStreams,too.\nSo I replaced close inputStreams to input close dataStreams", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560218014", "createdAt": "2021-01-19T14:32:09Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwMDc4NA=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjg4NDA3OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMToxNjoxNVrOIWJ5og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMToxNjoxNVrOIWJ5og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwMTc5NA==", "bodyText": "Why throw bk exception here? does IllegalArgumentException works?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560101794", "createdAt": "2021-01-19T11:16:15Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 128}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNjkwOTYzOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMToyMzowOFrOIWKJHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNTowOTowNFrOIWSx_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwNTc1Ng==", "bodyText": "Please double confirm the groupedReaders are sorted by ledger Id, entry id, Otherwise, this will bread the entry read in order guarantee", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560105756", "createdAt": "2021-01-19T11:23:08Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());\n+            return promise;\n+        }\n+        executor.submit(() -> {\n+            List<LedgerEntry> entries = new ArrayList<LedgerEntry>();\n+            List<GroupedReader> groupedReaders = null;\n+            try {\n+                groupedReaders = getGroupedReader(firstEntry, lastEntry);\n+            } catch (Exception e) {\n+                promise.completeExceptionally(e);\n+                return;\n+            }\n+\n+            for (GroupedReader groupedReader : groupedReaders) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI0NzI5NQ==", "bodyText": "double confirm code added", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560247295", "createdAt": "2021-01-19T15:09:04Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());\n+            return promise;\n+        }\n+        executor.submit(() -> {\n+            List<LedgerEntry> entries = new ArrayList<LedgerEntry>();\n+            List<GroupedReader> groupedReaders = null;\n+            try {\n+                groupedReaders = getGroupedReader(firstEntry, lastEntry);\n+            } catch (Exception e) {\n+                promise.completeExceptionally(e);\n+                return;\n+            }\n+\n+            for (GroupedReader groupedReader : groupedReaders) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwNTc1Ng=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDQ2NTM0OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMzo1NToyMFrOIWr2Jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMzo1NToyMFrOIWr2Jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1Nzk1OQ==", "bodyText": "streamingoffload()?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560657959", "createdAt": "2021-01-20T03:55:20Z", "author": {"login": "zymap"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +150,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * longterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDQ3NDk1OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMzo1OTo1OVrOIWr7gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNFQxNDoyNTozNVrOIZNHlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ==", "bodyText": "Do we need to check the returned value? It's might be null.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560659329", "createdAt": "2021-01-20T03:59:59Z", "author": {"login": "zymap"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1685,14 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc0MjAxMA==", "bodyText": "I added comment for the interface, yes it may return a future with null, the caller should deal with it.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560742010", "createdAt": "2021-01-20T07:53:21Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1685,14 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ=="}, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc1NjU1Mg==", "bodyText": "We might can throw an exception for that?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560756552", "createdAt": "2021-01-20T08:19:42Z", "author": {"login": "zymap"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1685,14 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ=="}, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzEwMDYyOA==", "bodyText": "And please consider returns a copy of LedgerInfo to void be modified from external?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563100628", "createdAt": "2021-01-23T11:03:56Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1685,14 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ=="}, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzMwMDI0NQ==", "bodyText": "@codelipenghui The LedgerInfo class is generated by protobuf, which is already an immutable class, we don't need to do extra things to make it immutable.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563300245", "createdAt": "2021-01-24T14:25:35Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1685,14 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ=="}, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDQ4NDU4OnYy", "diffSide": "RIGHT", "path": "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/OffloadPrefixReadTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNDowNToyNFrOIWsBLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwODoyMDozNlrOIWx5pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY2MDc4MA==", "bodyText": "any() should be any type, why we need to cast it to the UUID?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560660780", "createdAt": "2021-01-20T04:05:24Z", "author": {"login": "zymap"}, "path": "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/OffloadPrefixReadTest.java", "diffHunk": "@@ -97,21 +97,21 @@ public void testOffloadRead() throws Exception {\n             assertEquals(new String(e.getData()), \"entry-\" + i++);\n         }\n         verify(offloader, times(1))\n-            .readOffloaded(anyLong(), any(), anyMap());\n+                .readOffloaded(anyLong(), (UUID) any(), anyMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc0MjU5MQ==", "bodyText": "Because readOffloaded have different version of overload, I used cast to avoid ambiguous method call.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560742591", "createdAt": "2021-01-20T07:54:35Z", "author": {"login": "Renkai"}, "path": "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/OffloadPrefixReadTest.java", "diffHunk": "@@ -97,21 +97,21 @@ public void testOffloadRead() throws Exception {\n             assertEquals(new String(e.getData()), \"entry-\" + i++);\n         }\n         verify(offloader, times(1))\n-            .readOffloaded(anyLong(), any(), anyMap());\n+                .readOffloaded(anyLong(), (UUID) any(), anyMap());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY2MDc4MA=="}, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc1NzE1OA==", "bodyText": "okay, you can use any(UUID.class) to do that.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560757158", "createdAt": "2021-01-20T08:20:36Z", "author": {"login": "zymap"}, "path": "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/OffloadPrefixReadTest.java", "diffHunk": "@@ -97,21 +97,21 @@ public void testOffloadRead() throws Exception {\n             assertEquals(new String(e.getData()), \"entry-\" + i++);\n         }\n         verify(offloader, times(1))\n-            .readOffloaded(anyLong(), any(), anyMap());\n+                .readOffloaded(anyLong(), (UUID) any(), anyMap());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY2MDc4MA=="}, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDU2MTA2OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNDozNTo1OFrOIWsxdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwODowMjoyN1rOIWxQjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY3MzE0Mg==", "bodyText": "If we have another call for the streamingOffloading, do those variables will impact the previous offload process? Because the following offload loop still uses the same variables.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560673142", "createdAt": "2021-01-20T04:35:58Z", "author": {"login": "zymap"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +266,213 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new OffloadSegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(),\n+                driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc0NjYzNw==", "bodyText": "If we have another call for the streamingOffloading, do those variables will impact the previous offload process? Because the following offload loop still uses the same variables.\n\nIn our design, an offloader instance can only call streamingOffload once, I will add some document and check on it.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560746637", "createdAt": "2021-01-20T08:02:27Z", "author": {"login": "Renkai"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +266,213 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new OffloadSegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(),\n+                driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY3MzE0Mg=="}, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDU2MTc4OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNDozNjoxN1rOIWsx3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNDozNjoxN1rOIWsx3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY3MzI0Nw==", "bodyText": "same above.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560673247", "createdAt": "2021-01-20T04:36:17Z", "author": {"login": "zymap"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +266,213 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new OffloadSegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(),\n+                driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU0NjQyODkxOnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yM1QxMzozMDoyMlrOIZEIsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yM1QxMzozMDoyMlrOIZEIsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE1MzA3Mw==", "bodyText": "This should be OffloadIndexBlockV2Builder?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563153073", "createdAt": "2021-01-23T13:30:22Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.OffloadIndexBlockBuilderImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n+\n+/**\n+ * Interface for builder of index block used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+@LimitedPrivate\n+public interface StreamingOffloadIndexBlockBuilder {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7794e184a56fd7ac007a1180e2263563d060d364"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU0NjQyOTg0OnYy", "diffSide": "RIGHT", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingOffloadIndexBlockImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yM1QxMzozMjoxMVrOIZEJLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yM1QxMzozMjoxMVrOIZEJLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE1MzE5Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class StreamingOffloadIndexBlockImpl implements OffloadIndexBlockV2 {\n          \n          \n            \n            public class OffloadIndexBlockV2Impl implements OffloadIndexBlockV2 {", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563153197", "createdAt": "2021-01-23T13:32:11Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingOffloadIndexBlockImpl.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.Maps;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufInputStream;\n+import io.netty.util.Recycler;\n+import io.netty.util.Recycler.Handle;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableMap;\n+import java.util.Objects;\n+import java.util.TreeMap;\n+import org.apache.bookkeeper.client.api.DigestType;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.mledger.offload.jcloud.OffloadIndexBlock.IndexInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.OffloadIndexBlockV2;\n+import org.apache.bookkeeper.mledger.offload.jcloud.OffloadIndexEntry;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n+import org.apache.bookkeeper.net.BookieId;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingOffloadIndexBlockImpl implements OffloadIndexBlockV2 {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7794e184a56fd7ac007a1180e2263563d060d364"}, "originalPosition": 46}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2655, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}